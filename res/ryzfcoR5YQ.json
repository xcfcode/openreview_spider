{"notes": [{"id": "ryzfcoR5YQ", "original": "SkxO5iocYX", "number": 517, "cdate": 1538087818374, "ddate": null, "tcdate": 1538087818374, "tmdate": 1545355386178, "tddate": null, "forum": "ryzfcoR5YQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting", "abstract": "Accurate spatio-temporal traffic forecasting is a fundamental task that has wide applications in city management, transportation area and financial domain. There are many factors that make this significant task also challenging, like: (1) maze-like road network makes the spatial dependency complex; (2) the traffic-time relationships bring non-linear temporal complication; (3) with the larger road network, the difficulty of flow forecasting grows. The prevalent and state-of-the-art methods have mainly been discussed on datasets covering relatively small districts and short time span, e.g., the dataset that is collected within a city during months. To forecast the traffic flow across a wide area and overcome the mentioned challenges, we design and propose a promising forecasting model called Layerwise Recurrent Autoencoder (LRA), in which a three-layer stacked autoencoder (SAE) architecture is used to obtain temporal traffic correlations and a recurrent neural networks (RNNs) model for prediction. The convolutional neural networks (CNNs) model is also employed to extract spatial traffic information within the transport topology for more accurate prediction. To the best of our knowledge, there is no general and effective method for traffic flow prediction in large area which covers a group of cities. The experiment is completed on such large scale real-world traffic datasets to show superiority. And a smaller dataset is exploited to prove universality of the proposed model. And evaluations show that our model outperforms the state-of-the-art baselines by 6% - 15%.", "keywords": ["traffic flow forecasting", "spatiotemporal dependencies", "deep learning", "intelligent transportation system"], "authorids": ["zhaopeize@sensetime.com", "caidanfeng@sensetime.com", "zhangshaokun@sensetime.com", "chenfeng@xmu.edu.cn", "zhangzhemin@xmu.edu.cn", "cwang@xmu.edu.cn", "junli@xmu.edu.cn"], "authors": ["Peize Zhao", "Danfeng Cai", "Shaokun Zhang", "Feng Chen", "Zhemin Zhang", "Cheng Wang", "Jonathan Li"], "TL;DR": "We propose Layerwise Recurrent Autoencoder with effective spatiotemporal dependencies modeling for general traffic flow forecasting.", "pdf": "/pdf/819fe626b59be1697c22ab5d9570defb54e49754.pdf", "paperhash": "zhao|layerwise_recurrent_autoencoder_for_general_realworld_traffic_flow_forecasting", "_bibtex": "@misc{\nzhao2019layerwise,\ntitle={Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting},\nauthor={Peize Zhao and Danfeng Cai and Shaokun Zhang and Feng Chen and Zhemin Zhang and Cheng Wang and Jonathan Li},\nyear={2019},\nurl={https://openreview.net/forum?id=ryzfcoR5YQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "ryxjRj-Zx4", "original": null, "number": 1, "cdate": 1544784851138, "ddate": null, "tcdate": 1544784851138, "tmdate": 1545354524105, "tddate": null, "forum": "ryzfcoR5YQ", "replyto": "ryzfcoR5YQ", "invitation": "ICLR.cc/2019/Conference/-/Paper517/Meta_Review", "content": {"metareview": "The paper proposes an interesting neural architecture for traffic flow forecasting, which is tested on a number of datasets. Unfortunately, the lack of clarity as well as  precision  in writing appears to be a big issue for this paper, which prevents it from being accepted for publication in its current form. However, the reviewers did provide valuable feedback regarding writing, explanation, presentation and structure,  that the paper would benefit from.\n", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "lack of clarity and precision in writing"}, "signatures": ["ICLR.cc/2019/Conference/Paper517/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper517/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting", "abstract": "Accurate spatio-temporal traffic forecasting is a fundamental task that has wide applications in city management, transportation area and financial domain. There are many factors that make this significant task also challenging, like: (1) maze-like road network makes the spatial dependency complex; (2) the traffic-time relationships bring non-linear temporal complication; (3) with the larger road network, the difficulty of flow forecasting grows. The prevalent and state-of-the-art methods have mainly been discussed on datasets covering relatively small districts and short time span, e.g., the dataset that is collected within a city during months. To forecast the traffic flow across a wide area and overcome the mentioned challenges, we design and propose a promising forecasting model called Layerwise Recurrent Autoencoder (LRA), in which a three-layer stacked autoencoder (SAE) architecture is used to obtain temporal traffic correlations and a recurrent neural networks (RNNs) model for prediction. The convolutional neural networks (CNNs) model is also employed to extract spatial traffic information within the transport topology for more accurate prediction. To the best of our knowledge, there is no general and effective method for traffic flow prediction in large area which covers a group of cities. The experiment is completed on such large scale real-world traffic datasets to show superiority. And a smaller dataset is exploited to prove universality of the proposed model. And evaluations show that our model outperforms the state-of-the-art baselines by 6% - 15%.", "keywords": ["traffic flow forecasting", "spatiotemporal dependencies", "deep learning", "intelligent transportation system"], "authorids": ["zhaopeize@sensetime.com", "caidanfeng@sensetime.com", "zhangshaokun@sensetime.com", "chenfeng@xmu.edu.cn", "zhangzhemin@xmu.edu.cn", "cwang@xmu.edu.cn", "junli@xmu.edu.cn"], "authors": ["Peize Zhao", "Danfeng Cai", "Shaokun Zhang", "Feng Chen", "Zhemin Zhang", "Cheng Wang", "Jonathan Li"], "TL;DR": "We propose Layerwise Recurrent Autoencoder with effective spatiotemporal dependencies modeling for general traffic flow forecasting.", "pdf": "/pdf/819fe626b59be1697c22ab5d9570defb54e49754.pdf", "paperhash": "zhao|layerwise_recurrent_autoencoder_for_general_realworld_traffic_flow_forecasting", "_bibtex": "@misc{\nzhao2019layerwise,\ntitle={Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting},\nauthor={Peize Zhao and Danfeng Cai and Shaokun Zhang and Feng Chen and Zhemin Zhang and Cheng Wang and Jonathan Li},\nyear={2019},\nurl={https://openreview.net/forum?id=ryzfcoR5YQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper517/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353189696, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryzfcoR5YQ", "replyto": "ryzfcoR5YQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper517/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper517/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper517/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353189696}}}, {"id": "Syxx2arKa7", "original": null, "number": 4, "cdate": 1542180263616, "ddate": null, "tcdate": 1542180263616, "tmdate": 1542180263616, "tddate": null, "forum": "ryzfcoR5YQ", "replyto": "H1xTDOudh7", "invitation": "ICLR.cc/2019/Conference/-/Paper517/Official_Comment", "content": {"title": "Reply for Reviewer3", "comment": "Thanks for your comments. Here's our reply:\n\nFor your major comments: \n1)\tThe two datasets are introduced in the Appendix C, even with a distribution of sensors of the larger one. Please check it in our paper.\n2)\tWe listed some key parameters in Appendix D, we believe with information of our paper, the readers can easily re-produce our work with Tensorflow. Of course, it would be easier if we make our code public, but the intellectual property right was kept by our company, and will be used in business projects. If the time is proper, the code would be released.\n3)\tThe experiments are performed to show the better performance of our method over others, and the efficiency of our design of the network (SAE and GCN in Section 4.3), we think the experiments are clear in Section 4, including the other techniques (AR, ARIMA, ESN, LSTM and DCRNN). Please check our paper, especially in Section 4.\n4)\tTraffic flow is a common terminology in traffic-related forecasting area, which means the number of moving pedestrians or cars in traffic network.\n5)\tYes, we agree that our language skills are poor, and needed to be improved.\n\nSpecific points:\n1)\tIt is natural in traffic forecasting that the more complex the road topology is the harder prediction would be. Since the complexity of traffic condition would exponentially grow with the larger traffic network.\n2)\tThe superiority means \"better performance\", that we originally use driving distance to build spatial dependency, and our model is generalized for traffic forecasting in both large and small datasets.\n3)\tYes, this sentence should be supported with citations.\n4)\tSorry for giving you this impression, might because of our English skills, but this paper do have some novel contributions. This paper is focused on the design of the model and the originality of our model. We also compared the proposed model with other baselines, to show the efficiency and generalization.\n5)\tThe related works are common forecasting methods and classified in two categories: statistic methods and deep learning methods. We selected some representative methods in both categories as baselines to compare with our model. And we also used some ideas from the related works (Diffusion convolutional recurrent neural network: Data-driven traffic forecasting and Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction)\n6)\tTo extract temporal relationships within the history traffic flows, we took SAE in the layer-wise structure as a basic unit to extract stable high-level temporal features, which is the preparation of traffic prediction.\n7)\tWe put Appendix B in the end because we think the structures of autoencoder and SAE should be familiar in the forecasting field, and only for reference. The reason Appendix C was put behind the main body is because we want to keep the integrity and fluency in the experiment section.\n8)\tThis is our fault, x^{(1)} is the input sequence of autoencoder, we should make it more clear.\n9)\tSparsity constrain is sparsity, but in another presentation. When sparsity constraints are added to the objective function, an autoencoder becomes a sparse autoencoder, which considers the sparse representation of the hidden layer. Sparsity is used to avoid over-fitting.\n10)\tThe weights can be obtained by some API of Tensorflow, and during the training process, they are trained by BP method.\n11)\tWe think it would be better for reading experiment that reader can know the structure of model, before he sees it.\n12)\tTake the large dataset as example, we have 365 days of traffic data, and the first 80% are randomly divided into training sets and validation sets with a ratio of 7:1, i.e. 255 days for training, and 37 days for evaluation. The remaining 20% (73 days) is used as test sets. We believe this division method is closer to real use.\n13)\tWe don't get your point in your comment, could you please make it clear?\n\nHope our explanations can help you to understand our paper.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper517/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper517/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper517/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting", "abstract": "Accurate spatio-temporal traffic forecasting is a fundamental task that has wide applications in city management, transportation area and financial domain. There are many factors that make this significant task also challenging, like: (1) maze-like road network makes the spatial dependency complex; (2) the traffic-time relationships bring non-linear temporal complication; (3) with the larger road network, the difficulty of flow forecasting grows. The prevalent and state-of-the-art methods have mainly been discussed on datasets covering relatively small districts and short time span, e.g., the dataset that is collected within a city during months. To forecast the traffic flow across a wide area and overcome the mentioned challenges, we design and propose a promising forecasting model called Layerwise Recurrent Autoencoder (LRA), in which a three-layer stacked autoencoder (SAE) architecture is used to obtain temporal traffic correlations and a recurrent neural networks (RNNs) model for prediction. The convolutional neural networks (CNNs) model is also employed to extract spatial traffic information within the transport topology for more accurate prediction. To the best of our knowledge, there is no general and effective method for traffic flow prediction in large area which covers a group of cities. The experiment is completed on such large scale real-world traffic datasets to show superiority. And a smaller dataset is exploited to prove universality of the proposed model. And evaluations show that our model outperforms the state-of-the-art baselines by 6% - 15%.", "keywords": ["traffic flow forecasting", "spatiotemporal dependencies", "deep learning", "intelligent transportation system"], "authorids": ["zhaopeize@sensetime.com", "caidanfeng@sensetime.com", "zhangshaokun@sensetime.com", "chenfeng@xmu.edu.cn", "zhangzhemin@xmu.edu.cn", "cwang@xmu.edu.cn", "junli@xmu.edu.cn"], "authors": ["Peize Zhao", "Danfeng Cai", "Shaokun Zhang", "Feng Chen", "Zhemin Zhang", "Cheng Wang", "Jonathan Li"], "TL;DR": "We propose Layerwise Recurrent Autoencoder with effective spatiotemporal dependencies modeling for general traffic flow forecasting.", "pdf": "/pdf/819fe626b59be1697c22ab5d9570defb54e49754.pdf", "paperhash": "zhao|layerwise_recurrent_autoencoder_for_general_realworld_traffic_flow_forecasting", "_bibtex": "@misc{\nzhao2019layerwise,\ntitle={Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting},\nauthor={Peize Zhao and Danfeng Cai and Shaokun Zhang and Feng Chen and Zhemin Zhang and Cheng Wang and Jonathan Li},\nyear={2019},\nurl={https://openreview.net/forum?id=ryzfcoR5YQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper517/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621623792, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryzfcoR5YQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper517/Authors", "ICLR.cc/2019/Conference/Paper517/Reviewers", "ICLR.cc/2019/Conference/Paper517/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper517/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper517/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper517/Authors|ICLR.cc/2019/Conference/Paper517/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper517/Reviewers", "ICLR.cc/2019/Conference/Paper517/Authors", "ICLR.cc/2019/Conference/Paper517/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621623792}}}, {"id": "rJlQtpHta7", "original": null, "number": 3, "cdate": 1542180219515, "ddate": null, "tcdate": 1542180219515, "tmdate": 1542180219515, "tddate": null, "forum": "ryzfcoR5YQ", "replyto": "BkgiKcMihQ", "invitation": "ICLR.cc/2019/Conference/-/Paper517/Official_Comment", "content": {"title": "Reply for Reviewer2", "comment": "Thanks for your review comments. Here's our reply:\n\n1)\tYou are right, we should cite some publications to support it.\n\n2)\tAs for our contribution one, the purpose we take experiments on both large and small datasets is to test the generalization of our network. Therefore, we trained our model on both large and small datasets, and tested with these two datasets. We compared our outputs with many baselines in Section 4, on both datasets, please check this in our paper.\n\nAs for contribution two, we employed three different time series sequences to provide multi-perspective fusion learning. With the layer-wise structure, the daily and weekly periodic features of traffic volume are captured. In another word, a stack of historical sequence data is used in our experiments, rather than \"lagged\" time data.\n\nIn the contribution three, we used driving distance to determine the spatial dependency, and this contribution was novel. And with the driving distance, we built a graph-based matrix, as a result, we then applied GCN to learn the inner features from the graph-based matrix. The use of GCN was inspired by one of our baselines, DCRNN (Diffusion convolutional recurrent neural network: Data-driven traffic forecasting). In DCRNN, they designed an experiment of comparing their diffusion method with the use of GCN. In their experiment, the result of diffusion method was better than GCN, but their dataset was not so large as ours, and when we compare their method with our datasets, the performance was not so good, even in our smaller dataset. Hence, we think the application of GCN in forecasting task is also novel.\n\n3)\tThe reason why SAE is the first operator in the network is to extract stable high-level temporal features. We put this part in the beginning of Section 3. And the use of SAE do help the performance of forecasting, please check the content in Section 4.3.\n\n4)\tThe sparsity of SAE was a proved solution of overfitting in practice. And the key of our paper was to provide a novel method for general forecasting task, therefore, we don't put much words on other choice, but just use sparsity as a common knowledge.\n\n5)\tThe spatial dependency was determined by driving distance in our paper, and that should be a certain process, rather an assumption. Since the aim of our model was to provide accurate prediction in general situations, and the spatial dependency is crucial, since the spatial dependency is variable in different places. With driving distance and GCN, the model can grasp the most precise priori knowledge of spatial locations.\n\n6)\tIn fact, we select the time based on a scheme, not randomly. Take the large dataset as example, we have 365 days of traffic data, and the first 80% are randomly divided into training sets and validation sets with a ratio of 7:1, i.e. 255 days for training, and 37 days for evaluation. The remaining 20% (73 days) is used as test sets. We believe this division method is closer to real use.\n\nIf you have further questions, we are happy to discuss with you.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper517/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper517/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper517/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting", "abstract": "Accurate spatio-temporal traffic forecasting is a fundamental task that has wide applications in city management, transportation area and financial domain. There are many factors that make this significant task also challenging, like: (1) maze-like road network makes the spatial dependency complex; (2) the traffic-time relationships bring non-linear temporal complication; (3) with the larger road network, the difficulty of flow forecasting grows. The prevalent and state-of-the-art methods have mainly been discussed on datasets covering relatively small districts and short time span, e.g., the dataset that is collected within a city during months. To forecast the traffic flow across a wide area and overcome the mentioned challenges, we design and propose a promising forecasting model called Layerwise Recurrent Autoencoder (LRA), in which a three-layer stacked autoencoder (SAE) architecture is used to obtain temporal traffic correlations and a recurrent neural networks (RNNs) model for prediction. The convolutional neural networks (CNNs) model is also employed to extract spatial traffic information within the transport topology for more accurate prediction. To the best of our knowledge, there is no general and effective method for traffic flow prediction in large area which covers a group of cities. The experiment is completed on such large scale real-world traffic datasets to show superiority. And a smaller dataset is exploited to prove universality of the proposed model. And evaluations show that our model outperforms the state-of-the-art baselines by 6% - 15%.", "keywords": ["traffic flow forecasting", "spatiotemporal dependencies", "deep learning", "intelligent transportation system"], "authorids": ["zhaopeize@sensetime.com", "caidanfeng@sensetime.com", "zhangshaokun@sensetime.com", "chenfeng@xmu.edu.cn", "zhangzhemin@xmu.edu.cn", "cwang@xmu.edu.cn", "junli@xmu.edu.cn"], "authors": ["Peize Zhao", "Danfeng Cai", "Shaokun Zhang", "Feng Chen", "Zhemin Zhang", "Cheng Wang", "Jonathan Li"], "TL;DR": "We propose Layerwise Recurrent Autoencoder with effective spatiotemporal dependencies modeling for general traffic flow forecasting.", "pdf": "/pdf/819fe626b59be1697c22ab5d9570defb54e49754.pdf", "paperhash": "zhao|layerwise_recurrent_autoencoder_for_general_realworld_traffic_flow_forecasting", "_bibtex": "@misc{\nzhao2019layerwise,\ntitle={Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting},\nauthor={Peize Zhao and Danfeng Cai and Shaokun Zhang and Feng Chen and Zhemin Zhang and Cheng Wang and Jonathan Li},\nyear={2019},\nurl={https://openreview.net/forum?id=ryzfcoR5YQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper517/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621623792, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryzfcoR5YQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper517/Authors", "ICLR.cc/2019/Conference/Paper517/Reviewers", "ICLR.cc/2019/Conference/Paper517/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper517/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper517/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper517/Authors|ICLR.cc/2019/Conference/Paper517/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper517/Reviewers", "ICLR.cc/2019/Conference/Paper517/Authors", "ICLR.cc/2019/Conference/Paper517/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621623792}}}, {"id": "rkxDV6Bt6m", "original": null, "number": 2, "cdate": 1542180142785, "ddate": null, "tcdate": 1542180142785, "tmdate": 1542180142785, "tddate": null, "forum": "ryzfcoR5YQ", "replyto": "H1lJ6bITn7", "invitation": "ICLR.cc/2019/Conference/-/Paper517/Official_Comment", "content": {"title": "Reply for Reviewer1", "comment": "Thanks for your review and sorry for the confusions.\n\nIn the proposed model, there are three main parts and the motivations behind them are listed here:\n\nSAE: Regardless of the complex traffic trend, the SAE can stably extract implicit high-level features, which have almost the same characteristics as the original input. Besides, the general purpose of using SAE is to reduce the data dimension, this is also a motivation of exploiting SAE. Proved by experiments in Section 4.2, with SAE, the loss value of the model can drop quickly.\n\nRNN: As the commonly used method on time series prediction, RNN was used to process the implicit high-level features extracted by SAE. By the way, we used a layer-wise structured model, which was inspired by Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction. The structure provided the model a conception of multiple perspectives, that considered three sequence of history data (current time volume, the volume of the time one week ago and the volume of the time four weeks ago). The model can not only learn the peak-valley periods of traffic in days, but learn the peak-valley periods in weeks.\n\nGCN: The motivation of using GCN was because the use of driving distance. Originally, we take driving distance, rather than Euclid distance to build spatial dependency. And based on driving distance, a graph-based matrix was built, which records the correlation between different sensors. As a result, graph convolutional network is used to learn prior knowledge in graph-based matrix, and it is regarded as an important factor in traffic forecasting. In Deep Spatio-Temporal Residual Networks for Citywide Crowd Flows Prediction, the authors used the traffic volume in region blocks to forecast traffic volume, but didn't consider the spatial correlations.\n\nThese are our motivation of proposed model, if you have further questions, please let us know.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper517/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper517/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper517/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting", "abstract": "Accurate spatio-temporal traffic forecasting is a fundamental task that has wide applications in city management, transportation area and financial domain. There are many factors that make this significant task also challenging, like: (1) maze-like road network makes the spatial dependency complex; (2) the traffic-time relationships bring non-linear temporal complication; (3) with the larger road network, the difficulty of flow forecasting grows. The prevalent and state-of-the-art methods have mainly been discussed on datasets covering relatively small districts and short time span, e.g., the dataset that is collected within a city during months. To forecast the traffic flow across a wide area and overcome the mentioned challenges, we design and propose a promising forecasting model called Layerwise Recurrent Autoencoder (LRA), in which a three-layer stacked autoencoder (SAE) architecture is used to obtain temporal traffic correlations and a recurrent neural networks (RNNs) model for prediction. The convolutional neural networks (CNNs) model is also employed to extract spatial traffic information within the transport topology for more accurate prediction. To the best of our knowledge, there is no general and effective method for traffic flow prediction in large area which covers a group of cities. The experiment is completed on such large scale real-world traffic datasets to show superiority. And a smaller dataset is exploited to prove universality of the proposed model. And evaluations show that our model outperforms the state-of-the-art baselines by 6% - 15%.", "keywords": ["traffic flow forecasting", "spatiotemporal dependencies", "deep learning", "intelligent transportation system"], "authorids": ["zhaopeize@sensetime.com", "caidanfeng@sensetime.com", "zhangshaokun@sensetime.com", "chenfeng@xmu.edu.cn", "zhangzhemin@xmu.edu.cn", "cwang@xmu.edu.cn", "junli@xmu.edu.cn"], "authors": ["Peize Zhao", "Danfeng Cai", "Shaokun Zhang", "Feng Chen", "Zhemin Zhang", "Cheng Wang", "Jonathan Li"], "TL;DR": "We propose Layerwise Recurrent Autoencoder with effective spatiotemporal dependencies modeling for general traffic flow forecasting.", "pdf": "/pdf/819fe626b59be1697c22ab5d9570defb54e49754.pdf", "paperhash": "zhao|layerwise_recurrent_autoencoder_for_general_realworld_traffic_flow_forecasting", "_bibtex": "@misc{\nzhao2019layerwise,\ntitle={Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting},\nauthor={Peize Zhao and Danfeng Cai and Shaokun Zhang and Feng Chen and Zhemin Zhang and Cheng Wang and Jonathan Li},\nyear={2019},\nurl={https://openreview.net/forum?id=ryzfcoR5YQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper517/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621623792, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryzfcoR5YQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper517/Authors", "ICLR.cc/2019/Conference/Paper517/Reviewers", "ICLR.cc/2019/Conference/Paper517/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper517/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper517/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper517/Authors|ICLR.cc/2019/Conference/Paper517/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper517/Reviewers", "ICLR.cc/2019/Conference/Paper517/Authors", "ICLR.cc/2019/Conference/Paper517/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621623792}}}, {"id": "H1lJ6bITn7", "original": null, "number": 3, "cdate": 1541394870850, "ddate": null, "tcdate": 1541394870850, "tmdate": 1541533927283, "tddate": null, "forum": "ryzfcoR5YQ", "replyto": "ryzfcoR5YQ", "invitation": "ICLR.cc/2019/Conference/-/Paper517/Official_Review", "content": {"title": "Confused...", "review": "I am sorry but I am super confused with this paper. There is no clarity and about half of the sentences are written with broken english. \n\nThe model (as far as I can understand from the partial explanations and Figure 2) looks like a kitchen sink -- a combination of pieces from previously explored methods in the context of traffic flow estimation. This might be fine, but there is no motivation provided for this. \n\nRather than spending the method section with repeating well known Loss equations, KL-divergence, convolution, etc... Please focus on the architecture provided in the paper and the motivations behind it. More importantly, how it differs from previous approaches and why these choices have been made. \n\nThis paper is not ready for publication. It needs a re-write at least, preferably working out the original motivations behind architectural choices. ", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper517/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting", "abstract": "Accurate spatio-temporal traffic forecasting is a fundamental task that has wide applications in city management, transportation area and financial domain. There are many factors that make this significant task also challenging, like: (1) maze-like road network makes the spatial dependency complex; (2) the traffic-time relationships bring non-linear temporal complication; (3) with the larger road network, the difficulty of flow forecasting grows. The prevalent and state-of-the-art methods have mainly been discussed on datasets covering relatively small districts and short time span, e.g., the dataset that is collected within a city during months. To forecast the traffic flow across a wide area and overcome the mentioned challenges, we design and propose a promising forecasting model called Layerwise Recurrent Autoencoder (LRA), in which a three-layer stacked autoencoder (SAE) architecture is used to obtain temporal traffic correlations and a recurrent neural networks (RNNs) model for prediction. The convolutional neural networks (CNNs) model is also employed to extract spatial traffic information within the transport topology for more accurate prediction. To the best of our knowledge, there is no general and effective method for traffic flow prediction in large area which covers a group of cities. The experiment is completed on such large scale real-world traffic datasets to show superiority. And a smaller dataset is exploited to prove universality of the proposed model. And evaluations show that our model outperforms the state-of-the-art baselines by 6% - 15%.", "keywords": ["traffic flow forecasting", "spatiotemporal dependencies", "deep learning", "intelligent transportation system"], "authorids": ["zhaopeize@sensetime.com", "caidanfeng@sensetime.com", "zhangshaokun@sensetime.com", "chenfeng@xmu.edu.cn", "zhangzhemin@xmu.edu.cn", "cwang@xmu.edu.cn", "junli@xmu.edu.cn"], "authors": ["Peize Zhao", "Danfeng Cai", "Shaokun Zhang", "Feng Chen", "Zhemin Zhang", "Cheng Wang", "Jonathan Li"], "TL;DR": "We propose Layerwise Recurrent Autoencoder with effective spatiotemporal dependencies modeling for general traffic flow forecasting.", "pdf": "/pdf/819fe626b59be1697c22ab5d9570defb54e49754.pdf", "paperhash": "zhao|layerwise_recurrent_autoencoder_for_general_realworld_traffic_flow_forecasting", "_bibtex": "@misc{\nzhao2019layerwise,\ntitle={Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting},\nauthor={Peize Zhao and Danfeng Cai and Shaokun Zhang and Feng Chen and Zhemin Zhang and Cheng Wang and Jonathan Li},\nyear={2019},\nurl={https://openreview.net/forum?id=ryzfcoR5YQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper517/Official_Review", "cdate": 1542234443286, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "ryzfcoR5YQ", "replyto": "ryzfcoR5YQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper517/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335742253, "tmdate": 1552335742253, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper517/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "BkgiKcMihQ", "original": null, "number": 2, "cdate": 1541249667346, "ddate": null, "tcdate": 1541249667346, "tmdate": 1541533927075, "tddate": null, "forum": "ryzfcoR5YQ", "replyto": "ryzfcoR5YQ", "invitation": "ICLR.cc/2019/Conference/-/Paper517/Official_Review", "content": {"title": "significant clarification needed", "review": "This paper has potential, but I do not think it is ready for publication. I will ask some questions / make some suggestions:\n\n1) Your first sentence makes a claim about there being a large body of research on traffic flow forecasting. I don't doubt this, but you should cite some papers, please.\n\n2) Your contributions raise the following questions for me: \n\n- Contribution 1 is that you use a very large dataset (for training? you don't say.) and a small dataset (for testing), thus proving that your method works and generalizes. Your method may be effective, but compared to what? Your method may generalize, but how do we know that if you've only tested it on one small dataset?\n\n- Contribution 2 says that you creatively used lagged data in a time series model. This is probably a good idea, but it does not sound all that creative to me, compare with, e.g. an AR model.\n\n- Contribution 3 says that you use driving distance to model spatial correlation. Again, this is probably a good idea, and when we get further we learn that you applied a Graph Convolution Network. Were these the choices that you claim are novel? Are they novel? What other choices might be reasonable and how would they compare?\n\n3) Section 3 immediately jumps into the use of autoencoders. But I think you need to justify why we care about using autoencoders in the first place. If the problem is traffic forecasting, why don't you tackle that problem head on?\n\n4) Section 3 mentions sparsity without justifying why I care about sparsity. This might be an important tool for regularization in a deep neural network. Or it might not be--given enough data and other regularization techniques (weight decay, early stopping, dropout).\n\n5) Is the spatial dependency that you end up learning qualitatively different than the spatial dependency you would get by instead assuming a particular parametric form as is done in kernel methods / Gaussian processes, e.g. the Gaussian kernel or the Matern kernel parameterizes the covariance between observations at two spatial locations?\n\n6) In your experiment I believe you randomly split 15 minute blocks into train/test/validate. I think this evaluation will be over-optimistic insofar as if 10:30-10:45 and 11:00-11:15 are in the train set, but 10:45-11:00 is in the test set, it will be relatively easy to predict 10:45-11:00. I would suggest considering train/test/validate splits based on larger chunks, e.g. leave the data in 15 minute blocks, but randomly select hours (4 blocks) to put in train/test/validate.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper517/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting", "abstract": "Accurate spatio-temporal traffic forecasting is a fundamental task that has wide applications in city management, transportation area and financial domain. There are many factors that make this significant task also challenging, like: (1) maze-like road network makes the spatial dependency complex; (2) the traffic-time relationships bring non-linear temporal complication; (3) with the larger road network, the difficulty of flow forecasting grows. The prevalent and state-of-the-art methods have mainly been discussed on datasets covering relatively small districts and short time span, e.g., the dataset that is collected within a city during months. To forecast the traffic flow across a wide area and overcome the mentioned challenges, we design and propose a promising forecasting model called Layerwise Recurrent Autoencoder (LRA), in which a three-layer stacked autoencoder (SAE) architecture is used to obtain temporal traffic correlations and a recurrent neural networks (RNNs) model for prediction. The convolutional neural networks (CNNs) model is also employed to extract spatial traffic information within the transport topology for more accurate prediction. To the best of our knowledge, there is no general and effective method for traffic flow prediction in large area which covers a group of cities. The experiment is completed on such large scale real-world traffic datasets to show superiority. And a smaller dataset is exploited to prove universality of the proposed model. And evaluations show that our model outperforms the state-of-the-art baselines by 6% - 15%.", "keywords": ["traffic flow forecasting", "spatiotemporal dependencies", "deep learning", "intelligent transportation system"], "authorids": ["zhaopeize@sensetime.com", "caidanfeng@sensetime.com", "zhangshaokun@sensetime.com", "chenfeng@xmu.edu.cn", "zhangzhemin@xmu.edu.cn", "cwang@xmu.edu.cn", "junli@xmu.edu.cn"], "authors": ["Peize Zhao", "Danfeng Cai", "Shaokun Zhang", "Feng Chen", "Zhemin Zhang", "Cheng Wang", "Jonathan Li"], "TL;DR": "We propose Layerwise Recurrent Autoencoder with effective spatiotemporal dependencies modeling for general traffic flow forecasting.", "pdf": "/pdf/819fe626b59be1697c22ab5d9570defb54e49754.pdf", "paperhash": "zhao|layerwise_recurrent_autoencoder_for_general_realworld_traffic_flow_forecasting", "_bibtex": "@misc{\nzhao2019layerwise,\ntitle={Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting},\nauthor={Peize Zhao and Danfeng Cai and Shaokun Zhang and Feng Chen and Zhemin Zhang and Cheng Wang and Jonathan Li},\nyear={2019},\nurl={https://openreview.net/forum?id=ryzfcoR5YQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper517/Official_Review", "cdate": 1542234443286, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "ryzfcoR5YQ", "replyto": "ryzfcoR5YQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper517/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335742253, "tmdate": 1552335742253, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper517/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "H1xTDOudh7", "original": null, "number": 1, "cdate": 1541077092762, "ddate": null, "tcdate": 1541077092762, "tmdate": 1541533926874, "tddate": null, "forum": "ryzfcoR5YQ", "replyto": "ryzfcoR5YQ", "invitation": "ICLR.cc/2019/Conference/-/Paper517/Official_Review", "content": {"title": "Potentially interesting, though large omissions make this difficult to follow", "review": "The paper uses a number of deep learning approaches to analyse sets of Traffic data. However, as these sets of traffic data are never explained it is difficult to follow or understand what is going on here.\n\nSome major comments:\n1) Many of the key concepts in the paper are not discussed. The primary one would be that of what the two data sets contain. Without knowledge of this it is difficult to ascertain what is going on. \n\n2) Many of the processes used are not described in enough detail to either understand what is going on or to re-produce the work. Without this it is difficult to make headway wit the work.\n\n3) It is not clearly articulated what the experiments performed are doing. For example, how have you applied the other techniques to this data?\n\n4) Key terms are not defined. Such as Traffic Flow.\n\n5) The English structure of the paper is poor with many mistakes. A thorough proof-reading is essential.\n\nSome more specific points:\n- \"with the larger road network, the difficulty of flow forecasting grows.\" - This seems to be a consequence of the other ones not a challenge in it's own right.\n\n- What is \"superiority\"?\n\n- \"Spatiotemporal traffic flow forecasting task is currently under a heated discussion and has attracted a large research population.\" - evidence to back up this statement.\n\n- Your contributions aren't contributions, but rather a list of what you have done.\n\n- How does your related work relate to what you have done?\n\n- Hard to parse \"To extract temporal relationships within the history traffic flows, we model this process as a layering structure with autoencoder as cell\"\n\n- Appendices B and C should be in the main paper.\n\n- What is in x^{(1)}?\n\n- \"When take the sparsity constrains into consideration\" - what are the sparsity constraints?\n\n- How do you obtain the weights?\n\n- Figure 2 should come much sooner as it relates a lot of the concepts together.\n\n- \"On both datasets, we slice traffic flow information into 15 minutes windows, where 70% of data is for training, 10% for validation and remaining 20% for testing.\" - Is that each 15 mins is split 70:10:20?\n\n- Proof by example is not a proof.\n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper517/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting", "abstract": "Accurate spatio-temporal traffic forecasting is a fundamental task that has wide applications in city management, transportation area and financial domain. There are many factors that make this significant task also challenging, like: (1) maze-like road network makes the spatial dependency complex; (2) the traffic-time relationships bring non-linear temporal complication; (3) with the larger road network, the difficulty of flow forecasting grows. The prevalent and state-of-the-art methods have mainly been discussed on datasets covering relatively small districts and short time span, e.g., the dataset that is collected within a city during months. To forecast the traffic flow across a wide area and overcome the mentioned challenges, we design and propose a promising forecasting model called Layerwise Recurrent Autoencoder (LRA), in which a three-layer stacked autoencoder (SAE) architecture is used to obtain temporal traffic correlations and a recurrent neural networks (RNNs) model for prediction. The convolutional neural networks (CNNs) model is also employed to extract spatial traffic information within the transport topology for more accurate prediction. To the best of our knowledge, there is no general and effective method for traffic flow prediction in large area which covers a group of cities. The experiment is completed on such large scale real-world traffic datasets to show superiority. And a smaller dataset is exploited to prove universality of the proposed model. And evaluations show that our model outperforms the state-of-the-art baselines by 6% - 15%.", "keywords": ["traffic flow forecasting", "spatiotemporal dependencies", "deep learning", "intelligent transportation system"], "authorids": ["zhaopeize@sensetime.com", "caidanfeng@sensetime.com", "zhangshaokun@sensetime.com", "chenfeng@xmu.edu.cn", "zhangzhemin@xmu.edu.cn", "cwang@xmu.edu.cn", "junli@xmu.edu.cn"], "authors": ["Peize Zhao", "Danfeng Cai", "Shaokun Zhang", "Feng Chen", "Zhemin Zhang", "Cheng Wang", "Jonathan Li"], "TL;DR": "We propose Layerwise Recurrent Autoencoder with effective spatiotemporal dependencies modeling for general traffic flow forecasting.", "pdf": "/pdf/819fe626b59be1697c22ab5d9570defb54e49754.pdf", "paperhash": "zhao|layerwise_recurrent_autoencoder_for_general_realworld_traffic_flow_forecasting", "_bibtex": "@misc{\nzhao2019layerwise,\ntitle={Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting},\nauthor={Peize Zhao and Danfeng Cai and Shaokun Zhang and Feng Chen and Zhemin Zhang and Cheng Wang and Jonathan Li},\nyear={2019},\nurl={https://openreview.net/forum?id=ryzfcoR5YQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper517/Official_Review", "cdate": 1542234443286, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "ryzfcoR5YQ", "replyto": "ryzfcoR5YQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper517/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335742253, "tmdate": 1552335742253, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper517/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SJeKCW7scm", "original": null, "number": 1, "cdate": 1539154384887, "ddate": null, "tcdate": 1539154384887, "tmdate": 1539154384887, "tddate": null, "forum": "ryzfcoR5YQ", "replyto": "ryzfcoR5YQ", "invitation": "ICLR.cc/2019/Conference/-/Paper517/Official_Comment", "content": {"title": "Announcement of a typo", "comment": "We found a typo that may lead misunderstanding in the table 1, the MAE value of DCRNN and our LRA in ST-WB dataset with 15 min window should be 34.24 and 30.56 relatively. \n\nSorry for the ambiguousness caused by our fault, if you have any other questions, please feel free to ask us."}, "signatures": ["ICLR.cc/2019/Conference/Paper517/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper517/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper517/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting", "abstract": "Accurate spatio-temporal traffic forecasting is a fundamental task that has wide applications in city management, transportation area and financial domain. There are many factors that make this significant task also challenging, like: (1) maze-like road network makes the spatial dependency complex; (2) the traffic-time relationships bring non-linear temporal complication; (3) with the larger road network, the difficulty of flow forecasting grows. The prevalent and state-of-the-art methods have mainly been discussed on datasets covering relatively small districts and short time span, e.g., the dataset that is collected within a city during months. To forecast the traffic flow across a wide area and overcome the mentioned challenges, we design and propose a promising forecasting model called Layerwise Recurrent Autoencoder (LRA), in which a three-layer stacked autoencoder (SAE) architecture is used to obtain temporal traffic correlations and a recurrent neural networks (RNNs) model for prediction. The convolutional neural networks (CNNs) model is also employed to extract spatial traffic information within the transport topology for more accurate prediction. To the best of our knowledge, there is no general and effective method for traffic flow prediction in large area which covers a group of cities. The experiment is completed on such large scale real-world traffic datasets to show superiority. And a smaller dataset is exploited to prove universality of the proposed model. And evaluations show that our model outperforms the state-of-the-art baselines by 6% - 15%.", "keywords": ["traffic flow forecasting", "spatiotemporal dependencies", "deep learning", "intelligent transportation system"], "authorids": ["zhaopeize@sensetime.com", "caidanfeng@sensetime.com", "zhangshaokun@sensetime.com", "chenfeng@xmu.edu.cn", "zhangzhemin@xmu.edu.cn", "cwang@xmu.edu.cn", "junli@xmu.edu.cn"], "authors": ["Peize Zhao", "Danfeng Cai", "Shaokun Zhang", "Feng Chen", "Zhemin Zhang", "Cheng Wang", "Jonathan Li"], "TL;DR": "We propose Layerwise Recurrent Autoencoder with effective spatiotemporal dependencies modeling for general traffic flow forecasting.", "pdf": "/pdf/819fe626b59be1697c22ab5d9570defb54e49754.pdf", "paperhash": "zhao|layerwise_recurrent_autoencoder_for_general_realworld_traffic_flow_forecasting", "_bibtex": "@misc{\nzhao2019layerwise,\ntitle={Layerwise Recurrent Autoencoder for General Real-world Traffic Flow Forecasting},\nauthor={Peize Zhao and Danfeng Cai and Shaokun Zhang and Feng Chen and Zhemin Zhang and Cheng Wang and Jonathan Li},\nyear={2019},\nurl={https://openreview.net/forum?id=ryzfcoR5YQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper517/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621623792, "tddate": null, "super": null, "final": null, "reply": {"forum": "ryzfcoR5YQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper517/Authors", "ICLR.cc/2019/Conference/Paper517/Reviewers", "ICLR.cc/2019/Conference/Paper517/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper517/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper517/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper517/Authors|ICLR.cc/2019/Conference/Paper517/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper517/Reviewers", "ICLR.cc/2019/Conference/Paper517/Authors", "ICLR.cc/2019/Conference/Paper517/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621623792}}}], "count": 9}