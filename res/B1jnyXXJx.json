{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396304477, "tcdate": 1486396304477, "number": 1, "id": "Skd5oMI_e", "invitation": "ICLR.cc/2017/conference/-/paper4/acceptance", "forum": "B1jnyXXJx", "replyto": "B1jnyXXJx", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "The paper proposes a method for accelerating optimization near saddle points when training deep neural networks. The idea is to repel the current parameter vector from a running average of recent parameter values. The proposed method is shown to optimize faster than a variety of other methods in a variety of datasets and architectures.\n \n The author presents a fresh idea in the area of stochastic optimization for deep neural networks. However the paper doesn't quite appear to be above the Accept bar, due to remaining doubts about the thoroughness of the experiments.We therefore invite this paper for presentation at the Workshop track.", "decision": "Invite to Workshop Track"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Charged Point Normalization: An Efficient Solution to the Saddle Point Problem", "abstract": "Recently, the problem of local minima in very high dimensional non-convex optimization has been challenged and the problem of saddle points has been introduced. This paper introduces a dynamic type of normalization that forces the system to escape saddle points. Unlike other saddle point escaping algorithms, second order information is not utilized, and the system can be trained with an arbitrary gradient descent learner. The system drastically improves learning in a range of deep neural networks on various data-sets in comparison to non-CPN neural networks.", "pdf": "/pdf/4f4854eeac3c1a8dc5416dfce2adba583b6fb529.pdf", "paperhash": "aghajanyan|charged_point_normalization_an_efficient_solution_to_the_saddle_point_problem", "author_emails": "armen.ag@live.com", "conflicts": ["dimensionalmechanics.com"], "authors": ["Armen Aghajanyan"], "authorids": ["armen.ag@live.com"], "keywords": ["Deep learning", "Computer vision", "Optimization"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396305006, "id": "ICLR.cc/2017/conference/-/paper4/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "B1jnyXXJx", "replyto": "B1jnyXXJx", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396305006}}}, {"tddate": null, "tmdate": 1483833312513, "tcdate": 1483833312513, "number": 9, "id": "B1OJl-JUx", "invitation": "ICLR.cc/2017/conference/-/paper4/public/comment", "forum": "B1jnyXXJx", "replyto": "rJuJLGgVl", "signatures": ["~Armen_Aghajanyan1"], "readers": ["everyone"], "writers": ["~Armen_Aghajanyan1"], "content": {"title": "reply", "comment": "Thank you for your comments.\n\nI mentioned in the similarities to momentum in the paper. If momentum was the only positive effect of CPN than just increasing momentum would cause training to escape saddle points, but in reality, this does not happen. Hyperparameter search through standard training also showed that higher momentums wouldn't work. \n\nThank you."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Charged Point Normalization: An Efficient Solution to the Saddle Point Problem", "abstract": "Recently, the problem of local minima in very high dimensional non-convex optimization has been challenged and the problem of saddle points has been introduced. This paper introduces a dynamic type of normalization that forces the system to escape saddle points. Unlike other saddle point escaping algorithms, second order information is not utilized, and the system can be trained with an arbitrary gradient descent learner. The system drastically improves learning in a range of deep neural networks on various data-sets in comparison to non-CPN neural networks.", "pdf": "/pdf/4f4854eeac3c1a8dc5416dfce2adba583b6fb529.pdf", "paperhash": "aghajanyan|charged_point_normalization_an_efficient_solution_to_the_saddle_point_problem", "author_emails": "armen.ag@live.com", "conflicts": ["dimensionalmechanics.com"], "authors": ["Armen Aghajanyan"], "authorids": ["armen.ag@live.com"], "keywords": ["Deep learning", "Computer vision", "Optimization"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287766371, "id": "ICLR.cc/2017/conference/-/paper4/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1jnyXXJx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper4/reviewers", "ICLR.cc/2017/conference/paper4/areachairs"], "cdate": 1485287766371}}}, {"tddate": null, "tmdate": 1483833157648, "tcdate": 1483833157648, "number": 8, "id": "ryRS1ZyUg", "invitation": "ICLR.cc/2017/conference/-/paper4/public/comment", "forum": "B1jnyXXJx", "replyto": "Bk8KEGLEl", "signatures": ["~Armen_Aghajanyan1"], "readers": ["everyone"], "writers": ["~Armen_Aghajanyan1"], "content": {"title": "reply", "comment": "Thank you for comments.\n\nI'd like to note that if momentum was capable of escaping saddle points with the same proficiency as CPN then all that would be necessary is raising the momentum term. But in reality, this approach never works as it causes the gradients to expode.\n\nI mentioned the similarity to momentum in an update to the paper. The theoretical result show the asymptotic growth of saddle points independently of the joint probability.\n\nThank you."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Charged Point Normalization: An Efficient Solution to the Saddle Point Problem", "abstract": "Recently, the problem of local minima in very high dimensional non-convex optimization has been challenged and the problem of saddle points has been introduced. This paper introduces a dynamic type of normalization that forces the system to escape saddle points. Unlike other saddle point escaping algorithms, second order information is not utilized, and the system can be trained with an arbitrary gradient descent learner. The system drastically improves learning in a range of deep neural networks on various data-sets in comparison to non-CPN neural networks.", "pdf": "/pdf/4f4854eeac3c1a8dc5416dfce2adba583b6fb529.pdf", "paperhash": "aghajanyan|charged_point_normalization_an_efficient_solution_to_the_saddle_point_problem", "author_emails": "armen.ag@live.com", "conflicts": ["dimensionalmechanics.com"], "authors": ["Armen Aghajanyan"], "authorids": ["armen.ag@live.com"], "keywords": ["Deep learning", "Computer vision", "Optimization"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287766371, "id": "ICLR.cc/2017/conference/-/paper4/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1jnyXXJx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper4/reviewers", "ICLR.cc/2017/conference/paper4/areachairs"], "cdate": 1485287766371}}}, {"tddate": null, "tmdate": 1482240814003, "tcdate": 1482240814003, "number": 3, "id": "BJLE728Ex", "invitation": "ICLR.cc/2017/conference/-/paper4/official/review", "forum": "B1jnyXXJx", "replyto": "B1jnyXXJx", "signatures": ["ICLR.cc/2017/conference/paper4/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper4/AnonReviewer2"], "content": {"title": "Interesting idea but needs more work", "rating": "5: Marginally below acceptance threshold", "review": "Summary:\nThis paper proposes a regularizer that is claimed to help escaping from the saddle points. The method is inspired from physics, such that thinking of the optimization process is moving a positively charged particle would over the error surface which would be pushed away from saddle points due to the saddle point being positively changed as well. Authors of the paper show results over several different datasets.\n\nOverview of the Review:\n    Pros:\n        - The idea is very interesting.\n        - The diverse set of results on different datasets.\n    Cons:\n        - The justification is not strong enough.\n        - The paper is not well-written.\n        - Experiments are not convincing enough.\n\nCriticisms:\n\nI liked the idea and the intuitions coming from the paper. However, I think this paper is not written well. There are some variables introduced in the paper and not explained good-enough, for example in 2.3, the authors start to talk about p without introducing and defining it properly. The only other place it appears before is Equation 6. The Equations need some work as well, some work is needed in terms of improving the flow of the paper, e.g., introducing all the variables properly before using them.\n\nEquation 6 appears without a proper explanation and justification. It is necessary to explain it what it means properly since I think this is one of the most important equation in this paper. More analysis on what it means in terms of optimization point of view would also be appreciated.\n\n$\\phi$ is not a parameter, it is a function which has its own hyper-parameter $\\alpha$. \n\nIt would be interesting to report validation or test results on a few tasks as well. Since this method introduced as an additional cost function, its effect on the validation/test results would be interesting as well.\nThe authors should discuss more on how they choose the hyper-parameters of their models. \n\nThe Figure 2 and 3 does not add too much to the paper and they are very difficult to understand or draw any conclusions from. \n\nThere are lots of Figures under 3.4.2 without any labels of captions. Some of them are really small and difficult to understand since the labels on the figures appear very small and somewhat unreadable.\n\n\nA small question:\n\n* Do you also backpropagate through $\\tilde{\\mW}_i^t$?", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Charged Point Normalization: An Efficient Solution to the Saddle Point Problem", "abstract": "Recently, the problem of local minima in very high dimensional non-convex optimization has been challenged and the problem of saddle points has been introduced. This paper introduces a dynamic type of normalization that forces the system to escape saddle points. Unlike other saddle point escaping algorithms, second order information is not utilized, and the system can be trained with an arbitrary gradient descent learner. The system drastically improves learning in a range of deep neural networks on various data-sets in comparison to non-CPN neural networks.", "pdf": "/pdf/4f4854eeac3c1a8dc5416dfce2adba583b6fb529.pdf", "paperhash": "aghajanyan|charged_point_normalization_an_efficient_solution_to_the_saddle_point_problem", "author_emails": "armen.ag@live.com", "conflicts": ["dimensionalmechanics.com"], "authors": ["Armen Aghajanyan"], "authorids": ["armen.ag@live.com"], "keywords": ["Deep learning", "Computer vision", "Optimization"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512728146, "id": "ICLR.cc/2017/conference/-/paper4/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper4/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper4/AnonReviewer3", "ICLR.cc/2017/conference/paper4/AnonReviewer1", "ICLR.cc/2017/conference/paper4/AnonReviewer2"], "reply": {"forum": "B1jnyXXJx", "replyto": "B1jnyXXJx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper4/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper4/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512728146}}}, {"tddate": null, "tmdate": 1482200189749, "tcdate": 1482200189749, "number": 2, "id": "Bk8KEGLEl", "invitation": "ICLR.cc/2017/conference/-/paper4/official/review", "forum": "B1jnyXXJx", "replyto": "B1jnyXXJx", "signatures": ["ICLR.cc/2017/conference/paper4/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper4/AnonReviewer1"], "content": {"title": "Interesting idea, needs more rigorous comparison", "rating": "4: Ok but not good enough - rejection", "review": "This paper proposes a novel method for accelerating optimization near saddle points. The basic idea is to repel the current parameter vector from a running average of recent parameter values. This method is shown to optimize faster than a variety of other methods in a variety of datasets and architectures.\n\nOn the surface, the proposed method seems extremely close to momentum. It would be very valuable to think of a clear diagram illustrating how it differs from momentum and why it might be better near a saddle point. The illustration of better convergence on the toy saddle example is not what I mean here\u2014optimization speed comparisons are always difficult due to the many details and hyper parameters involved, so seeing it work faster in one specific application is not as useful as a conceptual diagram which shows a critical case where CPN will behave differently from\u2014and clearly qualitatively better than\u2014momentum.\n\nAnother way of getting at the relationship to momentum would be to try to find a form for R_t(f) that yields the exact momentum update. You could then compare this with the R_t(f) used in CPN.\n\nThe overly general notation $\\phi(W,W)$ etc should be dropped\u2014Eqn 8 is enough.\n\nThe theoretical results (Eqn 1 and Thm 1) should be removed, they are irrelevant until the joint density can be specified.\n\nExperimentally, it would be valuable to standardize the results to allow comparison to other methods. For instance, recreating Figure 4 of Dauphin et al, but engaging the CPN method rather than SFN, would clearly demonstrate that CPN can escape something that momentum cannot.\n\nI think the idea here is potentially very valuable, but needs more rigorous comparison and a clear relation to momentum and other work.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Charged Point Normalization: An Efficient Solution to the Saddle Point Problem", "abstract": "Recently, the problem of local minima in very high dimensional non-convex optimization has been challenged and the problem of saddle points has been introduced. This paper introduces a dynamic type of normalization that forces the system to escape saddle points. Unlike other saddle point escaping algorithms, second order information is not utilized, and the system can be trained with an arbitrary gradient descent learner. The system drastically improves learning in a range of deep neural networks on various data-sets in comparison to non-CPN neural networks.", "pdf": "/pdf/4f4854eeac3c1a8dc5416dfce2adba583b6fb529.pdf", "paperhash": "aghajanyan|charged_point_normalization_an_efficient_solution_to_the_saddle_point_problem", "author_emails": "armen.ag@live.com", "conflicts": ["dimensionalmechanics.com"], "authors": ["Armen Aghajanyan"], "authorids": ["armen.ag@live.com"], "keywords": ["Deep learning", "Computer vision", "Optimization"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512728146, "id": "ICLR.cc/2017/conference/-/paper4/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper4/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper4/AnonReviewer3", "ICLR.cc/2017/conference/paper4/AnonReviewer1", "ICLR.cc/2017/conference/paper4/AnonReviewer2"], "reply": {"forum": "B1jnyXXJx", "replyto": "B1jnyXXJx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper4/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper4/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512728146}}}, {"tddate": null, "tmdate": 1481810130170, "tcdate": 1481810130166, "number": 2, "id": "Sy9AxXgEl", "invitation": "ICLR.cc/2017/conference/-/paper4/official/comment", "forum": "B1jnyXXJx", "replyto": "B1WnDzx4g", "signatures": ["ICLR.cc/2017/conference/paper4/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper4/AnonReviewer3"], "content": {"title": "Details", "comment": "Thanks for your request.\n1) MNIST experiments\nSection 3.2.1 and 3.2.2\nYou compare SGD without momentum and CPN where momentum is present. The difference in performance is negligible. \nThis supports my arguments \"results are not great enough\"\n2) CIFAR experiments\nYou compare SGD with momentum *0.9* and CPN with momentum *0.95*. The default approach outperforms CPN during the first 30 epochs, then CPN outperforms SGD. How you selected 0.9 for SGD and \u03b2 = 0.01, \u03bb = 0.1 for CPN? The paper suggests that \"by hand around 4-8 times\". Which values of momentum you tried exactly? If only 0.9 for SGD with momentum and 4-8 for CPN then feel free to scale up the x-axis of CPN by 4-8.\n3) BABI dataset\n\"For the LSTM architecture, CPN hyper-parameters were: \u03b2 = 0.0025, \u03bb = .03, \u03b1 = 0.95. For the GRU\narchitecture, CPN hyper-parameters were: \u03b2 = 0.1, \u03bb = .1, \u03b1 = 0.95.\"\nHere, you jumped from 0.0025, \u03bb = .03 to \u03b2 = 0.1, \u03bb = .1 with \"4-8\" trials. Does not look trivial to me. The grid had to be \u03b2 in [0.0025; 0.1] and \u03bb in [0.03; 0.1] to get your hyperparameter settings in 4 trials! Adam was not optimized I suppose.\n4) Toy example\nYou show that by combing some baseline algorithms and CPN with *tuned hyperparameters* we can leave the saddle point. Great. Did you try to optimize hyperparameters of the baselines as well? This would be more fair, I guess. \nI suppose that any reasonable random walk (optionally, gradient-biased) could help to escape the saddle point of this 2-dimensional problem. \n\nI do not claim that the approach does not make sense. Instead, I think that the current comparison analysis is not convincing enough. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Charged Point Normalization: An Efficient Solution to the Saddle Point Problem", "abstract": "Recently, the problem of local minima in very high dimensional non-convex optimization has been challenged and the problem of saddle points has been introduced. This paper introduces a dynamic type of normalization that forces the system to escape saddle points. Unlike other saddle point escaping algorithms, second order information is not utilized, and the system can be trained with an arbitrary gradient descent learner. The system drastically improves learning in a range of deep neural networks on various data-sets in comparison to non-CPN neural networks.", "pdf": "/pdf/4f4854eeac3c1a8dc5416dfce2adba583b6fb529.pdf", "paperhash": "aghajanyan|charged_point_normalization_an_efficient_solution_to_the_saddle_point_problem", "author_emails": "armen.ag@live.com", "conflicts": ["dimensionalmechanics.com"], "authors": ["Armen Aghajanyan"], "authorids": ["armen.ag@live.com"], "keywords": ["Deep learning", "Computer vision", "Optimization"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287766245, "id": "ICLR.cc/2017/conference/-/paper4/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "B1jnyXXJx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper4/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper4/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper4/reviewers", "ICLR.cc/2017/conference/paper4/areachairs"], "cdate": 1485287766245}}}, {"tddate": null, "tmdate": 1481807785089, "tcdate": 1481807785084, "number": 7, "id": "B1WnDzx4g", "invitation": "ICLR.cc/2017/conference/-/paper4/public/comment", "forum": "B1jnyXXJx", "replyto": "rJuJLGgVl", "signatures": ["~Armen_Aghajanyan1"], "readers": ["everyone"], "writers": ["~Armen_Aghajanyan1"], "content": {"title": "Momentum: Reply", "comment": "Thank you for your review.\n\nBut I would please ask you to re-evaluate. \n\nThe paper ran multiple experiments that tested various architecures using various momentum methods ranging from RMSProp to Adam. If the positive effect of CPN was simply due to the momentum we would not see uniform improvements over all experiments using a large varying set of optimization routines. And for the toy-problem the only momentums that solved the toy-problem were unrealistic parameters that could not be used in a real setting. \n\nWe also believe that the theoretical perspective of this paper on saddle points is important. I ask you respectfully to reconsider.\n\nThank you.\nArmen."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Charged Point Normalization: An Efficient Solution to the Saddle Point Problem", "abstract": "Recently, the problem of local minima in very high dimensional non-convex optimization has been challenged and the problem of saddle points has been introduced. This paper introduces a dynamic type of normalization that forces the system to escape saddle points. Unlike other saddle point escaping algorithms, second order information is not utilized, and the system can be trained with an arbitrary gradient descent learner. The system drastically improves learning in a range of deep neural networks on various data-sets in comparison to non-CPN neural networks.", "pdf": "/pdf/4f4854eeac3c1a8dc5416dfce2adba583b6fb529.pdf", "paperhash": "aghajanyan|charged_point_normalization_an_efficient_solution_to_the_saddle_point_problem", "author_emails": "armen.ag@live.com", "conflicts": ["dimensionalmechanics.com"], "authors": ["Armen Aghajanyan"], "authorids": ["armen.ag@live.com"], "keywords": ["Deep learning", "Computer vision", "Optimization"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287766371, "id": "ICLR.cc/2017/conference/-/paper4/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1jnyXXJx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper4/reviewers", "ICLR.cc/2017/conference/paper4/areachairs"], "cdate": 1485287766371}}}, {"tddate": null, "tmdate": 1481807327681, "tcdate": 1481807327674, "number": 1, "id": "rJuJLGgVl", "invitation": "ICLR.cc/2017/conference/-/paper4/official/review", "forum": "B1jnyXXJx", "replyto": "B1jnyXXJx", "signatures": ["ICLR.cc/2017/conference/paper4/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper4/AnonReviewer3"], "content": {"title": "Momentum", "rating": "4: Ok but not good enough - rejection", "review": "The research direction taken by this paper is of great interest. \nHowever, the empirical results are not great enough to pay for the weaknesses of the proposed approach (see Section 6). \n\"Throughout this paper the selection of hyper-parameters was kept rather simple.\" but the momentum term of CPN is set to 0.95 \nand not 0.9 as in all/most optimizers CPN is compared to. I suppose that the positive effect of CPN (if any) is mostly due to its momentum term.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Charged Point Normalization: An Efficient Solution to the Saddle Point Problem", "abstract": "Recently, the problem of local minima in very high dimensional non-convex optimization has been challenged and the problem of saddle points has been introduced. This paper introduces a dynamic type of normalization that forces the system to escape saddle points. Unlike other saddle point escaping algorithms, second order information is not utilized, and the system can be trained with an arbitrary gradient descent learner. The system drastically improves learning in a range of deep neural networks on various data-sets in comparison to non-CPN neural networks.", "pdf": "/pdf/4f4854eeac3c1a8dc5416dfce2adba583b6fb529.pdf", "paperhash": "aghajanyan|charged_point_normalization_an_efficient_solution_to_the_saddle_point_problem", "author_emails": "armen.ag@live.com", "conflicts": ["dimensionalmechanics.com"], "authors": ["Armen Aghajanyan"], "authorids": ["armen.ag@live.com"], "keywords": ["Deep learning", "Computer vision", "Optimization"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512728146, "id": "ICLR.cc/2017/conference/-/paper4/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper4/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper4/AnonReviewer3", "ICLR.cc/2017/conference/paper4/AnonReviewer1", "ICLR.cc/2017/conference/paper4/AnonReviewer2"], "reply": {"forum": "B1jnyXXJx", "replyto": "B1jnyXXJx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper4/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper4/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512728146}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1481753312074, "tcdate": 1476763571305, "number": 4, "id": "B1jnyXXJx", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "B1jnyXXJx", "signatures": ["~Armen_Aghajanyan1"], "readers": ["everyone"], "content": {"TL;DR": "", "title": "Charged Point Normalization: An Efficient Solution to the Saddle Point Problem", "abstract": "Recently, the problem of local minima in very high dimensional non-convex optimization has been challenged and the problem of saddle points has been introduced. This paper introduces a dynamic type of normalization that forces the system to escape saddle points. Unlike other saddle point escaping algorithms, second order information is not utilized, and the system can be trained with an arbitrary gradient descent learner. The system drastically improves learning in a range of deep neural networks on various data-sets in comparison to non-CPN neural networks.", "pdf": "/pdf/4f4854eeac3c1a8dc5416dfce2adba583b6fb529.pdf", "paperhash": "aghajanyan|charged_point_normalization_an_efficient_solution_to_the_saddle_point_problem", "author_emails": "armen.ag@live.com", "conflicts": ["dimensionalmechanics.com"], "authors": ["Armen Aghajanyan"], "authorids": ["armen.ag@live.com"], "keywords": ["Deep learning", "Computer vision", "Optimization"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 18, "writable": false, "overwriting": ["BJdqLbDde"], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1481225016994, "tcdate": 1481225016986, "number": 6, "id": "B1ZrXVPXg", "invitation": "ICLR.cc/2017/conference/-/paper4/public/comment", "forum": "B1jnyXXJx", "replyto": "BJPZL-vmx", "signatures": ["~Armen_Aghajanyan1"], "readers": ["everyone"], "writers": ["~Armen_Aghajanyan1"], "content": {"title": "reply: hyperparameter optimization and momentum vs CPN", "comment": "Thank you for reading.\n\nA grid search was run for GD hyperparameters and the only parameters that successfully escaped the monkey saddle point toy problem were those that are unrealistic. They all contained extremely high learning rates and high momentums, that are never used when training real nets. I'll add that distinction in the paper. \n\nI can add a section to describe the similarities between momentum and CPN, mainly being that CPN charges are self-adapting, and contain more potential to move points out of saddle points. The toy problem shows that momentum based methods alone, with reasonable parameters, are not enough to escape saddle points. The paper has a set of other experiments which show that CPN allows momentum based methods to escape saddle points, where without CPN it wouldn't. Would you recommend showing another toy problem? \n\nThank you."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Charged Point Normalization: An Efficient Solution to the Saddle Point Problem", "abstract": "Recently, the problem of local minima in very high dimensional non-convex optimization has been challenged and the problem of saddle points has been introduced. This paper introduces a dynamic type of normalization that forces the system to escape saddle points. Unlike other saddle point escaping algorithms, second order information is not utilized, and the system can be trained with an arbitrary gradient descent learner. The system drastically improves learning in a range of deep neural networks on various data-sets in comparison to non-CPN neural networks.", "pdf": "/pdf/4f4854eeac3c1a8dc5416dfce2adba583b6fb529.pdf", "paperhash": "aghajanyan|charged_point_normalization_an_efficient_solution_to_the_saddle_point_problem", "author_emails": "armen.ag@live.com", "conflicts": ["dimensionalmechanics.com"], "authors": ["Armen Aghajanyan"], "authorids": ["armen.ag@live.com"], "keywords": ["Deep learning", "Computer vision", "Optimization"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287766371, "id": "ICLR.cc/2017/conference/-/paper4/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1jnyXXJx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper4/reviewers", "ICLR.cc/2017/conference/paper4/areachairs"], "cdate": 1485287766371}}}, {"tddate": null, "tmdate": 1481213438915, "tcdate": 1481213438908, "number": 3, "id": "BJPZL-vmx", "invitation": "ICLR.cc/2017/conference/-/paper4/pre-review/question", "forum": "B1jnyXXJx", "replyto": "B1jnyXXJx", "signatures": ["ICLR.cc/2017/conference/paper4/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper4/AnonReviewer1"], "content": {"title": "hyperparameter optimization and momentum vs CPN", "question": "The hyperparameters of gradient descent seem to be chosen once and fixed. Would optimizing the gradient descent hyperparameters lead to equivalent performance as the CPN method?\n\nFollowing up on another reviewer's question: CPN seems closely related to momentum. Can you provide a clear example to show how CPN is qualitatively distinct from momentum? (I believe it is, but this could be clarified further in the paper)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Charged Point Normalization: An Efficient Solution to the Saddle Point Problem", "abstract": "Recently, the problem of local minima in very high dimensional non-convex optimization has been challenged and the problem of saddle points has been introduced. This paper introduces a dynamic type of normalization that forces the system to escape saddle points. Unlike other saddle point escaping algorithms, second order information is not utilized, and the system can be trained with an arbitrary gradient descent learner. The system drastically improves learning in a range of deep neural networks on various data-sets in comparison to non-CPN neural networks.", "pdf": "/pdf/4f4854eeac3c1a8dc5416dfce2adba583b6fb529.pdf", "paperhash": "aghajanyan|charged_point_normalization_an_efficient_solution_to_the_saddle_point_problem", "author_emails": "armen.ag@live.com", "conflicts": ["dimensionalmechanics.com"], "authors": ["Armen Aghajanyan"], "authorids": ["armen.ag@live.com"], "keywords": ["Deep learning", "Computer vision", "Optimization"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481213439430, "id": "ICLR.cc/2017/conference/-/paper4/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper4/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper4/AnonReviewer3", "ICLR.cc/2017/conference/paper4/AnonReviewer2", "ICLR.cc/2017/conference/paper4/AnonReviewer1"], "reply": {"forum": "B1jnyXXJx", "replyto": "B1jnyXXJx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper4/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper4/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481213439430}}}, {"tddate": null, "tmdate": 1481179093529, "tcdate": 1481179093523, "number": 5, "id": "SkTC1t8Xx", "invitation": "ICLR.cc/2017/conference/-/paper4/public/comment", "forum": "B1jnyXXJx", "replyto": "HJGaJY17e", "signatures": ["~Armen_Aghajanyan1"], "readers": ["everyone"], "writers": ["~Armen_Aghajanyan1"], "content": {"title": "new version", "comment": "I uploaded a new version of the paper that talks about choice of hyper-parameters for the saddle point toy problem. I also added clarifications throughout the paper.\n\nPlease let me know what you think."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Charged Point Normalization: An Efficient Solution to the Saddle Point Problem", "abstract": "Recently, the problem of local minima in very high dimensional non-convex optimization has been challenged and the problem of saddle points has been introduced. This paper introduces a dynamic type of normalization that forces the system to escape saddle points. Unlike other saddle point escaping algorithms, second order information is not utilized, and the system can be trained with an arbitrary gradient descent learner. The system drastically improves learning in a range of deep neural networks on various data-sets in comparison to non-CPN neural networks.", "pdf": "/pdf/4f4854eeac3c1a8dc5416dfce2adba583b6fb529.pdf", "paperhash": "aghajanyan|charged_point_normalization_an_efficient_solution_to_the_saddle_point_problem", "author_emails": "armen.ag@live.com", "conflicts": ["dimensionalmechanics.com"], "authors": ["Armen Aghajanyan"], "authorids": ["armen.ag@live.com"], "keywords": ["Deep learning", "Computer vision", "Optimization"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287766371, "id": "ICLR.cc/2017/conference/-/paper4/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1jnyXXJx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper4/reviewers", "ICLR.cc/2017/conference/paper4/areachairs"], "cdate": 1485287766371}}}, {"tddate": null, "tmdate": 1481179023972, "tcdate": 1481179023967, "number": 4, "id": "H1OckYUml", "invitation": "ICLR.cc/2017/conference/-/paper4/public/comment", "forum": "B1jnyXXJx", "replyto": "B1ZCbXg7g", "signatures": ["~Armen_Aghajanyan1"], "readers": ["everyone"], "writers": ["~Armen_Aghajanyan1"], "content": {"title": "new version", "comment": "I've added revisions about hyper-parameters and clearer expectations. I also stated that all the graphs in the paper represent train loss.\n\nPlease let me know what you think."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Charged Point Normalization: An Efficient Solution to the Saddle Point Problem", "abstract": "Recently, the problem of local minima in very high dimensional non-convex optimization has been challenged and the problem of saddle points has been introduced. This paper introduces a dynamic type of normalization that forces the system to escape saddle points. Unlike other saddle point escaping algorithms, second order information is not utilized, and the system can be trained with an arbitrary gradient descent learner. The system drastically improves learning in a range of deep neural networks on various data-sets in comparison to non-CPN neural networks.", "pdf": "/pdf/4f4854eeac3c1a8dc5416dfce2adba583b6fb529.pdf", "paperhash": "aghajanyan|charged_point_normalization_an_efficient_solution_to_the_saddle_point_problem", "author_emails": "armen.ag@live.com", "conflicts": ["dimensionalmechanics.com"], "authors": ["Armen Aghajanyan"], "authorids": ["armen.ag@live.com"], "keywords": ["Deep learning", "Computer vision", "Optimization"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287766371, "id": "ICLR.cc/2017/conference/-/paper4/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1jnyXXJx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper4/reviewers", "ICLR.cc/2017/conference/paper4/areachairs"], "cdate": 1485287766371}}}, {"tddate": null, "tmdate": 1480832676379, "tcdate": 1480832676371, "number": 3, "id": "Sk3i8VbQg", "invitation": "ICLR.cc/2017/conference/-/paper4/public/comment", "forum": "B1jnyXXJx", "replyto": "B1ZCbXg7g", "signatures": ["~Armen_Aghajanyan1"], "readers": ["everyone"], "writers": ["~Armen_Aghajanyan1"], "content": {"title": "re: Clarifications", "comment": "Thank you for your comments.\n\nTo respond to your questions:\n\n- The $\\phi$ parameter is a function that combines collapses two parameters into one parameter of the same shape. It can be thought of as a merging function. In this paper, we stick to an exponential weighted average update as the merging function. Future works can analyze various more complicated schemes for merging these two parameters.\n\n- In terms of grounded justification via optimization theory, we had trouble showing CPN's success analytically due to its dynamic nature. The paper analytically describes the problem of saddle points and shows that SGD is good enough, in principle, to escape saddle points. The problem arises in the time until convergence which we experimentally show CPN decreases. \n\n- BatchNorm would be an interesting thing to test out. I'm not sure there is enough time to rerun all experiments with BatchNorm+HyperParameter optimization. But if you believe this will significantly improve the paper, we are willing to try. BatchNorm scales inner activations in order to reduce covariate shifting between the layers. In theory, this scaling should not have much effect on CPN.\n\n- Yes. The next set of revisions on the paper will include captions and explanation on choices of hyper-parameters.\n\n- The reason we didn't include validation losses is because we are attempting to improve optimization routines, whether or not it is overfitting is due to the regularization scheme being employed, another minor reason is including more plots would cause the number of pages to exceed the limit. If you would like I can place generalization results on the BaBl dataset. \n\nThank you very much for your comments. \nArmen A."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Charged Point Normalization: An Efficient Solution to the Saddle Point Problem", "abstract": "Recently, the problem of local minima in very high dimensional non-convex optimization has been challenged and the problem of saddle points has been introduced. This paper introduces a dynamic type of normalization that forces the system to escape saddle points. Unlike other saddle point escaping algorithms, second order information is not utilized, and the system can be trained with an arbitrary gradient descent learner. The system drastically improves learning in a range of deep neural networks on various data-sets in comparison to non-CPN neural networks.", "pdf": "/pdf/4f4854eeac3c1a8dc5416dfce2adba583b6fb529.pdf", "paperhash": "aghajanyan|charged_point_normalization_an_efficient_solution_to_the_saddle_point_problem", "author_emails": "armen.ag@live.com", "conflicts": ["dimensionalmechanics.com"], "authors": ["Armen Aghajanyan"], "authorids": ["armen.ag@live.com"], "keywords": ["Deep learning", "Computer vision", "Optimization"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287766371, "id": "ICLR.cc/2017/conference/-/paper4/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1jnyXXJx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper4/reviewers", "ICLR.cc/2017/conference/paper4/areachairs"], "cdate": 1485287766371}}}, {"tddate": null, "tmdate": 1480761838698, "tcdate": 1480761800837, "number": 2, "id": "B1ZCbXg7g", "invitation": "ICLR.cc/2017/conference/-/paper4/pre-review/question", "forum": "B1jnyXXJx", "replyto": "B1jnyXXJx", "signatures": ["ICLR.cc/2017/conference/paper4/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper4/AnonReviewer2"], "content": {"title": "Clarifications", "question": "\n- You mention  about \"while the function R contains parameters: \u03b2, p, \u03c6 and\". Where do you use \u03c6 as a parameter of R(.)?\n- Do you have more theoretically grounded justification for the charged point normalization? (In terms of optimization theory)\n- Can you compare against batch-norm? Does CPN also work well with batch/layer-norm?\n- Can you add captions to your Figures? For most of the figures it is not really clear whether you are showing validation or training curves.\n- Can you also report the generalization performance for the tasks that you have tested CPN. For example it would be interesting to see how CPN effects the generalization on bAbI task. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Charged Point Normalization: An Efficient Solution to the Saddle Point Problem", "abstract": "Recently, the problem of local minima in very high dimensional non-convex optimization has been challenged and the problem of saddle points has been introduced. This paper introduces a dynamic type of normalization that forces the system to escape saddle points. Unlike other saddle point escaping algorithms, second order information is not utilized, and the system can be trained with an arbitrary gradient descent learner. The system drastically improves learning in a range of deep neural networks on various data-sets in comparison to non-CPN neural networks.", "pdf": "/pdf/4f4854eeac3c1a8dc5416dfce2adba583b6fb529.pdf", "paperhash": "aghajanyan|charged_point_normalization_an_efficient_solution_to_the_saddle_point_problem", "author_emails": "armen.ag@live.com", "conflicts": ["dimensionalmechanics.com"], "authors": ["Armen Aghajanyan"], "authorids": ["armen.ag@live.com"], "keywords": ["Deep learning", "Computer vision", "Optimization"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481213439430, "id": "ICLR.cc/2017/conference/-/paper4/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper4/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper4/AnonReviewer3", "ICLR.cc/2017/conference/paper4/AnonReviewer2", "ICLR.cc/2017/conference/paper4/AnonReviewer1"], "reply": {"forum": "B1jnyXXJx", "replyto": "B1jnyXXJx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper4/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper4/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481213439430}}}, {"tddate": null, "tmdate": 1480726464068, "tcdate": 1480726464065, "number": 2, "id": "HyupwqJQl", "invitation": "ICLR.cc/2017/conference/-/paper4/public/comment", "forum": "B1jnyXXJx", "replyto": "BJWuLKJmx", "signatures": ["~Armen_Aghajanyan1"], "readers": ["everyone"], "writers": ["~Armen_Aghajanyan1"], "content": {"title": "reply", "comment": "I see.\n\nI'll edit my paper to include explanations behind choice of parameters behind CPN. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Charged Point Normalization: An Efficient Solution to the Saddle Point Problem", "abstract": "Recently, the problem of local minima in very high dimensional non-convex optimization has been challenged and the problem of saddle points has been introduced. This paper introduces a dynamic type of normalization that forces the system to escape saddle points. Unlike other saddle point escaping algorithms, second order information is not utilized, and the system can be trained with an arbitrary gradient descent learner. The system drastically improves learning in a range of deep neural networks on various data-sets in comparison to non-CPN neural networks.", "pdf": "/pdf/4f4854eeac3c1a8dc5416dfce2adba583b6fb529.pdf", "paperhash": "aghajanyan|charged_point_normalization_an_efficient_solution_to_the_saddle_point_problem", "author_emails": "armen.ag@live.com", "conflicts": ["dimensionalmechanics.com"], "authors": ["Armen Aghajanyan"], "authorids": ["armen.ag@live.com"], "keywords": ["Deep learning", "Computer vision", "Optimization"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287766371, "id": "ICLR.cc/2017/conference/-/paper4/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1jnyXXJx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper4/reviewers", "ICLR.cc/2017/conference/paper4/areachairs"], "cdate": 1485287766371}}}, {"tddate": null, "tmdate": 1480722025432, "tcdate": 1480722025427, "number": 1, "id": "BJWuLKJmx", "invitation": "ICLR.cc/2017/conference/-/paper4/official/comment", "forum": "B1jnyXXJx", "replyto": "BJDMZYJ7x", "signatures": ["ICLR.cc/2017/conference/paper4/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper4/AnonReviewer3"], "content": {"title": "reply", "comment": "it is up to you how to check the hypothesis\nwhen you consider momentum in other approaches, you often set it to 0.9 and not 0.95 as for CPN (for SGD in section 3.3.1, for ADAM in section 3.4.2, SGD and ADAM in section 4.3, etc), why?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Charged Point Normalization: An Efficient Solution to the Saddle Point Problem", "abstract": "Recently, the problem of local minima in very high dimensional non-convex optimization has been challenged and the problem of saddle points has been introduced. This paper introduces a dynamic type of normalization that forces the system to escape saddle points. Unlike other saddle point escaping algorithms, second order information is not utilized, and the system can be trained with an arbitrary gradient descent learner. The system drastically improves learning in a range of deep neural networks on various data-sets in comparison to non-CPN neural networks.", "pdf": "/pdf/4f4854eeac3c1a8dc5416dfce2adba583b6fb529.pdf", "paperhash": "aghajanyan|charged_point_normalization_an_efficient_solution_to_the_saddle_point_problem", "author_emails": "armen.ag@live.com", "conflicts": ["dimensionalmechanics.com"], "authors": ["Armen Aghajanyan"], "authorids": ["armen.ag@live.com"], "keywords": ["Deep learning", "Computer vision", "Optimization"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287766245, "id": "ICLR.cc/2017/conference/-/paper4/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "B1jnyXXJx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper4/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper4/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper4/reviewers", "ICLR.cc/2017/conference/paper4/areachairs"], "cdate": 1485287766245}}}, {"tddate": null, "tmdate": 1480720655387, "tcdate": 1480720655381, "number": 1, "id": "BJDMZYJ7x", "invitation": "ICLR.cc/2017/conference/-/paper4/public/comment", "forum": "B1jnyXXJx", "replyto": "HJGaJY17e", "signatures": ["~Armen_Aghajanyan1"], "readers": ["everyone"], "writers": ["~Armen_Aghajanyan1"], "content": {"title": "momentum: reply", "comment": "Thank you for reading my paper!\n\nSorry, I'm a little unclear on the hypothesis. Are you recommending to increase the SGD momentum to 0.95, on page 8?\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Charged Point Normalization: An Efficient Solution to the Saddle Point Problem", "abstract": "Recently, the problem of local minima in very high dimensional non-convex optimization has been challenged and the problem of saddle points has been introduced. This paper introduces a dynamic type of normalization that forces the system to escape saddle points. Unlike other saddle point escaping algorithms, second order information is not utilized, and the system can be trained with an arbitrary gradient descent learner. The system drastically improves learning in a range of deep neural networks on various data-sets in comparison to non-CPN neural networks.", "pdf": "/pdf/4f4854eeac3c1a8dc5416dfce2adba583b6fb529.pdf", "paperhash": "aghajanyan|charged_point_normalization_an_efficient_solution_to_the_saddle_point_problem", "author_emails": "armen.ag@live.com", "conflicts": ["dimensionalmechanics.com"], "authors": ["Armen Aghajanyan"], "authorids": ["armen.ag@live.com"], "keywords": ["Deep learning", "Computer vision", "Optimization"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287766371, "id": "ICLR.cc/2017/conference/-/paper4/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "B1jnyXXJx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper4/reviewers", "ICLR.cc/2017/conference/paper4/areachairs"], "cdate": 1485287766371}}}, {"tddate": null, "tmdate": 1480720313930, "tcdate": 1480720313925, "number": 1, "id": "HJGaJY17e", "invitation": "ICLR.cc/2017/conference/-/paper4/pre-review/question", "forum": "B1jnyXXJx", "replyto": "B1jnyXXJx", "signatures": ["ICLR.cc/2017/conference/paper4/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper4/AnonReviewer3"], "content": {"title": "momentum", "question": "Please test the following hypothesis: \nequation (8) introduces a momentum term that helps to demonstrate better performance than SGD without momentum, \n\\alpha=0.95 was a good enough choice to show better performance than non-tuned algorithms on the monkey saddle function. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Charged Point Normalization: An Efficient Solution to the Saddle Point Problem", "abstract": "Recently, the problem of local minima in very high dimensional non-convex optimization has been challenged and the problem of saddle points has been introduced. This paper introduces a dynamic type of normalization that forces the system to escape saddle points. Unlike other saddle point escaping algorithms, second order information is not utilized, and the system can be trained with an arbitrary gradient descent learner. The system drastically improves learning in a range of deep neural networks on various data-sets in comparison to non-CPN neural networks.", "pdf": "/pdf/4f4854eeac3c1a8dc5416dfce2adba583b6fb529.pdf", "paperhash": "aghajanyan|charged_point_normalization_an_efficient_solution_to_the_saddle_point_problem", "author_emails": "armen.ag@live.com", "conflicts": ["dimensionalmechanics.com"], "authors": ["Armen Aghajanyan"], "authorids": ["armen.ag@live.com"], "keywords": ["Deep learning", "Computer vision", "Optimization"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481213439430, "id": "ICLR.cc/2017/conference/-/paper4/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper4/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper4/AnonReviewer3", "ICLR.cc/2017/conference/paper4/AnonReviewer2", "ICLR.cc/2017/conference/paper4/AnonReviewer1"], "reply": {"forum": "B1jnyXXJx", "replyto": "B1jnyXXJx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper4/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper4/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481213439430}}}], "count": 19}