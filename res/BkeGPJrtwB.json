{"notes": [{"id": "BkeGPJrtwB", "original": "HkedtcpuDH", "number": 1758, "cdate": 1569439577988, "ddate": null, "tcdate": 1569439577988, "tmdate": 1577168289773, "tddate": null, "forum": "BkeGPJrtwB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Fairness with Wasserstein Adversarial Networks", "authors": ["serrurier Mathieu", "Loubes Jean-Michel", "Edouard Pauwels"], "authorids": ["mathieu.serrurier@irit.fr", "loubes@math.univ-toulouse.fr", "edouard.pauwels@irit.fr"], "keywords": [], "abstract": "Quantifying, enforcing and implementing fairness emerged as a major topic in machine learning. We investigate these questions in the context of deep learning. Our main algorithmic and theoretical tool is the computational estimation of similarities between probability, ``\\`a la Wasserstein'', using adversarial networks. This idea is flexible enough to investigate different fairness constrained learning tasks, which we model by specifying properties of the underlying data generative process. The first setting considers bias in the generative model which should be filtered out. The second model is related to the presence of nuisance variables in the observations producing an unwanted bias for the learning task.  For both models, we devise a learning algorithm based on approximation of Wasserstein distances using adversarial networks. We provide formal arguments describing the fairness enforcing properties of these algorithm in relation with the underlying fairness generative processes. Finally we perform experiments, both on synthetic and real world data, to demonstrate empirically the superiority of our approach compared to state of the art fairness algorithms as well as concurrent GAN type adversarial architectures based on Jensen divergence.", "pdf": "/pdf/121658d37bbc5d736ccc2413a01661d806031e49.pdf", "paperhash": "mathieu|fairness_with_wasserstein_adversarial_networks", "original_pdf": "/attachment/121658d37bbc5d736ccc2413a01661d806031e49.pdf", "_bibtex": "@misc{\nmathieu2020fairness,\ntitle={Fairness with Wasserstein Adversarial Networks},\nauthor={serrurier Mathieu and Loubes Jean-Michel and Edouard Pauwels},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeGPJrtwB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "ypqPVEMrjG", "original": null, "number": 1, "cdate": 1576798731757, "ddate": null, "tcdate": 1576798731757, "tmdate": 1576800904690, "tddate": null, "forum": "BkeGPJrtwB", "replyto": "BkeGPJrtwB", "invitation": "ICLR.cc/2020/Conference/Paper1758/-/Decision", "content": {"decision": "Reject", "comment": "This paper presents an approach to enforce statistical fairness notions using adversarial networks. The reviewers point out several issues of the paper, including 1) their approach does not provably enforce criteria such as demographic parity, 2) lack of novelty and 3) poor presentation.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Fairness with Wasserstein Adversarial Networks", "authors": ["serrurier Mathieu", "Loubes Jean-Michel", "Edouard Pauwels"], "authorids": ["mathieu.serrurier@irit.fr", "loubes@math.univ-toulouse.fr", "edouard.pauwels@irit.fr"], "keywords": [], "abstract": "Quantifying, enforcing and implementing fairness emerged as a major topic in machine learning. We investigate these questions in the context of deep learning. Our main algorithmic and theoretical tool is the computational estimation of similarities between probability, ``\\`a la Wasserstein'', using adversarial networks. This idea is flexible enough to investigate different fairness constrained learning tasks, which we model by specifying properties of the underlying data generative process. The first setting considers bias in the generative model which should be filtered out. The second model is related to the presence of nuisance variables in the observations producing an unwanted bias for the learning task.  For both models, we devise a learning algorithm based on approximation of Wasserstein distances using adversarial networks. We provide formal arguments describing the fairness enforcing properties of these algorithm in relation with the underlying fairness generative processes. Finally we perform experiments, both on synthetic and real world data, to demonstrate empirically the superiority of our approach compared to state of the art fairness algorithms as well as concurrent GAN type adversarial architectures based on Jensen divergence.", "pdf": "/pdf/121658d37bbc5d736ccc2413a01661d806031e49.pdf", "paperhash": "mathieu|fairness_with_wasserstein_adversarial_networks", "original_pdf": "/attachment/121658d37bbc5d736ccc2413a01661d806031e49.pdf", "_bibtex": "@misc{\nmathieu2020fairness,\ntitle={Fairness with Wasserstein Adversarial Networks},\nauthor={serrurier Mathieu and Loubes Jean-Michel and Edouard Pauwels},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeGPJrtwB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "BkeGPJrtwB", "replyto": "BkeGPJrtwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795726237, "tmdate": 1576800278329, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1758/-/Decision"}}}, {"id": "HygO3_32YH", "original": null, "number": 1, "cdate": 1571764400277, "ddate": null, "tcdate": 1571764400277, "tmdate": 1572972427325, "tddate": null, "forum": "BkeGPJrtwB", "replyto": "BkeGPJrtwB", "invitation": "ICLR.cc/2020/Conference/Paper1758/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "In this paper, the authors proposed a fairness-aware learning method.\nIn particular, the authors considered two kinds of fairness problem and designed two regularizers accordingly.\nEssentially, both of these two strategies learn classifiers and calibrate the distributions conditioned on protected variables jointly. \nThe calibration of the distribution is achieved in the framework of optimal transport.\n\nThis work is a natural extension of the optimal transport-based method shown in (Barrio et al, 2019a,b). The main differences include 1) instead of calibrating distributions after learning classifiers, the proposed method achieves calibration and learning jointly, replacing the primal Wasserstein barycenter problem with the dual form of Wasserstein distance (Arjovsky et al. 2017); 2) the proposed method considers two types of fairness problem. \n\nCompared with vanilla GAN, the potential advantage of WGAN on distribution matching is well-known. It seems unfair that the authors compared the vanilla GAN-based regularizer with the proposed WGAN-based regularizer just on EMD because EMD corresponds to the proposed regularizer directly. In Table 1, although the DI of vanilla GAN is higher than that of WGAN, its ACC is also higher than that of WGAN as well. In Figure 5 (a, b), if we set lambda=0.6 for WGAN and lambda=1 for vanilla GAN, both of them can achieve ~0.838 ACC and ~0.100 DI. In Figure 5(c), what do the points represent? Why not use DI as the x-axis? Because of the issues in experiments, it is hard to evaluate the improvements of the proposed method.\n\nAdditionally, the proposed method always causes the degradation of ACC when improving DI. However, the method in (Barrio et al, 2019a) just applies a Wasserstein barycenter-based post-processing but can suppress the degradation on ACC greatly. Could the authors discuss the differences and the advantages of the proposed method in detail?  Could the authors consider more recent work as their baselines?\n\nIn summary, the method makes sense, but its novelty is limited and the improvements are incremental.\n\nMinors:\nPage 6, Line 3: Figure 3 \u2014> Figure 2.\nI suggest swapping Figure 2 and Figure 3."}, "signatures": ["ICLR.cc/2020/Conference/Paper1758/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1758/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Fairness with Wasserstein Adversarial Networks", "authors": ["serrurier Mathieu", "Loubes Jean-Michel", "Edouard Pauwels"], "authorids": ["mathieu.serrurier@irit.fr", "loubes@math.univ-toulouse.fr", "edouard.pauwels@irit.fr"], "keywords": [], "abstract": "Quantifying, enforcing and implementing fairness emerged as a major topic in machine learning. We investigate these questions in the context of deep learning. Our main algorithmic and theoretical tool is the computational estimation of similarities between probability, ``\\`a la Wasserstein'', using adversarial networks. This idea is flexible enough to investigate different fairness constrained learning tasks, which we model by specifying properties of the underlying data generative process. The first setting considers bias in the generative model which should be filtered out. The second model is related to the presence of nuisance variables in the observations producing an unwanted bias for the learning task.  For both models, we devise a learning algorithm based on approximation of Wasserstein distances using adversarial networks. We provide formal arguments describing the fairness enforcing properties of these algorithm in relation with the underlying fairness generative processes. Finally we perform experiments, both on synthetic and real world data, to demonstrate empirically the superiority of our approach compared to state of the art fairness algorithms as well as concurrent GAN type adversarial architectures based on Jensen divergence.", "pdf": "/pdf/121658d37bbc5d736ccc2413a01661d806031e49.pdf", "paperhash": "mathieu|fairness_with_wasserstein_adversarial_networks", "original_pdf": "/attachment/121658d37bbc5d736ccc2413a01661d806031e49.pdf", "_bibtex": "@misc{\nmathieu2020fairness,\ntitle={Fairness with Wasserstein Adversarial Networks},\nauthor={serrurier Mathieu and Loubes Jean-Michel and Edouard Pauwels},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeGPJrtwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BkeGPJrtwB", "replyto": "BkeGPJrtwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1758/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1758/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575743777658, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1758/Reviewers"], "noninvitees": [], "tcdate": 1570237732715, "tmdate": 1575743777672, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1758/-/Official_Review"}}}, {"id": "BJerxTNAYr", "original": null, "number": 2, "cdate": 1571863788945, "ddate": null, "tcdate": 1571863788945, "tmdate": 1572972427281, "tddate": null, "forum": "BkeGPJrtwB", "replyto": "BkeGPJrtwB", "invitation": "ICLR.cc/2020/Conference/Paper1758/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors propose a method for adding an approximate disparate impact loss to a classification objective, and show that optimizing a classifier for this loss leads to \"fairer\" predictions with little or no accuracy loss.\n\nThe authors first formulate two notions of fairness in terms of earth mover distance between the distribution of scores conditioned on either value of a protected variable. They then show that the dual formulation of the earth mover distance can be approximated (specifically, lower-bounded) by optimizing the parameters of a neural network under spectral norm constraints. This leads to a min-max global optimization scheme to learn a fair classifier.\n\nStrengths: The proposed method does better on the considered fairness metric than a GAN model with similar accuracy.\n\nWeaknesses: The paper is difficult to read, glosses over some important details, and contains some inaccuracies.\n\n-- Clarity: \n--- The authors need to better describe the assumptions (or lack thereof) made on the joint distribution of X, S, and Y. \n--- Measures such as the quantiles or probability laws need to be formally defined before they are used in definitions. \n--- The \\mathcal{L} notation is overloaded (it is used for probability laws, conditional and unconditional, as well as marginals, with \\mathcal{L}_1 referring to both!), leading to potential confusion.\n--- The domain of X and Y in equation (2) is not defined anywhere, neither is the distance.\n--- Similar lack of consistency with the use of F / \\mathcal{F} / \\hat{f}, without any explicit parameterization\n--- Figure 2 needs to be in Section 4, and Table 1 needs to be trimmed to size\n\n-- Overlooked problems:\n--- In the dual formulation, the optimization is done over a sub-set of Lipschitz function, hence approximation of \\mathcal{W} is a lower bound at every step. Minimizing a lower bound on a loss can be justified, but requires more discussion\n--- The trade-off inherent in the choice of n_w in algorithm 1 needs to be further discussed, especially in the case of large datasets where a full epoch of SGD in the inner loop of the optimization process is impractical\n\n-- Inaccuracies:\nThe graphical models in Figures 1 and 2 and conditional independences written in the text are not consistent:\n--- In Figure 1,  X is NOT independent of S given Y (neither is Y*) (see: V structures in a directed graphical model)\n--- In Figure 2, X* is independent of S regardless of conditioning on Y\n\nConsidering all of the above issues, the paper is not currently ready for publication"}, "signatures": ["ICLR.cc/2020/Conference/Paper1758/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1758/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Fairness with Wasserstein Adversarial Networks", "authors": ["serrurier Mathieu", "Loubes Jean-Michel", "Edouard Pauwels"], "authorids": ["mathieu.serrurier@irit.fr", "loubes@math.univ-toulouse.fr", "edouard.pauwels@irit.fr"], "keywords": [], "abstract": "Quantifying, enforcing and implementing fairness emerged as a major topic in machine learning. We investigate these questions in the context of deep learning. Our main algorithmic and theoretical tool is the computational estimation of similarities between probability, ``\\`a la Wasserstein'', using adversarial networks. This idea is flexible enough to investigate different fairness constrained learning tasks, which we model by specifying properties of the underlying data generative process. The first setting considers bias in the generative model which should be filtered out. The second model is related to the presence of nuisance variables in the observations producing an unwanted bias for the learning task.  For both models, we devise a learning algorithm based on approximation of Wasserstein distances using adversarial networks. We provide formal arguments describing the fairness enforcing properties of these algorithm in relation with the underlying fairness generative processes. Finally we perform experiments, both on synthetic and real world data, to demonstrate empirically the superiority of our approach compared to state of the art fairness algorithms as well as concurrent GAN type adversarial architectures based on Jensen divergence.", "pdf": "/pdf/121658d37bbc5d736ccc2413a01661d806031e49.pdf", "paperhash": "mathieu|fairness_with_wasserstein_adversarial_networks", "original_pdf": "/attachment/121658d37bbc5d736ccc2413a01661d806031e49.pdf", "_bibtex": "@misc{\nmathieu2020fairness,\ntitle={Fairness with Wasserstein Adversarial Networks},\nauthor={serrurier Mathieu and Loubes Jean-Michel and Edouard Pauwels},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeGPJrtwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BkeGPJrtwB", "replyto": "BkeGPJrtwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1758/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1758/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575743777658, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1758/Reviewers"], "noninvitees": [], "tcdate": 1570237732715, "tmdate": 1575743777672, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1758/-/Official_Review"}}}, {"id": "rkgtvbuH9S", "original": null, "number": 3, "cdate": 1572335969366, "ddate": null, "tcdate": 1572335969366, "tmdate": 1572972427238, "tddate": null, "forum": "BkeGPJrtwB", "replyto": "BkeGPJrtwB", "invitation": "ICLR.cc/2020/Conference/Paper1758/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a variant of adversarial learning to achieve some of the popular group fairness definitions. The main novelty is the idea of minimizing Wasserstein distance between the conditional distributions of classifier predictions given different values of the protected attribute.\n\nMy main concern is the approximation of a simple 1d Wasserstein distance with a neural network. Wasserstein distance between two discrete distributions in 1d can be computed in closed form (simple function of order statistics). That is, eq. (1) is simple to evaluate for two empirical distributions. There is no need to use a neural network for approximation, and even if authors choose to do so, some discussion on how well it approximates actual Wasserstein distance is needed. I think the proposed algorithm could be more interesting if authors can work out the optimization problem with the actual Wasserstein distance.\n\nOn the theoretical/motivation side, it is not enough to say that demographic parity is achieved when the corresponding Wasserstein distance is 0. What is needed is that demographic parity difference is bounded from above by the corresponding Wasserstein distance (I don't know if it is true or not, but would like to know). Then minimizing Wasserstein distance to achieve demographic parity could be justified.\n\nFinally, the paper is quite poorly written. The description of fairness in the introduction is very vague. Authors essentially describe demographic parity as fairness, while it is simply one of the several definitions of group fairness. There is also individual fairness (the paper by Dwork et al. is cited, but not properly discussed) and prior work emphasizing certain deficiencies of group fairness [1] along with several recent papers studying individual fairness [2,3], some also utilizing Wasserstein distance [4].\nAuthors also provided incorrect definition of disparate impact. Equation in the bottom of page 2 corresponds to statistical parity difference, while disparate impact is the ratio.\n\"Equality of opportunity\" on the top of page 3 seems to be a typo\n\"the mathematical properties of the disparate impact measure are not favorable, in particular it lacks robustness and smoothness features which would be necessary to blend algorithmic practice and mathematical theory\" - I don't think this claim makes sense. There are many prior works studying disparate impact and proposing algorithms to achieve it, e.g. the cited work of Feldman et al. Authors should be more specific regarding what mathematical properties they consider not favorable.\n\nThere are a lot of typos and grammatical mistakes, e.g.\nin the 1st paragraph of section 2.2, the sentence \"Hence the aim in this case is to\u201d is unfinished.\nin the 1st paragraph of section 3, the first sentence seems to be unfinished.\n\n[1] Kleinberg, J., Mullainathan, S., & Raghavan, M. (2016). Inherent trade-offs in the fair determination of risk scores.\n[2] Kearns, M., Roth, A., & Sharifi-Malvajerdi, S. (2019). Average Individual Fairness: Algorithms, Generalization and Experiments.\n[3] Jung, C., Kearns, M., Neel, S., Roth, A., Stapleton, L., & Wu, Z. S. (2019). Eliciting and Enforcing Subjective Individual Fairness.\n[4] Yurochkin, M., Bower, A., & Sun, Y. (2019). Learning fair predictors with Sensitive Subspace Robustness."}, "signatures": ["ICLR.cc/2020/Conference/Paper1758/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1758/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Fairness with Wasserstein Adversarial Networks", "authors": ["serrurier Mathieu", "Loubes Jean-Michel", "Edouard Pauwels"], "authorids": ["mathieu.serrurier@irit.fr", "loubes@math.univ-toulouse.fr", "edouard.pauwels@irit.fr"], "keywords": [], "abstract": "Quantifying, enforcing and implementing fairness emerged as a major topic in machine learning. We investigate these questions in the context of deep learning. Our main algorithmic and theoretical tool is the computational estimation of similarities between probability, ``\\`a la Wasserstein'', using adversarial networks. This idea is flexible enough to investigate different fairness constrained learning tasks, which we model by specifying properties of the underlying data generative process. The first setting considers bias in the generative model which should be filtered out. The second model is related to the presence of nuisance variables in the observations producing an unwanted bias for the learning task.  For both models, we devise a learning algorithm based on approximation of Wasserstein distances using adversarial networks. We provide formal arguments describing the fairness enforcing properties of these algorithm in relation with the underlying fairness generative processes. Finally we perform experiments, both on synthetic and real world data, to demonstrate empirically the superiority of our approach compared to state of the art fairness algorithms as well as concurrent GAN type adversarial architectures based on Jensen divergence.", "pdf": "/pdf/121658d37bbc5d736ccc2413a01661d806031e49.pdf", "paperhash": "mathieu|fairness_with_wasserstein_adversarial_networks", "original_pdf": "/attachment/121658d37bbc5d736ccc2413a01661d806031e49.pdf", "_bibtex": "@misc{\nmathieu2020fairness,\ntitle={Fairness with Wasserstein Adversarial Networks},\nauthor={serrurier Mathieu and Loubes Jean-Michel and Edouard Pauwels},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeGPJrtwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BkeGPJrtwB", "replyto": "BkeGPJrtwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1758/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1758/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575743777658, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1758/Reviewers"], "noninvitees": [], "tcdate": 1570237732715, "tmdate": 1575743777672, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1758/-/Official_Review"}}}], "count": 5}