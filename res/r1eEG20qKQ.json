{"notes": [{"id": "r1eEG20qKQ", "original": "B1gYhkRcYX", "number": 1254, "cdate": 1538087947712, "ddate": null, "tcdate": 1538087947712, "tmdate": 1552016158723, "tddate": null, "forum": "r1eEG20qKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions", "abstract": "Hyperparameter optimization can be formulated as a bilevel optimization problem, where the optimal parameters on the training set depend on the hyperparameters. We aim to adapt regularization hyperparameters for neural networks by fitting compact approximations to the best-response function, which maps hyperparameters to optimal weights and biases. We show how to construct scalable best-response approximations for neural networks by modeling the best-response as a single network whose hidden units are gated conditionally on the regularizer. We justify this approximation by showing the exact best-response for a shallow linear network with L2-regularized Jacobian can be represented by a similar gating mechanism. We fit this model using a gradient-based hyperparameter optimization algorithm which alternates between approximating the best-response around the current hyperparameters and optimizing the hyperparameters using the approximate best-response function. Unlike other gradient-based approaches, we do not require differentiating the training loss with respect to the hyperparameters, allowing us to tune discrete hyperparameters, data augmentation hyperparameters, and dropout probabilities. Because the hyperparameters are adapted online, our approach discovers hyperparameter schedules that can outperform fixed hyperparameter values. Empirically, our approach outperforms competing hyperparameter optimization methods on large-scale deep learning problems. We call our networks, which update their own hyperparameters online during training, Self-Tuning Networks (STNs).", "keywords": ["hyperparameter optimization", "game theory", "optimization"], "authorids": ["mmackay@cs.toronto.edu", "pvicol@cs.toronto.edu", "lorraine@cs.toronto.edu", "duvenaud@cs.toronto.edu", "rgrosse@cs.toronto.edu"], "authors": ["Matthew Mackay", "Paul Vicol", "Jonathan Lorraine", "David Duvenaud", "Roger Grosse"], "TL;DR": "We use a hypernetwork to predict optimal weights given hyperparameters, and jointly train everything together.", "pdf": "/pdf/724b484decb86782e05d9e039fcc75e1040ea79d.pdf", "paperhash": "mackay|selftuning_networks_bilevel_optimization_of_hyperparameters_using_structured_bestresponse_functions", "_bibtex": "@inproceedings{\nmackay2018selftuning,\ntitle={Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions},\nauthor={Matthew Mackay and Paul Vicol and Jonathan Lorraine and David Duvenaud and Roger Grosse},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1eEG20qKQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "S1xVl8vPlE", "original": null, "number": 1, "cdate": 1545201132163, "ddate": null, "tcdate": 1545201132163, "tmdate": 1545354476200, "tddate": null, "forum": "r1eEG20qKQ", "replyto": "r1eEG20qKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1254/Meta_Review", "content": {"metareview": "The paper proposes an approach to hyperparameter tuning based on bilevel optimization, and demonstrates promising empirical results. Reviewer's concerns seem to be addressed well in rebuttals and extended version of the paper.", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Accept (Poster)", "title": "A useful approach to hyperparameter tuning, promising results"}, "signatures": ["ICLR.cc/2019/Conference/Paper1254/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1254/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions", "abstract": "Hyperparameter optimization can be formulated as a bilevel optimization problem, where the optimal parameters on the training set depend on the hyperparameters. We aim to adapt regularization hyperparameters for neural networks by fitting compact approximations to the best-response function, which maps hyperparameters to optimal weights and biases. We show how to construct scalable best-response approximations for neural networks by modeling the best-response as a single network whose hidden units are gated conditionally on the regularizer. We justify this approximation by showing the exact best-response for a shallow linear network with L2-regularized Jacobian can be represented by a similar gating mechanism. We fit this model using a gradient-based hyperparameter optimization algorithm which alternates between approximating the best-response around the current hyperparameters and optimizing the hyperparameters using the approximate best-response function. Unlike other gradient-based approaches, we do not require differentiating the training loss with respect to the hyperparameters, allowing us to tune discrete hyperparameters, data augmentation hyperparameters, and dropout probabilities. Because the hyperparameters are adapted online, our approach discovers hyperparameter schedules that can outperform fixed hyperparameter values. Empirically, our approach outperforms competing hyperparameter optimization methods on large-scale deep learning problems. We call our networks, which update their own hyperparameters online during training, Self-Tuning Networks (STNs).", "keywords": ["hyperparameter optimization", "game theory", "optimization"], "authorids": ["mmackay@cs.toronto.edu", "pvicol@cs.toronto.edu", "lorraine@cs.toronto.edu", "duvenaud@cs.toronto.edu", "rgrosse@cs.toronto.edu"], "authors": ["Matthew Mackay", "Paul Vicol", "Jonathan Lorraine", "David Duvenaud", "Roger Grosse"], "TL;DR": "We use a hypernetwork to predict optimal weights given hyperparameters, and jointly train everything together.", "pdf": "/pdf/724b484decb86782e05d9e039fcc75e1040ea79d.pdf", "paperhash": "mackay|selftuning_networks_bilevel_optimization_of_hyperparameters_using_structured_bestresponse_functions", "_bibtex": "@inproceedings{\nmackay2018selftuning,\ntitle={Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions},\nauthor={Matthew Mackay and Paul Vicol and Jonathan Lorraine and David Duvenaud and Roger Grosse},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1eEG20qKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1254/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352904725, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1eEG20qKQ", "replyto": "r1eEG20qKQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1254/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1254/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1254/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352904725}}}, {"id": "rkem6wHiCX", "original": null, "number": 9, "cdate": 1543358395035, "ddate": null, "tcdate": 1543358395035, "tmdate": 1543358395035, "tddate": null, "forum": "r1eEG20qKQ", "replyto": "r1eEG20qKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1254/Official_Comment", "content": {"title": "Summary of changes", "comment": "We thank all the reviewers for their helpful comments. \n\nWe have made the following changes to the paper to address reviewer concerns:\n\n--- Improved clarity: We simplified our notation and included a table of notation in Appendix A. We added an additional figure which clarifies why hyperparameters must be sampled carefully. We have also included a discussion of the direct/response gradient which clarifies our approach.\n\n--- Sensitivity to metaparameters: In response to concerns about the sensitivity of our algorithm to its \u201cmetaparameters\u201d, we have included sensitivity studies in Appendix H to examine how our method performs under various metaparameter settings. \n\n--- Ease of implementation: We emphasize that STNs are easy to implement and use in code simply by replacing existing deep learning modules with \u201chyper\u201d counterparts. To illustrate this, we added code listings used for our experiments in Appendix G. \n\n--- Comparison to additional hyperparameter optimization methods: We have included a comparison to Hyperband for our LSTM experiments. \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1254/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1254/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1254/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions", "abstract": "Hyperparameter optimization can be formulated as a bilevel optimization problem, where the optimal parameters on the training set depend on the hyperparameters. We aim to adapt regularization hyperparameters for neural networks by fitting compact approximations to the best-response function, which maps hyperparameters to optimal weights and biases. We show how to construct scalable best-response approximations for neural networks by modeling the best-response as a single network whose hidden units are gated conditionally on the regularizer. We justify this approximation by showing the exact best-response for a shallow linear network with L2-regularized Jacobian can be represented by a similar gating mechanism. We fit this model using a gradient-based hyperparameter optimization algorithm which alternates between approximating the best-response around the current hyperparameters and optimizing the hyperparameters using the approximate best-response function. Unlike other gradient-based approaches, we do not require differentiating the training loss with respect to the hyperparameters, allowing us to tune discrete hyperparameters, data augmentation hyperparameters, and dropout probabilities. Because the hyperparameters are adapted online, our approach discovers hyperparameter schedules that can outperform fixed hyperparameter values. Empirically, our approach outperforms competing hyperparameter optimization methods on large-scale deep learning problems. We call our networks, which update their own hyperparameters online during training, Self-Tuning Networks (STNs).", "keywords": ["hyperparameter optimization", "game theory", "optimization"], "authorids": ["mmackay@cs.toronto.edu", "pvicol@cs.toronto.edu", "lorraine@cs.toronto.edu", "duvenaud@cs.toronto.edu", "rgrosse@cs.toronto.edu"], "authors": ["Matthew Mackay", "Paul Vicol", "Jonathan Lorraine", "David Duvenaud", "Roger Grosse"], "TL;DR": "We use a hypernetwork to predict optimal weights given hyperparameters, and jointly train everything together.", "pdf": "/pdf/724b484decb86782e05d9e039fcc75e1040ea79d.pdf", "paperhash": "mackay|selftuning_networks_bilevel_optimization_of_hyperparameters_using_structured_bestresponse_functions", "_bibtex": "@inproceedings{\nmackay2018selftuning,\ntitle={Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions},\nauthor={Matthew Mackay and Paul Vicol and Jonathan Lorraine and David Duvenaud and Roger Grosse},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1eEG20qKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1254/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621606892, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1eEG20qKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1254/Authors", "ICLR.cc/2019/Conference/Paper1254/Reviewers", "ICLR.cc/2019/Conference/Paper1254/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1254/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1254/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1254/Authors|ICLR.cc/2019/Conference/Paper1254/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1254/Reviewers", "ICLR.cc/2019/Conference/Paper1254/Authors", "ICLR.cc/2019/Conference/Paper1254/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621606892}}}, {"id": "SJesafJKh7", "original": null, "number": 1, "cdate": 1541104322800, "ddate": null, "tcdate": 1541104322800, "tmdate": 1543344515671, "tddate": null, "forum": "r1eEG20qKQ", "replyto": "r1eEG20qKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1254/Official_Review", "content": {"title": "The idea is interesing, but the explaination and experiment can be better", "review": "First, the writing can be better. I had a hard time to understand the paper. It has many symbols, but some of them are not explained. For instance, in  formula (9), what are Q or s? Also, formula (14). I probably can guess them. Is it possible to simplify the notations or use a table to list the symbols? \n\nFinding good models is a bi-level or tri-level optimization problem. The paper describes a gradient-based hyperparameter optimization method, which finds model parameters, hyperparameter schedules, and network structure (limited) the same time. It is a interesting idea. Comparing random search, grid search and Spearmint, it seems to be better them. The paper rules out the performance gain is from the randomness of the hyperparameters, which is a good thought. \n\nMore evidences are needed to show this method is superior. The paper doesn't explain well why it works, and the experimental results are just ok. The network architecture search part is limited to number of filters in the experiments. Certainly, the results is not as good as  PNASNet or NASNet. \n\nEvolution algorithm or GA shows good performance in hyperparameter optimization or neural architecture search. Why not compare with them? Random and grid search are not good generally, and Bayesian optimization is expensive and its performance depends on implementation.   \n\nIn Table 2 and figure 4, should \"Loss\" be \"Error\"? \n\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1254/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions", "abstract": "Hyperparameter optimization can be formulated as a bilevel optimization problem, where the optimal parameters on the training set depend on the hyperparameters. We aim to adapt regularization hyperparameters for neural networks by fitting compact approximations to the best-response function, which maps hyperparameters to optimal weights and biases. We show how to construct scalable best-response approximations for neural networks by modeling the best-response as a single network whose hidden units are gated conditionally on the regularizer. We justify this approximation by showing the exact best-response for a shallow linear network with L2-regularized Jacobian can be represented by a similar gating mechanism. We fit this model using a gradient-based hyperparameter optimization algorithm which alternates between approximating the best-response around the current hyperparameters and optimizing the hyperparameters using the approximate best-response function. Unlike other gradient-based approaches, we do not require differentiating the training loss with respect to the hyperparameters, allowing us to tune discrete hyperparameters, data augmentation hyperparameters, and dropout probabilities. Because the hyperparameters are adapted online, our approach discovers hyperparameter schedules that can outperform fixed hyperparameter values. Empirically, our approach outperforms competing hyperparameter optimization methods on large-scale deep learning problems. We call our networks, which update their own hyperparameters online during training, Self-Tuning Networks (STNs).", "keywords": ["hyperparameter optimization", "game theory", "optimization"], "authorids": ["mmackay@cs.toronto.edu", "pvicol@cs.toronto.edu", "lorraine@cs.toronto.edu", "duvenaud@cs.toronto.edu", "rgrosse@cs.toronto.edu"], "authors": ["Matthew Mackay", "Paul Vicol", "Jonathan Lorraine", "David Duvenaud", "Roger Grosse"], "TL;DR": "We use a hypernetwork to predict optimal weights given hyperparameters, and jointly train everything together.", "pdf": "/pdf/724b484decb86782e05d9e039fcc75e1040ea79d.pdf", "paperhash": "mackay|selftuning_networks_bilevel_optimization_of_hyperparameters_using_structured_bestresponse_functions", "_bibtex": "@inproceedings{\nmackay2018selftuning,\ntitle={Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions},\nauthor={Matthew Mackay and Paul Vicol and Jonathan Lorraine and David Duvenaud and Roger Grosse},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1eEG20qKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1254/Official_Review", "cdate": 1542234270128, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "r1eEG20qKQ", "replyto": "r1eEG20qKQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1254/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335906851, "tmdate": 1552335906851, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1254/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rJlurZziCX", "original": null, "number": 8, "cdate": 1543344448214, "ddate": null, "tcdate": 1543344448214, "tmdate": 1543344448214, "tddate": null, "forum": "r1eEG20qKQ", "replyto": "B1eDIJ6FCQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1254/Official_Comment", "content": {"title": "Response to the comments of authors ", "comment": "The notation table definitely helps. Ideally, I'd like to see that the Hyperband method is used in all experiments. "}, "signatures": ["ICLR.cc/2019/Conference/Paper1254/AnonReviewer3"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1254/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1254/AnonReviewer3", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions", "abstract": "Hyperparameter optimization can be formulated as a bilevel optimization problem, where the optimal parameters on the training set depend on the hyperparameters. We aim to adapt regularization hyperparameters for neural networks by fitting compact approximations to the best-response function, which maps hyperparameters to optimal weights and biases. We show how to construct scalable best-response approximations for neural networks by modeling the best-response as a single network whose hidden units are gated conditionally on the regularizer. We justify this approximation by showing the exact best-response for a shallow linear network with L2-regularized Jacobian can be represented by a similar gating mechanism. We fit this model using a gradient-based hyperparameter optimization algorithm which alternates between approximating the best-response around the current hyperparameters and optimizing the hyperparameters using the approximate best-response function. Unlike other gradient-based approaches, we do not require differentiating the training loss with respect to the hyperparameters, allowing us to tune discrete hyperparameters, data augmentation hyperparameters, and dropout probabilities. Because the hyperparameters are adapted online, our approach discovers hyperparameter schedules that can outperform fixed hyperparameter values. Empirically, our approach outperforms competing hyperparameter optimization methods on large-scale deep learning problems. We call our networks, which update their own hyperparameters online during training, Self-Tuning Networks (STNs).", "keywords": ["hyperparameter optimization", "game theory", "optimization"], "authorids": ["mmackay@cs.toronto.edu", "pvicol@cs.toronto.edu", "lorraine@cs.toronto.edu", "duvenaud@cs.toronto.edu", "rgrosse@cs.toronto.edu"], "authors": ["Matthew Mackay", "Paul Vicol", "Jonathan Lorraine", "David Duvenaud", "Roger Grosse"], "TL;DR": "We use a hypernetwork to predict optimal weights given hyperparameters, and jointly train everything together.", "pdf": "/pdf/724b484decb86782e05d9e039fcc75e1040ea79d.pdf", "paperhash": "mackay|selftuning_networks_bilevel_optimization_of_hyperparameters_using_structured_bestresponse_functions", "_bibtex": "@inproceedings{\nmackay2018selftuning,\ntitle={Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions},\nauthor={Matthew Mackay and Paul Vicol and Jonathan Lorraine and David Duvenaud and Roger Grosse},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1eEG20qKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1254/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621606892, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1eEG20qKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1254/Authors", "ICLR.cc/2019/Conference/Paper1254/Reviewers", "ICLR.cc/2019/Conference/Paper1254/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1254/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1254/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1254/Authors|ICLR.cc/2019/Conference/Paper1254/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1254/Reviewers", "ICLR.cc/2019/Conference/Paper1254/Authors", "ICLR.cc/2019/Conference/Paper1254/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621606892}}}, {"id": "r1x8vz6F0X", "original": null, "number": 5, "cdate": 1543258717745, "ddate": null, "tcdate": 1543258717745, "tmdate": 1543261173884, "tddate": null, "forum": "r1eEG20qKQ", "replyto": "Hyl-6laK07", "invitation": "ICLR.cc/2019/Conference/-/Paper1254/Official_Comment", "content": {"title": "Response to Review 2 Continued", "comment": "Q: Section 5, paragraph Gradient-Based HO: \"differentiating gradient descent\" needs reformulation -- an algorithm cannot be differentiated.\n\nA: We have removed this terminology from the paper. To clarify, we view gradient descent as a function grad_descent(initial_weight, optimizer_parameters, hyperparameters) which returns final_weight as in [1]. This descent function is differentiable w.r.t. the hyperparameters as long as the hyperparameters are not discrete and the training loss is differentiable w.r.t. the hyperparameters. \n\n[1] Maclaurin, Dougal, David Duvenaud, and Ryan Adams. \"Gradient-based hyperparameter optimization through reversible learning.\" International Conference on Machine Learning. 2015.\n\n\nQ: Cons - The method itself depends on some parameters and it is not clear how to choose them. Therefore it might be tricky to make it work in practice. I feel like there is a lot of literature around HO but very often people still use the very simple grid/random search, because the alternative methods are often quite complex to implement and make really work. So the fact that the method depends on \"crucial\" parameters but that are not transparently managed may be a big drawback to its applicability.\n\nA: For implementation, it is easy to apply STN techniques to existing deep learning models by replacing existing modules with \u201chyper\u201d versions which take an additional vector of hyperparameters in addition to the usual input. These hyper-modules are precisely the approximate best response functions in Equation 13. We include code listings in the appendix showing our HyperLinear and HyperConv2d modules.\n\nThe STN training algorithm has a few metaparameters, including the schedule for the number of gradient steps performed on the training and validation sets, the initializations, and the learning rates for the base parameter optimizer and the hyperparameter optimizer. We found that default values for each of these hyperparameters work well across the tasks we investigated - these are included in Table 4.\n\nAdditionally, we have included ablation studies of the metaparameters in section H of the appendix.  These show how robust the optimization procedure is to the meta-parameters, and the importance of the response gradient.\n\nThus, STNs are easy to apply with minimal manual tuning by using the default configuration. \n\n\nQ: - No theoretical guarantee on the quality of the used approximation for neural networks\n\nA: While it is true there are no theoretical guarantees on the quality of the approximation, it is common to lack theoretical guarantees when developing new algorithms for neural networks. Indeed, it is an active area of research to prove the convergence of gradient descent even in shallow, nonlinear networks [1][2][3]. Incorporating the bilevel structure of the problem will likely introduce additional complications, although we hope to investigate this further in future work. \n\n[1] Difan Zou, Yuan Cao, Dongruo Zhou, and Quanquan Gu. \u201cStochastic Gradient Descent Optimizes Over-parameterized Deep ReLU Networks\u201d. Preprint, 2018.\n[2] Simon S. Du, Jason D. Lee, Haochuan Li, Liwei Wang, and Xiyu Zhai. \u201cGradient Descent Finds Global Minima of Deep Neural Networks\u201d. Preprint, 2018.\n[3] Zeyuan Allen-Zhu, Yuanzhi Li, and Zhao Song. \u201cA Convergence Theory for Deep Learning via Over-Parametrization\u201d. Preprint, 2018."}, "signatures": ["ICLR.cc/2019/Conference/Paper1254/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1254/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1254/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions", "abstract": "Hyperparameter optimization can be formulated as a bilevel optimization problem, where the optimal parameters on the training set depend on the hyperparameters. We aim to adapt regularization hyperparameters for neural networks by fitting compact approximations to the best-response function, which maps hyperparameters to optimal weights and biases. We show how to construct scalable best-response approximations for neural networks by modeling the best-response as a single network whose hidden units are gated conditionally on the regularizer. We justify this approximation by showing the exact best-response for a shallow linear network with L2-regularized Jacobian can be represented by a similar gating mechanism. We fit this model using a gradient-based hyperparameter optimization algorithm which alternates between approximating the best-response around the current hyperparameters and optimizing the hyperparameters using the approximate best-response function. Unlike other gradient-based approaches, we do not require differentiating the training loss with respect to the hyperparameters, allowing us to tune discrete hyperparameters, data augmentation hyperparameters, and dropout probabilities. Because the hyperparameters are adapted online, our approach discovers hyperparameter schedules that can outperform fixed hyperparameter values. Empirically, our approach outperforms competing hyperparameter optimization methods on large-scale deep learning problems. We call our networks, which update their own hyperparameters online during training, Self-Tuning Networks (STNs).", "keywords": ["hyperparameter optimization", "game theory", "optimization"], "authorids": ["mmackay@cs.toronto.edu", "pvicol@cs.toronto.edu", "lorraine@cs.toronto.edu", "duvenaud@cs.toronto.edu", "rgrosse@cs.toronto.edu"], "authors": ["Matthew Mackay", "Paul Vicol", "Jonathan Lorraine", "David Duvenaud", "Roger Grosse"], "TL;DR": "We use a hypernetwork to predict optimal weights given hyperparameters, and jointly train everything together.", "pdf": "/pdf/724b484decb86782e05d9e039fcc75e1040ea79d.pdf", "paperhash": "mackay|selftuning_networks_bilevel_optimization_of_hyperparameters_using_structured_bestresponse_functions", "_bibtex": "@inproceedings{\nmackay2018selftuning,\ntitle={Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions},\nauthor={Matthew Mackay and Paul Vicol and Jonathan Lorraine and David Duvenaud and Roger Grosse},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1eEG20qKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1254/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621606892, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1eEG20qKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1254/Authors", "ICLR.cc/2019/Conference/Paper1254/Reviewers", "ICLR.cc/2019/Conference/Paper1254/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1254/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1254/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1254/Authors|ICLR.cc/2019/Conference/Paper1254/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1254/Reviewers", "ICLR.cc/2019/Conference/Paper1254/Authors", "ICLR.cc/2019/Conference/Paper1254/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621606892}}}, {"id": "Hyl-6laK07", "original": null, "number": 4, "cdate": 1543258296599, "ddate": null, "tcdate": 1543258296599, "tmdate": 1543261143268, "tddate": null, "forum": "r1eEG20qKQ", "replyto": "HkeVPgy5nQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1254/Official_Comment", "content": {"title": "Response to Reviewer 2", "comment": "Thank you for your feedback.\n\nQ: Can cross-validation be adapted to this approach?\n\nA: Yes, this approach can be adapted to k-fold cross-validation. The outer objective would be the sum of the validation losses across all the folds.  K different best response approximations would be trained on the k training sets, using a shared distribution over the hyperparameters.\n\n\nQ: Can this be used to optimize the learning rate? Which is of course a crucial hyperparameter and that needs an update schedule during the training.\n\nA: No, the learning rate cannot be optimized using this approach. Learning rates are hyperparameters of our optimization algorithm for solving the bilevel program, but the algorithm for solving the program is separate from the program itself. Hence, learning rates are not part of the program\u2019s variables. However, it is straightforward to combine STNs with existing methods for optimizing learning rates in the literature [1,2,3].\n\n[1] Nicol N Schraudolph. Local gain adaptation in stochastic gradient descent. International Conference on Artificial Neural Networks (ICANN), 1999.\n[2] Tom Schaul, Sixin Zhang, and Yann LeCun. No more pesky learning rates. International Conference on Machine Learning (ICML), 2013.\n[3] Atilim G Baydin, Robert Cornish, David Martinez Rubio, Mark Schmidt, and Frank Wood. Online learning rate adaptation with hypergradient descent. International Conference on Learning Representations (ICLR), 2018.\n\n\nQ: Section 3.2: \"If the entries are too large, then \u03b8\u0302 \u03c6 will not be flexible enough to capture the best- response over the sampled neighborhood. However, its entries must remain sufficiently large so that \u03b8\u0302 \u03c6 captures the local shape around the current hyperparameter values.\" Not clear why -- more explanations would be helpful.\n\nA: If we sample hyperparameters over a large range where the best-response is highly non-linear, we will never learn a good linear approximation. If we sample hyperparameters from too small a range - say a point mass - then the approximation learned will only be valid at that single point, and will not give a correct gradient.  We must sample over a range where the best-response is approximately linear. In other words, the range of the region sampled should match the flexibility of the best-response approximation. We have added Figure 2 in the paper to help clarify this. \n\n\nQ: \"minimizing the first term eventually moves all probability mass towards an optimum \u03bb\u2217 ,resulting in \u03c3 = 0\". I can't see how minimizing the first term w.r.t \\phi (as in section \"2.2.Local approximation\") would alter \\sigma.\n\nA: The objective \\hat{F}_V is optimized w.r.t. \\lambda and \\sigma, not \\phi. In general, for any function g with minimum \\lambda*, minimizing E_{p(\\eps|\\sigma)}[g(\\lambda + \\eps)] w.r.t. \\lambda and \\sigma will achieve an optimum at (\\lambda*, 0), since sampling a nonzero \\eps when at \\lambda=\\lambda* will cause the expectation to increase in value.\n\n\nQ: \"\u03c4 must be set carefully to ensure...\". The authors still do not explain how to set \\tau.\n\nA: We set \\tau by doing a grid-search. However, we found a default value of tau=0 to work well across our experiments.\n\n\nQ: Section 3.3: If the hyperparameter is discrete and falls in Case 2, then REINFORCE gradient estimator is used. What about the quality of this gradient?\n\nA: We found it to work well empirically for tuning the number of hidden units. If variance grew too high, it would be possible to use various variance reduction techniques such as RELAX [1].\n\n[1] Grathwohl, Will, Choi, Dami, Wu, Yuhuai, Roeder, Geoff, Duvenaud, David. \u201cBackpropagation through the Void: Optimizing control variates for black-box gradient estimation\u201d. ICLR 2018"}, "signatures": ["ICLR.cc/2019/Conference/Paper1254/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1254/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1254/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions", "abstract": "Hyperparameter optimization can be formulated as a bilevel optimization problem, where the optimal parameters on the training set depend on the hyperparameters. We aim to adapt regularization hyperparameters for neural networks by fitting compact approximations to the best-response function, which maps hyperparameters to optimal weights and biases. We show how to construct scalable best-response approximations for neural networks by modeling the best-response as a single network whose hidden units are gated conditionally on the regularizer. We justify this approximation by showing the exact best-response for a shallow linear network with L2-regularized Jacobian can be represented by a similar gating mechanism. We fit this model using a gradient-based hyperparameter optimization algorithm which alternates between approximating the best-response around the current hyperparameters and optimizing the hyperparameters using the approximate best-response function. Unlike other gradient-based approaches, we do not require differentiating the training loss with respect to the hyperparameters, allowing us to tune discrete hyperparameters, data augmentation hyperparameters, and dropout probabilities. Because the hyperparameters are adapted online, our approach discovers hyperparameter schedules that can outperform fixed hyperparameter values. Empirically, our approach outperforms competing hyperparameter optimization methods on large-scale deep learning problems. We call our networks, which update their own hyperparameters online during training, Self-Tuning Networks (STNs).", "keywords": ["hyperparameter optimization", "game theory", "optimization"], "authorids": ["mmackay@cs.toronto.edu", "pvicol@cs.toronto.edu", "lorraine@cs.toronto.edu", "duvenaud@cs.toronto.edu", "rgrosse@cs.toronto.edu"], "authors": ["Matthew Mackay", "Paul Vicol", "Jonathan Lorraine", "David Duvenaud", "Roger Grosse"], "TL;DR": "We use a hypernetwork to predict optimal weights given hyperparameters, and jointly train everything together.", "pdf": "/pdf/724b484decb86782e05d9e039fcc75e1040ea79d.pdf", "paperhash": "mackay|selftuning_networks_bilevel_optimization_of_hyperparameters_using_structured_bestresponse_functions", "_bibtex": "@inproceedings{\nmackay2018selftuning,\ntitle={Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions},\nauthor={Matthew Mackay and Paul Vicol and Jonathan Lorraine and David Duvenaud and Roger Grosse},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1eEG20qKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1254/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621606892, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1eEG20qKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1254/Authors", "ICLR.cc/2019/Conference/Paper1254/Reviewers", "ICLR.cc/2019/Conference/Paper1254/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1254/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1254/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1254/Authors|ICLR.cc/2019/Conference/Paper1254/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1254/Reviewers", "ICLR.cc/2019/Conference/Paper1254/Authors", "ICLR.cc/2019/Conference/Paper1254/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621606892}}}, {"id": "B1eDIJ6FCQ", "original": null, "number": 3, "cdate": 1543257935294, "ddate": null, "tcdate": 1543257935294, "tmdate": 1543258176625, "tddate": null, "forum": "r1eEG20qKQ", "replyto": "SJesafJKh7", "invitation": "ICLR.cc/2019/Conference/-/Paper1254/Official_Comment", "content": {"title": "Response to Reviewer 3", "comment": "Thank you for your feedback.\n\nQ: Clarity of writing\nFirst, the writing can be better. I had a hard time to understand the paper.\nIt has many symbols, but some of them are not explained. For instance, in formula (9), what are Q or s? Also, formula (14). I probably can guess them. Is it possible to simplify the notations or use a table to list the symbols?\n\nA: We agree with the reviewer and appreciate the suggestions.  As such, we have added a table of notation to the appendix, along with simplifying our notation. \n\n\nQ: More evidences are needed to show this method is superior. The paper doesn't explain well why it works, and the experimental results are just ok. The network architecture search part is limited to number of filters in the experiments. Certainly, the results is not as good as  PNASNet or NASNet. \n\nA: STN techniques can be applied whenever there is a bilevel problem in which the lower-level variables are a neural network's parameters.  Therefore, STNs could be used for neural architecture search. However, they are most valuable when the upper-level variable does not affect the upper-level objective directly.  This is usually the case with regularization hyperparameters since one can not use naive simultaneous gradient descent (as in ENAS[3]). Thus, the focus in this paper is on regularization hyperparameters, separate from the network topology.\n\nWe are interested in using STNs for jointly tuning regularization hyperparameters and network topology in future work. There may be benefits over current approaches since they either do not attempt to approximate the response gradient (see Eq. 6) like ENAS[3] or approximate it using finite differences like DARTS[4]. Directly approximating the best-response and including its gradient may yield a more accurate gradient of the validation loss.\n\n[1] Zoph, Barret, and Quoc V. Le. \"Neural architecture search with reinforcement learning.\" arXiv preprint arXiv:1611.01578(2016).\n[2] Liu, Chenxi, et al. \"Progressive neural architecture search.\" arXiv preprint arXiv:1712.00559 (2017).\n[3] Pham, Hieu, et al. \"Efficient Neural Architecture Search via Parameter Sharing.\" arXiv preprint arXiv:1802.03268 (2018).\n[4] Liu, Hanxiao, Karen Simonyan, and Yiming Yang. \"Darts: Differentiable architecture search.\" arXiv preprint arXiv:1806.09055 (2018).\n\n\nQ: Evolution algorithm or GA shows good performance in hyperparameter optimization or neural architecture search. Why not compare with them? Random and grid search are not good generally, and Bayesian optimization is expensive and its performance depends on implementation. \n\nA: We include a comparison to Hyperband for LSTMs in the revised version of the paper.\n\n\nQ: In Table 2 and figure 4, should \"Loss\" be \"Error\"?\n\nA: Figure 4 (now 5) is the loss because that is the objective being minimized via gradient descent."}, "signatures": ["ICLR.cc/2019/Conference/Paper1254/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1254/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1254/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions", "abstract": "Hyperparameter optimization can be formulated as a bilevel optimization problem, where the optimal parameters on the training set depend on the hyperparameters. We aim to adapt regularization hyperparameters for neural networks by fitting compact approximations to the best-response function, which maps hyperparameters to optimal weights and biases. We show how to construct scalable best-response approximations for neural networks by modeling the best-response as a single network whose hidden units are gated conditionally on the regularizer. We justify this approximation by showing the exact best-response for a shallow linear network with L2-regularized Jacobian can be represented by a similar gating mechanism. We fit this model using a gradient-based hyperparameter optimization algorithm which alternates between approximating the best-response around the current hyperparameters and optimizing the hyperparameters using the approximate best-response function. Unlike other gradient-based approaches, we do not require differentiating the training loss with respect to the hyperparameters, allowing us to tune discrete hyperparameters, data augmentation hyperparameters, and dropout probabilities. Because the hyperparameters are adapted online, our approach discovers hyperparameter schedules that can outperform fixed hyperparameter values. Empirically, our approach outperforms competing hyperparameter optimization methods on large-scale deep learning problems. We call our networks, which update their own hyperparameters online during training, Self-Tuning Networks (STNs).", "keywords": ["hyperparameter optimization", "game theory", "optimization"], "authorids": ["mmackay@cs.toronto.edu", "pvicol@cs.toronto.edu", "lorraine@cs.toronto.edu", "duvenaud@cs.toronto.edu", "rgrosse@cs.toronto.edu"], "authors": ["Matthew Mackay", "Paul Vicol", "Jonathan Lorraine", "David Duvenaud", "Roger Grosse"], "TL;DR": "We use a hypernetwork to predict optimal weights given hyperparameters, and jointly train everything together.", "pdf": "/pdf/724b484decb86782e05d9e039fcc75e1040ea79d.pdf", "paperhash": "mackay|selftuning_networks_bilevel_optimization_of_hyperparameters_using_structured_bestresponse_functions", "_bibtex": "@inproceedings{\nmackay2018selftuning,\ntitle={Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions},\nauthor={Matthew Mackay and Paul Vicol and Jonathan Lorraine and David Duvenaud and Roger Grosse},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1eEG20qKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1254/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621606892, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1eEG20qKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1254/Authors", "ICLR.cc/2019/Conference/Paper1254/Reviewers", "ICLR.cc/2019/Conference/Paper1254/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1254/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1254/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1254/Authors|ICLR.cc/2019/Conference/Paper1254/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1254/Reviewers", "ICLR.cc/2019/Conference/Paper1254/Authors", "ICLR.cc/2019/Conference/Paper1254/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621606892}}}, {"id": "SklEgC2YCX", "original": null, "number": 2, "cdate": 1543257580362, "ddate": null, "tcdate": 1543257580362, "tmdate": 1543257580362, "tddate": null, "forum": "r1eEG20qKQ", "replyto": "HJx1qfxi3Q", "invitation": "ICLR.cc/2019/Conference/-/Paper1254/Official_Comment", "content": {"title": "Response to Reviewer 1", "comment": "Thank you for your feedback.\n\nQ: Experiments are run on small scale problems, namely, CIFAR-10 and PTB. Results are encouraging but not stellar. More work would need to be done to validate the utility of the proposed approach on larger scale problems.\n\nA: Smaller datasets such as CIFAR-10 and PTB provide an ideal testbed for hyperparameter optimization algorithms since performance depends heavily on regularization. The architectures used for RNNs are comparable in size to top-performing architectures on PTB [1,2]. In addition, we believe we are the first to tune RNN hyperparameters using gradient-based methods since these hyperparameters are often dropout probabilities that other gradient-based methods can\u2019t handle.\n\nAlexNet is a standard architecture used when ResNets are too powerful and can overfit. This convolutional architecture is comparable to the largest tuned via gradient-based hyperparameter optimization methods in the literature. Papers such as [3,4] evaluate their algorithms on MNIST-size datasets using logistic regression or small feed-forward networks. In [5] a similar size convolutional network to AlexNet is tuned, but they weren\u2019t able to tune data augmentation hyperparameters and had to use continuous dropout noise to obtain a gradient, unlike our method. \n\n\n[1] Merity, Stephen, Keskar, Nitish S., and Socher, Richard. \"Regularizing and optimizing LSTM language models.\" ICLR 2018.\n[2] Melis, Gabor, Dyer, Chris, and Blunsom, Phil. \u201cOn the State of the Art of Evaluation in Neural Language Models\u201d ICLR 2018\n[3] Pedregosa, Fabian. \u201cHyperparameter optimization with approximate gradient\u201d ICML 2016\n[4] Maclaurin, Dougal, Duvenaud, David, and Adams, Ryan. \u201cGradient-based Hyperparameter Optimization through Reversible Learning\u201d ICML 2015\n[5] Luketina, Jelena, Berglund, Mathias, Greff, Klaus, and Raiko, Tapani. \u201cScalable Gradient-Based Tuning of Continuous Regularization Hyperparameters\u201d ICML 2016"}, "signatures": ["ICLR.cc/2019/Conference/Paper1254/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1254/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1254/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions", "abstract": "Hyperparameter optimization can be formulated as a bilevel optimization problem, where the optimal parameters on the training set depend on the hyperparameters. We aim to adapt regularization hyperparameters for neural networks by fitting compact approximations to the best-response function, which maps hyperparameters to optimal weights and biases. We show how to construct scalable best-response approximations for neural networks by modeling the best-response as a single network whose hidden units are gated conditionally on the regularizer. We justify this approximation by showing the exact best-response for a shallow linear network with L2-regularized Jacobian can be represented by a similar gating mechanism. We fit this model using a gradient-based hyperparameter optimization algorithm which alternates between approximating the best-response around the current hyperparameters and optimizing the hyperparameters using the approximate best-response function. Unlike other gradient-based approaches, we do not require differentiating the training loss with respect to the hyperparameters, allowing us to tune discrete hyperparameters, data augmentation hyperparameters, and dropout probabilities. Because the hyperparameters are adapted online, our approach discovers hyperparameter schedules that can outperform fixed hyperparameter values. Empirically, our approach outperforms competing hyperparameter optimization methods on large-scale deep learning problems. We call our networks, which update their own hyperparameters online during training, Self-Tuning Networks (STNs).", "keywords": ["hyperparameter optimization", "game theory", "optimization"], "authorids": ["mmackay@cs.toronto.edu", "pvicol@cs.toronto.edu", "lorraine@cs.toronto.edu", "duvenaud@cs.toronto.edu", "rgrosse@cs.toronto.edu"], "authors": ["Matthew Mackay", "Paul Vicol", "Jonathan Lorraine", "David Duvenaud", "Roger Grosse"], "TL;DR": "We use a hypernetwork to predict optimal weights given hyperparameters, and jointly train everything together.", "pdf": "/pdf/724b484decb86782e05d9e039fcc75e1040ea79d.pdf", "paperhash": "mackay|selftuning_networks_bilevel_optimization_of_hyperparameters_using_structured_bestresponse_functions", "_bibtex": "@inproceedings{\nmackay2018selftuning,\ntitle={Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions},\nauthor={Matthew Mackay and Paul Vicol and Jonathan Lorraine and David Duvenaud and Roger Grosse},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1eEG20qKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1254/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621606892, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1eEG20qKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1254/Authors", "ICLR.cc/2019/Conference/Paper1254/Reviewers", "ICLR.cc/2019/Conference/Paper1254/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1254/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1254/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1254/Authors|ICLR.cc/2019/Conference/Paper1254/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1254/Reviewers", "ICLR.cc/2019/Conference/Paper1254/Authors", "ICLR.cc/2019/Conference/Paper1254/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621606892}}}, {"id": "HJx1qfxi3Q", "original": null, "number": 3, "cdate": 1541239430814, "ddate": null, "tcdate": 1541239430814, "tmdate": 1541533291608, "tddate": null, "forum": "r1eEG20qKQ", "replyto": "r1eEG20qKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1254/Official_Review", "content": {"title": "Principled approach to hyperparameter tuning but only evaluated on small scale problems to-date.", "review": "The paper proposes a bilevel optimization approach for hyperparameter tuning. This idea is not new having been proposed in works prior to the current resurgence of deep learning (e.g., Do et al., 2007, Domke 2012, and Kunisch & Pock, 2013). However, the combination of bilevel optimization for hyperparameter tuning with approximation is interesting. Moreover, the proposed approach readily handles discrete parameters.\n\nExperiments are run on small scale problems, namely, CIFAR-10 and PTB. Results are encouraging but not stellar. More work would need to be done to validate the utility of the proposed approach on larger scale problems.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1254/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions", "abstract": "Hyperparameter optimization can be formulated as a bilevel optimization problem, where the optimal parameters on the training set depend on the hyperparameters. We aim to adapt regularization hyperparameters for neural networks by fitting compact approximations to the best-response function, which maps hyperparameters to optimal weights and biases. We show how to construct scalable best-response approximations for neural networks by modeling the best-response as a single network whose hidden units are gated conditionally on the regularizer. We justify this approximation by showing the exact best-response for a shallow linear network with L2-regularized Jacobian can be represented by a similar gating mechanism. We fit this model using a gradient-based hyperparameter optimization algorithm which alternates between approximating the best-response around the current hyperparameters and optimizing the hyperparameters using the approximate best-response function. Unlike other gradient-based approaches, we do not require differentiating the training loss with respect to the hyperparameters, allowing us to tune discrete hyperparameters, data augmentation hyperparameters, and dropout probabilities. Because the hyperparameters are adapted online, our approach discovers hyperparameter schedules that can outperform fixed hyperparameter values. Empirically, our approach outperforms competing hyperparameter optimization methods on large-scale deep learning problems. We call our networks, which update their own hyperparameters online during training, Self-Tuning Networks (STNs).", "keywords": ["hyperparameter optimization", "game theory", "optimization"], "authorids": ["mmackay@cs.toronto.edu", "pvicol@cs.toronto.edu", "lorraine@cs.toronto.edu", "duvenaud@cs.toronto.edu", "rgrosse@cs.toronto.edu"], "authors": ["Matthew Mackay", "Paul Vicol", "Jonathan Lorraine", "David Duvenaud", "Roger Grosse"], "TL;DR": "We use a hypernetwork to predict optimal weights given hyperparameters, and jointly train everything together.", "pdf": "/pdf/724b484decb86782e05d9e039fcc75e1040ea79d.pdf", "paperhash": "mackay|selftuning_networks_bilevel_optimization_of_hyperparameters_using_structured_bestresponse_functions", "_bibtex": "@inproceedings{\nmackay2018selftuning,\ntitle={Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions},\nauthor={Matthew Mackay and Paul Vicol and Jonathan Lorraine and David Duvenaud and Roger Grosse},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1eEG20qKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1254/Official_Review", "cdate": 1542234270128, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "r1eEG20qKQ", "replyto": "r1eEG20qKQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1254/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335906851, "tmdate": 1552335906851, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1254/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HkeVPgy5nQ", "original": null, "number": 2, "cdate": 1541169244449, "ddate": null, "tcdate": 1541169244449, "tmdate": 1541533291408, "tddate": null, "forum": "r1eEG20qKQ", "replyto": "r1eEG20qKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1254/Official_Review", "content": {"title": "Good idea, not clear if it is easy to apply.", "review": "\n========\\\\\nSummary\\\\\n========\\\\\n\nThe paper deals with hyper-parameter optimization of neural networks. The authors formulate the problem as a bilevel optimization problem: minimizing the validation loss over the hyperparameters, subject to the parameters being at the minimum of the training loss. The authors propose an approximation of the so-called best-response function, that maps the hyperparameters to the corresponding optimal parameters (w.r.t the minimization of the training loss), allowing a formulate as a single-level optimization problem and the use gradient descent algorithm. The proposed\napproximation is based on shifting and scaling the weights and biases of the network. There are no guarantee on its quality except in some very simple cases. The approach assumes a distribution on the hyperparameters, governed by a parameter, which is adapted during the course of the training to achieve a compromise between the flexibility of the best-response function and the quality of its local approximation around the current hyperparameters. The authors show\nthat their approach beats grid-search, random search and Bayesian optimization on the CIFAR-10 and PTB datasets. They point out that the dynamic update of the hyperparameters during the training allows to reach a better performance than any fixed hyperparameter. \\\\\n\n\n======================\\\\\nComments and questions\\\\\n======================\\\\\n\nCan cross-validation be adapted to this approach? \\\\\n\nCan this be used to optimize the learning rate? Which is of course a crucial hyperparameter and that needs an update schedule during the training. \\\\\n\nSection 3.2:\\\\\n\n\"If the entries are too large, then \u03b8\u0302 \u03c6 will not be flexible enough to capture the best- response over the sampled neighborhood. However, its entries must remain sufficiently large so that \u03b8\u0302 \u03c6 captures the local shape around the current hyperparameter values.\" Not clear why -- more explanations would be helpful. \\\\\n\n\"minimizing the first term eventually moves all probability mass towards an optimum \u03bb\u2217 ,resulting in \u03c3 = 0\". I can't see how minimizing the first term w.r.t \\phi (as in section \"2.2.Local approximation\") would alter \\sigma. \\\\\n\n\"\u03c4 must be set carefully to ensure...\". The authors still do not explain how to set \\tau. \\\\\n\nSection 3.3: \\\\\n\nIf the hyperparameter is discrete and falls in Case 2, then REINFORCE gradient estimator is used. What about the quality of this gradient? \\\\\n\nSection 5, paragraph Gradient-Based HO: \"differentiating gradient descent\" needs reformulation -- an algorithm cannot be differentiated. \\\\\n\nPros \\\\\n- The paper is pretty clear \\\\\n- Generalizes a previous idea and makes it handle discrete hyperparameters and scale better. \\\\\n- I like the idea of hyperparameters changing dynamically during the training which allows to explore a much larger space than one value \\\\\n- Although limited, the experimental results are convincing \\\\\n\nCons \\\\\n- The method itself depends on some parameters and it is not clear how to choose them. Therefore it might be tricky to make it work in practice. I feel like there is a lot of literature around HO but very often people still use the very simple grid/random search, because the alternative methods are often quite complex to implement and make really work. So the fact that the method depends on \"crucial\" parameters but that are not transparently managed may be a big drawback to its applicability. \\\\\n- No theoretical guarantee on the quality of the used approximation for neural networks \\\\\n- Does not handle the learning rate which is a crucial hyperparameter (but maybe it could) \\\\\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1254/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions", "abstract": "Hyperparameter optimization can be formulated as a bilevel optimization problem, where the optimal parameters on the training set depend on the hyperparameters. We aim to adapt regularization hyperparameters for neural networks by fitting compact approximations to the best-response function, which maps hyperparameters to optimal weights and biases. We show how to construct scalable best-response approximations for neural networks by modeling the best-response as a single network whose hidden units are gated conditionally on the regularizer. We justify this approximation by showing the exact best-response for a shallow linear network with L2-regularized Jacobian can be represented by a similar gating mechanism. We fit this model using a gradient-based hyperparameter optimization algorithm which alternates between approximating the best-response around the current hyperparameters and optimizing the hyperparameters using the approximate best-response function. Unlike other gradient-based approaches, we do not require differentiating the training loss with respect to the hyperparameters, allowing us to tune discrete hyperparameters, data augmentation hyperparameters, and dropout probabilities. Because the hyperparameters are adapted online, our approach discovers hyperparameter schedules that can outperform fixed hyperparameter values. Empirically, our approach outperforms competing hyperparameter optimization methods on large-scale deep learning problems. We call our networks, which update their own hyperparameters online during training, Self-Tuning Networks (STNs).", "keywords": ["hyperparameter optimization", "game theory", "optimization"], "authorids": ["mmackay@cs.toronto.edu", "pvicol@cs.toronto.edu", "lorraine@cs.toronto.edu", "duvenaud@cs.toronto.edu", "rgrosse@cs.toronto.edu"], "authors": ["Matthew Mackay", "Paul Vicol", "Jonathan Lorraine", "David Duvenaud", "Roger Grosse"], "TL;DR": "We use a hypernetwork to predict optimal weights given hyperparameters, and jointly train everything together.", "pdf": "/pdf/724b484decb86782e05d9e039fcc75e1040ea79d.pdf", "paperhash": "mackay|selftuning_networks_bilevel_optimization_of_hyperparameters_using_structured_bestresponse_functions", "_bibtex": "@inproceedings{\nmackay2018selftuning,\ntitle={Self-Tuning Networks: Bilevel Optimization of Hyperparameters using Structured Best-Response Functions},\nauthor={Matthew Mackay and Paul Vicol and Jonathan Lorraine and David Duvenaud and Roger Grosse},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1eEG20qKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1254/Official_Review", "cdate": 1542234270128, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "r1eEG20qKQ", "replyto": "r1eEG20qKQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1254/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335906851, "tmdate": 1552335906851, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1254/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 11}