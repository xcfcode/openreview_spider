{"notes": [{"id": "S1xipR4FPB", "original": "H1eHamq_wr", "number": 1406, "cdate": 1569439426891, "ddate": null, "tcdate": 1569439426891, "tmdate": 1577168220827, "tddate": null, "forum": "S1xipR4FPB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["ruishan@stanford.edu", "lmackey@stanford.edu", "fusi@microsoft.com"], "title": "Teacher-Student Compression with Generative Adversarial Networks", "authors": ["Ruishan Liu", "Nicolo Fusi", "Lester Mackey"], "pdf": "/pdf/fd0e3200bca8c724c46a57aacde218a5f93d226f.pdf", "abstract": "More accurate machine learning models often demand more computation and memory at test time, making them difficult to deploy on CPU- or memory-constrained devices. Teacher-student compression (TSC), also known as distillation, alleviates this burden by training a less expensive student model to mimic the expensive teacher model while maintaining most of the original accuracy. However, when fresh data is unavailable for the compression task, the teacher's training data is typically reused, leading to suboptimal compression. In this work, we propose to augment the compression dataset with synthetic data from a generative adversarial network (GAN) designed to approximate the training data distribution. Our GAN-assisted TSC (GAN-TSC) significantly improves student accuracy for expensive models such as large random forests and deep neural networks on both tabular and image datasets. Building on these results, we propose a comprehensive metric\u2014the TSC Score\u2014to evaluate the quality of synthetic datasets based on their induced TSC performance. The TSC Score captures both data diversity and class affinity, and we illustrate its benefits over the popular Inception Score in the context of image classification.", "code": "https://drive.google.com/drive/folders/1IovL_rAVKVnpG2enqAgfPMilOUH-n8tu?usp=sharing", "keywords": [], "paperhash": "liu|teacherstudent_compression_with_generative_adversarial_networks", "original_pdf": "/attachment/fd0e3200bca8c724c46a57aacde218a5f93d226f.pdf", "_bibtex": "@misc{\nliu2020teacherstudent,\ntitle={Teacher-Student Compression with Generative Adversarial Networks},\nauthor={Ruishan Liu and Nicolo Fusi and Lester Mackey},\nyear={2020},\nurl={https://openreview.net/forum?id=S1xipR4FPB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "5NH_wiG8cb", "original": null, "number": 1, "cdate": 1576798722499, "ddate": null, "tcdate": 1576798722499, "tmdate": 1576800914069, "tddate": null, "forum": "S1xipR4FPB", "replyto": "S1xipR4FPB", "invitation": "ICLR.cc/2020/Conference/Paper1406/-/Decision", "content": {"decision": "Reject", "comment": "This paper uses GAN for data augmentation to improve the performance of knowledge distillation.\n\nReviewers and AC commonly think the paper suffers from limited novelty and insufficient experimental supports/details.\n\nHence, I recommend rejection.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["ruishan@stanford.edu", "lmackey@stanford.edu", "fusi@microsoft.com"], "title": "Teacher-Student Compression with Generative Adversarial Networks", "authors": ["Ruishan Liu", "Nicolo Fusi", "Lester Mackey"], "pdf": "/pdf/fd0e3200bca8c724c46a57aacde218a5f93d226f.pdf", "abstract": "More accurate machine learning models often demand more computation and memory at test time, making them difficult to deploy on CPU- or memory-constrained devices. Teacher-student compression (TSC), also known as distillation, alleviates this burden by training a less expensive student model to mimic the expensive teacher model while maintaining most of the original accuracy. However, when fresh data is unavailable for the compression task, the teacher's training data is typically reused, leading to suboptimal compression. In this work, we propose to augment the compression dataset with synthetic data from a generative adversarial network (GAN) designed to approximate the training data distribution. Our GAN-assisted TSC (GAN-TSC) significantly improves student accuracy for expensive models such as large random forests and deep neural networks on both tabular and image datasets. Building on these results, we propose a comprehensive metric\u2014the TSC Score\u2014to evaluate the quality of synthetic datasets based on their induced TSC performance. The TSC Score captures both data diversity and class affinity, and we illustrate its benefits over the popular Inception Score in the context of image classification.", "code": "https://drive.google.com/drive/folders/1IovL_rAVKVnpG2enqAgfPMilOUH-n8tu?usp=sharing", "keywords": [], "paperhash": "liu|teacherstudent_compression_with_generative_adversarial_networks", "original_pdf": "/attachment/fd0e3200bca8c724c46a57aacde218a5f93d226f.pdf", "_bibtex": "@misc{\nliu2020teacherstudent,\ntitle={Teacher-Student Compression with Generative Adversarial Networks},\nauthor={Ruishan Liu and Nicolo Fusi and Lester Mackey},\nyear={2020},\nurl={https://openreview.net/forum?id=S1xipR4FPB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "S1xipR4FPB", "replyto": "S1xipR4FPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795726952, "tmdate": 1576800279142, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1406/-/Decision"}}}, {"id": "BkxtFPgnFS", "original": null, "number": 1, "cdate": 1571714945206, "ddate": null, "tcdate": 1571714945206, "tmdate": 1572972472952, "tddate": null, "forum": "S1xipR4FPB", "replyto": "S1xipR4FPB", "invitation": "ICLR.cc/2020/Conference/Paper1406/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes an approach for improving teacher-student compression by introducing the assistant of GANs. A conditional GAN is trained for generating synthetic data. Then, the generated data combined with training data is used for knowledge distillation. Experiments on large random forests and deep neural networks demonstrate the effectiveness of the proposed method on data-augmentation. Moreover, an evaluation metric is proposed to evaluate s across-class diversity and intra-class diversity for generative models.\n\nPros:\n\n+ While using synthetic data of GANs to assist supervised learning has been shown to be failed in pervious works (e.g. [1] and also shown in this paper, this paper presents a new perspective to utilize GAN as a successful data-augmentation technique in teacher student paradigm.\n+ Experiments are conducted in several settings including different models (random forests, deep neural networks) and different datasets (images and tabular) to show the effectiveness of proposed method in various settings.\n+ The proposed GAN-TSC can be combined with standard augmentation to achieve higher performance as shown in the experiments.\n+ This paper is well written and easy to follow.\n\nCons:\n\n- Knowledge distillation, as a classical model compression technique, has been applied in deep convolutional models for several years. The CIFAR-10 dataset is too simple to evaluate this kind of methods. The author should try to conduct experiments on large scale datasets such as ImageNet, unless the reliability of the proposed algorithm would be very limited.\n- The proposed TSCScore seems to be similar with [1], especially when its novelty mainly lies in intra-class diversity compared with IS. It\u2019s necessary to discuss difference between TSCScore and [1].\n\n[1] Konstantin Shmelkov, Cordelia Schmid, and Karteek Alahari. How good is my GAN? ECCV 2018.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1406/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1406/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["ruishan@stanford.edu", "lmackey@stanford.edu", "fusi@microsoft.com"], "title": "Teacher-Student Compression with Generative Adversarial Networks", "authors": ["Ruishan Liu", "Nicolo Fusi", "Lester Mackey"], "pdf": "/pdf/fd0e3200bca8c724c46a57aacde218a5f93d226f.pdf", "abstract": "More accurate machine learning models often demand more computation and memory at test time, making them difficult to deploy on CPU- or memory-constrained devices. Teacher-student compression (TSC), also known as distillation, alleviates this burden by training a less expensive student model to mimic the expensive teacher model while maintaining most of the original accuracy. However, when fresh data is unavailable for the compression task, the teacher's training data is typically reused, leading to suboptimal compression. In this work, we propose to augment the compression dataset with synthetic data from a generative adversarial network (GAN) designed to approximate the training data distribution. Our GAN-assisted TSC (GAN-TSC) significantly improves student accuracy for expensive models such as large random forests and deep neural networks on both tabular and image datasets. Building on these results, we propose a comprehensive metric\u2014the TSC Score\u2014to evaluate the quality of synthetic datasets based on their induced TSC performance. The TSC Score captures both data diversity and class affinity, and we illustrate its benefits over the popular Inception Score in the context of image classification.", "code": "https://drive.google.com/drive/folders/1IovL_rAVKVnpG2enqAgfPMilOUH-n8tu?usp=sharing", "keywords": [], "paperhash": "liu|teacherstudent_compression_with_generative_adversarial_networks", "original_pdf": "/attachment/fd0e3200bca8c724c46a57aacde218a5f93d226f.pdf", "_bibtex": "@misc{\nliu2020teacherstudent,\ntitle={Teacher-Student Compression with Generative Adversarial Networks},\nauthor={Ruishan Liu and Nicolo Fusi and Lester Mackey},\nyear={2020},\nurl={https://openreview.net/forum?id=S1xipR4FPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "S1xipR4FPB", "replyto": "S1xipR4FPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1406/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1406/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575581575657, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1406/Reviewers"], "noninvitees": [], "tcdate": 1570237737847, "tmdate": 1575581575673, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1406/-/Official_Review"}}}, {"id": "S1gog4vAYS", "original": null, "number": 2, "cdate": 1571873778836, "ddate": null, "tcdate": 1571873778836, "tmdate": 1572972472905, "tddate": null, "forum": "S1xipR4FPB", "replyto": "S1xipR4FPB", "invitation": "ICLR.cc/2020/Conference/Paper1406/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "In this manuscript, authors adopt GAN for data augmentation to improve the performance of knowledge distillation. My concerns are as follows.\n1.\tThe novelty is limited. Using GAN for data augmentation is not new and authors only introduce it for KD, which didn\u2019t address the essential problem of KD itself.\n2.\tThe experiments are not sufficient. For DNNs, authors only compare the performance on CIFAR-10 with the conventional KD. More data sets and benchmark algorithms are helpful to illustrate the effectiveness of GAN data.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1406/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1406/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["ruishan@stanford.edu", "lmackey@stanford.edu", "fusi@microsoft.com"], "title": "Teacher-Student Compression with Generative Adversarial Networks", "authors": ["Ruishan Liu", "Nicolo Fusi", "Lester Mackey"], "pdf": "/pdf/fd0e3200bca8c724c46a57aacde218a5f93d226f.pdf", "abstract": "More accurate machine learning models often demand more computation and memory at test time, making them difficult to deploy on CPU- or memory-constrained devices. Teacher-student compression (TSC), also known as distillation, alleviates this burden by training a less expensive student model to mimic the expensive teacher model while maintaining most of the original accuracy. However, when fresh data is unavailable for the compression task, the teacher's training data is typically reused, leading to suboptimal compression. In this work, we propose to augment the compression dataset with synthetic data from a generative adversarial network (GAN) designed to approximate the training data distribution. Our GAN-assisted TSC (GAN-TSC) significantly improves student accuracy for expensive models such as large random forests and deep neural networks on both tabular and image datasets. Building on these results, we propose a comprehensive metric\u2014the TSC Score\u2014to evaluate the quality of synthetic datasets based on their induced TSC performance. The TSC Score captures both data diversity and class affinity, and we illustrate its benefits over the popular Inception Score in the context of image classification.", "code": "https://drive.google.com/drive/folders/1IovL_rAVKVnpG2enqAgfPMilOUH-n8tu?usp=sharing", "keywords": [], "paperhash": "liu|teacherstudent_compression_with_generative_adversarial_networks", "original_pdf": "/attachment/fd0e3200bca8c724c46a57aacde218a5f93d226f.pdf", "_bibtex": "@misc{\nliu2020teacherstudent,\ntitle={Teacher-Student Compression with Generative Adversarial Networks},\nauthor={Ruishan Liu and Nicolo Fusi and Lester Mackey},\nyear={2020},\nurl={https://openreview.net/forum?id=S1xipR4FPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "S1xipR4FPB", "replyto": "S1xipR4FPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1406/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1406/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575581575657, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1406/Reviewers"], "noninvitees": [], "tcdate": 1570237737847, "tmdate": 1575581575673, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1406/-/Official_Review"}}}, {"id": "Sye1MwBJ9S", "original": null, "number": 3, "cdate": 1571931910868, "ddate": null, "tcdate": 1571931910868, "tmdate": 1572972472860, "tddate": null, "forum": "S1xipR4FPB", "replyto": "S1xipR4FPB", "invitation": "ICLR.cc/2020/Conference/Paper1406/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents an algorithm to generate images for training a student network through distillation. The paper claims the use of the same training data is not necessarily beneficial when it comes to improving the accuracy of the student being trained. \nThe paper sits on the empirically driven side with sufficient experiments in the context of random forest and CNN.\nAs a second contribution, the paper proposes a scoring process to evaluate the quality of datasets generated by GAN methods. There are little experiments on this side. \n\n\nPros:\n- I like the paper and the idea behind being able to improve or even train a student network when the original data is not present.\n- Metrics tailored to the problem are relevant. \n\nNegs:\n\n- While there are plenty of experiments, there is a lack of detailed descriptions. \n- The scoring for GANS seems to be barely tested. In the scoring GAN, The fact that TSCS drops is enough to be a valid metric (or better than existing?). In the TSC vs inception, it is hard for me to see the unrealistic artifacts and, according to the text, that is not what TSCS is measuring, right? What is the influence of using different student-teacher configuration? (on the time to produce the scores the paper claims NiN and LeNet, is there any difference if using other architectures (ResNet family for instance)? At least, in that case, the time changes. It would be nice to see the stability of this metric to demonstrate that the need for training an inexpensive model is correct. \n\n\nFor the TSC vs Inception, the GANs are subjectively assessed, isn't it (as to select well-trained to Inferior). Would it be possible to see exactly the same images between the two of them? Seems like the difference in quality for IS is significantly larger than for the proposed metric (even in the last gan there is a slight increase in the metric). \n\nIt seems to me that IS is just a quality metric based on how a single image looks like. Would it be possible to disentangle the training and the scoring in the proposed metric? What if my hyperparameters for doing the single epoch are totally wrong?\n\n\nIn the general idea of the GAN, while I like it, there is little about how the GAN is actually trained. I guess this GAN is trained using some sort of real data and therefore, the comparison is not totally fair. How many images were used to train this GAN? What would happen if those images are used directly in the distillation framework? \n\nHow many images are generated in section 4? Is the influence of pfake related to the dataset? If I have to train using another dataset, how do i set that parameter? "}, "signatures": ["ICLR.cc/2020/Conference/Paper1406/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1406/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["ruishan@stanford.edu", "lmackey@stanford.edu", "fusi@microsoft.com"], "title": "Teacher-Student Compression with Generative Adversarial Networks", "authors": ["Ruishan Liu", "Nicolo Fusi", "Lester Mackey"], "pdf": "/pdf/fd0e3200bca8c724c46a57aacde218a5f93d226f.pdf", "abstract": "More accurate machine learning models often demand more computation and memory at test time, making them difficult to deploy on CPU- or memory-constrained devices. Teacher-student compression (TSC), also known as distillation, alleviates this burden by training a less expensive student model to mimic the expensive teacher model while maintaining most of the original accuracy. However, when fresh data is unavailable for the compression task, the teacher's training data is typically reused, leading to suboptimal compression. In this work, we propose to augment the compression dataset with synthetic data from a generative adversarial network (GAN) designed to approximate the training data distribution. Our GAN-assisted TSC (GAN-TSC) significantly improves student accuracy for expensive models such as large random forests and deep neural networks on both tabular and image datasets. Building on these results, we propose a comprehensive metric\u2014the TSC Score\u2014to evaluate the quality of synthetic datasets based on their induced TSC performance. The TSC Score captures both data diversity and class affinity, and we illustrate its benefits over the popular Inception Score in the context of image classification.", "code": "https://drive.google.com/drive/folders/1IovL_rAVKVnpG2enqAgfPMilOUH-n8tu?usp=sharing", "keywords": [], "paperhash": "liu|teacherstudent_compression_with_generative_adversarial_networks", "original_pdf": "/attachment/fd0e3200bca8c724c46a57aacde218a5f93d226f.pdf", "_bibtex": "@misc{\nliu2020teacherstudent,\ntitle={Teacher-Student Compression with Generative Adversarial Networks},\nauthor={Ruishan Liu and Nicolo Fusi and Lester Mackey},\nyear={2020},\nurl={https://openreview.net/forum?id=S1xipR4FPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "S1xipR4FPB", "replyto": "S1xipR4FPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1406/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1406/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575581575657, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1406/Reviewers"], "noninvitees": [], "tcdate": 1570237737847, "tmdate": 1575581575673, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1406/-/Official_Review"}}}], "count": 5}