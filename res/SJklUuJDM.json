{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124454185, "tcdate": 1518466534682, "number": 245, "cdate": 1518466534682, "id": "SJklUuJDM", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "SJklUuJDM", "signatures": ["~Siddhartha_Brahma1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "On the Scaling of Polynomial Features for Representation Matching", "abstract": "In many neural models, new features as polynomial functions of existing ones are used to augment representations. Using the natural language inference task as an example, we investigate the use of  scaled polynomials of degree 2 and above as matching features. We find that scaling degree 2 features has the highest impact on performance, reducing classification error by  5% in the best models.", "paperhash": "brahma|on_the_scaling_of_polynomial_features_for_representation_matching", "keywords": ["natural language inference", "polynomial features", "matching features", "LSTM"], "_bibtex": "@misc{\n  brahma2018on,\n  title={On the Scaling of Polynomial Features for Representation Matching},\n  author={Siddhartha Brahma},\n  year={2018},\n  url={https://openreview.net/forum?id=SJklUuJDM}\n}", "authorids": ["sidbrahma@gmail.com"], "authors": ["Siddhartha Brahma"], "TL;DR": "The use of appropriately scaled polynomial matching features improves classification accuracy in natural language inference.", "pdf": "/pdf/afe0929a99b577a9f6806e0bb0b005c90cd2f457.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582952997, "tcdate": 1520191524506, "number": 1, "cdate": 1520191524506, "id": "S1n7uTF_f", "invitation": "ICLR.cc/2018/Workshop/-/Paper245/Official_Review", "forum": "SJklUuJDM", "replyto": "SJklUuJDM", "signatures": ["ICLR.cc/2018/Workshop/Paper245/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper245/AnonReviewer2"], "content": {"title": "Lack of novelty and insightful analysis", "rating": "3: Clear rejection", "review": "The author investigates the effectiveness of using polynomial features to match sentences for the SNLI task.\n\nThe paper is clearly written. However, the study of polynomial features is decidedly not novel. Other than this, the analysis mostly show results of hyperparameter tuning without interpretation. For example, in which situations does the proposed method outperform the baseline? My other concern, in addition to the lack of novelty and insightful analysis, is that the author performs analysis using the test set. When the author says \"validation accuracy\", does this also refer to test set performance? If so, the performance of the model is consequently not comparable to existing results such as the ESIM model shown in Figure 2b. \n\nDue to the lack of novelty and unconvincing experimental setup, I do not recommend the paper for publication.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Scaling of Polynomial Features for Representation Matching", "abstract": "In many neural models, new features as polynomial functions of existing ones are used to augment representations. Using the natural language inference task as an example, we investigate the use of  scaled polynomials of degree 2 and above as matching features. We find that scaling degree 2 features has the highest impact on performance, reducing classification error by  5% in the best models.", "paperhash": "brahma|on_the_scaling_of_polynomial_features_for_representation_matching", "keywords": ["natural language inference", "polynomial features", "matching features", "LSTM"], "_bibtex": "@misc{\n  brahma2018on,\n  title={On the Scaling of Polynomial Features for Representation Matching},\n  author={Siddhartha Brahma},\n  year={2018},\n  url={https://openreview.net/forum?id=SJklUuJDM}\n}", "authorids": ["sidbrahma@gmail.com"], "authors": ["Siddhartha Brahma"], "TL;DR": "The use of appropriately scaled polynomial matching features improves classification accuracy in natural language inference.", "pdf": "/pdf/afe0929a99b577a9f6806e0bb0b005c90cd2f457.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582952803, "id": "ICLR.cc/2018/Workshop/-/Paper245/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper245/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper245/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper245/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper245/AnonReviewer1"], "reply": {"forum": "SJklUuJDM", "replyto": "SJklUuJDM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper245/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper245/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582952803}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582785147, "tcdate": 1520631579977, "number": 2, "cdate": 1520631579977, "id": "ryVXktgFG", "invitation": "ICLR.cc/2018/Workshop/-/Paper245/Official_Review", "forum": "SJklUuJDM", "replyto": "SJklUuJDM", "signatures": ["ICLR.cc/2018/Workshop/Paper245/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper245/AnonReviewer3"], "content": {"title": "Novelty is limited and improvement needs more explanation", "rating": "4: Ok but not good enough - rejection", "review": "The paper explores scaling and higher degrees (i.e., 3 and 4) of polynomial features (i.e., u*v) for representation matching, tested on a natural language inference task. Two types of models, i.e., siamese architectures and ESIM (Chen et al. 2017), are compared in the experiments, which show that scaling helps and the higher-degree features are only useful without scaling (in Figure 2(a)), on the given baselines.\n\nCons:\n1. The baseline model ESIM is reported to achieve an accuracy of 88.0% in (Chen et al. 2017), but in this paper, the performance of ESIM is reported to be 86.0%, which needs clarification. \n2. The scaling method is pretty heuristic. The intuition is to relieve difference of variances, i.e., \\sigma^2 and \\sigma^4. Possible alternatives include using sqrt (u * v) not  \\eta (u * v). The authors may consider having more discussion on this.\n\nPros: \nWith the given baselines, a relatively simple scaling method on features is shown to help representation matching. Polynomial features with more degree helps in some special cases.\n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Scaling of Polynomial Features for Representation Matching", "abstract": "In many neural models, new features as polynomial functions of existing ones are used to augment representations. Using the natural language inference task as an example, we investigate the use of  scaled polynomials of degree 2 and above as matching features. We find that scaling degree 2 features has the highest impact on performance, reducing classification error by  5% in the best models.", "paperhash": "brahma|on_the_scaling_of_polynomial_features_for_representation_matching", "keywords": ["natural language inference", "polynomial features", "matching features", "LSTM"], "_bibtex": "@misc{\n  brahma2018on,\n  title={On the Scaling of Polynomial Features for Representation Matching},\n  author={Siddhartha Brahma},\n  year={2018},\n  url={https://openreview.net/forum?id=SJklUuJDM}\n}", "authorids": ["sidbrahma@gmail.com"], "authors": ["Siddhartha Brahma"], "TL;DR": "The use of appropriately scaled polynomial matching features improves classification accuracy in natural language inference.", "pdf": "/pdf/afe0929a99b577a9f6806e0bb0b005c90cd2f457.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582952803, "id": "ICLR.cc/2018/Workshop/-/Paper245/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper245/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper245/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper245/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper245/AnonReviewer1"], "reply": {"forum": "SJklUuJDM", "replyto": "SJklUuJDM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper245/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper245/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582952803}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582710521, "tcdate": 1520688954127, "number": 3, "cdate": 1520688954127, "id": "SJGr1vbFf", "invitation": "ICLR.cc/2018/Workshop/-/Paper245/Official_Review", "forum": "SJklUuJDM", "replyto": "SJklUuJDM", "signatures": ["ICLR.cc/2018/Workshop/Paper245/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper245/AnonReviewer1"], "content": {"title": "Interesting matching features with minor improvements", "rating": "6: Marginally above acceptance threshold", "review": "This paper presents an investigation on different scaling of polynomial features for semantic similarity scores. Their experimental results demonstrated that using the right scaling factor can improve natural language inference task. \nIn sum, this paper is clearly written. The author presents a minor focus contribution with some minor improvements. \nTo verify the importance of the polynomial features, I suggest to include also results without using the polynomial features (e.g. only [u, v, |u-v|]).\nFurthermore, I suggest the author to perform an error analysis to have a better understanding in which cases the system was improved and why. \n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Scaling of Polynomial Features for Representation Matching", "abstract": "In many neural models, new features as polynomial functions of existing ones are used to augment representations. Using the natural language inference task as an example, we investigate the use of  scaled polynomials of degree 2 and above as matching features. We find that scaling degree 2 features has the highest impact on performance, reducing classification error by  5% in the best models.", "paperhash": "brahma|on_the_scaling_of_polynomial_features_for_representation_matching", "keywords": ["natural language inference", "polynomial features", "matching features", "LSTM"], "_bibtex": "@misc{\n  brahma2018on,\n  title={On the Scaling of Polynomial Features for Representation Matching},\n  author={Siddhartha Brahma},\n  year={2018},\n  url={https://openreview.net/forum?id=SJklUuJDM}\n}", "authorids": ["sidbrahma@gmail.com"], "authors": ["Siddhartha Brahma"], "TL;DR": "The use of appropriately scaled polynomial matching features improves classification accuracy in natural language inference.", "pdf": "/pdf/afe0929a99b577a9f6806e0bb0b005c90cd2f457.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582952803, "id": "ICLR.cc/2018/Workshop/-/Paper245/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper245/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper245/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper245/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper245/AnonReviewer1"], "reply": {"forum": "SJklUuJDM", "replyto": "SJklUuJDM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper245/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper245/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582952803}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573598911, "tcdate": 1521573598911, "number": 239, "cdate": 1521573598520, "id": "Syvky1J5z", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "SJklUuJDM", "replyto": "SJklUuJDM", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Scaling of Polynomial Features for Representation Matching", "abstract": "In many neural models, new features as polynomial functions of existing ones are used to augment representations. Using the natural language inference task as an example, we investigate the use of  scaled polynomials of degree 2 and above as matching features. We find that scaling degree 2 features has the highest impact on performance, reducing classification error by  5% in the best models.", "paperhash": "brahma|on_the_scaling_of_polynomial_features_for_representation_matching", "keywords": ["natural language inference", "polynomial features", "matching features", "LSTM"], "_bibtex": "@misc{\n  brahma2018on,\n  title={On the Scaling of Polynomial Features for Representation Matching},\n  author={Siddhartha Brahma},\n  year={2018},\n  url={https://openreview.net/forum?id=SJklUuJDM}\n}", "authorids": ["sidbrahma@gmail.com"], "authors": ["Siddhartha Brahma"], "TL;DR": "The use of appropriately scaled polynomial matching features improves classification accuracy in natural language inference.", "pdf": "/pdf/afe0929a99b577a9f6806e0bb0b005c90cd2f457.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}