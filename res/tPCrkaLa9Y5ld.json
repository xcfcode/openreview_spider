{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1392782940000, "tcdate": 1392782940000, "number": 1, "id": "9HKVWnz-B_9kL", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "tPCrkaLa9Y5ld", "replyto": "tsoQWNXLQBtRy", "signatures": ["Judy Hoffman"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Thank you for your comments and suggestions. \r\n\r\nFeature Selection:\r\nWe agree that there is great potential in using lower layers in adaptation. However, the trend seems to be that directly extracting representations from lower layers, decreases performance as you go lower. We have recently experimented with using the pooled output of the fifth layer and have found uniformly worse performance than the corresponding DeCAF6 results. Additionally, the feature dimensionality increases dramatically once we dip down into the convolutional layers, making it difficult to apply adaptation techniques with those representations. In the future we plan to mitigate this problem by investigating adaptation techniques for high dimensional and spatially structured features, but we consider that beyond the scope of this work.\r\n\r\nWe agree with the reviewer that the unsupervised methods we present could be used simply to learn a metric and then supervised data could be used to train a stronger classifier. We feel it is important to demonstrate achievable unsupervised transductive results with this setup. Our experiments using GFK as a supervised method performed better than the unsupervised GFK method, but worse than most of the other adaptation methods that were specifically developed for the supervised setting. To avoid confusion about the GFK method we omitted the supervised results in our paper."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "One-Shot Adaptation of Supervised Deep Convolutional Models", "decision": "submitted, no decision", "abstract": "Dataset bias remains a significant barrier towards solving real world computer vision tasks. Though deep convolutional networks have proven to be a competitive approach for image classification, a question remains: have these models have solved the dataset bias problem? In general, training or fine-tuning a state-of-the-art deep model on a new domain requires a significant amount of data, which for many applications is simply not available. Transfer of models directly to new domains without adaptation has historically led to poor recognition performance. In this paper, we pose the following question: is a single image dataset, much larger than previously explored for adaptation, comprehensive enough to learn general deep models that may be effectively applied to new image domains? In other words, are deep CNNs trained on large amounts of labeled data as susceptible to dataset bias as previous methods have been shown to be? We show that a generic supervised deep CNN model trained on a large dataset reduces, but does not remove, dataset bias. Furthermore, we propose several methods for adaptation with deep models that are able to operate with little (one example per category) or no labeled domain specific data. Our experiments show that adaptation of deep models on benchmark visual domain adaptation datasets can provide a significant performance boost.", "pdf": "https://arxiv.org/abs/1312.6204", "paperhash": "darrell|oneshot_adaptation_of_supervised_deep_convolutional_models", "keywords": [], "conflicts": [], "authors": ["Trevor Darrell", "Eric Tzeng", "Yangqing Jia", "Judy Hoffman", "Kate Saenko", "Jeff Donahue"], "authorids": ["trevordarrell@gmail.com", "etzeng@eecs.berkeley.edu", "jiayq84@gmail.com", "jhoffman@eecs.berkeley.edu", "saenko@cs.uml.edu", "jdonahue@eecs.berkeley.edu"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392782940000, "tcdate": 1392782940000, "number": 1, "id": "fQYvfJZIv7Qy1", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "tPCrkaLa9Y5ld", "replyto": "m5C13ZcMDI3uB", "signatures": ["Judy Hoffman"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Thank you for your comments and concerns. Please see our comment below which addresses the contributions of our paper."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "One-Shot Adaptation of Supervised Deep Convolutional Models", "decision": "submitted, no decision", "abstract": "Dataset bias remains a significant barrier towards solving real world computer vision tasks. Though deep convolutional networks have proven to be a competitive approach for image classification, a question remains: have these models have solved the dataset bias problem? In general, training or fine-tuning a state-of-the-art deep model on a new domain requires a significant amount of data, which for many applications is simply not available. Transfer of models directly to new domains without adaptation has historically led to poor recognition performance. In this paper, we pose the following question: is a single image dataset, much larger than previously explored for adaptation, comprehensive enough to learn general deep models that may be effectively applied to new image domains? In other words, are deep CNNs trained on large amounts of labeled data as susceptible to dataset bias as previous methods have been shown to be? We show that a generic supervised deep CNN model trained on a large dataset reduces, but does not remove, dataset bias. Furthermore, we propose several methods for adaptation with deep models that are able to operate with little (one example per category) or no labeled domain specific data. Our experiments show that adaptation of deep models on benchmark visual domain adaptation datasets can provide a significant performance boost.", "pdf": "https://arxiv.org/abs/1312.6204", "paperhash": "darrell|oneshot_adaptation_of_supervised_deep_convolutional_models", "keywords": [], "conflicts": [], "authors": ["Trevor Darrell", "Eric Tzeng", "Yangqing Jia", "Judy Hoffman", "Kate Saenko", "Jeff Donahue"], "authorids": ["trevordarrell@gmail.com", "etzeng@eecs.berkeley.edu", "jiayq84@gmail.com", "jhoffman@eecs.berkeley.edu", "saenko@cs.uml.edu", "jdonahue@eecs.berkeley.edu"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392782880000, "tcdate": 1392782880000, "number": 1, "id": "6dHgn74-FPnyG", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "tPCrkaLa9Y5ld", "replyto": "1g5c1HoHMpg8s", "signatures": ["Judy Hoffman"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Thank you for your detailed and helpful comments. We offer clarifications below and have also made the relevant edits to our paper which should be available on arXiv within a day.\r\n\r\nHyper-parameters:\r\nTuning hyper-parameters such as the C in the svm or Daume methods is very tricky when you have so little labeled target data.  In particular, for the C-SVM, we did not have any unbiased way to tune the parameter and so left it set as C=1.  Since all the methods we report use an SVM classifier that requires setting this C hyperparameter we feel that the relative comparisons between methods is sound even if the absolute numbers could be improved with a new setting for C. For linear interpolation we intended the numbers presented to indicate an optimal performance potential for the approach. We recognize and appreciate that in practice a user would have no way of knowing the optimal parameter choice. Therefore, we provided Figure 1a to provide a deeper understanding of this hyperparameter. Namely, 1) combining the two classifiers does no worse than the minimum of the two approaches and 2) setting the alpha parameter to favor the stronger classifier for the test setting produces the best performance. To avoid confusion we will change the numbers presented in the Tables to represent the average accuracy summed over the alpha parameter.   [clarified in section 4.2]\r\n\r\nComputation Time Comparison:\r\nWe agree that SVM training time is negligible compared to CNN training time. However, we are interested in comparing the computation time needed for each adaptation method. CNN training is not part of the computation time of the algorithm we are comparing as we treat it as a pretrained feature representation. \r\n\r\nTest set size:\r\nWe have clarified this in a new version of the paper. The webcam domain has between 15-30 examples per category. For each random train/test split we choose one example for training and 10 other examples for testing (so there is a balanced test set across categories). Therefore, each test split has 160 examples and this procedure is repeated 20 times. [clarified in Section 4.2]\r\n\r\nFeature Selection:\r\nWe focused our study of feature selection on the top 3 layers of the network. The lower levels offer worse overall performance and have much higher feature dimensions. In our experiments we observe that adaptation algorithms are beneficial at all of the top 3 layers, with layers 7 and 8 offering the best overall performance. Our intuition is that to achieve the best performance, one should use the highest (most abstract) layer, which is still able to capture the domain specific variations. When using ImageNet the highest layer (layer 8) has this capacity within it\u2019s 1000 dimensional vector because the entire network was explicitly trained on ImageNet data. We find that for the Amazon domain, layers 7 and 8 perform comparably (with 7 a bit higher). Since layer 8 is 1000way classifier activations it is likely starting to overfit to the ImageNet data and so layer 7 may need to be chosen when transferring from a non-ImageNet source domain. However, we will need to perform experiments with more source domains before this hypothesis can be proven. \r\n\r\nMinor remarks: \r\nWe have fixed the typos mentioned as well as clarifying that the unsupervised domain adaptation methods operate in a transductive setting and so use the test data for subspace learning. We also modified the first sentence of Section 3 to more precisely state the goals of the paper. The framework we introduce is the idea of adding a general adaptation layer that takes as input the activations from of the existing layers from both the source and target domains and outputs a classifier scores as activations. We show that this is a general framework by implementing the approach with a wide variety of adaptation algorithms."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "One-Shot Adaptation of Supervised Deep Convolutional Models", "decision": "submitted, no decision", "abstract": "Dataset bias remains a significant barrier towards solving real world computer vision tasks. Though deep convolutional networks have proven to be a competitive approach for image classification, a question remains: have these models have solved the dataset bias problem? In general, training or fine-tuning a state-of-the-art deep model on a new domain requires a significant amount of data, which for many applications is simply not available. Transfer of models directly to new domains without adaptation has historically led to poor recognition performance. In this paper, we pose the following question: is a single image dataset, much larger than previously explored for adaptation, comprehensive enough to learn general deep models that may be effectively applied to new image domains? In other words, are deep CNNs trained on large amounts of labeled data as susceptible to dataset bias as previous methods have been shown to be? We show that a generic supervised deep CNN model trained on a large dataset reduces, but does not remove, dataset bias. Furthermore, we propose several methods for adaptation with deep models that are able to operate with little (one example per category) or no labeled domain specific data. Our experiments show that adaptation of deep models on benchmark visual domain adaptation datasets can provide a significant performance boost.", "pdf": "https://arxiv.org/abs/1312.6204", "paperhash": "darrell|oneshot_adaptation_of_supervised_deep_convolutional_models", "keywords": [], "conflicts": [], "authors": ["Trevor Darrell", "Eric Tzeng", "Yangqing Jia", "Judy Hoffman", "Kate Saenko", "Jeff Donahue"], "authorids": ["trevordarrell@gmail.com", "etzeng@eecs.berkeley.edu", "jiayq84@gmail.com", "jhoffman@eecs.berkeley.edu", "saenko@cs.uml.edu", "jdonahue@eecs.berkeley.edu"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392782820000, "tcdate": 1392782820000, "number": 8, "id": "xk0agabF96kdB", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "tPCrkaLa9Y5ld", "replyto": "tPCrkaLa9Y5ld", "signatures": ["Judy Hoffman"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "Thank you to all the reviewers for your comments and suggestions. We would like to reiterate the main contributions of our paper and will respond to specific reviewer comments individually.\r\n\r\nOur work contributes to our understanding of learned representations in the following ways: \r\n\r\n1) Our work shows that deep representations learned on large source datasets lessen, but by no means remove the problem of dataset bias; this is important as some people might and have claimed otherwise. Demonstrating performance of deep representations under domain shift is a relevant and novel contribution that paves the way for future work that will be of broad interest to the community. Additionally, we show how the novel combination of existing DA and Deep techniques allows an interesting operating point for adaptation to a new domain (or task) when too few data are available to fine tune in the conventional deep way. We show various adaptation methods are able to improve with as few as one (or none) target labels.\r\n\r\n2) Our work shows novel experimental results on a standard domain adaptation dataset which has been extensively used in the literature. In particular, we choose to focus on the hardest shift -- amazon->webcam and augment the standard dataset by additionally considering ImageNet as a source domain. We also have practical motivations for considering webcam as a target domain since it is the most similar to a robotic vision domain.\r\n\r\n 3) Our work shows that some layers of the representation are better for domain adaptation than others, although we do not yet propose an automatic way of selecting the 'optimal' layer."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "One-Shot Adaptation of Supervised Deep Convolutional Models", "decision": "submitted, no decision", "abstract": "Dataset bias remains a significant barrier towards solving real world computer vision tasks. Though deep convolutional networks have proven to be a competitive approach for image classification, a question remains: have these models have solved the dataset bias problem? In general, training or fine-tuning a state-of-the-art deep model on a new domain requires a significant amount of data, which for many applications is simply not available. Transfer of models directly to new domains without adaptation has historically led to poor recognition performance. In this paper, we pose the following question: is a single image dataset, much larger than previously explored for adaptation, comprehensive enough to learn general deep models that may be effectively applied to new image domains? In other words, are deep CNNs trained on large amounts of labeled data as susceptible to dataset bias as previous methods have been shown to be? We show that a generic supervised deep CNN model trained on a large dataset reduces, but does not remove, dataset bias. Furthermore, we propose several methods for adaptation with deep models that are able to operate with little (one example per category) or no labeled domain specific data. Our experiments show that adaptation of deep models on benchmark visual domain adaptation datasets can provide a significant performance boost.", "pdf": "https://arxiv.org/abs/1312.6204", "paperhash": "darrell|oneshot_adaptation_of_supervised_deep_convolutional_models", "keywords": [], "conflicts": [], "authors": ["Trevor Darrell", "Eric Tzeng", "Yangqing Jia", "Judy Hoffman", "Kate Saenko", "Jeff Donahue"], "authorids": ["trevordarrell@gmail.com", "etzeng@eecs.berkeley.edu", "jiayq84@gmail.com", "jhoffman@eecs.berkeley.edu", "saenko@cs.uml.edu", "jdonahue@eecs.berkeley.edu"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391856960000, "tcdate": 1391856960000, "number": 7, "id": "ttR_C7vVGBtuo", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "tPCrkaLa9Y5ld", "replyto": "tPCrkaLa9Y5ld", "signatures": ["anonymous reviewer 6be7"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of One-Shot Adaptation of Supervised Deep Convolutional Models", "review": "This paper studies dataset bias problem. It investigates whether using large source datasets can eliminate dataset bias. The paper shows that such datasets reduce but still do not remove completely dataset bias.  It also shows that deep learning features are useful in helping domain adaptation. \r\n\r\nThis is a largely empirical study of the important issues.  The observation made the paper is important and thought-inspiring and worth reporting.\r\n\r\nIt might be interesting to report all layers (instead of just DeCAF6 and DeCAF7)'s performance on adaptation --- is it always the case that high-level layers are better at adaptation? \r\n\r\nGFK was used in the paper as an unsupervised domain adaptation method. However, it can be used easily as a semi-supervised or supervised method. For example, once GFK is learnt on unlabeled data, one can learn a classifier by revealing the labels of the target data. The benefit is a better metric is used to measure distances."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "One-Shot Adaptation of Supervised Deep Convolutional Models", "decision": "submitted, no decision", "abstract": "Dataset bias remains a significant barrier towards solving real world computer vision tasks. Though deep convolutional networks have proven to be a competitive approach for image classification, a question remains: have these models have solved the dataset bias problem? In general, training or fine-tuning a state-of-the-art deep model on a new domain requires a significant amount of data, which for many applications is simply not available. Transfer of models directly to new domains without adaptation has historically led to poor recognition performance. In this paper, we pose the following question: is a single image dataset, much larger than previously explored for adaptation, comprehensive enough to learn general deep models that may be effectively applied to new image domains? In other words, are deep CNNs trained on large amounts of labeled data as susceptible to dataset bias as previous methods have been shown to be? We show that a generic supervised deep CNN model trained on a large dataset reduces, but does not remove, dataset bias. Furthermore, we propose several methods for adaptation with deep models that are able to operate with little (one example per category) or no labeled domain specific data. Our experiments show that adaptation of deep models on benchmark visual domain adaptation datasets can provide a significant performance boost.", "pdf": "https://arxiv.org/abs/1312.6204", "paperhash": "darrell|oneshot_adaptation_of_supervised_deep_convolutional_models", "keywords": [], "conflicts": [], "authors": ["Trevor Darrell", "Eric Tzeng", "Yangqing Jia", "Judy Hoffman", "Kate Saenko", "Jeff Donahue"], "authorids": ["trevordarrell@gmail.com", "etzeng@eecs.berkeley.edu", "jiayq84@gmail.com", "jhoffman@eecs.berkeley.edu", "saenko@cs.uml.edu", "jdonahue@eecs.berkeley.edu"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391755740000, "tcdate": 1391755740000, "number": 5, "id": "2-nekWqWeIsc0", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "tPCrkaLa9Y5ld", "replyto": "tPCrkaLa9Y5ld", "signatures": ["anonymous reviewer ab7e"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of One-Shot Adaptation of Supervised Deep Convolutional Models", "review": "The submission tackles the problem of one-shot classifier adaptation between biased datasets that contain overlapping object categories. The authors design a number of experiments to evaluate known transfer/adaptation approaches on deep convnet features taken from the last 3 layers of the Krizhevsky network. The basic approach is that the convnet is trained on LSVRC 1000-category data, then 16 categories are chosen that overlap with categories in 2 other datasets (amazon and webcam). Feature representations are taken from one of the layers of the network using amazon or imagenet data and webcam data, and adaptive classifiers are tested using the amazon or imagenet source and a single webcam image as target.\r\n\r\nThere is little that is innovative in the submission, since it uses only published or trivial approaches for the convnet and the domain adaptation and the empirical results are not broad enough. Moreover, the work does not contribute to our understanding of learned representations, so I see little relevance for ICLR. \r\n\r\nThe paper is well-written and offers a number of intuitive explanations for the results, although some of the conclusions don't seem well-justified given the limited evidence from only one target domain. The authors identify an interesting next step of doing learning in the convnet layers using feedback through the adaptation classifier, which could be worthwhile."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "One-Shot Adaptation of Supervised Deep Convolutional Models", "decision": "submitted, no decision", "abstract": "Dataset bias remains a significant barrier towards solving real world computer vision tasks. Though deep convolutional networks have proven to be a competitive approach for image classification, a question remains: have these models have solved the dataset bias problem? In general, training or fine-tuning a state-of-the-art deep model on a new domain requires a significant amount of data, which for many applications is simply not available. Transfer of models directly to new domains without adaptation has historically led to poor recognition performance. In this paper, we pose the following question: is a single image dataset, much larger than previously explored for adaptation, comprehensive enough to learn general deep models that may be effectively applied to new image domains? In other words, are deep CNNs trained on large amounts of labeled data as susceptible to dataset bias as previous methods have been shown to be? We show that a generic supervised deep CNN model trained on a large dataset reduces, but does not remove, dataset bias. Furthermore, we propose several methods for adaptation with deep models that are able to operate with little (one example per category) or no labeled domain specific data. Our experiments show that adaptation of deep models on benchmark visual domain adaptation datasets can provide a significant performance boost.", "pdf": "https://arxiv.org/abs/1312.6204", "paperhash": "darrell|oneshot_adaptation_of_supervised_deep_convolutional_models", "keywords": [], "conflicts": [], "authors": ["Trevor Darrell", "Eric Tzeng", "Yangqing Jia", "Judy Hoffman", "Kate Saenko", "Jeff Donahue"], "authorids": ["trevordarrell@gmail.com", "etzeng@eecs.berkeley.edu", "jiayq84@gmail.com", "jhoffman@eecs.berkeley.edu", "saenko@cs.uml.edu", "jdonahue@eecs.berkeley.edu"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391755740000, "tcdate": 1391755740000, "number": 4, "id": "ShZ5-f7a5Gplu", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "tPCrkaLa9Y5ld", "replyto": "tPCrkaLa9Y5ld", "signatures": ["anonymous reviewer ab7e"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of One-Shot Adaptation of Supervised Deep Convolutional Models", "review": "The submission tackles the problem of one-shot classifier adaptation between biased datasets that contain overlapping object categories. The authors design a number of experiments to evaluate known transfer/adaptation approaches on deep convnet features taken from the last 3 layers of the Krizhevsky network. The basic approach is that the convnet is trained on LSVRC 1000-category data, then 16 categories are chosen that overlap with categories in 2 other datasets (amazon and webcam). Feature representations are taken from one of the layers of the network using amazon or imagenet data and webcam data, and adaptive classifiers are tested using the amazon or imagenet source and a single webcam image as target.\r\n\r\nThere is little that is innovative in the submission, since it uses only published or trivial approaches for the convnet and the domain adaptation and the empirical results are not broad enough. Moreover, the work does not contribute to our understanding of learned representations, so I see little relevance for ICLR. \r\n\r\nThe paper is well-written and offers a number of intuitive explanations for the results, although some of the conclusions don't seem well-justified given the limited evidence from only one target domain. The authors identify an interesting next step of doing learning in the convnet layers using feedback through the adaptation classifier, which could be worthwhile."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "One-Shot Adaptation of Supervised Deep Convolutional Models", "decision": "submitted, no decision", "abstract": "Dataset bias remains a significant barrier towards solving real world computer vision tasks. Though deep convolutional networks have proven to be a competitive approach for image classification, a question remains: have these models have solved the dataset bias problem? In general, training or fine-tuning a state-of-the-art deep model on a new domain requires a significant amount of data, which for many applications is simply not available. Transfer of models directly to new domains without adaptation has historically led to poor recognition performance. In this paper, we pose the following question: is a single image dataset, much larger than previously explored for adaptation, comprehensive enough to learn general deep models that may be effectively applied to new image domains? In other words, are deep CNNs trained on large amounts of labeled data as susceptible to dataset bias as previous methods have been shown to be? We show that a generic supervised deep CNN model trained on a large dataset reduces, but does not remove, dataset bias. Furthermore, we propose several methods for adaptation with deep models that are able to operate with little (one example per category) or no labeled domain specific data. Our experiments show that adaptation of deep models on benchmark visual domain adaptation datasets can provide a significant performance boost.", "pdf": "https://arxiv.org/abs/1312.6204", "paperhash": "darrell|oneshot_adaptation_of_supervised_deep_convolutional_models", "keywords": [], "conflicts": [], "authors": ["Trevor Darrell", "Eric Tzeng", "Yangqing Jia", "Judy Hoffman", "Kate Saenko", "Jeff Donahue"], "authorids": ["trevordarrell@gmail.com", "etzeng@eecs.berkeley.edu", "jiayq84@gmail.com", "jhoffman@eecs.berkeley.edu", "saenko@cs.uml.edu", "jdonahue@eecs.berkeley.edu"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391755740000, "tcdate": 1391755740000, "number": 3, "id": "7E9uK23zu67Xx", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "tPCrkaLa9Y5ld", "replyto": "tPCrkaLa9Y5ld", "signatures": ["anonymous reviewer ab7e"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of One-Shot Adaptation of Supervised Deep Convolutional Models", "review": "The submission tackles the problem of one-shot classifier adaptation between biased datasets that contain overlapping object categories. The authors design a number of experiments to evaluate known transfer/adaptation approaches on deep convnet features taken from the last 3 layers of the Krizhevsky network. The basic approach is that the convnet is trained on LSVRC 1000-category data, then 16 categories are chosen that overlap with categories in 2 other datasets (amazon and webcam). Feature representations are taken from one of the layers of the network using amazon or imagenet data and webcam data, and adaptive classifiers are tested using the amazon or imagenet source and a single webcam image as target.\r\n\r\nThere is little that is innovative in the submission, since it uses only published or trivial approaches for the convnet and the domain adaptation and the empirical results are not broad enough. Moreover, the work does not contribute to our understanding of learned representations, so I see little relevance for ICLR. \r\n\r\nThe paper is well-written and offers a number of intuitive explanations for the results, although some of the conclusions don't seem well-justified given the limited evidence from only one target domain. The authors identify an interesting next step of doing learning in the convnet layers using feedback through the adaptation classifier, which could be worthwhile."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "One-Shot Adaptation of Supervised Deep Convolutional Models", "decision": "submitted, no decision", "abstract": "Dataset bias remains a significant barrier towards solving real world computer vision tasks. Though deep convolutional networks have proven to be a competitive approach for image classification, a question remains: have these models have solved the dataset bias problem? In general, training or fine-tuning a state-of-the-art deep model on a new domain requires a significant amount of data, which for many applications is simply not available. Transfer of models directly to new domains without adaptation has historically led to poor recognition performance. In this paper, we pose the following question: is a single image dataset, much larger than previously explored for adaptation, comprehensive enough to learn general deep models that may be effectively applied to new image domains? In other words, are deep CNNs trained on large amounts of labeled data as susceptible to dataset bias as previous methods have been shown to be? We show that a generic supervised deep CNN model trained on a large dataset reduces, but does not remove, dataset bias. Furthermore, we propose several methods for adaptation with deep models that are able to operate with little (one example per category) or no labeled domain specific data. Our experiments show that adaptation of deep models on benchmark visual domain adaptation datasets can provide a significant performance boost.", "pdf": "https://arxiv.org/abs/1312.6204", "paperhash": "darrell|oneshot_adaptation_of_supervised_deep_convolutional_models", "keywords": [], "conflicts": [], "authors": ["Trevor Darrell", "Eric Tzeng", "Yangqing Jia", "Judy Hoffman", "Kate Saenko", "Jeff Donahue"], "authorids": ["trevordarrell@gmail.com", "etzeng@eecs.berkeley.edu", "jiayq84@gmail.com", "jhoffman@eecs.berkeley.edu", "saenko@cs.uml.edu", "jdonahue@eecs.berkeley.edu"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391755740000, "tcdate": 1391755740000, "number": 2, "id": "m5C13ZcMDI3uB", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "tPCrkaLa9Y5ld", "replyto": "tPCrkaLa9Y5ld", "signatures": ["anonymous reviewer ab7e"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of One-Shot Adaptation of Supervised Deep Convolutional Models", "review": "The submission tackles the problem of one-shot classifier adaptation between biased datasets that contain overlapping object categories. The authors design a number of experiments to evaluate known transfer/adaptation approaches on deep convnet features taken from the last 3 layers of the Krizhevsky network. The basic approach is that the convnet is trained on LSVRC 1000-category data, then 16 categories are chosen that overlap with categories in 2 other datasets (amazon and webcam). Feature representations are taken from one of the layers of the network using amazon or imagenet data and webcam data, and adaptive classifiers are tested using the amazon or imagenet source and a single webcam image as target.\r\n\r\nThere is little that is innovative in the submission, since it uses only published or trivial approaches for the convnet and the domain adaptation and the empirical results are not broad enough. Moreover, the work does not contribute to our understanding of learned representations, so I see little relevance for ICLR. \r\n\r\nThe paper is well-written and offers a number of intuitive explanations for the results, although some of the conclusions don't seem well-justified given the limited evidence from only one target domain. The authors identify an interesting next step of doing learning in the convnet layers using feedback through the adaptation classifier, which could be worthwhile."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "One-Shot Adaptation of Supervised Deep Convolutional Models", "decision": "submitted, no decision", "abstract": "Dataset bias remains a significant barrier towards solving real world computer vision tasks. Though deep convolutional networks have proven to be a competitive approach for image classification, a question remains: have these models have solved the dataset bias problem? In general, training or fine-tuning a state-of-the-art deep model on a new domain requires a significant amount of data, which for many applications is simply not available. Transfer of models directly to new domains without adaptation has historically led to poor recognition performance. In this paper, we pose the following question: is a single image dataset, much larger than previously explored for adaptation, comprehensive enough to learn general deep models that may be effectively applied to new image domains? In other words, are deep CNNs trained on large amounts of labeled data as susceptible to dataset bias as previous methods have been shown to be? We show that a generic supervised deep CNN model trained on a large dataset reduces, but does not remove, dataset bias. Furthermore, we propose several methods for adaptation with deep models that are able to operate with little (one example per category) or no labeled domain specific data. Our experiments show that adaptation of deep models on benchmark visual domain adaptation datasets can provide a significant performance boost.", "pdf": "https://arxiv.org/abs/1312.6204", "paperhash": "darrell|oneshot_adaptation_of_supervised_deep_convolutional_models", "keywords": [], "conflicts": [], "authors": ["Trevor Darrell", "Eric Tzeng", "Yangqing Jia", "Judy Hoffman", "Kate Saenko", "Jeff Donahue"], "authorids": ["trevordarrell@gmail.com", "etzeng@eecs.berkeley.edu", "jiayq84@gmail.com", "jhoffman@eecs.berkeley.edu", "saenko@cs.uml.edu", "jdonahue@eecs.berkeley.edu"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391755740000, "tcdate": 1391755740000, "number": 6, "id": "tsoQWNXLQBtRy", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "tPCrkaLa9Y5ld", "replyto": "tPCrkaLa9Y5ld", "signatures": ["anonymous reviewer ab7e"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of One-Shot Adaptation of Supervised Deep Convolutional Models", "review": "The submission tackles the problem of one-shot classifier adaptation between biased datasets that contain overlapping object categories. The authors design a number of experiments to evaluate known transfer/adaptation approaches on deep convnet features taken from the last 3 layers of the Krizhevsky network. The basic approach is that the convnet is trained on LSVRC 1000-category data, then 16 categories are chosen that overlap with categories in 2 other datasets (amazon and webcam). Feature representations are taken from one of the layers of the network using amazon or imagenet data and webcam data, and adaptive classifiers are tested using the amazon or imagenet source and a single webcam image as target.\r\n\r\nThere is little that is innovative in the submission, since it uses only published or trivial approaches for the convnet and the domain adaptation and the empirical results are not broad enough. Moreover, the work does not contribute to our understanding of learned representations, so I see little relevance for ICLR. \r\n\r\nThe paper is well-written and offers a number of intuitive explanations for the results, although some of the conclusions don't seem well-justified given the limited evidence from only one target domain. The authors identify an interesting next step of doing learning in the convnet layers using feedback through the adaptation classifier, which could be worthwhile."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "One-Shot Adaptation of Supervised Deep Convolutional Models", "decision": "submitted, no decision", "abstract": "Dataset bias remains a significant barrier towards solving real world computer vision tasks. Though deep convolutional networks have proven to be a competitive approach for image classification, a question remains: have these models have solved the dataset bias problem? In general, training or fine-tuning a state-of-the-art deep model on a new domain requires a significant amount of data, which for many applications is simply not available. Transfer of models directly to new domains without adaptation has historically led to poor recognition performance. In this paper, we pose the following question: is a single image dataset, much larger than previously explored for adaptation, comprehensive enough to learn general deep models that may be effectively applied to new image domains? In other words, are deep CNNs trained on large amounts of labeled data as susceptible to dataset bias as previous methods have been shown to be? We show that a generic supervised deep CNN model trained on a large dataset reduces, but does not remove, dataset bias. Furthermore, we propose several methods for adaptation with deep models that are able to operate with little (one example per category) or no labeled domain specific data. Our experiments show that adaptation of deep models on benchmark visual domain adaptation datasets can provide a significant performance boost.", "pdf": "https://arxiv.org/abs/1312.6204", "paperhash": "darrell|oneshot_adaptation_of_supervised_deep_convolutional_models", "keywords": [], "conflicts": [], "authors": ["Trevor Darrell", "Eric Tzeng", "Yangqing Jia", "Judy Hoffman", "Kate Saenko", "Jeff Donahue"], "authorids": ["trevordarrell@gmail.com", "etzeng@eecs.berkeley.edu", "jiayq84@gmail.com", "jhoffman@eecs.berkeley.edu", "saenko@cs.uml.edu", "jdonahue@eecs.berkeley.edu"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391624760000, "tcdate": 1391624760000, "number": 1, "id": "1g5c1HoHMpg8s", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "tPCrkaLa9Y5ld", "replyto": "tPCrkaLa9Y5ld", "signatures": ["anonymous reviewer 93c2"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of One-Shot Adaptation of Supervised Deep Convolutional Models", "review": "This paper presents an extensive empirical evaluation of various methods and frameworks for domain adaptation, that is, when training (i.e. source) and test (i.e. target) data are expected to be sampled from different - but related - distributions. The study is carried out for the image labeling problem, with the CNN of Krizhevsky et al. as base classifier for the source domain. The main goal is to explore various strategies for applying this network trained for 1,000 categories on ImageNet to other images of the same categories but taken in different conditions (basically taken from a webcam here). The main ideas is to use features from the CNN architecture (different layers are considered) and feed them to various domain adaptation techniques, supervised or not. For the supervised case, the setting is drastic and allows only a single labeled example per category from the target domain.\r\n\r\n----\r\n\r\nThe paper tackles an important issue and is sound; the numerous experiments appear to be reliable. It is clearly written despite some typos. But it also raises some questions.\r\n\r\nIn the beginning of Section 3, it is written 'We propose a generic framework to selectively adapt the parameters of a deep network', which is rather ambitious. The experimental study is extensive and covers many methods but I'm unsure that this actually provides a generic framework for deep learning because (1) this only covers CNNs and (2) it is more the application of existing methods than the definition of a new scheme. The main conclusion of the paper, which is that transferring from ImageNet is more efficient than from Amazon, is fine but does not lead to a framework definition. \r\n\r\nA very interesting point of the paper is to provide some elements about which features from a CNN should be fed to adaptation methods (which layer basically). I think this is a key problem and I regret that the paper does not elaborate too much on this point. There is some discussion but it seems that the quality of adaption given features from a certain layer can also indicate the abstraction level of the features learned by the CNN. Perhaps, one could elaborate on this.\r\n\r\nWhen labeled data is unavailable, which is the case here for the target domain, training is complicated (and that's what's addressed in the paper with at most 1 example per category) but model selection is also tricky. For instance, setting the C for the SVMs of the Daume III method or the alpha of the linear interpolation can be complex. This crucial problem is not really tackled in the paper since hyperparameters values are either set through unjustified heuristics or left somewhat undecided. The alpha of the linear interpolation seems to be chosen while looking at the curves of Figure 1 (a), that is, by looking at the evaluation set.. Nothing is said on how the C used for the SVMs of Daume III is chosen and its value is not given. This is problematic since these are the 2 best performing methods.\r\n\r\nIt is said a couple times that adaption methods based on SVMs (such as Daume III) might suffer from long training duration because of the large number of training examples. I disagree. I suppose that the SVM is using a linear kernel (it should be stated). If this is the case, then it has been shown many times that linear SVMs can be very efficient in training time and memory usage. I suspect the SVM training time to be somewhat negligible compared to that of the CNN.\r\n\r\nThe test set is rather small, only 160 images, which are split into 20 random splits of 8 images. I wonder if averaging test results obtained on such small sets, which hence never contains all 16 categories, makes sense. I would rather like some statistical significance paired tests for instance.\r\n\r\n\r\nMinor remarks:\r\n- Section 2: typo: reported in 4 -> reported in Section 4\r\n- Section 4.2: how many unlabeled examples from the target are used for the unsupervised adaptation approaches, is it 10 per categories as in the test set or 20 as for the source domain train set?\r\n- Section 4.3: typo: make use a subspace -> make use of a subspace .\r\n- Section 4.6: the discussion on the size of the subspace is useless. It is pretty obvious that a dimension lower than the number of categories is detrimental."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "One-Shot Adaptation of Supervised Deep Convolutional Models", "decision": "submitted, no decision", "abstract": "Dataset bias remains a significant barrier towards solving real world computer vision tasks. Though deep convolutional networks have proven to be a competitive approach for image classification, a question remains: have these models have solved the dataset bias problem? In general, training or fine-tuning a state-of-the-art deep model on a new domain requires a significant amount of data, which for many applications is simply not available. Transfer of models directly to new domains without adaptation has historically led to poor recognition performance. In this paper, we pose the following question: is a single image dataset, much larger than previously explored for adaptation, comprehensive enough to learn general deep models that may be effectively applied to new image domains? In other words, are deep CNNs trained on large amounts of labeled data as susceptible to dataset bias as previous methods have been shown to be? We show that a generic supervised deep CNN model trained on a large dataset reduces, but does not remove, dataset bias. Furthermore, we propose several methods for adaptation with deep models that are able to operate with little (one example per category) or no labeled domain specific data. Our experiments show that adaptation of deep models on benchmark visual domain adaptation datasets can provide a significant performance boost.", "pdf": "https://arxiv.org/abs/1312.6204", "paperhash": "darrell|oneshot_adaptation_of_supervised_deep_convolutional_models", "keywords": [], "conflicts": [], "authors": ["Trevor Darrell", "Eric Tzeng", "Yangqing Jia", "Judy Hoffman", "Kate Saenko", "Jeff Donahue"], "authorids": ["trevordarrell@gmail.com", "etzeng@eecs.berkeley.edu", "jiayq84@gmail.com", "jhoffman@eecs.berkeley.edu", "saenko@cs.uml.edu", "jdonahue@eecs.berkeley.edu"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1387872000000, "tcdate": 1387872000000, "number": 46, "id": "tPCrkaLa9Y5ld", "invitation": "ICLR.cc/2014/conference/-/submission", "forum": "tPCrkaLa9Y5ld", "signatures": ["trevordarrell@gmail.com"], "readers": ["everyone"], "content": {"title": "One-Shot Adaptation of Supervised Deep Convolutional Models", "decision": "submitted, no decision", "abstract": "Dataset bias remains a significant barrier towards solving real world computer vision tasks. Though deep convolutional networks have proven to be a competitive approach for image classification, a question remains: have these models have solved the dataset bias problem? In general, training or fine-tuning a state-of-the-art deep model on a new domain requires a significant amount of data, which for many applications is simply not available. Transfer of models directly to new domains without adaptation has historically led to poor recognition performance. In this paper, we pose the following question: is a single image dataset, much larger than previously explored for adaptation, comprehensive enough to learn general deep models that may be effectively applied to new image domains? In other words, are deep CNNs trained on large amounts of labeled data as susceptible to dataset bias as previous methods have been shown to be? We show that a generic supervised deep CNN model trained on a large dataset reduces, but does not remove, dataset bias. Furthermore, we propose several methods for adaptation with deep models that are able to operate with little (one example per category) or no labeled domain specific data. Our experiments show that adaptation of deep models on benchmark visual domain adaptation datasets can provide a significant performance boost.", "pdf": "https://arxiv.org/abs/1312.6204", "paperhash": "darrell|oneshot_adaptation_of_supervised_deep_convolutional_models", "keywords": [], "conflicts": [], "authors": ["Trevor Darrell", "Eric Tzeng", "Yangqing Jia", "Judy Hoffman", "Kate Saenko", "Jeff Donahue"], "authorids": ["trevordarrell@gmail.com", "etzeng@eecs.berkeley.edu", "jiayq84@gmail.com", "jhoffman@eecs.berkeley.edu", "saenko@cs.uml.edu", "jdonahue@eecs.berkeley.edu"]}, "writers": [], "details": {"replyCount": 11, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496674357195, "id": "ICLR.cc/2014/conference/-/submission", "writers": ["ICLR.cc/2014"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717, "cdate": 1496674357195}}}], "count": 12}