{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124294106, "tcdate": 1518471232416, "number": 294, "cdate": 1518471232416, "id": "BkuSOYkvG", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "BkuSOYkvG", "signatures": ["~Mehdi_S._M._Sajjadi1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Tempered Adversarial Networks", "abstract": "Generative adversarial networks (GANs) have been shown to produce realistic samples from high-dimensional distributions, but training them is considered hard. A possible explanation for training instabilities is the inherent imbalance between the networks: While the discriminator is trained directly on both real and fake samples, the generator only has control over the fake samples it produces since the real data distribution is fixed by the choice of a given dataset. We propose a simple modification that gives the generator control over the real samples, leading to a tempered learning process for both generator and discriminator. The real data distribution passes through a lens before being revealed to the discriminator, balancing the training process by gradually revealing more detailed features necessary to produce high-quality results. The proposed module automatically adjusts the learning process to the current strength of the networks, yet is generic and easy to add to any GAN variant. In a number of experiments, we show that this is a promising technique to improve quality, stability and/or convergence speed across a range of different GAN architectures (DCGAN, LSGAN, WGAN-GP).", "paperhash": "sajjadi|tempered_adversarial_networks", "keywords": ["generative adversarial networks"], "_bibtex": "@misc{\n  sajjadi2018tempered,\n  title={Tempered Adversarial Networks},\n  author={Mehdi S. M. Sajjadi and Giambattista Parascandolo and Arash Mehrjou and Bernhard Sch\u00f6lkopf},\n  year={2018},\n  url={https://openreview.net/forum?id=BkuSOYkvG}\n}", "authorids": ["msajjadi@tue.mpg.de", "gparascandolo@tue.mpg.de", "amehrjou@tue.mpg.de", "bs@tuebingen.mpg.de"], "authors": ["Mehdi S. M. Sajjadi", "Giambattista Parascandolo", "Arash Mehrjou", "Bernhard Sch\u00f6lkopf"], "TL;DR": "Passing the real data distribution in a GAN through a lens stabilizes training and leads to better results in DCGAN, LSGAN and WGAN-GP.", "pdf": "/pdf/b0a59c8346a3309df9ea51a58ad6bc24bea0b3a7.pdf"}, "nonreaders": [], "details": {"replyCount": 6, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "tmdate": 1523812691944, "tcdate": 1523812691944, "number": 3, "cdate": 1523812691944, "id": "B1nItb-2G", "invitation": "ICLR.cc/2018/Workshop/-/Paper294/Official_Comment", "forum": "BkuSOYkvG", "replyto": "BkuSOYkvG", "signatures": ["ICLR.cc/2018/Workshop/Paper294/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper294/Authors"], "content": {"title": "Thank you", "comment": "We thank the authors for the helpful comments and will incorporate the suggestions into ongoing efforts to further analyze the effects of the proposed technique."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tempered Adversarial Networks", "abstract": "Generative adversarial networks (GANs) have been shown to produce realistic samples from high-dimensional distributions, but training them is considered hard. A possible explanation for training instabilities is the inherent imbalance between the networks: While the discriminator is trained directly on both real and fake samples, the generator only has control over the fake samples it produces since the real data distribution is fixed by the choice of a given dataset. We propose a simple modification that gives the generator control over the real samples, leading to a tempered learning process for both generator and discriminator. The real data distribution passes through a lens before being revealed to the discriminator, balancing the training process by gradually revealing more detailed features necessary to produce high-quality results. The proposed module automatically adjusts the learning process to the current strength of the networks, yet is generic and easy to add to any GAN variant. In a number of experiments, we show that this is a promising technique to improve quality, stability and/or convergence speed across a range of different GAN architectures (DCGAN, LSGAN, WGAN-GP).", "paperhash": "sajjadi|tempered_adversarial_networks", "keywords": ["generative adversarial networks"], "_bibtex": "@misc{\n  sajjadi2018tempered,\n  title={Tempered Adversarial Networks},\n  author={Mehdi S. M. Sajjadi and Giambattista Parascandolo and Arash Mehrjou and Bernhard Sch\u00f6lkopf},\n  year={2018},\n  url={https://openreview.net/forum?id=BkuSOYkvG}\n}", "authorids": ["msajjadi@tue.mpg.de", "gparascandolo@tue.mpg.de", "amehrjou@tue.mpg.de", "bs@tuebingen.mpg.de"], "authors": ["Mehdi S. M. Sajjadi", "Giambattista Parascandolo", "Arash Mehrjou", "Bernhard Sch\u00f6lkopf"], "TL;DR": "Passing the real data distribution in a GAN through a lens stabilizes training and leads to better results in DCGAN, LSGAN and WGAN-GP.", "pdf": "/pdf/b0a59c8346a3309df9ea51a58ad6bc24bea0b3a7.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1519222446123, "id": "ICLR.cc/2018/Workshop/-/Paper294/Official_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "BkuSOYkvG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper294/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper294/Authors|ICLR.cc/2018/Workshop/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper294/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper294/Authors|ICLR.cc/2018/Workshop/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Workshop/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Workshop/Paper294/Reviewers", "ICLR.cc/2018/Workshop/Paper294/Authors", "ICLR.cc/2018/Workshop/Program_Chairs"], "cdate": 1519222446123}}, "tauthor": "msajjadi@tue.mpg.de"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582783970, "tcdate": 1520632174057, "number": 1, "cdate": 1520632174057, "id": "r1IdbKgYG", "invitation": "ICLR.cc/2018/Workshop/-/Paper294/Official_Review", "forum": "BkuSOYkvG", "replyto": "BkuSOYkvG", "signatures": ["ICLR.cc/2018/Workshop/Paper294/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper294/AnonReviewer3"], "content": {"title": "Good workshop paper", "rating": "7: Good paper, accept", "review": "This paper proposes an interesting idea that puts an additional \"lense\" layer before the real training samples, to cope with the initial big difference in distribution between generated and real samples. The lense layer is gradually tuned towards identity over training. Quite thorough experiments show the idea is kind of working and indeed make the training stable. So I think it could be a good workshop paper. \n\nI wonder how it is compared to BEGAN (https://arxiv.org/abs/1703.10717) which also uses a hyper parameter to tune the strength between Generative and Discriminative components. \n\nNote that I am not an expert in GAN so I might miss some strongly related works. ", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tempered Adversarial Networks", "abstract": "Generative adversarial networks (GANs) have been shown to produce realistic samples from high-dimensional distributions, but training them is considered hard. A possible explanation for training instabilities is the inherent imbalance between the networks: While the discriminator is trained directly on both real and fake samples, the generator only has control over the fake samples it produces since the real data distribution is fixed by the choice of a given dataset. We propose a simple modification that gives the generator control over the real samples, leading to a tempered learning process for both generator and discriminator. The real data distribution passes through a lens before being revealed to the discriminator, balancing the training process by gradually revealing more detailed features necessary to produce high-quality results. The proposed module automatically adjusts the learning process to the current strength of the networks, yet is generic and easy to add to any GAN variant. In a number of experiments, we show that this is a promising technique to improve quality, stability and/or convergence speed across a range of different GAN architectures (DCGAN, LSGAN, WGAN-GP).", "paperhash": "sajjadi|tempered_adversarial_networks", "keywords": ["generative adversarial networks"], "_bibtex": "@misc{\n  sajjadi2018tempered,\n  title={Tempered Adversarial Networks},\n  author={Mehdi S. M. Sajjadi and Giambattista Parascandolo and Arash Mehrjou and Bernhard Sch\u00f6lkopf},\n  year={2018},\n  url={https://openreview.net/forum?id=BkuSOYkvG}\n}", "authorids": ["msajjadi@tue.mpg.de", "gparascandolo@tue.mpg.de", "amehrjou@tue.mpg.de", "bs@tuebingen.mpg.de"], "authors": ["Mehdi S. M. Sajjadi", "Giambattista Parascandolo", "Arash Mehrjou", "Bernhard Sch\u00f6lkopf"], "TL;DR": "Passing the real data distribution in a GAN through a lens stabilizes training and leads to better results in DCGAN, LSGAN and WGAN-GP.", "pdf": "/pdf/b0a59c8346a3309df9ea51a58ad6bc24bea0b3a7.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582783772, "id": "ICLR.cc/2018/Workshop/-/Paper294/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper294/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper294/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper294/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper294/AnonReviewer1"], "reply": {"forum": "BkuSOYkvG", "replyto": "BkuSOYkvG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper294/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper294/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582783772}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582782820, "tcdate": 1520632322153, "number": 2, "cdate": 1520632322153, "id": "HJcWGKgtG", "invitation": "ICLR.cc/2018/Workshop/-/Paper294/Official_Review", "forum": "BkuSOYkvG", "replyto": "BkuSOYkvG", "signatures": ["ICLR.cc/2018/Workshop/Paper294/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper294/AnonReviewer2"], "content": {"title": "Interesting, but not convinced by the setup.", "rating": "6: Marginally above acceptance threshold", "review": "In this paper, the authors propose to add a \"Lens\" network between the true data distribution and  the discriminator. They train this network with two objectives, the normal discriminator objective L_D, and a reconstruction objective.\nThe authors then report improved results on multiple datasets and architectures.\n\nThe paper is well-written from an essay point of view, but from an experimental point of view, several things are fishy and worrying. The story that the authors propose doesn't satisfy me, here's why:\n1) in GANs, generators do *not* chase a fixed distribution. They chase the implicit data distribution that the discriminator has modeled through gradients provided by said discriminator.\n2) the proposed story for the Lens mechanism is that it \"automatically balances\" L^R and L^A, but there is little evidence to suggest that this is the case. In fact the evidence, to me, suggests that:\n2.1) as L^A starts going away things get better (given that you choose K=1e5 and that from your training curves things start going well at that point, I'm wondering why you have no training curve for lambda=0; Fig 4's explanation is also conjecture IMO)\n2.2) as L^R gets lower because of a better reconstruction, things get better. \n3) Once lambda is removed, there is some resemblance with \"Adversarial Autoencoders\" (arxiv.org/abs/1511.05644), and with \"Adversarially Learned Inference\" (arxiv.org/abs/1606.00704). (I'm not on author on either those papers)\n4) You claim that the effect of the lens is \"automatically\" balanced, but you've very clearly defined manually a scheduling for lambda, and it is not obvious to me why L minimizing L^A balances anything.\n\nw.r.t. 2.1, what would happen if you froze everything, reset L(X), and then train only L(X)? Would it match G(X)? Would it match X? (as a result of minimizing L^R). \nWhat would happen if L(X) simply optimized for L^R? Maybe that is the real contribution here.\n\n\nThere's definitely something going on because you are getting interesting results, but I think your setup deserves a lot more investigating, just for example:\n- The discriminator's data is coming from a neural net, that's somewhat unusual. Does that have a meaningful effect?\n- The lens network could cheat with the residual connection, does it? If not is it really helping out the discriminator? How?\n\nWhile I'm aware this is a workshop submission and not all those questions can be answered, the authors seem to be selling more than they have which bothers me. They make a (afaik) novel contribution, have results to back what they're doing.\n\nSide note: It says on the iclr.cc website that \"Extended abstracts submitted to the Workshop Track are strictly limited to 3 pages, excluding references.\" To me this paper seems like a full paper disguised as an extended abstract with a long appendix.\n\nTypo: in Section 2 'G(\\mathcal{X})' should be 'G(\\mathcal{Z})' (twice).", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tempered Adversarial Networks", "abstract": "Generative adversarial networks (GANs) have been shown to produce realistic samples from high-dimensional distributions, but training them is considered hard. A possible explanation for training instabilities is the inherent imbalance between the networks: While the discriminator is trained directly on both real and fake samples, the generator only has control over the fake samples it produces since the real data distribution is fixed by the choice of a given dataset. We propose a simple modification that gives the generator control over the real samples, leading to a tempered learning process for both generator and discriminator. The real data distribution passes through a lens before being revealed to the discriminator, balancing the training process by gradually revealing more detailed features necessary to produce high-quality results. The proposed module automatically adjusts the learning process to the current strength of the networks, yet is generic and easy to add to any GAN variant. In a number of experiments, we show that this is a promising technique to improve quality, stability and/or convergence speed across a range of different GAN architectures (DCGAN, LSGAN, WGAN-GP).", "paperhash": "sajjadi|tempered_adversarial_networks", "keywords": ["generative adversarial networks"], "_bibtex": "@misc{\n  sajjadi2018tempered,\n  title={Tempered Adversarial Networks},\n  author={Mehdi S. M. Sajjadi and Giambattista Parascandolo and Arash Mehrjou and Bernhard Sch\u00f6lkopf},\n  year={2018},\n  url={https://openreview.net/forum?id=BkuSOYkvG}\n}", "authorids": ["msajjadi@tue.mpg.de", "gparascandolo@tue.mpg.de", "amehrjou@tue.mpg.de", "bs@tuebingen.mpg.de"], "authors": ["Mehdi S. M. Sajjadi", "Giambattista Parascandolo", "Arash Mehrjou", "Bernhard Sch\u00f6lkopf"], "TL;DR": "Passing the real data distribution in a GAN through a lens stabilizes training and leads to better results in DCGAN, LSGAN and WGAN-GP.", "pdf": "/pdf/b0a59c8346a3309df9ea51a58ad6bc24bea0b3a7.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582783772, "id": "ICLR.cc/2018/Workshop/-/Paper294/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper294/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper294/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper294/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper294/AnonReviewer1"], "reply": {"forum": "BkuSOYkvG", "replyto": "BkuSOYkvG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper294/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper294/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582783772}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582771990, "tcdate": 1520637078146, "number": 3, "cdate": 1520637078146, "id": "SJCqN9gYG", "invitation": "ICLR.cc/2018/Workshop/-/Paper294/Official_Review", "forum": "BkuSOYkvG", "replyto": "BkuSOYkvG", "signatures": ["ICLR.cc/2018/Workshop/Paper294/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper294/AnonReviewer1"], "content": {"title": "the advantages of the proposed methods are not clear", "rating": "5: Marginally below acceptance threshold", "review": "summary: \n\nThe paper propose to learn a function L that is almost the identity (min _{L} ||x- L(x)||) for training GAN where (real is replaced by L(x)), L is progressively going to identity. This is similar to the effect of adding noise that is annealed over the training on real data. \n\nAsymmetric noise on real data only  has been considered for  in Sobolev GAN. Noising both real and fake data was also considered known as instance noise in \"AMORTISED MAP INFERENCE FOR IMAGE SUPER-RESOLUTION\".  A comparaison to annealed noising should be considered in this paper,as L is only learning some noising/ blurring of the image.\n\nThe paper mentions some relation to progressive growing  and says that the scale can be only used for images, the paper will be much stronger if it shows any improvement using the lens on text generation for instance. \n\nOverall the ideas in the paper need more empirical investigation: 1) comparaison to noising and 2) seeing if the lens function gives improvement in text generation where progressive scale growing is not obvious. \n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tempered Adversarial Networks", "abstract": "Generative adversarial networks (GANs) have been shown to produce realistic samples from high-dimensional distributions, but training them is considered hard. A possible explanation for training instabilities is the inherent imbalance between the networks: While the discriminator is trained directly on both real and fake samples, the generator only has control over the fake samples it produces since the real data distribution is fixed by the choice of a given dataset. We propose a simple modification that gives the generator control over the real samples, leading to a tempered learning process for both generator and discriminator. The real data distribution passes through a lens before being revealed to the discriminator, balancing the training process by gradually revealing more detailed features necessary to produce high-quality results. The proposed module automatically adjusts the learning process to the current strength of the networks, yet is generic and easy to add to any GAN variant. In a number of experiments, we show that this is a promising technique to improve quality, stability and/or convergence speed across a range of different GAN architectures (DCGAN, LSGAN, WGAN-GP).", "paperhash": "sajjadi|tempered_adversarial_networks", "keywords": ["generative adversarial networks"], "_bibtex": "@misc{\n  sajjadi2018tempered,\n  title={Tempered Adversarial Networks},\n  author={Mehdi S. M. Sajjadi and Giambattista Parascandolo and Arash Mehrjou and Bernhard Sch\u00f6lkopf},\n  year={2018},\n  url={https://openreview.net/forum?id=BkuSOYkvG}\n}", "authorids": ["msajjadi@tue.mpg.de", "gparascandolo@tue.mpg.de", "amehrjou@tue.mpg.de", "bs@tuebingen.mpg.de"], "authors": ["Mehdi S. M. Sajjadi", "Giambattista Parascandolo", "Arash Mehrjou", "Bernhard Sch\u00f6lkopf"], "TL;DR": "Passing the real data distribution in a GAN through a lens stabilizes training and leads to better results in DCGAN, LSGAN and WGAN-GP.", "pdf": "/pdf/b0a59c8346a3309df9ea51a58ad6bc24bea0b3a7.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582783772, "id": "ICLR.cc/2018/Workshop/-/Paper294/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper294/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper294/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper294/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper294/AnonReviewer1"], "reply": {"forum": "BkuSOYkvG", "replyto": "BkuSOYkvG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper294/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper294/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582783772}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573572365, "tcdate": 1521573572365, "number": 129, "cdate": 1521573572025, "id": "HJ3aA0RYz", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "BkuSOYkvG", "replyto": "BkuSOYkvG", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tempered Adversarial Networks", "abstract": "Generative adversarial networks (GANs) have been shown to produce realistic samples from high-dimensional distributions, but training them is considered hard. A possible explanation for training instabilities is the inherent imbalance between the networks: While the discriminator is trained directly on both real and fake samples, the generator only has control over the fake samples it produces since the real data distribution is fixed by the choice of a given dataset. We propose a simple modification that gives the generator control over the real samples, leading to a tempered learning process for both generator and discriminator. The real data distribution passes through a lens before being revealed to the discriminator, balancing the training process by gradually revealing more detailed features necessary to produce high-quality results. The proposed module automatically adjusts the learning process to the current strength of the networks, yet is generic and easy to add to any GAN variant. In a number of experiments, we show that this is a promising technique to improve quality, stability and/or convergence speed across a range of different GAN architectures (DCGAN, LSGAN, WGAN-GP).", "paperhash": "sajjadi|tempered_adversarial_networks", "keywords": ["generative adversarial networks"], "_bibtex": "@misc{\n  sajjadi2018tempered,\n  title={Tempered Adversarial Networks},\n  author={Mehdi S. M. Sajjadi and Giambattista Parascandolo and Arash Mehrjou and Bernhard Sch\u00f6lkopf},\n  year={2018},\n  url={https://openreview.net/forum?id=BkuSOYkvG}\n}", "authorids": ["msajjadi@tue.mpg.de", "gparascandolo@tue.mpg.de", "amehrjou@tue.mpg.de", "bs@tuebingen.mpg.de"], "authors": ["Mehdi S. M. Sajjadi", "Giambattista Parascandolo", "Arash Mehrjou", "Bernhard Sch\u00f6lkopf"], "TL;DR": "Passing the real data distribution in a GAN through a lens stabilizes training and leads to better results in DCGAN, LSGAN and WGAN-GP.", "pdf": "/pdf/b0a59c8346a3309df9ea51a58ad6bc24bea0b3a7.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}, {"tddate": null, "ddate": null, "tmdate": 1520077390687, "tcdate": 1520077222492, "number": 1, "cdate": 1520077222492, "id": "H10jYbuuM", "invitation": "ICLR.cc/2018/Workshop/-/Paper294/Official_Comment", "forum": "BkuSOYkvG", "replyto": "BkuSOYkvG", "signatures": ["ICLR.cc/2018/Workshop/Paper294/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper294/Authors"], "content": {"title": "Erroneous figures", "comment": "We have noticed an error in the figures of the submission. Several figures in the uploaded version erroneously show generated samples instead of real or lensed real samples due to a bug in a post processing image cropping script for the tex file.\n\nDetails:\nFig. 1+4: top right column \"Lensed Samples L(X)\" and \"Real samples X\" below mistakenly display the results of the Generator.\nFig. 8: top right column \"Lensed Samples L(X)\" mistakenly shows the same images as the generated images.\n\nThe figures have been updated with the correct images in the arXiv version (1802.04374)."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tempered Adversarial Networks", "abstract": "Generative adversarial networks (GANs) have been shown to produce realistic samples from high-dimensional distributions, but training them is considered hard. A possible explanation for training instabilities is the inherent imbalance between the networks: While the discriminator is trained directly on both real and fake samples, the generator only has control over the fake samples it produces since the real data distribution is fixed by the choice of a given dataset. We propose a simple modification that gives the generator control over the real samples, leading to a tempered learning process for both generator and discriminator. The real data distribution passes through a lens before being revealed to the discriminator, balancing the training process by gradually revealing more detailed features necessary to produce high-quality results. The proposed module automatically adjusts the learning process to the current strength of the networks, yet is generic and easy to add to any GAN variant. In a number of experiments, we show that this is a promising technique to improve quality, stability and/or convergence speed across a range of different GAN architectures (DCGAN, LSGAN, WGAN-GP).", "paperhash": "sajjadi|tempered_adversarial_networks", "keywords": ["generative adversarial networks"], "_bibtex": "@misc{\n  sajjadi2018tempered,\n  title={Tempered Adversarial Networks},\n  author={Mehdi S. M. Sajjadi and Giambattista Parascandolo and Arash Mehrjou and Bernhard Sch\u00f6lkopf},\n  year={2018},\n  url={https://openreview.net/forum?id=BkuSOYkvG}\n}", "authorids": ["msajjadi@tue.mpg.de", "gparascandolo@tue.mpg.de", "amehrjou@tue.mpg.de", "bs@tuebingen.mpg.de"], "authors": ["Mehdi S. M. Sajjadi", "Giambattista Parascandolo", "Arash Mehrjou", "Bernhard Sch\u00f6lkopf"], "TL;DR": "Passing the real data distribution in a GAN through a lens stabilizes training and leads to better results in DCGAN, LSGAN and WGAN-GP.", "pdf": "/pdf/b0a59c8346a3309df9ea51a58ad6bc24bea0b3a7.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1519222446123, "id": "ICLR.cc/2018/Workshop/-/Paper294/Official_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "BkuSOYkvG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper294/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper294/Authors|ICLR.cc/2018/Workshop/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper294/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper294/Authors|ICLR.cc/2018/Workshop/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Workshop/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Workshop/Paper294/Reviewers", "ICLR.cc/2018/Workshop/Paper294/Authors", "ICLR.cc/2018/Workshop/Program_Chairs"], "cdate": 1519222446123}}, "tauthor": "msajjadi@tue.mpg.de"}], "count": 7}