{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1486773321657, "tcdate": 1486773321657, "number": 13, "id": "HJGU3Rodl", "invitation": "ICLR.cc/2017/workshop/-/submission", "forum": "HJGU3Rodl", "original": "S1OufnIlx", "signatures": ["~Alexey_Kurakin1"], "readers": ["everyone"], "content": {"TL;DR": "", "title": "Adversarial examples in the physical world", "abstract": "Most existing machine learning classifiers are highly vulnerable to adversarial examples.\nAn adversarial example is a sample of input data which has been modified\nvery slightly in a way that is intended to cause a machine learning classifier\nto misclassify it.\nIn many cases, these modifications can be so subtle that a human observer does\nnot even notice the modification at all, yet the classifier still makes a mistake.\nAdversarial examples pose security concerns\nbecause they could be used to perform an attack on machine learning systems, even if the adversary has no\naccess to the underlying model.\nUp to now, all previous work has assumed a threat model in which the adversary can\nfeed data directly into the machine learning classifier.\nThis is not always the case for systems operating in the physical world,\nfor example those which are using signals from cameras and other sensors as input.\nThis paper shows that even in such physical world scenarios, machine learning systems are vulnerable\nto adversarial examples.\nWe demonstrate this by feeding adversarial images obtained from a cell-phone camera\nto an ImageNet Inception classifier and measuring the classification accuracy of the system.\nWe find that a large fraction of adversarial examples are classified incorrectly\neven when perceived through the camera.", "pdf": "/pdf/552d64863cad3f64ba42f3da1b762d47a7db1258.pdf", "paperhash": "kurakin|adversarial_examples_in_the_physical_world", "conflicts": ["google.com", "openai.com"], "keywords": ["Supervised Learning", "Computer vision"], "authors": ["Alexey Kurakin", "Ian J. Goodfellow", "Samy Bengio"], "authorids": ["kurakin@google.com", "ian@openai.com", "bengio@google.com"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "tags": [], "original": {"tddate": null, "replyto": null, "ddate": null, "active": true, "tmdate": 1484678242596, "tcdate": 1478046320019, "number": 35, "id": "S1OufnIlx", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "S1OufnIlx", "signatures": ["~Alexey_Kurakin1"], "readers": ["everyone"], "content": {"TL;DR": "", "title": "Adversarial examples in the physical world", "abstract": "Most existing machine learning classifiers are highly vulnerable to adversarial examples.\nAn adversarial example is a sample of input data which has been modified\nvery slightly in a way that is intended to cause a machine learning classifier\nto misclassify it.\nIn many cases, these modifications can be so subtle that a human observer does\nnot even notice the modification at all, yet the classifier still makes a mistake.\nAdversarial examples pose security concerns\nbecause they could be used to perform an attack on machine learning systems, even if the adversary has no\naccess to the underlying model.\nUp to now, all previous work has assumed a threat model in which the adversary can\nfeed data directly into the machine learning classifier.\nThis is not always the case for systems operating in the physical world,\nfor example those which are using signals from cameras and other sensors as input.\nThis paper shows that even in such physical world scenarios, machine learning systems are vulnerable\nto adversarial examples.\nWe demonstrate this by feeding adversarial images obtained from a cell-phone camera\nto an ImageNet Inception classifier and measuring the classification accuracy of the system.\nWe find that a large fraction of adversarial examples are classified incorrectly\neven when perceived through the camera.", "pdf": "/pdf/e8eca92cff8015f8d0ec8db450144a10b1b9bdab.pdf", "paperhash": "kurakin|adversarial_examples_in_the_physical_world", "conflicts": ["google.com", "openai.com"], "keywords": ["Supervised Learning", "Computer vision"], "authors": ["Alexey Kurakin", "Ian J. Goodfellow", "Samy Bengio"], "authorids": ["kurakin@google.com", "ian@openai.com", "bengio@google.com"]}, "writers": [], "nonreaders": []}, "originalWritable": false, "originalInvitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}, "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1487690420000, "tmdate": 1484242559574, "id": "ICLR.cc/2017/workshop/-/submission", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1495466420000, "cdate": 1484242559574}}}], "count": 1}