{"notes": [{"id": "SJeItTEKvr", "original": "S1x38kpvvS", "number": 670, "cdate": 1569439101819, "ddate": null, "tcdate": 1569439101819, "tmdate": 1577168218506, "tddate": null, "forum": "SJeItTEKvr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["tao.zheng@student.uts.edu.au", "ivor.tsang@uts.edu.au", "xiny@sustech.edu.cn"], "title": "MULTI-LABEL METRIC LEARNING WITH BIDIRECTIONAL REPRESENTATION DEEP NEURAL NETWORKS", "authors": ["Tao Zheng", "Ivor Tsang", "Xin Yao"], "pdf": "/pdf/6cf8c63d5d6324d16a3dc6be3f7b55e4ea4cb1e1.pdf", "abstract": "Multi-Label Learning task simultaneously predicting multiple labels has attracted researchers' interest for its wide application. \nMetric Learning crucially determines the performance of the k nearest neighbor algorithms, the most popular framework handling the multi-label problem.\nHowever, the existing advanced multiple-label metric learning suffers the inferior capacity and application restriction. \nWe propose an extendable and end-to-end deep representation approach for metric learning on multi-label data set that is based on neural networks able to operate on feature data or directly on raw image data. \nWe motivate the choice of our network architecture via a Bidirectional Representation learning where the label dependency is also integrated and deep convolutional networks that handle image data. \nIn multi-label metric learning, instances with the more different labels will be dragged the more far away, but ones with identical labels will concentrate together. \nOur model scales linearly in the number of instances and trains deep neural networks that encode both input data and output labels, then, obtains a metric space for testing data. \nIn a number of experiments on multi-labels tasks, we demonstrate that our approach is better than related methods based on the systematic metric and its extendability.   \n", "keywords": ["metric learning", "representation learning", "multi-label classification", "multi-output"], "paperhash": "zheng|multilabel_metric_learning_with_bidirectional_representation_deep_neural_networks", "original_pdf": "/attachment/6cf8c63d5d6324d16a3dc6be3f7b55e4ea4cb1e1.pdf", "_bibtex": "@misc{\nzheng2020multilabel,\ntitle={{\\{}MULTI{\\}}-{\\{}LABEL{\\}} {\\{}METRIC{\\}} {\\{}LEARNING{\\}} {\\{}WITH{\\}} {\\{}BIDIRECTIONAL{\\}} {\\{}REPRESENTATION{\\}} {\\{}DEEP{\\}} {\\{}NEURAL{\\}} {\\{}NETWORKS{\\}}},\nauthor={Tao Zheng and Ivor Tsang and Xin Yao},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeItTEKvr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "qzM8xZN2H", "original": null, "number": 1, "cdate": 1576798702864, "ddate": null, "tcdate": 1576798702864, "tmdate": 1576800933144, "tddate": null, "forum": "SJeItTEKvr", "replyto": "SJeItTEKvr", "invitation": "ICLR.cc/2020/Conference/Paper670/-/Decision", "content": {"decision": "Reject", "comment": "All reviewers agreed that this submission is still premature to be accepted to ICLR2020.\nWe hope the review comments are useful for improving your paper for potential future submission.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["tao.zheng@student.uts.edu.au", "ivor.tsang@uts.edu.au", "xiny@sustech.edu.cn"], "title": "MULTI-LABEL METRIC LEARNING WITH BIDIRECTIONAL REPRESENTATION DEEP NEURAL NETWORKS", "authors": ["Tao Zheng", "Ivor Tsang", "Xin Yao"], "pdf": "/pdf/6cf8c63d5d6324d16a3dc6be3f7b55e4ea4cb1e1.pdf", "abstract": "Multi-Label Learning task simultaneously predicting multiple labels has attracted researchers' interest for its wide application. \nMetric Learning crucially determines the performance of the k nearest neighbor algorithms, the most popular framework handling the multi-label problem.\nHowever, the existing advanced multiple-label metric learning suffers the inferior capacity and application restriction. \nWe propose an extendable and end-to-end deep representation approach for metric learning on multi-label data set that is based on neural networks able to operate on feature data or directly on raw image data. \nWe motivate the choice of our network architecture via a Bidirectional Representation learning where the label dependency is also integrated and deep convolutional networks that handle image data. \nIn multi-label metric learning, instances with the more different labels will be dragged the more far away, but ones with identical labels will concentrate together. \nOur model scales linearly in the number of instances and trains deep neural networks that encode both input data and output labels, then, obtains a metric space for testing data. \nIn a number of experiments on multi-labels tasks, we demonstrate that our approach is better than related methods based on the systematic metric and its extendability.   \n", "keywords": ["metric learning", "representation learning", "multi-label classification", "multi-output"], "paperhash": "zheng|multilabel_metric_learning_with_bidirectional_representation_deep_neural_networks", "original_pdf": "/attachment/6cf8c63d5d6324d16a3dc6be3f7b55e4ea4cb1e1.pdf", "_bibtex": "@misc{\nzheng2020multilabel,\ntitle={{\\{}MULTI{\\}}-{\\{}LABEL{\\}} {\\{}METRIC{\\}} {\\{}LEARNING{\\}} {\\{}WITH{\\}} {\\{}BIDIRECTIONAL{\\}} {\\{}REPRESENTATION{\\}} {\\{}DEEP{\\}} {\\{}NEURAL{\\}} {\\{}NETWORKS{\\}}},\nauthor={Tao Zheng and Ivor Tsang and Xin Yao},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeItTEKvr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "SJeItTEKvr", "replyto": "SJeItTEKvr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795728900, "tmdate": 1576800281404, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper670/-/Decision"}}}, {"id": "ByxiegNpYH", "original": null, "number": 1, "cdate": 1571794931045, "ddate": null, "tcdate": 1571794931045, "tmdate": 1572972566841, "tddate": null, "forum": "SJeItTEKvr", "replyto": "SJeItTEKvr", "invitation": "ICLR.cc/2020/Conference/Paper670/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper addresses the problem of multi-label prediction.  It proposes a method that uses a co-embedding of instances and labels into a joint embedding space in a way that related instances and labels fall close by and unrelated ones fall far away.  For this purpose, embeddings from input space and label space to a common space are learned from training data. At the prediction time, KNN to the embedding of the test instance in the co-embedding space is used to predict relevant labels.\nFeaturized (attributed)  labels are potentially considered, which can facilitate incorporating label dependence and generalization over unseen labels.\n\nMain shortcomings:\n- The novelty of the work is limited. Ideas introduced in this work are present and being investigated in literature for a while now, leading to remaining limited contribution for the paper.  Related work on joint embedding, co-embedding, label-embedding, and zero shot learning seem to be neglected totally. For example, the paper lacks awareness of, citation to and comparison with related work such as [1-5].\n- Presentation of the paper can be highly improved. There are several grammatical and writing problems in the paper.\nFormulation can also benefit from  improved presentation. See for example Eq (1).\n- Technical arguments are not all well founded. For example, the scalability claim in the abstract  of the paper seems to refer to \"prediction\" time complexity being linear in the number of \"training\" examples, which is not actually fast.\n\nIn summary, based on the above reasons, I vote for the paper to be strongly rejected.\n\n[1] Akata, Zeynep, et al. \"Label-embedding for image classification.\" IEEE transactions on pattern analysis and machine intelligence 38.7 (2015): 1425-1438.\n[2] Weston, Jason, Samy Bengio, and Nicolas Usunier. \"Wsabie: Scaling up to large vocabulary image annotation.\" Twenty-Second International Joint Conference on Artificial Intelligence. 2011.\n[3] Li, Xin, and Yuhong Guo. \"Bi-directional representation learning for multi-label classification.\" Joint European conference on machine learning and knowledge discovery in databases. Springer, Berlin, Heidelberg, 2014.\n[4] Mirzazadeh, Farzaneh, et al. \"Scalable metric learning for co-embedding.\" Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, Cham, 2015.\n[5] Yeh, Chih-Kuan, et al. \"Learning deep latent space for multi-label classification.\" Thirty-First AAAI Conference on Artificial Intelligence. 2017."}, "signatures": ["ICLR.cc/2020/Conference/Paper670/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper670/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["tao.zheng@student.uts.edu.au", "ivor.tsang@uts.edu.au", "xiny@sustech.edu.cn"], "title": "MULTI-LABEL METRIC LEARNING WITH BIDIRECTIONAL REPRESENTATION DEEP NEURAL NETWORKS", "authors": ["Tao Zheng", "Ivor Tsang", "Xin Yao"], "pdf": "/pdf/6cf8c63d5d6324d16a3dc6be3f7b55e4ea4cb1e1.pdf", "abstract": "Multi-Label Learning task simultaneously predicting multiple labels has attracted researchers' interest for its wide application. \nMetric Learning crucially determines the performance of the k nearest neighbor algorithms, the most popular framework handling the multi-label problem.\nHowever, the existing advanced multiple-label metric learning suffers the inferior capacity and application restriction. \nWe propose an extendable and end-to-end deep representation approach for metric learning on multi-label data set that is based on neural networks able to operate on feature data or directly on raw image data. \nWe motivate the choice of our network architecture via a Bidirectional Representation learning where the label dependency is also integrated and deep convolutional networks that handle image data. \nIn multi-label metric learning, instances with the more different labels will be dragged the more far away, but ones with identical labels will concentrate together. \nOur model scales linearly in the number of instances and trains deep neural networks that encode both input data and output labels, then, obtains a metric space for testing data. \nIn a number of experiments on multi-labels tasks, we demonstrate that our approach is better than related methods based on the systematic metric and its extendability.   \n", "keywords": ["metric learning", "representation learning", "multi-label classification", "multi-output"], "paperhash": "zheng|multilabel_metric_learning_with_bidirectional_representation_deep_neural_networks", "original_pdf": "/attachment/6cf8c63d5d6324d16a3dc6be3f7b55e4ea4cb1e1.pdf", "_bibtex": "@misc{\nzheng2020multilabel,\ntitle={{\\{}MULTI{\\}}-{\\{}LABEL{\\}} {\\{}METRIC{\\}} {\\{}LEARNING{\\}} {\\{}WITH{\\}} {\\{}BIDIRECTIONAL{\\}} {\\{}REPRESENTATION{\\}} {\\{}DEEP{\\}} {\\{}NEURAL{\\}} {\\{}NETWORKS{\\}}},\nauthor={Tao Zheng and Ivor Tsang and Xin Yao},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeItTEKvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJeItTEKvr", "replyto": "SJeItTEKvr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper670/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper670/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574734204908, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper670/Reviewers"], "noninvitees": [], "tcdate": 1570237748798, "tmdate": 1574734204923, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper670/-/Official_Review"}}}, {"id": "rJxYss7z5S", "original": null, "number": 2, "cdate": 1572121504560, "ddate": null, "tcdate": 1572121504560, "tmdate": 1572972566798, "tddate": null, "forum": "SJeItTEKvr", "replyto": "SJeItTEKvr", "invitation": "ICLR.cc/2020/Conference/Paper670/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper aims to solve multi-label problems via learning a share embedding space for instances and its label sets. Specifically, the author considers deep neural networks F(x) as an encoder for the instance (either raw input or features) and a shallow MLPs G(y) as an encoder for the label outputs. In the training stage, the instance embedding and its label embedding are forced to be close. An additional constraint is instances with different labels should be far from each other. After training, the inference can be done in the embedding space by looking up the labels of the query\u2019s kNN instances. \n\nMetric learning for multi-label problems is not new, many works have been proposed such as [1,2]. Using deep neural networks for multi-label problems is also not new, see [3,4]. Thus, the novelty of the proposed method is rather limited. The interesting part is the constraint of Eq(11), where kNN need to be updated whenever the instance encoder model F(X) is changing during the optimization, which is very expensive for large-scale application.\n \n[1] Sparse Local Embeddings for Extreme Multi-label Classification, NIPS 2015.\n[2] Learning Deep Latent Space for Multi-label Classification, AAAI 2017.\n[3] Deep Learning for Extreme Multi-label Text Classification, SIGIR 2017.\n[4] X-BERT: eXtreme Multi-label Text Classification with BERT, ArXiv 2019. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper670/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper670/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["tao.zheng@student.uts.edu.au", "ivor.tsang@uts.edu.au", "xiny@sustech.edu.cn"], "title": "MULTI-LABEL METRIC LEARNING WITH BIDIRECTIONAL REPRESENTATION DEEP NEURAL NETWORKS", "authors": ["Tao Zheng", "Ivor Tsang", "Xin Yao"], "pdf": "/pdf/6cf8c63d5d6324d16a3dc6be3f7b55e4ea4cb1e1.pdf", "abstract": "Multi-Label Learning task simultaneously predicting multiple labels has attracted researchers' interest for its wide application. \nMetric Learning crucially determines the performance of the k nearest neighbor algorithms, the most popular framework handling the multi-label problem.\nHowever, the existing advanced multiple-label metric learning suffers the inferior capacity and application restriction. \nWe propose an extendable and end-to-end deep representation approach for metric learning on multi-label data set that is based on neural networks able to operate on feature data or directly on raw image data. \nWe motivate the choice of our network architecture via a Bidirectional Representation learning where the label dependency is also integrated and deep convolutional networks that handle image data. \nIn multi-label metric learning, instances with the more different labels will be dragged the more far away, but ones with identical labels will concentrate together. \nOur model scales linearly in the number of instances and trains deep neural networks that encode both input data and output labels, then, obtains a metric space for testing data. \nIn a number of experiments on multi-labels tasks, we demonstrate that our approach is better than related methods based on the systematic metric and its extendability.   \n", "keywords": ["metric learning", "representation learning", "multi-label classification", "multi-output"], "paperhash": "zheng|multilabel_metric_learning_with_bidirectional_representation_deep_neural_networks", "original_pdf": "/attachment/6cf8c63d5d6324d16a3dc6be3f7b55e4ea4cb1e1.pdf", "_bibtex": "@misc{\nzheng2020multilabel,\ntitle={{\\{}MULTI{\\}}-{\\{}LABEL{\\}} {\\{}METRIC{\\}} {\\{}LEARNING{\\}} {\\{}WITH{\\}} {\\{}BIDIRECTIONAL{\\}} {\\{}REPRESENTATION{\\}} {\\{}DEEP{\\}} {\\{}NEURAL{\\}} {\\{}NETWORKS{\\}}},\nauthor={Tao Zheng and Ivor Tsang and Xin Yao},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeItTEKvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJeItTEKvr", "replyto": "SJeItTEKvr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper670/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper670/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574734204908, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper670/Reviewers"], "noninvitees": [], "tcdate": 1570237748798, "tmdate": 1574734204923, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper670/-/Official_Review"}}}, {"id": "rylMTp8t5B", "original": null, "number": 3, "cdate": 1572593082097, "ddate": null, "tcdate": 1572593082097, "tmdate": 1572972566756, "tddate": null, "forum": "SJeItTEKvr", "replyto": "SJeItTEKvr", "invitation": "ICLR.cc/2020/Conference/Paper670/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper presents a metric learning approach for the multi-label classification problem. It basically maps the input features and the output labels into the same space and then uses k-NN to find the closest labels for each inputs. During training, it minimizes the squared Euclidean distance between the input embedding and label embedding. In the experiments, some image datasets and text datasets are used to compare with several multi-label learning algorithms. \n\nThe proposed method is clearly presented in the paper. However, I have several concerns.\n\n1. The proposed method is straightforward and lacks of significant novelty.\n2. The datasets are very small scale in terms of both sample size and label size. \n3. The comparing methods are a little bit out-dated. I would also suggest to compare directly with the naive one-versus-all method using deep learning extraction models. \n4. There are a few typos. For example, on Page 1, \"because it wide application\", \"but cannon deal\", \"may lost key information\"; on Page 2, \"an bidirectional\", \"mapping of outputs to metric space are\"; on Page 3, \"a scalable models\", etc.. Besides, Eq (1) should be written in a more formal way. \n\nOverall, I vote for rejection and the main reason is the lack of novelty. "}, "signatures": ["ICLR.cc/2020/Conference/Paper670/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper670/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["tao.zheng@student.uts.edu.au", "ivor.tsang@uts.edu.au", "xiny@sustech.edu.cn"], "title": "MULTI-LABEL METRIC LEARNING WITH BIDIRECTIONAL REPRESENTATION DEEP NEURAL NETWORKS", "authors": ["Tao Zheng", "Ivor Tsang", "Xin Yao"], "pdf": "/pdf/6cf8c63d5d6324d16a3dc6be3f7b55e4ea4cb1e1.pdf", "abstract": "Multi-Label Learning task simultaneously predicting multiple labels has attracted researchers' interest for its wide application. \nMetric Learning crucially determines the performance of the k nearest neighbor algorithms, the most popular framework handling the multi-label problem.\nHowever, the existing advanced multiple-label metric learning suffers the inferior capacity and application restriction. \nWe propose an extendable and end-to-end deep representation approach for metric learning on multi-label data set that is based on neural networks able to operate on feature data or directly on raw image data. \nWe motivate the choice of our network architecture via a Bidirectional Representation learning where the label dependency is also integrated and deep convolutional networks that handle image data. \nIn multi-label metric learning, instances with the more different labels will be dragged the more far away, but ones with identical labels will concentrate together. \nOur model scales linearly in the number of instances and trains deep neural networks that encode both input data and output labels, then, obtains a metric space for testing data. \nIn a number of experiments on multi-labels tasks, we demonstrate that our approach is better than related methods based on the systematic metric and its extendability.   \n", "keywords": ["metric learning", "representation learning", "multi-label classification", "multi-output"], "paperhash": "zheng|multilabel_metric_learning_with_bidirectional_representation_deep_neural_networks", "original_pdf": "/attachment/6cf8c63d5d6324d16a3dc6be3f7b55e4ea4cb1e1.pdf", "_bibtex": "@misc{\nzheng2020multilabel,\ntitle={{\\{}MULTI{\\}}-{\\{}LABEL{\\}} {\\{}METRIC{\\}} {\\{}LEARNING{\\}} {\\{}WITH{\\}} {\\{}BIDIRECTIONAL{\\}} {\\{}REPRESENTATION{\\}} {\\{}DEEP{\\}} {\\{}NEURAL{\\}} {\\{}NETWORKS{\\}}},\nauthor={Tao Zheng and Ivor Tsang and Xin Yao},\nyear={2020},\nurl={https://openreview.net/forum?id=SJeItTEKvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJeItTEKvr", "replyto": "SJeItTEKvr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper670/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper670/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574734204908, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper670/Reviewers"], "noninvitees": [], "tcdate": 1570237748798, "tmdate": 1574734204923, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper670/-/Official_Review"}}}], "count": 5}