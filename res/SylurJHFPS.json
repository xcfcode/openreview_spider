{"notes": [{"id": "SylurJHFPS", "original": "SygXwGTuvS", "number": 1698, "cdate": 1569439552489, "ddate": null, "tcdate": 1569439552489, "tmdate": 1577168216747, "tddate": null, "forum": "SylurJHFPS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["1045258214@qq.com", "1061185275@qq.com", "jandp@pku.edu.cn", "626913553@qq.com", "wanghongjun@swjtu.edu.cn", "daixinyu@nju.edu.cn", "chenjj@nju.edu.cn"], "title": "The Detection of Distributional Discrepancy for Text Generation", "authors": ["Xingyuan Chen", "Ping Cai", "Peng Jin", "Haokun Du", "Hongjun Wang", "Xinyu Dai", "Jiajun Chen"], "pdf": "/pdf/38b390ebc596c0ace8731b947b8920236a7b7b90.pdf", "abstract": "The text generated by neural language models is not as good as the real text. This means that their distributions are different. Generative Adversarial Nets (GAN) are used to alleviate it. However, some researchers argue that GAN variants do not work at all. When both sample quality (such as Bleu) and sample diversity (such as self-Bleu) are taken into account, the GAN variants even are worse than a well-adjusted language model. But, Bleu and self-Bleu can not precisely measure this distributional discrepancy. In fact, how to measure the distributional discrepancy between real text and generated text is still an open problem. In this paper, we theoretically propose two metric functions to measure the distributional difference between real text and generated text. Besides that, a method is put forward to estimate them. First, we evaluate language model with these two functions and find the difference is huge. Then, we try several methods to use the detected discrepancy signal to improve the generator. However the difference becomes even bigger than before. Experimenting on two existing language GANs, the distributional discrepancy between real text and generated text increases with more adversarial learning rounds. It demonstrates both of these language GANs fail. ", "code": "https://github.com/anonymousBoy-sys/seqgan-relgan", "keywords": [], "paperhash": "chen|the_detection_of_distributional_discrepancy_for_text_generation", "original_pdf": "/attachment/38b390ebc596c0ace8731b947b8920236a7b7b90.pdf", "_bibtex": "@misc{\nchen2020the,\ntitle={The Detection of Distributional Discrepancy for Text Generation},\nauthor={Xingyuan Chen and Ping Cai and Peng Jin and Haokun Du and Hongjun Wang and Xinyu Dai and Jiajun Chen},\nyear={2020},\nurl={https://openreview.net/forum?id=SylurJHFPS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "PV64LzvDS", "original": null, "number": 1, "cdate": 1576798730159, "ddate": null, "tcdate": 1576798730159, "tmdate": 1576800906349, "tddate": null, "forum": "SylurJHFPS", "replyto": "SylurJHFPS", "invitation": "ICLR.cc/2020/Conference/Paper1698/-/Decision", "content": {"decision": "Reject", "comment": "The authors propose a novel metric to detect distributional discrepancy for text generation models and argue that these can be used to explain the failure of GANs for language generation tasks. The reviewers found significant deficiencies with the paper, including:\n\n1) Numerous grammatical errors and typos, that make it difficult to read the paper.\n\n2) Mischarcterization of prior work on neural language models, and failure to compare with standard distributional discrepancy measures studied in prior work (KL, total variation, Wasserstein etc.). Further, the necessity of the complicated procedure derived by the authors is not well-justified.\n\n3) Failure to run experiments on standard banchmarks for image generation (which are much better studied applications of GANs) and confirm the superiority of the proposed metrics relative to standard baselines. \n\nThe reviewers were agreed on the rejection decision and the authors did not participate in the rebuttal phase.\n\nI therefore recommend rejection.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["1045258214@qq.com", "1061185275@qq.com", "jandp@pku.edu.cn", "626913553@qq.com", "wanghongjun@swjtu.edu.cn", "daixinyu@nju.edu.cn", "chenjj@nju.edu.cn"], "title": "The Detection of Distributional Discrepancy for Text Generation", "authors": ["Xingyuan Chen", "Ping Cai", "Peng Jin", "Haokun Du", "Hongjun Wang", "Xinyu Dai", "Jiajun Chen"], "pdf": "/pdf/38b390ebc596c0ace8731b947b8920236a7b7b90.pdf", "abstract": "The text generated by neural language models is not as good as the real text. This means that their distributions are different. Generative Adversarial Nets (GAN) are used to alleviate it. However, some researchers argue that GAN variants do not work at all. When both sample quality (such as Bleu) and sample diversity (such as self-Bleu) are taken into account, the GAN variants even are worse than a well-adjusted language model. But, Bleu and self-Bleu can not precisely measure this distributional discrepancy. In fact, how to measure the distributional discrepancy between real text and generated text is still an open problem. In this paper, we theoretically propose two metric functions to measure the distributional difference between real text and generated text. Besides that, a method is put forward to estimate them. First, we evaluate language model with these two functions and find the difference is huge. Then, we try several methods to use the detected discrepancy signal to improve the generator. However the difference becomes even bigger than before. Experimenting on two existing language GANs, the distributional discrepancy between real text and generated text increases with more adversarial learning rounds. It demonstrates both of these language GANs fail. ", "code": "https://github.com/anonymousBoy-sys/seqgan-relgan", "keywords": [], "paperhash": "chen|the_detection_of_distributional_discrepancy_for_text_generation", "original_pdf": "/attachment/38b390ebc596c0ace8731b947b8920236a7b7b90.pdf", "_bibtex": "@misc{\nchen2020the,\ntitle={The Detection of Distributional Discrepancy for Text Generation},\nauthor={Xingyuan Chen and Ping Cai and Peng Jin and Haokun Du and Hongjun Wang and Xinyu Dai and Jiajun Chen},\nyear={2020},\nurl={https://openreview.net/forum?id=SylurJHFPS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "SylurJHFPS", "replyto": "SylurJHFPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795726400, "tmdate": 1576800278525, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1698/-/Decision"}}}, {"id": "H1e5DF0aKH", "original": null, "number": 3, "cdate": 1571838305936, "ddate": null, "tcdate": 1571838305936, "tmdate": 1573141345562, "tddate": null, "forum": "SylurJHFPS", "replyto": "SylurJHFPS", "invitation": "ICLR.cc/2020/Conference/Paper1698/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #1", "review": "This paper argues that text generated by existing neural language models are not as good as real text and proposes two metric functions to measure the distributional difference between real text and generated text. The proposed metrics are tried on language GANs but fail to produce any improvement.\n\nMajor issues:\n\nThis manuscript is poorly organized and the introduction is not well-written. It\u2019s true that generating text from random noise vector remains a challenging problem, but sequence-to-sequence models for machine translation and question answering have achieved tremendous successes. The description in the first paragraph about neural language models is not accurate. \n\nThere are numerous grammar issues and mis-spellings. For e.g., pp. 1: \u201cRelGAN which needs not...\u201d, pp. 2: \u201cWe analysis\u2026\u201d, \u201ccould be find\u2026\u201d, pp 3: \u201cequation 8\u201d should be \u201cequation 9\u201d...\n\nThe proposed metrics are also questionable. Eq. 3 on page 2 holds for any x sampled from the distribution, not just for a single data point. To test the effectiveness of a good metric, extensive experiments on toy datasets such as MNIST, CIFAR10, and synthetic datasets should be conducted. This paper mixes text generation and proposed metrics together. The claimed failure experiments make the proposed metrics even more questionable.\n\nIn summary, the presentation and the organization of this paper should be significantly improved for submission. The proposed metrics are questionable and should be thoroughly tested on synthetic and toy datasets before deploying it for text generation.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1698/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1698/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["1045258214@qq.com", "1061185275@qq.com", "jandp@pku.edu.cn", "626913553@qq.com", "wanghongjun@swjtu.edu.cn", "daixinyu@nju.edu.cn", "chenjj@nju.edu.cn"], "title": "The Detection of Distributional Discrepancy for Text Generation", "authors": ["Xingyuan Chen", "Ping Cai", "Peng Jin", "Haokun Du", "Hongjun Wang", "Xinyu Dai", "Jiajun Chen"], "pdf": "/pdf/38b390ebc596c0ace8731b947b8920236a7b7b90.pdf", "abstract": "The text generated by neural language models is not as good as the real text. This means that their distributions are different. Generative Adversarial Nets (GAN) are used to alleviate it. However, some researchers argue that GAN variants do not work at all. When both sample quality (such as Bleu) and sample diversity (such as self-Bleu) are taken into account, the GAN variants even are worse than a well-adjusted language model. But, Bleu and self-Bleu can not precisely measure this distributional discrepancy. In fact, how to measure the distributional discrepancy between real text and generated text is still an open problem. In this paper, we theoretically propose two metric functions to measure the distributional difference between real text and generated text. Besides that, a method is put forward to estimate them. First, we evaluate language model with these two functions and find the difference is huge. Then, we try several methods to use the detected discrepancy signal to improve the generator. However the difference becomes even bigger than before. Experimenting on two existing language GANs, the distributional discrepancy between real text and generated text increases with more adversarial learning rounds. It demonstrates both of these language GANs fail. ", "code": "https://github.com/anonymousBoy-sys/seqgan-relgan", "keywords": [], "paperhash": "chen|the_detection_of_distributional_discrepancy_for_text_generation", "original_pdf": "/attachment/38b390ebc596c0ace8731b947b8920236a7b7b90.pdf", "_bibtex": "@misc{\nchen2020the,\ntitle={The Detection of Distributional Discrepancy for Text Generation},\nauthor={Xingyuan Chen and Ping Cai and Peng Jin and Haokun Du and Hongjun Wang and Xinyu Dai and Jiajun Chen},\nyear={2020},\nurl={https://openreview.net/forum?id=SylurJHFPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SylurJHFPS", "replyto": "SylurJHFPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1698/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1698/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575242653227, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1698/Reviewers"], "noninvitees": [], "tcdate": 1570237733582, "tmdate": 1575242653243, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1698/-/Official_Review"}}}, {"id": "SJlBb0_QYB", "original": null, "number": 1, "cdate": 1571159549291, "ddate": null, "tcdate": 1571159549291, "tmdate": 1572972434789, "tddate": null, "forum": "SylurJHFPS", "replyto": "SylurJHFPS", "invitation": "ICLR.cc/2020/Conference/Paper1698/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes an estimator to quantify the difference in distributions between real and generated text based on a classifier that discriminates between real vs generated text.  The methodology is however not particularly well motivated and the experiments do not convince me that this proposed measure is superior to other reasonable choices.  Overall, the writing also contains many grammatical errors and confusing at places.\n\nMajor Comments:\n\n- There are tons of other existing measures of distributional discrepancy that could be applied to this same problem.  Some would be classical approaches (eg. Kullback-Leibler or other f-divergence based on estimated densities, Maximum Mean Discrepancy based on a specific text kernel, etc) while others would be highly related to this work through their use of a classifier.  Here's just a few examples: \n\ni) Lopez-Paz & Oquab (2018). \"Revisiting Classifier Two-Sample Tests\n\": https://arxiv.org/abs/1610.06545 \nii) the Wasserstein critic in Wasserstein-GAN\niii) Sugiyama et al (2012). \"Density Ratio Estimation in Machine Learning\"\n\nGiven all these existing methods (I am sure there are many more), it is unclear to me why the estimator proposed in this paper should be better. The authors need to clarify this both intuitively and empirically via comparison experiments (theoretical comparisons would be nice to see as well).\n\n- The authors are proposing a measure of discrepancy, which is essentially useful as a two-sample statistical test.  As such, the authors should demonstrate a power analysis of their test to detect differences between real vs generated text and show this new test is better than tests based on existing discrepancy measures.\n\n- The authors claim training a generator to minimize their proposed divergence is superior to a standard language GAN. However, the method to achieve this is quite convoluted, and straightforward generator training to minimize D_phi does not appear to work (the authors do not say why either).\n\n\nMinor Comments:\n\n- x needs to be defined before equation (1). \n\n- It is mathematically incorrect to talk about probability density functions when dealing with discrete text. Rather these should be referred to as probability mass functions, likelihoods, or distributions (not \"distributional function\" either). \n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1698/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1698/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["1045258214@qq.com", "1061185275@qq.com", "jandp@pku.edu.cn", "626913553@qq.com", "wanghongjun@swjtu.edu.cn", "daixinyu@nju.edu.cn", "chenjj@nju.edu.cn"], "title": "The Detection of Distributional Discrepancy for Text Generation", "authors": ["Xingyuan Chen", "Ping Cai", "Peng Jin", "Haokun Du", "Hongjun Wang", "Xinyu Dai", "Jiajun Chen"], "pdf": "/pdf/38b390ebc596c0ace8731b947b8920236a7b7b90.pdf", "abstract": "The text generated by neural language models is not as good as the real text. This means that their distributions are different. Generative Adversarial Nets (GAN) are used to alleviate it. However, some researchers argue that GAN variants do not work at all. When both sample quality (such as Bleu) and sample diversity (such as self-Bleu) are taken into account, the GAN variants even are worse than a well-adjusted language model. But, Bleu and self-Bleu can not precisely measure this distributional discrepancy. In fact, how to measure the distributional discrepancy between real text and generated text is still an open problem. In this paper, we theoretically propose two metric functions to measure the distributional difference between real text and generated text. Besides that, a method is put forward to estimate them. First, we evaluate language model with these two functions and find the difference is huge. Then, we try several methods to use the detected discrepancy signal to improve the generator. However the difference becomes even bigger than before. Experimenting on two existing language GANs, the distributional discrepancy between real text and generated text increases with more adversarial learning rounds. It demonstrates both of these language GANs fail. ", "code": "https://github.com/anonymousBoy-sys/seqgan-relgan", "keywords": [], "paperhash": "chen|the_detection_of_distributional_discrepancy_for_text_generation", "original_pdf": "/attachment/38b390ebc596c0ace8731b947b8920236a7b7b90.pdf", "_bibtex": "@misc{\nchen2020the,\ntitle={The Detection of Distributional Discrepancy for Text Generation},\nauthor={Xingyuan Chen and Ping Cai and Peng Jin and Haokun Du and Hongjun Wang and Xinyu Dai and Jiajun Chen},\nyear={2020},\nurl={https://openreview.net/forum?id=SylurJHFPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SylurJHFPS", "replyto": "SylurJHFPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1698/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1698/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575242653227, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1698/Reviewers"], "noninvitees": [], "tcdate": 1570237733582, "tmdate": 1575242653243, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1698/-/Official_Review"}}}, {"id": "HyxQWDWtYH", "original": null, "number": 2, "cdate": 1571522298882, "ddate": null, "tcdate": 1571522298882, "tmdate": 1572972434753, "tddate": null, "forum": "SylurJHFPS", "replyto": "SylurJHFPS", "invitation": "ICLR.cc/2020/Conference/Paper1698/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes two metrics to measure the discrepancy between generated text and real text, based on the discriminator score in GANs. Empirically, it shows that text generated by current text generation methods is still far from human-generated text, as measured by the proposed metric. The writing is a bit rough so sometimes it's hard to figure out what has been done. It's also unclear how the proposed metrics compare to simply using the discriminator for evaluation. Therefore, I'm inclined to reject the current submission.\n\nApproach:\n- The proposed metric essentially relies on the learned discriminator to measure the closeness of generated text vs real text, based on the strong assumption that the learned discriminator is near-optimal. It has been previously shown that learning a classifier from generated and real text does not generalize well (Lowe et al, 2017, Chaganty et al, 2018).\n- What's the advantage of the proposed metric, compared to existing ones, e.g. KL divergence, total variation etc.?\n\nExperiments:\n- What's the accuracy of the learned discriminators? The discrepancy could be due to both data difference and classification error.\n\nMinor:\nBleu -> BLEU\n\nReference:\nTowards an automatic turing test: Learning to evaluate dialogue responses. R. Lowe, M. Noseworthy, I. V. Serban, N. Angelard- Gontier, Y. Bengio, and J. Pineau. 2017.\nThe price of debiasing automatic metrics in natural language evaluation. A. Chaganty, S. Mussmann, and P. Liang. 2018. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1698/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1698/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["1045258214@qq.com", "1061185275@qq.com", "jandp@pku.edu.cn", "626913553@qq.com", "wanghongjun@swjtu.edu.cn", "daixinyu@nju.edu.cn", "chenjj@nju.edu.cn"], "title": "The Detection of Distributional Discrepancy for Text Generation", "authors": ["Xingyuan Chen", "Ping Cai", "Peng Jin", "Haokun Du", "Hongjun Wang", "Xinyu Dai", "Jiajun Chen"], "pdf": "/pdf/38b390ebc596c0ace8731b947b8920236a7b7b90.pdf", "abstract": "The text generated by neural language models is not as good as the real text. This means that their distributions are different. Generative Adversarial Nets (GAN) are used to alleviate it. However, some researchers argue that GAN variants do not work at all. When both sample quality (such as Bleu) and sample diversity (such as self-Bleu) are taken into account, the GAN variants even are worse than a well-adjusted language model. But, Bleu and self-Bleu can not precisely measure this distributional discrepancy. In fact, how to measure the distributional discrepancy between real text and generated text is still an open problem. In this paper, we theoretically propose two metric functions to measure the distributional difference between real text and generated text. Besides that, a method is put forward to estimate them. First, we evaluate language model with these two functions and find the difference is huge. Then, we try several methods to use the detected discrepancy signal to improve the generator. However the difference becomes even bigger than before. Experimenting on two existing language GANs, the distributional discrepancy between real text and generated text increases with more adversarial learning rounds. It demonstrates both of these language GANs fail. ", "code": "https://github.com/anonymousBoy-sys/seqgan-relgan", "keywords": [], "paperhash": "chen|the_detection_of_distributional_discrepancy_for_text_generation", "original_pdf": "/attachment/38b390ebc596c0ace8731b947b8920236a7b7b90.pdf", "_bibtex": "@misc{\nchen2020the,\ntitle={The Detection of Distributional Discrepancy for Text Generation},\nauthor={Xingyuan Chen and Ping Cai and Peng Jin and Haokun Du and Hongjun Wang and Xinyu Dai and Jiajun Chen},\nyear={2020},\nurl={https://openreview.net/forum?id=SylurJHFPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SylurJHFPS", "replyto": "SylurJHFPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1698/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1698/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575242653227, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1698/Reviewers"], "noninvitees": [], "tcdate": 1570237733582, "tmdate": 1575242653243, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1698/-/Official_Review"}}}], "count": 5}