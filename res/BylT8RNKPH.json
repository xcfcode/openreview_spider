{"notes": [{"id": "BylT8RNKPH", "original": "Hygb44P_PS", "number": 1156, "cdate": 1569439317302, "ddate": null, "tcdate": 1569439317302, "tmdate": 1577168212666, "tddate": null, "forum": "BylT8RNKPH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "A Base Model Selection Methodology for Efficient Fine-Tuning", "authors": ["Yosuke Ueno", "Masaaki Kondo"], "authorids": ["ueno@hal.ipc.i.u-tokyo.ac.jp", "kondo@hal.ipc.i.u-tokyo.ac.jp"], "keywords": ["transfer learning", "fine-tuning", "parameter transfer"], "TL;DR": " We propose several metrics to estimate the transferability of pre-trained CNN models for a given target task.", "abstract": "While the accuracy of image classification achieves significant improvement with deep Convolutional Neural Networks (CNN), training a deep CNN is a time-consuming task because it requires a large amount of labeled data and takes a long time to converge even with high performance computing resources.\nFine-tuning, one of the transfer learning methods, is effective in decreasing time and the amount of data necessary for CNN training. It is known that fine-tuning can be performed efficiently if the source and the target tasks have high relativity.\nHowever, the technique to evaluate the relativity or transferability of trained models quantitatively from their parameters has not been established. In this paper, we propose and evaluate several metrics to estimate the transferability of pre-trained CNN models for a given target task by featuremaps of the last convolutional layer.\nWe found that some of the proposed metrics are good predictors of fine-tuned accuracy, but their effectiveness depends on the structure of the network. Therefore, we also propose to combine two metrics to get a generally applicable indicator. \nThe experimental results reveal that one of the combined metrics is well correlated with fine-tuned accuracy in a variety of network structure and our method has a good potential to reduce the burden of CNN training.", "pdf": "/pdf/51b88569ba9c74fd4cf67b41220c53934418a521.pdf", "code": "https://www.dropbox.com/s/ry1gh8bf4yy4qe7/iclr2020_code_submission.tar.gz?dl=0", "paperhash": "ueno|a_base_model_selection_methodology_for_efficient_finetuning", "original_pdf": "/attachment/da74696d0d8f46939cd1d0ecd81bba97ed1cdfdd.pdf", "_bibtex": "@misc{\nueno2020a,\ntitle={A Base Model Selection Methodology for Efficient Fine-Tuning},\nauthor={Yosuke Ueno and Masaaki Kondo},\nyear={2020},\nurl={https://openreview.net/forum?id=BylT8RNKPH}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "60S2eLVFVa", "original": null, "number": 1, "cdate": 1576798715999, "ddate": null, "tcdate": 1576798715999, "tmdate": 1576800920528, "tddate": null, "forum": "BylT8RNKPH", "replyto": "BylT8RNKPH", "invitation": "ICLR.cc/2020/Conference/Paper1156/-/Decision", "content": {"decision": "Reject", "comment": "This paper proposes to speed up finetuning of pretrained deep image classification networks by predicting the success rate of a zoom of pre-trained  networks without completely running them on the test set. The idea is that a sensible measure from the output layer might well correlate with the performance of the network. All reviewers consider this is an important problem and a good direction to make the effort. However, various concerns are raised and all reviewers unanimously rate weak reject. The major concerns include the unclear relationship between the metrics and the fine-tuning performance, non- comprehensive experiments, poor writing quality. The authors respond to Reviewers\u2019 concerns but did not change the major concerns. The ACs concur the concerns and the paper can not be accepted at its current state.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Base Model Selection Methodology for Efficient Fine-Tuning", "authors": ["Yosuke Ueno", "Masaaki Kondo"], "authorids": ["ueno@hal.ipc.i.u-tokyo.ac.jp", "kondo@hal.ipc.i.u-tokyo.ac.jp"], "keywords": ["transfer learning", "fine-tuning", "parameter transfer"], "TL;DR": " We propose several metrics to estimate the transferability of pre-trained CNN models for a given target task.", "abstract": "While the accuracy of image classification achieves significant improvement with deep Convolutional Neural Networks (CNN), training a deep CNN is a time-consuming task because it requires a large amount of labeled data and takes a long time to converge even with high performance computing resources.\nFine-tuning, one of the transfer learning methods, is effective in decreasing time and the amount of data necessary for CNN training. It is known that fine-tuning can be performed efficiently if the source and the target tasks have high relativity.\nHowever, the technique to evaluate the relativity or transferability of trained models quantitatively from their parameters has not been established. In this paper, we propose and evaluate several metrics to estimate the transferability of pre-trained CNN models for a given target task by featuremaps of the last convolutional layer.\nWe found that some of the proposed metrics are good predictors of fine-tuned accuracy, but their effectiveness depends on the structure of the network. Therefore, we also propose to combine two metrics to get a generally applicable indicator. \nThe experimental results reveal that one of the combined metrics is well correlated with fine-tuned accuracy in a variety of network structure and our method has a good potential to reduce the burden of CNN training.", "pdf": "/pdf/51b88569ba9c74fd4cf67b41220c53934418a521.pdf", "code": "https://www.dropbox.com/s/ry1gh8bf4yy4qe7/iclr2020_code_submission.tar.gz?dl=0", "paperhash": "ueno|a_base_model_selection_methodology_for_efficient_finetuning", "original_pdf": "/attachment/da74696d0d8f46939cd1d0ecd81bba97ed1cdfdd.pdf", "_bibtex": "@misc{\nueno2020a,\ntitle={A Base Model Selection Methodology for Efficient Fine-Tuning},\nauthor={Yosuke Ueno and Masaaki Kondo},\nyear={2020},\nurl={https://openreview.net/forum?id=BylT8RNKPH}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "BylT8RNKPH", "replyto": "BylT8RNKPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795712899, "tmdate": 1576800262386, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1156/-/Decision"}}}, {"id": "S1x958KoiH", "original": null, "number": 4, "cdate": 1573783186277, "ddate": null, "tcdate": 1573783186277, "tmdate": 1573783186277, "tddate": null, "forum": "BylT8RNKPH", "replyto": "HkgI8AGkYr", "invitation": "ICLR.cc/2020/Conference/Paper1156/-/Official_Comment", "content": {"title": "Response to review #2", "comment": "1. Why during fine-tuning, do you use SGD instead of Adam?\nReply: Since SGD is simpler than Adam, we thought that the results and findings using SGD could be more general and interpretable.\n\n2. What kind of correlation metrics do you use in Eqn. (4)? And will the correlation metric influence the effectiveness of S4?\nReply: Thanks for asking. We use Pearson's product moment correlation between each channel of the featuremaps. We have made this clear in the revised paper. Since Pearson's product moment correlation is a very general metric, we think there is not any bias for the effectiveness of S4.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1156/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1156/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Base Model Selection Methodology for Efficient Fine-Tuning", "authors": ["Yosuke Ueno", "Masaaki Kondo"], "authorids": ["ueno@hal.ipc.i.u-tokyo.ac.jp", "kondo@hal.ipc.i.u-tokyo.ac.jp"], "keywords": ["transfer learning", "fine-tuning", "parameter transfer"], "TL;DR": " We propose several metrics to estimate the transferability of pre-trained CNN models for a given target task.", "abstract": "While the accuracy of image classification achieves significant improvement with deep Convolutional Neural Networks (CNN), training a deep CNN is a time-consuming task because it requires a large amount of labeled data and takes a long time to converge even with high performance computing resources.\nFine-tuning, one of the transfer learning methods, is effective in decreasing time and the amount of data necessary for CNN training. It is known that fine-tuning can be performed efficiently if the source and the target tasks have high relativity.\nHowever, the technique to evaluate the relativity or transferability of trained models quantitatively from their parameters has not been established. In this paper, we propose and evaluate several metrics to estimate the transferability of pre-trained CNN models for a given target task by featuremaps of the last convolutional layer.\nWe found that some of the proposed metrics are good predictors of fine-tuned accuracy, but their effectiveness depends on the structure of the network. Therefore, we also propose to combine two metrics to get a generally applicable indicator. \nThe experimental results reveal that one of the combined metrics is well correlated with fine-tuned accuracy in a variety of network structure and our method has a good potential to reduce the burden of CNN training.", "pdf": "/pdf/51b88569ba9c74fd4cf67b41220c53934418a521.pdf", "code": "https://www.dropbox.com/s/ry1gh8bf4yy4qe7/iclr2020_code_submission.tar.gz?dl=0", "paperhash": "ueno|a_base_model_selection_methodology_for_efficient_finetuning", "original_pdf": "/attachment/da74696d0d8f46939cd1d0ecd81bba97ed1cdfdd.pdf", "_bibtex": "@misc{\nueno2020a,\ntitle={A Base Model Selection Methodology for Efficient Fine-Tuning},\nauthor={Yosuke Ueno and Masaaki Kondo},\nyear={2020},\nurl={https://openreview.net/forum?id=BylT8RNKPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BylT8RNKPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1156/Authors", "ICLR.cc/2020/Conference/Paper1156/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1156/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1156/Reviewers", "ICLR.cc/2020/Conference/Paper1156/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1156/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1156/Authors|ICLR.cc/2020/Conference/Paper1156/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504160378, "tmdate": 1576860562040, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1156/Authors", "ICLR.cc/2020/Conference/Paper1156/Reviewers", "ICLR.cc/2020/Conference/Paper1156/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1156/-/Official_Comment"}}}, {"id": "r1xwvUFoiB", "original": null, "number": 3, "cdate": 1573783134544, "ddate": null, "tcdate": 1573783134544, "tmdate": 1573783134544, "tddate": null, "forum": "BylT8RNKPH", "replyto": "H1xRBbkYtB", "invitation": "ICLR.cc/2020/Conference/Paper1156/-/Official_Comment", "content": {"title": "Response to review #3", "comment": "1. How many different $\\alpha$ values did the authors consider in the combined metrics? Were the same alpha values used for each experiment?\nCan this approach be generalized to new target datasets?\n\nReply: The value of $\\alpha$ is changed from 0 to 1 with an increment of 0.001 in all the experiments. We have made this clear in the revised paper.\nFor all model architectures and datasets, we searched for a combination of two metrics by changing the alpha that maximizes the average rank correlation coefficients.\nSince we evaluated several cases and found the optimal combination, we believe this approach can be applied even for new datasets. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1156/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1156/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Base Model Selection Methodology for Efficient Fine-Tuning", "authors": ["Yosuke Ueno", "Masaaki Kondo"], "authorids": ["ueno@hal.ipc.i.u-tokyo.ac.jp", "kondo@hal.ipc.i.u-tokyo.ac.jp"], "keywords": ["transfer learning", "fine-tuning", "parameter transfer"], "TL;DR": " We propose several metrics to estimate the transferability of pre-trained CNN models for a given target task.", "abstract": "While the accuracy of image classification achieves significant improvement with deep Convolutional Neural Networks (CNN), training a deep CNN is a time-consuming task because it requires a large amount of labeled data and takes a long time to converge even with high performance computing resources.\nFine-tuning, one of the transfer learning methods, is effective in decreasing time and the amount of data necessary for CNN training. It is known that fine-tuning can be performed efficiently if the source and the target tasks have high relativity.\nHowever, the technique to evaluate the relativity or transferability of trained models quantitatively from their parameters has not been established. In this paper, we propose and evaluate several metrics to estimate the transferability of pre-trained CNN models for a given target task by featuremaps of the last convolutional layer.\nWe found that some of the proposed metrics are good predictors of fine-tuned accuracy, but their effectiveness depends on the structure of the network. Therefore, we also propose to combine two metrics to get a generally applicable indicator. \nThe experimental results reveal that one of the combined metrics is well correlated with fine-tuned accuracy in a variety of network structure and our method has a good potential to reduce the burden of CNN training.", "pdf": "/pdf/51b88569ba9c74fd4cf67b41220c53934418a521.pdf", "code": "https://www.dropbox.com/s/ry1gh8bf4yy4qe7/iclr2020_code_submission.tar.gz?dl=0", "paperhash": "ueno|a_base_model_selection_methodology_for_efficient_finetuning", "original_pdf": "/attachment/da74696d0d8f46939cd1d0ecd81bba97ed1cdfdd.pdf", "_bibtex": "@misc{\nueno2020a,\ntitle={A Base Model Selection Methodology for Efficient Fine-Tuning},\nauthor={Yosuke Ueno and Masaaki Kondo},\nyear={2020},\nurl={https://openreview.net/forum?id=BylT8RNKPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BylT8RNKPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1156/Authors", "ICLR.cc/2020/Conference/Paper1156/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1156/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1156/Reviewers", "ICLR.cc/2020/Conference/Paper1156/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1156/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1156/Authors|ICLR.cc/2020/Conference/Paper1156/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504160378, "tmdate": 1576860562040, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1156/Authors", "ICLR.cc/2020/Conference/Paper1156/Reviewers", "ICLR.cc/2020/Conference/Paper1156/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1156/-/Official_Comment"}}}, {"id": "r1g5hBKsoB", "original": null, "number": 2, "cdate": 1573782962174, "ddate": null, "tcdate": 1573782962174, "tmdate": 1573782962174, "tddate": null, "forum": "BylT8RNKPH", "replyto": "r1lkxZb0FH", "invitation": "ICLR.cc/2020/Conference/Paper1156/-/Official_Comment", "content": {"title": "Response to review #1", "comment": "1. During training, does the author apply weight decay by which some of the metrics could be affected? The reviewer would like to see figures showing the relationship between the weight/feature norms and the metric during training.\n\nReply: We would like to thank the reviewer for pointing this out and valuable suggestions. We did not actually use weight decay during training. Based on the reviewer's suggestion, we have added feature norms for the last convolutional layer into Figure 1 of the revised paper. We found that S1 and S2 do not have any correlation with the feature norm, but S6 does show a negative correlation. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1156/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1156/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Base Model Selection Methodology for Efficient Fine-Tuning", "authors": ["Yosuke Ueno", "Masaaki Kondo"], "authorids": ["ueno@hal.ipc.i.u-tokyo.ac.jp", "kondo@hal.ipc.i.u-tokyo.ac.jp"], "keywords": ["transfer learning", "fine-tuning", "parameter transfer"], "TL;DR": " We propose several metrics to estimate the transferability of pre-trained CNN models for a given target task.", "abstract": "While the accuracy of image classification achieves significant improvement with deep Convolutional Neural Networks (CNN), training a deep CNN is a time-consuming task because it requires a large amount of labeled data and takes a long time to converge even with high performance computing resources.\nFine-tuning, one of the transfer learning methods, is effective in decreasing time and the amount of data necessary for CNN training. It is known that fine-tuning can be performed efficiently if the source and the target tasks have high relativity.\nHowever, the technique to evaluate the relativity or transferability of trained models quantitatively from their parameters has not been established. In this paper, we propose and evaluate several metrics to estimate the transferability of pre-trained CNN models for a given target task by featuremaps of the last convolutional layer.\nWe found that some of the proposed metrics are good predictors of fine-tuned accuracy, but their effectiveness depends on the structure of the network. Therefore, we also propose to combine two metrics to get a generally applicable indicator. \nThe experimental results reveal that one of the combined metrics is well correlated with fine-tuned accuracy in a variety of network structure and our method has a good potential to reduce the burden of CNN training.", "pdf": "/pdf/51b88569ba9c74fd4cf67b41220c53934418a521.pdf", "code": "https://www.dropbox.com/s/ry1gh8bf4yy4qe7/iclr2020_code_submission.tar.gz?dl=0", "paperhash": "ueno|a_base_model_selection_methodology_for_efficient_finetuning", "original_pdf": "/attachment/da74696d0d8f46939cd1d0ecd81bba97ed1cdfdd.pdf", "_bibtex": "@misc{\nueno2020a,\ntitle={A Base Model Selection Methodology for Efficient Fine-Tuning},\nauthor={Yosuke Ueno and Masaaki Kondo},\nyear={2020},\nurl={https://openreview.net/forum?id=BylT8RNKPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BylT8RNKPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1156/Authors", "ICLR.cc/2020/Conference/Paper1156/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1156/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1156/Reviewers", "ICLR.cc/2020/Conference/Paper1156/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1156/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1156/Authors|ICLR.cc/2020/Conference/Paper1156/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504160378, "tmdate": 1576860562040, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1156/Authors", "ICLR.cc/2020/Conference/Paper1156/Reviewers", "ICLR.cc/2020/Conference/Paper1156/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1156/-/Official_Comment"}}}, {"id": "SJxrFStjoH", "original": null, "number": 1, "cdate": 1573782908703, "ddate": null, "tcdate": 1573782908703, "tmdate": 1573782908703, "tddate": null, "forum": "BylT8RNKPH", "replyto": "BylT8RNKPH", "invitation": "ICLR.cc/2020/Conference/Paper1156/-/Official_Comment", "content": {"title": "General response", "comment": "First of all, we would like to express our gratitude to all reviewers for their thoughtful reviews and valuable comments.  We attempted to reply to some of the questions and comments in the individual reply field for each reviewer."}, "signatures": ["ICLR.cc/2020/Conference/Paper1156/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1156/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Base Model Selection Methodology for Efficient Fine-Tuning", "authors": ["Yosuke Ueno", "Masaaki Kondo"], "authorids": ["ueno@hal.ipc.i.u-tokyo.ac.jp", "kondo@hal.ipc.i.u-tokyo.ac.jp"], "keywords": ["transfer learning", "fine-tuning", "parameter transfer"], "TL;DR": " We propose several metrics to estimate the transferability of pre-trained CNN models for a given target task.", "abstract": "While the accuracy of image classification achieves significant improvement with deep Convolutional Neural Networks (CNN), training a deep CNN is a time-consuming task because it requires a large amount of labeled data and takes a long time to converge even with high performance computing resources.\nFine-tuning, one of the transfer learning methods, is effective in decreasing time and the amount of data necessary for CNN training. It is known that fine-tuning can be performed efficiently if the source and the target tasks have high relativity.\nHowever, the technique to evaluate the relativity or transferability of trained models quantitatively from their parameters has not been established. In this paper, we propose and evaluate several metrics to estimate the transferability of pre-trained CNN models for a given target task by featuremaps of the last convolutional layer.\nWe found that some of the proposed metrics are good predictors of fine-tuned accuracy, but their effectiveness depends on the structure of the network. Therefore, we also propose to combine two metrics to get a generally applicable indicator. \nThe experimental results reveal that one of the combined metrics is well correlated with fine-tuned accuracy in a variety of network structure and our method has a good potential to reduce the burden of CNN training.", "pdf": "/pdf/51b88569ba9c74fd4cf67b41220c53934418a521.pdf", "code": "https://www.dropbox.com/s/ry1gh8bf4yy4qe7/iclr2020_code_submission.tar.gz?dl=0", "paperhash": "ueno|a_base_model_selection_methodology_for_efficient_finetuning", "original_pdf": "/attachment/da74696d0d8f46939cd1d0ecd81bba97ed1cdfdd.pdf", "_bibtex": "@misc{\nueno2020a,\ntitle={A Base Model Selection Methodology for Efficient Fine-Tuning},\nauthor={Yosuke Ueno and Masaaki Kondo},\nyear={2020},\nurl={https://openreview.net/forum?id=BylT8RNKPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BylT8RNKPH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1156/Authors", "ICLR.cc/2020/Conference/Paper1156/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1156/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1156/Reviewers", "ICLR.cc/2020/Conference/Paper1156/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1156/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1156/Authors|ICLR.cc/2020/Conference/Paper1156/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504160378, "tmdate": 1576860562040, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1156/Authors", "ICLR.cc/2020/Conference/Paper1156/Reviewers", "ICLR.cc/2020/Conference/Paper1156/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1156/-/Official_Comment"}}}, {"id": "HkgI8AGkYr", "original": null, "number": 1, "cdate": 1570872909814, "ddate": null, "tcdate": 1570872909814, "tmdate": 1572972505476, "tddate": null, "forum": "BylT8RNKPH", "replyto": "BylT8RNKPH", "invitation": "ICLR.cc/2020/Conference/Paper1156/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "In this paper, the authors tried several metrics, from which they pinpoint one as the indicator to select a pretrained model without practically fine-tuning. I appreciate that the authors addressed an important problem, while the experimental setup and results are less convincing. Therefore, the proposed metric(s) and settings in the current shape are not that practical. \n\nPros:\n-\tIn this work, the authors focused on an important problem \u2013 selecting the best pretrained model from a zoo of models without finetuning all of them in a brute-force manner. \n-\tThe idea of applying the metric(s) to select a layer from which the consecutive layers are truncated is intriguing, for the sake of model compression.\n\nCons:\n-\tThe work is more alike a course project than a novel scientific contribution, with all the metrics mainly inherited from the evaluation of clustering and other existing literatures. \n-\tThe experiments are not comprehensive, so that the conclusions drawn are weak and untenable.  \n-\tThe writing with many grammatical errors and typos definitely needs polishing.\n\nDetailed comments:\n1.\tThe authors calculated all the metrics in terms of feature maps in the last layer. Therefore, it is not valid to conclude that other metrics are less effective than sparsity. Some metrics, like fisher discriminator, are likely effective only in the low-level features. It is better for the authors to investigate all metrics in terms of all layers.\n2.\tSince all the pretrained models are pretrained from ImageNet, it is possible that they lose some diversity, which tends to deactivate metrics other than S5 and S6. Unless the authors trained several models from scratch on different datasets and achieved similar results, the conclusion that S5 and S6 are strong is not that convincing.\n3.\tWhy during fine-tuning, do you use SGD instead of Adam?\n4.\tWhat kind of correlation metrics do you use in Eqn. (4)? And will the correlation metric influence the effectiveness of S4?\n5.\tThe most confusing part lies in that the valid metric suggested by the author, i.e., C5,6(0.574), is only an empirical observation on a very limited number of datasets, without any principled methodology. Actually, it is highly possible that given a highly different dataset, the best metric changes. Should the practitioners determine which metric to use first, and even the coefficient to combine metrics?  This is paradox, in my opinion. \n6.\tGrammatical errors and missing details:\no\tAbstract: a variety of network structure -> a variety of network structures\no\tSection 3: The sentences for the three hypotheses, H1/2/3, do not even have verbs in the if part. \no\tSection 3.4: to estimates -> to estimate\no\tSection 3.6: which quantify -> which quantifies\no\t\u2026"}, "signatures": ["ICLR.cc/2020/Conference/Paper1156/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1156/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Base Model Selection Methodology for Efficient Fine-Tuning", "authors": ["Yosuke Ueno", "Masaaki Kondo"], "authorids": ["ueno@hal.ipc.i.u-tokyo.ac.jp", "kondo@hal.ipc.i.u-tokyo.ac.jp"], "keywords": ["transfer learning", "fine-tuning", "parameter transfer"], "TL;DR": " We propose several metrics to estimate the transferability of pre-trained CNN models for a given target task.", "abstract": "While the accuracy of image classification achieves significant improvement with deep Convolutional Neural Networks (CNN), training a deep CNN is a time-consuming task because it requires a large amount of labeled data and takes a long time to converge even with high performance computing resources.\nFine-tuning, one of the transfer learning methods, is effective in decreasing time and the amount of data necessary for CNN training. It is known that fine-tuning can be performed efficiently if the source and the target tasks have high relativity.\nHowever, the technique to evaluate the relativity or transferability of trained models quantitatively from their parameters has not been established. In this paper, we propose and evaluate several metrics to estimate the transferability of pre-trained CNN models for a given target task by featuremaps of the last convolutional layer.\nWe found that some of the proposed metrics are good predictors of fine-tuned accuracy, but their effectiveness depends on the structure of the network. Therefore, we also propose to combine two metrics to get a generally applicable indicator. \nThe experimental results reveal that one of the combined metrics is well correlated with fine-tuned accuracy in a variety of network structure and our method has a good potential to reduce the burden of CNN training.", "pdf": "/pdf/51b88569ba9c74fd4cf67b41220c53934418a521.pdf", "code": "https://www.dropbox.com/s/ry1gh8bf4yy4qe7/iclr2020_code_submission.tar.gz?dl=0", "paperhash": "ueno|a_base_model_selection_methodology_for_efficient_finetuning", "original_pdf": "/attachment/da74696d0d8f46939cd1d0ecd81bba97ed1cdfdd.pdf", "_bibtex": "@misc{\nueno2020a,\ntitle={A Base Model Selection Methodology for Efficient Fine-Tuning},\nauthor={Yosuke Ueno and Masaaki Kondo},\nyear={2020},\nurl={https://openreview.net/forum?id=BylT8RNKPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BylT8RNKPH", "replyto": "BylT8RNKPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1156/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1156/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575599914598, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1156/Reviewers"], "noninvitees": [], "tcdate": 1570237741532, "tmdate": 1575599914612, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1156/-/Official_Review"}}}, {"id": "H1xRBbkYtB", "original": null, "number": 2, "cdate": 1571512645590, "ddate": null, "tcdate": 1571512645590, "tmdate": 1572972505437, "tddate": null, "forum": "BylT8RNKPH", "replyto": "BylT8RNKPH", "invitation": "ICLR.cc/2020/Conference/Paper1156/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper aims to speed up finetuning of pretrained deep image classification networks by predicting the success rate of the process without running it. The authors suggest running samples from the target task on the (trained) source model, and computing a few sensible measures from the final output layer which indicate how well the trained features are separating the target images. Many experiments are presented, and some of them seem promising. \n\nOverall the idea is, while simple, interesting and potentially promising: DL Training costs have been rising significantly in the past few years, and being able to make sensible predictions about which source dataset/task combination best fits a target task would be a great contribution. Nonetheless, there are some methodological concerns that cast doubt about the presented results, which would need to be addressed before making this paper ready for publication.\n\nComments:\n\n1. The authors present multiple experimental results, many of which indicate a somewhat noisy signal. The only method that works on most tasks, combining S5 and S6, is somewhat underreported. How many different \\alpha values did the authors consider? how were they selected? Was the same alpha values used for each all experiments? Given this large set of measures and combinations of measures experimented with in this paper, I am left wondering whether this approach would generalize to new target datasets.\n\n2. A major assumption the authors are making is that there is a single number that determines whether a given trained architecture would transfer well to a new target task. But the finetuning process is affected by many factors (e.g, hyperparameters, random seeds), and thus it might be that with a different hyperparameter selection, the observed correlations would look completely different. I would have liked to see at the very least an analysis of the correlation between multiple runs of finetuning that show that they are well correlated before computing correlations with external measures.\n\n3. The authors point out that transfer learning works poorly on medical imaging (Sato et al., 2018). It would be interesting to experiment with such datasets and observe whether the proposed method is able to make accurate predictions in this domain.\n\n4. The experiments regarding truncating CNNs seem interesting, and I was disappointed to find out they are not part of the main paper.\n\nOther comments:\n\n1. Moons et al. (2016) and Molchanov et al. (2017) speed up *inference* and not training.\n\n2. The authors argue that Mahajan et al. (2018) \"did not apply it (their method) for detection or segmentation tasks.\". However, neither did this paper.\n\n3. Writing: \n-- Several typos and grammatical errors across the paper. For instance:\n- \"*In* many previous research efforts suggested\" (\"in\" should be dropped)\n- Hypothesis H1 is ungrammatical \n\n-- Many of the citations were in the wrong format (intro: Canziani et al. 2016), repetitive (3.5: Yaguchi et al.), etc.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1156/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1156/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Base Model Selection Methodology for Efficient Fine-Tuning", "authors": ["Yosuke Ueno", "Masaaki Kondo"], "authorids": ["ueno@hal.ipc.i.u-tokyo.ac.jp", "kondo@hal.ipc.i.u-tokyo.ac.jp"], "keywords": ["transfer learning", "fine-tuning", "parameter transfer"], "TL;DR": " We propose several metrics to estimate the transferability of pre-trained CNN models for a given target task.", "abstract": "While the accuracy of image classification achieves significant improvement with deep Convolutional Neural Networks (CNN), training a deep CNN is a time-consuming task because it requires a large amount of labeled data and takes a long time to converge even with high performance computing resources.\nFine-tuning, one of the transfer learning methods, is effective in decreasing time and the amount of data necessary for CNN training. It is known that fine-tuning can be performed efficiently if the source and the target tasks have high relativity.\nHowever, the technique to evaluate the relativity or transferability of trained models quantitatively from their parameters has not been established. In this paper, we propose and evaluate several metrics to estimate the transferability of pre-trained CNN models for a given target task by featuremaps of the last convolutional layer.\nWe found that some of the proposed metrics are good predictors of fine-tuned accuracy, but their effectiveness depends on the structure of the network. Therefore, we also propose to combine two metrics to get a generally applicable indicator. \nThe experimental results reveal that one of the combined metrics is well correlated with fine-tuned accuracy in a variety of network structure and our method has a good potential to reduce the burden of CNN training.", "pdf": "/pdf/51b88569ba9c74fd4cf67b41220c53934418a521.pdf", "code": "https://www.dropbox.com/s/ry1gh8bf4yy4qe7/iclr2020_code_submission.tar.gz?dl=0", "paperhash": "ueno|a_base_model_selection_methodology_for_efficient_finetuning", "original_pdf": "/attachment/da74696d0d8f46939cd1d0ecd81bba97ed1cdfdd.pdf", "_bibtex": "@misc{\nueno2020a,\ntitle={A Base Model Selection Methodology for Efficient Fine-Tuning},\nauthor={Yosuke Ueno and Masaaki Kondo},\nyear={2020},\nurl={https://openreview.net/forum?id=BylT8RNKPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BylT8RNKPH", "replyto": "BylT8RNKPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1156/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1156/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575599914598, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1156/Reviewers"], "noninvitees": [], "tcdate": 1570237741532, "tmdate": 1575599914612, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1156/-/Official_Review"}}}, {"id": "r1lkxZb0FH", "original": null, "number": 3, "cdate": 1571848422928, "ddate": null, "tcdate": 1571848422928, "tmdate": 1572972505399, "tddate": null, "forum": "BylT8RNKPH", "replyto": "BylT8RNKPH", "invitation": "ICLR.cc/2020/Conference/Paper1156/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors propose several metrics to evaluate the transferability of pretrained CNN models for a target task without actually fine-tuning the networks to accelerate fine-tuning. \n\nThe paper has done some interesting empirical studies on how to predict the transferability of a neural network. The motivation of performing model selection without actual finetuning has many benefits for practical applications and I believe this is the right direction. In this perspective, the paper is novel. However, my major concern is a lack of in-depth analysis and thorough verification of the proposed metrics.\n\nFirst, there is no clear relationship between the six evaluation metrics and the fine-tuning performance. Figure 1 depicts some correlation, however, it is not clear enough. The difference in ResNet18 is not further investigated. Given the dominant usage of ResNets and its variations in practice, it is important to provide analysis for the reasons behind.\n\nSecond, some of the proposed metrics (S1/S2) are actually closely related with weight norms.  The definition of high value elements in S6 is also based on the absolute difference with the maximum feature map values. Does the author apply weight decay during training? Normally the weight norm will becomes smaller and so could the featuremap values. The S1/S2/S6 metrics could therefore be influenced. I would like to see figures showing the relationship between the weight/feature norms and the metric during training. \n\nThird, it turns out that the only useful metrics are the combination of feature sparsity and feature steepness (i.e., C_56). The authors should make it more specific and clear for their contributions. Why only two combination of the metrics is considered? Does the best selected coefficient generalize to other models and datasets?\n\nFinally, according to https://arxiv.org/abs/1805.08974, better pretrained ImageNet model also generalize better. I would expect a deeper ResNets should outperform AlexNet and VGG16.  What is the relationship between the proposed metrics and the ImageNet performance? \n\nMinor:\n\nThe S3 metric is actually \u201ca ratio of inter-class variance to intra-class variance\u201d rather than \u201c ratio of intra-class variance to inter-class variance\u201d.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1156/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1156/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Base Model Selection Methodology for Efficient Fine-Tuning", "authors": ["Yosuke Ueno", "Masaaki Kondo"], "authorids": ["ueno@hal.ipc.i.u-tokyo.ac.jp", "kondo@hal.ipc.i.u-tokyo.ac.jp"], "keywords": ["transfer learning", "fine-tuning", "parameter transfer"], "TL;DR": " We propose several metrics to estimate the transferability of pre-trained CNN models for a given target task.", "abstract": "While the accuracy of image classification achieves significant improvement with deep Convolutional Neural Networks (CNN), training a deep CNN is a time-consuming task because it requires a large amount of labeled data and takes a long time to converge even with high performance computing resources.\nFine-tuning, one of the transfer learning methods, is effective in decreasing time and the amount of data necessary for CNN training. It is known that fine-tuning can be performed efficiently if the source and the target tasks have high relativity.\nHowever, the technique to evaluate the relativity or transferability of trained models quantitatively from their parameters has not been established. In this paper, we propose and evaluate several metrics to estimate the transferability of pre-trained CNN models for a given target task by featuremaps of the last convolutional layer.\nWe found that some of the proposed metrics are good predictors of fine-tuned accuracy, but their effectiveness depends on the structure of the network. Therefore, we also propose to combine two metrics to get a generally applicable indicator. \nThe experimental results reveal that one of the combined metrics is well correlated with fine-tuned accuracy in a variety of network structure and our method has a good potential to reduce the burden of CNN training.", "pdf": "/pdf/51b88569ba9c74fd4cf67b41220c53934418a521.pdf", "code": "https://www.dropbox.com/s/ry1gh8bf4yy4qe7/iclr2020_code_submission.tar.gz?dl=0", "paperhash": "ueno|a_base_model_selection_methodology_for_efficient_finetuning", "original_pdf": "/attachment/da74696d0d8f46939cd1d0ecd81bba97ed1cdfdd.pdf", "_bibtex": "@misc{\nueno2020a,\ntitle={A Base Model Selection Methodology for Efficient Fine-Tuning},\nauthor={Yosuke Ueno and Masaaki Kondo},\nyear={2020},\nurl={https://openreview.net/forum?id=BylT8RNKPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BylT8RNKPH", "replyto": "BylT8RNKPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1156/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1156/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575599914598, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1156/Reviewers"], "noninvitees": [], "tcdate": 1570237741532, "tmdate": 1575599914612, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1156/-/Official_Review"}}}], "count": 9}