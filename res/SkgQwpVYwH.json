{"notes": [{"id": "SkgQwpVYwH", "original": "HkxDjocPPB", "number": 590, "cdate": 1569439066976, "ddate": null, "tcdate": 1569439066976, "tmdate": 1577168276481, "tddate": null, "forum": "SkgQwpVYwH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Credible Sample Elicitation by Deep Learning, for Deep Learning", "authors": ["Yang Liu", "Zuyue Fu", "Zhuoran Yang", "Zhaoran Wang"], "authorids": ["yangliu@ucsc.edu", "zuyuefu2022@u.northwestern.edu", "zy6@princeton.edu", "zhaoranwang@gmail.com"], "keywords": [], "TL;DR": "This paper proposes a deep learning aided method to elicit credible samples from self-interested agents. ", "abstract": "It is important to collect credible training samples $(x,y)$ for building data-intensive learning systems (e.g., a deep learning system). In the literature, there is a line of studies on eliciting distributional information from self-interested agents who hold a relevant information.  Asking people to report complex distribution $p(x)$, though theoretically viable, is challenging in practice. This is primarily due to the heavy cognitive loads required for human agents to reason and report this high dimensional information. Consider the example where we are interested in building an image classifier via first collecting a certain category of  high-dimensional image data. While classical elicitation results apply to eliciting a complex and generative (and continuous) distribution $p(x)$ for this image data, we are interested in eliciting samples $x_i \\sim p(x)$ from agents. This paper introduces a deep learning aided method to incentivize credible sample contributions from selfish and rational agents. The challenge to do so is to design an incentive-compatible score function to score each reported sample to induce truthful reports, instead of an arbitrary or even adversarial one. We show that with accurate estimation of a certain $f$-divergence function we are able to achieve approximate incentive compatibility in eliciting truthful samples. We then present an efficient estimator with theoretical guarantee via studying the variational forms of $f$-divergence function. Our work complements the literature of information elicitation via introducing the problem of \\emph{sample elicitation}.  We also show a connection between this sample elicitation problem and $f$-GAN, and how this connection can help reconstruct an estimator of the distribution based on collected samples.", "pdf": "/pdf/75470e160d0934494068371f70527f64a36eb4ea.pdf", "paperhash": "liu|credible_sample_elicitation_by_deep_learning_for_deep_learning", "original_pdf": "/attachment/3ddb47f7a74f7728d0febe60fec647d7d7da2f44.pdf", "_bibtex": "@misc{\nliu2020credible,\ntitle={Credible Sample Elicitation by Deep Learning, for Deep Learning},\nauthor={Yang Liu and Zuyue Fu and Zhuoran Yang and Zhaoran Wang},\nyear={2020},\nurl={https://openreview.net/forum?id=SkgQwpVYwH}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 6, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "oecYLGMfCE", "original": null, "number": 1, "cdate": 1576798700632, "ddate": null, "tcdate": 1576798700632, "tmdate": 1576800935315, "tddate": null, "forum": "SkgQwpVYwH", "replyto": "SkgQwpVYwH", "invitation": "ICLR.cc/2020/Conference/Paper590/-/Decision", "content": {"decision": "Reject", "comment": "The primary contribution of this manuscript is a conceptual and theoretical solution to the sample elicitation problem, where agents are asked to report samples. The procedure is implemented using score functions to evaluate the quality of the samples.\n\nThe reviewers and AC agree that the problem studied is timely and interesting, as there is limited work on credible sample elicitation in the literature. However, the reviewers were unconvinced about the motivation of the work, and the clarity of the conceptual results. There is also a lack of empirical evaluation. IN the opinion of the AC, this manuscript, while interesting, can be improved by significant revision for clarity and context, and revisions should ideally include some empirical evaluation.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Credible Sample Elicitation by Deep Learning, for Deep Learning", "authors": ["Yang Liu", "Zuyue Fu", "Zhuoran Yang", "Zhaoran Wang"], "authorids": ["yangliu@ucsc.edu", "zuyuefu2022@u.northwestern.edu", "zy6@princeton.edu", "zhaoranwang@gmail.com"], "keywords": [], "TL;DR": "This paper proposes a deep learning aided method to elicit credible samples from self-interested agents. ", "abstract": "It is important to collect credible training samples $(x,y)$ for building data-intensive learning systems (e.g., a deep learning system). In the literature, there is a line of studies on eliciting distributional information from self-interested agents who hold a relevant information.  Asking people to report complex distribution $p(x)$, though theoretically viable, is challenging in practice. This is primarily due to the heavy cognitive loads required for human agents to reason and report this high dimensional information. Consider the example where we are interested in building an image classifier via first collecting a certain category of  high-dimensional image data. While classical elicitation results apply to eliciting a complex and generative (and continuous) distribution $p(x)$ for this image data, we are interested in eliciting samples $x_i \\sim p(x)$ from agents. This paper introduces a deep learning aided method to incentivize credible sample contributions from selfish and rational agents. The challenge to do so is to design an incentive-compatible score function to score each reported sample to induce truthful reports, instead of an arbitrary or even adversarial one. We show that with accurate estimation of a certain $f$-divergence function we are able to achieve approximate incentive compatibility in eliciting truthful samples. We then present an efficient estimator with theoretical guarantee via studying the variational forms of $f$-divergence function. Our work complements the literature of information elicitation via introducing the problem of \\emph{sample elicitation}.  We also show a connection between this sample elicitation problem and $f$-GAN, and how this connection can help reconstruct an estimator of the distribution based on collected samples.", "pdf": "/pdf/75470e160d0934494068371f70527f64a36eb4ea.pdf", "paperhash": "liu|credible_sample_elicitation_by_deep_learning_for_deep_learning", "original_pdf": "/attachment/3ddb47f7a74f7728d0febe60fec647d7d7da2f44.pdf", "_bibtex": "@misc{\nliu2020credible,\ntitle={Credible Sample Elicitation by Deep Learning, for Deep Learning},\nauthor={Yang Liu and Zuyue Fu and Zhuoran Yang and Zhaoran Wang},\nyear={2020},\nurl={https://openreview.net/forum?id=SkgQwpVYwH}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "SkgQwpVYwH", "replyto": "SkgQwpVYwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795720449, "tmdate": 1576800271278, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper590/-/Decision"}}}, {"id": "B1xaYslOor", "original": null, "number": 5, "cdate": 1573550981081, "ddate": null, "tcdate": 1573550981081, "tmdate": 1573550981081, "tddate": null, "forum": "SkgQwpVYwH", "replyto": "SkgQwpVYwH", "invitation": "ICLR.cc/2020/Conference/Paper590/-/Official_Comment", "content": {"title": "Revision uploaded", "comment": "Dear reviewers,\n\nWe have updated our draft according to your comments and uploaded a revised draft. We have better motivated why we consider using deep learning to design a data-driven elicitation mechanism. We have also fixed typos and made several clarifications. We thank all reviewers for the helpful comments. \n\nBest,\nAuthors"}, "signatures": ["ICLR.cc/2020/Conference/Paper590/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper590/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Credible Sample Elicitation by Deep Learning, for Deep Learning", "authors": ["Yang Liu", "Zuyue Fu", "Zhuoran Yang", "Zhaoran Wang"], "authorids": ["yangliu@ucsc.edu", "zuyuefu2022@u.northwestern.edu", "zy6@princeton.edu", "zhaoranwang@gmail.com"], "keywords": [], "TL;DR": "This paper proposes a deep learning aided method to elicit credible samples from self-interested agents. ", "abstract": "It is important to collect credible training samples $(x,y)$ for building data-intensive learning systems (e.g., a deep learning system). In the literature, there is a line of studies on eliciting distributional information from self-interested agents who hold a relevant information.  Asking people to report complex distribution $p(x)$, though theoretically viable, is challenging in practice. This is primarily due to the heavy cognitive loads required for human agents to reason and report this high dimensional information. Consider the example where we are interested in building an image classifier via first collecting a certain category of  high-dimensional image data. While classical elicitation results apply to eliciting a complex and generative (and continuous) distribution $p(x)$ for this image data, we are interested in eliciting samples $x_i \\sim p(x)$ from agents. This paper introduces a deep learning aided method to incentivize credible sample contributions from selfish and rational agents. The challenge to do so is to design an incentive-compatible score function to score each reported sample to induce truthful reports, instead of an arbitrary or even adversarial one. We show that with accurate estimation of a certain $f$-divergence function we are able to achieve approximate incentive compatibility in eliciting truthful samples. We then present an efficient estimator with theoretical guarantee via studying the variational forms of $f$-divergence function. Our work complements the literature of information elicitation via introducing the problem of \\emph{sample elicitation}.  We also show a connection between this sample elicitation problem and $f$-GAN, and how this connection can help reconstruct an estimator of the distribution based on collected samples.", "pdf": "/pdf/75470e160d0934494068371f70527f64a36eb4ea.pdf", "paperhash": "liu|credible_sample_elicitation_by_deep_learning_for_deep_learning", "original_pdf": "/attachment/3ddb47f7a74f7728d0febe60fec647d7d7da2f44.pdf", "_bibtex": "@misc{\nliu2020credible,\ntitle={Credible Sample Elicitation by Deep Learning, for Deep Learning},\nauthor={Yang Liu and Zuyue Fu and Zhuoran Yang and Zhaoran Wang},\nyear={2020},\nurl={https://openreview.net/forum?id=SkgQwpVYwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SkgQwpVYwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper590/Authors", "ICLR.cc/2020/Conference/Paper590/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper590/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper590/Reviewers", "ICLR.cc/2020/Conference/Paper590/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper590/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper590/Authors|ICLR.cc/2020/Conference/Paper590/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504169177, "tmdate": 1576860536952, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper590/Authors", "ICLR.cc/2020/Conference/Paper590/Reviewers", "ICLR.cc/2020/Conference/Paper590/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper590/-/Official_Comment"}}}, {"id": "BklArEngjr", "original": null, "number": 3, "cdate": 1573073990113, "ddate": null, "tcdate": 1573073990113, "tmdate": 1573116747800, "tddate": null, "forum": "SkgQwpVYwH", "replyto": "SkeHgYNhtB", "invitation": "ICLR.cc/2020/Conference/Paper590/-/Official_Comment", "content": {"title": "thank you for the catches & clarifications", "comment": "Yes, the upper bound should be relevant to y, W_L^1, and W_L^2.  We are sorry about the typo, but it does not affect the results much by slight modification.  In specific, to obtain the accurate result as stated in Theorem A.3, we only need to multiply by \\sum_{j=1}^L A_j in the definition of \\gamma_2 in (A.3) (with Theorem A.3 being unchanged). \n\nIn the proof of Lemma B.2 in Section B.5, the \u201cless than or equal to\u201d sign should be changed to \u201casymptotically less than or equal to\u201d sign. In this way, the inequality holds since both 1/(4L_0) and 1/\\mu_0 are constants. \n\nAgain, we apologize for these typos, and we thank the reviewer for pointing them out for the improvement of our paper.  We have already uploaded a revision to reflect these changes.\n\nTheorem 3.5: \u201cp=q\u201d is a typical argument in information elicitation.  In order to induce truthful reporting, the agent needs to reason about the expectation of his score w.r.t. His true belief. And the agents are assumed to believe that his *truthful* samples come from the same distribution as the ground truth ones. The lower bound is due to the following facts: i) the $(\\delta(n), \\epsilon(n))$ estimation guarantee of the divergence function informs us $\\hat{D}_f(q||p) \\leq D_f(q||p)+\\epsilon(n)$ (with probability at least $1-\\delta(n)$), the true value plus an error term. ii) then p=q allows us to change $D_f(q||p)$ to $D_f(p||p)$.\n\n$\\bar{S}$ is the max of $S$ - but here is a typo, we do not need this $\\bar{S}$ term. The upper bounds holds as $D_f(p||\\tilde{p}) \\geq 0$ by definition of divergence. Plug in we derived the claim. We are updating the draft to reflect the catch. \n\nWe will clarify the relationships between a report x and a reference sample x\u2019 in the introduction. \n\nWe hope this helps clarify the confusions! Again thank you for all the catches. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper590/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper590/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Credible Sample Elicitation by Deep Learning, for Deep Learning", "authors": ["Yang Liu", "Zuyue Fu", "Zhuoran Yang", "Zhaoran Wang"], "authorids": ["yangliu@ucsc.edu", "zuyuefu2022@u.northwestern.edu", "zy6@princeton.edu", "zhaoranwang@gmail.com"], "keywords": [], "TL;DR": "This paper proposes a deep learning aided method to elicit credible samples from self-interested agents. ", "abstract": "It is important to collect credible training samples $(x,y)$ for building data-intensive learning systems (e.g., a deep learning system). In the literature, there is a line of studies on eliciting distributional information from self-interested agents who hold a relevant information.  Asking people to report complex distribution $p(x)$, though theoretically viable, is challenging in practice. This is primarily due to the heavy cognitive loads required for human agents to reason and report this high dimensional information. Consider the example where we are interested in building an image classifier via first collecting a certain category of  high-dimensional image data. While classical elicitation results apply to eliciting a complex and generative (and continuous) distribution $p(x)$ for this image data, we are interested in eliciting samples $x_i \\sim p(x)$ from agents. This paper introduces a deep learning aided method to incentivize credible sample contributions from selfish and rational agents. The challenge to do so is to design an incentive-compatible score function to score each reported sample to induce truthful reports, instead of an arbitrary or even adversarial one. We show that with accurate estimation of a certain $f$-divergence function we are able to achieve approximate incentive compatibility in eliciting truthful samples. We then present an efficient estimator with theoretical guarantee via studying the variational forms of $f$-divergence function. Our work complements the literature of information elicitation via introducing the problem of \\emph{sample elicitation}.  We also show a connection between this sample elicitation problem and $f$-GAN, and how this connection can help reconstruct an estimator of the distribution based on collected samples.", "pdf": "/pdf/75470e160d0934494068371f70527f64a36eb4ea.pdf", "paperhash": "liu|credible_sample_elicitation_by_deep_learning_for_deep_learning", "original_pdf": "/attachment/3ddb47f7a74f7728d0febe60fec647d7d7da2f44.pdf", "_bibtex": "@misc{\nliu2020credible,\ntitle={Credible Sample Elicitation by Deep Learning, for Deep Learning},\nauthor={Yang Liu and Zuyue Fu and Zhuoran Yang and Zhaoran Wang},\nyear={2020},\nurl={https://openreview.net/forum?id=SkgQwpVYwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SkgQwpVYwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper590/Authors", "ICLR.cc/2020/Conference/Paper590/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper590/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper590/Reviewers", "ICLR.cc/2020/Conference/Paper590/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper590/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper590/Authors|ICLR.cc/2020/Conference/Paper590/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504169177, "tmdate": 1576860536952, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper590/Authors", "ICLR.cc/2020/Conference/Paper590/Reviewers", "ICLR.cc/2020/Conference/Paper590/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper590/-/Official_Comment"}}}, {"id": "S1eZp6oliS", "original": null, "number": 2, "cdate": 1573072313101, "ddate": null, "tcdate": 1573072313101, "tmdate": 1573072887536, "tddate": null, "forum": "SkgQwpVYwH", "replyto": "Skgt6nCCKS", "invitation": "ICLR.cc/2020/Conference/Paper590/-/Official_Comment", "content": {"title": "clarification of our motivation, and why deep learning", "comment": "Since ICLR is the premier deep learning conference, we are motivated to collect credible and quality samples from strategic agents (e.g., ordinary people) for deep learning. Naturally, we think it is of interest to try using deep learning techniques to solve the score function design problem via a data-driven approach. Along the way of developing our results, we realized the connection between our elicitation problem and GAN, which we detail in Section 5. \n\nBeyond above, the deep learning based estimators are able to handle complex data. And with our deep learning solution, we are further able to provide estimates for the divergence functions used for our scoring mechanisms, with provable finite sample complexity. In our opinion, these are highly non-trivial contributions. In this paper, we focus on developing theoretical guarantees- other parametric families either can not handle complex data, e.g., it is hard to handle images using kernel methods, or do not have provable guarantees on the sample complexity.\n\nWe wonder whether there is another reason that leads to the reviewer\u2019s recommendation of rejection. We are happy to further clarify. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper590/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper590/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Credible Sample Elicitation by Deep Learning, for Deep Learning", "authors": ["Yang Liu", "Zuyue Fu", "Zhuoran Yang", "Zhaoran Wang"], "authorids": ["yangliu@ucsc.edu", "zuyuefu2022@u.northwestern.edu", "zy6@princeton.edu", "zhaoranwang@gmail.com"], "keywords": [], "TL;DR": "This paper proposes a deep learning aided method to elicit credible samples from self-interested agents. ", "abstract": "It is important to collect credible training samples $(x,y)$ for building data-intensive learning systems (e.g., a deep learning system). In the literature, there is a line of studies on eliciting distributional information from self-interested agents who hold a relevant information.  Asking people to report complex distribution $p(x)$, though theoretically viable, is challenging in practice. This is primarily due to the heavy cognitive loads required for human agents to reason and report this high dimensional information. Consider the example where we are interested in building an image classifier via first collecting a certain category of  high-dimensional image data. While classical elicitation results apply to eliciting a complex and generative (and continuous) distribution $p(x)$ for this image data, we are interested in eliciting samples $x_i \\sim p(x)$ from agents. This paper introduces a deep learning aided method to incentivize credible sample contributions from selfish and rational agents. The challenge to do so is to design an incentive-compatible score function to score each reported sample to induce truthful reports, instead of an arbitrary or even adversarial one. We show that with accurate estimation of a certain $f$-divergence function we are able to achieve approximate incentive compatibility in eliciting truthful samples. We then present an efficient estimator with theoretical guarantee via studying the variational forms of $f$-divergence function. Our work complements the literature of information elicitation via introducing the problem of \\emph{sample elicitation}.  We also show a connection between this sample elicitation problem and $f$-GAN, and how this connection can help reconstruct an estimator of the distribution based on collected samples.", "pdf": "/pdf/75470e160d0934494068371f70527f64a36eb4ea.pdf", "paperhash": "liu|credible_sample_elicitation_by_deep_learning_for_deep_learning", "original_pdf": "/attachment/3ddb47f7a74f7728d0febe60fec647d7d7da2f44.pdf", "_bibtex": "@misc{\nliu2020credible,\ntitle={Credible Sample Elicitation by Deep Learning, for Deep Learning},\nauthor={Yang Liu and Zuyue Fu and Zhuoran Yang and Zhaoran Wang},\nyear={2020},\nurl={https://openreview.net/forum?id=SkgQwpVYwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SkgQwpVYwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper590/Authors", "ICLR.cc/2020/Conference/Paper590/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper590/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper590/Reviewers", "ICLR.cc/2020/Conference/Paper590/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper590/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper590/Authors|ICLR.cc/2020/Conference/Paper590/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504169177, "tmdate": 1576860536952, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper590/Authors", "ICLR.cc/2020/Conference/Paper590/Reviewers", "ICLR.cc/2020/Conference/Paper590/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper590/-/Official_Comment"}}}, {"id": "SkeHgYNhtB", "original": null, "number": 1, "cdate": 1571731693220, "ddate": null, "tcdate": 1571731693220, "tmdate": 1572972576407, "tddate": null, "forum": "SkgQwpVYwH", "replyto": "SkgQwpVYwH", "invitation": "ICLR.cc/2020/Conference/Paper590/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "N/A", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review": "This paper proposes a sample elicitation framework to tackle the problem of eliciting credible samples from agents for complex distributions. The authors suggest that deep neural frameworks can be applied in this framework for sample elicitation through the derivations. The authors also show the connection between the problem of sample elicitation and f-GAN. However, some problems in the proof on sample elicitation should be clarified or carefully explained.\n\n- In (C.15) in Section C.7, why the upper bound is irrelevant to y or W_L^1 or W_L^2? Since we do not have W_L^1 = W_L^2, how to derive the inequality in (C.15)?\n\n- In the proof of Lemma B.2 in Section B.5, why 1/(4L_0) and (1/\\mu_0) are simply removed in the inequality below? \n\n- The inequalities in the proof of Theorem 3.5 in Section B.1 should be further explained. What is the meaning of \u201cagent believes p = q\u201d and how to apply this to the lower bound? What is the meaning of \\bar{S} and how to get these inequalities for the upper bound?\n\nSome minor comments\n- The relation of x\u2019 and x in the first paragraph on page 2 should be further clarified, and some formal definition should be given. The readers who are not familiar with this area would be confused about the problem before reading Section 2.1.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper590/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper590/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Credible Sample Elicitation by Deep Learning, for Deep Learning", "authors": ["Yang Liu", "Zuyue Fu", "Zhuoran Yang", "Zhaoran Wang"], "authorids": ["yangliu@ucsc.edu", "zuyuefu2022@u.northwestern.edu", "zy6@princeton.edu", "zhaoranwang@gmail.com"], "keywords": [], "TL;DR": "This paper proposes a deep learning aided method to elicit credible samples from self-interested agents. ", "abstract": "It is important to collect credible training samples $(x,y)$ for building data-intensive learning systems (e.g., a deep learning system). In the literature, there is a line of studies on eliciting distributional information from self-interested agents who hold a relevant information.  Asking people to report complex distribution $p(x)$, though theoretically viable, is challenging in practice. This is primarily due to the heavy cognitive loads required for human agents to reason and report this high dimensional information. Consider the example where we are interested in building an image classifier via first collecting a certain category of  high-dimensional image data. While classical elicitation results apply to eliciting a complex and generative (and continuous) distribution $p(x)$ for this image data, we are interested in eliciting samples $x_i \\sim p(x)$ from agents. This paper introduces a deep learning aided method to incentivize credible sample contributions from selfish and rational agents. The challenge to do so is to design an incentive-compatible score function to score each reported sample to induce truthful reports, instead of an arbitrary or even adversarial one. We show that with accurate estimation of a certain $f$-divergence function we are able to achieve approximate incentive compatibility in eliciting truthful samples. We then present an efficient estimator with theoretical guarantee via studying the variational forms of $f$-divergence function. Our work complements the literature of information elicitation via introducing the problem of \\emph{sample elicitation}.  We also show a connection between this sample elicitation problem and $f$-GAN, and how this connection can help reconstruct an estimator of the distribution based on collected samples.", "pdf": "/pdf/75470e160d0934494068371f70527f64a36eb4ea.pdf", "paperhash": "liu|credible_sample_elicitation_by_deep_learning_for_deep_learning", "original_pdf": "/attachment/3ddb47f7a74f7728d0febe60fec647d7d7da2f44.pdf", "_bibtex": "@misc{\nliu2020credible,\ntitle={Credible Sample Elicitation by Deep Learning, for Deep Learning},\nauthor={Yang Liu and Zuyue Fu and Zhuoran Yang and Zhaoran Wang},\nyear={2020},\nurl={https://openreview.net/forum?id=SkgQwpVYwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SkgQwpVYwH", "replyto": "SkgQwpVYwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper590/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper590/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576133611024, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper590/Reviewers"], "noninvitees": [], "tcdate": 1570237749943, "tmdate": 1576133611037, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper590/-/Official_Review"}}}, {"id": "Skgt6nCCKS", "original": null, "number": 2, "cdate": 1571904704844, "ddate": null, "tcdate": 1571904704844, "tmdate": 1572972576373, "tddate": null, "forum": "SkgQwpVYwH", "replyto": "SkgQwpVYwH", "invitation": "ICLR.cc/2020/Conference/Paper590/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "- Summary\n\nThis paper studies the sample elicitation problem where agents are asked to report samples. The goal is then to evaluate the quality of these reported samples by means of a scoring function S. Following previous related works, the authors use the equivalence between maximizing the expected proper score and minimizing some f-divergence. Their approach relies on the dual expression of the f-divergence which writes as a maximum over a set of functions t. Theoretical guarantees are given for f-scorings obtained (with or without ground truth samples) by first computing the empirical optimal function t, then plugged to estimate the f-divergence. Finally, a deep learning approach is proposed by considering functions f parameterized as sparse deep neural networks.\n\n- Critics\n\nThe paper is globally well written but not well motivated and sometimes difficult to understand.\nIn particular, the notions of \"elicitation\", \"reports\" and \"score function\" should be defined mathematically more clearly.\nMoreover, the deep learning aspect of the paper is not well motivated and is introduced in a very arbitrary way. Why not choosing another parametric family of functions? Is there another (broad) family of functions for which the computation of the argmin in Equation (4.3) is more tractable in practice?\nA convincing way to motivate this deep learning approach would be to include numerical experiments and to compare to other parametric families.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper590/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper590/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Credible Sample Elicitation by Deep Learning, for Deep Learning", "authors": ["Yang Liu", "Zuyue Fu", "Zhuoran Yang", "Zhaoran Wang"], "authorids": ["yangliu@ucsc.edu", "zuyuefu2022@u.northwestern.edu", "zy6@princeton.edu", "zhaoranwang@gmail.com"], "keywords": [], "TL;DR": "This paper proposes a deep learning aided method to elicit credible samples from self-interested agents. ", "abstract": "It is important to collect credible training samples $(x,y)$ for building data-intensive learning systems (e.g., a deep learning system). In the literature, there is a line of studies on eliciting distributional information from self-interested agents who hold a relevant information.  Asking people to report complex distribution $p(x)$, though theoretically viable, is challenging in practice. This is primarily due to the heavy cognitive loads required for human agents to reason and report this high dimensional information. Consider the example where we are interested in building an image classifier via first collecting a certain category of  high-dimensional image data. While classical elicitation results apply to eliciting a complex and generative (and continuous) distribution $p(x)$ for this image data, we are interested in eliciting samples $x_i \\sim p(x)$ from agents. This paper introduces a deep learning aided method to incentivize credible sample contributions from selfish and rational agents. The challenge to do so is to design an incentive-compatible score function to score each reported sample to induce truthful reports, instead of an arbitrary or even adversarial one. We show that with accurate estimation of a certain $f$-divergence function we are able to achieve approximate incentive compatibility in eliciting truthful samples. We then present an efficient estimator with theoretical guarantee via studying the variational forms of $f$-divergence function. Our work complements the literature of information elicitation via introducing the problem of \\emph{sample elicitation}.  We also show a connection between this sample elicitation problem and $f$-GAN, and how this connection can help reconstruct an estimator of the distribution based on collected samples.", "pdf": "/pdf/75470e160d0934494068371f70527f64a36eb4ea.pdf", "paperhash": "liu|credible_sample_elicitation_by_deep_learning_for_deep_learning", "original_pdf": "/attachment/3ddb47f7a74f7728d0febe60fec647d7d7da2f44.pdf", "_bibtex": "@misc{\nliu2020credible,\ntitle={Credible Sample Elicitation by Deep Learning, for Deep Learning},\nauthor={Yang Liu and Zuyue Fu and Zhuoran Yang and Zhaoran Wang},\nyear={2020},\nurl={https://openreview.net/forum?id=SkgQwpVYwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SkgQwpVYwH", "replyto": "SkgQwpVYwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper590/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper590/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576133611024, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper590/Reviewers"], "noninvitees": [], "tcdate": 1570237749943, "tmdate": 1576133611037, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper590/-/Official_Review"}}}], "count": 7}