{"notes": [{"id": "SJxakiC4u4", "original": "SJgffxeNdN", "number": 43, "cdate": 1553423077170, "ddate": null, "tcdate": 1553423077170, "tmdate": 1562082116153, "tddate": null, "forum": "SJxakiC4u4", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "Unsupervised Continual Learning and Self-Taught Associative Memory Hierarchies", "authors": ["James Smith", "Seth Baer", "Zsolt Kira", "Constantine Dovrolis"], "authorids": ["jamessealesmith@gatech.edu", "cooperbaer.seth@gatech.edu", "zkira@gatech.edu", "constantine@gatech.edu"], "keywords": ["continual learning", "unsupervised learning", "online learning"], "TL;DR": "We introduce unsupervised continual learning (UCL) and a neuro-inspired architecture that solves the UCL problem.", "abstract": "We first pose the Unsupervised Continual Learning (UCL) problem: learning salient representations from a non-stationary stream of unlabeled data in which the number of object classes varies with time. Given limited labeled data just before inference, those representations can also be associated with specific object types to perform classification. To solve the UCL problem, we propose an architecture that involves a single module, called Self-Taught Associative Memory (STAM), which loosely models the function of a cortical column in the mammalian brain. Hierarchies of STAM modules learn based on a combination of Hebbian learning, online clustering, detection of novel patterns and forgetting outliers, and top-down predictions. We illustrate the operation of STAMs in the context of learning handwritten digits in a continual manner with only 3-12 labeled examples per class. STAMs suggest a promising direction to solve the UCL problem without catastrophic forgetting.", "pdf": "/pdf/0160180817a477333ffaf54e8ffdf19deb8ea247.pdf", "paperhash": "smith|unsupervised_continual_learning_and_selftaught_associative_memory_hierarchies"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 2, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "OpenReview.net"}, {"id": "Skg8yoJdYN", "original": null, "number": 1, "cdate": 1554672350207, "ddate": null, "tcdate": 1554672350207, "tmdate": 1555512016617, "tddate": null, "forum": "SJxakiC4u4", "replyto": "SJxakiC4u4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper43/Official_Review", "content": {"title": "Compelling method; some additional analysis would be helpful", "review": "\nPaper Summary\n\nThis paper proposes using hierarchies of Self-Taught Associative Memory (STAM) modules to solve the Unsupervised Continual Learning  (UCL) problem, wherein salient representations must be learned from a stream of unlabeled data that can be used for classification with a small amount of labeled data provided at a later time.  Importantly, the stream is assumed to be non-stationary in the sense that the number of classes in the stream varies with time and carries no associated prior that is known to the modeler.  The paper describes the STAM approach and presents compelling evidence that the representations it learns are well-suited for few-shot classification when compared with reasonable baselines.\n\n\nQuality (Pros)\n(1) The UCL problem is clearly described\n\n(2) The STAM architecture represents an interesting method for learning a representation that takes advantage of hierarchical receptive fields in a similar manner to CNNs, but is adaptable to changing data distributions by design via the online clustering and outlier pruning steps.  \n\n(3) The association of learned representations with different classes is accomplished in a reasonable way\n\n(4) Experimental results suggest that the STAM method consistently outperforms the CAE baseline \n\n\nLimitations (Cons) and Questions\n(1) Additional motivation for the UCL problem would be welcome, as well as experiments on additional datasets that would demonstrate a wider variety of use cases\n\n(2) It is unclear how such hyperparameters as the number of standard differences used in the novelty detector, the number of clusters chosen at each level in the hierarchy, and the allegiance value at which centroids are removed at the classification stage affect performance.  How much computational effort is required to find these values?  And how much does performance depend on them?\n\n(3) Computational efficiency is not touched upon; from a systems standpoint, what is the cost of this model relative to the CAE baseline?\n\n(4) I would suggest adding N = 1,000, 10,000 numbers to Figure 3 -- it is currently hard to read and contextualize.  It would also help to show the difference between 1,00 and 10,000 on a single graph, perhaps, as it is difficult do see the relative changes as currently presented\n\n(5) A point that I found confusing was exactly how the outliers are detected in the second paragraph under equation (5).  Specifically, from my reading, I was under the impression that y_{i+1,m} would be equivalent to c_i(y_{i+1,m}) except for any differences caused by averaging with other overlapping patches.  Is this averaging with overlapping patches then the reason that y_{i+1,m} and c_i(y_{i+1,m}) could be different?  Or have I misunderstood?  Regardless, some clarifying language around this point could be helpful to the reader.\n\n\nClarity\n\nThe presentation is generally clear and well-written, modulo the above suggestions.\n\n\nSignificance\n\nThe STAM approach seems to be a compelling method to solve the UCL problem based on the analysis presented, and comparison to baselines seems reasonable.  This method could be useful in a number of machine learning applications.\n", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper43/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper43/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Continual Learning and Self-Taught Associative Memory Hierarchies", "authors": ["James Smith", "Seth Baer", "Zsolt Kira", "Constantine Dovrolis"], "authorids": ["jamessealesmith@gatech.edu", "cooperbaer.seth@gatech.edu", "zkira@gatech.edu", "constantine@gatech.edu"], "keywords": ["continual learning", "unsupervised learning", "online learning"], "TL;DR": "We introduce unsupervised continual learning (UCL) and a neuro-inspired architecture that solves the UCL problem.", "abstract": "We first pose the Unsupervised Continual Learning (UCL) problem: learning salient representations from a non-stationary stream of unlabeled data in which the number of object classes varies with time. Given limited labeled data just before inference, those representations can also be associated with specific object types to perform classification. To solve the UCL problem, we propose an architecture that involves a single module, called Self-Taught Associative Memory (STAM), which loosely models the function of a cortical column in the mammalian brain. Hierarchies of STAM modules learn based on a combination of Hebbian learning, online clustering, detection of novel patterns and forgetting outliers, and top-down predictions. We illustrate the operation of STAMs in the context of learning handwritten digits in a continual manner with only 3-12 labeled examples per class. STAMs suggest a promising direction to solve the UCL problem without catastrophic forgetting.", "pdf": "/pdf/0160180817a477333ffaf54e8ffdf19deb8ea247.pdf", "paperhash": "smith|unsupervised_continual_learning_and_selftaught_associative_memory_hierarchies"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper43/Official_Review", "cdate": 1553713414648, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "SJxakiC4u4", "replyto": "SJxakiC4u4", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper43/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper43/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713414648, "tmdate": 1555511824808, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper43/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "Byx2ylpGcE", "original": null, "number": 1, "cdate": 1555382244409, "ddate": null, "tcdate": 1555382244409, "tmdate": 1555510974889, "tddate": null, "forum": "SJxakiC4u4", "replyto": "SJxakiC4u4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper43/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Continual Learning and Self-Taught Associative Memory Hierarchies", "authors": ["James Smith", "Seth Baer", "Zsolt Kira", "Constantine Dovrolis"], "authorids": ["jamessealesmith@gatech.edu", "cooperbaer.seth@gatech.edu", "zkira@gatech.edu", "constantine@gatech.edu"], "keywords": ["continual learning", "unsupervised learning", "online learning"], "TL;DR": "We introduce unsupervised continual learning (UCL) and a neuro-inspired architecture that solves the UCL problem.", "abstract": "We first pose the Unsupervised Continual Learning (UCL) problem: learning salient representations from a non-stationary stream of unlabeled data in which the number of object classes varies with time. Given limited labeled data just before inference, those representations can also be associated with specific object types to perform classification. To solve the UCL problem, we propose an architecture that involves a single module, called Self-Taught Associative Memory (STAM), which loosely models the function of a cortical column in the mammalian brain. Hierarchies of STAM modules learn based on a combination of Hebbian learning, online clustering, detection of novel patterns and forgetting outliers, and top-down predictions. We illustrate the operation of STAMs in the context of learning handwritten digits in a continual manner with only 3-12 labeled examples per class. STAMs suggest a promising direction to solve the UCL problem without catastrophic forgetting.", "pdf": "/pdf/0160180817a477333ffaf54e8ffdf19deb8ea247.pdf", "paperhash": "smith|unsupervised_continual_learning_and_selftaught_associative_memory_hierarchies"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper43/Decision", "cdate": 1554736076099, "reply": {"forum": "SJxakiC4u4", "replyto": "SJxakiC4u4", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736076099, "tmdate": 1555510962746, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 3}