{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396328597, "tcdate": 1486396328597, "number": 1, "id": "rJZ3jMUux", "invitation": "ICLR.cc/2017/conference/-/paper53/acceptance", "forum": "ryb-q1Olg", "replyto": "ryb-q1Olg", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "The reviewers pointed out several issues with the paper, and all recommended rejection."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Rectified Factor Networks for Biclustering", "abstract": "Biclustering is evolving into one of the major tools for analyzing large datasets given as matrix of samples times features. Biclustering has several noteworthy applications and has been successfully applied in life sciences and e-commerce for drug design and recommender systems, respectively.\n\nFABIA is one of the most successful biclustering methods and is used by companies like Bayer, Janssen, or Zalando. FABIA is a generative model that represents each bicluster by two sparse membership vectors: one for the samples and one for the features. However, FABIA is restricted to about 20 code units because of the high computational complexity of computing the posterior. Furthermore, code units are sometimes insufficiently decorrelated. Sample membership is difficult to determine because vectors do not have exact zero entries and can have both large positive and large negative values.\n\nWe propose to use the recently introduced unsupervised Deep Learning approach Rectified Factor Networks (RFNs) to overcome the drawbacks of existing biclustering methods. RFNs efficiently construct very sparse, non-linear, high-dimensional representations of the input via their posterior means. RFN learning is a generalized alternating minimization algorithm based on the posterior regularization method which enforces non-negative and normalized posterior means. Each code unit represents a bicluster, where samples for which the code unit is active belong to the bicluster and features that have activating weights to the code unit belong to the bicluster.\n\nOn 400 benchmark datasets with artificially implanted biclusters, RFN significantly outperformed 13 other biclustering competitors including FABIA. In biclustering experiments on three gene expression datasets with known clusters that were determined by separate measurements, RFN biclustering was two times significantly better than the other 13 methods and once on second place. On data of the 1000 Genomes Project, RFN could identify DNA segments which indicate, that interbreeding with other hominins starting already before ancestors of modern humans left Africa.", "pdf": "/pdf/dde80649dd3335264f25e9dfbb0f5cfa392cea7b.pdf", "paperhash": "clevert|rectified_factor_networks_for_biclustering", "conflicts": ["jku.at"], "keywords": ["Deep learning", "Unsupervised Learning", "Applications"], "authors": ["Djork-Arn\u00e9 Clevert", "Thomas Unterthiner", "Sepp Hochreiter"], "authorids": ["okko@bioinf.jku.at", "unterthiner@bioinf.jku.at", "hochreit@bioinf.jku.at"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396329086, "id": "ICLR.cc/2017/conference/-/paper53/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "ryb-q1Olg", "replyto": "ryb-q1Olg", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396329086}}}, {"tddate": null, "tmdate": 1481832680971, "tcdate": 1481832680964, "number": 3, "id": "S1blY_lNe", "invitation": "ICLR.cc/2017/conference/-/paper53/official/review", "forum": "ryb-q1Olg", "replyto": "ryb-q1Olg", "signatures": ["ICLR.cc/2017/conference/paper53/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper53/AnonReviewer1"], "content": {"title": "Interesting work but poorly presented", "rating": "4: Ok but not good enough - rejection", "review": "The paper presents a repurposing of rectified factor networks proposed\nearlier by the same authors to biclustering. The method seems\npotentially quite interesting but the paper has serious problems in\nthe presentation.\n\n\nQuality:\n\nThe method relies mainly on techniques presented in a NIPS 2015 paper\nby (mostly) the same authors. The experimental procedure should be\nclarified further. The results (especially Table 2) seem to depend\ncritically upon the sparsity of the reported clusters, but the authors\ndo not explain in sufficient detail how the sparsity hyperparameter is\ndetermined.\n\n\nClarity:\n\nThe style of writing is terrible and completely unacceptable as a\nscientific publication. The text looks more like an industry white\npaper or advertisement, not an objective scientific paper. A complete\nrewrite would be needed before the paper can be considered for\npublication. Specifically, all references to companies using your\nmethods must be deleted.\n\nAdditionally, Table 1 is essentially unreadable. I would recommend\nusing a figure or cleaning up the table by removing all engineering\nnotation and reporting numbers per 1000 so that e.g. \"0.475 +/- 9e-4\"\nwould become \"475 +/- 0.9\". In general figures would be preferred as a\nprimary means for presenting the results in text while tables can be\nincluded as supplementary information.\n\n\nOriginality:\n\nThe novelty of the work appears limited: the method is mostly based on\na NIPS 2015 paper by the same authors. The experimental evaluation\nappears at least partially novel, but for example the IBD detection is\nvery similar to Hochreiter (2013) but without any comparison.\n\n\nSignificance:\n\nThe authors' strongest claim is based on strong empirical performance\nin their own benchmark problems. It is however unclear how useful this\nwould be to others as there is no code available and the details of\nthe implementation are less than complete. Furthermore, the method\ndepends on many specific tuning parameters whose tuning method is not\nfully defined, leaving it unclear how to guarantee the generalisation\nof the good performance.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Rectified Factor Networks for Biclustering", "abstract": "Biclustering is evolving into one of the major tools for analyzing large datasets given as matrix of samples times features. Biclustering has several noteworthy applications and has been successfully applied in life sciences and e-commerce for drug design and recommender systems, respectively.\n\nFABIA is one of the most successful biclustering methods and is used by companies like Bayer, Janssen, or Zalando. FABIA is a generative model that represents each bicluster by two sparse membership vectors: one for the samples and one for the features. However, FABIA is restricted to about 20 code units because of the high computational complexity of computing the posterior. Furthermore, code units are sometimes insufficiently decorrelated. Sample membership is difficult to determine because vectors do not have exact zero entries and can have both large positive and large negative values.\n\nWe propose to use the recently introduced unsupervised Deep Learning approach Rectified Factor Networks (RFNs) to overcome the drawbacks of existing biclustering methods. RFNs efficiently construct very sparse, non-linear, high-dimensional representations of the input via their posterior means. RFN learning is a generalized alternating minimization algorithm based on the posterior regularization method which enforces non-negative and normalized posterior means. Each code unit represents a bicluster, where samples for which the code unit is active belong to the bicluster and features that have activating weights to the code unit belong to the bicluster.\n\nOn 400 benchmark datasets with artificially implanted biclusters, RFN significantly outperformed 13 other biclustering competitors including FABIA. In biclustering experiments on three gene expression datasets with known clusters that were determined by separate measurements, RFN biclustering was two times significantly better than the other 13 methods and once on second place. On data of the 1000 Genomes Project, RFN could identify DNA segments which indicate, that interbreeding with other hominins starting already before ancestors of modern humans left Africa.", "pdf": "/pdf/dde80649dd3335264f25e9dfbb0f5cfa392cea7b.pdf", "paperhash": "clevert|rectified_factor_networks_for_biclustering", "conflicts": ["jku.at"], "keywords": ["Deep learning", "Unsupervised Learning", "Applications"], "authors": ["Djork-Arn\u00e9 Clevert", "Thomas Unterthiner", "Sepp Hochreiter"], "authorids": ["okko@bioinf.jku.at", "unterthiner@bioinf.jku.at", "hochreit@bioinf.jku.at"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512714218, "id": "ICLR.cc/2017/conference/-/paper53/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper53/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper53/AnonReviewer2", "ICLR.cc/2017/conference/paper53/AnonReviewer3", "ICLR.cc/2017/conference/paper53/AnonReviewer1"], "reply": {"forum": "ryb-q1Olg", "replyto": "ryb-q1Olg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper53/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper53/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512714218}}}, {"tddate": null, "tmdate": 1481524028193, "tcdate": 1481524028185, "number": 2, "id": "ryVHQTjmx", "invitation": "ICLR.cc/2017/conference/-/paper53/official/review", "forum": "ryb-q1Olg", "replyto": "ryb-q1Olg", "signatures": ["ICLR.cc/2017/conference/paper53/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper53/AnonReviewer3"], "content": {"title": "Interesting paper, but the exact model being used is difficult to understand. ", "rating": "5: Marginally below acceptance threshold", "review": "Clarity: The novel contribution of the paper --- Section 2.2 --- was very difficult to understand. The notation seemed inconsistent (particularly the use of l, p, and m), and I am still not confident that I understand the model being used.\n\nOriginality: The novelty comes from applying the RFN model (including the ReLU non-linearity and dropout training) to the problem of biclustering. It sounds like a good idea. \n\nSignificance: The proposed algorithm appears to be a useful tool for unsupervised data modelling, and the authors make a convincing argument that it is significant. (I.E. The previous state-of-the-art, FABIA, is widely used and this method both outperforms and addresses some of the practical difficulties with that method.)\n\nQuality: The experiments are high-quality. \n\nComments:\n1) The introduction claims that this method is much faster than FABIA because the use of rectified units allow it to be run on GPUs. It is not clear to me how this works. How many biclusters can be supported with this method? It looks like the number of biclusters used for this method in the experiments is only 3-5?\n2) The introduction claims that using dropout during training increases sparsity in the bicluster assignments. This seems like a reasonable hypothesis, but this claim should be supported with a better argument or experiments.\n3) How is the model deep? The model isn't deep just because it uses a relu and dropout.", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Rectified Factor Networks for Biclustering", "abstract": "Biclustering is evolving into one of the major tools for analyzing large datasets given as matrix of samples times features. Biclustering has several noteworthy applications and has been successfully applied in life sciences and e-commerce for drug design and recommender systems, respectively.\n\nFABIA is one of the most successful biclustering methods and is used by companies like Bayer, Janssen, or Zalando. FABIA is a generative model that represents each bicluster by two sparse membership vectors: one for the samples and one for the features. However, FABIA is restricted to about 20 code units because of the high computational complexity of computing the posterior. Furthermore, code units are sometimes insufficiently decorrelated. Sample membership is difficult to determine because vectors do not have exact zero entries and can have both large positive and large negative values.\n\nWe propose to use the recently introduced unsupervised Deep Learning approach Rectified Factor Networks (RFNs) to overcome the drawbacks of existing biclustering methods. RFNs efficiently construct very sparse, non-linear, high-dimensional representations of the input via their posterior means. RFN learning is a generalized alternating minimization algorithm based on the posterior regularization method which enforces non-negative and normalized posterior means. Each code unit represents a bicluster, where samples for which the code unit is active belong to the bicluster and features that have activating weights to the code unit belong to the bicluster.\n\nOn 400 benchmark datasets with artificially implanted biclusters, RFN significantly outperformed 13 other biclustering competitors including FABIA. In biclustering experiments on three gene expression datasets with known clusters that were determined by separate measurements, RFN biclustering was two times significantly better than the other 13 methods and once on second place. On data of the 1000 Genomes Project, RFN could identify DNA segments which indicate, that interbreeding with other hominins starting already before ancestors of modern humans left Africa.", "pdf": "/pdf/dde80649dd3335264f25e9dfbb0f5cfa392cea7b.pdf", "paperhash": "clevert|rectified_factor_networks_for_biclustering", "conflicts": ["jku.at"], "keywords": ["Deep learning", "Unsupervised Learning", "Applications"], "authors": ["Djork-Arn\u00e9 Clevert", "Thomas Unterthiner", "Sepp Hochreiter"], "authorids": ["okko@bioinf.jku.at", "unterthiner@bioinf.jku.at", "hochreit@bioinf.jku.at"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512714218, "id": "ICLR.cc/2017/conference/-/paper53/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper53/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper53/AnonReviewer2", "ICLR.cc/2017/conference/paper53/AnonReviewer3", "ICLR.cc/2017/conference/paper53/AnonReviewer1"], "reply": {"forum": "ryb-q1Olg", "replyto": "ryb-q1Olg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper53/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper53/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512714218}}}, {"tddate": null, "tmdate": 1481174536089, "tcdate": 1481174376851, "number": 1, "id": "ByW_pPL7e", "invitation": "ICLR.cc/2017/conference/-/paper53/official/review", "forum": "ryb-q1Olg", "replyto": "ryb-q1Olg", "signatures": ["ICLR.cc/2017/conference/paper53/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper53/AnonReviewer2"], "content": {"title": "Review on the paper", "rating": "5: Marginally below acceptance threshold", "review": "This paper applies RFN for biclustering to overcome the drawbacks in FABIA. The proposed method performs best among 14 biclustering methods, However, my first concern is that from the methodological point of view, the novelty of the proposed method seems small. The authors replied to the same question which another reviewer gave, but the replies were not so convincing. \n\nThis paper was actually difficult for me to follow. For instance, in Figure 1, a bicluster matrix is constructed as an outer product of $h$ and $w$. $h$ is a hidden unit, but what is $w$? I could not find any definition. Furthermore, I could not know how $h$ is estimated in this method. Therefore, I do NOT understand how this method performs biclustering. \n\nTotally, I am not sure that this paper is suitable for publication. \n\nProns:\nEmpirical performance is good.\n\nCons:\nNovelty of the proposed method\nSome description in the paper is unclear.\n\n", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Rectified Factor Networks for Biclustering", "abstract": "Biclustering is evolving into one of the major tools for analyzing large datasets given as matrix of samples times features. Biclustering has several noteworthy applications and has been successfully applied in life sciences and e-commerce for drug design and recommender systems, respectively.\n\nFABIA is one of the most successful biclustering methods and is used by companies like Bayer, Janssen, or Zalando. FABIA is a generative model that represents each bicluster by two sparse membership vectors: one for the samples and one for the features. However, FABIA is restricted to about 20 code units because of the high computational complexity of computing the posterior. Furthermore, code units are sometimes insufficiently decorrelated. Sample membership is difficult to determine because vectors do not have exact zero entries and can have both large positive and large negative values.\n\nWe propose to use the recently introduced unsupervised Deep Learning approach Rectified Factor Networks (RFNs) to overcome the drawbacks of existing biclustering methods. RFNs efficiently construct very sparse, non-linear, high-dimensional representations of the input via their posterior means. RFN learning is a generalized alternating minimization algorithm based on the posterior regularization method which enforces non-negative and normalized posterior means. Each code unit represents a bicluster, where samples for which the code unit is active belong to the bicluster and features that have activating weights to the code unit belong to the bicluster.\n\nOn 400 benchmark datasets with artificially implanted biclusters, RFN significantly outperformed 13 other biclustering competitors including FABIA. In biclustering experiments on three gene expression datasets with known clusters that were determined by separate measurements, RFN biclustering was two times significantly better than the other 13 methods and once on second place. On data of the 1000 Genomes Project, RFN could identify DNA segments which indicate, that interbreeding with other hominins starting already before ancestors of modern humans left Africa.", "pdf": "/pdf/dde80649dd3335264f25e9dfbb0f5cfa392cea7b.pdf", "paperhash": "clevert|rectified_factor_networks_for_biclustering", "conflicts": ["jku.at"], "keywords": ["Deep learning", "Unsupervised Learning", "Applications"], "authors": ["Djork-Arn\u00e9 Clevert", "Thomas Unterthiner", "Sepp Hochreiter"], "authorids": ["okko@bioinf.jku.at", "unterthiner@bioinf.jku.at", "hochreit@bioinf.jku.at"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512714218, "id": "ICLR.cc/2017/conference/-/paper53/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper53/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper53/AnonReviewer2", "ICLR.cc/2017/conference/paper53/AnonReviewer3", "ICLR.cc/2017/conference/paper53/AnonReviewer1"], "reply": {"forum": "ryb-q1Olg", "replyto": "ryb-q1Olg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper53/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper53/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512714218}}}, {"tddate": null, "tmdate": 1481005828625, "tcdate": 1481005828616, "number": 1, "id": "B1aWiA7Ql", "invitation": "ICLR.cc/2017/conference/-/paper53/public/comment", "forum": "ryb-q1Olg", "replyto": "ryOzNR0fx", "signatures": ["~Djork-Arne_Clevert1"], "readers": ["everyone"], "writers": ["~Djork-Arne_Clevert1"], "content": {"title": "Novelty of the submission", "comment": "In the last decade biclustering evolved into a major and very successful technique in statistics and bioinformatics. Several high impact discoveries often published in journals like Nature were made possible by biclustering which gave new biological or medical insights. Biclustering is now established as a reliable tool in statistics and bioinformatics. At the same time, deep learning grew into one of the most successful fields in machine learning. In deep learning, an important invention was rectified linear units (ReLUs).\nFor the first time we bridge these two successful fields. Our novel insight is that ReLUs can be considered as biclustering units: they are activated for particular samples and they are driven by particular features (the samples and features that form the bicluster). Our unsupervised deep learning approach RFN is based on rectifying and ReLUs, therefore, allows for detecting biclusters and realizes biclustering.\n\nNovel in this contribution is (1) to bridge biclustering and deep learning and (2) to consider ReLUs as biclustering units. To implement biclustering, it is essential to construct sparse codes and to construct sparse weight matrices. We use our RFN approach which must be modified to produce sparse weight vectors using a Laplace prior and is equipped with dropout to increase sparseness of the code. Consequently, novel in contrast to RFN is (1) sparse weights via Laplace distribution and (2) increasing sparseness of the code via dropout. The dropout procedure must be carefully implemented since dropout must be applied to the posterior, that is, we drop out the mean value of the variational distribution. Only these two sparseness-related adjustments allow to realize biclustering with RFNs. \n \nThe most relevant novelty is that we demonstrate that RFNs used for biclustering is currently the best biclustering method if compared to the best performing approaches to biclustering [1]. We believe that unsupervised deep learning methods like RFN for biclustering will have impact on the field of life sciences and medicine. \n\n\n[1] A. Kasim, Z, Shkedy, S. Kaiser, W. Talloen, S. Hochreiter. Applied Biclustering Methods for Big and High Dimensional Data Using R. Chapman and Hall / CRC Biostatistics Series, Taylor & Francis Group, 2016"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Rectified Factor Networks for Biclustering", "abstract": "Biclustering is evolving into one of the major tools for analyzing large datasets given as matrix of samples times features. Biclustering has several noteworthy applications and has been successfully applied in life sciences and e-commerce for drug design and recommender systems, respectively.\n\nFABIA is one of the most successful biclustering methods and is used by companies like Bayer, Janssen, or Zalando. FABIA is a generative model that represents each bicluster by two sparse membership vectors: one for the samples and one for the features. However, FABIA is restricted to about 20 code units because of the high computational complexity of computing the posterior. Furthermore, code units are sometimes insufficiently decorrelated. Sample membership is difficult to determine because vectors do not have exact zero entries and can have both large positive and large negative values.\n\nWe propose to use the recently introduced unsupervised Deep Learning approach Rectified Factor Networks (RFNs) to overcome the drawbacks of existing biclustering methods. RFNs efficiently construct very sparse, non-linear, high-dimensional representations of the input via their posterior means. RFN learning is a generalized alternating minimization algorithm based on the posterior regularization method which enforces non-negative and normalized posterior means. Each code unit represents a bicluster, where samples for which the code unit is active belong to the bicluster and features that have activating weights to the code unit belong to the bicluster.\n\nOn 400 benchmark datasets with artificially implanted biclusters, RFN significantly outperformed 13 other biclustering competitors including FABIA. In biclustering experiments on three gene expression datasets with known clusters that were determined by separate measurements, RFN biclustering was two times significantly better than the other 13 methods and once on second place. On data of the 1000 Genomes Project, RFN could identify DNA segments which indicate, that interbreeding with other hominins starting already before ancestors of modern humans left Africa.", "pdf": "/pdf/dde80649dd3335264f25e9dfbb0f5cfa392cea7b.pdf", "paperhash": "clevert|rectified_factor_networks_for_biclustering", "conflicts": ["jku.at"], "keywords": ["Deep learning", "Unsupervised Learning", "Applications"], "authors": ["Djork-Arn\u00e9 Clevert", "Thomas Unterthiner", "Sepp Hochreiter"], "authorids": ["okko@bioinf.jku.at", "unterthiner@bioinf.jku.at", "hochreit@bioinf.jku.at"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287748442, "id": "ICLR.cc/2017/conference/-/paper53/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ryb-q1Olg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper53/reviewers", "ICLR.cc/2017/conference/paper53/areachairs"], "cdate": 1485287748442}}}, {"tddate": null, "tmdate": 1480676367976, "tcdate": 1480676367972, "number": 1, "id": "ryOzNR0fx", "invitation": "ICLR.cc/2017/conference/-/paper53/pre-review/question", "forum": "ryb-q1Olg", "replyto": "ryb-q1Olg", "signatures": ["ICLR.cc/2017/conference/paper53/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper53/AnonReviewer1"], "content": {"title": "Relationship with the previous NIPS paper", "question": "Thanks for the interesting paper!\n\nThe paper appears to be methodologically very closely related to the NIPS 2015 paper of Clevert et al. as almost all methods description seems to refer to that. Could you please provide a brief summary of what are key similarities and differences and what do you believe is the novelty of the current submission?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Rectified Factor Networks for Biclustering", "abstract": "Biclustering is evolving into one of the major tools for analyzing large datasets given as matrix of samples times features. Biclustering has several noteworthy applications and has been successfully applied in life sciences and e-commerce for drug design and recommender systems, respectively.\n\nFABIA is one of the most successful biclustering methods and is used by companies like Bayer, Janssen, or Zalando. FABIA is a generative model that represents each bicluster by two sparse membership vectors: one for the samples and one for the features. However, FABIA is restricted to about 20 code units because of the high computational complexity of computing the posterior. Furthermore, code units are sometimes insufficiently decorrelated. Sample membership is difficult to determine because vectors do not have exact zero entries and can have both large positive and large negative values.\n\nWe propose to use the recently introduced unsupervised Deep Learning approach Rectified Factor Networks (RFNs) to overcome the drawbacks of existing biclustering methods. RFNs efficiently construct very sparse, non-linear, high-dimensional representations of the input via their posterior means. RFN learning is a generalized alternating minimization algorithm based on the posterior regularization method which enforces non-negative and normalized posterior means. Each code unit represents a bicluster, where samples for which the code unit is active belong to the bicluster and features that have activating weights to the code unit belong to the bicluster.\n\nOn 400 benchmark datasets with artificially implanted biclusters, RFN significantly outperformed 13 other biclustering competitors including FABIA. In biclustering experiments on three gene expression datasets with known clusters that were determined by separate measurements, RFN biclustering was two times significantly better than the other 13 methods and once on second place. On data of the 1000 Genomes Project, RFN could identify DNA segments which indicate, that interbreeding with other hominins starting already before ancestors of modern humans left Africa.", "pdf": "/pdf/dde80649dd3335264f25e9dfbb0f5cfa392cea7b.pdf", "paperhash": "clevert|rectified_factor_networks_for_biclustering", "conflicts": ["jku.at"], "keywords": ["Deep learning", "Unsupervised Learning", "Applications"], "authors": ["Djork-Arn\u00e9 Clevert", "Thomas Unterthiner", "Sepp Hochreiter"], "authorids": ["okko@bioinf.jku.at", "unterthiner@bioinf.jku.at", "hochreit@bioinf.jku.at"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959490408, "id": "ICLR.cc/2017/conference/-/paper53/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper53/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper53/AnonReviewer1"], "reply": {"forum": "ryb-q1Olg", "replyto": "ryb-q1Olg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper53/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper53/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959490408}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1478126073331, "tcdate": 1478126073318, "number": 53, "id": "ryb-q1Olg", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "ryb-q1Olg", "signatures": ["~Djork-Arne_Clevert1"], "readers": ["everyone"], "content": {"TL;DR": "", "title": "Rectified Factor Networks for Biclustering", "abstract": "Biclustering is evolving into one of the major tools for analyzing large datasets given as matrix of samples times features. Biclustering has several noteworthy applications and has been successfully applied in life sciences and e-commerce for drug design and recommender systems, respectively.\n\nFABIA is one of the most successful biclustering methods and is used by companies like Bayer, Janssen, or Zalando. FABIA is a generative model that represents each bicluster by two sparse membership vectors: one for the samples and one for the features. However, FABIA is restricted to about 20 code units because of the high computational complexity of computing the posterior. Furthermore, code units are sometimes insufficiently decorrelated. Sample membership is difficult to determine because vectors do not have exact zero entries and can have both large positive and large negative values.\n\nWe propose to use the recently introduced unsupervised Deep Learning approach Rectified Factor Networks (RFNs) to overcome the drawbacks of existing biclustering methods. RFNs efficiently construct very sparse, non-linear, high-dimensional representations of the input via their posterior means. RFN learning is a generalized alternating minimization algorithm based on the posterior regularization method which enforces non-negative and normalized posterior means. Each code unit represents a bicluster, where samples for which the code unit is active belong to the bicluster and features that have activating weights to the code unit belong to the bicluster.\n\nOn 400 benchmark datasets with artificially implanted biclusters, RFN significantly outperformed 13 other biclustering competitors including FABIA. In biclustering experiments on three gene expression datasets with known clusters that were determined by separate measurements, RFN biclustering was two times significantly better than the other 13 methods and once on second place. On data of the 1000 Genomes Project, RFN could identify DNA segments which indicate, that interbreeding with other hominins starting already before ancestors of modern humans left Africa.", "pdf": "/pdf/dde80649dd3335264f25e9dfbb0f5cfa392cea7b.pdf", "paperhash": "clevert|rectified_factor_networks_for_biclustering", "conflicts": ["jku.at"], "keywords": ["Deep learning", "Unsupervised Learning", "Applications"], "authors": ["Djork-Arn\u00e9 Clevert", "Thomas Unterthiner", "Sepp Hochreiter"], "authorids": ["okko@bioinf.jku.at", "unterthiner@bioinf.jku.at", "hochreit@bioinf.jku.at"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 6, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}], "count": 7}