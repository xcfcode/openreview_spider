{"notes": [{"id": "iUTHidd-ylL", "original": "U3ObVTCA6Yd", "number": 1563, "cdate": 1601308173368, "ddate": null, "tcdate": 1601308173368, "tmdate": 1614985634319, "tddate": null, "forum": "iUTHidd-ylL", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Matrix Data Deep Decoder - Geometric Learning for Structured Data Completion", "authorids": ["~Maria_Schmidt1", "~Alexander_Bronstein1"], "authors": ["Maria Schmidt", "Alexander Bronstein"], "keywords": ["Deep learning", "Non-Euclidean data completion", "Sparse matrices", "Recommender systems", "Recommendation systems", "Sparse representations"], "abstract": "In this work, we present a fully convolutional end to end method to reconstruct corrupted sparse matrices of Non-Euclidean data. The classic example for such matrices is recommender systems matrices where the rows/columns represent items/users and the entries are ratings. The method we present is inspired by the surprising and spectacular success of methods like$\"$  deep image prior$\"$  and $``$deep decoder$\"$  for corrupted image completion. In sharp contrast to previous Matrix Completion methods wherein the latent matrix or its factors directly serve as the optimization variable, in the method we present, the matrix is parameterized as the weights of a graph neural network acting on a random noisy input. Then we are tuning the network parameters to get a result as close as possible to the initial sparse matrix (using its factors) getting that way state of the art matrix completion result. In addition to the conceptual simplicity of our method, which is just Non-Euclidean generalization of deep image priors, it holds fewer parameters than previously presented methods which makes the parameters more trackable and the method more computationally efficient and more applicable for the real-world tasks. The method also achieves state-of-the-art results for the matrix completion task on the classical benchmarks in the field. The method also surprisingly shows that untrained convolutional neural network can use a good prior not only for image completion but also for Matrix Completion when redefined for graphs.", "one-sentence_summary": "Non-Euclidean Data Matrix Completion with end-to-end fully convolutional graph neural network based on Deep Image Prior Generalization  ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "schmidt|matrix_data_deep_decoder_geometric_learning_for_structured_data_completion", "pdf": "/pdf/38ffb209883019f8715291b06a7b8004b3c591cb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=cXMF1NKpXx", "_bibtex": "@misc{\nschmidt2021matrix,\ntitle={Matrix Data Deep Decoder - Geometric Learning for Structured Data Completion},\nauthor={Maria Schmidt and Alexander Bronstein},\nyear={2021},\nurl={https://openreview.net/forum?id=iUTHidd-ylL}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "boajrC5EMKS", "original": null, "number": 1, "cdate": 1610040526947, "ddate": null, "tcdate": 1610040526947, "tmdate": 1610474136070, "tddate": null, "forum": "iUTHidd-ylL", "replyto": "iUTHidd-ylL", "invitation": "ICLR.cc/2021/Conference/Paper1563/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The focus of this paper is to analyze an end to end network to reconstruct matrices originating from non-Euclidean data which are corrupted. The authors present an untrained network for this task. In the review period the reviewers raised a variety of concerns including concerns about novelty of the paper with respect to existing work, technical depth and clarity. The authors did not respond to these concerns. Therefore, I recommend rejection."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix Data Deep Decoder - Geometric Learning for Structured Data Completion", "authorids": ["~Maria_Schmidt1", "~Alexander_Bronstein1"], "authors": ["Maria Schmidt", "Alexander Bronstein"], "keywords": ["Deep learning", "Non-Euclidean data completion", "Sparse matrices", "Recommender systems", "Recommendation systems", "Sparse representations"], "abstract": "In this work, we present a fully convolutional end to end method to reconstruct corrupted sparse matrices of Non-Euclidean data. The classic example for such matrices is recommender systems matrices where the rows/columns represent items/users and the entries are ratings. The method we present is inspired by the surprising and spectacular success of methods like$\"$  deep image prior$\"$  and $``$deep decoder$\"$  for corrupted image completion. In sharp contrast to previous Matrix Completion methods wherein the latent matrix or its factors directly serve as the optimization variable, in the method we present, the matrix is parameterized as the weights of a graph neural network acting on a random noisy input. Then we are tuning the network parameters to get a result as close as possible to the initial sparse matrix (using its factors) getting that way state of the art matrix completion result. In addition to the conceptual simplicity of our method, which is just Non-Euclidean generalization of deep image priors, it holds fewer parameters than previously presented methods which makes the parameters more trackable and the method more computationally efficient and more applicable for the real-world tasks. The method also achieves state-of-the-art results for the matrix completion task on the classical benchmarks in the field. The method also surprisingly shows that untrained convolutional neural network can use a good prior not only for image completion but also for Matrix Completion when redefined for graphs.", "one-sentence_summary": "Non-Euclidean Data Matrix Completion with end-to-end fully convolutional graph neural network based on Deep Image Prior Generalization  ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "schmidt|matrix_data_deep_decoder_geometric_learning_for_structured_data_completion", "pdf": "/pdf/38ffb209883019f8715291b06a7b8004b3c591cb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=cXMF1NKpXx", "_bibtex": "@misc{\nschmidt2021matrix,\ntitle={Matrix Data Deep Decoder - Geometric Learning for Structured Data Completion},\nauthor={Maria Schmidt and Alexander Bronstein},\nyear={2021},\nurl={https://openreview.net/forum?id=iUTHidd-ylL}\n}"}, "tags": [], "invitation": {"reply": {"forum": "iUTHidd-ylL", "replyto": "iUTHidd-ylL", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040526934, "tmdate": 1610474136054, "id": "ICLR.cc/2021/Conference/Paper1563/-/Decision"}}}, {"id": "VfcJ4UB9QSq", "original": null, "number": 1, "cdate": 1603325370798, "ddate": null, "tcdate": 1603325370798, "tmdate": 1605024414055, "tddate": null, "forum": "iUTHidd-ylL", "replyto": "iUTHidd-ylL", "invitation": "ICLR.cc/2021/Conference/Paper1563/-/Official_Review", "content": {"title": "The main contribution of this paper is to adopt matrix data deep decoder for matrix completion task.", "review": "In this work,  the authors addressed the problem of Matrix Completion on Non-Euclidean domains.  They mainly adopt the method Matrix Data Deep Decoder, inspired by the Deep Decoder method for Image Completion. Here are my main concerns:\n\n1. The technical contributions of this paper is limited since it mainly adopts existing methods, like Matrix Completion + Deep Decoder + multi-graph convolution. It seems for me this paper is more like an engineering paper consist of lots of stuff. It is better to release the source code to understand this kind of composition stuffs.\n\n2. The motivation of this work is also not very sound. The authors spend lots of content on the related work. However, the main idea is only presented in a presuppose-code style in Page 6, which is not very clear.\n\n3. In the experimental parts. Why use different methods for different dataset in Table 2(a), (b), (c)?  Is it possible to conduct all of the baselines for all datasets? Also,  the matrix completion has been studied for many years with many solid theory results,  the baselines in the experiments are not SOAT.\n\nTypos:\nIn page 4: stracture -------> structure\nIn page 7:  can be found in the work of [30] -----> the cite form is not correct.\n\nIn summary, the paper show that a GCN network is a good prior for the Matrix completion problem. However,  the technical contributions of this paper is limited and the overall presentation can be further improved.", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1563/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1563/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix Data Deep Decoder - Geometric Learning for Structured Data Completion", "authorids": ["~Maria_Schmidt1", "~Alexander_Bronstein1"], "authors": ["Maria Schmidt", "Alexander Bronstein"], "keywords": ["Deep learning", "Non-Euclidean data completion", "Sparse matrices", "Recommender systems", "Recommendation systems", "Sparse representations"], "abstract": "In this work, we present a fully convolutional end to end method to reconstruct corrupted sparse matrices of Non-Euclidean data. The classic example for such matrices is recommender systems matrices where the rows/columns represent items/users and the entries are ratings. The method we present is inspired by the surprising and spectacular success of methods like$\"$  deep image prior$\"$  and $``$deep decoder$\"$  for corrupted image completion. In sharp contrast to previous Matrix Completion methods wherein the latent matrix or its factors directly serve as the optimization variable, in the method we present, the matrix is parameterized as the weights of a graph neural network acting on a random noisy input. Then we are tuning the network parameters to get a result as close as possible to the initial sparse matrix (using its factors) getting that way state of the art matrix completion result. In addition to the conceptual simplicity of our method, which is just Non-Euclidean generalization of deep image priors, it holds fewer parameters than previously presented methods which makes the parameters more trackable and the method more computationally efficient and more applicable for the real-world tasks. The method also achieves state-of-the-art results for the matrix completion task on the classical benchmarks in the field. The method also surprisingly shows that untrained convolutional neural network can use a good prior not only for image completion but also for Matrix Completion when redefined for graphs.", "one-sentence_summary": "Non-Euclidean Data Matrix Completion with end-to-end fully convolutional graph neural network based on Deep Image Prior Generalization  ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "schmidt|matrix_data_deep_decoder_geometric_learning_for_structured_data_completion", "pdf": "/pdf/38ffb209883019f8715291b06a7b8004b3c591cb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=cXMF1NKpXx", "_bibtex": "@misc{\nschmidt2021matrix,\ntitle={Matrix Data Deep Decoder - Geometric Learning for Structured Data Completion},\nauthor={Maria Schmidt and Alexander Bronstein},\nyear={2021},\nurl={https://openreview.net/forum?id=iUTHidd-ylL}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "iUTHidd-ylL", "replyto": "iUTHidd-ylL", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1563/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538115880, "tmdate": 1606915807658, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1563/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1563/-/Official_Review"}}}, {"id": "2mfpuNwIXH8", "original": null, "number": 2, "cdate": 1603874100980, "ddate": null, "tcdate": 1603874100980, "tmdate": 1605024413992, "tddate": null, "forum": "iUTHidd-ylL", "replyto": "iUTHidd-ylL", "invitation": "ICLR.cc/2021/Conference/Paper1563/-/Official_Review", "content": {"title": "Nontitle's", "review": "It could be accepted with major changes in the structure of the paper and rewriting some parts. But I would prefer to vote for rejecting and ask them for upgrading the writing overall. \n\nPros:\nVery promising method and concept.\nExperimental results look great comparing to the two state-of-the-art methods (Referring to table 2 \u2013 performance comparison)\n\nCons:\n1.\tThe grammar and style of writing are not as high as expected. \nSeveral typos and lowercase/uppercase misuse throughout the whole paper. Numerous grammatical errors. \nUse of several run-on sentences. For example:\nIn abstract:\nUse of the adjectives \u201csurprising\u201d and \u201cspectacular\u201d for the state-of-the-art methods is uncustomary language for a technical literature. \nThe sentence starting with \u201cIn sharp contrast to previous \u2026\u201d is a run-on sentence. It can be broken to at least two sentences. \nThen the sentence containing \u201cgetting that way state of the art \u2026\u201d is vague. Do you mean \u201cin that way we get?\u201d\nThe sentence starting with \u201cIn addition to the conceptual simplicity of our method \u2026\u201d is a run-on sentence. Should be broken to at least two sentences. \n\nIn section 1 Introduction:\n\u201cIn this work, we present a simplified \u2026\u201d sentence is too long. \nAfter \u201ca classical end to end graph convolutional neural network and is/was inspired\u2026\u201d, is/was is missing before inspired. \nThe sentence starting with \u201cWhen, the geometry of the column/row \u2026\u201d is grammatically incorrect. It could be connected to the previous sentence with a phrase in which, instead of using \u201cwhen\u201d. \n\n2.\tThe structure of the paper is not completely standard. \n\u2022\tContribution i and ii are technically one contribution and should be merged. \n\u2022\tIn section 2.3 \u201ctwo recent works\u201d are mentioned with no immediate reference to the papers.\n\u2022\tFuture work could be a section after a conclusion called future work, not as an appendix. The appendix is usually for detailed descriptions of methods. \n\u2022\tToo many small subsections. \no\tToo many small subsections in section 2. Preliminaries.\no\tIn section 3.1, network preparation starts with bullet points right away. An explaining sentence or two is needed before starting the bullet point. The same issue at 3.2, only two figures are shown with no extra explanation. \no\t3.3 is not a necessary subsection. Should be merged with other explanations of this section. \n\n\n\n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1563/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1563/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix Data Deep Decoder - Geometric Learning for Structured Data Completion", "authorids": ["~Maria_Schmidt1", "~Alexander_Bronstein1"], "authors": ["Maria Schmidt", "Alexander Bronstein"], "keywords": ["Deep learning", "Non-Euclidean data completion", "Sparse matrices", "Recommender systems", "Recommendation systems", "Sparse representations"], "abstract": "In this work, we present a fully convolutional end to end method to reconstruct corrupted sparse matrices of Non-Euclidean data. The classic example for such matrices is recommender systems matrices where the rows/columns represent items/users and the entries are ratings. The method we present is inspired by the surprising and spectacular success of methods like$\"$  deep image prior$\"$  and $``$deep decoder$\"$  for corrupted image completion. In sharp contrast to previous Matrix Completion methods wherein the latent matrix or its factors directly serve as the optimization variable, in the method we present, the matrix is parameterized as the weights of a graph neural network acting on a random noisy input. Then we are tuning the network parameters to get a result as close as possible to the initial sparse matrix (using its factors) getting that way state of the art matrix completion result. In addition to the conceptual simplicity of our method, which is just Non-Euclidean generalization of deep image priors, it holds fewer parameters than previously presented methods which makes the parameters more trackable and the method more computationally efficient and more applicable for the real-world tasks. The method also achieves state-of-the-art results for the matrix completion task on the classical benchmarks in the field. The method also surprisingly shows that untrained convolutional neural network can use a good prior not only for image completion but also for Matrix Completion when redefined for graphs.", "one-sentence_summary": "Non-Euclidean Data Matrix Completion with end-to-end fully convolutional graph neural network based on Deep Image Prior Generalization  ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "schmidt|matrix_data_deep_decoder_geometric_learning_for_structured_data_completion", "pdf": "/pdf/38ffb209883019f8715291b06a7b8004b3c591cb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=cXMF1NKpXx", "_bibtex": "@misc{\nschmidt2021matrix,\ntitle={Matrix Data Deep Decoder - Geometric Learning for Structured Data Completion},\nauthor={Maria Schmidt and Alexander Bronstein},\nyear={2021},\nurl={https://openreview.net/forum?id=iUTHidd-ylL}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "iUTHidd-ylL", "replyto": "iUTHidd-ylL", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1563/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538115880, "tmdate": 1606915807658, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1563/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1563/-/Official_Review"}}}, {"id": "FHx8gFyYfdu", "original": null, "number": 3, "cdate": 1603920132609, "ddate": null, "tcdate": 1603920132609, "tmdate": 1605024413933, "tddate": null, "forum": "iUTHidd-ylL", "replyto": "iUTHidd-ylL", "invitation": "ICLR.cc/2021/Conference/Paper1563/-/Official_Review", "content": {"title": "Official Blind Review #2", "review": "This paper aims to tackle the matrix completion problem by drawing connection from prior work in image completion domain. It seems to be a combination of prior work: Multi-graph convolution combined with Dirichlet energy on row and column graph laplacian where the input rating matrix is corrupted with noise. The writing and presentation is significantly below par Iclr acceptance in the current form. Also, considering some of the work mentioned below, SOTA results is an overclaim.\n\na) Clarity Issues- \nPage 6 is incomprehensible in current form where the main algorithm is described. There are too many font changes in the results and main algorithm section. There is a grammatical / spelling error or typo almost every 5 lines throughout the paper. Few examples below:\n\n-results for Matrix Completion *where* obtained \n-Figure 3: Network Structure Illustration \u2013 MDDD algorithm flow *scatch*\n-then present in a *summerizing* tables the Results compared to other known methods.\n-the Non-Factorised and the *factosised* algorithms.\n-*translate\" its network \n-so it would *feet* for Matrix completion\n\nb) State of the art on Matrix completion:\nWhile this work claims state of the art results, it is missing some recent work (Iclr 20) that have achieved better state of the art results than reported in this paper.\n\n1) Inductive Matrix completion with gnn iclr 20 https://openreview.net/forum?id=ByxxgCEYDS\n2) Deep Matrix Factorization with spectral regularizers (https://arxiv.org/abs/1911.07255)\n\nc) Related work :\nThis section is completely missing. While authors use 3 and half pages to describe the background needed,  it is not clear to me how this work uses multi graph convolution used in prior work or how does the authors make use of Dirichlet energy that is defined in preliminary section if it is differently used here than prior work.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1563/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1563/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix Data Deep Decoder - Geometric Learning for Structured Data Completion", "authorids": ["~Maria_Schmidt1", "~Alexander_Bronstein1"], "authors": ["Maria Schmidt", "Alexander Bronstein"], "keywords": ["Deep learning", "Non-Euclidean data completion", "Sparse matrices", "Recommender systems", "Recommendation systems", "Sparse representations"], "abstract": "In this work, we present a fully convolutional end to end method to reconstruct corrupted sparse matrices of Non-Euclidean data. The classic example for such matrices is recommender systems matrices where the rows/columns represent items/users and the entries are ratings. The method we present is inspired by the surprising and spectacular success of methods like$\"$  deep image prior$\"$  and $``$deep decoder$\"$  for corrupted image completion. In sharp contrast to previous Matrix Completion methods wherein the latent matrix or its factors directly serve as the optimization variable, in the method we present, the matrix is parameterized as the weights of a graph neural network acting on a random noisy input. Then we are tuning the network parameters to get a result as close as possible to the initial sparse matrix (using its factors) getting that way state of the art matrix completion result. In addition to the conceptual simplicity of our method, which is just Non-Euclidean generalization of deep image priors, it holds fewer parameters than previously presented methods which makes the parameters more trackable and the method more computationally efficient and more applicable for the real-world tasks. The method also achieves state-of-the-art results for the matrix completion task on the classical benchmarks in the field. The method also surprisingly shows that untrained convolutional neural network can use a good prior not only for image completion but also for Matrix Completion when redefined for graphs.", "one-sentence_summary": "Non-Euclidean Data Matrix Completion with end-to-end fully convolutional graph neural network based on Deep Image Prior Generalization  ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "schmidt|matrix_data_deep_decoder_geometric_learning_for_structured_data_completion", "pdf": "/pdf/38ffb209883019f8715291b06a7b8004b3c591cb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=cXMF1NKpXx", "_bibtex": "@misc{\nschmidt2021matrix,\ntitle={Matrix Data Deep Decoder - Geometric Learning for Structured Data Completion},\nauthor={Maria Schmidt and Alexander Bronstein},\nyear={2021},\nurl={https://openreview.net/forum?id=iUTHidd-ylL}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "iUTHidd-ylL", "replyto": "iUTHidd-ylL", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1563/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538115880, "tmdate": 1606915807658, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1563/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1563/-/Official_Review"}}}, {"id": "_iqwmjgFff4", "original": null, "number": 4, "cdate": 1603925754371, "ddate": null, "tcdate": 1603925754371, "tmdate": 1605024413873, "tddate": null, "forum": "iUTHidd-ylL", "replyto": "iUTHidd-ylL", "invitation": "ICLR.cc/2021/Conference/Paper1563/-/Official_Review", "content": {"title": "Contribution Limited; Lacking Theoretical Understanding", "review": "Topic: Matrix Completion for Recommender Systems\n\n\nmain contribution\n\nusing the idea of `deep prior for matrix completion.\n\n\nStrength\n\n-  performance: It seems that the method outperforms a number of baselines on different recommender system tasks. This suggests the usefulness of the proposed method.\n\n\n\nWeakness\n\n- Contribution Limited: The problem is formulated as graph Laplacian regularized matrix completion problem. This has been a long-existing technique. The contribution of this work lies in modeling the complete matrix within the range of a deep generative model and learns the deep generative model on the fly. GNN based link prediction is not a new technique. The work puts GNN based link prediction together with low-rank regularization, which is perhaps the reason why some practical benefits were observed, but the contribution is limited.\n\nIn fact, it is very hard to see how much new contribution is there on top of the main reference \n\nFederico Monti, Michael M. Bronstein, and Xavier Bresson. Geometric matrix completion with\nrecurrent multi-graph neural networks. CoRR, abs/1704.06803, 2017. URL http://arxiv.\norg/abs/1704.06803.\n\nThere may have been some regularization and network modifications, but the new contributions seem to be marginal.\n\nIs it possible to clarify what are the new contributions on top of the framework from the above reference?\n\n\n- Clarity and Soundness:\n -- Most of the effort was invested onto constructing the graph CNN that is claimed tailored for non-Euclidean matrices. But this part looks a bit theoretically (or even intuitively) ungrounded --- particularly, it is not easy to follow the rationale behind sec. 2.4. It is also unclear how is this construction suitable for handling non-Euclidean cases. This part may need some more explanations. \n\n-- the writing of the work is a bit convoluted or at least misleading. It tries to connect with deep prior based approaches, but the actual method is not really related. In a nutshell, the approach is a regression approach that maps embeddings of the row and column entities of the matrix to be completed to the ratings. The embeddings are constructed from graph Laplacians, and the mapping (regression model) is a particularly constructed neural network. It is suggested that these points to be clearly articulated.\n\n\n- Technical Depth: The regression formulation with the regularization and constraints are not outright unreasonable, but it seems that there is no further justification of the approach beyond intuition. The reason why the regression model/network should be constructed this way other than other ways is unclear and unjustified, even on an intuition level. The technical depth of this work may have large room to improve.\n\n- Simulation validation: It is unclear if the proposed algorithm converges or not, even on simple simulated data. It is suggested to show the algorithms\u2019 numerical behaviors so that the readers have some sense about its convergence characterizations. The current version does not have such information.\n\n- Questionable Mathematical Representation: The last equation in page 3 looks a bit strange: if X is approximated by WH\u2019, then it is automatically rank limited (by the number of columns of W,H). Adding a nuclear norm on WH\u2019 looks unnecessarily complicated.\n\n\n- writing: The writing seems to have been done in a hastily manner, with many typos (see \u201cMinor\u201d). \n\n\n\n\n\nMinor:\n\npage 2: ``non-convex (but still very well-behaved)\u2019\u2019: what does it mean?\npage 2: two equations, \u201cmin\u201d should be \u201carg min\u201d?\npage 4  sec 2.4 \u201cstracture\u201d\nsec 2.3.2 \u201cbetter then\u201d \nmost of the tables and figures seem to have very low resolution\nsec 3.1 is very hard to read through \n\n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper1563/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1563/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Matrix Data Deep Decoder - Geometric Learning for Structured Data Completion", "authorids": ["~Maria_Schmidt1", "~Alexander_Bronstein1"], "authors": ["Maria Schmidt", "Alexander Bronstein"], "keywords": ["Deep learning", "Non-Euclidean data completion", "Sparse matrices", "Recommender systems", "Recommendation systems", "Sparse representations"], "abstract": "In this work, we present a fully convolutional end to end method to reconstruct corrupted sparse matrices of Non-Euclidean data. The classic example for such matrices is recommender systems matrices where the rows/columns represent items/users and the entries are ratings. The method we present is inspired by the surprising and spectacular success of methods like$\"$  deep image prior$\"$  and $``$deep decoder$\"$  for corrupted image completion. In sharp contrast to previous Matrix Completion methods wherein the latent matrix or its factors directly serve as the optimization variable, in the method we present, the matrix is parameterized as the weights of a graph neural network acting on a random noisy input. Then we are tuning the network parameters to get a result as close as possible to the initial sparse matrix (using its factors) getting that way state of the art matrix completion result. In addition to the conceptual simplicity of our method, which is just Non-Euclidean generalization of deep image priors, it holds fewer parameters than previously presented methods which makes the parameters more trackable and the method more computationally efficient and more applicable for the real-world tasks. The method also achieves state-of-the-art results for the matrix completion task on the classical benchmarks in the field. The method also surprisingly shows that untrained convolutional neural network can use a good prior not only for image completion but also for Matrix Completion when redefined for graphs.", "one-sentence_summary": "Non-Euclidean Data Matrix Completion with end-to-end fully convolutional graph neural network based on Deep Image Prior Generalization  ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "schmidt|matrix_data_deep_decoder_geometric_learning_for_structured_data_completion", "pdf": "/pdf/38ffb209883019f8715291b06a7b8004b3c591cb.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=cXMF1NKpXx", "_bibtex": "@misc{\nschmidt2021matrix,\ntitle={Matrix Data Deep Decoder - Geometric Learning for Structured Data Completion},\nauthor={Maria Schmidt and Alexander Bronstein},\nyear={2021},\nurl={https://openreview.net/forum?id=iUTHidd-ylL}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "iUTHidd-ylL", "replyto": "iUTHidd-ylL", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1563/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538115880, "tmdate": 1606915807658, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1563/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1563/-/Official_Review"}}}], "count": 6}