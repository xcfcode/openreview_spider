{"notes": [{"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1458096725965, "tcdate": 1458096725965, "id": "WL92zp3pGc5zMX2Kf21p", "invitation": "ICLR.cc/2016/workshop/-/paper/79/comment", "forum": "oVgon01wpfrlgPMRsB1E", "replyto": "E8VDZMZp3H31v0m2iDQ8", "signatures": ["~Boxiang_Wang1"], "readers": ["everyone"], "writers": ["~Boxiang_Wang1"], "content": {"title": "Response to \"a potentially interesting paper, but with limited novelty\"", "comment": "We sincerely thank the anonymous referee for the careful and constructive review of the manuscript. We address the comments and questions in the following. The revised extended abstract can be seen in\nhttp://users.stat.umn.edu/~wang3660/sdwd_ICLR2016.pdf\nThe full paper can be seen in\nhttp://arxiv.org/pdf/1501.06066v1.pdf\n\nWe deeply appreciate the reviewer for further considerations.\n\nComment 1:  the formulation of the linear SVM is not the standard one. Could the authors provide a reference where this formulation appears? It does not seem obvious that it is equivalent to the standard C-SVM (if it is). The formulation is also non-convex with a quadratic equality constraints, which adds to the confusion.\nResponse: The formulation of the linear SVM is equivalent to the standard C-SVM. The formulation used in our paper was the original definition of SVM and has an intuitive geometric explanation, say maximizing the margin. In order to solve SVM, this formulation was transformed as a convex quadratic programming problem (as the so-called C-SVM). Introducing the original definition also allows for the motivation of DWD.\n\nComment 2: The reviewer could not understand the link between the formulation (2.1) and the DWD formulation of the previous page. Are they equivalent when replacing the l1-norm by the l2-regularization?\nResponse: Yes, they are equivalent when replacing the l1 norm by the l2 regularization. In the revised version, we make up such equivalence and the full paper gives more details.\n\nComment 3: Plotting the function V(u) could be helpful to visualize what the loss function is really doing (instead of Fig 1 for instance). It seems that a possible interpretation is simply a smoothed version of the hinge loss.\nResponse: DWD has a nice geometric interpretation (minimizing total inverse distance) and hence superior performance as shown by its inventors. In order to solve DWD, we derive its loss, which amounts to a smoothed version of hinge loss. We kept Figure 1 because it shows sparse DWD is a superior alternative to sparse SVM, especially in computation time.\n\nComment 4: The loss V in the objective 2.1 is smooth. Therefore, we have access to a large literature about composite minimization to solve such problems (see for instance Bach et al. Optimization with sparsity-inducing penalties, 2012) and Section 3 seems to reinvent the wheel. \nResponse: First, this paper is the first work to solve DWD based on its loss function, since all the existing DWD algorithms do not work well for high-dimensional data. Second, the loss function does not have second-order derivative, so it cannot be solved by other commonly used algorithms, for example, Newton's method. We solve DWD by reforming a novel algorithm, GCD algorithm, which combines coordinate descent and proximal gradient. \n\nOverall, DWD is a SVM-like classification method. In this work, we present the sparse formulation, which makes DWD available for high-dimensional classification. We also derive a novel  and efficient algorithm, which is completely different from the existing work. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Sparse Distance Weighted Discrimination", "abstract": "Distance weighted discrimination (DWD) was originally proposed to handle the data piling issue in the support vector machine. In this paper, we consider the sparse penalized DWD for high-dimensional classification. The state-of-the-art algorithm for solving the standard DWD is based on second-order cone programming, however such an algorithm does not work well for the sparse penalized DWD with high-dimensional data. In order to overcome the challenging computation difficulty, we develop a very efficient algorithm to compute the solution path of the sparse DWD at a given fine grid of regularization parameters. We implement the algorithm in a publicly available R package sdwd. We conduct extensive numerical experiments to demonstrate the computational efficiency and classification performance of our method.", "pdf": "/pdf/oVgon01wpfrlgPMRsB1E.pdf", "paperhash": "wang|sparse_distance_weighted_discrimination", "conflicts": ["stat.umn.edu"], "authorids": ["wang3660@umn.edu", "zouxx019@umn.edu"], "authors": ["Boxiang Wang", "Hui Zou"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "tmdate": null, "cdate": 1455777246742, "ddate": null, "super": null, "final": null, "tcdate": 1455777246742, "id": "ICLR.cc/2016/workshop/-/paper/79/comment", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "readers": ["everyone"], "reply": {"pdf": null, "replyto": null, "writers": {"values-regex": "~.*"}, "forum": "oVgon01wpfrlgPMRsB1E", "signatures": {"values-regex": "~.*", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "invitees": ["~", "ICLR.cc/2016/workshop/paper/79/reviewer"], "nonreaders": [], "noninvitees": []}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1458060472872, "tcdate": 1458060472872, "id": "E8VDZMZp3H31v0m2iDQ8", "invitation": "ICLR.cc/2016/workshop/-/paper/79/review/11", "forum": "oVgon01wpfrlgPMRsB1E", "replyto": "oVgon01wpfrlgPMRsB1E", "signatures": ["ICLR.cc/2016/workshop/paper/79/reviewer/11"], "readers": ["everyone"], "writers": ["ICLR.cc/2016/workshop/paper/79/reviewer/11"], "content": {"title": "a potentially interesting paper, but with limited novelty", "rating": "4: Ok but not good enough - rejection", "review": "The paper proposes a sparse version of the distance weighted discrimination principle of Marron et al., 2007.\nIt consists of replacing the l2 regularization by the l1-norm.\n\nNovelty\nThe DWD formulation of Marron et al., 2007 is not well known and has not received much attention. As far as the reviewer knows, there is no sparse version of this formulation. Therefore, we can argue that the paper has some novelty, but in a field crowded with papers about sparsity, this novelty is moderate.\n\nClarity\nThe paper is rather unclear for several reasons:\n * the formulation of the linear SVM is not the standard one. Could the authors provide a reference where this formulation appears? It does not seem obvious that it is equivalent to the standard C-SVM (if it is). The formulation is also non-convex with a quadratic equality constraints, which adds to the confusion.\n * The reviewer could not understand the link between the formulation (2.1) and the DWD formulation of the previous page. Are they equivalent when replacing the l1-norm by the l2-regularization?\n * Plotting the function V(u) could be helpful to visualize what the loss function is really doing (instead of Fig 1 for instance). It seems that a possible interpretation is simply a smoothed version of the hinge loss.\n\nSignificance and Quality\n * The loss V in the objective 2.1 is smooth. Therefore, we have access to a large literature about composite minimization to solve such problems (see for instance Bach et al. Optimization with sparsity-inducing penalties, 2012) and Section 3 seems to reinvent the wheel. \n \nTo conclude, the papers lacks of clarity, has moderate novelty and does not make significant enough contributions. My recommendation for this ICLR venue is reject. \n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Sparse Distance Weighted Discrimination", "abstract": "Distance weighted discrimination (DWD) was originally proposed to handle the data piling issue in the support vector machine. In this paper, we consider the sparse penalized DWD for high-dimensional classification. The state-of-the-art algorithm for solving the standard DWD is based on second-order cone programming, however such an algorithm does not work well for the sparse penalized DWD with high-dimensional data. In order to overcome the challenging computation difficulty, we develop a very efficient algorithm to compute the solution path of the sparse DWD at a given fine grid of regularization parameters. We implement the algorithm in a publicly available R package sdwd. We conduct extensive numerical experiments to demonstrate the computational efficiency and classification performance of our method.", "pdf": "/pdf/oVgon01wpfrlgPMRsB1E.pdf", "paperhash": "wang|sparse_distance_weighted_discrimination", "conflicts": ["stat.umn.edu"], "authorids": ["wang3660@umn.edu", "zouxx019@umn.edu"], "authors": ["Boxiang Wang", "Hui Zou"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456579945947, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456579945947, "id": "ICLR.cc/2016/workshop/-/paper/79/review/11", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "oVgon01wpfrlgPMRsB1E", "replyto": "oVgon01wpfrlgPMRsB1E", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/79/reviewer/11", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "replyto": null, "ddate": null, "cdate": null, "tmdate": 1455777244109, "tcdate": 1455777244109, "id": "oVgon01wpfrlgPMRsB1E", "invitation": "ICLR.cc/2016/workshop/-/submission", "forum": "oVgon01wpfrlgPMRsB1E", "signatures": ["~Boxiang_Wang1"], "readers": ["everyone"], "writers": ["~Boxiang_Wang1"], "content": {"CMT_id": "", "title": "Sparse Distance Weighted Discrimination", "abstract": "Distance weighted discrimination (DWD) was originally proposed to handle the data piling issue in the support vector machine. In this paper, we consider the sparse penalized DWD for high-dimensional classification. The state-of-the-art algorithm for solving the standard DWD is based on second-order cone programming, however such an algorithm does not work well for the sparse penalized DWD with high-dimensional data. In order to overcome the challenging computation difficulty, we develop a very efficient algorithm to compute the solution path of the sparse DWD at a given fine grid of regularization parameters. We implement the algorithm in a publicly available R package sdwd. We conduct extensive numerical experiments to demonstrate the computational efficiency and classification performance of our method.", "pdf": "/pdf/oVgon01wpfrlgPMRsB1E.pdf", "paperhash": "wang|sparse_distance_weighted_discrimination", "conflicts": ["stat.umn.edu"], "authorids": ["wang3660@umn.edu", "zouxx019@umn.edu"], "authors": ["Boxiang Wang", "Hui Zou"]}, "nonreaders": [], "details": {"replyCount": 2, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1454464564200, "ddate": null, "super": null, "final": null, "duedate": 1455833700000, "tcdate": 1454464564200, "id": "ICLR.cc/2016/workshop/-/submission", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "readers": ["everyone"], "reply": {"pdf": null, "forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"order": 4, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv.", "value-regex": "upload|http://arxiv.org/pdf/.+"}, "title": {"order": 3, "description": "Title of paper.", "value-regex": ".{0,500}"}, "abstract": {"order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"order": 1, "description": "Comma separated list of author names, as they appear in the paper.", "value-regex": "[^,\\n]+(,[^,\\n]+)*"}, "author_emails": {"order": 2, "description": "Comma separated list of author email addresses, in the same order as above.", "value-regex": "[^,\\n]+(,[^,\\n]+)*"}, "conflicts": {"order": 100, "description": "Semi-colon separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.).", "value-regex": "^([a-zA-Z0-9][a-zA-Z0-9-_]{0,61}[a-zA-Z0-9]{0,1}\\.([a-zA-Z]{1,6}|[a-zA-Z0-9-]{1,30}\\.[a-zA-Z]{2,3}))+(;[a-zA-Z0-9][a-zA-Z0-9-_]{0,61}[a-zA-Z0-9]{0,1}\\.([a-zA-Z]{1,6}|[a-zA-Z0-9-]{1,30}\\.[a-zA-Z]{2,3}))*$"}, "CMT_id": {"order": 5, "value-regex": ".*", "description": "If the paper is a resubmission from the ICLR 2016 Conference Track, enter its CMT ID; otherwise, leave blank."}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "expdate": 1463609700000}}}], "count": 3}