{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1486662540140, "tcdate": 1478205420262, "number": 84, "id": "rJEgeXFex", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "rJEgeXFex", "signatures": ["~Jacek_Bajor1"], "readers": ["everyone"], "content": {"title": "Predicting Medications from Diagnostic Codes with Recurrent Neural Networks", "abstract": "It is a surprising fact that electronic medical records are failing at one of their primary purposes, that of tracking the set of medications that the patient is actively taking. Studies estimate that up to 50% of such lists omit active drugs, and that up to 25% of all active medications do not appear on the appropriate patient list. Manual efforts to maintain these lists involve a great deal of tedious human labor, which could be reduced by computational tools to suggest likely missing or incorrect medications on a patient\u2019s list. We report here an application of recurrent neural networks to predict the likely therapeutic classes of medications that a patient is taking, given a sequence of the last 100 billing codes in their record. Our best model was a GRU that achieved high prediction accuracy (micro-averaged AUC 0.93, Label Ranking Loss 0.076), limited by hardware constraints on model size. Additionally, examining individual cases revealed that many of the predictions marked incorrect were likely to be examples of either omitted medications or omitted billing codes, supporting our assertion of a substantial number of errors and omissions in the data, and the likelihood of models such as these to help correct them.", "pdf": "/pdf/f612598e357946a8f81772ed1cb0cf561d06bb20.pdf", "TL;DR": "Applying recurrent neural networks to fix errors and omissions in patient medication records.", "paperhash": "bajor|predicting_medications_from_diagnostic_codes_with_recurrent_neural_networks", "conflicts": ["vanderbilt.edu"], "keywords": ["Deep learning", "Supervised Learning", "Applications"], "authors": ["Jacek M. Bajor", "Thomas A. Lasko"], "authorids": ["jacek.m.bajor@vanderbilt.edu", "tom.lasko@vanderbilt.edu"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 15, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396347116, "tcdate": 1486396347116, "number": 1, "id": "Hy7TsfUug", "invitation": "ICLR.cc/2017/conference/-/paper84/acceptance", "forum": "rJEgeXFex", "replyto": "rJEgeXFex", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "This paper applies RNNs to predict medications from billing costs. While this paper does not have technical novelty, it is well done and well organized. It demonstrates a creative use of recent models in a very important domain, and I think many people in our community are interested and inspired by well-done applications that branch to socially important domains. Moreover, I think an advantage to accepting it at ICLR is that it gives our \"expert\" stamp of approval -- I see a lot of questionable / badly applied / antiquated machine learning methods in domain conferences, so I think it would be helpful for those domains to have examples of application papers that are considered sound.", "decision": "Accept (Poster)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Predicting Medications from Diagnostic Codes with Recurrent Neural Networks", "abstract": "It is a surprising fact that electronic medical records are failing at one of their primary purposes, that of tracking the set of medications that the patient is actively taking. Studies estimate that up to 50% of such lists omit active drugs, and that up to 25% of all active medications do not appear on the appropriate patient list. Manual efforts to maintain these lists involve a great deal of tedious human labor, which could be reduced by computational tools to suggest likely missing or incorrect medications on a patient\u2019s list. We report here an application of recurrent neural networks to predict the likely therapeutic classes of medications that a patient is taking, given a sequence of the last 100 billing codes in their record. Our best model was a GRU that achieved high prediction accuracy (micro-averaged AUC 0.93, Label Ranking Loss 0.076), limited by hardware constraints on model size. Additionally, examining individual cases revealed that many of the predictions marked incorrect were likely to be examples of either omitted medications or omitted billing codes, supporting our assertion of a substantial number of errors and omissions in the data, and the likelihood of models such as these to help correct them.", "pdf": "/pdf/f612598e357946a8f81772ed1cb0cf561d06bb20.pdf", "TL;DR": "Applying recurrent neural networks to fix errors and omissions in patient medication records.", "paperhash": "bajor|predicting_medications_from_diagnostic_codes_with_recurrent_neural_networks", "conflicts": ["vanderbilt.edu"], "keywords": ["Deep learning", "Supervised Learning", "Applications"], "authors": ["Jacek M. Bajor", "Thomas A. Lasko"], "authorids": ["jacek.m.bajor@vanderbilt.edu", "tom.lasko@vanderbilt.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396347704, "id": "ICLR.cc/2017/conference/-/paper84/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "rJEgeXFex", "replyto": "rJEgeXFex", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396347704}}}, {"tddate": null, "tmdate": 1485602369573, "tcdate": 1485602369573, "number": 4, "id": "ry5S0eqPl", "invitation": "ICLR.cc/2017/conference/-/paper84/official/comment", "forum": "rJEgeXFex", "replyto": "BJxe5PrLe", "signatures": ["ICLR.cc/2017/conference/paper84/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper84/AnonReviewer3"], "content": {"title": "Updated score to 6", "comment": "I agree with the motivations of the author and the area chair, and updated my score to enable acceptance."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Predicting Medications from Diagnostic Codes with Recurrent Neural Networks", "abstract": "It is a surprising fact that electronic medical records are failing at one of their primary purposes, that of tracking the set of medications that the patient is actively taking. Studies estimate that up to 50% of such lists omit active drugs, and that up to 25% of all active medications do not appear on the appropriate patient list. Manual efforts to maintain these lists involve a great deal of tedious human labor, which could be reduced by computational tools to suggest likely missing or incorrect medications on a patient\u2019s list. We report here an application of recurrent neural networks to predict the likely therapeutic classes of medications that a patient is taking, given a sequence of the last 100 billing codes in their record. Our best model was a GRU that achieved high prediction accuracy (micro-averaged AUC 0.93, Label Ranking Loss 0.076), limited by hardware constraints on model size. Additionally, examining individual cases revealed that many of the predictions marked incorrect were likely to be examples of either omitted medications or omitted billing codes, supporting our assertion of a substantial number of errors and omissions in the data, and the likelihood of models such as these to help correct them.", "pdf": "/pdf/f612598e357946a8f81772ed1cb0cf561d06bb20.pdf", "TL;DR": "Applying recurrent neural networks to fix errors and omissions in patient medication records.", "paperhash": "bajor|predicting_medications_from_diagnostic_codes_with_recurrent_neural_networks", "conflicts": ["vanderbilt.edu"], "keywords": ["Deep learning", "Supervised Learning", "Applications"], "authors": ["Jacek M. Bajor", "Thomas A. Lasko"], "authorids": ["jacek.m.bajor@vanderbilt.edu", "tom.lasko@vanderbilt.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287734964, "id": "ICLR.cc/2017/conference/-/paper84/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "rJEgeXFex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper84/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper84/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper84/reviewers", "ICLR.cc/2017/conference/paper84/areachairs"], "cdate": 1485287734964}}}, {"tddate": null, "tmdate": 1485602278213, "tcdate": 1481894583173, "number": 1, "id": "S11T5vW4e", "invitation": "ICLR.cc/2017/conference/-/paper84/official/review", "forum": "rJEgeXFex", "replyto": "rJEgeXFex", "signatures": ["ICLR.cc/2017/conference/paper84/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper84/AnonReviewer3"], "content": {"title": "Good medical application paper for a medical or data science venue", "rating": "6: Marginally above acceptance threshold", "review": "This is a well-conducted and well-written study on the prediction of medication from diagnostic codes. The authors compared GRUs, LSTMs, feed-forward networks and random forests (making a case for why random forests should be used, instead of SVMs) and analysed the predictions and embeddings.\n\nThe authors also did address the questions of the reviewers.\n\nMy only negative point is that this work might be more relevant for a data science or medical venue rather than at ICLR.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Predicting Medications from Diagnostic Codes with Recurrent Neural Networks", "abstract": "It is a surprising fact that electronic medical records are failing at one of their primary purposes, that of tracking the set of medications that the patient is actively taking. Studies estimate that up to 50% of such lists omit active drugs, and that up to 25% of all active medications do not appear on the appropriate patient list. Manual efforts to maintain these lists involve a great deal of tedious human labor, which could be reduced by computational tools to suggest likely missing or incorrect medications on a patient\u2019s list. We report here an application of recurrent neural networks to predict the likely therapeutic classes of medications that a patient is taking, given a sequence of the last 100 billing codes in their record. Our best model was a GRU that achieved high prediction accuracy (micro-averaged AUC 0.93, Label Ranking Loss 0.076), limited by hardware constraints on model size. Additionally, examining individual cases revealed that many of the predictions marked incorrect were likely to be examples of either omitted medications or omitted billing codes, supporting our assertion of a substantial number of errors and omissions in the data, and the likelihood of models such as these to help correct them.", "pdf": "/pdf/f612598e357946a8f81772ed1cb0cf561d06bb20.pdf", "TL;DR": "Applying recurrent neural networks to fix errors and omissions in patient medication records.", "paperhash": "bajor|predicting_medications_from_diagnostic_codes_with_recurrent_neural_networks", "conflicts": ["vanderbilt.edu"], "keywords": ["Deep learning", "Supervised Learning", "Applications"], "authors": ["Jacek M. Bajor", "Thomas A. Lasko"], "authorids": ["jacek.m.bajor@vanderbilt.edu", "tom.lasko@vanderbilt.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512703262, "id": "ICLR.cc/2017/conference/-/paper84/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper84/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper84/AnonReviewer3", "ICLR.cc/2017/conference/paper84/AnonReviewer1", "ICLR.cc/2017/conference/paper84/AnonReviewer2"], "reply": {"forum": "rJEgeXFex", "replyto": "rJEgeXFex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper84/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper84/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512703262}}}, {"tddate": null, "tmdate": 1485042406369, "tcdate": 1485042406369, "number": 2, "id": "B1CJ7_bwl", "invitation": "ICLR.cc/2017/conference/-/paper84/official/comment", "forum": "rJEgeXFex", "replyto": "rJEGyBz4g", "signatures": ["ICLR.cc/2017/conference/paper84/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper84/AnonReviewer1"], "content": {"title": "Update score to 8", "comment": "Just wanted to call this to the attention of the meta-reviewer."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Predicting Medications from Diagnostic Codes with Recurrent Neural Networks", "abstract": "It is a surprising fact that electronic medical records are failing at one of their primary purposes, that of tracking the set of medications that the patient is actively taking. Studies estimate that up to 50% of such lists omit active drugs, and that up to 25% of all active medications do not appear on the appropriate patient list. Manual efforts to maintain these lists involve a great deal of tedious human labor, which could be reduced by computational tools to suggest likely missing or incorrect medications on a patient\u2019s list. We report here an application of recurrent neural networks to predict the likely therapeutic classes of medications that a patient is taking, given a sequence of the last 100 billing codes in their record. Our best model was a GRU that achieved high prediction accuracy (micro-averaged AUC 0.93, Label Ranking Loss 0.076), limited by hardware constraints on model size. Additionally, examining individual cases revealed that many of the predictions marked incorrect were likely to be examples of either omitted medications or omitted billing codes, supporting our assertion of a substantial number of errors and omissions in the data, and the likelihood of models such as these to help correct them.", "pdf": "/pdf/f612598e357946a8f81772ed1cb0cf561d06bb20.pdf", "TL;DR": "Applying recurrent neural networks to fix errors and omissions in patient medication records.", "paperhash": "bajor|predicting_medications_from_diagnostic_codes_with_recurrent_neural_networks", "conflicts": ["vanderbilt.edu"], "keywords": ["Deep learning", "Supervised Learning", "Applications"], "authors": ["Jacek M. Bajor", "Thomas A. Lasko"], "authorids": ["jacek.m.bajor@vanderbilt.edu", "tom.lasko@vanderbilt.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287734964, "id": "ICLR.cc/2017/conference/-/paper84/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "rJEgeXFex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper84/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper84/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper84/reviewers", "ICLR.cc/2017/conference/paper84/areachairs"], "cdate": 1485287734964}}}, {"tddate": null, "tmdate": 1485042383828, "tcdate": 1481948940392, "number": 2, "id": "rJEGyBz4g", "invitation": "ICLR.cc/2017/conference/-/paper84/official/review", "forum": "rJEgeXFex", "replyto": "rJEgeXFex", "signatures": ["ICLR.cc/2017/conference/paper84/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper84/AnonReviewer1"], "content": {"title": "Strong application work, very important problem", "rating": "8: Top 50% of accepted papers, clear accept", "review": "In light of the detailed author responses and further updates to the manuscript, I am raising my score to an 8 and reiterating my support for this paper. I think it will be among the strongest non-traditional applied deep learning work at ICLR and will receive a great deal of interest and attention from attendees.\n\n-----\n\nThis paper describes modern deep learning approach to the problem of predicting the medications taken by a patient during a period of time based solely upon the sequence of ICD-9 codes assigned to the patient during that same time period. This problem is formulated as a multilabel sequence classification (in contrast to language modeling, which is multiclass classification). They propose to use standard LSTM and GRU architectures with embedding layers to handle the sparse categorical inputs, similar to that described in related work by Choi, et al. In experiments using a cohort of ~610K patient records, they find that RNN models outperform strong baselines including an MLP and a random forest, as well as a common sense baseline. The differences in performance between the recurrent models and the MLP appear to be large enough to be significant, given the size of the test set.\n\nStrengths:\n- Very important problem. As the authors point out, two the value propositions of EHRs -- which have been widely adopted throughout the US due to a combination of legislation and billions of dollars in incentives from the federal government -- included more accurate records and fewer medication mistakes. These two benefits have largely failed to materialize. This seems like a major opportunity for data mining and machine learning.\n- Paper is well-written with lucid introduction and motivation, thorough discussion of related work, clear description of experiments and metrics, and interesting qualitative analysis of results.\n- Empirical results are solid with a strong win for RNNs over convincing baselines. This is in contrast to some recent related papers, including Lipton & Kale et al, ICLR 2016, where the gap between the RNN and MLP was relatively small, and Choi et al, MLHC 2016, which omitted many obvious baselines.\n- Discussion is thorough and thoughtful. The authors are right about the kidney code embedding results: this is a very promising result.\n\nWeaknesses:\n- The authors make several unintuitive decisions related to data preprocessing and experimental design, foremost among them the choice NOT to use full patient sequences but instead only truncated patient sequences that each ends at randomly chosen time point. This does not necessarily invalidate their results, but it is somewhat unnatural and the explanation is difficult to follow, reducing the paper's potential impact. It is also reduces the RNN's potential advantage.\n- The chosen metrics seem appropriate, but non-experts may have trouble interpreting the absolute and relative performances (beyond the superficial, e.g., RNN score 0.01 more than NN!). The authors should invest some space in explaining (1) what level of performance -- for each metric -- would be necessary for the model to be useful in a real clinical setting and (2) whether the gaps between the various models are \"significant\" (even in an informal sense).\n- The paper proposes nothing novel in terms of methods, which is a serious weakness for a methods conference like ICLR. I think it is strong enough empirically (and sufficiently interesting in application) to warrant acceptance regardless, but there may be things the authors can do to make it more competitive. For example, one potential hypothesis is that higher capacity models are more prone to overfitting noisy targets. Is there some way to investigate this, perhaps by looking at the kinds of errors each model makes?\n\nI have a final comment: as a piece of clinical work, the paper has a huge weakness: the lack of ground truth labels for missing medications. Models are both trained and tested on data with noisy labels. For training, the authors are right that this shouldn't be a huge problem, provided the label noise is random (even class conditional isn't too big of a problem). For testing, though, this seems like it could skew metrics. Further, the assumption that the label noise is not systemic seems very unlikely given that these data are recorded by human clinicians. The cases shown in Appendix C lend some credence to this assertion: for Case 1, 7/26 actual medications received probabilities < 0.5. My hunch is that clinical reviewers would view the paper with great skepticism. The authors will need to get creative about evaluation -- or invest a lot of time/money in labeling data -- to really prove that this works.\n\nFor what it is worth, I hope that this paper is accepted as I think it will be of great interest to the ICLR community. However, I am borderline about whether I'd be willing to fight for its acceptance. If the authors can address the reviewers' critiques -- and in particular, dive into the question of overfitting the imperfect labels and provide some insights -- I might be willing to raise my score and lobby for acceptance.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Predicting Medications from Diagnostic Codes with Recurrent Neural Networks", "abstract": "It is a surprising fact that electronic medical records are failing at one of their primary purposes, that of tracking the set of medications that the patient is actively taking. Studies estimate that up to 50% of such lists omit active drugs, and that up to 25% of all active medications do not appear on the appropriate patient list. Manual efforts to maintain these lists involve a great deal of tedious human labor, which could be reduced by computational tools to suggest likely missing or incorrect medications on a patient\u2019s list. We report here an application of recurrent neural networks to predict the likely therapeutic classes of medications that a patient is taking, given a sequence of the last 100 billing codes in their record. Our best model was a GRU that achieved high prediction accuracy (micro-averaged AUC 0.93, Label Ranking Loss 0.076), limited by hardware constraints on model size. Additionally, examining individual cases revealed that many of the predictions marked incorrect were likely to be examples of either omitted medications or omitted billing codes, supporting our assertion of a substantial number of errors and omissions in the data, and the likelihood of models such as these to help correct them.", "pdf": "/pdf/f612598e357946a8f81772ed1cb0cf561d06bb20.pdf", "TL;DR": "Applying recurrent neural networks to fix errors and omissions in patient medication records.", "paperhash": "bajor|predicting_medications_from_diagnostic_codes_with_recurrent_neural_networks", "conflicts": ["vanderbilt.edu"], "keywords": ["Deep learning", "Supervised Learning", "Applications"], "authors": ["Jacek M. Bajor", "Thomas A. Lasko"], "authorids": ["jacek.m.bajor@vanderbilt.edu", "tom.lasko@vanderbilt.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512703262, "id": "ICLR.cc/2017/conference/-/paper84/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper84/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper84/AnonReviewer3", "ICLR.cc/2017/conference/paper84/AnonReviewer1", "ICLR.cc/2017/conference/paper84/AnonReviewer2"], "reply": {"forum": "rJEgeXFex", "replyto": "rJEgeXFex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper84/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper84/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512703262}}}, {"tddate": null, "tmdate": 1484254457582, "tcdate": 1484254457582, "number": 6, "id": "ByfbaDrIx", "invitation": "ICLR.cc/2017/conference/-/paper84/public/comment", "forum": "rJEgeXFex", "replyto": "r1UHA4XNg", "signatures": ["~Jacek_Bajor1"], "readers": ["everyone"], "writers": ["~Jacek_Bajor1"], "content": {"title": "Response", "comment": "We appreciate the positive comments of all reviewers and the questions/suggestions that have improved the paper to this point. Below we summarize and address the concerns of each reviewer.\n\n> More analysis would be useful, especially of the embedding, which appears to be a negative result.\n\nThe embedding is not actually a negative result, but from this comment we now understand that the way we presented Figure 5 gives the impression of one. In the figure, we colored the elements by the ICD chapter (roughly corresponding to organ system), but we did not mean to imply that an ideal embedding would separate the elements into groups of the same color. This was an obvious mistake on our part, because usually such figures are indeed colored that way. In fact, the reason we thought an embedding might be useful is because of the strong relationships that exist between elements of different chapters, and we expected/wanted to see much mixture of the colors in among some general areas of color sameness.\n\nTo address this issue and provide further analysis of the embedding, we have changed the coloring of the figure to better indicate when the embedding aligns with clinical judgment. Each element is now colored according to the semantic clinical relatedness of the element's nearest neighbor in the embedding space (not the t-SNE space), indicating whether the neighbor represents a condition that is strongly related, loosely related, or unrelated to that of the given element. The determination was made by hand for all 2000 elements, using the clinical judgement of a licensed physician. Nearest neighbors were computed under the manhattan distance, which we found to be the most useful of several Minkowski distance metrics tried, with p ranging above and below 1.0.\n\nWe found that about half of the nearest neighbors were strongly related, whereas a sampling of 100 random pairs produced 0.08 (95%CI [0.028, 0.125]) fraction of nearest neighbors that were strongly related. We also found the surprising result that the probability of a strongly related neighbor actually increases with longer distances to that neighbor, instead of what we had expected, that closer neighbors would indicate a stronger relationship. While it was obviously true by inspection that closer distances reflect stronger clinical relationships, an increasing distance to the nearest neighbor indicates a sparser populated portion of the embedding space, and there is a clear, approximately linear relationship between the nearest neighbor distance and the probability of a strong semantic relationship that extends over the full range of nearest distances. Further work in this direction to discover the causes of the relationship will be very interesting, but time and space limit us to simply reporting the result of this analysis.\n\nWe have updated the paper to include the re-colored figure, the new numeric results (in the text of Section 4), a paragraph of description and one of discussion on the analysis (Sections 3.4.2 and 4), and we have added Figure 6 displaying the conditional probability of relatedness given distance to the nearest neighbor. We believe that this is an intriguing addition to the paper, and we appreciate the suggestion of the reviewer to go further in this direction. It does make the paper a little long, however. We could move Figure 6 to an appendix if desired.\n\n> Reduce medical jargon.\n\nWe agree that jargon is undesirable, and we have reviewed the paper and did our best to minimize medical jargon and explain medical terms, although we only found a few cases where we could improve on what we had. We replaced the term RxNorm with a simple description of it (but kept the footnote to its URL), added concise descriptions of the example conditions we mention, and spelled out Intensive Care Unit. We'll be happy to address further specific instances if someone points them out, or if we have misunderstood what the reviewer is referring to."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Predicting Medications from Diagnostic Codes with Recurrent Neural Networks", "abstract": "It is a surprising fact that electronic medical records are failing at one of their primary purposes, that of tracking the set of medications that the patient is actively taking. Studies estimate that up to 50% of such lists omit active drugs, and that up to 25% of all active medications do not appear on the appropriate patient list. Manual efforts to maintain these lists involve a great deal of tedious human labor, which could be reduced by computational tools to suggest likely missing or incorrect medications on a patient\u2019s list. We report here an application of recurrent neural networks to predict the likely therapeutic classes of medications that a patient is taking, given a sequence of the last 100 billing codes in their record. Our best model was a GRU that achieved high prediction accuracy (micro-averaged AUC 0.93, Label Ranking Loss 0.076), limited by hardware constraints on model size. Additionally, examining individual cases revealed that many of the predictions marked incorrect were likely to be examples of either omitted medications or omitted billing codes, supporting our assertion of a substantial number of errors and omissions in the data, and the likelihood of models such as these to help correct them.", "pdf": "/pdf/f612598e357946a8f81772ed1cb0cf561d06bb20.pdf", "TL;DR": "Applying recurrent neural networks to fix errors and omissions in patient medication records.", "paperhash": "bajor|predicting_medications_from_diagnostic_codes_with_recurrent_neural_networks", "conflicts": ["vanderbilt.edu"], "keywords": ["Deep learning", "Supervised Learning", "Applications"], "authors": ["Jacek M. Bajor", "Thomas A. Lasko"], "authorids": ["jacek.m.bajor@vanderbilt.edu", "tom.lasko@vanderbilt.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287735090, "id": "ICLR.cc/2017/conference/-/paper84/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJEgeXFex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper84/reviewers", "ICLR.cc/2017/conference/paper84/areachairs"], "cdate": 1485287735090}}}, {"tddate": null, "tmdate": 1484254100124, "tcdate": 1484254100124, "number": 5, "id": "H12cjDSUe", "invitation": "ICLR.cc/2017/conference/-/paper84/public/comment", "forum": "rJEgeXFex", "replyto": "rJEGyBz4g", "signatures": ["~Jacek_Bajor1"], "readers": ["everyone"], "writers": ["~Jacek_Bajor1"], "content": {"title": "Response", "comment": "> Would have been more natural to use full sequences rather than partial sequences limited by a maximum number of elements. The description of sampling was hard to follow. The sequence limitation may have reduced the RNN's advantage.\n\nWe understand this concern, and we agree that it would have been more natural and intuitive to use the full sequence for each patient. We also agree that its original description was hard to follow. We explained in the question/answer round the reasons for our choice (mainly training time and stratifying input samples by medication), and the efforts we made to investigate its impact on the results (probably a small impact, if any). We re-wrote the description to be clearer in this version (Section 3.1, paragraph 3). We believe our design is a reasonable compromise between the ideal and the practical.\n\n> Please explain what performance of each measure is needed to be clinically useful.\n\nMulti-label classification is pretty new to medicine, so there is not much documented experience to draw from. But we've added a two short paragraphs to Section 4 to give a couple rules of thumb that will help readers evaluate the clinical utility of the results.\n\n> Deeper analysis, such as investigating the effect of noisy targets and the kinds of errors made by each model, may make the paper more competitive, given that it is an applications paper that doesn't present any new theory or methods.\n\nWhile we did not have the time or resources to go further in this suggested direction (which we agree would be useful), we did add further analysis on the efficacy of the embedding, which we believe will be of interest to the ICLR community.\n\n> Clinicians will view the results with skepticism because of the lack of ground truth due to noisy labels.\n\nYes, we agree, and we try to succinctly make this point in the paper. We intended this work to present initial experiments in this direction, with more thorough and expensive validation to come later, depending on how well this proof of concept worked. Of course, the necessary depth of that validation depends on the way in which the suggestions will be used. If we want to use the suggestions as some kind of prior probability for further downstream analysis, then we're probably well on our way to having acceptable performance. For use in clinical quality assurance, or use at the bedside, especially in a modal context in which the clinician would have to explicitly accept or reject the suggestions, we would have to demonstrate their correctness with much more rigor, probably culminating in a prospective trial (and the suggestions themselves would need to be improved from what we achieved here).\n\nThe reviewer also points out the example of Case 1 in the appendix, where \"7/26 actual medications received probabilities < 0.5.\" Note that we make no claims about the calibration of the RNN's predictions. We have found by eyeball that a cutoff of 0.2 gives a reasonable balance between sensitivity and specificity, and we state this in the paper."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Predicting Medications from Diagnostic Codes with Recurrent Neural Networks", "abstract": "It is a surprising fact that electronic medical records are failing at one of their primary purposes, that of tracking the set of medications that the patient is actively taking. Studies estimate that up to 50% of such lists omit active drugs, and that up to 25% of all active medications do not appear on the appropriate patient list. Manual efforts to maintain these lists involve a great deal of tedious human labor, which could be reduced by computational tools to suggest likely missing or incorrect medications on a patient\u2019s list. We report here an application of recurrent neural networks to predict the likely therapeutic classes of medications that a patient is taking, given a sequence of the last 100 billing codes in their record. Our best model was a GRU that achieved high prediction accuracy (micro-averaged AUC 0.93, Label Ranking Loss 0.076), limited by hardware constraints on model size. Additionally, examining individual cases revealed that many of the predictions marked incorrect were likely to be examples of either omitted medications or omitted billing codes, supporting our assertion of a substantial number of errors and omissions in the data, and the likelihood of models such as these to help correct them.", "pdf": "/pdf/f612598e357946a8f81772ed1cb0cf561d06bb20.pdf", "TL;DR": "Applying recurrent neural networks to fix errors and omissions in patient medication records.", "paperhash": "bajor|predicting_medications_from_diagnostic_codes_with_recurrent_neural_networks", "conflicts": ["vanderbilt.edu"], "keywords": ["Deep learning", "Supervised Learning", "Applications"], "authors": ["Jacek M. Bajor", "Thomas A. Lasko"], "authorids": ["jacek.m.bajor@vanderbilt.edu", "tom.lasko@vanderbilt.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287735090, "id": "ICLR.cc/2017/conference/-/paper84/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJEgeXFex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper84/reviewers", "ICLR.cc/2017/conference/paper84/areachairs"], "cdate": 1485287735090}}}, {"tddate": null, "tmdate": 1484253672075, "tcdate": 1484253672075, "number": 4, "id": "BJxe5PrLe", "invitation": "ICLR.cc/2017/conference/-/paper84/public/comment", "forum": "rJEgeXFex", "replyto": "S11T5vW4e", "signatures": ["~Jacek_Bajor1"], "readers": ["everyone"], "writers": ["~Jacek_Bajor1"], "content": {"title": "Response", "comment": "We agree that this work would be relevant in a data science or computational medicine venue. We submitted it to ICLR after seeing applications listed as a relevant subject area in the call for papers, and reasoning that there was no better place to have discussions about our application than among the researchers who developed the methods it uses."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Predicting Medications from Diagnostic Codes with Recurrent Neural Networks", "abstract": "It is a surprising fact that electronic medical records are failing at one of their primary purposes, that of tracking the set of medications that the patient is actively taking. Studies estimate that up to 50% of such lists omit active drugs, and that up to 25% of all active medications do not appear on the appropriate patient list. Manual efforts to maintain these lists involve a great deal of tedious human labor, which could be reduced by computational tools to suggest likely missing or incorrect medications on a patient\u2019s list. We report here an application of recurrent neural networks to predict the likely therapeutic classes of medications that a patient is taking, given a sequence of the last 100 billing codes in their record. Our best model was a GRU that achieved high prediction accuracy (micro-averaged AUC 0.93, Label Ranking Loss 0.076), limited by hardware constraints on model size. Additionally, examining individual cases revealed that many of the predictions marked incorrect were likely to be examples of either omitted medications or omitted billing codes, supporting our assertion of a substantial number of errors and omissions in the data, and the likelihood of models such as these to help correct them.", "pdf": "/pdf/f612598e357946a8f81772ed1cb0cf561d06bb20.pdf", "TL;DR": "Applying recurrent neural networks to fix errors and omissions in patient medication records.", "paperhash": "bajor|predicting_medications_from_diagnostic_codes_with_recurrent_neural_networks", "conflicts": ["vanderbilt.edu"], "keywords": ["Deep learning", "Supervised Learning", "Applications"], "authors": ["Jacek M. Bajor", "Thomas A. Lasko"], "authorids": ["jacek.m.bajor@vanderbilt.edu", "tom.lasko@vanderbilt.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287735090, "id": "ICLR.cc/2017/conference/-/paper84/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJEgeXFex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper84/reviewers", "ICLR.cc/2017/conference/paper84/areachairs"], "cdate": 1485287735090}}}, {"tddate": null, "tmdate": 1482014269899, "tcdate": 1482014269899, "number": 3, "id": "r1UHA4XNg", "invitation": "ICLR.cc/2017/conference/-/paper84/official/review", "forum": "rJEgeXFex", "replyto": "rJEgeXFex", "signatures": ["ICLR.cc/2017/conference/paper84/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper84/AnonReviewer2"], "content": {"title": "Thorough empirical investigation of an interesting and (to my knowledge) novel application area", "rating": "7: Good paper, accept", "review": "This is a well written, organized, and presented paper that I enjoyed reading.  I commend the authors on their attention to the narrative and the explanations.  While it did not present any new methodology or architecture, it instead addressed an important application of predicting the medications a patient is using, given the record of billing codes.  The dataset they use is impressive and useful and, frankly, more interesting than the typical toy datasets in machine learning.  That said, the investigation of those results was not as deep as I thought it should have been in an empirical/applications paper.  Despite their focus on the application, I was encouraged to see the authors use cutting edge choices (eg Keras, adadelta, etc) in their architecture.  A few points of criticism:\n\n-The numerical results are in my view too brief.  Fig 4 is anecdotal, Fig 5 is essentially a negative result (tSNE is only in some places interpretable), so that leaves Table 1.  I recognize there is only one dataset, but this does not offer a vast amount of empirical evidence and analysis that one might expect out of a paper with no major algorithmic/theoretical advances.  To be clear I don't think this is disqualifying or deeply concerning; I simply found it a bit underwhelming.\n\n- To be constructive, re the results I would recommend removing Fig 5 and replacing that with some more meaningful analysis of performance.  I found Fig 5 to be mostly uninformative, other than as a negative result, which I think can be stated in a sentence rather than in a large figure.\n\n- There is a bit of jargon used and expertise required that may not be familiar to the typical ICLR reader.  I saw that another reviewer suggested perhaps ICLR is not the right venue for this work.  While I certainly see the reviewer's point that a medical or healthcare venue may be more suitable, I do want to cast my vote of keeping this paper here... our community benefits from more thoughtful and in depth applications. Instead I think this can be addressed by tightening up those points of jargon and making the results more easy to evaluate by an ICLR reader (that is, as it stands now researchers without medical experience have to take your results after Table 1 on faith, rather than getting to apply their well-trained quantitative eye). \n\nOverall, a nice paper.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Predicting Medications from Diagnostic Codes with Recurrent Neural Networks", "abstract": "It is a surprising fact that electronic medical records are failing at one of their primary purposes, that of tracking the set of medications that the patient is actively taking. Studies estimate that up to 50% of such lists omit active drugs, and that up to 25% of all active medications do not appear on the appropriate patient list. Manual efforts to maintain these lists involve a great deal of tedious human labor, which could be reduced by computational tools to suggest likely missing or incorrect medications on a patient\u2019s list. We report here an application of recurrent neural networks to predict the likely therapeutic classes of medications that a patient is taking, given a sequence of the last 100 billing codes in their record. Our best model was a GRU that achieved high prediction accuracy (micro-averaged AUC 0.93, Label Ranking Loss 0.076), limited by hardware constraints on model size. Additionally, examining individual cases revealed that many of the predictions marked incorrect were likely to be examples of either omitted medications or omitted billing codes, supporting our assertion of a substantial number of errors and omissions in the data, and the likelihood of models such as these to help correct them.", "pdf": "/pdf/f612598e357946a8f81772ed1cb0cf561d06bb20.pdf", "TL;DR": "Applying recurrent neural networks to fix errors and omissions in patient medication records.", "paperhash": "bajor|predicting_medications_from_diagnostic_codes_with_recurrent_neural_networks", "conflicts": ["vanderbilt.edu"], "keywords": ["Deep learning", "Supervised Learning", "Applications"], "authors": ["Jacek M. Bajor", "Thomas A. Lasko"], "authorids": ["jacek.m.bajor@vanderbilt.edu", "tom.lasko@vanderbilt.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512703262, "id": "ICLR.cc/2017/conference/-/paper84/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper84/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper84/AnonReviewer3", "ICLR.cc/2017/conference/paper84/AnonReviewer1", "ICLR.cc/2017/conference/paper84/AnonReviewer2"], "reply": {"forum": "rJEgeXFex", "replyto": "rJEgeXFex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper84/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper84/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512703262}}}, {"tddate": null, "tmdate": 1481130611884, "tcdate": 1481129968976, "number": 1, "id": "SkKxg6SXg", "invitation": "ICLR.cc/2017/conference/-/paper84/public/comment", "forum": "rJEgeXFex", "replyto": "BJziEP1Qx", "signatures": ["~Jacek_Bajor1"], "readers": ["everyone"], "writers": ["~Jacek_Bajor1"], "content": {"title": "Response", "comment": "Choi 2016b is good work that used a GRU with an embedding input layer to predict the future development of heart failure from patient data. Their learning problem was binary classification, and they used the sequential orientation of the GRU to capture a notion of progression toward the disease. In contrast, our problem is multilabel classification, using the sequence of diagnostic billing codes  to predict all medications a patient has been taking. Our application uses the sequential orientation of the GRU to capture temporal relationships between clinical problems that may inform the set of medications prescribed. For example, a patient with hypertension may be prescribed a beta blocker as initial therapy in the absence of other disease, but if he has a history of prostatitis he may be prescribed an alpha blocker instead, because alpha blockers treat both hypertension and prostatitis. Or a patient currently on a beta blocker for hypertension may be switched to an alpha blocker if he subsequently develops prostatitis.\n\nThere are other, minor technical differences between their work and ours (fixed time observation window vs. fixed number of sequence elements, pre-trained embedding vs. simultaneously trained embedding, logistic regression top layer vs. direct output of the GRU), but the biggest difference and novelty from our perspective is the completely different domain problem addressed by the two bodies of work. A further minor difference is that we took the extra step of investigating the contribution of the sequence orientation of an RNN to its success on the problem, by comparing to the closest possible model without a sequence orientation.\n\nSo from our perspective, our work is not built on Choi 2016b, it is not an extension of it, and we honestly don't see how their approach is applicable to our problem, without modifying it to basically become our approach.  The two bodies of work were done approximately simultaneously. The similarities lie in the fact that we use similar, popular tools and similar data sources to solve different problems (and different classes of learning problems) in the computational medicine domain. We think both are innovative application of state-of-the-art methods to this domain."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Predicting Medications from Diagnostic Codes with Recurrent Neural Networks", "abstract": "It is a surprising fact that electronic medical records are failing at one of their primary purposes, that of tracking the set of medications that the patient is actively taking. Studies estimate that up to 50% of such lists omit active drugs, and that up to 25% of all active medications do not appear on the appropriate patient list. Manual efforts to maintain these lists involve a great deal of tedious human labor, which could be reduced by computational tools to suggest likely missing or incorrect medications on a patient\u2019s list. We report here an application of recurrent neural networks to predict the likely therapeutic classes of medications that a patient is taking, given a sequence of the last 100 billing codes in their record. Our best model was a GRU that achieved high prediction accuracy (micro-averaged AUC 0.93, Label Ranking Loss 0.076), limited by hardware constraints on model size. Additionally, examining individual cases revealed that many of the predictions marked incorrect were likely to be examples of either omitted medications or omitted billing codes, supporting our assertion of a substantial number of errors and omissions in the data, and the likelihood of models such as these to help correct them.", "pdf": "/pdf/f612598e357946a8f81772ed1cb0cf561d06bb20.pdf", "TL;DR": "Applying recurrent neural networks to fix errors and omissions in patient medication records.", "paperhash": "bajor|predicting_medications_from_diagnostic_codes_with_recurrent_neural_networks", "conflicts": ["vanderbilt.edu"], "keywords": ["Deep learning", "Supervised Learning", "Applications"], "authors": ["Jacek M. Bajor", "Thomas A. Lasko"], "authorids": ["jacek.m.bajor@vanderbilt.edu", "tom.lasko@vanderbilt.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287735090, "id": "ICLR.cc/2017/conference/-/paper84/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJEgeXFex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper84/reviewers", "ICLR.cc/2017/conference/paper84/areachairs"], "cdate": 1485287735090}}}, {"tddate": null, "tmdate": 1481130440842, "tcdate": 1481130440835, "number": 3, "id": "By-RbaHXl", "invitation": "ICLR.cc/2017/conference/-/paper84/public/comment", "forum": "rJEgeXFex", "replyto": "r1Nnw3ymx", "signatures": ["~Jacek_Bajor1"], "readers": ["everyone"], "writers": ["~Jacek_Bajor1"], "content": {"title": "Response", "comment": ">Do your (input) codes and (output) medications include the entire sequence of codes and medications prior to the reference point? Or simply the just the prior 100 codes, regardless of duration of the sequence they span? Why not use all prior codes and medications?\n\n>Following up on that point, since your training/validation/test split is based on complete patient records, why not use entire sequential patient records, rather than just the data preceding some arbitrarily chosen reference point?\n\nUsing all codes in a patient record would have been ideal in some circumstances, but our available hardware limited us to less than that if we wanted reasonable training times. So we constructed our instances to include up to 100 billing code events before the index medication event, regardless of the duration of the resulting sequence. (The time of each event was part of the input instance, so the model can take the time range into account.) This is not as drastic of a constraint as one may think, because 90% of the records in our database had fewer than 100 billing code events. Our sampling scheme was also chosen to ensure similar target representation among all medications to be predicted, which would not have happened if we simply chose, say, the last 100 or first 100 codes in each record.\n\n>Do the cited missing medication rates apply to your training and test data? I.e., are you training and testing your model on incomplete medication data? If so, how would this affect your conclusions? If you filled in the missing medications, how so (and why couldn't that technique be used to directly solve this problem)?\n\nYes, we trained and tested on the (presumed) incomplete medication data. Our hope and further presumption was that the large number of training samples would overcome much of the training error that might occur due to the missing data, so long as those data were not systematically missing (such as certain medications being more likely to be omitted than others.) This was, in fact, the main goal of the work, to train a model to probabilistically fill in the missing items from the incomplete dataset itself. Subjective analysis of our results, presented in Appendix C and discussed in section 4, show that (to some degree, at least) this succeeded. However, we also agree that  missing data in the test set do affect our objective measures of performance, and so we interpret those measures as lower bounds on the actual performance. This is briefly discussed in Section 4.\n\n>When computing your performance metrics, how do you handle the variable number of (medication output) time points per patient record sequence?\n\nThe training target is a single, 182-element-long multi-hot vector, representing all medications appearing in the patient record during the time span of the billing code sequence, and the model predicts a similar multi-hot single vector. We treat this as a multi-label problem, rather than a sequence prediction problem.\n\n>Can you defend your claim that micro-AUC and label ranking loss are robust to the number of positive labels?\n\nYes, although based on these questions we think our original description was misleading. What we were after was a measure in which each training instance had equal weight in the total score, regardless of the number of positive labels that appeared in that instance. In other words, we wanted a measure in which it was not easier to get a higher score if the instance had very many or very few positive labels, because we wanted to reliably select and examine the worst instance predictions. So, for example, micro-AUC is calculated by considering each of the 182 labels for each instance individually, with the loss for that instance and that prediction depending only on the predicted probability of the correct label. An instance with 2 positive labels has no inherent advantage or disadvantage compared to an instance with 180 positive labels; each is the average of the loss for all 182 labels.\n\nLikewise, label ranking loss is the fraction of all possible (positive, negative) label pairs for each instance in which the negative label has a higher predictive score than the positive label. This gives equal weight to each instance, regardless of the number of positives vs. negatives for that instance.\n\nOn the other hand, it's obvious that an instance with two positive labels will more easily get a lower Coverage Error than an instance with 180 positive labels.\n\nWe've changed our description tin section 3.4 to more clearly reflect this intent.\n\n>One of the problems with micro-averaged metrics is that they can make it difficult to judge absolute performance (vs. relative performance between models): predicting each label proportional to its base rate (i.e., slightly more informed random guessing) will score >0.5. How would such a model perform in your task?\n\nThis is an excellent point, and we appreciate you making it. We have added the results for such a model to the manuscript (Table 1 and section 3.3). For convenience, we copy the results here:\n\n* Micro-AUC: 0.8281\n* LR Loss: 0.1724\n* Macro-AUC: 0.5\n* LR Avg. Prec.: 0.3548\n* Cov. Error: 97.2008\n\n>It's interesting that you used a (learned) embedding layer for codes but a manual grouping for [medications]. That seems sensible since one is an input, the other a fixed output, but do you have any thoughts about being able to use a learned grouping for the medications similar to your embedding for codes?\n\nYes, this is another excellent point. We actually did try to learn a medication embedding, but the results were not clinically accurate enough to be useful. We needed the evaluation to reflect the fact that most medications in the same mechanistic class are essentially synonyms, and we initially wanted to learn from the data what those synonyms are. A learned embedding could have gone beyond the yes/no determination of interchangeability, and included a more nuanced view of the degree to which two medications were interchangeable, at least as far as the history of clinical practice is concerned. For reasons that we might speculate but haven't established definitively, the embedding approach showed some success at doing this, but not enough to capture what we were after. But since there are existing curated ontologies that define a rough cut on the equivalence classes, we decided to use them instead.\n\nHowever, we are convinced that learning similarities and subtle differences between medications is possible using methods like semantic embedding. It just seems to require more thoughtful work than it initially appeared."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Predicting Medications from Diagnostic Codes with Recurrent Neural Networks", "abstract": "It is a surprising fact that electronic medical records are failing at one of their primary purposes, that of tracking the set of medications that the patient is actively taking. Studies estimate that up to 50% of such lists omit active drugs, and that up to 25% of all active medications do not appear on the appropriate patient list. Manual efforts to maintain these lists involve a great deal of tedious human labor, which could be reduced by computational tools to suggest likely missing or incorrect medications on a patient\u2019s list. We report here an application of recurrent neural networks to predict the likely therapeutic classes of medications that a patient is taking, given a sequence of the last 100 billing codes in their record. Our best model was a GRU that achieved high prediction accuracy (micro-averaged AUC 0.93, Label Ranking Loss 0.076), limited by hardware constraints on model size. Additionally, examining individual cases revealed that many of the predictions marked incorrect were likely to be examples of either omitted medications or omitted billing codes, supporting our assertion of a substantial number of errors and omissions in the data, and the likelihood of models such as these to help correct them.", "pdf": "/pdf/f612598e357946a8f81772ed1cb0cf561d06bb20.pdf", "TL;DR": "Applying recurrent neural networks to fix errors and omissions in patient medication records.", "paperhash": "bajor|predicting_medications_from_diagnostic_codes_with_recurrent_neural_networks", "conflicts": ["vanderbilt.edu"], "keywords": ["Deep learning", "Supervised Learning", "Applications"], "authors": ["Jacek M. Bajor", "Thomas A. Lasko"], "authorids": ["jacek.m.bajor@vanderbilt.edu", "tom.lasko@vanderbilt.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287735090, "id": "ICLR.cc/2017/conference/-/paper84/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJEgeXFex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper84/reviewers", "ICLR.cc/2017/conference/paper84/areachairs"], "cdate": 1485287735090}}}, {"tddate": null, "tmdate": 1481130071615, "tcdate": 1481130071609, "number": 2, "id": "HyxwgpH7x", "invitation": "ICLR.cc/2017/conference/-/paper84/public/comment", "forum": "rJEgeXFex", "replyto": "SyM4W3kQl", "signatures": ["~Jacek_Bajor1"], "readers": ["everyone"], "writers": ["~Jacek_Bajor1"], "content": {"title": "Response", "comment": "We agree that an SVM with a Gaussian kernel could serve as a relevant benchmark, but we chose a random forest for the following reasons:\n\n1. We wanted a model that would be something like \"close to the best you can do without using a neural network\". (Manuel Fern\u00e1ndez-Delgado, Eva Cernadas, Sen\u00e9n Barro and Dinani Amorim. Do we Need Hundreds of Classifiers to Solve Real World Classification Problems? Journal of Machine Learning Research, 15(Oct):3133\u22123181, 2014).\n2. We wanted a model for which it wouldn't take a lot of work to optimize the hyperparameters.\n3. We wanted a model that wouldn't take an intractable amount of time or space to train on our large dataset. Even as it was, we had to split up the data to train the random forest.\n\nWe modified Section 3.2.3 to better explain this."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Predicting Medications from Diagnostic Codes with Recurrent Neural Networks", "abstract": "It is a surprising fact that electronic medical records are failing at one of their primary purposes, that of tracking the set of medications that the patient is actively taking. Studies estimate that up to 50% of such lists omit active drugs, and that up to 25% of all active medications do not appear on the appropriate patient list. Manual efforts to maintain these lists involve a great deal of tedious human labor, which could be reduced by computational tools to suggest likely missing or incorrect medications on a patient\u2019s list. We report here an application of recurrent neural networks to predict the likely therapeutic classes of medications that a patient is taking, given a sequence of the last 100 billing codes in their record. Our best model was a GRU that achieved high prediction accuracy (micro-averaged AUC 0.93, Label Ranking Loss 0.076), limited by hardware constraints on model size. Additionally, examining individual cases revealed that many of the predictions marked incorrect were likely to be examples of either omitted medications or omitted billing codes, supporting our assertion of a substantial number of errors and omissions in the data, and the likelihood of models such as these to help correct them.", "pdf": "/pdf/f612598e357946a8f81772ed1cb0cf561d06bb20.pdf", "TL;DR": "Applying recurrent neural networks to fix errors and omissions in patient medication records.", "paperhash": "bajor|predicting_medications_from_diagnostic_codes_with_recurrent_neural_networks", "conflicts": ["vanderbilt.edu"], "keywords": ["Deep learning", "Supervised Learning", "Applications"], "authors": ["Jacek M. Bajor", "Thomas A. Lasko"], "authorids": ["jacek.m.bajor@vanderbilt.edu", "tom.lasko@vanderbilt.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287735090, "id": "ICLR.cc/2017/conference/-/paper84/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJEgeXFex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper84/reviewers", "ICLR.cc/2017/conference/paper84/areachairs"], "cdate": 1485287735090}}}, {"tddate": null, "tmdate": 1480734635717, "tcdate": 1480734635711, "number": 3, "id": "r1Nnw3ymx", "invitation": "ICLR.cc/2017/conference/-/paper84/pre-review/question", "forum": "rJEgeXFex", "replyto": "rJEgeXFex", "signatures": ["ICLR.cc/2017/conference/paper84/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper84/AnonReviewer1"], "content": {"title": "Task setup details a little unclear", "question": "A very interesting empirical paper. I am a little unclear about your task setup, as well as your motivation for its particular design:\n\n* Do your (input) codes and (output) medications include the entire sequence of codes and medications prior to the reference point? Or simply the just the prior 100 codes, regardless of duration of the sequence they span? Why not use all prior codes and medications?\n\n* Following up on that point, since your training/validation/test split is based on complete patient records, why not use entire sequential patient records, rather than just the data preceding some arbitrarily chosen reference point?\n\n* Do the cited missing medication rates apply to your training and test data? I.e., are you training and testing your model on incomplete medication data? If so, how would this affect your conclusions? If you filled in the missing medications, how so (and why couldn't that technique be used to directly solve this problem)?\n\n* When computing your performance metrics, how do you handle the variable number of (medication output) time points per patient record sequence?\n\nSome unrelated questions:\n\n* Can you defend your claim that micro-AUC and label ranking loss are robust to the number of positive labels?\n\n* One of the problems with micro-averaged metrics is that they can make it difficult to judge absolute performance (vs. relative performance between models): predicting each label proportional to its base rate (i.e., slightly more informed random guessing) will score >0.5. How would such a model perform in your task?\n\n* It's interesting that you used a (learned) embedding layer for codes but a manual grouping for codes. That seems sensible since one is an input, the other a fixed output, but do you have any thoughts about being able to use a learned grouping for the medications similar to your embedding for codes?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Predicting Medications from Diagnostic Codes with Recurrent Neural Networks", "abstract": "It is a surprising fact that electronic medical records are failing at one of their primary purposes, that of tracking the set of medications that the patient is actively taking. Studies estimate that up to 50% of such lists omit active drugs, and that up to 25% of all active medications do not appear on the appropriate patient list. Manual efforts to maintain these lists involve a great deal of tedious human labor, which could be reduced by computational tools to suggest likely missing or incorrect medications on a patient\u2019s list. We report here an application of recurrent neural networks to predict the likely therapeutic classes of medications that a patient is taking, given a sequence of the last 100 billing codes in their record. Our best model was a GRU that achieved high prediction accuracy (micro-averaged AUC 0.93, Label Ranking Loss 0.076), limited by hardware constraints on model size. Additionally, examining individual cases revealed that many of the predictions marked incorrect were likely to be examples of either omitted medications or omitted billing codes, supporting our assertion of a substantial number of errors and omissions in the data, and the likelihood of models such as these to help correct them.", "pdf": "/pdf/f612598e357946a8f81772ed1cb0cf561d06bb20.pdf", "TL;DR": "Applying recurrent neural networks to fix errors and omissions in patient medication records.", "paperhash": "bajor|predicting_medications_from_diagnostic_codes_with_recurrent_neural_networks", "conflicts": ["vanderbilt.edu"], "keywords": ["Deep learning", "Supervised Learning", "Applications"], "authors": ["Jacek M. Bajor", "Thomas A. Lasko"], "authorids": ["jacek.m.bajor@vanderbilt.edu", "tom.lasko@vanderbilt.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959471809, "id": "ICLR.cc/2017/conference/-/paper84/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper84/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper84/AnonReviewer2", "ICLR.cc/2017/conference/paper84/AnonReviewer3", "ICLR.cc/2017/conference/paper84/AnonReviewer1"], "reply": {"forum": "rJEgeXFex", "replyto": "rJEgeXFex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper84/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper84/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959471809}}}, {"tddate": null, "tmdate": 1480732970183, "tcdate": 1480732970179, "number": 2, "id": "SyM4W3kQl", "invitation": "ICLR.cc/2017/conference/-/paper84/pre-review/question", "forum": "rJEgeXFex", "replyto": "rJEgeXFex", "signatures": ["ICLR.cc/2017/conference/paper84/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper84/AnonReviewer3"], "content": {"title": "Baselines", "question": "This well-written paper has thorough analysis. My one question is about the baseline used in this paper: random forests. Would not a kernel-based method (e.g., SVM with Gaussian kernel) be a simpler and more relevant model to benchmark the contribution of deep learning methods?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Predicting Medications from Diagnostic Codes with Recurrent Neural Networks", "abstract": "It is a surprising fact that electronic medical records are failing at one of their primary purposes, that of tracking the set of medications that the patient is actively taking. Studies estimate that up to 50% of such lists omit active drugs, and that up to 25% of all active medications do not appear on the appropriate patient list. Manual efforts to maintain these lists involve a great deal of tedious human labor, which could be reduced by computational tools to suggest likely missing or incorrect medications on a patient\u2019s list. We report here an application of recurrent neural networks to predict the likely therapeutic classes of medications that a patient is taking, given a sequence of the last 100 billing codes in their record. Our best model was a GRU that achieved high prediction accuracy (micro-averaged AUC 0.93, Label Ranking Loss 0.076), limited by hardware constraints on model size. Additionally, examining individual cases revealed that many of the predictions marked incorrect were likely to be examples of either omitted medications or omitted billing codes, supporting our assertion of a substantial number of errors and omissions in the data, and the likelihood of models such as these to help correct them.", "pdf": "/pdf/f612598e357946a8f81772ed1cb0cf561d06bb20.pdf", "TL;DR": "Applying recurrent neural networks to fix errors and omissions in patient medication records.", "paperhash": "bajor|predicting_medications_from_diagnostic_codes_with_recurrent_neural_networks", "conflicts": ["vanderbilt.edu"], "keywords": ["Deep learning", "Supervised Learning", "Applications"], "authors": ["Jacek M. Bajor", "Thomas A. Lasko"], "authorids": ["jacek.m.bajor@vanderbilt.edu", "tom.lasko@vanderbilt.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959471809, "id": "ICLR.cc/2017/conference/-/paper84/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper84/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper84/AnonReviewer2", "ICLR.cc/2017/conference/paper84/AnonReviewer3", "ICLR.cc/2017/conference/paper84/AnonReviewer1"], "reply": {"forum": "rJEgeXFex", "replyto": "rJEgeXFex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper84/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper84/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959471809}}}, {"tddate": null, "tmdate": 1480713369743, "tcdate": 1480713369739, "number": 1, "id": "BJziEP1Qx", "invitation": "ICLR.cc/2017/conference/-/paper84/pre-review/question", "forum": "rJEgeXFex", "replyto": "rJEgeXFex", "signatures": ["ICLR.cc/2017/conference/paper84/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper84/AnonReviewer2"], "content": {"title": "distinction vs Choi et al 2016b", "question": "Can you provide more detail as to the distinction with Choi et al 2016b?  It appears they use a GRU similar to your optimal architecture (in the sense of Table 1).  Is the only difference here the data set?  Given the similarity and the recency of that work, I'd like to have a detailed understanding of what novelty you propose here.  Have you used their method on your dataset, and if so, what performance results?  What key extensions do you propose here?  Thank you."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Predicting Medications from Diagnostic Codes with Recurrent Neural Networks", "abstract": "It is a surprising fact that electronic medical records are failing at one of their primary purposes, that of tracking the set of medications that the patient is actively taking. Studies estimate that up to 50% of such lists omit active drugs, and that up to 25% of all active medications do not appear on the appropriate patient list. Manual efforts to maintain these lists involve a great deal of tedious human labor, which could be reduced by computational tools to suggest likely missing or incorrect medications on a patient\u2019s list. We report here an application of recurrent neural networks to predict the likely therapeutic classes of medications that a patient is taking, given a sequence of the last 100 billing codes in their record. Our best model was a GRU that achieved high prediction accuracy (micro-averaged AUC 0.93, Label Ranking Loss 0.076), limited by hardware constraints on model size. Additionally, examining individual cases revealed that many of the predictions marked incorrect were likely to be examples of either omitted medications or omitted billing codes, supporting our assertion of a substantial number of errors and omissions in the data, and the likelihood of models such as these to help correct them.", "pdf": "/pdf/f612598e357946a8f81772ed1cb0cf561d06bb20.pdf", "TL;DR": "Applying recurrent neural networks to fix errors and omissions in patient medication records.", "paperhash": "bajor|predicting_medications_from_diagnostic_codes_with_recurrent_neural_networks", "conflicts": ["vanderbilt.edu"], "keywords": ["Deep learning", "Supervised Learning", "Applications"], "authors": ["Jacek M. Bajor", "Thomas A. Lasko"], "authorids": ["jacek.m.bajor@vanderbilt.edu", "tom.lasko@vanderbilt.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959471809, "id": "ICLR.cc/2017/conference/-/paper84/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper84/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper84/AnonReviewer2", "ICLR.cc/2017/conference/paper84/AnonReviewer3", "ICLR.cc/2017/conference/paper84/AnonReviewer1"], "reply": {"forum": "rJEgeXFex", "replyto": "rJEgeXFex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper84/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper84/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959471809}}}], "count": 16}