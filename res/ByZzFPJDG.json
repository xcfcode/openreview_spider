{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124293488, "tcdate": 1518463240945, "number": 221, "cdate": 1518463240945, "id": "ByZzFPJDG", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "ByZzFPJDG", "signatures": ["~Maxim_Vadimovich_Kochurov1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Bayesian Incremental Learning for Deep Neural Networks", "abstract": "In industrial machine learning pipelines, data often arrive in parts. Particularly in the case of deep neural networks, it may be too expensive to train the model from scratch each time, so one would rather use a previously learned model and the new data to improve performance. However, deep neural networks are prone to getting stuck in a suboptimal solution when trained on only new data as compared to the full dataset. Our work focuses on a continuous learning setup where the task is always the same and new parts of data arrive sequentially. We apply a Bayesian approach to update the posterior approximation with each new piece of data and find this method to outperform the traditional approach in our experiments.", "paperhash": "kochurov|bayesian_incremental_learning_for_deep_neural_networks", "keywords": ["variational inference", "incremental learning", "Bayesian neural networks"], "_bibtex": "@misc{\n  kochurov2018bayesian,\n  title={Bayesian Incremental Learning for Deep Neural Networks},\n  author={Max Kochurov and Timur Garipov and Dmitry Podoprikhin and Dmitry Molchanov and Arsenii Ashukha and Dmitry Vetrov},\n  year={2018},\n  url={https://openreview.net/forum?id=ByZzFPJDG}\n}", "authorids": ["maxim.v.kochurov@gmail.com", "timgaripov@gmail.com", "timmyofmexico@gmail.com", "dmolch111@gmail.com", "ars.ashuha@gmail.com", "vetrodim@gmail.com"], "authors": ["Max Kochurov", "Timur Garipov", "Dmitry Podoprikhin", "Dmitry Molchanov", "Arsenii Ashukha", "Dmitry Vetrov"], "TL;DR": "We propose a Bayesian incremental learning algorithm with a way to use pre-trained DNNs", "pdf": "/pdf/9320ab0564d3fb9b4884b2fc72a4b7799c56e984.pdf"}, "nonreaders": [], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "tmdate": 1522319859594, "tcdate": 1522319859594, "number": 1, "cdate": 1522319859594, "id": "rk2ezScqM", "invitation": "ICLR.cc/2018/Workshop/-/Paper221/Public_Comment", "forum": "ByZzFPJDG", "replyto": "ByZzFPJDG", "signatures": ["~Thang_D_Bui1"], "readers": ["everyone"], "writers": ["~Thang_D_Bui1"], "content": {"title": "Variational continual learning (arxiv 2017, ICLR 2018)", "comment": "We enjoyed reading your paper. However, we believe that the relationship to Variational Continual Learning [1] should be made explicit. Variational Continual Learning uses the same general setup: a combination of online variational inference and Monte Carlo variational inference employing the reparameterization trick.\n\n[1] Cuong V. Nguyen, Yingzhen Li, Thang D. Bui, and Richard E. Turner. Variational continual learning, 2017.\n\nFull disclosure: we are the authors of this paper."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bayesian Incremental Learning for Deep Neural Networks", "abstract": "In industrial machine learning pipelines, data often arrive in parts. Particularly in the case of deep neural networks, it may be too expensive to train the model from scratch each time, so one would rather use a previously learned model and the new data to improve performance. However, deep neural networks are prone to getting stuck in a suboptimal solution when trained on only new data as compared to the full dataset. Our work focuses on a continuous learning setup where the task is always the same and new parts of data arrive sequentially. We apply a Bayesian approach to update the posterior approximation with each new piece of data and find this method to outperform the traditional approach in our experiments.", "paperhash": "kochurov|bayesian_incremental_learning_for_deep_neural_networks", "keywords": ["variational inference", "incremental learning", "Bayesian neural networks"], "_bibtex": "@misc{\n  kochurov2018bayesian,\n  title={Bayesian Incremental Learning for Deep Neural Networks},\n  author={Max Kochurov and Timur Garipov and Dmitry Podoprikhin and Dmitry Molchanov and Arsenii Ashukha and Dmitry Vetrov},\n  year={2018},\n  url={https://openreview.net/forum?id=ByZzFPJDG}\n}", "authorids": ["maxim.v.kochurov@gmail.com", "timgaripov@gmail.com", "timmyofmexico@gmail.com", "dmolch111@gmail.com", "ars.ashuha@gmail.com", "vetrodim@gmail.com"], "authors": ["Max Kochurov", "Timur Garipov", "Dmitry Podoprikhin", "Dmitry Molchanov", "Arsenii Ashukha", "Dmitry Vetrov"], "TL;DR": "We propose a Bayesian incremental learning algorithm with a way to use pre-trained DNNs", "pdf": "/pdf/9320ab0564d3fb9b4884b2fc72a4b7799c56e984.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712624693, "id": "ICLR.cc/2018/Workshop/-/Paper221/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper221/Reviewers"], "reply": {"replyto": null, "forum": "ByZzFPJDG", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712624693}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582992796, "tcdate": 1519419224399, "number": 1, "cdate": 1519419224399, "id": "SkxP1bCPz", "invitation": "ICLR.cc/2018/Workshop/-/Paper221/Official_Review", "forum": "ByZzFPJDG", "replyto": "ByZzFPJDG", "signatures": ["ICLR.cc/2018/Workshop/Paper221/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper221/AnonReviewer3"], "content": {"title": "Interesting ", "rating": "8: Top 50% of accepted papers, clear accept", "review": "The idea of applying Bayesian updates to effect online learning is not new. However, this paper provides interesting insights regarding the technical implementation details that are needed for applying this concept to deep networks.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bayesian Incremental Learning for Deep Neural Networks", "abstract": "In industrial machine learning pipelines, data often arrive in parts. Particularly in the case of deep neural networks, it may be too expensive to train the model from scratch each time, so one would rather use a previously learned model and the new data to improve performance. However, deep neural networks are prone to getting stuck in a suboptimal solution when trained on only new data as compared to the full dataset. Our work focuses on a continuous learning setup where the task is always the same and new parts of data arrive sequentially. We apply a Bayesian approach to update the posterior approximation with each new piece of data and find this method to outperform the traditional approach in our experiments.", "paperhash": "kochurov|bayesian_incremental_learning_for_deep_neural_networks", "keywords": ["variational inference", "incremental learning", "Bayesian neural networks"], "_bibtex": "@misc{\n  kochurov2018bayesian,\n  title={Bayesian Incremental Learning for Deep Neural Networks},\n  author={Max Kochurov and Timur Garipov and Dmitry Podoprikhin and Dmitry Molchanov and Arsenii Ashukha and Dmitry Vetrov},\n  year={2018},\n  url={https://openreview.net/forum?id=ByZzFPJDG}\n}", "authorids": ["maxim.v.kochurov@gmail.com", "timgaripov@gmail.com", "timmyofmexico@gmail.com", "dmolch111@gmail.com", "ars.ashuha@gmail.com", "vetrodim@gmail.com"], "authors": ["Max Kochurov", "Timur Garipov", "Dmitry Podoprikhin", "Dmitry Molchanov", "Arsenii Ashukha", "Dmitry Vetrov"], "TL;DR": "We propose a Bayesian incremental learning algorithm with a way to use pre-trained DNNs", "pdf": "/pdf/9320ab0564d3fb9b4884b2fc72a4b7799c56e984.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582992594, "id": "ICLR.cc/2018/Workshop/-/Paper221/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper221/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper221/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper221/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper221/AnonReviewer2"], "reply": {"forum": "ByZzFPJDG", "replyto": "ByZzFPJDG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper221/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper221/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582992594}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582711098, "tcdate": 1520688452048, "number": 2, "cdate": 1520688452048, "id": "HJ3SaU-Yf", "invitation": "ICLR.cc/2018/Workshop/-/Paper221/Official_Review", "forum": "ByZzFPJDG", "replyto": "ByZzFPJDG", "signatures": ["ICLR.cc/2018/Workshop/Paper221/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper221/AnonReviewer1"], "content": {"title": "Simple but practical idea, systematically tested.", "rating": "7: Good paper, accept", "review": "In this work, Bayesian online updating is used to update the weights of a DNN as more training data becomes available. To avoid the direct intractability, a variational lower bound is used to approximately compute the updated weight densities. Different approximating distributions for the posterior are considered. Pretraining is framed as using a prior in this approach.\n\nThe paper is clearly written and systematically tests several potential approximating distributions, instead of simply considering mean field. The experiments show the clear advantage of the proposed approach with respect to fine-tuning, as well as the influence in accuracy of different posterior families.\n\nNot a very novel approach, but targeting a useful use case and well-executed evaluation.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bayesian Incremental Learning for Deep Neural Networks", "abstract": "In industrial machine learning pipelines, data often arrive in parts. Particularly in the case of deep neural networks, it may be too expensive to train the model from scratch each time, so one would rather use a previously learned model and the new data to improve performance. However, deep neural networks are prone to getting stuck in a suboptimal solution when trained on only new data as compared to the full dataset. Our work focuses on a continuous learning setup where the task is always the same and new parts of data arrive sequentially. We apply a Bayesian approach to update the posterior approximation with each new piece of data and find this method to outperform the traditional approach in our experiments.", "paperhash": "kochurov|bayesian_incremental_learning_for_deep_neural_networks", "keywords": ["variational inference", "incremental learning", "Bayesian neural networks"], "_bibtex": "@misc{\n  kochurov2018bayesian,\n  title={Bayesian Incremental Learning for Deep Neural Networks},\n  author={Max Kochurov and Timur Garipov and Dmitry Podoprikhin and Dmitry Molchanov and Arsenii Ashukha and Dmitry Vetrov},\n  year={2018},\n  url={https://openreview.net/forum?id=ByZzFPJDG}\n}", "authorids": ["maxim.v.kochurov@gmail.com", "timgaripov@gmail.com", "timmyofmexico@gmail.com", "dmolch111@gmail.com", "ars.ashuha@gmail.com", "vetrodim@gmail.com"], "authors": ["Max Kochurov", "Timur Garipov", "Dmitry Podoprikhin", "Dmitry Molchanov", "Arsenii Ashukha", "Dmitry Vetrov"], "TL;DR": "We propose a Bayesian incremental learning algorithm with a way to use pre-trained DNNs", "pdf": "/pdf/9320ab0564d3fb9b4884b2fc72a4b7799c56e984.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582992594, "id": "ICLR.cc/2018/Workshop/-/Paper221/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper221/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper221/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper221/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper221/AnonReviewer2"], "reply": {"forum": "ByZzFPJDG", "replyto": "ByZzFPJDG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper221/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper221/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582992594}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582633962, "tcdate": 1520815600056, "number": 3, "cdate": 1520815600056, "id": "SyOgRBXFM", "invitation": "ICLR.cc/2018/Workshop/-/Paper221/Official_Review", "forum": "ByZzFPJDG", "replyto": "ByZzFPJDG", "signatures": ["ICLR.cc/2018/Workshop/Paper221/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper221/AnonReviewer2"], "content": {"title": "Straightforward approach but informative experimental results", "rating": "6: Marginally above acceptance threshold", "review": "This paper proposed incremental learning based on the Bayesian framework which inherently has the incremental update.\nThe approach is straightforward but the experimental results seem to be interesting and informative for ICLR workshop.\nThey may lead to the next important step for Bayesian deep learning.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bayesian Incremental Learning for Deep Neural Networks", "abstract": "In industrial machine learning pipelines, data often arrive in parts. Particularly in the case of deep neural networks, it may be too expensive to train the model from scratch each time, so one would rather use a previously learned model and the new data to improve performance. However, deep neural networks are prone to getting stuck in a suboptimal solution when trained on only new data as compared to the full dataset. Our work focuses on a continuous learning setup where the task is always the same and new parts of data arrive sequentially. We apply a Bayesian approach to update the posterior approximation with each new piece of data and find this method to outperform the traditional approach in our experiments.", "paperhash": "kochurov|bayesian_incremental_learning_for_deep_neural_networks", "keywords": ["variational inference", "incremental learning", "Bayesian neural networks"], "_bibtex": "@misc{\n  kochurov2018bayesian,\n  title={Bayesian Incremental Learning for Deep Neural Networks},\n  author={Max Kochurov and Timur Garipov and Dmitry Podoprikhin and Dmitry Molchanov and Arsenii Ashukha and Dmitry Vetrov},\n  year={2018},\n  url={https://openreview.net/forum?id=ByZzFPJDG}\n}", "authorids": ["maxim.v.kochurov@gmail.com", "timgaripov@gmail.com", "timmyofmexico@gmail.com", "dmolch111@gmail.com", "ars.ashuha@gmail.com", "vetrodim@gmail.com"], "authors": ["Max Kochurov", "Timur Garipov", "Dmitry Podoprikhin", "Dmitry Molchanov", "Arsenii Ashukha", "Dmitry Vetrov"], "TL;DR": "We propose a Bayesian incremental learning algorithm with a way to use pre-trained DNNs", "pdf": "/pdf/9320ab0564d3fb9b4884b2fc72a4b7799c56e984.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582992594, "id": "ICLR.cc/2018/Workshop/-/Paper221/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper221/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper221/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper221/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper221/AnonReviewer2"], "reply": {"forum": "ByZzFPJDG", "replyto": "ByZzFPJDG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper221/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper221/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582992594}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573551650, "tcdate": 1521573551650, "number": 37, "cdate": 1521573551307, "id": "B1dnRAAtM", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "ByZzFPJDG", "replyto": "ByZzFPJDG", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bayesian Incremental Learning for Deep Neural Networks", "abstract": "In industrial machine learning pipelines, data often arrive in parts. Particularly in the case of deep neural networks, it may be too expensive to train the model from scratch each time, so one would rather use a previously learned model and the new data to improve performance. However, deep neural networks are prone to getting stuck in a suboptimal solution when trained on only new data as compared to the full dataset. Our work focuses on a continuous learning setup where the task is always the same and new parts of data arrive sequentially. We apply a Bayesian approach to update the posterior approximation with each new piece of data and find this method to outperform the traditional approach in our experiments.", "paperhash": "kochurov|bayesian_incremental_learning_for_deep_neural_networks", "keywords": ["variational inference", "incremental learning", "Bayesian neural networks"], "_bibtex": "@misc{\n  kochurov2018bayesian,\n  title={Bayesian Incremental Learning for Deep Neural Networks},\n  author={Max Kochurov and Timur Garipov and Dmitry Podoprikhin and Dmitry Molchanov and Arsenii Ashukha and Dmitry Vetrov},\n  year={2018},\n  url={https://openreview.net/forum?id=ByZzFPJDG}\n}", "authorids": ["maxim.v.kochurov@gmail.com", "timgaripov@gmail.com", "timmyofmexico@gmail.com", "dmolch111@gmail.com", "ars.ashuha@gmail.com", "vetrodim@gmail.com"], "authors": ["Max Kochurov", "Timur Garipov", "Dmitry Podoprikhin", "Dmitry Molchanov", "Arsenii Ashukha", "Dmitry Vetrov"], "TL;DR": "We propose a Bayesian incremental learning algorithm with a way to use pre-trained DNNs", "pdf": "/pdf/9320ab0564d3fb9b4884b2fc72a4b7799c56e984.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 6}