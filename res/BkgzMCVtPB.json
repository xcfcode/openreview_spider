{"notes": [{"id": "BkgzMCVtPB", "original": "Bkgr5o4OPr", "number": 995, "cdate": 1569439242282, "ddate": null, "tcdate": 1569439242282, "tmdate": 1583912047044, "tddate": null, "forum": "BkgzMCVtPB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Optimal Strategies Against Generative Attacks", "authors": ["Roy Mor", "Erez Peterfreund", "Matan Gavish", "Amir Globerson"], "authorids": ["roy16mor@gmail.com", "erezpeter@cs.huji.ac.il", "matan.gavish@mail.huji.ac.il", "amir.globerson@gmail.com"], "keywords": [], "abstract": "Generative neural models have improved dramatically recently. With this progress comes the risk that such models will be used to attack systems that rely on sensor data for authentication and anomaly detection. Many such learning systems are installed worldwide, protecting critical infrastructure or private data against malfunction and cyber attacks. We formulate the scenario of such an authentication system facing generative impersonation attacks, characterize it from a theoretical perspective and explore its practical implications. In particular, we ask fundamental theoretical questions in learning, statistics and information theory: How hard is it to detect a \"fake reality\"? How much data does the attacker need to collect before it can reliably generate nominally-looking artificial data? Are there optimal strategies for the attacker or the authenticator? We cast the problem as a maximin game, characterize the optimal strategy for both attacker and authenticator in the general case, and provide the optimal strategies in closed form for the case of Gaussian source distributions. Our analysis reveals the structure of the optimal attack and the relative importance of data collection for both authenticator and attacker. Based on these insights we design practical learning approaches and show that they result in models that are more robust to various attacks on real-world data.", "pdf": "/pdf/b1e4d05cc1d50ea1b844e9acb434fb509e067e2f.pdf", "code": "https://github.com/roymor1/OptimalStrategiesAgainstGenerativeAttacks", "paperhash": "mor|optimal_strategies_against_generative_attacks", "_bibtex": "@inproceedings{\nMor2020Optimal,\ntitle={Optimal Strategies Against Generative Attacks},\nauthor={Roy Mor and Erez Peterfreund and Matan Gavish and Amir Globerson},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkgzMCVtPB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/ec5b70b89e7d868956419723a966330475390e96.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "sH9vCYg_1", "original": null, "number": 1, "cdate": 1576798711716, "ddate": null, "tcdate": 1576798711716, "tmdate": 1576800924666, "tddate": null, "forum": "BkgzMCVtPB", "replyto": "BkgzMCVtPB", "invitation": "ICLR.cc/2020/Conference/Paper995/-/Decision", "content": {"decision": "Accept (Talk)", "comment": "This paper concerns the problem of defending against generative \"attacks\": that is, falsification of data for malicious purposes through the use of synthesized data based on \"leaked\" samples of real data. The paper casts the problem formally and assesses the problem of authentication in terms of the sample complexity at test time and the sample budget of the attacker. The authors prove a Nash equillibrium exists, derive a closed form for the special case of multivariate Gaussian data, and propose an algorithm called GAN in the Middle leveraging the developed principles, showing an implementation to perform better than authentication baselines and suggesting other applications.\n\nReviewers were overall very positive, in agreement that the problem addressed is important and the contribution made is significant. Most criticisms were superficial. This is a dense piece of work, and presentation could still be improved. However this is clearly a significant piece of work addressing a problem of increasing importance, and is worthy of acceptance.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimal Strategies Against Generative Attacks", "authors": ["Roy Mor", "Erez Peterfreund", "Matan Gavish", "Amir Globerson"], "authorids": ["roy16mor@gmail.com", "erezpeter@cs.huji.ac.il", "matan.gavish@mail.huji.ac.il", "amir.globerson@gmail.com"], "keywords": [], "abstract": "Generative neural models have improved dramatically recently. With this progress comes the risk that such models will be used to attack systems that rely on sensor data for authentication and anomaly detection. Many such learning systems are installed worldwide, protecting critical infrastructure or private data against malfunction and cyber attacks. We formulate the scenario of such an authentication system facing generative impersonation attacks, characterize it from a theoretical perspective and explore its practical implications. In particular, we ask fundamental theoretical questions in learning, statistics and information theory: How hard is it to detect a \"fake reality\"? How much data does the attacker need to collect before it can reliably generate nominally-looking artificial data? Are there optimal strategies for the attacker or the authenticator? We cast the problem as a maximin game, characterize the optimal strategy for both attacker and authenticator in the general case, and provide the optimal strategies in closed form for the case of Gaussian source distributions. Our analysis reveals the structure of the optimal attack and the relative importance of data collection for both authenticator and attacker. Based on these insights we design practical learning approaches and show that they result in models that are more robust to various attacks on real-world data.", "pdf": "/pdf/b1e4d05cc1d50ea1b844e9acb434fb509e067e2f.pdf", "code": "https://github.com/roymor1/OptimalStrategiesAgainstGenerativeAttacks", "paperhash": "mor|optimal_strategies_against_generative_attacks", "_bibtex": "@inproceedings{\nMor2020Optimal,\ntitle={Optimal Strategies Against Generative Attacks},\nauthor={Roy Mor and Erez Peterfreund and Matan Gavish and Amir Globerson},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkgzMCVtPB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/ec5b70b89e7d868956419723a966330475390e96.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "BkgzMCVtPB", "replyto": "BkgzMCVtPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795721759, "tmdate": 1576800272907, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper995/-/Decision"}}}, {"id": "r1lRr8jocr", "original": null, "number": 4, "cdate": 1572742726093, "ddate": null, "tcdate": 1572742726093, "tmdate": 1574349329379, "tddate": null, "forum": "BkgzMCVtPB", "replyto": "BkgzMCVtPB", "invitation": "ICLR.cc/2020/Conference/Paper995/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #3", "review": "This paper addresses the issue of malicious use of generative models to fool authentication/anomaly detection systems that rely on sensor data. The authors formulate the scenario as a maxmin game between an authenticator and an attacker, with limitations on the number of samples available to the authenticator to fix a decision rule, the number of samples required at test time for the authenticator to take a decision and the number of leaked samples the attacker has access to. The authors prove that the game admits a Nash equilibrium and derive a closed form solution for the case of multivariate Gaussian data. Finally, the authors propose an algorithm called \"GAN In the Middle\" and perform experiments to show consistency with the theoretical results, better authentication performance than state of the art methods and usability for data augmentation.\n\nThis pager should be accepted. Overall, it addresses crucial problems with the recent advances of generative models and provides significant theoretical results. The experiments would benefit from some clarification.\n\nFor the experiments, the following should be addressed:\n* Confidence intervals for all results (specifically in Figure 1a and in Table 1)\n* Figure 1a: it would be interesting to see a similar analysis also for other values of m and k. \n* Table 1: This result would also be more supporting if experiments were performed for varying values of m, n and k. The description of the RS attack could be made more precise: does it mean that the attacker samples images at random? Intuitively, it feels confusing that the GIM authenticator would perform worse on this setting.\n* The experiments on handwritten data would be more similar to what I imagine being a real-world authentication scenario  if performed on a task where a class is a single person writing multiple characters, as opposed to characters being classes.\n\n\nMinor comments:\n* Page 6, second to last row: there is a\"the\" repeated twice.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper995/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper995/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimal Strategies Against Generative Attacks", "authors": ["Roy Mor", "Erez Peterfreund", "Matan Gavish", "Amir Globerson"], "authorids": ["roy16mor@gmail.com", "erezpeter@cs.huji.ac.il", "matan.gavish@mail.huji.ac.il", "amir.globerson@gmail.com"], "keywords": [], "abstract": "Generative neural models have improved dramatically recently. With this progress comes the risk that such models will be used to attack systems that rely on sensor data for authentication and anomaly detection. Many such learning systems are installed worldwide, protecting critical infrastructure or private data against malfunction and cyber attacks. We formulate the scenario of such an authentication system facing generative impersonation attacks, characterize it from a theoretical perspective and explore its practical implications. In particular, we ask fundamental theoretical questions in learning, statistics and information theory: How hard is it to detect a \"fake reality\"? How much data does the attacker need to collect before it can reliably generate nominally-looking artificial data? Are there optimal strategies for the attacker or the authenticator? We cast the problem as a maximin game, characterize the optimal strategy for both attacker and authenticator in the general case, and provide the optimal strategies in closed form for the case of Gaussian source distributions. Our analysis reveals the structure of the optimal attack and the relative importance of data collection for both authenticator and attacker. Based on these insights we design practical learning approaches and show that they result in models that are more robust to various attacks on real-world data.", "pdf": "/pdf/b1e4d05cc1d50ea1b844e9acb434fb509e067e2f.pdf", "code": "https://github.com/roymor1/OptimalStrategiesAgainstGenerativeAttacks", "paperhash": "mor|optimal_strategies_against_generative_attacks", "_bibtex": "@inproceedings{\nMor2020Optimal,\ntitle={Optimal Strategies Against Generative Attacks},\nauthor={Roy Mor and Erez Peterfreund and Matan Gavish and Amir Globerson},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkgzMCVtPB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/ec5b70b89e7d868956419723a966330475390e96.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BkgzMCVtPB", "replyto": "BkgzMCVtPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper995/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper995/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575860012338, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper995/Reviewers"], "noninvitees": [], "tcdate": 1570237743924, "tmdate": 1575860012352, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper995/-/Official_Review"}}}, {"id": "BkeCz02Lsr", "original": null, "number": 4, "cdate": 1573469718036, "ddate": null, "tcdate": 1573469718036, "tmdate": 1573469718036, "tddate": null, "forum": "BkgzMCVtPB", "replyto": "rJliBd199H", "invitation": "ICLR.cc/2020/Conference/Paper995/-/Official_Comment", "content": {"title": "Thank you very much for your review and great comments.", "comment": "Thank you very much for your review and positive comments. We address specific comments below:\n\n- Reviewer comment:\n\"I am unclear on how the data augmentation experiment fits into the overall picture - perhaps a more detailed explanation of how and why this would be used to form an \"attack\" would help.\"\n\n- Response:\nThe GIM architecture receives as input a set of m iid examples (e.g., images) drawn from a source distribution, and outputs a set of n > m examples that \u201care similar\u201d to those drawn iid from the same source distribution. \nThus, GIM can be also used for data augmentation in the context of few-shot learning, where one receives a (usually small) set of examples of a class and wants to generate more instances of this class for training a classifier. We included these experiments in order to show that GIM performs well in this setting, and can thus be used in applications beyond authentication. \n\n- Reviewer comment:\n\"This is a solid paper, and most of my critiques are \"out of scope\" and revolve around experiments that would be nice to see. Though GAN-for-text is not simple, showing this type of setup for text would be interesting for a number of reasons, same for audio.\"\n\n- Response:\nThe idea to extend the current work to signals such as text, audio and video is indeed very interesting, and we plan to do follow up work in these directions: both theoretical (e.g. extend the iid setting to sources that generate stochastic sequences with assumptions such as Markov chains or Hidden Markov models), as well as applied (e.g., training GIM for text, audio and video).\n\n- Reviewer comment:\n\"Continual passes through the text, with a focus on clarity could also be helpful - the topic is dense, and the text does a good job describing what is happening, but it is always possible to further distill these complex topics, and relegate some useful-but-not-critical pieces to the appendix.\"\n\n- Response:\nWe will further edit and restructure the text as you suggested before the camera ready version.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper995/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper995/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimal Strategies Against Generative Attacks", "authors": ["Roy Mor", "Erez Peterfreund", "Matan Gavish", "Amir Globerson"], "authorids": ["roy16mor@gmail.com", "erezpeter@cs.huji.ac.il", "matan.gavish@mail.huji.ac.il", "amir.globerson@gmail.com"], "keywords": [], "abstract": "Generative neural models have improved dramatically recently. With this progress comes the risk that such models will be used to attack systems that rely on sensor data for authentication and anomaly detection. Many such learning systems are installed worldwide, protecting critical infrastructure or private data against malfunction and cyber attacks. We formulate the scenario of such an authentication system facing generative impersonation attacks, characterize it from a theoretical perspective and explore its practical implications. In particular, we ask fundamental theoretical questions in learning, statistics and information theory: How hard is it to detect a \"fake reality\"? How much data does the attacker need to collect before it can reliably generate nominally-looking artificial data? Are there optimal strategies for the attacker or the authenticator? We cast the problem as a maximin game, characterize the optimal strategy for both attacker and authenticator in the general case, and provide the optimal strategies in closed form for the case of Gaussian source distributions. Our analysis reveals the structure of the optimal attack and the relative importance of data collection for both authenticator and attacker. Based on these insights we design practical learning approaches and show that they result in models that are more robust to various attacks on real-world data.", "pdf": "/pdf/b1e4d05cc1d50ea1b844e9acb434fb509e067e2f.pdf", "code": "https://github.com/roymor1/OptimalStrategiesAgainstGenerativeAttacks", "paperhash": "mor|optimal_strategies_against_generative_attacks", "_bibtex": "@inproceedings{\nMor2020Optimal,\ntitle={Optimal Strategies Against Generative Attacks},\nauthor={Roy Mor and Erez Peterfreund and Matan Gavish and Amir Globerson},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkgzMCVtPB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/ec5b70b89e7d868956419723a966330475390e96.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkgzMCVtPB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper995/Authors", "ICLR.cc/2020/Conference/Paper995/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper995/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper995/Reviewers", "ICLR.cc/2020/Conference/Paper995/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper995/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper995/Authors|ICLR.cc/2020/Conference/Paper995/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504162908, "tmdate": 1576860532016, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper995/Authors", "ICLR.cc/2020/Conference/Paper995/Reviewers", "ICLR.cc/2020/Conference/Paper995/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper995/-/Official_Comment"}}}, {"id": "Bkepx22LjS", "original": null, "number": 3, "cdate": 1573469173117, "ddate": null, "tcdate": 1573469173117, "tmdate": 1573469173117, "tddate": null, "forum": "BkgzMCVtPB", "replyto": "r1lRr8jocr", "invitation": "ICLR.cc/2020/Conference/Paper995/-/Official_Comment", "content": {"title": "Thank you very much for your review and great comments.", "comment": "Thank you very much for your review and great comments. We address specific comments below:\n\n- Reviewer comment: \n\"Confidence intervals for all results (specifically in Figure 1a and in Table 1)\"\n\n- Response:\nWe will add confidence intervals for the experiments in the camera ready version (these require tens of repetitions per experiment, and are thus time consuming). Our experience with running several restarts and evaluating different checkpoints shows that results are stable, and the trends shown are robust.\n\n- Reviewer comment: \n\"Figure 1a: it would be interesting to see a similar analysis also for other values of m and k.\"\n\n- Response:\nWe agree that such experiments are interesting, and were left out due to space considerations. We can definitely add some more Gaussian experiments over different m and k values to the appendix in the camera ready version.\n\n- Reviewer comment: \n\"Table 1: This result would also be more supporting if experiments were performed for varying values of m, n and k.\"\n\n- Response:\nWe did perform other experiments (not reported in order to not make the paper too dense) for other values, and observed that the larger the ratio n/m is, the better our authenticator performs (in agreement with our theory). We chose to report results on m=1,n=5,k=5 for simplicity and in order to show that even for very practical n values - our model performs well.\nWe will be happy to add to more experimental results for different m,n,k values in the camera ready version.\n\n- Reviewer comment: \n\"The description of the RS attack could be made more precise: does it mean that the attacker samples images at random?\"\n\n- Response:\nThe RS attacker is defined as follows: It first draws a source from a uniform distribution over the sources in the dataset. Then it draws n images of that source from a uniform distribution over the images available to that source. \nOne can think of this setting as a scenario where an attacker tries to impersonate a source (e.g. person) without having leaked information on the source\u2019s identity. Thus the attacker chooses an identity at random and uses n real observations of that person.\nWe have updated the paper to make the definition more precise.\n\n- Reviewer comment: \n\"Intuitively, it feels confusing that the GIM authenticator would perform worse on this setting (RS).\"\n\n- Response:\nNote that the GIM authenticator actually achieves better accuracy against the RS attacker than against the GIM attacker on both Omniglot and Voxceleb2. This is exactly what we expect, Since the GIM attacker is expected to be the worst case attack - and thus result in the worst authentication accuracy. \n\n- Reviewer comment: \n\"The experiments on handwritten data would be more similar to what I imagine being a real-world authentication scenario  if performed on a task where a class is a single person writing multiple characters, as opposed to characters being classes.\"\n\n- Response:\nWe agree that this is a more realistic authentication setting and thus an interesting experiment to consider. We are not aware of a good existing dataset for this setup, and thus chose Omniglot since it is a commonly used dataset for generative models and few shot classification. However, in followup work we intend to further explore available datasets (e.g., in voice and hand-writing) that capture an authentication setting \n\n- Reviewer comment: \n\"Page 6, second to last row: there is a\"the\" repeated twice.\"\n\n- Response:\nThanks for noticing. We updated the paper to fix this typo.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper995/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper995/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimal Strategies Against Generative Attacks", "authors": ["Roy Mor", "Erez Peterfreund", "Matan Gavish", "Amir Globerson"], "authorids": ["roy16mor@gmail.com", "erezpeter@cs.huji.ac.il", "matan.gavish@mail.huji.ac.il", "amir.globerson@gmail.com"], "keywords": [], "abstract": "Generative neural models have improved dramatically recently. With this progress comes the risk that such models will be used to attack systems that rely on sensor data for authentication and anomaly detection. Many such learning systems are installed worldwide, protecting critical infrastructure or private data against malfunction and cyber attacks. We formulate the scenario of such an authentication system facing generative impersonation attacks, characterize it from a theoretical perspective and explore its practical implications. In particular, we ask fundamental theoretical questions in learning, statistics and information theory: How hard is it to detect a \"fake reality\"? How much data does the attacker need to collect before it can reliably generate nominally-looking artificial data? Are there optimal strategies for the attacker or the authenticator? We cast the problem as a maximin game, characterize the optimal strategy for both attacker and authenticator in the general case, and provide the optimal strategies in closed form for the case of Gaussian source distributions. Our analysis reveals the structure of the optimal attack and the relative importance of data collection for both authenticator and attacker. Based on these insights we design practical learning approaches and show that they result in models that are more robust to various attacks on real-world data.", "pdf": "/pdf/b1e4d05cc1d50ea1b844e9acb434fb509e067e2f.pdf", "code": "https://github.com/roymor1/OptimalStrategiesAgainstGenerativeAttacks", "paperhash": "mor|optimal_strategies_against_generative_attacks", "_bibtex": "@inproceedings{\nMor2020Optimal,\ntitle={Optimal Strategies Against Generative Attacks},\nauthor={Roy Mor and Erez Peterfreund and Matan Gavish and Amir Globerson},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkgzMCVtPB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/ec5b70b89e7d868956419723a966330475390e96.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkgzMCVtPB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper995/Authors", "ICLR.cc/2020/Conference/Paper995/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper995/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper995/Reviewers", "ICLR.cc/2020/Conference/Paper995/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper995/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper995/Authors|ICLR.cc/2020/Conference/Paper995/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504162908, "tmdate": 1576860532016, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper995/Authors", "ICLR.cc/2020/Conference/Paper995/Reviewers", "ICLR.cc/2020/Conference/Paper995/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper995/-/Official_Comment"}}}, {"id": "HJxoCK3UoS", "original": null, "number": 2, "cdate": 1573468626844, "ddate": null, "tcdate": 1573468626844, "tmdate": 1573468626844, "tddate": null, "forum": "BkgzMCVtPB", "replyto": "BJge4FdRFH", "invitation": "ICLR.cc/2020/Conference/Paper995/-/Official_Comment", "content": {"title": "Thank you very much for your review and great comments.", "comment": "Thank you very much for your review and great comments. We address specific comments below:\n\n- Reviewer comment: \n\"In Theorem 4.1, the symbol g_{X | Y} was introduced previously, whereas g_{X | A} was never introduced. I have to go to the appendix to understand the definition of g_{X | A}.\"\n\n- Response:\nThe definitions of g_{X | A},f_{X|A} were moved to the appendix due to space considerations. We agree that it should appear in the main text, and have updated the paper accordingly.\n\n- Reviewer comment: \n\"There is a minor issue in the proof of Lemma D.2 in page 16. The authors seem to miss a 1/2 factor in the second to last row in equation (D.3).\"\n\n- Response:\nNote that the expression in Eq. (D.3) is an argmin, and therefore multiplying or dividing by a constant factor does not change the value of the expression. Therefore, the equality is correct as written. Nevertheless, we agree that it will be clearer to drop the factor 0.5 in the last line - and have updated the paper accordingly.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper995/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper995/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimal Strategies Against Generative Attacks", "authors": ["Roy Mor", "Erez Peterfreund", "Matan Gavish", "Amir Globerson"], "authorids": ["roy16mor@gmail.com", "erezpeter@cs.huji.ac.il", "matan.gavish@mail.huji.ac.il", "amir.globerson@gmail.com"], "keywords": [], "abstract": "Generative neural models have improved dramatically recently. With this progress comes the risk that such models will be used to attack systems that rely on sensor data for authentication and anomaly detection. Many such learning systems are installed worldwide, protecting critical infrastructure or private data against malfunction and cyber attacks. We formulate the scenario of such an authentication system facing generative impersonation attacks, characterize it from a theoretical perspective and explore its practical implications. In particular, we ask fundamental theoretical questions in learning, statistics and information theory: How hard is it to detect a \"fake reality\"? How much data does the attacker need to collect before it can reliably generate nominally-looking artificial data? Are there optimal strategies for the attacker or the authenticator? We cast the problem as a maximin game, characterize the optimal strategy for both attacker and authenticator in the general case, and provide the optimal strategies in closed form for the case of Gaussian source distributions. Our analysis reveals the structure of the optimal attack and the relative importance of data collection for both authenticator and attacker. Based on these insights we design practical learning approaches and show that they result in models that are more robust to various attacks on real-world data.", "pdf": "/pdf/b1e4d05cc1d50ea1b844e9acb434fb509e067e2f.pdf", "code": "https://github.com/roymor1/OptimalStrategiesAgainstGenerativeAttacks", "paperhash": "mor|optimal_strategies_against_generative_attacks", "_bibtex": "@inproceedings{\nMor2020Optimal,\ntitle={Optimal Strategies Against Generative Attacks},\nauthor={Roy Mor and Erez Peterfreund and Matan Gavish and Amir Globerson},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkgzMCVtPB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/ec5b70b89e7d868956419723a966330475390e96.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkgzMCVtPB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper995/Authors", "ICLR.cc/2020/Conference/Paper995/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper995/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper995/Reviewers", "ICLR.cc/2020/Conference/Paper995/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper995/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper995/Authors|ICLR.cc/2020/Conference/Paper995/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504162908, "tmdate": 1576860532016, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper995/Authors", "ICLR.cc/2020/Conference/Paper995/Reviewers", "ICLR.cc/2020/Conference/Paper995/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper995/-/Official_Comment"}}}, {"id": "BJlsYOhIoS", "original": null, "number": 1, "cdate": 1573468290558, "ddate": null, "tcdate": 1573468290558, "tmdate": 1573468290558, "tddate": null, "forum": "BkgzMCVtPB", "replyto": "SygqiKVl5r", "invitation": "ICLR.cc/2020/Conference/Paper995/-/Official_Comment", "content": {"title": "Thank you very much for your review and great comments.", "comment": "Thank you very much for your review and great comments. We address specific comments below:\n\n- Reviewer comment: \n\"\\bar{x} and \\bar{a} in Theorem 4.2 should be clearly defined\"\n\n- Response:\nThe definition for \\bar{x},\\bar{a} was indeed missing from the main paper. We have updated the paper to include the definition in section 4.3\n\n- Reviewer comment: \n\"It seems to me that the authors use the term \u201cML attacker\u201d to denote some different attacking algorithms.\"\n\n- Response:\nAs described in Section 4.3, we use the term \u201cML Attacker\u201d to denote an attacker that uses the intuitive strategy of estimating the mean of the source using maximum likelihood (Hence the name \u2018ML\u2019) and generating the attack sample by drawing n iid points from a Gaussian distribution with the estimated mean and known variance. In our setup this strategy turns out to be sub-optimal, as we show theoretically in section F.4 and empirically in Figure 1C.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper995/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper995/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimal Strategies Against Generative Attacks", "authors": ["Roy Mor", "Erez Peterfreund", "Matan Gavish", "Amir Globerson"], "authorids": ["roy16mor@gmail.com", "erezpeter@cs.huji.ac.il", "matan.gavish@mail.huji.ac.il", "amir.globerson@gmail.com"], "keywords": [], "abstract": "Generative neural models have improved dramatically recently. With this progress comes the risk that such models will be used to attack systems that rely on sensor data for authentication and anomaly detection. Many such learning systems are installed worldwide, protecting critical infrastructure or private data against malfunction and cyber attacks. We formulate the scenario of such an authentication system facing generative impersonation attacks, characterize it from a theoretical perspective and explore its practical implications. In particular, we ask fundamental theoretical questions in learning, statistics and information theory: How hard is it to detect a \"fake reality\"? How much data does the attacker need to collect before it can reliably generate nominally-looking artificial data? Are there optimal strategies for the attacker or the authenticator? We cast the problem as a maximin game, characterize the optimal strategy for both attacker and authenticator in the general case, and provide the optimal strategies in closed form for the case of Gaussian source distributions. Our analysis reveals the structure of the optimal attack and the relative importance of data collection for both authenticator and attacker. Based on these insights we design practical learning approaches and show that they result in models that are more robust to various attacks on real-world data.", "pdf": "/pdf/b1e4d05cc1d50ea1b844e9acb434fb509e067e2f.pdf", "code": "https://github.com/roymor1/OptimalStrategiesAgainstGenerativeAttacks", "paperhash": "mor|optimal_strategies_against_generative_attacks", "_bibtex": "@inproceedings{\nMor2020Optimal,\ntitle={Optimal Strategies Against Generative Attacks},\nauthor={Roy Mor and Erez Peterfreund and Matan Gavish and Amir Globerson},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkgzMCVtPB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/ec5b70b89e7d868956419723a966330475390e96.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BkgzMCVtPB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper995/Authors", "ICLR.cc/2020/Conference/Paper995/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper995/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper995/Reviewers", "ICLR.cc/2020/Conference/Paper995/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper995/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper995/Authors|ICLR.cc/2020/Conference/Paper995/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504162908, "tmdate": 1576860532016, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper995/Authors", "ICLR.cc/2020/Conference/Paper995/Reviewers", "ICLR.cc/2020/Conference/Paper995/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper995/-/Official_Comment"}}}, {"id": "BJge4FdRFH", "original": null, "number": 1, "cdate": 1571879207829, "ddate": null, "tcdate": 1571879207829, "tmdate": 1572972525868, "tddate": null, "forum": "BkgzMCVtPB", "replyto": "BkgzMCVtPB", "invitation": "ICLR.cc/2020/Conference/Paper995/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a new threat model for generative impersonation attacks: The attacker has access to several leaked images of a person; the authenticator knows several registration images per person and decides a person's identify by comparing some newly-sampled images from that person with corresponding registration images. The authors formulate this threat model as a minimax game and analyzed its Nash equilibrium. In the simplified case that observations are multivariate Gaussian, the authors are able to characterize the optimal strategies of the attacker and authenticator explicitly, which gives a nice intuition on how the theoretical optimum changes with respect to data dimension, number of leaked images, etc. Additionally, the authors implemented this attack (named Gan-in-the-middle attack) with an objective similar to GANs, empirically verified the theoretical results, and demonstrated the success of their approach on VoxCeleb2 and \n\nAs far as I know, this formulation of generative impersonation attacks is novel. The threat model nicely captures the most important aspects of impersonation attacks and is relatively realistic.\n\nThe theoretical analysis is insightful. I especially like that the authors can prove no defense is possible when n <= m, which nicely matches the intuition. The results on Gaussian case not only provide intuition, but also provide motivation for the design of attacker and defender architectures in GIM attacks. \n\nThe experiments are well-designed. The model architectures are well-motivated from Theorem 4.2. It is great to see that results of toy experiments match the theoretical analysis in Figure 1(a). The GIM attack on the Voxceleb2 images generates very realistic and reasonable portraits in Figure 2(a). The data augmentation experiment can be naturally fit into the framework of impersonation attacks and the application of their techniques in this direction is very exciting.\n\nI only have two minor suggestions:\n\n1. In Theorem 4.1, the symbol g_{X | Y} was introduced previously, whereas g_{X | A} was never introduced. I have to go to the appendix to understand the definition of g_{X | A}.\n\n2. There is a minor issue in the proof of Lemma D.2 in page 16. The authors seem to miss a 1/2 factor in the second to last row in equation (D.3).\n\n\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper995/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper995/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimal Strategies Against Generative Attacks", "authors": ["Roy Mor", "Erez Peterfreund", "Matan Gavish", "Amir Globerson"], "authorids": ["roy16mor@gmail.com", "erezpeter@cs.huji.ac.il", "matan.gavish@mail.huji.ac.il", "amir.globerson@gmail.com"], "keywords": [], "abstract": "Generative neural models have improved dramatically recently. With this progress comes the risk that such models will be used to attack systems that rely on sensor data for authentication and anomaly detection. Many such learning systems are installed worldwide, protecting critical infrastructure or private data against malfunction and cyber attacks. We formulate the scenario of such an authentication system facing generative impersonation attacks, characterize it from a theoretical perspective and explore its practical implications. In particular, we ask fundamental theoretical questions in learning, statistics and information theory: How hard is it to detect a \"fake reality\"? How much data does the attacker need to collect before it can reliably generate nominally-looking artificial data? Are there optimal strategies for the attacker or the authenticator? We cast the problem as a maximin game, characterize the optimal strategy for both attacker and authenticator in the general case, and provide the optimal strategies in closed form for the case of Gaussian source distributions. Our analysis reveals the structure of the optimal attack and the relative importance of data collection for both authenticator and attacker. Based on these insights we design practical learning approaches and show that they result in models that are more robust to various attacks on real-world data.", "pdf": "/pdf/b1e4d05cc1d50ea1b844e9acb434fb509e067e2f.pdf", "code": "https://github.com/roymor1/OptimalStrategiesAgainstGenerativeAttacks", "paperhash": "mor|optimal_strategies_against_generative_attacks", "_bibtex": "@inproceedings{\nMor2020Optimal,\ntitle={Optimal Strategies Against Generative Attacks},\nauthor={Roy Mor and Erez Peterfreund and Matan Gavish and Amir Globerson},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkgzMCVtPB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/ec5b70b89e7d868956419723a966330475390e96.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BkgzMCVtPB", "replyto": "BkgzMCVtPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper995/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper995/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575860012338, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper995/Reviewers"], "noninvitees": [], "tcdate": 1570237743924, "tmdate": 1575860012352, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper995/-/Official_Review"}}}, {"id": "SygqiKVl5r", "original": null, "number": 2, "cdate": 1571994017592, "ddate": null, "tcdate": 1571994017592, "tmdate": 1572972525827, "tddate": null, "forum": "BkgzMCVtPB", "replyto": "BkgzMCVtPB", "invitation": "ICLR.cc/2020/Conference/Paper995/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "# Summary\nThe authors investigate an attack-defense problem in which an attacker attempts to pass authentication by generating a faked input, while an authenticator attempts to detect the fraud. They formulate this problem as a zero-sum game and reveal the closed form of the optimal strategies. Furthermore, they reveal a more insightful closed form of the optimal strategies in the Gaussian case. This result clarifies the relationship between the success rate of the attacker and the numbers of the source, registration, and leaked observations. The analysis for the Gaussian case also gives an interesting insight that the optimal attacker\u2019s strategy is to generate fake inputs so that its sufficient statistics are matched to that of the leaked observations. Based on this insight, the authors propose a new learning algorithm for the authenticator and demonstrate by some empirical evaluations that the proposed algorithm is robust against the faked input.\n\n# Detailed comments\nThis is an interesting and well-written paper. I recommend acceptance of this paper.\nThe authors investigate an attack of generating a faked input for passing the authenticator under which the attacker can only observe partial information about the source input. This is an interesting point of view and allows us to analyze a more practical situation. Furthermore, based on the theoretical analyses, they reveal an interesting insight of the optimal attacker\u2019s strategy that the optimal strategy generates a faked input so that its sufficient statistics are matched to that of the leaked observations. This insight introduces the new robust learning algorithm which outperforms the existing robust learning algorithm demonstrated as in the empirical evaluations.\nSome minor refinements would improve the paper:\n- \\bar{x} and \\bar{a} in Theorem 4.2 should be clearly defined.\n- It seems to me that the authors use the term \u201cML attacker\u201d to denote some different attacking algorithms."}, "signatures": ["ICLR.cc/2020/Conference/Paper995/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper995/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimal Strategies Against Generative Attacks", "authors": ["Roy Mor", "Erez Peterfreund", "Matan Gavish", "Amir Globerson"], "authorids": ["roy16mor@gmail.com", "erezpeter@cs.huji.ac.il", "matan.gavish@mail.huji.ac.il", "amir.globerson@gmail.com"], "keywords": [], "abstract": "Generative neural models have improved dramatically recently. With this progress comes the risk that such models will be used to attack systems that rely on sensor data for authentication and anomaly detection. Many such learning systems are installed worldwide, protecting critical infrastructure or private data against malfunction and cyber attacks. We formulate the scenario of such an authentication system facing generative impersonation attacks, characterize it from a theoretical perspective and explore its practical implications. In particular, we ask fundamental theoretical questions in learning, statistics and information theory: How hard is it to detect a \"fake reality\"? How much data does the attacker need to collect before it can reliably generate nominally-looking artificial data? Are there optimal strategies for the attacker or the authenticator? We cast the problem as a maximin game, characterize the optimal strategy for both attacker and authenticator in the general case, and provide the optimal strategies in closed form for the case of Gaussian source distributions. Our analysis reveals the structure of the optimal attack and the relative importance of data collection for both authenticator and attacker. Based on these insights we design practical learning approaches and show that they result in models that are more robust to various attacks on real-world data.", "pdf": "/pdf/b1e4d05cc1d50ea1b844e9acb434fb509e067e2f.pdf", "code": "https://github.com/roymor1/OptimalStrategiesAgainstGenerativeAttacks", "paperhash": "mor|optimal_strategies_against_generative_attacks", "_bibtex": "@inproceedings{\nMor2020Optimal,\ntitle={Optimal Strategies Against Generative Attacks},\nauthor={Roy Mor and Erez Peterfreund and Matan Gavish and Amir Globerson},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkgzMCVtPB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/ec5b70b89e7d868956419723a966330475390e96.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BkgzMCVtPB", "replyto": "BkgzMCVtPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper995/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper995/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575860012338, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper995/Reviewers"], "noninvitees": [], "tcdate": 1570237743924, "tmdate": 1575860012352, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper995/-/Official_Review"}}}, {"id": "rJliBd199H", "original": null, "number": 3, "cdate": 1572628547327, "ddate": null, "tcdate": 1572628547327, "tmdate": 1572972525786, "tddate": null, "forum": "BkgzMCVtPB", "replyto": "BkgzMCVtPB", "invitation": "ICLR.cc/2020/Conference/Paper995/-/Official_Review", "content": {"rating": "8: Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "\"Optimal Strategies Against Generative Attacks\" describes just what the title implies - various dimensions of the problem of defending against a generative adversary, with theoretical discussion under limited settings, as well as practical experiments extending on the intuitions gained using the theoretical exploration under limited conditions.\n\nParticularly, one of the key stated goals of the paper is to \"construct a theorectical framework for studying the security risk arising from generative models, and explore its practical implications\". Given this goal, the paper performs admirably.\n\nThe appendix is extensive, and gives a lot more insight into the core paper itself.\n\nI am unclear on how the data augmentation experiment fits into the overall picture - perhaps a more detailed explanation of how and why this would be used to form an \"attack\" would help. The other experiments are sensible, and demonstrate reasonable and expected results. \n\nThis is a solid paper, and most of my critiques are \"out of scope\" and revolve around experiments that would be nice to see. Though GAN-for-text is not simple, showing this type of setup for text would be interesting for a number of reasons, same for audio.\n\nContinual passes through the text, with a focus on clarity could also be helpful - the topic is dense, and the text does a good job describing what is happening, but it is always possible to further distill these complex topics, and relegate some useful-but-not-critical pieces to the appendix.\n\nThese are minor quibbles, and overall this paper was an interesting and useful read, on a relatively underexplored topic. It shows theorectical results, and practical experimental demonstrations of the theories proposed. Given the stated goals of the paper, it performs admirably."}, "signatures": ["ICLR.cc/2020/Conference/Paper995/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper995/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimal Strategies Against Generative Attacks", "authors": ["Roy Mor", "Erez Peterfreund", "Matan Gavish", "Amir Globerson"], "authorids": ["roy16mor@gmail.com", "erezpeter@cs.huji.ac.il", "matan.gavish@mail.huji.ac.il", "amir.globerson@gmail.com"], "keywords": [], "abstract": "Generative neural models have improved dramatically recently. With this progress comes the risk that such models will be used to attack systems that rely on sensor data for authentication and anomaly detection. Many such learning systems are installed worldwide, protecting critical infrastructure or private data against malfunction and cyber attacks. We formulate the scenario of such an authentication system facing generative impersonation attacks, characterize it from a theoretical perspective and explore its practical implications. In particular, we ask fundamental theoretical questions in learning, statistics and information theory: How hard is it to detect a \"fake reality\"? How much data does the attacker need to collect before it can reliably generate nominally-looking artificial data? Are there optimal strategies for the attacker or the authenticator? We cast the problem as a maximin game, characterize the optimal strategy for both attacker and authenticator in the general case, and provide the optimal strategies in closed form for the case of Gaussian source distributions. Our analysis reveals the structure of the optimal attack and the relative importance of data collection for both authenticator and attacker. Based on these insights we design practical learning approaches and show that they result in models that are more robust to various attacks on real-world data.", "pdf": "/pdf/b1e4d05cc1d50ea1b844e9acb434fb509e067e2f.pdf", "code": "https://github.com/roymor1/OptimalStrategiesAgainstGenerativeAttacks", "paperhash": "mor|optimal_strategies_against_generative_attacks", "_bibtex": "@inproceedings{\nMor2020Optimal,\ntitle={Optimal Strategies Against Generative Attacks},\nauthor={Roy Mor and Erez Peterfreund and Matan Gavish and Amir Globerson},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BkgzMCVtPB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/ec5b70b89e7d868956419723a966330475390e96.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BkgzMCVtPB", "replyto": "BkgzMCVtPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper995/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper995/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575860012338, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper995/Reviewers"], "noninvitees": [], "tcdate": 1570237743924, "tmdate": 1575860012352, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper995/-/Official_Review"}}}], "count": 10}