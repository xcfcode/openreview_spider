{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396564334, "tcdate": 1486396564334, "number": 1, "id": "By3qnGIux", "invitation": "ICLR.cc/2017/conference/-/paper403/acceptance", "forum": "BJbD_Pqlg", "replyto": "BJbD_Pqlg", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "I think the reviewers evaluated this paper very carefully and were well balanced. The reviewers all agree that the presented comparison between human vision and DNNs is interesting. At the same time, none of the reviewers would strongly defend the paper. As it stands, this work seems a little too premature for publication as the analysis does not go too much beyond what we already know. We encourage the authors to deepen the investigation and resubmit."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Human perception in computer vision", "abstract": "Computer vision has made remarkable progress in recent years. Deep neural network (DNN) models optimized to identify objects in images exhibit unprecedented task-trained accuracy and, remarkably, some generalization ability: new visual problems can now be solved more easily based on previous learning. Biological vision (learned in life and through evolution) is also accurate and general-purpose. Is it possible that these different learning regimes converge to similar problem-dependent optimal computations? We therefore asked whether the human system-level computation of visual perception has DNN correlates and considered several anecdotal test cases. We found that perceptual sensitivity to image changes has DNN mid-computation correlates, while sensitivity to segmentation, crowding and shape has DNN end-computation correlates. Our results quantify the applicability of using DNN computation to estimate perceptual loss, and are consistent with the fascinating theoretical view that properties of human perception are a consequence of architecture-independent visual learning.", "pdf": "/pdf/f7a47138dcb8ca903d2eb0305183df272b9b4db4.pdf", "TL;DR": "Correlates for several properties of human perception emerge in convolutional neural networks following image categorization learning.", "paperhash": "dekel|human_perception_in_computer_vision", "conflicts": ["weizmann.ac.il"], "authors": ["Ron Dekel"], "authorids": ["ron.dekel@weizmann.ac.il"], "keywords": ["Computer vision", "Transfer Learning"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396564830, "id": "ICLR.cc/2017/conference/-/paper403/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "BJbD_Pqlg", "replyto": "BJbD_Pqlg", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396564830}}}, {"tddate": null, "tmdate": 1484741368672, "tcdate": 1481920897912, "number": 1, "id": "BkcY-CZNl", "invitation": "ICLR.cc/2017/conference/-/paper403/official/review", "forum": "BJbD_Pqlg", "replyto": "BJbD_Pqlg", "signatures": ["ICLR.cc/2017/conference/paper403/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper403/AnonReviewer3"], "content": {"title": "Updated Review", "rating": "7: Good paper, accept", "review": "The paper reports several connections between the image representations in state-of-the are object recognition networks and findings from human visual psychophysics:\n1) It shows that the mean L1 distance in the feature space of certain CNN layers is predictive of human noise-detection thresholds in natural images.\n2) It reports that for 3 different 2-AFC tasks for which there exists a condition that is hard and one that is easy for humans, the mutual information between decision label and quantised CNN activations is usually higher in the condition that is easier for humans.\n3) It reproduces the general bandpass nature of contrast/frequency detection sensitivity in humans. \n\nWhile these findings appear interesting, they are also rather anecdotal and some of them seem to be rather trivial (e.g. findings in 2). To make a convincing statement it would be important to explore what aspects of the CNN lead to the reported findings. One possible way of doing that could be to include good baseline models to compare against. As I mentioned before, one such baseline should be reasonable low-level vision model. Another interesting direction would be to compare the results for the same network at different training stages.\n\nIn that way one might be able to find out which parts of the reported results can be reproduced by simple low-level image processing systems,  which parts are due to the general deep network\u2019s architecture and which parts arise from the powerful computational properties (object recognition performance) of the CNNs.\n\nIn conclusion, I believe that establishing correspondences between state-of-the art CNNs and human vision is a potentially fruitful approach. However to make a convincing point that found correspondences are non-trivial, it is crucial to show that non-trivial aspects of the CNN lead to the reported findings, which was not done. Therefore, the contribution of the paper is limited since I cannot judge whether the findings really tell me something about a unique relation between high-performing CNNs and the human visual system.\n\nUPDATE:\n\nThank you very much for your extensive revision and inclusion of several of the suggested baselines. \nThe results of the baseline models often raise more questions and make the interpretation of the results more complex, but I feel that this reflects the complexity of the topic and makes the work rather more worthwhile. \n\nOne further suggestion: As the experiments with the snapshots of the CaffeNet shows, the direct relationship between CNN performance and prediction accuracy of biological vision known from Yamins et al. 2014 and Cadieu et al. 2014 does not necessarily hold in your experiments. I think this should be discussed somewhere in the paper.\n\nAll in all, I think that the paper now constitutes a decent contribution relating state-of-the art CNNs to human psychophysics and I would be happy for this work to be accepted.\n\nI raise the my rating for this paper to 7.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Human perception in computer vision", "abstract": "Computer vision has made remarkable progress in recent years. Deep neural network (DNN) models optimized to identify objects in images exhibit unprecedented task-trained accuracy and, remarkably, some generalization ability: new visual problems can now be solved more easily based on previous learning. Biological vision (learned in life and through evolution) is also accurate and general-purpose. Is it possible that these different learning regimes converge to similar problem-dependent optimal computations? We therefore asked whether the human system-level computation of visual perception has DNN correlates and considered several anecdotal test cases. We found that perceptual sensitivity to image changes has DNN mid-computation correlates, while sensitivity to segmentation, crowding and shape has DNN end-computation correlates. Our results quantify the applicability of using DNN computation to estimate perceptual loss, and are consistent with the fascinating theoretical view that properties of human perception are a consequence of architecture-independent visual learning.", "pdf": "/pdf/f7a47138dcb8ca903d2eb0305183df272b9b4db4.pdf", "TL;DR": "Correlates for several properties of human perception emerge in convolutional neural networks following image categorization learning.", "paperhash": "dekel|human_perception_in_computer_vision", "conflicts": ["weizmann.ac.il"], "authors": ["Ron Dekel"], "authorids": ["ron.dekel@weizmann.ac.il"], "keywords": ["Computer vision", "Transfer Learning"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512596831, "id": "ICLR.cc/2017/conference/-/paper403/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper403/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper403/AnonReviewer3", "ICLR.cc/2017/conference/paper403/AnonReviewer1", "ICLR.cc/2017/conference/paper403/AnonReviewer2"], "reply": {"forum": "BJbD_Pqlg", "replyto": "BJbD_Pqlg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper403/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper403/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512596831}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1484661377400, "tcdate": 1478289497612, "number": 403, "id": "BJbD_Pqlg", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "BJbD_Pqlg", "signatures": ["~Ron_Dekel1"], "readers": ["everyone"], "content": {"title": "Human perception in computer vision", "abstract": "Computer vision has made remarkable progress in recent years. Deep neural network (DNN) models optimized to identify objects in images exhibit unprecedented task-trained accuracy and, remarkably, some generalization ability: new visual problems can now be solved more easily based on previous learning. Biological vision (learned in life and through evolution) is also accurate and general-purpose. Is it possible that these different learning regimes converge to similar problem-dependent optimal computations? We therefore asked whether the human system-level computation of visual perception has DNN correlates and considered several anecdotal test cases. We found that perceptual sensitivity to image changes has DNN mid-computation correlates, while sensitivity to segmentation, crowding and shape has DNN end-computation correlates. Our results quantify the applicability of using DNN computation to estimate perceptual loss, and are consistent with the fascinating theoretical view that properties of human perception are a consequence of architecture-independent visual learning.", "pdf": "/pdf/f7a47138dcb8ca903d2eb0305183df272b9b4db4.pdf", "TL;DR": "Correlates for several properties of human perception emerge in convolutional neural networks following image categorization learning.", "paperhash": "dekel|human_perception_in_computer_vision", "conflicts": ["weizmann.ac.il"], "authors": ["Ron Dekel"], "authorids": ["ron.dekel@weizmann.ac.il"], "keywords": ["Computer vision", "Transfer Learning"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1484660794652, "tcdate": 1484479399787, "number": 2, "id": "S1x3sRdLx", "invitation": "ICLR.cc/2017/conference/-/paper403/public/comment", "forum": "BJbD_Pqlg", "replyto": "BJbD_Pqlg", "signatures": ["~Ron_Dekel1"], "readers": ["everyone"], "writers": ["~Ron_Dekel1"], "content": {"title": "Edits", "comment": "Jan 16-17, 2017:\n- Edited the hypothesis about \"Overshoot\" and \"Undershoot\" inconsistency with perception (result 1).\n- Added the prediction quality of perceptual threshold as a function of layer for model ResNet-152 .\n\nJan 15, 2017:\n-\tAdded results for three baseline models: two linear filter banks (Gabor decomposition and steerable pyramid) and VGG-19 with scrambled weights.\n-\tAdded results for CaffeNet model at several snapshots during training.\n-\tAdded human data for contrast sensitivity (figure 3 results).\n-\tAdded configurations for context experiments (figure 2 results). Now there are 90 configurations per CNN architecture for Segmentation, Crowding, and Shape.\n-\tCosmetics and minor corrections.\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Human perception in computer vision", "abstract": "Computer vision has made remarkable progress in recent years. Deep neural network (DNN) models optimized to identify objects in images exhibit unprecedented task-trained accuracy and, remarkably, some generalization ability: new visual problems can now be solved more easily based on previous learning. Biological vision (learned in life and through evolution) is also accurate and general-purpose. Is it possible that these different learning regimes converge to similar problem-dependent optimal computations? We therefore asked whether the human system-level computation of visual perception has DNN correlates and considered several anecdotal test cases. We found that perceptual sensitivity to image changes has DNN mid-computation correlates, while sensitivity to segmentation, crowding and shape has DNN end-computation correlates. Our results quantify the applicability of using DNN computation to estimate perceptual loss, and are consistent with the fascinating theoretical view that properties of human perception are a consequence of architecture-independent visual learning.", "pdf": "/pdf/f7a47138dcb8ca903d2eb0305183df272b9b4db4.pdf", "TL;DR": "Correlates for several properties of human perception emerge in convolutional neural networks following image categorization learning.", "paperhash": "dekel|human_perception_in_computer_vision", "conflicts": ["weizmann.ac.il"], "authors": ["Ron Dekel"], "authorids": ["ron.dekel@weizmann.ac.il"], "keywords": ["Computer vision", "Transfer Learning"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287590860, "id": "ICLR.cc/2017/conference/-/paper403/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJbD_Pqlg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper403/reviewers", "ICLR.cc/2017/conference/paper403/areachairs"], "cdate": 1485287590860}}}, {"tddate": null, "tmdate": 1484495511879, "tcdate": 1484495511879, "number": 6, "id": "Skli5zYIl", "invitation": "ICLR.cc/2017/conference/-/paper403/public/comment", "forum": "BJbD_Pqlg", "replyto": "ByL97qNEg", "signatures": ["~Ron_Dekel1"], "readers": ["everyone"], "writers": ["~Ron_Dekel1"], "content": {"title": "Response to Reviewer1", "comment": "Thank you for the review which raises two important points.\n\nAbout adversarial examples. Using these techniques, a small imperceptible pixel change causes a very large change in the reported class label of an image. This should not be taken as an argument against the claims of this work for two reasons.\nFirst, the approach used here considers the average change over all units in the entire network, so techniques developed to cause a large change in a single neuron (the output class label neuron) may simply not work. I may be wrong here, but it seems much more difficult to simultaneously cause a large change in millions of roughly independent neurons than it is to change one (the independence implies that a change which specifically increases one neuron will on average cause zero change in others). \nSecond, the adversarial examples are more a backdoor of the architecture than of the learned representation. That is, because the net is composed of linear components, it is susceptible to some variations in image space (Goodfellow, Shlens, Szegedy, 2014). These variations can be easily found when intentionally searched for, but are extremely rare. Even if the results reported here do not work for some extremely rare cases, it is not at odds with prediction working very well for regular images, and is not at odds with the learned representation converging towards human perception.\n\nAbout investigating the properties of the transformation \u2013 this was not attempted.\n\n \n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Human perception in computer vision", "abstract": "Computer vision has made remarkable progress in recent years. Deep neural network (DNN) models optimized to identify objects in images exhibit unprecedented task-trained accuracy and, remarkably, some generalization ability: new visual problems can now be solved more easily based on previous learning. Biological vision (learned in life and through evolution) is also accurate and general-purpose. Is it possible that these different learning regimes converge to similar problem-dependent optimal computations? We therefore asked whether the human system-level computation of visual perception has DNN correlates and considered several anecdotal test cases. We found that perceptual sensitivity to image changes has DNN mid-computation correlates, while sensitivity to segmentation, crowding and shape has DNN end-computation correlates. Our results quantify the applicability of using DNN computation to estimate perceptual loss, and are consistent with the fascinating theoretical view that properties of human perception are a consequence of architecture-independent visual learning.", "pdf": "/pdf/f7a47138dcb8ca903d2eb0305183df272b9b4db4.pdf", "TL;DR": "Correlates for several properties of human perception emerge in convolutional neural networks following image categorization learning.", "paperhash": "dekel|human_perception_in_computer_vision", "conflicts": ["weizmann.ac.il"], "authors": ["Ron Dekel"], "authorids": ["ron.dekel@weizmann.ac.il"], "keywords": ["Computer vision", "Transfer Learning"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287590860, "id": "ICLR.cc/2017/conference/-/paper403/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJbD_Pqlg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper403/reviewers", "ICLR.cc/2017/conference/paper403/areachairs"], "cdate": 1485287590860}}}, {"tddate": null, "tmdate": 1484483527762, "tcdate": 1484483527762, "number": 5, "id": "H1x0okYLx", "invitation": "ICLR.cc/2017/conference/-/paper403/public/comment", "forum": "BJbD_Pqlg", "replyto": "H19W6GPVl", "signatures": ["~Ron_Dekel1"], "readers": ["everyone"], "writers": ["~Ron_Dekel1"], "content": {"title": "Response to Reviewer2", "comment": "Thank you for the detailed and thoughtful review, which helped improve the quality of the work.\n\nAbout your suggestion to widen or close the gap: this was not attempted, but figure 1 now depicts mis-predicted examples. (The psychophysical data for result 1 was collected by Alam et al. (2014).)\n\nAbout telling DNN models apart: the approach described in this work cannot tell which DNN model is most suited to predict perception, since the predictions of the different models are very similar. Although ResNet-152 may seem to be an exception, this is mostly an artifact of averaging across layers, a heuristic which permits a parameter-free prediction, but is less appropriate in this very deep model for some cases.\n\nThe similarity depicted in result 2 is qualitative (Easy vs. Hard), but is considered for a large number of configurations to try and show that it is robust. Table 6 now reports a quantitative comparison of order-of-difficulty for Shape, showing somewhat low values of measured similarity, not much different from baseline (the main qualitative Easy vs. Hard comparison is more robust).\n\nFollowing your suggestion, result 3 was compared with human perceptual data. Unfortunately, when correctly quantified, the contrast constancy which was reported to develop along the net is false: the representation in the final \u201cprob\u201d layer is not more similar to perception than in the early \u201cconv1_1\u201d layer. (Apparently, what develops across the net is the log-linear contrast response.)\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Human perception in computer vision", "abstract": "Computer vision has made remarkable progress in recent years. Deep neural network (DNN) models optimized to identify objects in images exhibit unprecedented task-trained accuracy and, remarkably, some generalization ability: new visual problems can now be solved more easily based on previous learning. Biological vision (learned in life and through evolution) is also accurate and general-purpose. Is it possible that these different learning regimes converge to similar problem-dependent optimal computations? We therefore asked whether the human system-level computation of visual perception has DNN correlates and considered several anecdotal test cases. We found that perceptual sensitivity to image changes has DNN mid-computation correlates, while sensitivity to segmentation, crowding and shape has DNN end-computation correlates. Our results quantify the applicability of using DNN computation to estimate perceptual loss, and are consistent with the fascinating theoretical view that properties of human perception are a consequence of architecture-independent visual learning.", "pdf": "/pdf/f7a47138dcb8ca903d2eb0305183df272b9b4db4.pdf", "TL;DR": "Correlates for several properties of human perception emerge in convolutional neural networks following image categorization learning.", "paperhash": "dekel|human_perception_in_computer_vision", "conflicts": ["weizmann.ac.il"], "authors": ["Ron Dekel"], "authorids": ["ron.dekel@weizmann.ac.il"], "keywords": ["Computer vision", "Transfer Learning"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287590860, "id": "ICLR.cc/2017/conference/-/paper403/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJbD_Pqlg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper403/reviewers", "ICLR.cc/2017/conference/paper403/areachairs"], "cdate": 1485287590860}}}, {"tddate": null, "tmdate": 1484482319812, "tcdate": 1484482319812, "number": 3, "id": "B1dfvkKLe", "invitation": "ICLR.cc/2017/conference/-/paper403/public/comment", "forum": "BJbD_Pqlg", "replyto": "BkcY-CZNl", "signatures": ["~Ron_Dekel1"], "readers": ["everyone"], "writers": ["~Ron_Dekel1"], "content": {"title": "Answer to Reviewer3", "comment": "Thank you for the review, which raised a crucial issue that indeed was not adequately addressed.\n\nFollowing your suggestion, analyses were added for several baseline models: Gabor decomposition, steerable pyramid, the same architecture at different time points during training, and a scrambling of model parameters (though not all baselines for all results). While these baselines show good predictive strength in some cases, they fail in others. In a more general perspective, it is not difficult to craft simple models that exhibit the properties depicted in results 2 and 3. For example in result 2, Segmentation is just a second-order texture, Crowding is just clutter, and Shape is only partially similar. Still, what may be considered surprising and unexpected is that all these unrelated properties were picked up during object recognition learning in what appears to be a very robust way (across most architectures and tested variants). More formally, to predict the outcome of a new psychophysical experiment, DNN predictions may be worthwhile to consider.\n\nNote that result 3 is now weakened: the contrast constancy previously reported is not as strong as it seemed when quantified correctly."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Human perception in computer vision", "abstract": "Computer vision has made remarkable progress in recent years. Deep neural network (DNN) models optimized to identify objects in images exhibit unprecedented task-trained accuracy and, remarkably, some generalization ability: new visual problems can now be solved more easily based on previous learning. Biological vision (learned in life and through evolution) is also accurate and general-purpose. Is it possible that these different learning regimes converge to similar problem-dependent optimal computations? We therefore asked whether the human system-level computation of visual perception has DNN correlates and considered several anecdotal test cases. We found that perceptual sensitivity to image changes has DNN mid-computation correlates, while sensitivity to segmentation, crowding and shape has DNN end-computation correlates. Our results quantify the applicability of using DNN computation to estimate perceptual loss, and are consistent with the fascinating theoretical view that properties of human perception are a consequence of architecture-independent visual learning.", "pdf": "/pdf/f7a47138dcb8ca903d2eb0305183df272b9b4db4.pdf", "TL;DR": "Correlates for several properties of human perception emerge in convolutional neural networks following image categorization learning.", "paperhash": "dekel|human_perception_in_computer_vision", "conflicts": ["weizmann.ac.il"], "authors": ["Ron Dekel"], "authorids": ["ron.dekel@weizmann.ac.il"], "keywords": ["Computer vision", "Transfer Learning"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287590860, "id": "ICLR.cc/2017/conference/-/paper403/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJbD_Pqlg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper403/reviewers", "ICLR.cc/2017/conference/paper403/areachairs"], "cdate": 1485287590860}}}, {"tddate": null, "tmdate": 1482267906120, "tcdate": 1482267906120, "number": 3, "id": "H19W6GPVl", "invitation": "ICLR.cc/2017/conference/-/paper403/official/review", "forum": "BJbD_Pqlg", "replyto": "BJbD_Pqlg", "signatures": ["ICLR.cc/2017/conference/paper403/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper403/AnonReviewer2"], "content": {"title": "Review of \"Human Perception in Computer Vision\"", "rating": "6: Marginally above acceptance threshold", "review": "The author works to compare DNNs to human visual perception, both quantitatively and qualitatively. \n\nTheir first result involves performing a psychophysical experiment both on humans and on a model and then comparing the results (actually I think the psychophysical data was collected in a different work, and is just used here).   The specific psychophysical experiment determined, separately for each of a set of approx. 1110 images, what the noise level of additive noise would have to be to make a just-noticeable-difference for humans in discriminating the noiseless image from the noisy one.   The authors then define a metric on neural networks that allows them to measure what they posit might be a similar property for the networks.  They then correlate the pattern of noise levels between neural networks that the humans.    Deep neural networks end up being much better predictors of the human pattern of noise levels than simpler measure of image perturbation (e.g. RMS contrast).  \n\nA second result involves comparing DNNs to humans in terms of their pattern errors in a series of highly controlled experiments using stimuli that illustrate classic properties of human visual processing -- including segmentation, crowding and shape understanding.  They then used an information-theoretic single-neuron metric of discriminability to assess similar patterns of errors for the DNNs.   Again, top layers of DNNs were able to reproduce the human patterns of difficulty across stimuli, at least to some extent. \n\nA third result involves comparing DNNs to humans in terms of their pattern of contrast sensitivity across a series of sine-grating images at different frequencies.  (There is a classic result from vision research as to what this pattern should be, so it makes a natural target for comparison to models.)   The authors define a DNN correlate for the propertie in terms of the cross-neuron average of the L1-distance between responses to a blank image and responses to a sinuisoid of each contrast and frequency.   They then qualitatively compare the results of this metric for DNNs models to known results from the literature on humans, finding that, like humans, there is an apparent bandpass response for low-contrast gratings and a mostly constant response at high contrast.  \n\nPros:\n    * The general concept of comparing deep nets to psychophysical results in a detailed, quantitative way, is really nice.   \n\n    * They nicely defined a set of \"linking functions\", e.g. metrics that express how a specific behavioral result is to be generated from the neural network.  (Ie. the L1 metrics in results 1 and 3 and the information-theoretic measure in result 2.)   The framework for setting up such linking functions seems like a great direction to me. \n\n    * The actual psychophysical data seems to have been handled in a very careful and thoughtful way.   These folks clearly know what they're doing on the psychophysical end.  \n\n\nCons:\n    * To my mind, the biggest problem wit this paper is that that it doesn't say something that we didn't really know already.   Existing results have shown that DNNs are pretty good models of the human visual system in a whole bunch of ways, and this paper adds some more ways.    What would have been great would be: \n         (a) showing that they metric of comparison to humans that was sufficiently sensitive that it could pull apart various DNN models, making one clearly better than the others. \n         (b) identifying a wide gap between the DNNs and the humans that is still unfilled.   They sort of do this, since while the DNNs are good at reproducing the human judgements in Result 1, they are not perfect -- gap is between 60% explained variance and 84% inter-human consistency.    This 24% gap is potentially important, so I'd really like to see them have explored that gap more -- e.g. (i) widening the gap by identifying which images caused the gap most and focusing a test on those, or (ii) closing the gap by training a neural network to get the pattern 100% correct and seeing if that made better CNNs as measured on other metrics/tasks. \n\nIn other words, I would definitely have traded off not having results 2 and 3 for a deeper exploration of result 1.    I think their overall approach could be very fruitful, but it hasn't really been carried far enough here. \n\n   * I found a few things confusing about the layout of the paper.  I especially found that the quantitative results for results 2 and 3 were not clearly displayed.   Why was figure 8 relegated to the appendix?  Where are the quantifications of model-human similarities for the data shown in Figure 8?  Isn't this the whole meat of their second result?   This should really be presented in a more clear way.    \n\n    * Where is the quantification of model-human similarity for the data show in Figure 3?  Isn't there a way to get the human contrast-sensitivity curve and then compare it to that of models in a more quantitively precise way, rather than just note a qualitative agreement?   It seems odd to me that this wasn't done. \n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Human perception in computer vision", "abstract": "Computer vision has made remarkable progress in recent years. Deep neural network (DNN) models optimized to identify objects in images exhibit unprecedented task-trained accuracy and, remarkably, some generalization ability: new visual problems can now be solved more easily based on previous learning. Biological vision (learned in life and through evolution) is also accurate and general-purpose. Is it possible that these different learning regimes converge to similar problem-dependent optimal computations? We therefore asked whether the human system-level computation of visual perception has DNN correlates and considered several anecdotal test cases. We found that perceptual sensitivity to image changes has DNN mid-computation correlates, while sensitivity to segmentation, crowding and shape has DNN end-computation correlates. Our results quantify the applicability of using DNN computation to estimate perceptual loss, and are consistent with the fascinating theoretical view that properties of human perception are a consequence of architecture-independent visual learning.", "pdf": "/pdf/f7a47138dcb8ca903d2eb0305183df272b9b4db4.pdf", "TL;DR": "Correlates for several properties of human perception emerge in convolutional neural networks following image categorization learning.", "paperhash": "dekel|human_perception_in_computer_vision", "conflicts": ["weizmann.ac.il"], "authors": ["Ron Dekel"], "authorids": ["ron.dekel@weizmann.ac.il"], "keywords": ["Computer vision", "Transfer Learning"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512596831, "id": "ICLR.cc/2017/conference/-/paper403/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper403/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper403/AnonReviewer3", "ICLR.cc/2017/conference/paper403/AnonReviewer1", "ICLR.cc/2017/conference/paper403/AnonReviewer2"], "reply": {"forum": "BJbD_Pqlg", "replyto": "BJbD_Pqlg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper403/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper403/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512596831}}}, {"tddate": null, "tmdate": 1482101645923, "tcdate": 1482101645923, "number": 2, "id": "ByL97qNEg", "invitation": "ICLR.cc/2017/conference/-/paper403/official/review", "forum": "BJbD_Pqlg", "replyto": "BJbD_Pqlg", "signatures": ["ICLR.cc/2017/conference/paper403/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper403/AnonReviewer1"], "content": {"title": "Review of \"HUMAN PERCEPTION IN COMPUTER VISION\"", "rating": "6: Marginally above acceptance threshold", "review": "This paper compares the performance, in terms of sensitivity to perturbations, of multilayer neural networks to human vision.  In many of the tasks tested, multilayer neural networks exhibit similar sensitivities as human vision.  \n\nFrom the tasks used in this paper one may conclude that multilayer neural networks capture many properties of the human visual system.  But of course there are well known adversarial examples in which small, perceptually invisible perturbations cause catastrophic errors in categorization, so against that backdrop it is difficult to know what to make of these results.  That the two systems exhibit similar phenomenologies in some cases could mean any number of things, and so it would have been nice to see a more in depth analysis of why this is happening in some cases and not others.  For example, for the noise perturbations described in the the first section, one sees already that conv2 is correlated with human sensitivity.  So why not examine how the first layer filters are being combined to produce this contextual effect?  From that we might actually learn something about neural mechanisms.\n\nAlthough I like and am sympathetic to the direction the author is taking here, I feel it just scratches the surface in terms of analyzing perceptual correlates in multilayer neural nets.  \n\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Human perception in computer vision", "abstract": "Computer vision has made remarkable progress in recent years. Deep neural network (DNN) models optimized to identify objects in images exhibit unprecedented task-trained accuracy and, remarkably, some generalization ability: new visual problems can now be solved more easily based on previous learning. Biological vision (learned in life and through evolution) is also accurate and general-purpose. Is it possible that these different learning regimes converge to similar problem-dependent optimal computations? We therefore asked whether the human system-level computation of visual perception has DNN correlates and considered several anecdotal test cases. We found that perceptual sensitivity to image changes has DNN mid-computation correlates, while sensitivity to segmentation, crowding and shape has DNN end-computation correlates. Our results quantify the applicability of using DNN computation to estimate perceptual loss, and are consistent with the fascinating theoretical view that properties of human perception are a consequence of architecture-independent visual learning.", "pdf": "/pdf/f7a47138dcb8ca903d2eb0305183df272b9b4db4.pdf", "TL;DR": "Correlates for several properties of human perception emerge in convolutional neural networks following image categorization learning.", "paperhash": "dekel|human_perception_in_computer_vision", "conflicts": ["weizmann.ac.il"], "authors": ["Ron Dekel"], "authorids": ["ron.dekel@weizmann.ac.il"], "keywords": ["Computer vision", "Transfer Learning"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512596831, "id": "ICLR.cc/2017/conference/-/paper403/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper403/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper403/AnonReviewer3", "ICLR.cc/2017/conference/paper403/AnonReviewer1", "ICLR.cc/2017/conference/paper403/AnonReviewer2"], "reply": {"forum": "BJbD_Pqlg", "replyto": "BJbD_Pqlg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper403/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper403/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512596831}}}, {"tddate": null, "tmdate": 1481483765846, "tcdate": 1481412110256, "number": 1, "id": "S18fC-9Ql", "invitation": "ICLR.cc/2017/conference/-/paper403/public/comment", "forum": "BJbD_Pqlg", "replyto": "rkIeN3U7e", "signatures": ["~Ron_Dekel1"], "readers": ["everyone"], "writers": ["~Ron_Dekel1"], "content": {"title": "Early response", "comment": "We thank the reviewer for the pre-review questions, which will help improve the work.\n - Figure 1c shows accuracy of prediction as a function of layer for the different scales (100%, 66%, 50%). That is, rows 1-3 in Table 2 correspond to the three line colors of Figure 1c. The manuscript will be edited to emphasize this point. Based on receptive field sizes in model VGG-19, a factor 2 change in input scale should roughly cause a shift of one layer (i.e. conv2_1 -> conv1_1, conv3_1 -> conv_2_1, etc), unlike the small changes observed (the different lines nearly overlap).\n - There were 90 different types of patterns (varying scale, target position, and noise magnitude), each tested with three models (VGG-19, CaffeNet, GoogLeNet). In addition, model ResNet-152 was tested for 10 patterns. So 90+90+90+10=280. The manuscript will be edited to emphasize this point.\n - The manuscript will also be edited to include data on which configurations do not follow the order-of-difficulty from human Psychophysics. A main factor appears to be that two of the shapes are systematically against the order found in human Psychophysics.\n - We acknowledge that without a low-level image processing baseline it is difficult to judge the significance of the results in Figure 2. The manuscript will be edited to include a multiscale linear filter bank baseline. Also, regarding the results in Figure 1, note that the perceptual model depicted in Table 1 (by Alam et al. 2014) uses a multiscale log-Gabor filter bank. The manuscript will be edited to explain this point."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Human perception in computer vision", "abstract": "Computer vision has made remarkable progress in recent years. Deep neural network (DNN) models optimized to identify objects in images exhibit unprecedented task-trained accuracy and, remarkably, some generalization ability: new visual problems can now be solved more easily based on previous learning. Biological vision (learned in life and through evolution) is also accurate and general-purpose. Is it possible that these different learning regimes converge to similar problem-dependent optimal computations? We therefore asked whether the human system-level computation of visual perception has DNN correlates and considered several anecdotal test cases. We found that perceptual sensitivity to image changes has DNN mid-computation correlates, while sensitivity to segmentation, crowding and shape has DNN end-computation correlates. Our results quantify the applicability of using DNN computation to estimate perceptual loss, and are consistent with the fascinating theoretical view that properties of human perception are a consequence of architecture-independent visual learning.", "pdf": "/pdf/f7a47138dcb8ca903d2eb0305183df272b9b4db4.pdf", "TL;DR": "Correlates for several properties of human perception emerge in convolutional neural networks following image categorization learning.", "paperhash": "dekel|human_perception_in_computer_vision", "conflicts": ["weizmann.ac.il"], "authors": ["Ron Dekel"], "authorids": ["ron.dekel@weizmann.ac.il"], "keywords": ["Computer vision", "Transfer Learning"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287590860, "id": "ICLR.cc/2017/conference/-/paper403/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "BJbD_Pqlg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper403/reviewers", "ICLR.cc/2017/conference/paper403/areachairs"], "cdate": 1485287590860}}}, {"tddate": null, "tmdate": 1481194407677, "tcdate": 1481192429676, "number": 1, "id": "rkIeN3U7e", "invitation": "ICLR.cc/2017/conference/-/paper403/pre-review/question", "forum": "BJbD_Pqlg", "replyto": "BJbD_Pqlg", "signatures": ["ICLR.cc/2017/conference/paper403/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper403/AnonReviewer3"], "content": {"title": "Questions", "question": "- Did you do the threshold prediction experiment for differently scaled versions of the input image (as suggested by Table 2, row 2 and 3)? \nIf so, was there a systematical change in the best correlated L1 layer when changing the input size of the image by rescaling? I.e. is there an effect solely based on the relative receptive field size of the units?\n\n- For the experiments shown in Figure 2 there are 280 configurations for the segmentation and crowding task. In section 7 there are only 90 configurations described for each task, what are the extra configurations?\n\n- For the same experiments, could the authors comment on what configurations typically did not follow the task-difficulty ordering known from human psychophysics.\n\nEdit:\nGenerally, to judge the significance of the findings it would be nice to compare to a good baseline model. Such a model might be a multi-scale linear filter bank (compared to the multiscale non-linear filter bank that is the CNN) that is powerful in terms of low-level image processing but lacks high-level information processing abilities. An example of such a model would be the steerable pyramid by Simoncelli et al. (http://www.cns.nyu.edu/~eero/steerpyr/)."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Human perception in computer vision", "abstract": "Computer vision has made remarkable progress in recent years. Deep neural network (DNN) models optimized to identify objects in images exhibit unprecedented task-trained accuracy and, remarkably, some generalization ability: new visual problems can now be solved more easily based on previous learning. Biological vision (learned in life and through evolution) is also accurate and general-purpose. Is it possible that these different learning regimes converge to similar problem-dependent optimal computations? We therefore asked whether the human system-level computation of visual perception has DNN correlates and considered several anecdotal test cases. We found that perceptual sensitivity to image changes has DNN mid-computation correlates, while sensitivity to segmentation, crowding and shape has DNN end-computation correlates. Our results quantify the applicability of using DNN computation to estimate perceptual loss, and are consistent with the fascinating theoretical view that properties of human perception are a consequence of architecture-independent visual learning.", "pdf": "/pdf/f7a47138dcb8ca903d2eb0305183df272b9b4db4.pdf", "TL;DR": "Correlates for several properties of human perception emerge in convolutional neural networks following image categorization learning.", "paperhash": "dekel|human_perception_in_computer_vision", "conflicts": ["weizmann.ac.il"], "authors": ["Ron Dekel"], "authorids": ["ron.dekel@weizmann.ac.il"], "keywords": ["Computer vision", "Transfer Learning"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481192430269, "id": "ICLR.cc/2017/conference/-/paper403/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper403/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper403/AnonReviewer3"], "reply": {"forum": "BJbD_Pqlg", "replyto": "BJbD_Pqlg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper403/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper403/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481192430269}}}], "count": 11}