{"notes": [{"id": "H1zxjsCqKQ", "original": "SygRDYo5YX", "number": 592, "cdate": 1538087832093, "ddate": null, "tcdate": 1538087832093, "tmdate": 1545355424397, "tddate": null, "forum": "H1zxjsCqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Gradient-based learning for F-measure and other performance metrics", "abstract": "Many important classification performance metrics, e.g. $F$-measure, are non-differentiable and non-decomposable, and are thus unfriendly to gradient descent algorithm.\nConsequently, despite their popularity as evaluation metrics, these metrics are rarely optimized as training objectives in neural network community.\nIn this paper, we propose an empirical utility maximization scheme with provable learning guarantees to address the non-differentiability of these metrics. \nWe then derive a strongly consistent gradient estimator to handle non-decomposability.\nThese innovations enable end-to-end optimization of these metrics with the same computational complexity as optimizing a decomposable and differentiable metric, e.g. cross-entropy loss.", "keywords": [], "authorids": ["yg1246@nyu.edu", "zz@nyu.edu", "kyunghyun.cho@nyu.edu"], "authors": ["Yu Gai", "Zheng Zhang", "Kyunghyun Cho"], "pdf": "/pdf/d764d2fd10465696ba590d8fae8f97c4d399b7c3.pdf", "paperhash": "gai|gradientbased_learning_for_fmeasure_and_other_performance_metrics", "_bibtex": "@misc{\ngai2019gradientbased,\ntitle={Gradient-based learning for F-measure and other performance metrics},\nauthor={Yu Gai and Zheng Zhang and Kyunghyun Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=H1zxjsCqKQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "HkxeNVDmeV", "original": null, "number": 1, "cdate": 1544938535953, "ddate": null, "tcdate": 1544938535953, "tmdate": 1545354491231, "tddate": null, "forum": "H1zxjsCqKQ", "replyto": "H1zxjsCqKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper592/Meta_Review", "content": {"metareview": "This manuscript proposes a gradient-based learning scheme for non-differentiable and non-decomposable metrics. The key idea is to optimize a soft predictor directly (instead of aiming for a deterministic predictor), which results in a differentiable loss for many of these metrics. Theoretical results are provided which describe the performance of this approach.\n\nThe reviewers and ACs noted weakness in the original submission related to the clarity of the presentation and novelty as related to already published work. There was also a concern about the usefulness the main theoretical results due to asymptotic assumptions. The manuscript would be significantly strengthened if the reliance on infinite sample sizes is resolved, or sufficient empirical evidence is provided which suggests that the asymptotic issues are not practically significant.", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "Metareview"}, "signatures": ["ICLR.cc/2019/Conference/Paper592/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper592/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradient-based learning for F-measure and other performance metrics", "abstract": "Many important classification performance metrics, e.g. $F$-measure, are non-differentiable and non-decomposable, and are thus unfriendly to gradient descent algorithm.\nConsequently, despite their popularity as evaluation metrics, these metrics are rarely optimized as training objectives in neural network community.\nIn this paper, we propose an empirical utility maximization scheme with provable learning guarantees to address the non-differentiability of these metrics. \nWe then derive a strongly consistent gradient estimator to handle non-decomposability.\nThese innovations enable end-to-end optimization of these metrics with the same computational complexity as optimizing a decomposable and differentiable metric, e.g. cross-entropy loss.", "keywords": [], "authorids": ["yg1246@nyu.edu", "zz@nyu.edu", "kyunghyun.cho@nyu.edu"], "authors": ["Yu Gai", "Zheng Zhang", "Kyunghyun Cho"], "pdf": "/pdf/d764d2fd10465696ba590d8fae8f97c4d399b7c3.pdf", "paperhash": "gai|gradientbased_learning_for_fmeasure_and_other_performance_metrics", "_bibtex": "@misc{\ngai2019gradientbased,\ntitle={Gradient-based learning for F-measure and other performance metrics},\nauthor={Yu Gai and Zheng Zhang and Kyunghyun Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=H1zxjsCqKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper592/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353161376, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1zxjsCqKQ", "replyto": "H1zxjsCqKQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper592/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper592/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper592/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353161376}}}, {"id": "SJelZfOtCX", "original": null, "number": 6, "cdate": 1543238135994, "ddate": null, "tcdate": 1543238135994, "tmdate": 1543238135994, "tddate": null, "forum": "H1zxjsCqKQ", "replyto": "SklGS11FCX", "invitation": "ICLR.cc/2019/Conference/-/Paper592/Official_Comment", "content": {"title": "nonconvexity", "comment": "Yes, the loss is nonconvex w.r.t. \\theta, even in the case of accuracy. (I was thinking about convexity w.r.t. the classifier's posterior probabilities when writing the response)"}, "signatures": ["ICLR.cc/2019/Conference/Paper592/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper592/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper592/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradient-based learning for F-measure and other performance metrics", "abstract": "Many important classification performance metrics, e.g. $F$-measure, are non-differentiable and non-decomposable, and are thus unfriendly to gradient descent algorithm.\nConsequently, despite their popularity as evaluation metrics, these metrics are rarely optimized as training objectives in neural network community.\nIn this paper, we propose an empirical utility maximization scheme with provable learning guarantees to address the non-differentiability of these metrics. \nWe then derive a strongly consistent gradient estimator to handle non-decomposability.\nThese innovations enable end-to-end optimization of these metrics with the same computational complexity as optimizing a decomposable and differentiable metric, e.g. cross-entropy loss.", "keywords": [], "authorids": ["yg1246@nyu.edu", "zz@nyu.edu", "kyunghyun.cho@nyu.edu"], "authors": ["Yu Gai", "Zheng Zhang", "Kyunghyun Cho"], "pdf": "/pdf/d764d2fd10465696ba590d8fae8f97c4d399b7c3.pdf", "paperhash": "gai|gradientbased_learning_for_fmeasure_and_other_performance_metrics", "_bibtex": "@misc{\ngai2019gradientbased,\ntitle={Gradient-based learning for F-measure and other performance metrics},\nauthor={Yu Gai and Zheng Zhang and Kyunghyun Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=H1zxjsCqKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper592/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621723, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1zxjsCqKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper592/Authors", "ICLR.cc/2019/Conference/Paper592/Reviewers", "ICLR.cc/2019/Conference/Paper592/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper592/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper592/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper592/Authors|ICLR.cc/2019/Conference/Paper592/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper592/Reviewers", "ICLR.cc/2019/Conference/Paper592/Authors", "ICLR.cc/2019/Conference/Paper592/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621723}}}, {"id": "r1eujgeB37", "original": null, "number": 2, "cdate": 1540845727542, "ddate": null, "tcdate": 1540845727542, "tmdate": 1543200907015, "tddate": null, "forum": "H1zxjsCqKQ", "replyto": "H1zxjsCqKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper592/Official_Review", "content": {"title": "Needs more theoretical or experimental support.", "review": "Update: I still feel that the paper should have either strong theory, strong experiments, or some of each to be accepted, but that both are lacking. The revisions required would be too great for acceptance at this time. \n\nOriginal review:\nThe paper proposes a general method to optimize for performance metrics which can be written in terms of the entries of the confusion matrix. The idea is to approximate the entries of the confusion matrix using their expected values for a randomized classifier, plug these estimates into the formula for the desired metric, and optimize that quantity. This is a compelling idea but it needs more support than the theoretical or experimental sections give. \n\nThe simplicity and generality of the method are appealing. Smooth surrogates derived from randomized classifiers have been considered in the context of accuracy [1] and other performance measures [2, 3] and the paper should include some discussion of this prior work, but to my knowledge the broad applicability to non-decomposable and non-differentiable metrics expressible in terms of the confusion matrix is new. \n\nThe theoretical sections could use some improvement. It is worth mentioning that the loss obtained with the proposed method is nonconvex. The first equation in theorem 1 is described with \u201c... where convergence in probability is entry-wise\u201d, when the equation refers to almost sure convergence for a scalar, not convergence in probability for entries of a matrix. \n\nNo convergence rates are given, only asymptotic almost sure convergence as the size of the dataset or the minibatch goes to infinity. For finite datasets these statements are obvious, and while convergence is reassuring for infinite datasets, I imagine the rates will look very different for the loss (a scalar) and the gradient (which may have millions of coordinates). Theorem 3 considers the generalization of a single classifier which is independent of the empirical sample, which makes it irrelevant to cases where the model is learned. Theorem 4, which seeks to give a uniform bound over the model class, only shows that generalization occurs in the limit of infinitely much data (which is not surprising or particularly interesting).\n\nThe experimental section compares the algorithm against a well-known and strong baseline, but without any information about the variance of the results and only for a deep network. Several questions remain: Where the proposed method improves over the baseline, is this improvement due to the new method or the interaction between the method and the model? How would the method perform on e.g. a linear model, which is better understood? How do the results depend on batch size, which affects the bias in the gradients? \n\n[1] Roux, Nicolas Le. \"Tighter bounds lead to improved classifiers.\" arXiv preprint arXiv:1606.09202 (2016).\n[2] Mozer, Michael C., et al. \"Prodding the ROC curve: Constrained optimization of classifier performance.\" Advances in Neural Information Processing Systems. 2002.\n[3] Goh, Gabriel, et al. \"Satisfying real-world goals with dataset constraints.\" Advances in Neural Information Processing Systems. 2016.\n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper592/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Gradient-based learning for F-measure and other performance metrics", "abstract": "Many important classification performance metrics, e.g. $F$-measure, are non-differentiable and non-decomposable, and are thus unfriendly to gradient descent algorithm.\nConsequently, despite their popularity as evaluation metrics, these metrics are rarely optimized as training objectives in neural network community.\nIn this paper, we propose an empirical utility maximization scheme with provable learning guarantees to address the non-differentiability of these metrics. \nWe then derive a strongly consistent gradient estimator to handle non-decomposability.\nThese innovations enable end-to-end optimization of these metrics with the same computational complexity as optimizing a decomposable and differentiable metric, e.g. cross-entropy loss.", "keywords": [], "authorids": ["yg1246@nyu.edu", "zz@nyu.edu", "kyunghyun.cho@nyu.edu"], "authors": ["Yu Gai", "Zheng Zhang", "Kyunghyun Cho"], "pdf": "/pdf/d764d2fd10465696ba590d8fae8f97c4d399b7c3.pdf", "paperhash": "gai|gradientbased_learning_for_fmeasure_and_other_performance_metrics", "_bibtex": "@misc{\ngai2019gradientbased,\ntitle={Gradient-based learning for F-measure and other performance metrics},\nauthor={Yu Gai and Zheng Zhang and Kyunghyun Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=H1zxjsCqKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper592/Official_Review", "cdate": 1542234424320, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "H1zxjsCqKQ", "replyto": "H1zxjsCqKQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper592/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335759310, "tmdate": 1552335759310, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper592/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SklGS11FCX", "original": null, "number": 5, "cdate": 1543200570067, "ddate": null, "tcdate": 1543200570067, "tmdate": 1543200570067, "tddate": null, "forum": "H1zxjsCqKQ", "replyto": "ryewV_5KTQ", "invitation": "ICLR.cc/2019/Conference/-/Paper592/Official_Comment", "content": {"title": "nonconvexity", "comment": "Even for accuracy, the expected classification error results in a nonconvex loss. See the Le Roux reference I mentioned. "}, "signatures": ["ICLR.cc/2019/Conference/Paper592/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper592/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper592/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradient-based learning for F-measure and other performance metrics", "abstract": "Many important classification performance metrics, e.g. $F$-measure, are non-differentiable and non-decomposable, and are thus unfriendly to gradient descent algorithm.\nConsequently, despite their popularity as evaluation metrics, these metrics are rarely optimized as training objectives in neural network community.\nIn this paper, we propose an empirical utility maximization scheme with provable learning guarantees to address the non-differentiability of these metrics. \nWe then derive a strongly consistent gradient estimator to handle non-decomposability.\nThese innovations enable end-to-end optimization of these metrics with the same computational complexity as optimizing a decomposable and differentiable metric, e.g. cross-entropy loss.", "keywords": [], "authorids": ["yg1246@nyu.edu", "zz@nyu.edu", "kyunghyun.cho@nyu.edu"], "authors": ["Yu Gai", "Zheng Zhang", "Kyunghyun Cho"], "pdf": "/pdf/d764d2fd10465696ba590d8fae8f97c4d399b7c3.pdf", "paperhash": "gai|gradientbased_learning_for_fmeasure_and_other_performance_metrics", "_bibtex": "@misc{\ngai2019gradientbased,\ntitle={Gradient-based learning for F-measure and other performance metrics},\nauthor={Yu Gai and Zheng Zhang and Kyunghyun Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=H1zxjsCqKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper592/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621723, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1zxjsCqKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper592/Authors", "ICLR.cc/2019/Conference/Paper592/Reviewers", "ICLR.cc/2019/Conference/Paper592/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper592/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper592/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper592/Authors|ICLR.cc/2019/Conference/Paper592/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper592/Reviewers", "ICLR.cc/2019/Conference/Paper592/Authors", "ICLR.cc/2019/Conference/Paper592/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621723}}}, {"id": "SJlQ9lsK6m", "original": null, "number": 4, "cdate": 1542201483132, "ddate": null, "tcdate": 1542201483132, "tmdate": 1542201483132, "tddate": null, "forum": "H1zxjsCqKQ", "replyto": "BJguooef3m", "invitation": "ICLR.cc/2019/Conference/-/Paper592/Official_Comment", "content": {"title": "Responses", "comment": "Dear Reviewer,\n\nFirst, thank you for your helpful review!\n\nRegarding issues you mentioned:\n\n1. The idea of optimizing non-decomposable objectives by leveraging their mathematical properties is indeed not new. However, we believe that the formulation and analysis of the proposed surrogate objective is novel. [Ref 1] is very interesting and we will consider it as a baseline for our method. We did not consider the existence and uniqueness of the Bayes classifier. We are only interested in whether our surrogate objective can yield best-in-class classifiers given a fixed hypothesis class (Theorem 4), which is why our results only require a weaker condition.\n\n2. Yes, we should discuss sample complexity, especially when discussing the impact of batch size. The convergence of empirical mean to population indeed can become a problem when there are very few samples for a class. However, this issue is less severe for large datasets, where minority classes have numerous samples despite their low frequencies.\n\n3. We will surely include more details about experiments. We will also release our code soon."}, "signatures": ["ICLR.cc/2019/Conference/Paper592/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper592/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper592/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradient-based learning for F-measure and other performance metrics", "abstract": "Many important classification performance metrics, e.g. $F$-measure, are non-differentiable and non-decomposable, and are thus unfriendly to gradient descent algorithm.\nConsequently, despite their popularity as evaluation metrics, these metrics are rarely optimized as training objectives in neural network community.\nIn this paper, we propose an empirical utility maximization scheme with provable learning guarantees to address the non-differentiability of these metrics. \nWe then derive a strongly consistent gradient estimator to handle non-decomposability.\nThese innovations enable end-to-end optimization of these metrics with the same computational complexity as optimizing a decomposable and differentiable metric, e.g. cross-entropy loss.", "keywords": [], "authorids": ["yg1246@nyu.edu", "zz@nyu.edu", "kyunghyun.cho@nyu.edu"], "authors": ["Yu Gai", "Zheng Zhang", "Kyunghyun Cho"], "pdf": "/pdf/d764d2fd10465696ba590d8fae8f97c4d399b7c3.pdf", "paperhash": "gai|gradientbased_learning_for_fmeasure_and_other_performance_metrics", "_bibtex": "@misc{\ngai2019gradientbased,\ntitle={Gradient-based learning for F-measure and other performance metrics},\nauthor={Yu Gai and Zheng Zhang and Kyunghyun Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=H1zxjsCqKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper592/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621723, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1zxjsCqKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper592/Authors", "ICLR.cc/2019/Conference/Paper592/Reviewers", "ICLR.cc/2019/Conference/Paper592/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper592/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper592/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper592/Authors|ICLR.cc/2019/Conference/Paper592/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper592/Reviewers", "ICLR.cc/2019/Conference/Paper592/Authors", "ICLR.cc/2019/Conference/Paper592/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621723}}}, {"id": "ryewV_5KTQ", "original": null, "number": 3, "cdate": 1542199343308, "ddate": null, "tcdate": 1542199343308, "tmdate": 1542199343308, "tddate": null, "forum": "H1zxjsCqKQ", "replyto": "r1eujgeB37", "invitation": "ICLR.cc/2019/Conference/-/Paper592/Official_Comment", "content": {"title": "Responses", "comment": "Dear Reviewer,\n\nFirst, thank you for your helpful review!\n\nWe agree that we should provide convergence rates. For the convergence of scalars (e.g., in Theorem 4), it would not be hard to derive convergence rates by replacing the law of large number in our analysis with concentration inequalities. The convergence rates of gradients, as you mentioned, is trickier and we will further study this. Also, replacing Theorem 3 with a data-dependent generalization bound may require more efforts and we will further study this.\n\nWe believe that the convexity of the proposed surrogate objective depends on the convexity of the performance metric that we are concerned with. With a convex performance metric, the proposed performance metric is convex. For example, in the case where the performance metric is accuracy, the proposed surrogate objective is simply a sum of posterior probabilities inferred by our classifier. Of course, the objective cannot be convex with a non-convex performance metric.\n\nThe first equation in Theorem 1 will be fixed.\n\nWe will augment the experimental section to provide more information. Works you mentioned are very helpful. We will include them in our updates."}, "signatures": ["ICLR.cc/2019/Conference/Paper592/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper592/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper592/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradient-based learning for F-measure and other performance metrics", "abstract": "Many important classification performance metrics, e.g. $F$-measure, are non-differentiable and non-decomposable, and are thus unfriendly to gradient descent algorithm.\nConsequently, despite their popularity as evaluation metrics, these metrics are rarely optimized as training objectives in neural network community.\nIn this paper, we propose an empirical utility maximization scheme with provable learning guarantees to address the non-differentiability of these metrics. \nWe then derive a strongly consistent gradient estimator to handle non-decomposability.\nThese innovations enable end-to-end optimization of these metrics with the same computational complexity as optimizing a decomposable and differentiable metric, e.g. cross-entropy loss.", "keywords": [], "authorids": ["yg1246@nyu.edu", "zz@nyu.edu", "kyunghyun.cho@nyu.edu"], "authors": ["Yu Gai", "Zheng Zhang", "Kyunghyun Cho"], "pdf": "/pdf/d764d2fd10465696ba590d8fae8f97c4d399b7c3.pdf", "paperhash": "gai|gradientbased_learning_for_fmeasure_and_other_performance_metrics", "_bibtex": "@misc{\ngai2019gradientbased,\ntitle={Gradient-based learning for F-measure and other performance metrics},\nauthor={Yu Gai and Zheng Zhang and Kyunghyun Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=H1zxjsCqKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper592/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621723, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1zxjsCqKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper592/Authors", "ICLR.cc/2019/Conference/Paper592/Reviewers", "ICLR.cc/2019/Conference/Paper592/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper592/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper592/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper592/Authors|ICLR.cc/2019/Conference/Paper592/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper592/Reviewers", "ICLR.cc/2019/Conference/Paper592/Authors", "ICLR.cc/2019/Conference/Paper592/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621723}}}, {"id": "rJgelvYYa7", "original": null, "number": 2, "cdate": 1542194920223, "ddate": null, "tcdate": 1542194920223, "tmdate": 1542194920223, "tddate": null, "forum": "H1zxjsCqKQ", "replyto": "r1lueqC63X", "invitation": "ICLR.cc/2019/Conference/-/Paper592/Official_Comment", "content": {"title": "Responses", "comment": "Dear Reviewer,\n\nFirst, thank you for your helpful review!\n\nRegarding issues you mentioned:\n\n- Page 1, Section 2.1. Could you please specify where the typo is?\n\n- Page 7. Indeed, when analyzing the impact of batch size, we should have given the rate of convergence instead of only considering asymptotic behaviors.\n\n- Algorithm 1 & 2. Fixed.\n\n- We will include an experiment with multi-class F1 score, in which case the GS method is proved optimal as well. For other performance metrics, we are still looking for strong baselines.\n\n- We suspect that the GS method is outperformed because we did not use sufficiently dense grids when grid-searching \\lambda. The reason for not using denser grids is that we also have to grid-search other hyper-parameters, e.g. learning rate, and thus using denser grids for the GS method will significantly increase computation time. Using the step size mentioned in our paper, we need almost two days to finish all experiments with the GS method on a 4-GPU workstation. Thus halving the step size in our case will cost almost another two days.\n\n- We did not notice references you mentioned and will include them in our paper."}, "signatures": ["ICLR.cc/2019/Conference/Paper592/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper592/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper592/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradient-based learning for F-measure and other performance metrics", "abstract": "Many important classification performance metrics, e.g. $F$-measure, are non-differentiable and non-decomposable, and are thus unfriendly to gradient descent algorithm.\nConsequently, despite their popularity as evaluation metrics, these metrics are rarely optimized as training objectives in neural network community.\nIn this paper, we propose an empirical utility maximization scheme with provable learning guarantees to address the non-differentiability of these metrics. \nWe then derive a strongly consistent gradient estimator to handle non-decomposability.\nThese innovations enable end-to-end optimization of these metrics with the same computational complexity as optimizing a decomposable and differentiable metric, e.g. cross-entropy loss.", "keywords": [], "authorids": ["yg1246@nyu.edu", "zz@nyu.edu", "kyunghyun.cho@nyu.edu"], "authors": ["Yu Gai", "Zheng Zhang", "Kyunghyun Cho"], "pdf": "/pdf/d764d2fd10465696ba590d8fae8f97c4d399b7c3.pdf", "paperhash": "gai|gradientbased_learning_for_fmeasure_and_other_performance_metrics", "_bibtex": "@misc{\ngai2019gradientbased,\ntitle={Gradient-based learning for F-measure and other performance metrics},\nauthor={Yu Gai and Zheng Zhang and Kyunghyun Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=H1zxjsCqKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper592/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621723, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1zxjsCqKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper592/Authors", "ICLR.cc/2019/Conference/Paper592/Reviewers", "ICLR.cc/2019/Conference/Paper592/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper592/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper592/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper592/Authors|ICLR.cc/2019/Conference/Paper592/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper592/Reviewers", "ICLR.cc/2019/Conference/Paper592/Authors", "ICLR.cc/2019/Conference/Paper592/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621723}}}, {"id": "r1lueqC63X", "original": null, "number": 3, "cdate": 1541429744422, "ddate": null, "tcdate": 1541429744422, "tmdate": 1541533859962, "tddate": null, "forum": "H1zxjsCqKQ", "replyto": "H1zxjsCqKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper592/Official_Review", "content": {"title": "An interesting paper with some issues ", "review": "This paper proposes a gradient-based learning for F1 measure under the utility maximization framework. F1 is a widely used evaluation metric in information retrieval and machine learning, and it is hard to optimize as it is non-decomposable and non-differentiable. This research direction is hence extremely interesting. \n\nThe paper is well organized and easy to follow. The general methodology seems sound. Below are some detailed comments.\n\n- Page 1, Section 2.1. The notation of the probabilistic classifier is not typed correctly.  \n\n- Page 7. The result strongly depends on how well Eq. (5) holds. Two critical assumptions regarding the data are made here, (1) D -> \u221e and (2) B -> \u221e. The first assumption is implicitly confirmed in the experiments, as in Table 1 the proposed method outperforms when the sample size is big. I am a little bit puzzled about the second assumption though. Eq. (7) holds, (and consequently Eq. (5)) when B -> \u221e, but it cannot be the case in practice, since B tends to have moderate sizes. I wonder how this impacts the results. Batch size isn't discussed at all in the experiments. The discussion on noise control is nice, but it doesn't contribute to the validation of Eq. (5) or Eq. (7).\n\n- Algorithm 1 & 2. It may be a good idea to be explicit what the outputs of the algorithms are. The algorithms are referenced by their section numbers instead of their algorithm numbers. \n\n- The experimental section can be extended. The paper has extensively discussed other well-behaved metrics and tasks beyond binary classification. None of these are tested empirically. \n\n- If I understand correctly, the GS method, with a much higher computational cost, is near optimal. If so, its results should serve as an empirical upper-bound for F1. Then how come the proposed method outperforms it on 4 over 6 dataset? \n\n- There are additional references on F1 maximization. To name a few: (1) Chai. Expectation of F-measures. SIGIR 2005. (2) Waegeman et al. On the Bayes-Optimality of F-Measure Maximizers. JMLR.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper592/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradient-based learning for F-measure and other performance metrics", "abstract": "Many important classification performance metrics, e.g. $F$-measure, are non-differentiable and non-decomposable, and are thus unfriendly to gradient descent algorithm.\nConsequently, despite their popularity as evaluation metrics, these metrics are rarely optimized as training objectives in neural network community.\nIn this paper, we propose an empirical utility maximization scheme with provable learning guarantees to address the non-differentiability of these metrics. \nWe then derive a strongly consistent gradient estimator to handle non-decomposability.\nThese innovations enable end-to-end optimization of these metrics with the same computational complexity as optimizing a decomposable and differentiable metric, e.g. cross-entropy loss.", "keywords": [], "authorids": ["yg1246@nyu.edu", "zz@nyu.edu", "kyunghyun.cho@nyu.edu"], "authors": ["Yu Gai", "Zheng Zhang", "Kyunghyun Cho"], "pdf": "/pdf/d764d2fd10465696ba590d8fae8f97c4d399b7c3.pdf", "paperhash": "gai|gradientbased_learning_for_fmeasure_and_other_performance_metrics", "_bibtex": "@misc{\ngai2019gradientbased,\ntitle={Gradient-based learning for F-measure and other performance metrics},\nauthor={Yu Gai and Zheng Zhang and Kyunghyun Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=H1zxjsCqKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper592/Official_Review", "cdate": 1542234424320, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "H1zxjsCqKQ", "replyto": "H1zxjsCqKQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper592/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335759310, "tmdate": 1552335759310, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper592/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "BJguooef3m", "original": null, "number": 1, "cdate": 1540651936096, "ddate": null, "tcdate": 1540651936096, "tmdate": 1541533859540, "tddate": null, "forum": "H1zxjsCqKQ", "replyto": "H1zxjsCqKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper592/Official_Review", "content": {"title": "Marginally below acceptance", "review": "This paper studies the problem of optimizing non-decomposable metric in classification. This topic has been discussed in several recent works mainly under deterministic classifier context, the authors discuss the possibility of training a neural network and learn the model by gradient-based methods, which could result in randomized classifier; and conducted experiments to compare the performance with other existing methodologies. I have the following concerns after reading it.\n\n1.The main idea of the paper has shown in other related works and the authors didn\u2019t convince me why their work solves something that could not be solved in existing work. The related work section missed some relevant recent work including Ref[1], in which the method is also gradient-based and can be applied to neural networks. The well-behaved notion used in Definition 2 seems much weaker than the assumptions shown in Ref[1,2] to guarantee existence or uniqueness of the Bayes classifier, the authors could spend some effort to discuss why they require less assumptions.\n\n2.For the theory part, all the convergence results are proved in an asymptotic way without further discussion in the sample complexity. This becomes problematic for this work because (as shown in eq (7)) mini batch size goes to infinity is an unrealistic assumption in neural network training. Also when the class is unbalanced, empirical mean converging to population also slows down significantly which is required in Eq (4) and other places. I would like to see more discussion on the sample complexity either theoretically or experimentally.\n\n3.The experiments lack details for reproducing the results or generalizing the gain to other problems. For example, batch size, learning rate or how the size of the network influence the performance metrics. This information will be useful for others who want to apply the proposed method.\n \nThere are some minor formatting issues like the leading space in \\citep. Please fix those.\n\nBased on the above reasons, I\u2019ll give this paper a 5.\n\n[Ref 1] Yan, B., Koyejo, S., Zhong, K. & Ravikumar, P.. (2018). Binary Classification with Karmic, Threshold-Quasi-Concave Metrics. Proceedings of the 35th International Conference on Machine Learning, in PMLR 80:5531-5540\n[Ref 2] Narasimhan, H., Kar, P., & Jain, P. (2015, June). Optimizing non-decomposable performance measures: a tale of two classes. In International Conference on Machine Learning (pp. 199-208).", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper592/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradient-based learning for F-measure and other performance metrics", "abstract": "Many important classification performance metrics, e.g. $F$-measure, are non-differentiable and non-decomposable, and are thus unfriendly to gradient descent algorithm.\nConsequently, despite their popularity as evaluation metrics, these metrics are rarely optimized as training objectives in neural network community.\nIn this paper, we propose an empirical utility maximization scheme with provable learning guarantees to address the non-differentiability of these metrics. \nWe then derive a strongly consistent gradient estimator to handle non-decomposability.\nThese innovations enable end-to-end optimization of these metrics with the same computational complexity as optimizing a decomposable and differentiable metric, e.g. cross-entropy loss.", "keywords": [], "authorids": ["yg1246@nyu.edu", "zz@nyu.edu", "kyunghyun.cho@nyu.edu"], "authors": ["Yu Gai", "Zheng Zhang", "Kyunghyun Cho"], "pdf": "/pdf/d764d2fd10465696ba590d8fae8f97c4d399b7c3.pdf", "paperhash": "gai|gradientbased_learning_for_fmeasure_and_other_performance_metrics", "_bibtex": "@misc{\ngai2019gradientbased,\ntitle={Gradient-based learning for F-measure and other performance metrics},\nauthor={Yu Gai and Zheng Zhang and Kyunghyun Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=H1zxjsCqKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper592/Official_Review", "cdate": 1542234424320, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "H1zxjsCqKQ", "replyto": "H1zxjsCqKQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper592/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335759310, "tmdate": 1552335759310, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper592/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HklmIaLChX", "original": null, "number": 1, "cdate": 1541463371233, "ddate": null, "tcdate": 1541463371233, "tmdate": 1541463371233, "tddate": null, "forum": "H1zxjsCqKQ", "replyto": "H1zxjsCqKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper592/Official_Comment", "content": {"title": "Revision", "comment": "Dear Reviewers and Readers,\n\nWe notice that there are typos in our submission. Also, there are places where our presentation are not very clear. We have therefore uploaded a revision of our submission.\n\nWe apologize for any confusion caused by the original manuscript.\n\nBest,\nAuthors"}, "signatures": ["ICLR.cc/2019/Conference/Paper592/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper592/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper592/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Gradient-based learning for F-measure and other performance metrics", "abstract": "Many important classification performance metrics, e.g. $F$-measure, are non-differentiable and non-decomposable, and are thus unfriendly to gradient descent algorithm.\nConsequently, despite their popularity as evaluation metrics, these metrics are rarely optimized as training objectives in neural network community.\nIn this paper, we propose an empirical utility maximization scheme with provable learning guarantees to address the non-differentiability of these metrics. \nWe then derive a strongly consistent gradient estimator to handle non-decomposability.\nThese innovations enable end-to-end optimization of these metrics with the same computational complexity as optimizing a decomposable and differentiable metric, e.g. cross-entropy loss.", "keywords": [], "authorids": ["yg1246@nyu.edu", "zz@nyu.edu", "kyunghyun.cho@nyu.edu"], "authors": ["Yu Gai", "Zheng Zhang", "Kyunghyun Cho"], "pdf": "/pdf/d764d2fd10465696ba590d8fae8f97c4d399b7c3.pdf", "paperhash": "gai|gradientbased_learning_for_fmeasure_and_other_performance_metrics", "_bibtex": "@misc{\ngai2019gradientbased,\ntitle={Gradient-based learning for F-measure and other performance metrics},\nauthor={Yu Gai and Zheng Zhang and Kyunghyun Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=H1zxjsCqKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper592/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621723, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1zxjsCqKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper592/Authors", "ICLR.cc/2019/Conference/Paper592/Reviewers", "ICLR.cc/2019/Conference/Paper592/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper592/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper592/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper592/Authors|ICLR.cc/2019/Conference/Paper592/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper592/Reviewers", "ICLR.cc/2019/Conference/Paper592/Authors", "ICLR.cc/2019/Conference/Paper592/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621723}}}], "count": 11}