{"notes": [{"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1458095625137, "tcdate": 1458095625137, "id": "jZ9yVQXrxsnlBG2Xfzj1", "invitation": "ICLR.cc/2016/workshop/-/paper/127/review/12", "forum": "2xwPBxZoQTpKBZvXtQng", "replyto": "2xwPBxZoQTpKBZvXtQng", "signatures": ["ICLR.cc/2016/workshop/paper/127/reviewer/12"], "readers": ["everyone"], "writers": ["ICLR.cc/2016/workshop/paper/127/reviewer/12"], "content": {"title": "Review of Seq-NMS for Video object detection", "rating": "4: Ok but not good enough - rejection", "review": "This short paper offers a useful, and straightforward, modification to R-CNN style processing to improve video tracking / temporal detection.  The idea may have limited novelty, but is not likely to be of broad interest to the ICLR community, since the proposed method leverages rather classic dynamic programming schemes. It does not appear there is a novel approach, e.g., to learn the model end-to-end from data. Unfortunately I cannot recommend acceptance to the workshop program, given that it is rather selective this year.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Seq-NMS for Video Object Detection", "abstract": "Video object detection is challenging because objects that are easily detected in one frame may be difficult to detect in another frame within the same clip. Recently, there have been major advances for doing object detection in a single image. These methods typically contain three phases: (i) object proposal generation (ii) object classification and (iii) post-processing. We propose a modification of the post-processing phase that uses high-scoring object detections from nearby frames to boost scores of weaker detections within the same clip. We show that our method obtains superior results to state-of-the-art single image object detection techniques. Our method placed $3^{rd}$ in the video object detection (VID) task of the ImageNet Large Scale Visual Recognition Challenge 2015 (ILSVRC2015).", "pdf": "/pdf/2xwPBxZoQTpKBZvXtQng.pdf", "paperhash": "han|seqnms_for_video_object_detection", "conflicts": ["illinois.edu", "nus.edu.sg", "google.com", "iro.montreal.ca"], "authors": ["Wei Han", "Pooya Khorrami", "Tom Le Paine", "Prajit Ramachandran", "Mohammad Babaeizadeh", "Honghui Shi", "Jiana Li", "Shuicheng Yan", "Thomas S. Huang"], "authorids": ["weihan3@illinois.edu", "pkhorra2@illinois.edu", "paine1@illinois.edu", "prmchnd2@illinois.edu", "mb2@illinois.edu", "hshi10@illinois.edu", "elev373@nus.edu.sg", "eleyans@nus.edu.sg", "t-huang1@illinois.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456580022040, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456580022040, "id": "ICLR.cc/2016/workshop/-/paper/127/review/12", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "2xwPBxZoQTpKBZvXtQng", "replyto": "2xwPBxZoQTpKBZvXtQng", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/127/reviewer/12", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1457129129279, "tcdate": 1457129129279, "id": "WL93AQ5rgh5zMX2Kf2K8", "invitation": "ICLR.cc/2016/workshop/-/paper/127/review/11", "forum": "2xwPBxZoQTpKBZvXtQng", "replyto": "2xwPBxZoQTpKBZvXtQng", "signatures": ["ICLR.cc/2016/workshop/paper/127/reviewer/11"], "readers": ["everyone"], "writers": ["ICLR.cc/2016/workshop/paper/127/reviewer/11"], "content": {"title": "The paper proposes a simple and reasonable post-processing step for non-max suppression of detections in a video.", "rating": "3: Clear rejection", "review": "The paper proposes a dynamic programming based inference scheme for non-max suppression of detections in a video. This allows high-scoring object detections\nfrom nearby frames to boost scores of weaker detections within the same clip, to improve the final video object detection performance.\n\nThe proposed idea has already been used in past work (for example, almost exactly in Finding Action Tubes, Gkioxari et al. CVPR 2015, I am sure there are numerous other papers using the same idea). I don't find the ideas presented in the paper to be at all novel, and dont think the paper makes a contribution substantial enough for publication.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Seq-NMS for Video Object Detection", "abstract": "Video object detection is challenging because objects that are easily detected in one frame may be difficult to detect in another frame within the same clip. Recently, there have been major advances for doing object detection in a single image. These methods typically contain three phases: (i) object proposal generation (ii) object classification and (iii) post-processing. We propose a modification of the post-processing phase that uses high-scoring object detections from nearby frames to boost scores of weaker detections within the same clip. We show that our method obtains superior results to state-of-the-art single image object detection techniques. Our method placed $3^{rd}$ in the video object detection (VID) task of the ImageNet Large Scale Visual Recognition Challenge 2015 (ILSVRC2015).", "pdf": "/pdf/2xwPBxZoQTpKBZvXtQng.pdf", "paperhash": "han|seqnms_for_video_object_detection", "conflicts": ["illinois.edu", "nus.edu.sg", "google.com", "iro.montreal.ca"], "authors": ["Wei Han", "Pooya Khorrami", "Tom Le Paine", "Prajit Ramachandran", "Mohammad Babaeizadeh", "Honghui Shi", "Jiana Li", "Shuicheng Yan", "Thomas S. Huang"], "authorids": ["weihan3@illinois.edu", "pkhorra2@illinois.edu", "paine1@illinois.edu", "prmchnd2@illinois.edu", "mb2@illinois.edu", "hshi10@illinois.edu", "elev373@nus.edu.sg", "eleyans@nus.edu.sg", "t-huang1@illinois.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456580022404, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456580022404, "id": "ICLR.cc/2016/workshop/-/paper/127/review/11", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "2xwPBxZoQTpKBZvXtQng", "replyto": "2xwPBxZoQTpKBZvXtQng", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/127/reviewer/11", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1456700067102, "tcdate": 1456700067102, "id": "WL9GgJOEMs5zMX2Kf2Kz", "invitation": "ICLR.cc/2016/workshop/-/paper/127/review/10", "forum": "2xwPBxZoQTpKBZvXtQng", "replyto": "2xwPBxZoQTpKBZvXtQng", "signatures": ["ICLR.cc/2016/workshop/paper/127/reviewer/10"], "readers": ["everyone"], "writers": ["ICLR.cc/2016/workshop/paper/127/reviewer/10"], "content": {"title": "The authors utilize a reasonable post-processing approach to video detection to improve object detection accuracy, but the paper is not a sufficient contribution to warrant publication.", "rating": "3: Clear rejection", "review": "The authors propose a technique to improve video object detection by applying a post-processing technique to single frame detections. The method falls into the standard \u201ctracking by detection\u201d paradigm and achieves a boost over single frame detection on the video detection task. The authors achieved 3rd place in the ILSVRC video object detection challenge, scoring 48.7 mAP versus the winners who achieve 67.8 mAP. Tracking by detection is a well studied problem (and the authors give a few references). This approach falls squarely into that line of work but the core object detector is modernized to be a CNN. Novelty is low, it\u2019s an application of a fairly standard framework to a modern object detector. While the method did ok in the video object detection challenge, it lost to the first place winner by a huge margin (~20 mAP absolute difference). While a few older \u201ctracking by detection\u201d papers are given a full submission would require a much more thorough comparison and literature review. For example see Burgos-Artizzu et al. in BMVC13 on \u201cMerging Pose Estimates Across Space and Time\u201d who also apply a generalized NMS to video. Of course there exists numerous other such papers. Regardless, as it stands, it is unclear if there is any novel algorithmic contribution. It may be that the post-processing works better than previous approaches, but there are no comparisons to show this is the case. This was definitely a reasonable contribution to the challenge but does not meet the bar for publication.\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Seq-NMS for Video Object Detection", "abstract": "Video object detection is challenging because objects that are easily detected in one frame may be difficult to detect in another frame within the same clip. Recently, there have been major advances for doing object detection in a single image. These methods typically contain three phases: (i) object proposal generation (ii) object classification and (iii) post-processing. We propose a modification of the post-processing phase that uses high-scoring object detections from nearby frames to boost scores of weaker detections within the same clip. We show that our method obtains superior results to state-of-the-art single image object detection techniques. Our method placed $3^{rd}$ in the video object detection (VID) task of the ImageNet Large Scale Visual Recognition Challenge 2015 (ILSVRC2015).", "pdf": "/pdf/2xwPBxZoQTpKBZvXtQng.pdf", "paperhash": "han|seqnms_for_video_object_detection", "conflicts": ["illinois.edu", "nus.edu.sg", "google.com", "iro.montreal.ca"], "authors": ["Wei Han", "Pooya Khorrami", "Tom Le Paine", "Prajit Ramachandran", "Mohammad Babaeizadeh", "Honghui Shi", "Jiana Li", "Shuicheng Yan", "Thomas S. Huang"], "authorids": ["weihan3@illinois.edu", "pkhorra2@illinois.edu", "paine1@illinois.edu", "prmchnd2@illinois.edu", "mb2@illinois.edu", "hshi10@illinois.edu", "elev373@nus.edu.sg", "eleyans@nus.edu.sg", "t-huang1@illinois.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456580009366, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456580009366, "id": "ICLR.cc/2016/workshop/-/paper/127/review/10", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "2xwPBxZoQTpKBZvXtQng", "replyto": "2xwPBxZoQTpKBZvXtQng", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/127/reviewer/10", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "replyto": null, "ddate": null, "cdate": null, "tmdate": 1455824603751, "tcdate": 1455824603751, "id": "2xwPBxZoQTpKBZvXtQng", "invitation": "ICLR.cc/2016/workshop/-/submission", "forum": "2xwPBxZoQTpKBZvXtQng", "signatures": ["~Pooya_Khorrami1"], "readers": ["everyone"], "writers": ["~Pooya_Khorrami1"], "content": {"CMT_id": "", "title": "Seq-NMS for Video Object Detection", "abstract": "Video object detection is challenging because objects that are easily detected in one frame may be difficult to detect in another frame within the same clip. Recently, there have been major advances for doing object detection in a single image. These methods typically contain three phases: (i) object proposal generation (ii) object classification and (iii) post-processing. We propose a modification of the post-processing phase that uses high-scoring object detections from nearby frames to boost scores of weaker detections within the same clip. We show that our method obtains superior results to state-of-the-art single image object detection techniques. Our method placed $3^{rd}$ in the video object detection (VID) task of the ImageNet Large Scale Visual Recognition Challenge 2015 (ILSVRC2015).", "pdf": "/pdf/2xwPBxZoQTpKBZvXtQng.pdf", "paperhash": "han|seqnms_for_video_object_detection", "conflicts": ["illinois.edu", "nus.edu.sg", "google.com", "iro.montreal.ca"], "authors": ["Wei Han", "Pooya Khorrami", "Tom Le Paine", "Prajit Ramachandran", "Mohammad Babaeizadeh", "Honghui Shi", "Jiana Li", "Shuicheng Yan", "Thomas S. Huang"], "authorids": ["weihan3@illinois.edu", "pkhorra2@illinois.edu", "paine1@illinois.edu", "prmchnd2@illinois.edu", "mb2@illinois.edu", "hshi10@illinois.edu", "elev373@nus.edu.sg", "eleyans@nus.edu.sg", "t-huang1@illinois.edu"]}, "nonreaders": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1454464564200, "ddate": null, "super": null, "final": null, "duedate": 1455833700000, "tcdate": 1454464564200, "id": "ICLR.cc/2016/workshop/-/submission", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "readers": ["everyone"], "reply": {"pdf": null, "forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"order": 4, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv.", "value-regex": "upload|http://arxiv.org/pdf/.+"}, "title": {"order": 3, "description": "Title of paper.", "value-regex": ".{0,500}"}, "abstract": {"order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"order": 1, "description": "Comma separated list of author names, as they appear in the paper.", "value-regex": "[^,\\n]+(,[^,\\n]+)*"}, "author_emails": {"order": 2, "description": "Comma separated list of author email addresses, in the same order as above.", "value-regex": "[^,\\n]+(,[^,\\n]+)*"}, "conflicts": {"order": 100, "description": "Semi-colon separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.).", "value-regex": "^([a-zA-Z0-9][a-zA-Z0-9-_]{0,61}[a-zA-Z0-9]{0,1}\\.([a-zA-Z]{1,6}|[a-zA-Z0-9-]{1,30}\\.[a-zA-Z]{2,3}))+(;[a-zA-Z0-9][a-zA-Z0-9-_]{0,61}[a-zA-Z0-9]{0,1}\\.([a-zA-Z]{1,6}|[a-zA-Z0-9-]{1,30}\\.[a-zA-Z]{2,3}))*$"}, "CMT_id": {"order": 5, "value-regex": ".*", "description": "If the paper is a resubmission from the ICLR 2016 Conference Track, enter its CMT ID; otherwise, leave blank."}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "expdate": 1463609700000}}}], "count": 4}