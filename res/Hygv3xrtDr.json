{"notes": [{"id": "Hygv3xrtDr", "original": "HklyPgbFPr", "number": 2539, "cdate": 1569439918528, "ddate": null, "tcdate": 1569439918528, "tmdate": 1577168228342, "tddate": null, "forum": "Hygv3xrtDr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["sanborn@berkeley.edu", "mbchang@berkeley.edu", "svlevine@eecs.berkeley.edu", "tomg@princeton.edu"], "title": "Sparse Skill Coding: Learning Behavioral Hierarchies with Sparse Codes", "authors": ["Sophia Sanborn", "Michael Chang", "Sergey Levine", "Thomas Griffiths"], "pdf": "/pdf/a9ec663ac61dfbf133bccbf5dc1d6be70e5404b4.pdf", "abstract": "Many approaches to hierarchical reinforcement learning aim to identify sub-goal structure in tasks. We consider an alternative perspective based on identifying behavioral `motifs'---repeated action sequences that can be compressed to yield a compact code of action trajectories. We present a method for iteratively compressing action trajectories to learn nested behavioral hierarchies of arbitrary depth, with actions of arbitrary length. The learned temporally extended actions provide new action primitives that can participate in deeper hierarchies as the agent learns. We demonstrate the relevance of this approach for tasks with non-trivial hierarchical structure and show that the approach can be used to accelerate learning in recursively more complex tasks through transfer.", "keywords": ["hierarchical reinforcement learning", "unsupervised learning", "compression"], "paperhash": "sanborn|sparse_skill_coding_learning_behavioral_hierarchies_with_sparse_codes", "original_pdf": "/attachment/a9ec663ac61dfbf133bccbf5dc1d6be70e5404b4.pdf", "_bibtex": "@misc{\nsanborn2020sparse,\ntitle={Sparse Skill Coding: Learning Behavioral Hierarchies with Sparse Codes},\nauthor={Sophia Sanborn and Michael Chang and Sergey Levine and Thomas Griffiths},\nyear={2020},\nurl={https://openreview.net/forum?id=Hygv3xrtDr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "aN2RvgJtU9", "original": null, "number": 1, "cdate": 1576798751605, "ddate": null, "tcdate": 1576798751605, "tmdate": 1576800884073, "tddate": null, "forum": "Hygv3xrtDr", "replyto": "Hygv3xrtDr", "invitation": "ICLR.cc/2020/Conference/Paper2539/-/Decision", "content": {"decision": "Reject", "comment": "The paper proposes an interesting idea of identifying repeated action sequences, or behavioral motifs, in the context of hierarchical reinforcement learning, using sparsity/compression.  While this is a fresh and useful idea, it appears that the paper requires more work, both in terms of presentation/clarity and in terms of stronger empirical results.\n", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["sanborn@berkeley.edu", "mbchang@berkeley.edu", "svlevine@eecs.berkeley.edu", "tomg@princeton.edu"], "title": "Sparse Skill Coding: Learning Behavioral Hierarchies with Sparse Codes", "authors": ["Sophia Sanborn", "Michael Chang", "Sergey Levine", "Thomas Griffiths"], "pdf": "/pdf/a9ec663ac61dfbf133bccbf5dc1d6be70e5404b4.pdf", "abstract": "Many approaches to hierarchical reinforcement learning aim to identify sub-goal structure in tasks. We consider an alternative perspective based on identifying behavioral `motifs'---repeated action sequences that can be compressed to yield a compact code of action trajectories. We present a method for iteratively compressing action trajectories to learn nested behavioral hierarchies of arbitrary depth, with actions of arbitrary length. The learned temporally extended actions provide new action primitives that can participate in deeper hierarchies as the agent learns. We demonstrate the relevance of this approach for tasks with non-trivial hierarchical structure and show that the approach can be used to accelerate learning in recursively more complex tasks through transfer.", "keywords": ["hierarchical reinforcement learning", "unsupervised learning", "compression"], "paperhash": "sanborn|sparse_skill_coding_learning_behavioral_hierarchies_with_sparse_codes", "original_pdf": "/attachment/a9ec663ac61dfbf133bccbf5dc1d6be70e5404b4.pdf", "_bibtex": "@misc{\nsanborn2020sparse,\ntitle={Sparse Skill Coding: Learning Behavioral Hierarchies with Sparse Codes},\nauthor={Sophia Sanborn and Michael Chang and Sergey Levine and Thomas Griffiths},\nyear={2020},\nurl={https://openreview.net/forum?id=Hygv3xrtDr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "Hygv3xrtDr", "replyto": "Hygv3xrtDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795724605, "tmdate": 1576800276275, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2539/-/Decision"}}}, {"id": "ByggG2tniH", "original": null, "number": 1, "cdate": 1573850119869, "ddate": null, "tcdate": 1573850119869, "tmdate": 1573850119869, "tddate": null, "forum": "Hygv3xrtDr", "replyto": "Hygv3xrtDr", "invitation": "ICLR.cc/2020/Conference/Paper2539/-/Official_Comment", "content": {"title": "Thank you for the thoughtful feedback and suggestions", "comment": "We appreciate the thoughtful feedback on our paper from all 3 reviewers. We believe that substantial revisions to the exposition and experiments are required to properly communicate and demonstrate our approach. This includes 1) comparisons to alternative sequence compression based approaches, 2) a clearer analysis of macro actions learned with our method and others, 3) experiments that more clearly demonstrate the extent of our approach\u2019s generality and limitations, and 4) substantial changes to the exposition. We plan to address these concerns in a future version that we will submit elsewhere. Thank you to the reviewers for your time and careful reading."}, "signatures": ["ICLR.cc/2020/Conference/Paper2539/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2539/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["sanborn@berkeley.edu", "mbchang@berkeley.edu", "svlevine@eecs.berkeley.edu", "tomg@princeton.edu"], "title": "Sparse Skill Coding: Learning Behavioral Hierarchies with Sparse Codes", "authors": ["Sophia Sanborn", "Michael Chang", "Sergey Levine", "Thomas Griffiths"], "pdf": "/pdf/a9ec663ac61dfbf133bccbf5dc1d6be70e5404b4.pdf", "abstract": "Many approaches to hierarchical reinforcement learning aim to identify sub-goal structure in tasks. We consider an alternative perspective based on identifying behavioral `motifs'---repeated action sequences that can be compressed to yield a compact code of action trajectories. We present a method for iteratively compressing action trajectories to learn nested behavioral hierarchies of arbitrary depth, with actions of arbitrary length. The learned temporally extended actions provide new action primitives that can participate in deeper hierarchies as the agent learns. We demonstrate the relevance of this approach for tasks with non-trivial hierarchical structure and show that the approach can be used to accelerate learning in recursively more complex tasks through transfer.", "keywords": ["hierarchical reinforcement learning", "unsupervised learning", "compression"], "paperhash": "sanborn|sparse_skill_coding_learning_behavioral_hierarchies_with_sparse_codes", "original_pdf": "/attachment/a9ec663ac61dfbf133bccbf5dc1d6be70e5404b4.pdf", "_bibtex": "@misc{\nsanborn2020sparse,\ntitle={Sparse Skill Coding: Learning Behavioral Hierarchies with Sparse Codes},\nauthor={Sophia Sanborn and Michael Chang and Sergey Levine and Thomas Griffiths},\nyear={2020},\nurl={https://openreview.net/forum?id=Hygv3xrtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Hygv3xrtDr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2539/Authors", "ICLR.cc/2020/Conference/Paper2539/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2539/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2539/Reviewers", "ICLR.cc/2020/Conference/Paper2539/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2539/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2539/Authors|ICLR.cc/2020/Conference/Paper2539/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504139859, "tmdate": 1576860555915, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2539/Authors", "ICLR.cc/2020/Conference/Paper2539/Reviewers", "ICLR.cc/2020/Conference/Paper2539/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2539/-/Official_Comment"}}}, {"id": "SJlAblT6YB", "original": null, "number": 2, "cdate": 1571831814097, "ddate": null, "tcdate": 1571831814097, "tmdate": 1572972325363, "tddate": null, "forum": "Hygv3xrtDr", "replyto": "Hygv3xrtDr", "invitation": "ICLR.cc/2020/Conference/Paper2539/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "\nThe paper proposes a method that aims at encoding trajectories (described as a sequence of actions) into a set of discrete codes with a hierarchical structure. The principle of the algorithm (as far as the article allows me to understand) is to apply multiple iterations of classical sparse coding over the trajectories. The experimental section on simple (deterministic) tasks shows that the SSC method is able to extract interesting options, which can then be used to learn faster on some close domains.\n\nIn terms of positioning, I find the idea of the paper interesting (i.e encoding trajectories through discrete symbols) since it uses sparse coding approaches which, as far as I know, are not classical in the RL domain. This type of approach can give us both a meaningful insight about the \"nature\" of the learned policy (as it is the case in the paper that compresses expert trajectories), and can also become a manner to constraint an RL algorithm to force it to exhibit behaviors that could seem more natural to humans.  \n\nBut the way it is done in this article is disappointing. First of all, the article is badly written, and I am still not sure to fully understand how the algorithm exactly works. Indeed, many notations are not well defined (see at the end of the review), and it makes the algorithm 1 difficult to catch. Then, the authors consider that trajectories are represented as sequences of actions (using one-hot encoding) and do not discuss this hard choice: representing trajectories as a sequence of actions usually rely on the assumption that both the environment is deterministic, and the initial state is always the same. Is it the case in this paper? If it is, it clearly restricts the applicability of the technique. If it is not, then I don't see how it could work well... As far as I understand, all experimental environments are deterministic. So the algorithm description would clearly need to be rewritten, and the authors have to discuss the assumptions they are doing mainly: deterministic environments and also the fact that the \"options\" can only be extracted once a first policy has be learned (or by using expert traces) which limits its applicability.\n\nIn terms of experiments, the assumption made is that we have access to a set of 'good' trajectories (which is easy in the proposed environments, but may be difficult in the real-life). It is compared to the option-critic architecture which simultaneously learns the options and the policy and I think that the comparison is somehow unfair. Since SSC is more a \"sequence compression\" algorithm, I would prefer to compare with existing sequence compression algorithms like hierarchical recurrent neural networks for instance.  The results are illustrated in very simple environments and the article would gain by using more complex ones (for instance the Atari grand challenge dataset could be used for such a study). So it is difficult to understand if the approach as it is is really interesting and efficient for general RL purposes. \n\nSummary: A good idea, but not well described, with strong assumptions not discussed, and with low-quality experimental results. \n\nSome other minor remarks:\nThe introduction is a little bit messy and does not well allow one to understand the focus on the paper, mixing some notions of neuroscience with classical reinforcement learning aspects, the connection between the two domains being not trivial. \n\nEquation 2 versus Equation 3: What is the difference?\ns notation appears in 2.1 and 2.2 while it corresponds to different things. The variables are not defined and we don't know in which domain they rely on. \nArticulation between sparse coding and MDL not clear (since sparse coding is directly a way to minimize the MDL). MDL never used after that.\nsection 3, paragraph 3: I do not understand what is described here. The description has to be rewritten to allow the readers to understand the algorithm e.g \"the size of the dictionary elements is set to 2-timesteps. \" ?  \"The dictionary element a which has the highest explained variance is then selected and assigned an integer code n + 1 \" Variance on what ?  what is T_i ?\n[cite] appears in the introduction\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2539/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2539/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["sanborn@berkeley.edu", "mbchang@berkeley.edu", "svlevine@eecs.berkeley.edu", "tomg@princeton.edu"], "title": "Sparse Skill Coding: Learning Behavioral Hierarchies with Sparse Codes", "authors": ["Sophia Sanborn", "Michael Chang", "Sergey Levine", "Thomas Griffiths"], "pdf": "/pdf/a9ec663ac61dfbf133bccbf5dc1d6be70e5404b4.pdf", "abstract": "Many approaches to hierarchical reinforcement learning aim to identify sub-goal structure in tasks. We consider an alternative perspective based on identifying behavioral `motifs'---repeated action sequences that can be compressed to yield a compact code of action trajectories. We present a method for iteratively compressing action trajectories to learn nested behavioral hierarchies of arbitrary depth, with actions of arbitrary length. The learned temporally extended actions provide new action primitives that can participate in deeper hierarchies as the agent learns. We demonstrate the relevance of this approach for tasks with non-trivial hierarchical structure and show that the approach can be used to accelerate learning in recursively more complex tasks through transfer.", "keywords": ["hierarchical reinforcement learning", "unsupervised learning", "compression"], "paperhash": "sanborn|sparse_skill_coding_learning_behavioral_hierarchies_with_sparse_codes", "original_pdf": "/attachment/a9ec663ac61dfbf133bccbf5dc1d6be70e5404b4.pdf", "_bibtex": "@misc{\nsanborn2020sparse,\ntitle={Sparse Skill Coding: Learning Behavioral Hierarchies with Sparse Codes},\nauthor={Sophia Sanborn and Michael Chang and Sergey Levine and Thomas Griffiths},\nyear={2020},\nurl={https://openreview.net/forum?id=Hygv3xrtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Hygv3xrtDr", "replyto": "Hygv3xrtDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2539/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2539/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576554262603, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2539/Reviewers"], "noninvitees": [], "tcdate": 1570237721413, "tmdate": 1576554262617, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2539/-/Official_Review"}}}, {"id": "rye7qxJAKS", "original": null, "number": 3, "cdate": 1571840138574, "ddate": null, "tcdate": 1571840138574, "tmdate": 1572972325318, "tddate": null, "forum": "Hygv3xrtDr", "replyto": "Hygv3xrtDr", "invitation": "ICLR.cc/2020/Conference/Paper2539/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper discusses identifying motifs for aiding in the solving of cognitive tasks when using Reinforcement Learning. The idea seems quite novel, but the presentation seems to be more complicated than it needs to be for the idea. For example the introduction is quite hard to parse and when you get down to it, the ideas don\u2019t seem that complex.\n\nThe discussion of the technique seems to be lacking in detail. I would be hard-pushed to reproduce the work from the material presented.\n\nFigure 2 is complex and lacks enough discussion in the text.\n\nFigure 3 is likewise complex and is not mentioned at all in the text.\n\nFigure 4 needs more discussion.\n\nThe results presented are quite minimal and don\u2019t fully explore and evaluate the approach taken.\n\nSpecific issues:\n- Page 2: broken citation: \u201cstate space [cite], \u201c\n\n- \u201cLightbot: The Lightbot domain \u2026 a positive reward of only if it successfully turns off all lights.\u201d - this seems to be the opposite of all previous statements which talked about Turing lights on.\n\n- \u201cWe also model each Fractal Lightbot puzzle \u2026 and a reward of 100 for successfully transferring the tower of disks.\u201d - this sounds more like the reward for the tower."}, "signatures": ["ICLR.cc/2020/Conference/Paper2539/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2539/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["sanborn@berkeley.edu", "mbchang@berkeley.edu", "svlevine@eecs.berkeley.edu", "tomg@princeton.edu"], "title": "Sparse Skill Coding: Learning Behavioral Hierarchies with Sparse Codes", "authors": ["Sophia Sanborn", "Michael Chang", "Sergey Levine", "Thomas Griffiths"], "pdf": "/pdf/a9ec663ac61dfbf133bccbf5dc1d6be70e5404b4.pdf", "abstract": "Many approaches to hierarchical reinforcement learning aim to identify sub-goal structure in tasks. We consider an alternative perspective based on identifying behavioral `motifs'---repeated action sequences that can be compressed to yield a compact code of action trajectories. We present a method for iteratively compressing action trajectories to learn nested behavioral hierarchies of arbitrary depth, with actions of arbitrary length. The learned temporally extended actions provide new action primitives that can participate in deeper hierarchies as the agent learns. We demonstrate the relevance of this approach for tasks with non-trivial hierarchical structure and show that the approach can be used to accelerate learning in recursively more complex tasks through transfer.", "keywords": ["hierarchical reinforcement learning", "unsupervised learning", "compression"], "paperhash": "sanborn|sparse_skill_coding_learning_behavioral_hierarchies_with_sparse_codes", "original_pdf": "/attachment/a9ec663ac61dfbf133bccbf5dc1d6be70e5404b4.pdf", "_bibtex": "@misc{\nsanborn2020sparse,\ntitle={Sparse Skill Coding: Learning Behavioral Hierarchies with Sparse Codes},\nauthor={Sophia Sanborn and Michael Chang and Sergey Levine and Thomas Griffiths},\nyear={2020},\nurl={https://openreview.net/forum?id=Hygv3xrtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Hygv3xrtDr", "replyto": "Hygv3xrtDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2539/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2539/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576554262603, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2539/Reviewers"], "noninvitees": [], "tcdate": 1570237721413, "tmdate": 1576554262617, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2539/-/Official_Review"}}}, {"id": "HklhbwPTYr", "original": null, "number": 1, "cdate": 1571809028164, "ddate": null, "tcdate": 1571809028164, "tmdate": 1572972325273, "tddate": null, "forum": "Hygv3xrtDr", "replyto": "Hygv3xrtDr", "invitation": "ICLR.cc/2020/Conference/Paper2539/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper aims to propose a new way of discovering a specific type of temporal abstraction, the pattern of actions. To achieve this goal, it applies the sparse coding method to discover an efficient encoding of the action sequences generated by the agent's interaction with the environment. The filters/dictionaries discovered by the method then represent certain patterns of actions.\n\nIn general, I think it proposes an interesting view of the temporal abstraction. Although this kind of temporal abstraction is only valid in the certain types of environment (For example, as it only represents certain patterns of action sequence, it suffers from non-optimality in stochastic environment where no fixed action sequence would be optimal for solving the problem), the paper, especially the experiment part, clearly tells its readers in what situation can we expect it to perform well. In this sense, I think it provides some scientific insights that benefit my understanding.\n\nHowever, there are many places in the paper making me confused. Therefore I can not fully understand the paper and can not accept it. My concerns are:\n\n1. Equations 1, 2, and 3 are loosey-goosey. For example, there is no definition of x_i, is it a vector or a scalar? Similarly, there is no definition of W and s.\n2. paragraph 3 in section 3 is extremely hard to understand. For example, the first sentence: \"At all stages, the size of the dictionary elements is set to 2-timesteps\". Where does the \"2-timesteps\" come? I have no idea what it is talking about.\n3. in the algorithm, T_i is not defined.\n4. in the experiment part, figure 4 only provides the termination of options/skills but doesn't provide corresponding policies/action sequence, which makes me hard to evaluate the result.\n5. figure 7 and 8 seems to be contradicted with the paper's claim. And the author didn't give a reasonable explanation.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2539/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2539/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["sanborn@berkeley.edu", "mbchang@berkeley.edu", "svlevine@eecs.berkeley.edu", "tomg@princeton.edu"], "title": "Sparse Skill Coding: Learning Behavioral Hierarchies with Sparse Codes", "authors": ["Sophia Sanborn", "Michael Chang", "Sergey Levine", "Thomas Griffiths"], "pdf": "/pdf/a9ec663ac61dfbf133bccbf5dc1d6be70e5404b4.pdf", "abstract": "Many approaches to hierarchical reinforcement learning aim to identify sub-goal structure in tasks. We consider an alternative perspective based on identifying behavioral `motifs'---repeated action sequences that can be compressed to yield a compact code of action trajectories. We present a method for iteratively compressing action trajectories to learn nested behavioral hierarchies of arbitrary depth, with actions of arbitrary length. The learned temporally extended actions provide new action primitives that can participate in deeper hierarchies as the agent learns. We demonstrate the relevance of this approach for tasks with non-trivial hierarchical structure and show that the approach can be used to accelerate learning in recursively more complex tasks through transfer.", "keywords": ["hierarchical reinforcement learning", "unsupervised learning", "compression"], "paperhash": "sanborn|sparse_skill_coding_learning_behavioral_hierarchies_with_sparse_codes", "original_pdf": "/attachment/a9ec663ac61dfbf133bccbf5dc1d6be70e5404b4.pdf", "_bibtex": "@misc{\nsanborn2020sparse,\ntitle={Sparse Skill Coding: Learning Behavioral Hierarchies with Sparse Codes},\nauthor={Sophia Sanborn and Michael Chang and Sergey Levine and Thomas Griffiths},\nyear={2020},\nurl={https://openreview.net/forum?id=Hygv3xrtDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Hygv3xrtDr", "replyto": "Hygv3xrtDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2539/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2539/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576554262603, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2539/Reviewers"], "noninvitees": [], "tcdate": 1570237721413, "tmdate": 1576554262617, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2539/-/Official_Review"}}}], "count": 6}