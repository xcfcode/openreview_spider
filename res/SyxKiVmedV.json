{"notes": [{"id": "SyxKiVmedV", "original": "SyeoJkFYwE", "number": 28, "cdate": 1553114273028, "ddate": null, "tcdate": 1553114273028, "tmdate": 1562082105467, "tddate": null, "forum": "SyxKiVmedV", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "Explanation-Based Attention for Semi-Supervised Deep Active Learning", "authors": ["Denis Gudovskiy", "Alec Hodgkinson", "Takuya Yamaguchi", "Sotaro Tsukizawa"], "authorids": ["denis.gudovskiy@us.panasonic.com", "alec.hodgkinson@us.panasonic.com", "yamaguchi.takuya2015@jp.panasonic.com", "tsukizawa.sotaro@jp.panasonic.com"], "keywords": ["active learning", "attention", "explanation", "feature extraction"], "TL;DR": "We introduce an attention mechanism to improve feature extraction for deep active learning (AL) in the semi-supervised setting.", "abstract": "We introduce an attention mechanism to improve feature extraction for deep active learning (AL) in the semi-supervised setting. The proposed attention mechanism is based on recent methods to visually explain predictions made by DNNs. We apply the proposed explanation-based attention to MNIST and SVHN classification. The conducted experiments show accuracy improvements for the original and class-imbalanced datasets with the same number of training examples and faster long-tail convergence compared to uncertainty-based methods.", "pdf": "/pdf/d9efb2023d7bf5bdadb61116f0f2c2e50387ae2c.pdf", "paperhash": "gudovskiy|explanationbased_attention_for_semisupervised_deep_active_learning"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "OpenReview.net"}, {"id": "ryxkScFiYV", "original": null, "number": 1, "cdate": 1554909750800, "ddate": null, "tcdate": 1554909750800, "tmdate": 1555511878858, "tddate": null, "forum": "SyxKiVmedV", "replyto": "SyxKiVmedV", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper28/Official_Review", "content": {"title": "A small but focused contribution on active learning ", "review": "This paper presents a novel method to match feature similarities for selecting unlabeled samples for active learning to train a model more label-efficiently.\nThe major innovation is to utilize Explanation-Based Attention (EBA) mechanism to improve matching feature similarities, which has been proved effective to attribute feature importance in computer vision domains.\nThe experiments show it outperforms conventional uncertainty-based approaches, especially when classes are imbalanced.\n\nOverall, this paper is a small but focused contribution on active learning and well-written, clear for readers to follow.\nThe presentation can be improved with a more detailed description of notations (e,g. N_b and V_a are not explained, though it's easy to guess their meanings).\nAn illustrative figures of workflow mentioned in the section \"summary for the proposed method\" would be a plus.\nThe paper also enjoys the merit that it has a brief, clear overview of recent AL research to put itself in a broader context.\n\nMy major concerns are two-fold:\n1) the intuition of utilizing integrated gradients (IG) and pseudo-labels is not super clear to me; 2) experiments should be more extensive.\nThe authors assume that the way of using IGs as EBA for evaluating sample similarity by multiplying themselves with descriptor matrices can upweight features that \"a) are not class and instance-level discriminative, b) spatially represent features for a plurality of objects in the input. \"\nThe assumption needs more justification.\nFor example, a) why to use average pooling function for both gradients and features is reasonable, b) the derivation of R_b is of what properties such that the distribution between training data and validation set are more similar iteratively (so we can believe the set of b-th iteration is better than the set of {b-1}-th). Also, experiments can justify the assumption as well with more visual explanations on why the proposed AL method is better and reasonable.\n\nFor the title, I suggest the authors not to use \"explanation-based\" since it is a little bit misleading. Readers may expect the authors use some kinds of explanitions to improve AL. I would say \"Integrated Gradients-based Attention for Deep Active Learning\" would be better.\n\nThat being said, I enjoyed reading this paper and would like to see it accepted with better presentation and more justification, experiments.\n\n", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper28/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper28/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Explanation-Based Attention for Semi-Supervised Deep Active Learning", "authors": ["Denis Gudovskiy", "Alec Hodgkinson", "Takuya Yamaguchi", "Sotaro Tsukizawa"], "authorids": ["denis.gudovskiy@us.panasonic.com", "alec.hodgkinson@us.panasonic.com", "yamaguchi.takuya2015@jp.panasonic.com", "tsukizawa.sotaro@jp.panasonic.com"], "keywords": ["active learning", "attention", "explanation", "feature extraction"], "TL;DR": "We introduce an attention mechanism to improve feature extraction for deep active learning (AL) in the semi-supervised setting.", "abstract": "We introduce an attention mechanism to improve feature extraction for deep active learning (AL) in the semi-supervised setting. The proposed attention mechanism is based on recent methods to visually explain predictions made by DNNs. We apply the proposed explanation-based attention to MNIST and SVHN classification. The conducted experiments show accuracy improvements for the original and class-imbalanced datasets with the same number of training examples and faster long-tail convergence compared to uncertainty-based methods.", "pdf": "/pdf/d9efb2023d7bf5bdadb61116f0f2c2e50387ae2c.pdf", "paperhash": "gudovskiy|explanationbased_attention_for_semisupervised_deep_active_learning"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper28/Official_Review", "cdate": 1553713417481, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "SyxKiVmedV", "replyto": "SyxKiVmedV", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper28/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper28/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713417481, "tmdate": 1555511815244, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper28/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "Hke2Xie-c4", "original": null, "number": 2, "cdate": 1555266339683, "ddate": null, "tcdate": 1555266339683, "tmdate": 1555511873410, "tddate": null, "forum": "SyxKiVmedV", "replyto": "SyxKiVmedV", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper28/Official_Review", "content": {"title": "Review of \"Explanation-Based Attention for Semi-Supervised Deep Active Learning\"", "review": "The authors consider the setting of deep attention learning. It consists in selecting critical unlabelled data in a semi-labelled dataset, so that once labelled they can improve drastically the accuracy of the model. The approach of the authors consist in training a DNN that computes similarity between data, starting with a limited pool of labelled data points. To do so, they augment iteratively the dataset using a greedy approach. \n\nThe paper is well written, and even I am not not at all a specialist of the field I think I understood the main points of the paper.\n\nThe numerical experiments seems strong enough to be convinced by their approach.", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "1: The reviewer's evaluation is an educated guess"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper28/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper28/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Explanation-Based Attention for Semi-Supervised Deep Active Learning", "authors": ["Denis Gudovskiy", "Alec Hodgkinson", "Takuya Yamaguchi", "Sotaro Tsukizawa"], "authorids": ["denis.gudovskiy@us.panasonic.com", "alec.hodgkinson@us.panasonic.com", "yamaguchi.takuya2015@jp.panasonic.com", "tsukizawa.sotaro@jp.panasonic.com"], "keywords": ["active learning", "attention", "explanation", "feature extraction"], "TL;DR": "We introduce an attention mechanism to improve feature extraction for deep active learning (AL) in the semi-supervised setting.", "abstract": "We introduce an attention mechanism to improve feature extraction for deep active learning (AL) in the semi-supervised setting. The proposed attention mechanism is based on recent methods to visually explain predictions made by DNNs. We apply the proposed explanation-based attention to MNIST and SVHN classification. The conducted experiments show accuracy improvements for the original and class-imbalanced datasets with the same number of training examples and faster long-tail convergence compared to uncertainty-based methods.", "pdf": "/pdf/d9efb2023d7bf5bdadb61116f0f2c2e50387ae2c.pdf", "paperhash": "gudovskiy|explanationbased_attention_for_semisupervised_deep_active_learning"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper28/Official_Review", "cdate": 1553713417481, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "SyxKiVmedV", "replyto": "SyxKiVmedV", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper28/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper28/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713417481, "tmdate": 1555511815244, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper28/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "SJl17qhfq4", "original": null, "number": 1, "cdate": 1555380759427, "ddate": null, "tcdate": 1555380759427, "tmdate": 1555510979829, "tddate": null, "forum": "SyxKiVmedV", "replyto": "SyxKiVmedV", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper28/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Explanation-Based Attention for Semi-Supervised Deep Active Learning", "authors": ["Denis Gudovskiy", "Alec Hodgkinson", "Takuya Yamaguchi", "Sotaro Tsukizawa"], "authorids": ["denis.gudovskiy@us.panasonic.com", "alec.hodgkinson@us.panasonic.com", "yamaguchi.takuya2015@jp.panasonic.com", "tsukizawa.sotaro@jp.panasonic.com"], "keywords": ["active learning", "attention", "explanation", "feature extraction"], "TL;DR": "We introduce an attention mechanism to improve feature extraction for deep active learning (AL) in the semi-supervised setting.", "abstract": "We introduce an attention mechanism to improve feature extraction for deep active learning (AL) in the semi-supervised setting. The proposed attention mechanism is based on recent methods to visually explain predictions made by DNNs. We apply the proposed explanation-based attention to MNIST and SVHN classification. The conducted experiments show accuracy improvements for the original and class-imbalanced datasets with the same number of training examples and faster long-tail convergence compared to uncertainty-based methods.", "pdf": "/pdf/d9efb2023d7bf5bdadb61116f0f2c2e50387ae2c.pdf", "paperhash": "gudovskiy|explanationbased_attention_for_semisupervised_deep_active_learning"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper28/Decision", "cdate": 1554736066446, "reply": {"forum": "SyxKiVmedV", "replyto": "SyxKiVmedV", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736066446, "tmdate": 1555510972226, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 4}