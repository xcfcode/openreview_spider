{"notes": [{"id": "2rcgRSAa1A3", "original": "TLPHz7fsCYw", "number": 3103, "cdate": 1601308344345, "ddate": null, "tcdate": 1601308344345, "tmdate": 1614985645315, "tddate": null, "forum": "2rcgRSAa1A3", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Fighting Filterbubbles with Adversarial BERT-Training for News-Recommendation", "authorids": ["~Lukas_Pfahler1", "~Katharina_Morik1"], "authors": ["Lukas Pfahler", "Katharina Morik"], "keywords": ["Adversarial Learning", "Natural Language Processing", "BERT", "News Recommendation", "Attention"], "abstract": "Recommender engines play a role in the emergence and reinforcement of filter bubbles. When these systems learn that a user prefers content from a particular site, the user will be less likely to be exposed to different sources or opinions and, ultimately, is more likely to develop extremist tendencies.\nWe trace the roots of this phenomenon to the way the recommender engine represents news articles. The vectorial features modern systems extract from the plain text of news articles are already highly predictive of the associated news outlet. We propose a new training scheme based on adversarial machine learning to tackle this issue . Our  experiments show that the features we can extract this way are significantly less predictive of the news outlet and thus offer the possibility to reduce the risk of manifestation of new filter bubbles. We validate our intuitions in a news recommendation task using a recent attention-based recommendation system.", "one-sentence_summary": "In order to fight the emergence of filterbubbles in news recommendation systems, we use adversarial training to learn representations of news articles that are less predictive of their respective news outlet.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "pfahler|fighting_filterbubbles_with_adversarial_berttraining_for_newsrecommendation", "pdf": "/pdf/a438e3f78e3af32bc5a59bff9746afd22bc7015b.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=MQW82nnN9E", "_bibtex": "@misc{\npfahler2021fighting,\ntitle={Fighting Filterbubbles with Adversarial {\\{}BERT{\\}}-Training for News-Recommendation},\nauthor={Lukas Pfahler and Katharina Morik},\nyear={2021},\nurl={https://openreview.net/forum?id=2rcgRSAa1A3}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "jjeP-5rSKpd", "original": null, "number": 1, "cdate": 1610040516802, "ddate": null, "tcdate": 1610040516802, "tmdate": 1610474125064, "tddate": null, "forum": "2rcgRSAa1A3", "replyto": "2rcgRSAa1A3", "invitation": "ICLR.cc/2021/Conference/Paper3103/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "All reviewers agree that this paper is not ready for publication. In addition to the technical comments, the authors should pay attention to the comments by Reviewer 3 about the naivete of the motivation provided for the work. Filter bubbles (to the extent that they really exist; there is controversy about this) have multifactorial origins. "}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Fighting Filterbubbles with Adversarial BERT-Training for News-Recommendation", "authorids": ["~Lukas_Pfahler1", "~Katharina_Morik1"], "authors": ["Lukas Pfahler", "Katharina Morik"], "keywords": ["Adversarial Learning", "Natural Language Processing", "BERT", "News Recommendation", "Attention"], "abstract": "Recommender engines play a role in the emergence and reinforcement of filter bubbles. When these systems learn that a user prefers content from a particular site, the user will be less likely to be exposed to different sources or opinions and, ultimately, is more likely to develop extremist tendencies.\nWe trace the roots of this phenomenon to the way the recommender engine represents news articles. The vectorial features modern systems extract from the plain text of news articles are already highly predictive of the associated news outlet. We propose a new training scheme based on adversarial machine learning to tackle this issue . Our  experiments show that the features we can extract this way are significantly less predictive of the news outlet and thus offer the possibility to reduce the risk of manifestation of new filter bubbles. We validate our intuitions in a news recommendation task using a recent attention-based recommendation system.", "one-sentence_summary": "In order to fight the emergence of filterbubbles in news recommendation systems, we use adversarial training to learn representations of news articles that are less predictive of their respective news outlet.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "pfahler|fighting_filterbubbles_with_adversarial_berttraining_for_newsrecommendation", "pdf": "/pdf/a438e3f78e3af32bc5a59bff9746afd22bc7015b.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=MQW82nnN9E", "_bibtex": "@misc{\npfahler2021fighting,\ntitle={Fighting Filterbubbles with Adversarial {\\{}BERT{\\}}-Training for News-Recommendation},\nauthor={Lukas Pfahler and Katharina Morik},\nyear={2021},\nurl={https://openreview.net/forum?id=2rcgRSAa1A3}\n}"}, "tags": [], "invitation": {"reply": {"forum": "2rcgRSAa1A3", "replyto": "2rcgRSAa1A3", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040516789, "tmdate": 1610474125047, "id": "ICLR.cc/2021/Conference/Paper3103/-/Decision"}}}, {"id": "Vjz9VS0KfYg", "original": null, "number": 1, "cdate": 1603716759824, "ddate": null, "tcdate": 1603716759824, "tmdate": 1605024067808, "tddate": null, "forum": "2rcgRSAa1A3", "replyto": "2rcgRSAa1A3", "invitation": "ICLR.cc/2021/Conference/Paper3103/-/Official_Review", "content": {"title": "Good motivation, but need to fix many flaws in the paper.", "review": "This paper proposed an adversarial training framework for reducing the predictive ability of the new outlet from the news recommendation system. While deep learning-based news recommendation systems work very well, these systems tend to recommend contents of the same site, and are likely to develop extremist tendencies.\n\nFirst, this paper contains many typos and flaws, e.g., the missing references in Section 2, the fluctuation of reference format style, and the different AUC-ROC metric values for the end-to-end setting in the text and table. These flaws make this paper hard to be read. If this paper will be published, I strongly recommend that authors fix these flaws.\n\nSecond, while this paper starts with a good motivation, I was not sure that preventing the same outlet from adversarial learning procedures. If we want to recommend news from a large variety of sites, the recommendation service may be able to limit the maximum number of news articles from the same site. Therefore, I was not sure the decrease of the AUC-ROC can be compensated by the diversity increase of sites only. It is better if authors can provide evidence where the proposed adversarial settings can actually prevent filter bubbles, for example, by recommending different opinions than before.", "rating": "3: Clear rejection", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2021/Conference/Paper3103/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3103/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Fighting Filterbubbles with Adversarial BERT-Training for News-Recommendation", "authorids": ["~Lukas_Pfahler1", "~Katharina_Morik1"], "authors": ["Lukas Pfahler", "Katharina Morik"], "keywords": ["Adversarial Learning", "Natural Language Processing", "BERT", "News Recommendation", "Attention"], "abstract": "Recommender engines play a role in the emergence and reinforcement of filter bubbles. When these systems learn that a user prefers content from a particular site, the user will be less likely to be exposed to different sources or opinions and, ultimately, is more likely to develop extremist tendencies.\nWe trace the roots of this phenomenon to the way the recommender engine represents news articles. The vectorial features modern systems extract from the plain text of news articles are already highly predictive of the associated news outlet. We propose a new training scheme based on adversarial machine learning to tackle this issue . Our  experiments show that the features we can extract this way are significantly less predictive of the news outlet and thus offer the possibility to reduce the risk of manifestation of new filter bubbles. We validate our intuitions in a news recommendation task using a recent attention-based recommendation system.", "one-sentence_summary": "In order to fight the emergence of filterbubbles in news recommendation systems, we use adversarial training to learn representations of news articles that are less predictive of their respective news outlet.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "pfahler|fighting_filterbubbles_with_adversarial_berttraining_for_newsrecommendation", "pdf": "/pdf/a438e3f78e3af32bc5a59bff9746afd22bc7015b.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=MQW82nnN9E", "_bibtex": "@misc{\npfahler2021fighting,\ntitle={Fighting Filterbubbles with Adversarial {\\{}BERT{\\}}-Training for News-Recommendation},\nauthor={Lukas Pfahler and Katharina Morik},\nyear={2021},\nurl={https://openreview.net/forum?id=2rcgRSAa1A3}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "2rcgRSAa1A3", "replyto": "2rcgRSAa1A3", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3103/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538082247, "tmdate": 1606915804828, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3103/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3103/-/Official_Review"}}}, {"id": "5N4Gd1kBkj0", "original": null, "number": 2, "cdate": 1603885405477, "ddate": null, "tcdate": 1603885405477, "tmdate": 1605024067742, "tddate": null, "forum": "2rcgRSAa1A3", "replyto": "2rcgRSAa1A3", "invitation": "ICLR.cc/2021/Conference/Paper3103/-/Official_Review", "content": {"title": "The authors use adversarial training to reduce recommendations of news articles from the same outlet. The effect on filter bubbles is not clear.", "review": "The authors use adversarial training in an attempt to diversify recommendations of news articles. The effect on filter bubbles is not clear.\n\nThe authors address the issue of filter bubbles that according to their rationale result from recommendation engines for news articles. Their assumption is, that a news outlet constantly reports the same opinion and thus users should be recommended articles from a more diverse set of outlets to increase the diversity of opinions consumed by an user. To achieve that, the authors propose adversarial training to generate feature representations that encode outlet-specific information less. They evaluate if their obtained representation is less predictive of the outlet and also how this affects the recommendation performance.\n\nA strong point of this paper is the motivation and application area since it tackles a problem with direct societal impact, something that is typically not attempted in general machine learning papers. The technical novelty is minimal, since only well established techniques are applied. No technical novelty would be acceptable if some insights for the application area are generated. Unfortunately, several naive assumptions are being made and the evaluation goals are insufficient to obtain any valuable results:\n1. Outlets are not necessarily biased to one-sided opinions.\n2. Forcing recommendations from a variety of outlets can be achieved much simpler. No reasonable baseline is implemented and evaluated.\n3. The assumption that content from different sources has higher diversity in embedding space is not necessarily true. Different outlets commonly publish identical texts (for instance copied from the same press agencies).\n4. Embedding similarity is not equal to semantic similarity. Bert embeddings capture also syntactic characteristics, which does not necessarily translate to opinions.\n6. The data used to measure the recommendation performance is likely biased towards similar outlets. Thus, a performance drop is obvious.\n\nWhile I really like the general application area and the attempt to tackle such relevant issues, I think the paper is not ready. It needs to be clearer about it's goals, limitations and assumptions. The experimental design needs to be redone to allow to gain any valuable insights. I assume that also a manual analysis is required to confirm any of the hypothesis underlying this research.", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3103/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3103/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Fighting Filterbubbles with Adversarial BERT-Training for News-Recommendation", "authorids": ["~Lukas_Pfahler1", "~Katharina_Morik1"], "authors": ["Lukas Pfahler", "Katharina Morik"], "keywords": ["Adversarial Learning", "Natural Language Processing", "BERT", "News Recommendation", "Attention"], "abstract": "Recommender engines play a role in the emergence and reinforcement of filter bubbles. When these systems learn that a user prefers content from a particular site, the user will be less likely to be exposed to different sources or opinions and, ultimately, is more likely to develop extremist tendencies.\nWe trace the roots of this phenomenon to the way the recommender engine represents news articles. The vectorial features modern systems extract from the plain text of news articles are already highly predictive of the associated news outlet. We propose a new training scheme based on adversarial machine learning to tackle this issue . Our  experiments show that the features we can extract this way are significantly less predictive of the news outlet and thus offer the possibility to reduce the risk of manifestation of new filter bubbles. We validate our intuitions in a news recommendation task using a recent attention-based recommendation system.", "one-sentence_summary": "In order to fight the emergence of filterbubbles in news recommendation systems, we use adversarial training to learn representations of news articles that are less predictive of their respective news outlet.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "pfahler|fighting_filterbubbles_with_adversarial_berttraining_for_newsrecommendation", "pdf": "/pdf/a438e3f78e3af32bc5a59bff9746afd22bc7015b.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=MQW82nnN9E", "_bibtex": "@misc{\npfahler2021fighting,\ntitle={Fighting Filterbubbles with Adversarial {\\{}BERT{\\}}-Training for News-Recommendation},\nauthor={Lukas Pfahler and Katharina Morik},\nyear={2021},\nurl={https://openreview.net/forum?id=2rcgRSAa1A3}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "2rcgRSAa1A3", "replyto": "2rcgRSAa1A3", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3103/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538082247, "tmdate": 1606915804828, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3103/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3103/-/Official_Review"}}}, {"id": "2HhLeVS6iW", "original": null, "number": 3, "cdate": 1603950043626, "ddate": null, "tcdate": 1603950043626, "tmdate": 1605024067680, "tddate": null, "forum": "2rcgRSAa1A3", "replyto": "2rcgRSAa1A3", "invitation": "ICLR.cc/2021/Conference/Paper3103/-/Official_Review", "content": {"title": "This paper studies an interesting problem, fighting filter bubble, by applying GAN in news recommendation. The paper still require some more improvement.", "review": "The problem, fighting filter bubble, is an interesting and important problem to study for recommender systems. The writing of most parts in this paper are pretty clear and easy to follow. Using adversarial BERT training to solve this problem sounds like an interesting idea.\n\nHowever, the paper has multiple flaws:\n1. Its literature review in Sec. 2 is not complete. It only covers a few work related to adversarial training. In my view, another two lines of work that need to covered are fighting filterbubble/diversity in recommender systems and BERT-based recommender systems.\n2. The model is incremental, which is a direct application of adversarial BERT in the news recommendation domain. Its novelty is not enough, especially for ICLR. \n3. Experiments of this work are quite limited. No SOTA recommender systems or models to fight filter bubbles are compared. There're no experiments using variants of the proposed model, which left a few questions unanswered. For example, is predicting the news outlet the only task that is effective to train the model? In my view, news outlet only does not represent a user's preference well, so it doesn't really reflect filter bubbles. What will the result be if you use news topic as the target? How about other options? How about using muti-label to train the model?\n4. The paper doesn't seem to ready for submission. There're quite a few typos and loose ends. For example, a few citations in Sec. 2  are not in the right format. Several results in Tab. 2 are \"pending\".", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3103/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3103/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Fighting Filterbubbles with Adversarial BERT-Training for News-Recommendation", "authorids": ["~Lukas_Pfahler1", "~Katharina_Morik1"], "authors": ["Lukas Pfahler", "Katharina Morik"], "keywords": ["Adversarial Learning", "Natural Language Processing", "BERT", "News Recommendation", "Attention"], "abstract": "Recommender engines play a role in the emergence and reinforcement of filter bubbles. When these systems learn that a user prefers content from a particular site, the user will be less likely to be exposed to different sources or opinions and, ultimately, is more likely to develop extremist tendencies.\nWe trace the roots of this phenomenon to the way the recommender engine represents news articles. The vectorial features modern systems extract from the plain text of news articles are already highly predictive of the associated news outlet. We propose a new training scheme based on adversarial machine learning to tackle this issue . Our  experiments show that the features we can extract this way are significantly less predictive of the news outlet and thus offer the possibility to reduce the risk of manifestation of new filter bubbles. We validate our intuitions in a news recommendation task using a recent attention-based recommendation system.", "one-sentence_summary": "In order to fight the emergence of filterbubbles in news recommendation systems, we use adversarial training to learn representations of news articles that are less predictive of their respective news outlet.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "pfahler|fighting_filterbubbles_with_adversarial_berttraining_for_newsrecommendation", "pdf": "/pdf/a438e3f78e3af32bc5a59bff9746afd22bc7015b.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=MQW82nnN9E", "_bibtex": "@misc{\npfahler2021fighting,\ntitle={Fighting Filterbubbles with Adversarial {\\{}BERT{\\}}-Training for News-Recommendation},\nauthor={Lukas Pfahler and Katharina Morik},\nyear={2021},\nurl={https://openreview.net/forum?id=2rcgRSAa1A3}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "2rcgRSAa1A3", "replyto": "2rcgRSAa1A3", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3103/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538082247, "tmdate": 1606915804828, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3103/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3103/-/Official_Review"}}}, {"id": "FPocKAuhupI", "original": null, "number": 4, "cdate": 1604086036528, "ddate": null, "tcdate": 1604086036528, "tmdate": 1605024067623, "tddate": null, "forum": "2rcgRSAa1A3", "replyto": "2rcgRSAa1A3", "invitation": "ICLR.cc/2021/Conference/Paper3103/-/Official_Review", "content": {"title": "Application of adversarial training for News Recommendation Task", "review": "Authors propose an adversarial training task for tackling the problem of filter bubbles in news recommendation problem. The main aim of the paper is to propose a method which can obfuscate the news outlet information embedded in the news article's vectorial representation. They propose an adversarial training based method for it. \n\nThey propose a standard generator - discriminator setting, where the generator is trying to learn the masked language modelling task and the discriminator is trying to predict the news outlet of the news article. The generator simultaneously tries to optimize for the language modelling task and maximize the news outlet prediction loss. The discriminator tries to minimize the outlet prediction loss. \n\nStrong points of the paper:\n\n1) It tackles a very relevant problem in the current news recommendation problem, i.e. filter bubbles. \n2) The paper is well-written with relevant experiments. \n\nWeak points:\n\n1) The paper is a simple application of the well-established adversarial training methods and there is very little technical novelty in terms of the core contributions. Would advise authors to submit this work in an applied data sciences conferences like SIGIR, CIKM, ECIR etc. \n\n2) Authors have clearly put in a lot of efforts and they are praiseworthy, but given the nature of the contributions, submission to a more applied conference is suggested. ", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3103/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3103/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Fighting Filterbubbles with Adversarial BERT-Training for News-Recommendation", "authorids": ["~Lukas_Pfahler1", "~Katharina_Morik1"], "authors": ["Lukas Pfahler", "Katharina Morik"], "keywords": ["Adversarial Learning", "Natural Language Processing", "BERT", "News Recommendation", "Attention"], "abstract": "Recommender engines play a role in the emergence and reinforcement of filter bubbles. When these systems learn that a user prefers content from a particular site, the user will be less likely to be exposed to different sources or opinions and, ultimately, is more likely to develop extremist tendencies.\nWe trace the roots of this phenomenon to the way the recommender engine represents news articles. The vectorial features modern systems extract from the plain text of news articles are already highly predictive of the associated news outlet. We propose a new training scheme based on adversarial machine learning to tackle this issue . Our  experiments show that the features we can extract this way are significantly less predictive of the news outlet and thus offer the possibility to reduce the risk of manifestation of new filter bubbles. We validate our intuitions in a news recommendation task using a recent attention-based recommendation system.", "one-sentence_summary": "In order to fight the emergence of filterbubbles in news recommendation systems, we use adversarial training to learn representations of news articles that are less predictive of their respective news outlet.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "pfahler|fighting_filterbubbles_with_adversarial_berttraining_for_newsrecommendation", "pdf": "/pdf/a438e3f78e3af32bc5a59bff9746afd22bc7015b.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=MQW82nnN9E", "_bibtex": "@misc{\npfahler2021fighting,\ntitle={Fighting Filterbubbles with Adversarial {\\{}BERT{\\}}-Training for News-Recommendation},\nauthor={Lukas Pfahler and Katharina Morik},\nyear={2021},\nurl={https://openreview.net/forum?id=2rcgRSAa1A3}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "2rcgRSAa1A3", "replyto": "2rcgRSAa1A3", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3103/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538082247, "tmdate": 1606915804828, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3103/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3103/-/Official_Review"}}}], "count": 6}