{"notes": [{"id": "PbEHqvFtcS", "original": "OHssAJWH3MH", "number": 2007, "cdate": 1601308221097, "ddate": null, "tcdate": 1601308221097, "tmdate": 1616084358103, "tddate": null, "forum": "PbEHqvFtcS", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Byzantine-Resilient Non-Convex Stochastic Gradient Descent", "authorids": ["~Zeyuan_Allen-Zhu1", "faezeeb75@gmail.com", "~Jerry_Li1", "~Dan_Alistarh7"], "authors": ["Zeyuan Allen-Zhu", "Faeze Ebrahimianghazani", "Jerry Li", "Dan Alistarh"], "keywords": ["distributed machine learning", "distributed deep learning", "robust deep learning", "non-convex optimization", "Byzantine resilience"], "abstract": "We study adversary-resilient stochastic distributed optimization, in which $m$ machines can independently compute stochastic gradients, and cooperate to jointly optimize over their local objective functions. However, an $\\alpha$-fraction of the machines are Byzantine, in that they may behave in arbitrary, adversarial ways. We consider a variant of this procedure in the challenging non-convex case. Our main result is a new algorithm SafeguardSGD, which can provably escape saddle points and find approximate local minima of the non-convex objective. The algorithm is based on a new concentration filtering technique, and its sample and time complexity bounds match the best known theoretical bounds in the stochastic, distributed setting when no Byzantine machines are present. \n\nOur algorithm is very practical: it improves upon the performance of all prior methods when training deep neural networks, it is relatively lightweight, and it is the first method to withstand two recently-proposed Byzantine attacks. ", "one-sentence_summary": "New algorithm for non-convex distributed optimization against Byzantine attacks, with strong theoretical guarantees, and improves on the performance of prior methods for training deep neural networks against Byzantine attacks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "allenzhu|byzantineresilient_nonconvex_stochastic_gradient_descent", "pdf": "/pdf/2379eb6b69ea25e47b9d640e34e7a22a97b2dd5a.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nallen-zhu2021byzantineresilient,\ntitle={Byzantine-Resilient Non-Convex Stochastic Gradient Descent},\nauthor={Zeyuan Allen-Zhu and Faeze Ebrahimianghazani and Jerry Li and Dan Alistarh},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=PbEHqvFtcS}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "sSjGjdxxp5S", "original": null, "number": 1, "cdate": 1610040367081, "ddate": null, "tcdate": 1610040367081, "tmdate": 1610473957942, "tddate": null, "forum": "PbEHqvFtcS", "replyto": "PbEHqvFtcS", "invitation": "ICLR.cc/2021/Conference/Paper2007/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Poster)", "comment": "The paper presents a new algorithm for byzantine resilient nonconvex distributed optimization. The presentation is clear, the motivation is solid, and the problem setting is interesting. The novelty of the present work is sufficient for publicaiton. The new scheme comes with some provable guarantees, improving the prior state of the art. Some of these guarantees are arguably not corresponding to strong operational robustness guarantees, however they compare well with convergence proofs of the related literature. Some concerns were raised with regards to comparison with some prior work, but the authors addressed it in the rebuttal."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Byzantine-Resilient Non-Convex Stochastic Gradient Descent", "authorids": ["~Zeyuan_Allen-Zhu1", "faezeeb75@gmail.com", "~Jerry_Li1", "~Dan_Alistarh7"], "authors": ["Zeyuan Allen-Zhu", "Faeze Ebrahimianghazani", "Jerry Li", "Dan Alistarh"], "keywords": ["distributed machine learning", "distributed deep learning", "robust deep learning", "non-convex optimization", "Byzantine resilience"], "abstract": "We study adversary-resilient stochastic distributed optimization, in which $m$ machines can independently compute stochastic gradients, and cooperate to jointly optimize over their local objective functions. However, an $\\alpha$-fraction of the machines are Byzantine, in that they may behave in arbitrary, adversarial ways. We consider a variant of this procedure in the challenging non-convex case. Our main result is a new algorithm SafeguardSGD, which can provably escape saddle points and find approximate local minima of the non-convex objective. The algorithm is based on a new concentration filtering technique, and its sample and time complexity bounds match the best known theoretical bounds in the stochastic, distributed setting when no Byzantine machines are present. \n\nOur algorithm is very practical: it improves upon the performance of all prior methods when training deep neural networks, it is relatively lightweight, and it is the first method to withstand two recently-proposed Byzantine attacks. ", "one-sentence_summary": "New algorithm for non-convex distributed optimization against Byzantine attacks, with strong theoretical guarantees, and improves on the performance of prior methods for training deep neural networks against Byzantine attacks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "allenzhu|byzantineresilient_nonconvex_stochastic_gradient_descent", "pdf": "/pdf/2379eb6b69ea25e47b9d640e34e7a22a97b2dd5a.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nallen-zhu2021byzantineresilient,\ntitle={Byzantine-Resilient Non-Convex Stochastic Gradient Descent},\nauthor={Zeyuan Allen-Zhu and Faeze Ebrahimianghazani and Jerry Li and Dan Alistarh},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=PbEHqvFtcS}\n}"}, "tags": [], "invitation": {"reply": {"forum": "PbEHqvFtcS", "replyto": "PbEHqvFtcS", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040367067, "tmdate": 1610473957925, "id": "ICLR.cc/2021/Conference/Paper2007/-/Decision"}}}, {"id": "K_snPXBw0ND", "original": null, "number": 3, "cdate": 1604376559488, "ddate": null, "tcdate": 1604376559488, "tmdate": 1606793147507, "tddate": null, "forum": "PbEHqvFtcS", "replyto": "PbEHqvFtcS", "invitation": "ICLR.cc/2021/Conference/Paper2007/-/Official_Review", "content": {"title": "A good paper on Byzantine-resilient distributed optimization; does need additional clarifications and discussion that *might* be doable in a revision.", "review": "This paper studies distributed non-convex learning that is Byzantine resilient. The main contribution of the paper is an algorithm that is based on perturbed stochastic gradient descent, that is provably resilient to Byzantine failures, and that is guaranteed to reach near second-order stationary points of non-convex objective functions. Compared to similar works in the literature, this paper focuses on identifying Byzantine workers using a \"concentration of gradients\" argument that are then permanently removed from consideration for future iterations. The paper has a nice blend of algorithmic development, theoretical analysis, and detailed experiments. Overall, it is a good paper, worthy of publication in the proceedings. Before the final decision, however, I would like the authors to help address the following questions / comments of mine.\n\n**Major Comments**\n\n1. The permanent removal of workers from each iteration appears to be a risky strategy when one is dealing with workers' data that are not i.i.d. In particular, \"RSA: Byzantine-robust stochastic aggregation methods for distributed learning from heterogeneous datasets\" is one such work that seems to be able to deal with non-i.i.d. datasets in Byzantine settings. It would be useful to see how does the proposed approach work in the presence of non-i.i.d. datasets and how does it compare to works such as the one referenced earlier.\n   - A minor point, which is more of a curiosity: Is it possible for the Byzantine workers to play a colluding game where they force convergence **before** the algorithm had a chance to go through the two windows and eliminate the Byzantine workers?\n2. While the paper refers to its strategy as \"stochastic gradient descent\", the method is really \"perturbed stochastic gradient descent\" that involves adding white Gaussian noise of variance $\\nu^2$ to the iterates. This adds one more parameter to the problem and it is not clear how would one tune this parameter. Theorem 2.3 in the paper requires $\\nu^2$ to be set according to knowledge of $\\alpha$, the fraction of Byzantine workers. It is not clear from reading the paper as to how the authors set this parameter in their experiments.\n3. Related to the above point, Theorem 2.3 only provides scaling guidelines for the different parameters (including the stepsize) in SafeguardSGD and even those scaling guidelines involve knowledge of $\\alpha$. How does one fix these parameters and how were these parameters set for the experiments? In particular, one wonders why does the stepsize need to be a function of the fraction of Byzantine workers?\n4. The statement of Theorem 2.3 needs a bit of clarification. First, it would be useful to specify the \"high probability\" part. What's the scaling of this high probability and it scales with which parameters? Second, what is the practical significance of \"for at least constant fraction of the indices $t$\"? Does this mean that the algorithm can, at the final stages of the algorithm, actually leave the neighborhood of the stationary point?\n5. In Theorem C.1, part (c), the probability is lower bounded by 0.45. This does not seem like \"high probability\" at all. What are the implications of this assumption in Theorem C.1, part (c) on the overall results reported in the paper?\n6. The experimental results are done for fixed numbers of Byzantine workers. It would have been useful to see how the performance scales with the increase in the number of Byzantine workers.\n7. While this paper discusses distributed learning, Byzantine resilience in decentralized learning has also been investigated in recent works (see, e.g., Adversary-resilient distributed and decentralized statistical inference and machine learning: An overview of recent advances under the Byzantine threat model). Are there any lessons for distributed Byzantine resilience from this paper that can be translated to decentralized Byzantine resilience?\n\n**Minor Comments**\n\n1. The range of $p \\in (0,1)$ should be specified in Lemma 3.1 for complete rigor.\n\n***Post-discussion period comments***\n\nI am pleased with the revision the authors have posted during the discussion phase. I am also satisfied with the authors' response to my comments and to the comments of the other reviewers. I therefore recommend that this paper be accepted into proceedings of ICLR 2021.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2007/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2007/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Byzantine-Resilient Non-Convex Stochastic Gradient Descent", "authorids": ["~Zeyuan_Allen-Zhu1", "faezeeb75@gmail.com", "~Jerry_Li1", "~Dan_Alistarh7"], "authors": ["Zeyuan Allen-Zhu", "Faeze Ebrahimianghazani", "Jerry Li", "Dan Alistarh"], "keywords": ["distributed machine learning", "distributed deep learning", "robust deep learning", "non-convex optimization", "Byzantine resilience"], "abstract": "We study adversary-resilient stochastic distributed optimization, in which $m$ machines can independently compute stochastic gradients, and cooperate to jointly optimize over their local objective functions. However, an $\\alpha$-fraction of the machines are Byzantine, in that they may behave in arbitrary, adversarial ways. We consider a variant of this procedure in the challenging non-convex case. Our main result is a new algorithm SafeguardSGD, which can provably escape saddle points and find approximate local minima of the non-convex objective. The algorithm is based on a new concentration filtering technique, and its sample and time complexity bounds match the best known theoretical bounds in the stochastic, distributed setting when no Byzantine machines are present. \n\nOur algorithm is very practical: it improves upon the performance of all prior methods when training deep neural networks, it is relatively lightweight, and it is the first method to withstand two recently-proposed Byzantine attacks. ", "one-sentence_summary": "New algorithm for non-convex distributed optimization against Byzantine attacks, with strong theoretical guarantees, and improves on the performance of prior methods for training deep neural networks against Byzantine attacks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "allenzhu|byzantineresilient_nonconvex_stochastic_gradient_descent", "pdf": "/pdf/2379eb6b69ea25e47b9d640e34e7a22a97b2dd5a.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nallen-zhu2021byzantineresilient,\ntitle={Byzantine-Resilient Non-Convex Stochastic Gradient Descent},\nauthor={Zeyuan Allen-Zhu and Faeze Ebrahimianghazani and Jerry Li and Dan Alistarh},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=PbEHqvFtcS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "PbEHqvFtcS", "replyto": "PbEHqvFtcS", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2007/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538106052, "tmdate": 1606915763223, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2007/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2007/-/Official_Review"}}}, {"id": "6UAp3NyBClC", "original": null, "number": 8, "cdate": 1606182667413, "ddate": null, "tcdate": 1606182667413, "tmdate": 1606182667413, "tddate": null, "forum": "PbEHqvFtcS", "replyto": "szWSPm9v-Fp", "invitation": "ICLR.cc/2021/Conference/Paper2007/-/Official_Comment", "content": {"title": "While not a deal breaker for me, but Reviewer 1 has a solid point", "comment": "I agree with Reviewer 1 that Byzantine failures that are temporally limited can arise due to non-malicious reasons. The proposed approach would fully eliminate such workers from any future consideration, which means one can never benefit from data stored at that worker. While this is not a deal breaker for me, I believe that Reviewer 1's comment should be carefully discussed in the paper. Whether the solution to this issue is round-by-round schemes or not is something that can be left for future work. However, bringing this issue out in the paper is important before the revision deadline closes."}, "signatures": ["ICLR.cc/2021/Conference/Paper2007/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2007/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Byzantine-Resilient Non-Convex Stochastic Gradient Descent", "authorids": ["~Zeyuan_Allen-Zhu1", "faezeeb75@gmail.com", "~Jerry_Li1", "~Dan_Alistarh7"], "authors": ["Zeyuan Allen-Zhu", "Faeze Ebrahimianghazani", "Jerry Li", "Dan Alistarh"], "keywords": ["distributed machine learning", "distributed deep learning", "robust deep learning", "non-convex optimization", "Byzantine resilience"], "abstract": "We study adversary-resilient stochastic distributed optimization, in which $m$ machines can independently compute stochastic gradients, and cooperate to jointly optimize over their local objective functions. However, an $\\alpha$-fraction of the machines are Byzantine, in that they may behave in arbitrary, adversarial ways. We consider a variant of this procedure in the challenging non-convex case. Our main result is a new algorithm SafeguardSGD, which can provably escape saddle points and find approximate local minima of the non-convex objective. The algorithm is based on a new concentration filtering technique, and its sample and time complexity bounds match the best known theoretical bounds in the stochastic, distributed setting when no Byzantine machines are present. \n\nOur algorithm is very practical: it improves upon the performance of all prior methods when training deep neural networks, it is relatively lightweight, and it is the first method to withstand two recently-proposed Byzantine attacks. ", "one-sentence_summary": "New algorithm for non-convex distributed optimization against Byzantine attacks, with strong theoretical guarantees, and improves on the performance of prior methods for training deep neural networks against Byzantine attacks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "allenzhu|byzantineresilient_nonconvex_stochastic_gradient_descent", "pdf": "/pdf/2379eb6b69ea25e47b9d640e34e7a22a97b2dd5a.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nallen-zhu2021byzantineresilient,\ntitle={Byzantine-Resilient Non-Convex Stochastic Gradient Descent},\nauthor={Zeyuan Allen-Zhu and Faeze Ebrahimianghazani and Jerry Li and Dan Alistarh},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=PbEHqvFtcS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "PbEHqvFtcS", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2007/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2007/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2007/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2007/Authors|ICLR.cc/2021/Conference/Paper2007/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2007/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923853308, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2007/-/Official_Comment"}}}, {"id": "szWSPm9v-Fp", "original": null, "number": 6, "cdate": 1605590659301, "ddate": null, "tcdate": 1605590659301, "tmdate": 1606174928638, "tddate": null, "forum": "PbEHqvFtcS", "replyto": "MZycKG3DSe", "invitation": "ICLR.cc/2021/Conference/Paper2007/-/Official_Comment", "content": {"title": "Dear AnnoReviewer1: Thank you, we address your main questions below.", "comment": "Question 1: Comparison to [1], the ByzantineSGD in the convex case? Why [1] is not included in the experiments?\n\nShort Answer 1: on the theory side, the analysis of this paper is completely different from [1]; on the practical side, algorithm [1] doesn\u2019t work in the non-convex case at all (see below).\n\nLong answer 1: On the theoretical side, recall the same SGD algorithm admits completely different proofs in the convex vs non-convex cases. In the convex case, SGD convergence has a 3-line proof, but in the non-convex case, SGD requires long, delicate arguments to ensure approximate local minima, see e.g. 1902.04811 or the original 1503.02101. Thus, even the same SGD algorithm can require very new proofs in the nonconvex case, and can be considered as a significant contribution. We believe this makes our contribution relative to [1] very solid. Specifically, there is no proof overlap between our paper and [1]: e.g., there was no need to escape saddle points in a convex case. \n\nOn the practical side, please note in [1], thanks to convexity, it suffices to check concentration of \u201csum_{t=0,1,..T} nabla_t\u201d, without using sliding windows sum_{t=last, last+1,... T} like we do. This algorithmic difference means [1] could fail dramatically in the non-convex Byzantine case. A concrete experiment on CIFAR10 is given below.\n\nExperiment 1: consider same setting as our paper (resnet-20, 10 workers, 4 Byzantine workers, learning rate 0.1, decay at 80 and 120 epochs, etc). One can first run the vanilla SGD to compute \u201cthe maximum deviation per good worker\u201d for the accumulation vector \u201csum_{t=0,1,..T} nabla_t\u201d. This \u201cmaximum deviation\u201d is therefore a lower bound for the threshold used in algorithm [1]. Next, we can design an attacker, who evenly distributes this total allowed deviation to 5 consecutive epochs, and behaves honestly for the remaining epochs. Such an attacker cannot be caught by [1], because its total deviation across all the iterations is identical to a good worker. However, it can totally break [1].\n\nSpecifically, suppose 4 Byzantine workers all maliciously report \u201c-5\u201d times their stochastic gradients, and the remaining 6 good workers report their true stochastic gradients. One can verify numerically that this attacker can run for 5 consecutive epochs (say, epochs a, a+1, a+2, a+3, a+4) without being caught by algorithm [1]. Now, \n* if a<=75, within just 1 epoch of attack (not even needing 5 epochs), the neural net weights become NaN.\n* if 80<=a<=115, this attack is after the first learning rate decay. Within just 1 epoch of attack, the objective explodes and accuracy becomes 10%, and within 3 epochs it becomes NaN.\n* if 120<=a<=155, this attack is after the second learning rate decay. Within just 2 epochs of attack, the accuracy drops to 11%. Later, the accuracy cannot go above 40%.\n\n\nQ2: \u201cThe problem solved in this paper is not Byzantine tolerance but Byzantine worker detection ...\u2026 In this paper, the proposed method assumes that the malicious workers never change their roles (once Byzantine, always Byzantine)\u201d \n\nA2: our threat model is the standard Byzantine fault model of distributed computing (originally introduced in [Lamport et al., ToPLAS 1982]). Specifically, the Byzantine model assumes that a fraction of the workers can behave arbitrarily, but that their IDs stay fixed. \n\nWe stress that we do not assume that Byzantine workers have to always behave maliciously, or that our algorithm will always detect them. For instance, the Safeguard attack is designed so that our algorithm is never able to mark any of the workers as Byzantine, since they stay within the safeguard bounds. In such a case, our algorithm solves Byzantine-fault-tolerant SGD *without* Byzantine worker detection. \n\nExperimentally, we confirm that the Byzantine attackers can start to behave maliciously in the middle of the execution, as suggested, and the same performance will hold. (Please see the revision.)\n\nQuestion 3: (cont.) \u201csuch assumption is not required by most of the previous works (Krum, median, Zeno)...\u201c\n\nAnswer 3: Indeed, Krum, median, and Zeno filter out bad gradients in a round-by-round fashion, and so, the IDs of Byzantine nodes could change. However, the recent attack of [Baruch et al. \u201cCircumventing defenses for distributed learning\u201d, NeurIPS 2019] shows that such round-by-round schemes suffer from a serious vulnerability: an attacker can shift the true mean while being statistically indistinguishable from a correct worker, since it can always stay \u201cwithin variance\u201d at each round. Their paper breaks Krum and median in real-world scenarios. Thus, it is unclear whether any round-by-round filtering algorithm could defend against such an attack, without historical information or additional assumptions. Note that employing historical information implies that Byzantine workers cannot change IDs. \n\nBy contrast, our Safeguard is able to defend against this SOTA attack, specifically due to leveraging historical information.  \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2007/Authors"], "readers": ["everyone", "ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2007/Area_Chairs", "ICLR.cc/2021/Conference/Paper2007/Reviewers", "ICLR.cc/2021/Conference/Paper2007/Authors"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2007/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Byzantine-Resilient Non-Convex Stochastic Gradient Descent", "authorids": ["~Zeyuan_Allen-Zhu1", "faezeeb75@gmail.com", "~Jerry_Li1", "~Dan_Alistarh7"], "authors": ["Zeyuan Allen-Zhu", "Faeze Ebrahimianghazani", "Jerry Li", "Dan Alistarh"], "keywords": ["distributed machine learning", "distributed deep learning", "robust deep learning", "non-convex optimization", "Byzantine resilience"], "abstract": "We study adversary-resilient stochastic distributed optimization, in which $m$ machines can independently compute stochastic gradients, and cooperate to jointly optimize over their local objective functions. However, an $\\alpha$-fraction of the machines are Byzantine, in that they may behave in arbitrary, adversarial ways. We consider a variant of this procedure in the challenging non-convex case. Our main result is a new algorithm SafeguardSGD, which can provably escape saddle points and find approximate local minima of the non-convex objective. The algorithm is based on a new concentration filtering technique, and its sample and time complexity bounds match the best known theoretical bounds in the stochastic, distributed setting when no Byzantine machines are present. \n\nOur algorithm is very practical: it improves upon the performance of all prior methods when training deep neural networks, it is relatively lightweight, and it is the first method to withstand two recently-proposed Byzantine attacks. ", "one-sentence_summary": "New algorithm for non-convex distributed optimization against Byzantine attacks, with strong theoretical guarantees, and improves on the performance of prior methods for training deep neural networks against Byzantine attacks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "allenzhu|byzantineresilient_nonconvex_stochastic_gradient_descent", "pdf": "/pdf/2379eb6b69ea25e47b9d640e34e7a22a97b2dd5a.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nallen-zhu2021byzantineresilient,\ntitle={Byzantine-Resilient Non-Convex Stochastic Gradient Descent},\nauthor={Zeyuan Allen-Zhu and Faeze Ebrahimianghazani and Jerry Li and Dan Alistarh},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=PbEHqvFtcS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "PbEHqvFtcS", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2007/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2007/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2007/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2007/Authors|ICLR.cc/2021/Conference/Paper2007/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2007/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923853308, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2007/-/Official_Comment"}}}, {"id": "YOt2G5x6L3o", "original": null, "number": 5, "cdate": 1605590508763, "ddate": null, "tcdate": 1605590508763, "tmdate": 1605590570816, "tddate": null, "forum": "PbEHqvFtcS", "replyto": "7bk_pRkiDX_", "invitation": "ICLR.cc/2021/Conference/Paper2007/-/Official_Comment", "content": {"title": "Dear AnnoReviewer3:", "comment": "Thank you for the comments; below we summarize your major concerns and address them one by one.\n\n\nQ1: the machines are already running in a distributed environment, how can one do parallel speedup? \n\nA1: We mean the total distributed running time, compared to running everything on a single (honest) machine. Recall if there are no Byzantine workers, the (wall-clock) speed-up factor is m for SGD (when ignoring communication overhead). We thus call it \u201cparallel speedup\u201d following some tradition. We will explain this better in our revision.\n\nQ2: Please define notations before using them. It is quite an issue while reading the paper, you have to stop and have to find the definition. Omega(m^2 d) in the introduction is not defined before. While mentioning the number of iteration required x0 is not defined, \\tilde{O} is not defined and is defined at section 2. Lemma 3.2 Delta_t is used and then defined later.\n\nA2: We apologise, we will fix these issues in the revision. \n\nQ3: The formal analysis is though rigorous but it requires a lot of time to understand as some of these notations are not defined and clearly mentioned and one has to assume some of the arguments presented to follow on.\n\nA3: Thank you, we acknowledge your comment and will strive to improve in the revision. Meanwhile, we would like to mention that we have put significant effort to simplify analysis and notations. If you go to page 24-29 of the original paper by Jin et al (2019), see arXiv 1902.04811, you may notice that we have really tried our best to simplify notations, so that our Byzantine version of the proof is even shorter than the original Jin et al (2019), which has no Byzantine workers! \n\nSome of our simplifications come at the expense of adding a few minor assumptions (such as replacing E[| ..|^2]<=sigma^2 with an absolute bound |..|<=sigma. This has already made some reviewers (e.g. AnnoReviewer2) question why we do so. We have tried to find a delicate balance between what assumptions we make, and how simple the proof can be. We understand we can do even better, and will follow your suggestions.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2007/Authors"], "readers": ["everyone", "ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2007/Area_Chairs", "ICLR.cc/2021/Conference/Paper2007/Reviewers", "ICLR.cc/2021/Conference/Paper2007/Authors"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2007/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Byzantine-Resilient Non-Convex Stochastic Gradient Descent", "authorids": ["~Zeyuan_Allen-Zhu1", "faezeeb75@gmail.com", "~Jerry_Li1", "~Dan_Alistarh7"], "authors": ["Zeyuan Allen-Zhu", "Faeze Ebrahimianghazani", "Jerry Li", "Dan Alistarh"], "keywords": ["distributed machine learning", "distributed deep learning", "robust deep learning", "non-convex optimization", "Byzantine resilience"], "abstract": "We study adversary-resilient stochastic distributed optimization, in which $m$ machines can independently compute stochastic gradients, and cooperate to jointly optimize over their local objective functions. However, an $\\alpha$-fraction of the machines are Byzantine, in that they may behave in arbitrary, adversarial ways. We consider a variant of this procedure in the challenging non-convex case. Our main result is a new algorithm SafeguardSGD, which can provably escape saddle points and find approximate local minima of the non-convex objective. The algorithm is based on a new concentration filtering technique, and its sample and time complexity bounds match the best known theoretical bounds in the stochastic, distributed setting when no Byzantine machines are present. \n\nOur algorithm is very practical: it improves upon the performance of all prior methods when training deep neural networks, it is relatively lightweight, and it is the first method to withstand two recently-proposed Byzantine attacks. ", "one-sentence_summary": "New algorithm for non-convex distributed optimization against Byzantine attacks, with strong theoretical guarantees, and improves on the performance of prior methods for training deep neural networks against Byzantine attacks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "allenzhu|byzantineresilient_nonconvex_stochastic_gradient_descent", "pdf": "/pdf/2379eb6b69ea25e47b9d640e34e7a22a97b2dd5a.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nallen-zhu2021byzantineresilient,\ntitle={Byzantine-Resilient Non-Convex Stochastic Gradient Descent},\nauthor={Zeyuan Allen-Zhu and Faeze Ebrahimianghazani and Jerry Li and Dan Alistarh},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=PbEHqvFtcS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "PbEHqvFtcS", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2007/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2007/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2007/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2007/Authors|ICLR.cc/2021/Conference/Paper2007/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2007/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923853308, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2007/-/Official_Comment"}}}, {"id": "M9uerwUP_nj", "original": null, "number": 4, "cdate": 1605590242461, "ddate": null, "tcdate": 1605590242461, "tmdate": 1605590385088, "tddate": null, "forum": "PbEHqvFtcS", "replyto": "K_snPXBw0ND", "invitation": "ICLR.cc/2021/Conference/Paper2007/-/Official_Comment", "content": {"title": "Dear AnnoReviewer4:", "comment": "Thanks for careful reading of our paper. Below we only address your major comments in order (to save space).\n\nQ1: How about non-i.i.d. (heterogeneous) data?\n\nA1: Similar to some prior work, we study the case when workers have i.i.d. data. This is realistic since in many neural net training, e.g. when training ImageNet, the entire training data is usually shared across workers. We admit it can be challenging to study non-i.i.d. data for the nonconvex objectives, so this is left as future work. \n\nQ2: Should be \u201cperturbed\u201d SGD instead of SGD.\n\nA2: Fair point. We have followed tradition (since the seminal work 1503.02101 and others) to call \u201cperturbed SGD\u201d also SGD for short, because in practice, the random noise of SGD is sufficient to help escape saddle points, and the random Gaussian is added only for theoretical purposes.  Adding Gaussian perturbation in practice makes no difference (both for our alg and classical SGD). \n\nQ3: Theorem 2.3 only provides scaling guidelines for the different parameters ... those scaling guidelines involve knowledge of alpha. How were these parameters set for the experiments? \n\nA3: Such scaling guidelines are also common in prior works (see e.g. arXiv 1803.08917). One can derive different performance gains for different ranges of parameters (see for instance Theorem 3.8 of 1803.08917), and we have simply picked the \u201coptimal parameters\u201d in our theorem statement for a fair theoretical comparison.\n\nIn practice, there is no strict requirement, and we found a wide range of parameters to work. Our experiment parameters are given on Page 19. For instance, the \\nu parameter doesn\u2019t matter (see our answer A2 above) and setting \\nu=0 also works. The safeguard thresholds can be automatically derived either by pre-running the algorithm or calculating them on the fly. We chose the window sizes T1 and T2 without tuning. We set the learning rate to be 0.1, which is standard for this model/dataset in the failure-free case. \n\nQ4: It would be useful to specify the \"high probability\" part. What's the scaling of this high probability and it scales with which parameters? Second, what is the practical significance of \"for at least constant fraction of the indices t\"?\n\nA4: High probability means that if we want probability 1-p, then the final bounds only have log(1/p) factors. We hide it to make the theorem statement clean. In fact, we have carried around these log parameters in our proofs. We only omitted them in the last step, to keep the statement clean. \n\nAs regarding \u201cat least a constant fraction\u201d, this is necessary for theoretical purposes. All existing non-convex convergence results require it. See for instance the very first paper by Nesterov 2008 (Thm 5 in 1902.04811). Furthermore, Thms 10,13,16,17 in 1902.04811 even stated a weaker version \u201cmeet a stationary point at least once\u201d, as opposed to \u201cat least constant fraction of the iterations\u201d. Imagine, one can construct a nonconvex function where if you stop an algorithm at a fixed iteration T, it is on the way escaping one local minima and moving to a better local minima. This is why we cannot guarantee for all the indices in theory. This will not happen in the convex case, and not likely happen in practice in the nonconvex case.\n\nQ5: In Thm C.1, probability is lower bounded by 0.45. This does not seem like \"high probability\"\n\nA5: There is no contradiction. Thm 2.3 states that, w.h.p., for at least a CONSTANT fraction of the iterations, the result holds. This constant fraction can be for instance 30% of the iterations. As we said in Answer A4, this is *necessary* for non-convex theory and prior work (e.g. 1902.04811) often guarantees it for at least ONE iteration. We improved this to 30% of the iterations; but this cannot be improved to the last iteration only. \n\nQ6: experiment result for increasing the number of Byzantine workers?\n\nA6: Thanks. We currently used m=10 workers with 4 Byzantine workers (the hardest possible), and batch size 8 (so 80 samples per iteration). This total batch size 80 is a good choice for training residual models on CIFAR10. We have also tried 100 workers with 40 Byzantine workers and batch size 1 and there\u2019s no significant difference --- because the total number of samples per iteration remains the same. We could run for even more samples, but then run into batch scaling issues. \n\nQ7: Are there any lessons for distributed Byzantine resilience from this paper that can be translated to decentralized Byzantine resilience?\n\nA7: We believe additional assumptions are needed. If the Byzantine workers form a node cut to block honest workers from communication, then there\u2019s no solution. If the network forms a tree, we can ask the machines to pass gradients to the root; then, each non-Byzantine machine can keep a safeguard (like this paper) for its subtree. We believe this is a very interesting but challenging question, and we leave it a future work to study what\u2019s the reasonable assumption to make. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2007/Authors"], "readers": ["everyone", "ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2007/Area_Chairs", "ICLR.cc/2021/Conference/Paper2007/Reviewers", "ICLR.cc/2021/Conference/Paper2007/Authors"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2007/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Byzantine-Resilient Non-Convex Stochastic Gradient Descent", "authorids": ["~Zeyuan_Allen-Zhu1", "faezeeb75@gmail.com", "~Jerry_Li1", "~Dan_Alistarh7"], "authors": ["Zeyuan Allen-Zhu", "Faeze Ebrahimianghazani", "Jerry Li", "Dan Alistarh"], "keywords": ["distributed machine learning", "distributed deep learning", "robust deep learning", "non-convex optimization", "Byzantine resilience"], "abstract": "We study adversary-resilient stochastic distributed optimization, in which $m$ machines can independently compute stochastic gradients, and cooperate to jointly optimize over their local objective functions. However, an $\\alpha$-fraction of the machines are Byzantine, in that they may behave in arbitrary, adversarial ways. We consider a variant of this procedure in the challenging non-convex case. Our main result is a new algorithm SafeguardSGD, which can provably escape saddle points and find approximate local minima of the non-convex objective. The algorithm is based on a new concentration filtering technique, and its sample and time complexity bounds match the best known theoretical bounds in the stochastic, distributed setting when no Byzantine machines are present. \n\nOur algorithm is very practical: it improves upon the performance of all prior methods when training deep neural networks, it is relatively lightweight, and it is the first method to withstand two recently-proposed Byzantine attacks. ", "one-sentence_summary": "New algorithm for non-convex distributed optimization against Byzantine attacks, with strong theoretical guarantees, and improves on the performance of prior methods for training deep neural networks against Byzantine attacks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "allenzhu|byzantineresilient_nonconvex_stochastic_gradient_descent", "pdf": "/pdf/2379eb6b69ea25e47b9d640e34e7a22a97b2dd5a.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nallen-zhu2021byzantineresilient,\ntitle={Byzantine-Resilient Non-Convex Stochastic Gradient Descent},\nauthor={Zeyuan Allen-Zhu and Faeze Ebrahimianghazani and Jerry Li and Dan Alistarh},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=PbEHqvFtcS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "PbEHqvFtcS", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2007/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2007/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2007/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2007/Authors|ICLR.cc/2021/Conference/Paper2007/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2007/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923853308, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2007/-/Official_Comment"}}}, {"id": "KoJCYkwpzb1", "original": null, "number": 3, "cdate": 1605590082118, "ddate": null, "tcdate": 1605590082118, "tmdate": 1605590122388, "tddate": null, "forum": "PbEHqvFtcS", "replyto": "r7Ec0BSw3OA", "invitation": "ICLR.cc/2021/Conference/Paper2007/-/Official_Comment", "content": {"title": "Dear AnnoReviewer2:", "comment": "Thanks for your time and support. Below we try to address all of your main concerns.\n\nQ1: In Jin et al. (2019), dependence on d can be avoided when an additional assumption (Lipschitz stochastic gradient) is made. Can this work use this assumption? Footnote 3 on page 4 argues that it may be too strong for practical applications.\n\nA1: Thanks for asking. \n\nShort answer: (1) yes, we believe this assumption (which we didn\u2019t use) is \u201cprovably\u201d unrealistic, and (2) yes, our analysis can be adapted to leverage this assumption, but it requires an algorithmic change that we do not think is worth adding. \n\nLonger answer: first, this assumption is indeed too strong, at least for neural net training. In particular, an individual sample\u2019s Lip-smoothness can be 100++ times worse than the overall Lip-smoothness, even at the end of the training. One can either verify this by experiment (in which we did on CIFAR data), or compare this to existing work on adversarial examples: it is known that even an extremely small perturbation can drastically change the output (thus the cross-entropy gradient) for an *individual* sample on a clean-trained model. \n\nSecond, algorithms based on this assumption are often impractical for neural net training. For instance, variance reduction (VR) algorithms require this additional assumption to work; although beautiful in theory --- with 1/eps^3 rate at best, see arxiv 1807.01695 --- VR-based algs unfortunately do not beat SGD in practice. \n\nThird, if this assumption is made, there are two ways to modify our paper. The first one is to Byzantine \u201crobustify\u201d a VR-based alg (this is possible!) to get a 1/eps^3 rate. We don\u2019t think it\u2019s worth doing it, since VR-based algs do not beat SGD in neural net training. The other way is to derive the 1/eps^4 rate for SGD, but this requires an algorithmic change --- namely, to add a third safeguard to ensure \u201cthe stochastic nabla_t - nabla_0 is small and proportional to |xt-x0|\u201d under a certain window size. Again, since this assumption is not realistic, we do not wish to influence the readers to add this algorithmic change. But, it is indeed possible. \n\nQ2: Assumption 2.1, the bounds are typically in expectation: E[||\u2207f(x_t) - \u2207ti ||^2] <= \u03c3^2. Can this paper handle this assumption?\n\nA2: Yes we can, at the expense of complicating the proofs and introducing additional log factors. For instance, we used Lemma B.1 (Pinelis 1994) to derive concentration using absolute bounds, and if that changes to E[|..|^2] then one needs to complicate the notations and derive some vector version of Azuma inequality. We wished to make this paper simple enough comparing to e.g. Jin et al (2019) to attract more readers. Thus, we used this assumption.\n\n\nQ3: Algorithm 1, isn\u2019t it more natural to take an average over good{t+1}, not good_t?\n\nA3: You are right. We chose the latter since it makes our proof simpler. This way, the denominator no longer depends on the randomness/adversarial choice at the current round. Of course, one can switch it to good_{t+1} in the end and pay a negligible additive term.\n\nQ4: Page 13, last equation: I don\u2019t see how it follows from Lemma 4.2.\n\nA4: Thanks! That\u2019s a typo. Ignoring C1 for notational simplicity, Lemma 4.2 says <nabla f(wt), xi_t> <= |nabla f(wt)| * O(eta v) <= 0.05 eta |nabla f(wt)| + O(eta v^2). Then sum it up over t.\n\n\nQ5: Page 14, Equation B.2: isn\u2019t this way to bound the sum too loose? What\u2019s the intuition behind this approach? Can we get a better bound?\n\nA5: Short answer: you\u2019re absolutely right, that individual bound is loose. However, since we are not losing significant factors (once C2 is replaced with 1) compared to Jin et al. (2019), our analysis is still asymptotically tight.\n\nLonger answer: if one doesn\u2019t want to use Equation B.2, then our best guess is that one needs to add an additional safeguard to ensure \u201c<nabla f(w_t), nabla_t>\u201d also concentrates. This is different from the simple stochastic gradient concentration, so we want to keep the algorithm as simple as possible.\n\n\nQ6: suggest adding discussions for why the algorithm doesn\u2019t significantly degrade when \u03b1 is close to \u00bd, unlike what one can expect.\n\nA6: Thanks for this great suggestion. Short answer, with m machines the variance of the stochastic gradient usually degrades to 1/m of it used to be. However, with alpha*m machines colluding, they can contribute to this variance by alpha^2 additively. This gives the (alpha^2 + 1/m) that shows up in prior work and in this work. \n\n\nQ7: simple proof of Lemma 3.1\n\nA7: thank you and we believe you\u2019re right. Our main difficulties in the proofs are regarding how to use the \u201cminimal safeguard\u201d to derive tight bounds for SGD in the non-convex setting, and we believe this requires us to have quite different proofs from Jin et al. (2019).\n\nQ8: I believe that the following places would benefit from the further expansion. [...]\n\nA8: Thanks a lot! The above are all good suggestions, which we will implement in the next revision. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2007/Authors"], "readers": ["everyone", "ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2007/Area_Chairs", "ICLR.cc/2021/Conference/Paper2007/Reviewers", "ICLR.cc/2021/Conference/Paper2007/Authors"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2007/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Byzantine-Resilient Non-Convex Stochastic Gradient Descent", "authorids": ["~Zeyuan_Allen-Zhu1", "faezeeb75@gmail.com", "~Jerry_Li1", "~Dan_Alistarh7"], "authors": ["Zeyuan Allen-Zhu", "Faeze Ebrahimianghazani", "Jerry Li", "Dan Alistarh"], "keywords": ["distributed machine learning", "distributed deep learning", "robust deep learning", "non-convex optimization", "Byzantine resilience"], "abstract": "We study adversary-resilient stochastic distributed optimization, in which $m$ machines can independently compute stochastic gradients, and cooperate to jointly optimize over their local objective functions. However, an $\\alpha$-fraction of the machines are Byzantine, in that they may behave in arbitrary, adversarial ways. We consider a variant of this procedure in the challenging non-convex case. Our main result is a new algorithm SafeguardSGD, which can provably escape saddle points and find approximate local minima of the non-convex objective. The algorithm is based on a new concentration filtering technique, and its sample and time complexity bounds match the best known theoretical bounds in the stochastic, distributed setting when no Byzantine machines are present. \n\nOur algorithm is very practical: it improves upon the performance of all prior methods when training deep neural networks, it is relatively lightweight, and it is the first method to withstand two recently-proposed Byzantine attacks. ", "one-sentence_summary": "New algorithm for non-convex distributed optimization against Byzantine attacks, with strong theoretical guarantees, and improves on the performance of prior methods for training deep neural networks against Byzantine attacks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "allenzhu|byzantineresilient_nonconvex_stochastic_gradient_descent", "pdf": "/pdf/2379eb6b69ea25e47b9d640e34e7a22a97b2dd5a.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nallen-zhu2021byzantineresilient,\ntitle={Byzantine-Resilient Non-Convex Stochastic Gradient Descent},\nauthor={Zeyuan Allen-Zhu and Faeze Ebrahimianghazani and Jerry Li and Dan Alistarh},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=PbEHqvFtcS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "PbEHqvFtcS", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2007/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2007/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2007/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2007/Authors|ICLR.cc/2021/Conference/Paper2007/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2007/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923853308, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2007/-/Official_Comment"}}}, {"id": "7bk_pRkiDX_", "original": null, "number": 2, "cdate": 1603896084302, "ddate": null, "tcdate": 1603896084302, "tmdate": 1605517979419, "tddate": null, "forum": "PbEHqvFtcS", "replyto": "PbEHqvFtcS", "invitation": "ICLR.cc/2021/Conference/Paper2007/-/Official_Review", "content": {"title": "The paper has great formal analysis but is needs format organization and clarification", "review": "\nThe authors present quite an interesting approach where they focus on the number of stochastic gradient evaluations rather than bounding the number of sampled stochastic functions. They converted other aggregation functions in their own formulation and then did a fair comparison. The results are in favor of the authors' method. The SafegaurdSGD algorithm is presented with several formal analysis and authors shows that why it is theoretically better to have two matrices (history record or safeguards) to mark the working machines good or bad/byzantine. The time complexity they present seems a bit difficult to understand and the argument they present for parallel speedup is also difficult to grasp as the machines are already running in a distributed environment how one can do parallel speedup? This should be presented in a clear way. The formal analysis is though rigorous but it requires a lot of time to understand as some of these notations are not defined and clearly mentioned and one has to assume some of the arguments presented to follow on.  The author presents that their method offers stronger bounds.  I appreciate the formal work and it clearly aligns with the results they have shown in the paper and in the supplementary part. The authors have studied the latest attacks introduced in literature and experimented other methods in their own introduced attack for a fair comparison which is great. Although there are several parameters that the authors do not discuss how they are chosen for the experiments they just show the experiment results for some selected values of parameters. \nThe paper needs some format organization and need to define and clear something so it might become clear to other readers to understand and grasp concepts. \nThe authors have already talked about the parallel speed in the introduction and instead of iterating in after Theorem 2.3, space can be used to fill with other detail or definition as it can be seen the authors are already short on space due to page limit. \nIn the end, I want to say that please define notations before using them. It is quite an issue while reading the paper, you have to stop and have to find the definition. $\\Omega(m^2d)$ in the introduction $d$ is not defined before. While mentioning the number of iteration required $x_0$ is not defined, $\\Tilde O$ is not defined and is defined at section $2$. Lemma 3.2 $\\Delta_t$ is used and then defined later. The spelling of Loewner is wrong. \n ", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2021/Conference/Paper2007/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2007/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Byzantine-Resilient Non-Convex Stochastic Gradient Descent", "authorids": ["~Zeyuan_Allen-Zhu1", "faezeeb75@gmail.com", "~Jerry_Li1", "~Dan_Alistarh7"], "authors": ["Zeyuan Allen-Zhu", "Faeze Ebrahimianghazani", "Jerry Li", "Dan Alistarh"], "keywords": ["distributed machine learning", "distributed deep learning", "robust deep learning", "non-convex optimization", "Byzantine resilience"], "abstract": "We study adversary-resilient stochastic distributed optimization, in which $m$ machines can independently compute stochastic gradients, and cooperate to jointly optimize over their local objective functions. However, an $\\alpha$-fraction of the machines are Byzantine, in that they may behave in arbitrary, adversarial ways. We consider a variant of this procedure in the challenging non-convex case. Our main result is a new algorithm SafeguardSGD, which can provably escape saddle points and find approximate local minima of the non-convex objective. The algorithm is based on a new concentration filtering technique, and its sample and time complexity bounds match the best known theoretical bounds in the stochastic, distributed setting when no Byzantine machines are present. \n\nOur algorithm is very practical: it improves upon the performance of all prior methods when training deep neural networks, it is relatively lightweight, and it is the first method to withstand two recently-proposed Byzantine attacks. ", "one-sentence_summary": "New algorithm for non-convex distributed optimization against Byzantine attacks, with strong theoretical guarantees, and improves on the performance of prior methods for training deep neural networks against Byzantine attacks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "allenzhu|byzantineresilient_nonconvex_stochastic_gradient_descent", "pdf": "/pdf/2379eb6b69ea25e47b9d640e34e7a22a97b2dd5a.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nallen-zhu2021byzantineresilient,\ntitle={Byzantine-Resilient Non-Convex Stochastic Gradient Descent},\nauthor={Zeyuan Allen-Zhu and Faeze Ebrahimianghazani and Jerry Li and Dan Alistarh},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=PbEHqvFtcS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "PbEHqvFtcS", "replyto": "PbEHqvFtcS", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2007/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538106052, "tmdate": 1606915763223, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2007/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2007/-/Official_Review"}}}, {"id": "MZycKG3DSe", "original": null, "number": 1, "cdate": 1603688277936, "ddate": null, "tcdate": 1603688277936, "tmdate": 1605024309287, "tddate": null, "forum": "PbEHqvFtcS", "replyto": "PbEHqvFtcS", "invitation": "ICLR.cc/2021/Conference/Paper2007/-/Official_Review", "content": {"title": "below acceptance threshold", "review": "In this paper, the authors propose a new algorithm called SafeguardSGD, which solves the Byzantine detection problem, and tolerate less than half Byzantine workers with theoretical guarantees. Both theoretical and empirical results are provided. Compare to the baselines, the proposed algorithms show better performance on fixed Byzantine workers. In overall, I think this is a good paper.\n\nHowever, there are some issues to be resolved:\n\n1. The problem solved in this paper is actually not Byzantine tolerance, but Byzantine worker detection, which is a special case of Byzantine tolerance with stronger assumptions. The main difference is that, in this paper, the proposed method assumes that the malicious workers never change their roles (once Byzantine, always Byzantine), i.e., the indices of the Byzantine workers never change. Such assumption is not required by most of the previous works (Krum, median, Zeno), although it may not be emphasized in the previous work. With such assumption, the proposed algorithm could make the use of the historical info and remove the Byzantine worker permanently, which is why it could perform better than the baselines. I'm ok with the scenario (which is also used in [1]), but the authors should clearly state that the threat model in this paper is weaker than the previous work.\n\nWhy this assumption matters?  Note that it is unnecessary that the Byzantine workers always behaves maliciously.\n\nConsidering the following cases:\n\n(1) The Byzantine workers behave as honest workers at the beginning, and start the attack at the middle of the training. I believe the proposed algorithm could handle this case, but it will be better if such experiments could be added.\n\n(2) On some workers, there are some occasional and temporal hardware/software failures that produce results with huge error (flipped bits, large random noise), but such workers will recover later. In this case, it seems unreasonable to remove the failed workers from the list of good workers permanently.\n\n\n2. It seems that the proposed algorithm is highly related and similar to [1]. However, the difference to [1] is not discussed in details in this paper. Furthermore, since [1] uses the same weakened threat model as this paper, it should be the most important baseline to compare to, which is not included in the experiments. I understand that there is not experiments in [1], so doing experiments for it may be difficult, but I'm not sure whether it's just difficult or totally infeasible. At least, the authors should explain why [1] is not included in the experiments.\n\n[1] Alistarh, D., Allen-Zhu, Z., & Li, J. Byzantine stochastic gradient descent. NeurIPS 2018.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2007/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2007/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Byzantine-Resilient Non-Convex Stochastic Gradient Descent", "authorids": ["~Zeyuan_Allen-Zhu1", "faezeeb75@gmail.com", "~Jerry_Li1", "~Dan_Alistarh7"], "authors": ["Zeyuan Allen-Zhu", "Faeze Ebrahimianghazani", "Jerry Li", "Dan Alistarh"], "keywords": ["distributed machine learning", "distributed deep learning", "robust deep learning", "non-convex optimization", "Byzantine resilience"], "abstract": "We study adversary-resilient stochastic distributed optimization, in which $m$ machines can independently compute stochastic gradients, and cooperate to jointly optimize over their local objective functions. However, an $\\alpha$-fraction of the machines are Byzantine, in that they may behave in arbitrary, adversarial ways. We consider a variant of this procedure in the challenging non-convex case. Our main result is a new algorithm SafeguardSGD, which can provably escape saddle points and find approximate local minima of the non-convex objective. The algorithm is based on a new concentration filtering technique, and its sample and time complexity bounds match the best known theoretical bounds in the stochastic, distributed setting when no Byzantine machines are present. \n\nOur algorithm is very practical: it improves upon the performance of all prior methods when training deep neural networks, it is relatively lightweight, and it is the first method to withstand two recently-proposed Byzantine attacks. ", "one-sentence_summary": "New algorithm for non-convex distributed optimization against Byzantine attacks, with strong theoretical guarantees, and improves on the performance of prior methods for training deep neural networks against Byzantine attacks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "allenzhu|byzantineresilient_nonconvex_stochastic_gradient_descent", "pdf": "/pdf/2379eb6b69ea25e47b9d640e34e7a22a97b2dd5a.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nallen-zhu2021byzantineresilient,\ntitle={Byzantine-Resilient Non-Convex Stochastic Gradient Descent},\nauthor={Zeyuan Allen-Zhu and Faeze Ebrahimianghazani and Jerry Li and Dan Alistarh},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=PbEHqvFtcS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "PbEHqvFtcS", "replyto": "PbEHqvFtcS", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2007/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538106052, "tmdate": 1606915763223, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2007/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2007/-/Official_Review"}}}, {"id": "r7Ec0BSw3OA", "original": null, "number": 4, "cdate": 1604531974178, "ddate": null, "tcdate": 1604531974178, "tmdate": 1605024309109, "tddate": null, "forum": "PbEHqvFtcS", "replyto": "PbEHqvFtcS", "invitation": "ICLR.cc/2021/Conference/Paper2007/-/Official_Review", "content": {"title": "Good paper, accept", "review": "The paper considers stochastic gradient descent convergence in a distributed setting with m workers, where up to \u03b1 workers can be Byzantine, i.e. perform in an arbitrarily adversarial way. In this setting, they develop a variant of SGD which finds a second-order stationary point, prevents Byzantine workers from significantly affecting convergence, and achieves \u03b1^2 + 1/m speedup compared with the sequential case. The main idea of the algorithm is to measure deviations of gradient updates for a certain number of rounds and detect Byzantine machines which must have a significant deviation to noticeably affect the algorithm\u2019s behavior.\n\n\nIf I\u2019m correct, Lemma 3.1 allows a much simpler proof:\n|\\sum_{t=1}^{T-1} (\u03be_0 + \u2026 + \u03be_{t-1}) * Delta_t|\n<= |\\sum_{t=1}^{T-1} \u03be_t| * |\\sum_{t=1}^{T-1} Delta_t| + |\\sum_{t=1}^{T-1} \u03be_t * (Delta_1 + \u2026 + Delta_t)|\nThe first term is estimated as a sum of independent Guassians. The second term can be estimated using Azuma\u2019s inequality (it\u2019s a martingale since E[\u03be_t] = 0 and \u03be_t is independent on \u03be_1, \u2026, \u03be_{t-1}, Delta_1, \u2026, Delta_t). We can bound their norms of \u03be_t by O(log (T/p)) with probability 1 - p/T.\n\nQuestions:\nIn Jin et al. (2019), dependence on d can be avoided when an additional assumption (Lipschitz stochastic gradient) is made. Can this work use this assumption? I believe that footnote 3 on page 4 talks about this assumption and argues that it may be too strong for practical applications, but I don\u2019t see a reason to not get a result with this assumption. Are there technical obstacles?\nAssumption 2.1, both items: the bounds are typically taken in expectation: E[||\u2207f(x_t) - \u2207_ti ||^2] <= \u03c3^2. Can this paper handle this kind of assumption? At the very least, one can\u2019t immediately detect byzantine machines that deviate from the mean by more than \u03c3.\nAlgorithm 1, line 11: it shouldn\u2019t matter, but isn\u2019t it more natural to take an average over good_{t+1}, not good_t?\nPage 13, last equation: while the inequality seems to be true (since \u03be_t are independent Gaussians), I don\u2019t see how it follows from Lemma 4.2.\nPage 14, Equation B.2: isn\u2019t this way to bound the sum too loose? What\u2019s the intuition behind this approach? Can we get a better bound with some other approach?\n\nThe following parts would benefit from an additional discussion:\nWhile it\u2019s clear that \u03b1^2 + 1/m comes from bounds on \u03c3_t and Delta_t, the intuitive meaning behind the \u03b1^2 term is not clear. The reason why \u03b1=1/sqrt(m) is a threshold is also not clear.\nWhile it may be clear from the algorithm (namely how the median behaves), I think it\u2019s also worth explaining why the algorithm doesn\u2019t significantly degrade when \u03b1 is close to \u00bd, unlike what one can expect.\n\nI believe that the following places would benefit from the further expansion:\nPage 13, bound on ||Delta_0 + \u2026 + Delta||^2: it\u2019s better to explicitly write relation between B^t and Delta_t.\nPage 15, \u201cfor some vector ||\u03b8_t||\u201d: I would explain the bound.\nPage 15, \u201c\u03c8_t is zero except in the first coordinate\u201d: I would explain why.\nPage 16, right after M is introduced: I would explain the first transition.\n\nMinor issues:\nWhile assuming that smoothness constants are 1 slightly simplifies the presentation, I believe that it makes some transitions harder to understand. E.g. bound on \u03b8_t on page 15 would be more clear if the Hessian Lipshitz constant was in the equation.\nnu should be an input/parameter of Algorithm 1\nPage 13, proof of Claim B.2: it\u2019s said that the proof is by induction, by I don\u2019t think you use induction anywhere.\nPage 13, Proof of Lemma 4.3: \u201cLipschitz smoothness\u201d -> \u201csmoothness\u201d?\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2007/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2007/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Byzantine-Resilient Non-Convex Stochastic Gradient Descent", "authorids": ["~Zeyuan_Allen-Zhu1", "faezeeb75@gmail.com", "~Jerry_Li1", "~Dan_Alistarh7"], "authors": ["Zeyuan Allen-Zhu", "Faeze Ebrahimianghazani", "Jerry Li", "Dan Alistarh"], "keywords": ["distributed machine learning", "distributed deep learning", "robust deep learning", "non-convex optimization", "Byzantine resilience"], "abstract": "We study adversary-resilient stochastic distributed optimization, in which $m$ machines can independently compute stochastic gradients, and cooperate to jointly optimize over their local objective functions. However, an $\\alpha$-fraction of the machines are Byzantine, in that they may behave in arbitrary, adversarial ways. We consider a variant of this procedure in the challenging non-convex case. Our main result is a new algorithm SafeguardSGD, which can provably escape saddle points and find approximate local minima of the non-convex objective. The algorithm is based on a new concentration filtering technique, and its sample and time complexity bounds match the best known theoretical bounds in the stochastic, distributed setting when no Byzantine machines are present. \n\nOur algorithm is very practical: it improves upon the performance of all prior methods when training deep neural networks, it is relatively lightweight, and it is the first method to withstand two recently-proposed Byzantine attacks. ", "one-sentence_summary": "New algorithm for non-convex distributed optimization against Byzantine attacks, with strong theoretical guarantees, and improves on the performance of prior methods for training deep neural networks against Byzantine attacks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "allenzhu|byzantineresilient_nonconvex_stochastic_gradient_descent", "pdf": "/pdf/2379eb6b69ea25e47b9d640e34e7a22a97b2dd5a.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nallen-zhu2021byzantineresilient,\ntitle={Byzantine-Resilient Non-Convex Stochastic Gradient Descent},\nauthor={Zeyuan Allen-Zhu and Faeze Ebrahimianghazani and Jerry Li and Dan Alistarh},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=PbEHqvFtcS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "PbEHqvFtcS", "replyto": "PbEHqvFtcS", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2007/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538106052, "tmdate": 1606915763223, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2007/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2007/-/Official_Review"}}}], "count": 11}