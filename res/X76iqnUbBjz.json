{"notes": [{"id": "X76iqnUbBjz", "original": "oJRKqrRxxT4", "number": 273, "cdate": 1601308038424, "ddate": null, "tcdate": 1601308038424, "tmdate": 1615990912077, "tddate": null, "forum": "X76iqnUbBjz", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "A Unified Approach to Interpreting and Boosting Adversarial Transferability", "authorids": ["~Xin_Wang25", "~Jie_Ren1", "~Shuyun_Lin1", "~Xiangming_Zhu2", "~Yisen_Wang1", "~Quanshi_Zhang1"], "authors": ["Xin Wang", "Jie Ren", "Shuyun Lin", "Xiangming Zhu", "Yisen Wang", "Quanshi Zhang"], "keywords": ["Adversarial Learning", "Interpretability", "Adversarial Transferability"], "abstract": "In this paper, we use the interaction inside adversarial perturbations to explain and boost the adversarial transferability. We discover and prove the negative correlation between the adversarial transferability and the interaction inside adversarial perturbations. The negative correlation is further verified through different DNNs with various inputs. Moreover, this negative correlation can be regarded as a unified perspective to understand current transferability-boosting methods. To this end, we prove that some classic methods of enhancing the transferability essentially decease interactions inside adversarial perturbations. Based on this, we propose to directly penalize interactions during the attacking process, which significantly improves the adversarial transferability. We will release the code when the paper is accepted.", "one-sentence_summary": "We prove the close relationship between the interaction and adversarial transferability, provide a unified explanation for previous transferability-boosting methods, and develop a loss to improve adversarial transferability.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wang|a_unified_approach_to_interpreting_and_boosting_adversarial_transferability", "pdf": "/pdf/92ba2b486ce85a52e017691c5f53af8699796288.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nwang2021a,\ntitle={A Unified Approach to Interpreting and Boosting Adversarial Transferability},\nauthor={Xin Wang and Jie Ren and Shuyun Lin and Xiangming Zhu and Yisen Wang and Quanshi Zhang},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=X76iqnUbBjz}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 14, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "raXreyvy1kl", "original": null, "number": 1, "cdate": 1610040456064, "ddate": null, "tcdate": 1610040456064, "tmdate": 1610474058732, "tddate": null, "forum": "X76iqnUbBjz", "replyto": "X76iqnUbBjz", "invitation": "ICLR.cc/2021/Conference/Paper273/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Poster)", "comment": "This work provides interesting insights on the transferability of adversarial perturbations and proposes ways of making it more effective. While several reviewers have found parts of the paper unsatisfactory, there are interesting results to merit acceptance."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Unified Approach to Interpreting and Boosting Adversarial Transferability", "authorids": ["~Xin_Wang25", "~Jie_Ren1", "~Shuyun_Lin1", "~Xiangming_Zhu2", "~Yisen_Wang1", "~Quanshi_Zhang1"], "authors": ["Xin Wang", "Jie Ren", "Shuyun Lin", "Xiangming Zhu", "Yisen Wang", "Quanshi Zhang"], "keywords": ["Adversarial Learning", "Interpretability", "Adversarial Transferability"], "abstract": "In this paper, we use the interaction inside adversarial perturbations to explain and boost the adversarial transferability. We discover and prove the negative correlation between the adversarial transferability and the interaction inside adversarial perturbations. The negative correlation is further verified through different DNNs with various inputs. Moreover, this negative correlation can be regarded as a unified perspective to understand current transferability-boosting methods. To this end, we prove that some classic methods of enhancing the transferability essentially decease interactions inside adversarial perturbations. Based on this, we propose to directly penalize interactions during the attacking process, which significantly improves the adversarial transferability. We will release the code when the paper is accepted.", "one-sentence_summary": "We prove the close relationship between the interaction and adversarial transferability, provide a unified explanation for previous transferability-boosting methods, and develop a loss to improve adversarial transferability.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wang|a_unified_approach_to_interpreting_and_boosting_adversarial_transferability", "pdf": "/pdf/92ba2b486ce85a52e017691c5f53af8699796288.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nwang2021a,\ntitle={A Unified Approach to Interpreting and Boosting Adversarial Transferability},\nauthor={Xin Wang and Jie Ren and Shuyun Lin and Xiangming Zhu and Yisen Wang and Quanshi Zhang},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=X76iqnUbBjz}\n}"}, "tags": [], "invitation": {"reply": {"forum": "X76iqnUbBjz", "replyto": "X76iqnUbBjz", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040456051, "tmdate": 1610474058716, "id": "ICLR.cc/2021/Conference/Paper273/-/Decision"}}}, {"id": "_hUvpzxP2ul", "original": null, "number": 10, "cdate": 1605808898607, "ddate": null, "tcdate": 1605808898607, "tmdate": 1605961812095, "tddate": null, "forum": "X76iqnUbBjz", "replyto": "vD5zjFL1zp", "invitation": "ICLR.cc/2021/Conference/Paper273/-/Official_Comment", "content": {"title": "Responses to Reviewer #4 (Part 3)", "comment": "Q9: **About the range of $\\lambda$.** \"But in Figure 3, part a, the range of $\\lambda$ is from 0 to 1.2 for DN121, which does not include the $\\lambda$ value the authors suggested.\"\n\nA: We have followed your suggestions to conduct **new experiments** to test the effects of the larger $\\lambda$ value. Experimental results show that the large $\\lambda$ value usually exhibits high transferability. Please see Appendix P for details.\n- - -\nQ10: **About the time cost.** \"The computational cost is not discussed. As the authors said in Section 5 \"the computational cost of the IR loss is intolerable\u201d. No discussion about the running time is provided. Moreover, the authors choose the step to be 100, which further increases the running time.\"\n\nA: The complexity of the expectation of the interaction is actually linear. Moreover, we have followed your suggestions to conduct **new experiments** to analyze the running time of the IR attack. Please see Appendix J.3 for more details. On the setting of the step number, we have a detailed discussion in the answer to Q8.\n- - -\nQ11: \"The third line on page 5, the term $|\\delta|^p_p$ is wrong.\"\n\nA: A good question. In fact, this is a controversial issue in the adversarial attack. A typical case is the C&W attack (Carlini & Wagner, 2017). The C&W attack defined the attack in the thirteenth equation in the paper using the norm constraint as $|\\delta|_p$. However, the C&W method used the term of $|\\delta|^p_p$ when it implemented the attack. Please see Section VI.A in (Carlini & Wagner, 2017) for this. Therefore, we believe both $|\\delta|^p_p$ and $|\\delta|_p$ are reasonable regularization for the attack."}, "signatures": ["ICLR.cc/2021/Conference/Paper273/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper273/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Unified Approach to Interpreting and Boosting Adversarial Transferability", "authorids": ["~Xin_Wang25", "~Jie_Ren1", "~Shuyun_Lin1", "~Xiangming_Zhu2", "~Yisen_Wang1", "~Quanshi_Zhang1"], "authors": ["Xin Wang", "Jie Ren", "Shuyun Lin", "Xiangming Zhu", "Yisen Wang", "Quanshi Zhang"], "keywords": ["Adversarial Learning", "Interpretability", "Adversarial Transferability"], "abstract": "In this paper, we use the interaction inside adversarial perturbations to explain and boost the adversarial transferability. We discover and prove the negative correlation between the adversarial transferability and the interaction inside adversarial perturbations. The negative correlation is further verified through different DNNs with various inputs. Moreover, this negative correlation can be regarded as a unified perspective to understand current transferability-boosting methods. To this end, we prove that some classic methods of enhancing the transferability essentially decease interactions inside adversarial perturbations. Based on this, we propose to directly penalize interactions during the attacking process, which significantly improves the adversarial transferability. We will release the code when the paper is accepted.", "one-sentence_summary": "We prove the close relationship between the interaction and adversarial transferability, provide a unified explanation for previous transferability-boosting methods, and develop a loss to improve adversarial transferability.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wang|a_unified_approach_to_interpreting_and_boosting_adversarial_transferability", "pdf": "/pdf/92ba2b486ce85a52e017691c5f53af8699796288.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nwang2021a,\ntitle={A Unified Approach to Interpreting and Boosting Adversarial Transferability},\nauthor={Xin Wang and Jie Ren and Shuyun Lin and Xiangming Zhu and Yisen Wang and Quanshi Zhang},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=X76iqnUbBjz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "X76iqnUbBjz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper273/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper273/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper273/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper273/Authors|ICLR.cc/2021/Conference/Paper273/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper273/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923872815, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper273/-/Official_Comment"}}}, {"id": "claRl3KE1sn", "original": null, "number": 7, "cdate": 1605808463290, "ddate": null, "tcdate": 1605808463290, "tmdate": 1605961748865, "tddate": null, "forum": "X76iqnUbBjz", "replyto": "4Kk5Lqynsa", "invitation": "ICLR.cc/2021/Conference/Paper273/-/Official_Comment", "content": {"title": "Responses to Reviewer #2 (Part 3)", "comment": "Q5: **About the scalability.** \"According to the definition (Eqn. 3), the actual computation of the interaction is not very scalable when the set of players (\\Omega) is large. I think Eqn. 4 also lacks scalability because it is natural to think that the set of the adversarial perturbations is a continuous space.\"\n\nA: The review concerns two kinds of scalability of the interaction.\n\nFirst, **is the computational cost of the proposed IR loss unaffordable when the number of players is large?** To this end, we have proved in Eq. (4) that the computational complexity of the expectation of the interaction is linear, which is scalable. In fact, we do not directly compute interaction using Eq. (3). Instead, we compute the expectation of interactions with Eq. (4).\n\nIn addition, we have conducted a **new experiment**, in which the 100-step IR Attack on an ImageNet image is less than 50 seconds, which also prove the scalability of the interaction. Please see Appendix J.3 for details.\n\nSecond, **is the computational cost affordable when we consider the continuous space of adversarial perturbations?** It has been widely discussed (Ancona et al., 2019; Sundararajan & Najmi,2019) that when applying the Shapley value, the feature space is regarded as binary. It is because (Sundararajan & Najmi, 2019) has shown that only in the binary space, the Shapley value is the unique method to satisfy the *linearity axiom, the dummy axiom, the symmetry axiom, and the efficiency axiom*.  Thus, when we compute the interaction, the perturbation can be regarded in the binary space, i.e., whether the perturbation unit is added to the input or not, which enables scalability.\n- - -\nQ6: **About different settings of $\\lambda$.** \"In other words, I want to know when the tendency of Fig. 3 (a) converges to Fig. 3 (b) as $\\lambda$ goes higher.\"\n\nA: We have followed your suggestions to conduct **new experiments** to test the effects of the larger $\\lambda$ value. Experimental results show that the large $\\lambda$ value usually exhibits high transferability. Please see Appendix P for details.\n\n- - -\nQ7: **About readability.** \"Some of the arguments, especially propositions, are unnecessarily lengthy and hard to follow. To improve readability, I suggest clarifying the main points in the theoretical arguments. For example, please remove the redundant part 'Given an input image...' in Props. 1, 2 & 3 and make this statement as a proper Definition.\"\n\nA: We have followed your suggestion to polish the language of the propositions."}, "signatures": ["ICLR.cc/2021/Conference/Paper273/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper273/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Unified Approach to Interpreting and Boosting Adversarial Transferability", "authorids": ["~Xin_Wang25", "~Jie_Ren1", "~Shuyun_Lin1", "~Xiangming_Zhu2", "~Yisen_Wang1", "~Quanshi_Zhang1"], "authors": ["Xin Wang", "Jie Ren", "Shuyun Lin", "Xiangming Zhu", "Yisen Wang", "Quanshi Zhang"], "keywords": ["Adversarial Learning", "Interpretability", "Adversarial Transferability"], "abstract": "In this paper, we use the interaction inside adversarial perturbations to explain and boost the adversarial transferability. We discover and prove the negative correlation between the adversarial transferability and the interaction inside adversarial perturbations. The negative correlation is further verified through different DNNs with various inputs. Moreover, this negative correlation can be regarded as a unified perspective to understand current transferability-boosting methods. To this end, we prove that some classic methods of enhancing the transferability essentially decease interactions inside adversarial perturbations. Based on this, we propose to directly penalize interactions during the attacking process, which significantly improves the adversarial transferability. We will release the code when the paper is accepted.", "one-sentence_summary": "We prove the close relationship between the interaction and adversarial transferability, provide a unified explanation for previous transferability-boosting methods, and develop a loss to improve adversarial transferability.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wang|a_unified_approach_to_interpreting_and_boosting_adversarial_transferability", "pdf": "/pdf/92ba2b486ce85a52e017691c5f53af8699796288.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nwang2021a,\ntitle={A Unified Approach to Interpreting and Boosting Adversarial Transferability},\nauthor={Xin Wang and Jie Ren and Shuyun Lin and Xiangming Zhu and Yisen Wang and Quanshi Zhang},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=X76iqnUbBjz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "X76iqnUbBjz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper273/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper273/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper273/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper273/Authors|ICLR.cc/2021/Conference/Paper273/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper273/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923872815, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper273/-/Official_Comment"}}}, {"id": "pfC-1umOPNZ", "original": null, "number": 2, "cdate": 1605807689899, "ddate": null, "tcdate": 1605807689899, "tmdate": 1605961657110, "tddate": null, "forum": "X76iqnUbBjz", "replyto": "X76iqnUbBjz", "invitation": "ICLR.cc/2021/Conference/Paper273/-/Official_Comment", "content": {"title": "Summary of Changes", "comment": "We would like to thank all the reviewers for their careful reviews and valuable comments. Based on reviewers' feedback, we have updated the paper, with the following revisions:\n1. We have conducted a new experiment, in which we used different random samplings of grids or different initial perturbations to compute the variance. Please see Tables 1-4 for details.\n2. We have conducted a new experiment using the MI+IR attack, in order to further demonstrate the effectiveness of the IR loss. Experimental results have shown that the IR loss further enhanced the performance of the MI attack. Please see Table 7 and Appendix N.1 for details.\n3. We have conducted a new experiment using the VR+IR attack, in order to further demonstrate the effectiveness of the IR loss. Experimental results have shown that the IR loss further enhanced the performance of the VR attack. Please see Table 9 and Appendix N.1 for details.\n4. We have conducted a new experiment, in which we conducted targeted attacks on the CIFAR-10 dataset. Please see Table 10 and Appendix N.3 for details.\n5. We have conducted a new experiment on the ensemble source model, in which we added three additional DNNs as target DNNs. Please see Table 2 and the \"Experiments\" paragraph in Section 5 for details.\n6. We have conducted a new experiment about the computational cost. We measured the time cost of generating perturbations using the IR Attack in Table 6. It shows that the IR Attack was computationally applicable to high-dimensional data and deep neural networks. Please see Table 6 and Appendix J.3 for details.\n7. We have conducted a new experiment, in which we measured the interaction inside adversarial perturbations that were generated by the DI attack and the TI attack, respectively. We demonstrated that the DI and the TI attack both reduced interactions. Please see Table 11 and Appendix O for details.\n8. We have conducted a new experiment in order to test the effects of different $\\lambda$ values. Please see Appendix P for details.\n9. We have revised the paper to use the formal name \"Shapley interaction index\" to term the interaction used in our paper.\n10. We have added more discussions about related works on interactions. Please see the \"Interaction\" paragraph of Section 2 for details.\n11. We have added a paragraph to explain the enhancement of the adversarial transferability caused by the proposed IR loss. Please see the last paragraph on Page 8.\n12. We have revised Tables 1-2 by replacing the term \"Baseline\" of $L_\\infty$ attacks and $L_2$ attacks by \"PGD $L_\\infty$\" and \"PGD $L_2$\" for clarification, respectively. Similarly, we have renamed \"IR Attack\" of $L_\\infty$ attacks and $L_2$ attacks by \"PGD $L_\\infty$+IR\" and \"PGD $L_2$+IR\" for clarification, respectively.\n13. We have added a subsection \"Motivation\" within Appendix A to clarify the motivations of using the Shapley interaction index to define the interaction. Please see Appendix A.2 for details.\n14. We have added some paragraphs in Appendix N.1 to introduce the implementation details of the VR+IR Attack. Please see the second and third paragraphs in Appendix N.1 for details.\n15. We have fixed the reference format problem of Figure 4 and Figure 7 in the Appendix.\n16. We have reorganized the Appendix to improve the readability. We have merged the previous sections Appendix G and Appendix I into Appendix J in this version for better presentation.\n17. We have added a subsection \"scalability of the interaction loss\" within Appendix J to discuss two kinds of scalability of the proposed IR loss. Please see Appendix J.3 for details.\n18. We have polished the language according to suggestions from the reviewer. We have also cited and discussed several new related studies, which were mentioned by reviewers, in the related work section.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper273/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper273/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Unified Approach to Interpreting and Boosting Adversarial Transferability", "authorids": ["~Xin_Wang25", "~Jie_Ren1", "~Shuyun_Lin1", "~Xiangming_Zhu2", "~Yisen_Wang1", "~Quanshi_Zhang1"], "authors": ["Xin Wang", "Jie Ren", "Shuyun Lin", "Xiangming Zhu", "Yisen Wang", "Quanshi Zhang"], "keywords": ["Adversarial Learning", "Interpretability", "Adversarial Transferability"], "abstract": "In this paper, we use the interaction inside adversarial perturbations to explain and boost the adversarial transferability. We discover and prove the negative correlation between the adversarial transferability and the interaction inside adversarial perturbations. The negative correlation is further verified through different DNNs with various inputs. Moreover, this negative correlation can be regarded as a unified perspective to understand current transferability-boosting methods. To this end, we prove that some classic methods of enhancing the transferability essentially decease interactions inside adversarial perturbations. Based on this, we propose to directly penalize interactions during the attacking process, which significantly improves the adversarial transferability. We will release the code when the paper is accepted.", "one-sentence_summary": "We prove the close relationship between the interaction and adversarial transferability, provide a unified explanation for previous transferability-boosting methods, and develop a loss to improve adversarial transferability.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wang|a_unified_approach_to_interpreting_and_boosting_adversarial_transferability", "pdf": "/pdf/92ba2b486ce85a52e017691c5f53af8699796288.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nwang2021a,\ntitle={A Unified Approach to Interpreting and Boosting Adversarial Transferability},\nauthor={Xin Wang and Jie Ren and Shuyun Lin and Xiangming Zhu and Yisen Wang and Quanshi Zhang},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=X76iqnUbBjz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "X76iqnUbBjz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper273/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper273/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper273/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper273/Authors|ICLR.cc/2021/Conference/Paper273/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper273/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923872815, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper273/-/Official_Comment"}}}, {"id": "TLJkcS4Dp4", "original": null, "number": 9, "cdate": 1605808845196, "ddate": null, "tcdate": 1605808845196, "tmdate": 1605808845196, "tddate": null, "forum": "X76iqnUbBjz", "replyto": "vD5zjFL1zp", "invitation": "ICLR.cc/2021/Conference/Paper273/-/Official_Comment", "content": {"title": "Responses to Reviewer #4 (Part 2)", "comment": "Q6: **Justify more transferability-boosting methods reduce interactions:** \"The authors claim to provide a unified view to understand the enhancement of transferability; however the authors only explain three baseline models. Other types of adversarial example generation methods are not considered, such as Translation-Invariant Attack that the authors already mentioned in the related work. What is more, the Translation-Invariant Attack aims to compose the gradients of neighboring pixels together, which is contradictory to the authors\u2019 idea of reducing the interaction of perturbations.\"\n\nA: We have conducted **new experiments** to empirically demonstrate that DI and TI, which enhance the adversarial transferability, actually reduce interactions. Please see Appendix O Table 12 for details.\n\nBesides, for the theoretical proof, we have theoretically analyzed the MI, VRA, SGM. However, for other methods of improving adversarial transferability, such as Diversity Input (Xie, et al., 2019), which uses random data augmentation during attacking, it is difficult to mathematically prove that they essentially reduce interactions. As for Translation-Invariant Attack, it composes the gradients of neighboring pixels together, which can be regarded as to smooth the gradient. Intuitively, the effect is similar to Variance-Reduced Attack, which decreases the interaction.\n\n----\nQ7: \"From the experiment results in Table 1, why the performance of the IR attack is worse than the baseline when attacking RN-152 and DN-201 in the ensemble setting?\"\n\nA: A good question. It is mainly due to the model similarity between the source DNN and the target DNN. Particularly, our ensemble model is RN-34+RN-152+DN-121, so when the target model is RN-152, it is actually a white-box setting, instead of being a black-box. Therefore, the IR attack may be worse than the baseline.\n\nMoreover, we have conducted **new experiments** using three other target DNNs with different architectures from RNs or DNs, and updated the results to Table 2. Please see Table 2 for details. As Table 2 shows, perturbations generated on the ensemble model by IR attack were actually more transferable.\n- - -\nQ8: **About experimental settings.** \"In Section 5, Experiments, baselines: \"the transferability of each baseline was computed based on the best adversarial perturbation during the 100 steps\u2026\u201d and you also mention that \"Previous studies usually set the number of steps to 10 or 20\u201d. I am confused about why you set the step to be 100? For a fair comparison, you should follow the setting in previous studies.\"\n\nA: A good question. The fairness of comparisons is just the right motivation for us to evaluate the transferability using a leave-one-out strategy. To this end, our experimental settings ensure more fairness of comparisons than previous studies.\n\nFirst, the unfairness of using a fixed step number (such as 10 or 20 steps) for comparison in previous studies has been illustrated in Figure 7. As Figure 7 in Appendix K shows, the best transferability may be achieved in an intermediate step, rather than in the last step. If we set the number of steps to 20, it would be unfair for the MI attack, which achieves the best transferability in about the 10-th step. Please see Appendix K for details. This is a typical problem in adversarial examples. Previous studies[1] also discuss a similar issue that happened in adversarial training.\n\nTherefore, to enable fair comparisons, we do not directly use perturbations after 100 steps for evaluation. Instead, we use the leave-one-out evaluation, which automatically searches the best step in 100 steps.\n\nIn addition, setting a fixed step number also has other problems in implementation. It is because previous studies do not have unified settings of hyper-parameters, which significantly boosts the difficulty for fair comparisons. For example, in the MI attack, the number of steps is set to 10 (with step size set to 1.6/255), while in the VR attack, the number of steps is 5 (with step size set to 4/255). Therefore, it is unfair to directly compare the MI attack with the VR attack, when we require them to optimize the perturbation for 10 steps.\n\n[1] Rice, Leslie, Eric Wong, and J. Zico Kolter. \"Overfitting in adversarially robust deep learning.\" arXiv preprint arXiv:2002.11569 (2020)."}, "signatures": ["ICLR.cc/2021/Conference/Paper273/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper273/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Unified Approach to Interpreting and Boosting Adversarial Transferability", "authorids": ["~Xin_Wang25", "~Jie_Ren1", "~Shuyun_Lin1", "~Xiangming_Zhu2", "~Yisen_Wang1", "~Quanshi_Zhang1"], "authors": ["Xin Wang", "Jie Ren", "Shuyun Lin", "Xiangming Zhu", "Yisen Wang", "Quanshi Zhang"], "keywords": ["Adversarial Learning", "Interpretability", "Adversarial Transferability"], "abstract": "In this paper, we use the interaction inside adversarial perturbations to explain and boost the adversarial transferability. We discover and prove the negative correlation between the adversarial transferability and the interaction inside adversarial perturbations. The negative correlation is further verified through different DNNs with various inputs. Moreover, this negative correlation can be regarded as a unified perspective to understand current transferability-boosting methods. To this end, we prove that some classic methods of enhancing the transferability essentially decease interactions inside adversarial perturbations. Based on this, we propose to directly penalize interactions during the attacking process, which significantly improves the adversarial transferability. We will release the code when the paper is accepted.", "one-sentence_summary": "We prove the close relationship between the interaction and adversarial transferability, provide a unified explanation for previous transferability-boosting methods, and develop a loss to improve adversarial transferability.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wang|a_unified_approach_to_interpreting_and_boosting_adversarial_transferability", "pdf": "/pdf/92ba2b486ce85a52e017691c5f53af8699796288.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nwang2021a,\ntitle={A Unified Approach to Interpreting and Boosting Adversarial Transferability},\nauthor={Xin Wang and Jie Ren and Shuyun Lin and Xiangming Zhu and Yisen Wang and Quanshi Zhang},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=X76iqnUbBjz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "X76iqnUbBjz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper273/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper273/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper273/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper273/Authors|ICLR.cc/2021/Conference/Paper273/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper273/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923872815, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper273/-/Official_Comment"}}}, {"id": "OjbrE7Snk-N", "original": null, "number": 8, "cdate": 1605808645680, "ddate": null, "tcdate": 1605808645680, "tmdate": 1605808680042, "tddate": null, "forum": "X76iqnUbBjz", "replyto": "vD5zjFL1zp", "invitation": "ICLR.cc/2021/Conference/Paper273/-/Official_Comment", "content": {"title": "Responses to Reviewer #4 (Part 1)", "comment": "Thank you very much for your careful review and constructive comments. We try our best to answer all your concerns.\n\nQ1: \"Results are reported only on one dataset (ImageNet)\"\n\nA: Thank you. We have followed your suggestions to conduct **new experiments** on the CIFAR-10 dataset. Experimental results also proved that the adversarial transferability could be enhanced via reducing interactions. Please see Table 11 in Appendix N.3 for details.\n- - -\nQ2: **About paper writing.** \"The appendix needs to be revised for better presentation. There is some problem with the reference format about Figure 4 and Figure 7. I also suggest reorganizing the appendix.\"\n\nA: Thank you for your careful review. We have followed your suggestion to revise the appendix. We fix the reference format problem of Figure 4 and Figure 7 in the appendix. We merge previous sections Appendix G and Appendix I into Appendix J in this version for better presentation.\n- - -\nQ3: \"The variances of the results are not reported.\"\n\nA: We have followed your suggestions to conduct **new experiments** with different random samplings of grids or different initial perturbations to compute the variance. The variance is reported in Tables 1-4.\n- - -\nQ4: \"There are many outliers off the blue shade in the subgraph of Figure 1. Could the authors give some interpretation of why there are so many outliers?\"\n\nA: Although the negative relation has been verified in Figure 1, there are still noises in the data and some randomness in the optimization process. Nevertheless, as Figure 1 reports (see the upper right of each subfigure), the correlation coefficient shows that adversarial transferability and interaction have a strong negative relation.\n- - -\nQ5: **Optimizing interaction contradicts idea of one-pixel attack.** \"For Equation 4, the value of the expected interactions is equivalent to the expectation of the contribution for each pixel. The authors aim to minimize the value of the expected interactions that is the same to average the contribution to all pixels. That may contradict the idea of the one-pixel attack. More interpretation should be given to understand the concept of interactions.\"\n\nA: Good questions.\n* **Responses to whether the expectation of interactions is equivalent to the expectation of the contribution:** Sorry for the confusion, but according to Eq. (13), the expectation of interactions is **NOT** equivalent to the expectation of the contribution. As Eq.(13) shows, the interaction between perturbation units $i, j$ can be written as the difference of contributions of $i$-th unit's contribution $\\phi_i$,  when the $j$-th unit is perturbed *w.r.t* the case when the $j$-th unit is not perturbed. According to *the efficiency axiom* of the Shapley value (please see Appendix A for details), the expected contribution to all pixels is $\\frac{1}{n}(v(\\Omega)-v(\\emptyset)$), which is not equal to the value of the expected interaction in the Eq.(4).\n\n* **Responses to whether our research conflicts with the one-pixel attack:** Our method does not conflict with one-pixel attack. More specifically, the contribution of each pixel $\\phi(i \\mid \\Omega)$ can be decomposed as\n\n$$\n\\phi(i \\mid \\Omega)=v(\\{i\\})-v(\\emptyset)+\\left[E_{j \\in \\Omega \\backslash\\{i\\}}\\sum_{s=0}^{n-2}\\left[\\frac{n-1-s}{n} E_{|S|=s, S \\subseteq \\Omega \\backslash\\{i, j\\}}[v(S \\cup\\{i, j\\})-v(S \\cup\\{i\\})-v(S \\cup\\{j\\})+v(S)]\\right]\\right]\n$$\n\nThis does not conflict with the one-pixel attack. It is because the overall contribution of each pixel consists of two terms, (1) the pixel-wise attribution without interactions, i.e., $v(\\{i\\})-v(\\emptyset)$, and (2) pixel-wise interactions, i.e. $\\left[E_{j \\in \\Omega \\backslash\\{i\\}}\\sum_{s=0}^{n-2}\\left[\\frac{n-1-s}{n} E_{|S|=s, S \\subseteq \\Omega \\backslash\\{i, j\\}}[v(S \\cup\\{i, j\\})-v(S \\cup\\{i\\})-v(S \\cup\\{j\\})+v(S)]\\right]\\right]$. To this end, the one pixel-attack is mainly caused by the pixel-wise attributions without interactions.\n\n\n* **Responses to \"more interpretation\":** The psychical meaning of interactions can be understood as the collaborative behaviors of perturbation units that make themselves important in the attack. Please see the last paragraph on Page 3 for details."}, "signatures": ["ICLR.cc/2021/Conference/Paper273/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper273/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Unified Approach to Interpreting and Boosting Adversarial Transferability", "authorids": ["~Xin_Wang25", "~Jie_Ren1", "~Shuyun_Lin1", "~Xiangming_Zhu2", "~Yisen_Wang1", "~Quanshi_Zhang1"], "authors": ["Xin Wang", "Jie Ren", "Shuyun Lin", "Xiangming Zhu", "Yisen Wang", "Quanshi Zhang"], "keywords": ["Adversarial Learning", "Interpretability", "Adversarial Transferability"], "abstract": "In this paper, we use the interaction inside adversarial perturbations to explain and boost the adversarial transferability. We discover and prove the negative correlation between the adversarial transferability and the interaction inside adversarial perturbations. The negative correlation is further verified through different DNNs with various inputs. Moreover, this negative correlation can be regarded as a unified perspective to understand current transferability-boosting methods. To this end, we prove that some classic methods of enhancing the transferability essentially decease interactions inside adversarial perturbations. Based on this, we propose to directly penalize interactions during the attacking process, which significantly improves the adversarial transferability. We will release the code when the paper is accepted.", "one-sentence_summary": "We prove the close relationship between the interaction and adversarial transferability, provide a unified explanation for previous transferability-boosting methods, and develop a loss to improve adversarial transferability.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wang|a_unified_approach_to_interpreting_and_boosting_adversarial_transferability", "pdf": "/pdf/92ba2b486ce85a52e017691c5f53af8699796288.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nwang2021a,\ntitle={A Unified Approach to Interpreting and Boosting Adversarial Transferability},\nauthor={Xin Wang and Jie Ren and Shuyun Lin and Xiangming Zhu and Yisen Wang and Quanshi Zhang},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=X76iqnUbBjz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "X76iqnUbBjz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper273/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper273/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper273/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper273/Authors|ICLR.cc/2021/Conference/Paper273/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper273/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923872815, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper273/-/Official_Comment"}}}, {"id": "jzczpIfZuA", "original": null, "number": 6, "cdate": 1605808355069, "ddate": null, "tcdate": 1605808355069, "tmdate": 1605808355069, "tddate": null, "forum": "X76iqnUbBjz", "replyto": "4Kk5Lqynsa", "invitation": "ICLR.cc/2021/Conference/Paper273/-/Official_Comment", "content": {"title": "Response to Reviewer #2 (Part 2)", "comment": "Q3.1: \"Unfortunately, I feel this work is reluctant to compare the IR method with the State-of-the-Art methods.\"\n\nQ3.2: \"Lack of qualitative benefits of directly reducing the interaction based on the game theory.\"\n\nQ3.3: \"In Table 3, why is the result of (vanilla) IR Attack not reported? My concern is whether solely applying the IR attacking method has a clear contribution to be accepted in this conference. Please describe how IR attack (using only Eqn. 5) will perform compared to the SGM attacking method, which seems to be one of the State-of-the-Art.\"\n\nQ3.4: \"Why are the results of MI, VR, SGM methods not presented in Table 1?\"\n\nAnswers to Q3.1-Q3.4: The above questions concern the comparisons between the IR loss and other methods.\n\nFirst, we have followed your suggestions to conduct **new experiments**, in order to explore the qualitative benefits of using the IR loss compared with state-of-the-art methods. In new experiments, we use the IR loss to boost the performance of the four baselines, including the MI, VR, TI, and SGM. Experimental results show that the IR loss successfully boosts the performance. Please see Table 3 in Section 5 and Table 7-9 in Appendix N.1 for details.\n\nSecond, another issue about above experiments is whether the IR loss itself is powerful enough to compete with other methods (which also decrease interactions). Crucially, we have proved that all baselines, including the MI, VR, SGM attacks decrease the interaction in Section 4. Therefore, the comparison with the MI, VR, and SGM methods can just prove the optimization efficiency of decreasing the interaction, instead of examining whether the interaction reduction can boost the adversarial transferability.\n\n**To this end, although our proposed IR loss has achieved superior performance, strictly speaking, a good metric is not necessarily equivalent to a good loss of boosting adversarial transferability.** For example, the IOU metric is a standard metric to evaluate the detection accuracy, but it usually is not used as a loss function. Besides a good metric, the computation of transferable perturbations should also overcome the optimization problem (e.g., the local minimum of the interaction-decreasing task), which presents significant challenges to state-of-the-art methods. To this end, previous studies such as MI, VRA, SGM use various ways to optimize the interaction-decreasing problem. Therefore, we use the proposed IR loss to further boost the performance of existing transferability-boosting methods, which has successfully verified the negative correlation between adversarial transferability and interactions. Please see Tables 1-4 and Tables 7-9 for details.\n\nWe can understand the behaviors of the proposed IR loss as follows. Different methods generate adversarial perturbations in different manifolds, thereby exhibiting different transferability. Based on the current perturbation, the IR loss can point out the optimization direction towards the further decrease of interactions in a local manner due to its optimization power. Thus, the IR loss further boosts the transferability.\n\nWe have added the discussion about the behaviors of the proposed IR loss on the last paragraph of Page 8.\n- - -\nQ4: **About the relationship between Proposition 1 and the negative correlation.** \"As far as I understand from Proposition 1, it says that 'multi-step attacks generate more interaction than single-step attacks.' Please elaborate that this statement can be generalized to the following: 'the adversarial transferability and the interactions inside adversarial perturbations are negatively correlated'.\"\n\nA: A good question. Both Proposition 1 and the finding in (Xie et al. 2019) are the backgrounds of the hypothesis that \"the adversarial transferability and the interactions inside adversarial perturbations are negatively correlated.\" Specifically, Xie et al. (2019) find that multi-step attacks tend to exhibit lower transferability than single-step attacks. Moreover, Proposition 1 shows that multi-step attacks generate more interactions than single-step attacks. These two statements are the motivation for us to propose the hypothesis that \"the adversarial transferability and the interactions inside adversarial perturbations are negatively correlated.\" Please see the second paragraph under Proposition 1 on page 4 for details. This hypothesis has been verified from three perspectives.\n* We have conducted experiments to compute the transfer utility and the interaction of adversarial perturbations over different DNNs. Figure 1 shows the negative correlation between the transfer utility and the interaction.\n* We have theoretically proved that three classic transferability-boosting methods essentially decrease interactions between perturbation units. Please see Section 4 for details.\n* Experiments have shown that the proposed IR loss can boost the transferability of the PGD, MI, SGM, VR, and TI attacks. Please see Tables 1-4 and Tables 7-9 for details."}, "signatures": ["ICLR.cc/2021/Conference/Paper273/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper273/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Unified Approach to Interpreting and Boosting Adversarial Transferability", "authorids": ["~Xin_Wang25", "~Jie_Ren1", "~Shuyun_Lin1", "~Xiangming_Zhu2", "~Yisen_Wang1", "~Quanshi_Zhang1"], "authors": ["Xin Wang", "Jie Ren", "Shuyun Lin", "Xiangming Zhu", "Yisen Wang", "Quanshi Zhang"], "keywords": ["Adversarial Learning", "Interpretability", "Adversarial Transferability"], "abstract": "In this paper, we use the interaction inside adversarial perturbations to explain and boost the adversarial transferability. We discover and prove the negative correlation between the adversarial transferability and the interaction inside adversarial perturbations. The negative correlation is further verified through different DNNs with various inputs. Moreover, this negative correlation can be regarded as a unified perspective to understand current transferability-boosting methods. To this end, we prove that some classic methods of enhancing the transferability essentially decease interactions inside adversarial perturbations. Based on this, we propose to directly penalize interactions during the attacking process, which significantly improves the adversarial transferability. We will release the code when the paper is accepted.", "one-sentence_summary": "We prove the close relationship between the interaction and adversarial transferability, provide a unified explanation for previous transferability-boosting methods, and develop a loss to improve adversarial transferability.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wang|a_unified_approach_to_interpreting_and_boosting_adversarial_transferability", "pdf": "/pdf/92ba2b486ce85a52e017691c5f53af8699796288.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nwang2021a,\ntitle={A Unified Approach to Interpreting and Boosting Adversarial Transferability},\nauthor={Xin Wang and Jie Ren and Shuyun Lin and Xiangming Zhu and Yisen Wang and Quanshi Zhang},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=X76iqnUbBjz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "X76iqnUbBjz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper273/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper273/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper273/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper273/Authors|ICLR.cc/2021/Conference/Paper273/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper273/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923872815, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper273/-/Official_Comment"}}}, {"id": "zb99i5OowcM", "original": null, "number": 5, "cdate": 1605808028121, "ddate": null, "tcdate": 1605808028121, "tmdate": 1605808028121, "tddate": null, "forum": "X76iqnUbBjz", "replyto": "4Kk5Lqynsa", "invitation": "ICLR.cc/2021/Conference/Paper273/-/Official_Comment", "content": {"title": "Responses to Reviewer #2 (`Part 1)", "comment": "Thank you very much for your careful review and constructive comments. We try our best to answer all your concerns.\n\nQ1: **About experimental settings.** \"Although I am not sure about the exact settings that draw the numbers, the empirical results seem good.\"\n\nA: Experimental settings corresponding to results in Table 1-4 are introduced in the *Experiments* paragraph in Section 5. Let us take the $L_\\infty$ attack in Table 1 for example. We conduct 100-step untargeted attacks under $\\epsilon=16/255$ $L_\\infty$ norm constraint using 1000 images in the ImageNet dataset on a pretrained source DNN to generate adversarial examples. Then, we use the leave-one-out evaluation to measure the success rates of 1000 images generated on the source DNN.\n\nExperimental settings corresponding to results in Figure 1 are introduced on the last paragraph on Page 4 and the second paragraph in Appendix G. We gradually change the value of of $c$ in $\\min_\\delta -\\ell(h(x+\\delta), y) + c\\cdot \\|\\delta\\|^p_p \\; \\text{s.t.} \\; x+\\delta\\in[0, 1]^n$ to generate different adversarial examples on a source DNN. We require all adversarial attacks to generate perturbations with the same $L_2$ norm as the first adversarial attack. This is the stopping criteria for these adversarial attacks to ensure fair comparisons. Then, we measure the average interaction and the average transfer utility (on a target DNN) and draw each subfigure and report the Pearson correlation between the interaction and the transfer utility.\n\nQ2.1: \"However, bringing the game theory-based approach in this domain is quite unconventional. Hence, I strongly feel there should've been more theoretical arguments that strengthen the significance of this approach.\"\n\nQ2.2: \"Lack of a valid (theoretical) reason for the negative correlation.\"\n\nA: First, the theoretical proof serves as an explanation and verification for the phenomena of the negative correlations observed in experiments. Although the proofs of propositions are based on certain assumptions, these propositions still support the negative correlation between the interaction and the adversarial transferability.\n\nSecond, Proposition 1 just serves as a strong motivation for us to propose the hypothesis of the negative correlation. Proposition 1 proves that the multi-step attack generates perturbations with larger interactions than the single-step attack. Xie et al. (2019) find that the multi-step attack tended to overfit and generate perturbations with lower transferability. Intuitively, large interactions mean a strong cooperative relationship between perturbation units, which indicates the significant over-fitting to the source DNN. Thus, this motivates us to propose the *hypothesis* that \"the adversarial transferability and the interactions inside adversarial perturbations are negatively correlated.\" Please see the second paragraph under Proposition 1 on page 4 for details.\n\nThird, we have proved that three state-of-the-art transferability-boosting attacks essentially decrease interactions. This further supports the negative correlation observed in experiments.\n\nFourth, we have verified the negative correlation from the other two perspectives, (1) we have conducted experiments to compute the transfer utility and the interaction of adversarial perturbations over different DNNs. Figure 1 shows the negative correlation between the transfer utility and the interaction; (2) Experiments have shown that the proposed IR loss can boost the transferability of PGD, MI, SGM, VR, and TI attacks. Please see Tables 1-4 and Tables 7-9 for details."}, "signatures": ["ICLR.cc/2021/Conference/Paper273/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper273/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Unified Approach to Interpreting and Boosting Adversarial Transferability", "authorids": ["~Xin_Wang25", "~Jie_Ren1", "~Shuyun_Lin1", "~Xiangming_Zhu2", "~Yisen_Wang1", "~Quanshi_Zhang1"], "authors": ["Xin Wang", "Jie Ren", "Shuyun Lin", "Xiangming Zhu", "Yisen Wang", "Quanshi Zhang"], "keywords": ["Adversarial Learning", "Interpretability", "Adversarial Transferability"], "abstract": "In this paper, we use the interaction inside adversarial perturbations to explain and boost the adversarial transferability. We discover and prove the negative correlation between the adversarial transferability and the interaction inside adversarial perturbations. The negative correlation is further verified through different DNNs with various inputs. Moreover, this negative correlation can be regarded as a unified perspective to understand current transferability-boosting methods. To this end, we prove that some classic methods of enhancing the transferability essentially decease interactions inside adversarial perturbations. Based on this, we propose to directly penalize interactions during the attacking process, which significantly improves the adversarial transferability. We will release the code when the paper is accepted.", "one-sentence_summary": "We prove the close relationship between the interaction and adversarial transferability, provide a unified explanation for previous transferability-boosting methods, and develop a loss to improve adversarial transferability.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wang|a_unified_approach_to_interpreting_and_boosting_adversarial_transferability", "pdf": "/pdf/92ba2b486ce85a52e017691c5f53af8699796288.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nwang2021a,\ntitle={A Unified Approach to Interpreting and Boosting Adversarial Transferability},\nauthor={Xin Wang and Jie Ren and Shuyun Lin and Xiangming Zhu and Yisen Wang and Quanshi Zhang},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=X76iqnUbBjz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "X76iqnUbBjz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper273/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper273/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper273/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper273/Authors|ICLR.cc/2021/Conference/Paper273/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper273/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923872815, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper273/-/Official_Comment"}}}, {"id": "sh1YF2Pglwr", "original": null, "number": 4, "cdate": 1605807888852, "ddate": null, "tcdate": 1605807888852, "tmdate": 1605807888852, "tddate": null, "forum": "X76iqnUbBjz", "replyto": "6GzUTk847K", "invitation": "ICLR.cc/2021/Conference/Paper273/-/Official_Comment", "content": {"title": "Responses to Reviewer #1", "comment": "Thank you very much for your careful review and constructive comments. We try our best to answer all your concerns.\n\nQ1: **About the formal name of the interaction.** \"Only one comment about the definition of interaction scores. In some literature [Lundberg et al., 2019], it is called the Shapley interaction index.\"\n\nA: Thank you for your comments. First, yes, the interaction used in our paper is the Shapley interaction index, and we have clearly cited the corresponding paper (Michel & Marc, 1999) in Section 3.1. Second, we have revised the paper and used the formal name \"Shapley interaction index.\" Third, you have mentioned another paper that used the Shapley interaction index in the NLP task. We have added discussions about this paper in our related work to further point out the broad applicability of the Shapley interaction index."}, "signatures": ["ICLR.cc/2021/Conference/Paper273/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper273/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Unified Approach to Interpreting and Boosting Adversarial Transferability", "authorids": ["~Xin_Wang25", "~Jie_Ren1", "~Shuyun_Lin1", "~Xiangming_Zhu2", "~Yisen_Wang1", "~Quanshi_Zhang1"], "authors": ["Xin Wang", "Jie Ren", "Shuyun Lin", "Xiangming Zhu", "Yisen Wang", "Quanshi Zhang"], "keywords": ["Adversarial Learning", "Interpretability", "Adversarial Transferability"], "abstract": "In this paper, we use the interaction inside adversarial perturbations to explain and boost the adversarial transferability. We discover and prove the negative correlation between the adversarial transferability and the interaction inside adversarial perturbations. The negative correlation is further verified through different DNNs with various inputs. Moreover, this negative correlation can be regarded as a unified perspective to understand current transferability-boosting methods. To this end, we prove that some classic methods of enhancing the transferability essentially decease interactions inside adversarial perturbations. Based on this, we propose to directly penalize interactions during the attacking process, which significantly improves the adversarial transferability. We will release the code when the paper is accepted.", "one-sentence_summary": "We prove the close relationship between the interaction and adversarial transferability, provide a unified explanation for previous transferability-boosting methods, and develop a loss to improve adversarial transferability.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wang|a_unified_approach_to_interpreting_and_boosting_adversarial_transferability", "pdf": "/pdf/92ba2b486ce85a52e017691c5f53af8699796288.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nwang2021a,\ntitle={A Unified Approach to Interpreting and Boosting Adversarial Transferability},\nauthor={Xin Wang and Jie Ren and Shuyun Lin and Xiangming Zhu and Yisen Wang and Quanshi Zhang},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=X76iqnUbBjz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "X76iqnUbBjz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper273/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper273/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper273/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper273/Authors|ICLR.cc/2021/Conference/Paper273/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper273/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923872815, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper273/-/Official_Comment"}}}, {"id": "H7qgTdsVY92", "original": null, "number": 3, "cdate": 1605807823644, "ddate": null, "tcdate": 1605807823644, "tmdate": 1605807823644, "tddate": null, "forum": "X76iqnUbBjz", "replyto": "IaMI146e9hO", "invitation": "ICLR.cc/2021/Conference/Paper273/-/Official_Comment", "content": {"title": "Response to Reviewer #3", "comment": "Thank you very much for your careful review and constructive comments. We try our best to answer all your concerns.\n\nQ1: **About the motivation.** \"What is missing in the paper is the reason and motivation for using the Shapley values for defining the interaction.\"\n\nA: A good question. We have added reasons and motivations in Appendix A.2.\n1. **The interaction based on the Shapley value is theoretically rigorous.** We use the interaction defined based on the Shapley value, because the Shapley value has a solid theoretical foundation in the game theory, which is the *unique*  attribution satisfying four desirable axioms, i.e., *the linearity axiom, the dummy axiom, the symmetry axiom*, and *the efficiency axiom*.\n\n2. **The metric defined based on the Shapley value does not depend on network architectures.** Because adversarial transferability is a general property for the attack, a convincing metric for adversarial transferability is supposed not to be directly related to the network architecture. To this end, the computation of the interaction based on the Shapley value does not depend on the network architecture.\n\n3. **The computational cost of the Shapley-based interaction-reduction loss is relatively low.** Because of *the efficiency axiom* of the Shapley value, we prove that the time cost of computing the IR loss $\\ell_{interaction}=-\\frac{1}{n-1} \\mathbb{E}_{i}[v(\\Omega)-v(\\Omega \\backslash\\{i\\})-v(\\{i\\})+v(\\emptyset)]$ is linear, i.e., $O(n)$, where $n$ is the dimension of features. The linear complexity makes it possible to apply the interaction to high-dimensional data and deep neural networks.\n- - -\nQ2: \"No comparison and discussion is given the difference between their method and other methods that define the interaction between variables.\"\n\nA: A good question. We have added discussions about the difference between our method and other methods that define the interaction in Appendix A.2.\n\nDifferent metrics measure the interaction from different perspectives and represent different meanings. The interaction used in our paper measures the interaction between the units $i,j$ as the change of the $i$-th unit\u2019s importance when the unit $j$ exists *w.r.t* the case when the unit $j$ is absent. In comparison, Daria Sorokina (2008) defined the interaction of $K$ input variables of additive models. Tsang et al. (2018) measured statistical interactions based on DNN weights. Jin et al. (2020) quantified the contextual independence of words to hierarchically explain the LSTMs. This has been clarified in the related work section.\n\nIn addition, whether the interaction metric is computed based on the network architecture is a key difference between our metric and other interaction metrics. The computation of the interaction used in this paper does not depend on the network architecture. In comparison, previous definitions of the interaction are usually oriented to some specific model architectures. For example, the interaction proposed by Tsang et al. (2018) requires the DNN to be fully-connected. The interactions proposed by Murdoch et al. (2018) and Jin et al. (2020) are designed for LSTMs. The Hessian-based interaction (Janizek et al., 2020) requires the DNN to use the SoftPlus operation to replace the ReLU operation.\n\nFurthermore, the interaction used in our paper is defined based on the Shapley value, which is the *unique* attribution satisfying four desirable axioms, i.e., *the linearity axiom, the dummy axiom, the symmetry axiom*, and *the efficiency axiom*."}, "signatures": ["ICLR.cc/2021/Conference/Paper273/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper273/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Unified Approach to Interpreting and Boosting Adversarial Transferability", "authorids": ["~Xin_Wang25", "~Jie_Ren1", "~Shuyun_Lin1", "~Xiangming_Zhu2", "~Yisen_Wang1", "~Quanshi_Zhang1"], "authors": ["Xin Wang", "Jie Ren", "Shuyun Lin", "Xiangming Zhu", "Yisen Wang", "Quanshi Zhang"], "keywords": ["Adversarial Learning", "Interpretability", "Adversarial Transferability"], "abstract": "In this paper, we use the interaction inside adversarial perturbations to explain and boost the adversarial transferability. We discover and prove the negative correlation between the adversarial transferability and the interaction inside adversarial perturbations. The negative correlation is further verified through different DNNs with various inputs. Moreover, this negative correlation can be regarded as a unified perspective to understand current transferability-boosting methods. To this end, we prove that some classic methods of enhancing the transferability essentially decease interactions inside adversarial perturbations. Based on this, we propose to directly penalize interactions during the attacking process, which significantly improves the adversarial transferability. We will release the code when the paper is accepted.", "one-sentence_summary": "We prove the close relationship between the interaction and adversarial transferability, provide a unified explanation for previous transferability-boosting methods, and develop a loss to improve adversarial transferability.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wang|a_unified_approach_to_interpreting_and_boosting_adversarial_transferability", "pdf": "/pdf/92ba2b486ce85a52e017691c5f53af8699796288.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nwang2021a,\ntitle={A Unified Approach to Interpreting and Boosting Adversarial Transferability},\nauthor={Xin Wang and Jie Ren and Shuyun Lin and Xiangming Zhu and Yisen Wang and Quanshi Zhang},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=X76iqnUbBjz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "X76iqnUbBjz", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper273/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper273/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper273/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper273/Authors|ICLR.cc/2021/Conference/Paper273/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper273/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923872815, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper273/-/Official_Comment"}}}, {"id": "vD5zjFL1zp", "original": null, "number": 1, "cdate": 1603849125930, "ddate": null, "tcdate": 1603849125930, "tmdate": 1605024726493, "tddate": null, "forum": "X76iqnUbBjz", "replyto": "X76iqnUbBjz", "invitation": "ICLR.cc/2021/Conference/Paper273/-/Official_Review", "content": {"title": "Official Blind Review #4", "review": "Summary\nThe authors analyze the transferability of adversarial examples from the perspective of interactions based on game theory. They have discovered and shown  the negative correlation between the transferability and interactions inside adversarial perturbations. This discovery leads to an explanation of the adversarial transferability by the interaction inside adversarial perturbations. Thus, they proposed a new loss called interaction loss to penalize the interactions between perturbation units during attacking and experiments show the improvement of the adversarial transferability.\n\nStrengths\n1 An interesting understanding of adversarial transferability is provided.\n2 Mathematical proofs are admired.\n3 Results are very nicely presented, and writing is clear throughout the paper.\n\nWeaknesses\n1 Results are reported only on one dataset (ImageNet).\n2 The appendix needs to be revised for better presentation.\n3 The variances of the results are not reported.\n\nThis paper is well motivated because the authors observe the negative correlation between the transferability and interactions inside adversarial perturbations, and they provide a possible explanation of why the related research tasks  can improve the adversarial transferability. Further mathematical proofs and experiment results verify the observation. \n\nHowever, I have some questions about this paper.\n\nQuestions\n1.\tThere are many outliers off the blue shade in the subgraph of Figure 1. Could the authors give some interpretation of why there are so many outliers?\n\n2.\tFor Equation 4, the value of the expected interactions is equivalent to the expectation of the contribution for each pixel. The authors aim to minimize the value of the expected interactions that is the same to average the contribution to all pixels. That may contradict the idea of the one-pixel attack. More interpretation should be given to understand the concept of interactions.\n\n3.\tThe authors claim to provide a unified view to understand the enhancement of transferability; however the authors only explain three baseline models. Other types of adversarial example generation methods are not considered, such as Translation-Invariant Attack that the authors already mentioned in the related work. What is more, the Translation-Invariant Attack aims to compose the gradients of neighboring pixels together, which is contradictory to the authors\u2019 idea of reducing the interaction of perturbations.\n\t\n\n4.\tFrom the experiment results in Table 1, why the performance of the IR attack is worse than the baseline when attacking RN-152 and DN-201 in the ensemble setting?\n\n5.\tIn Section 5, Experiments, baselines: \u201cthe transferability of each baseline was computed based on the best adversarial perturbation during the 100 steps\u2026\u201d and you also mention that \u201cPrevious studies usually set the number of steps to 10 or 20\u201d. I am confused about why you set the step to be 100? For a fair comparison, you should follow the setting in previous studies.\n\n6.\tIn Section 5, Experiments, baselines: \u201cwe set $\\lambda = 1$ for the IR Attack, when the source DNN was ResNet, and set $\\lambda = 2$, for other source DNNs.\u201d, but in Figure 3, part a, the range of $\\lambda$ is from 0 to 1.2 for DN121, which does not include the \\lamda value the authors suggested. \n\n7.\tThe computational cost is not discussed. As the authors said in Section 5 \u201cthe computational cost of the interaction loss is intolerable\u201d. No discussion about the running time is provided. Moreover, the authors choose the step to be 100, which further increases the running time.\n\n8.\tThe third line on page 5, the term $|\\delta|_{p}^{p}$ is wrong. \n\n        It should be $|\\delta |_{p}$. \n\n9.\tAppendix: The is some problem with the reference format about Figure 4 and Figure 7. I also suggest reorganizing the appendix.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper273/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper273/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Unified Approach to Interpreting and Boosting Adversarial Transferability", "authorids": ["~Xin_Wang25", "~Jie_Ren1", "~Shuyun_Lin1", "~Xiangming_Zhu2", "~Yisen_Wang1", "~Quanshi_Zhang1"], "authors": ["Xin Wang", "Jie Ren", "Shuyun Lin", "Xiangming Zhu", "Yisen Wang", "Quanshi Zhang"], "keywords": ["Adversarial Learning", "Interpretability", "Adversarial Transferability"], "abstract": "In this paper, we use the interaction inside adversarial perturbations to explain and boost the adversarial transferability. We discover and prove the negative correlation between the adversarial transferability and the interaction inside adversarial perturbations. The negative correlation is further verified through different DNNs with various inputs. Moreover, this negative correlation can be regarded as a unified perspective to understand current transferability-boosting methods. To this end, we prove that some classic methods of enhancing the transferability essentially decease interactions inside adversarial perturbations. Based on this, we propose to directly penalize interactions during the attacking process, which significantly improves the adversarial transferability. We will release the code when the paper is accepted.", "one-sentence_summary": "We prove the close relationship between the interaction and adversarial transferability, provide a unified explanation for previous transferability-boosting methods, and develop a loss to improve adversarial transferability.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wang|a_unified_approach_to_interpreting_and_boosting_adversarial_transferability", "pdf": "/pdf/92ba2b486ce85a52e017691c5f53af8699796288.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nwang2021a,\ntitle={A Unified Approach to Interpreting and Boosting Adversarial Transferability},\nauthor={Xin Wang and Jie Ren and Shuyun Lin and Xiangming Zhu and Yisen Wang and Quanshi Zhang},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=X76iqnUbBjz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "X76iqnUbBjz", "replyto": "X76iqnUbBjz", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper273/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538146739, "tmdate": 1606915788371, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper273/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper273/-/Official_Review"}}}, {"id": "4Kk5Lqynsa", "original": null, "number": 2, "cdate": 1603852925009, "ddate": null, "tcdate": 1603852925009, "tmdate": 1605024726430, "tddate": null, "forum": "X76iqnUbBjz", "replyto": "X76iqnUbBjz", "invitation": "ICLR.cc/2021/Conference/Paper273/-/Official_Review", "content": {"title": "Review", "review": "The paper mainly deals with the negative correlation between adversarial transferability and the interaction inside adversarial perturbations. The authors claimed that utilizing the correlation can be regarded as a unified perspective to understand previously proposed methods. To this end, they presented an adversarial attacking loss, which can directly reduce the interaction, defined as the individual interaction between two perturbation units to the total reward function.\n\nThis paper provides an intriguing perspective that can explain adversarial attacking mechanisms. Although I am not sure about the exact settings that draw the numbers, the empirical results seem good; thus, reducing the interaction inside perturbations could be useful in practice. However, I cast doubt on the theoretical significance of the central hypothesis. This concern derives from lacking analyses on 1) a valid (theoretical) reason for the negative correlation, 2) qualitative benefits of directly reducing the interaction based on the game theory. \n\n[Quality]\n\nThe paper follows one solid logical structure aforementioned in Abstract and Introduction. However, I think Section 3 & 4 are confusing, which indeed are the core parts. For example, the propositions are overly verbose and hard to follow. Also, the theoretical statements and interpretations are not well aligned. I defer the detailed comments below.\n\n[Originality]\n\nThe originality of the paper is not outstanding, but sufficient for acceptance. \n\n[Significance]\n\nThe paper reveals one aspect of adversarial transferability for sure. However, bringing the game theory-based approach in this domain is quite unconventional. Hence, I strongly feel there should've been more theoretical arguments that strengthen the significance of this approach. I guess the authors' intention was to prove their claims empirically, and the paper provides some good results. Unfortunately, I feel this work is reluctant to compare the IR method with the State-of-the-Art methods (such as \"MI vs. vanilla IR,\" \"VR vs. vanilla IR,\" \"SGM vs. vanilla IR\").\n\n\n[Comments & Questions (sorted by priority)]\n1. As far as I understand from Proposition 1, it says that \"multi-step attacks generate more interaction than single-step attacks.\" Please elaborate that this statement can be generalized to the following: \"the adversarial transferability and the interactions inside adversarial perturbations are negatively correlated.\" \n2. In Table 3, why is the result of (vanilla) IR Attack not reported? The table shows that HyridIR, a combination of all techniques, achieves the best performance. Hence, it implies that reducing the interaction in multiple ways can be stacked for achieving good performance. However, the table does not show the success rate of the pure IR attacking method. My concern is whether solely applying the IR attacking method has a clear contribution to be accepted in this conference. Please describe how IR attack (using only Eqn. 5) will perform compared to the SGM attacking method, which seems to be one of the State-of-the-Art. \n3. According to the definition (Eqn. 3), the actual computation of the interaction is not very scalable when the set of players (\\Omega) is large. I think Eqn. 4 also lacks scalability because it is natural to think that the set of the adversarial perturbations is a continuous space.  \n4. Is high $\\lambda$ always effective? In Fig. 3, how the success rate changes when $\\lambda = 10^2, 10^3, \\dots$? In other words, I want to know when the tendency of Fig. 3 (a) converges to Fig. 3 (b) as $\\lambda$ goes higher.\n5. (Similar to #2) Why are the results of MI, VR, SGM methods not presented in Table 1?\n6. Some of the arguments, especially propositions, are unnecessarily lengthy and hard to follow. To improve readability, I suggest clarifying the main points in the theoretical arguments. For example, please remove the redundant part \"Given an input image $x \\in\\mathbb{R}^n$ ... $\\delta^m_{multi}), y)$.\" in Props. 1, 2 & 3 and make this statement as a proper Definition.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper273/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper273/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Unified Approach to Interpreting and Boosting Adversarial Transferability", "authorids": ["~Xin_Wang25", "~Jie_Ren1", "~Shuyun_Lin1", "~Xiangming_Zhu2", "~Yisen_Wang1", "~Quanshi_Zhang1"], "authors": ["Xin Wang", "Jie Ren", "Shuyun Lin", "Xiangming Zhu", "Yisen Wang", "Quanshi Zhang"], "keywords": ["Adversarial Learning", "Interpretability", "Adversarial Transferability"], "abstract": "In this paper, we use the interaction inside adversarial perturbations to explain and boost the adversarial transferability. We discover and prove the negative correlation between the adversarial transferability and the interaction inside adversarial perturbations. The negative correlation is further verified through different DNNs with various inputs. Moreover, this negative correlation can be regarded as a unified perspective to understand current transferability-boosting methods. To this end, we prove that some classic methods of enhancing the transferability essentially decease interactions inside adversarial perturbations. Based on this, we propose to directly penalize interactions during the attacking process, which significantly improves the adversarial transferability. We will release the code when the paper is accepted.", "one-sentence_summary": "We prove the close relationship between the interaction and adversarial transferability, provide a unified explanation for previous transferability-boosting methods, and develop a loss to improve adversarial transferability.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wang|a_unified_approach_to_interpreting_and_boosting_adversarial_transferability", "pdf": "/pdf/92ba2b486ce85a52e017691c5f53af8699796288.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nwang2021a,\ntitle={A Unified Approach to Interpreting and Boosting Adversarial Transferability},\nauthor={Xin Wang and Jie Ren and Shuyun Lin and Xiangming Zhu and Yisen Wang and Quanshi Zhang},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=X76iqnUbBjz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "X76iqnUbBjz", "replyto": "X76iqnUbBjz", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper273/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538146739, "tmdate": 1606915788371, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper273/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper273/-/Official_Review"}}}, {"id": "6GzUTk847K", "original": null, "number": 3, "cdate": 1603921705051, "ddate": null, "tcdate": 1603921705051, "tmdate": 1605024726362, "tddate": null, "forum": "X76iqnUbBjz", "replyto": "X76iqnUbBjz", "invitation": "ICLR.cc/2021/Conference/Paper273/-/Official_Review", "content": {"title": "Interesting work and solid analysis", "review": "This work proposes that the transferability of adversarial attacks has a negative correlation with the interaction within an input perturbation. By defining the interaction of perturbations with the Sharpley value, it can quantify the interactions and demonstrate the negative correlation with the transferability. Furthermore, this work shows that prior work on adversarial attacks (e.g., VR attack and MI attack) can be explained by the (expected) interaction scores. This work further demonstrates that the way of enhancing transferability by minimizing the interaction within input perturbations, with the experiments on the image classification task. \n\nOverall, I think this work provides a new perspective of understanding transferability and presents solid analysis/experiments to verify the hypothesis. \n\nOnly one comment about the definition of interaction scores. In some literature [Lundberg et al., 2019], it is called the Shapley interaction index, which uses the definition in equation (13) of Appendix D. Shapley interaction index has mainly been used in the machine learning literature recently for explaining feature interactions within models. E.g., \n\n1. Lundberg et al. Consistent Individualized Feature Attribution for Tree Ensembles. 2019\n2. Chen and Ji. Learning Variational Word Masks to Improve the Interpretability of Neural Text Classifiers. 2020\n", "rating": "10: Top 5% of accepted papers, seminal paper", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper273/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper273/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Unified Approach to Interpreting and Boosting Adversarial Transferability", "authorids": ["~Xin_Wang25", "~Jie_Ren1", "~Shuyun_Lin1", "~Xiangming_Zhu2", "~Yisen_Wang1", "~Quanshi_Zhang1"], "authors": ["Xin Wang", "Jie Ren", "Shuyun Lin", "Xiangming Zhu", "Yisen Wang", "Quanshi Zhang"], "keywords": ["Adversarial Learning", "Interpretability", "Adversarial Transferability"], "abstract": "In this paper, we use the interaction inside adversarial perturbations to explain and boost the adversarial transferability. We discover and prove the negative correlation between the adversarial transferability and the interaction inside adversarial perturbations. The negative correlation is further verified through different DNNs with various inputs. Moreover, this negative correlation can be regarded as a unified perspective to understand current transferability-boosting methods. To this end, we prove that some classic methods of enhancing the transferability essentially decease interactions inside adversarial perturbations. Based on this, we propose to directly penalize interactions during the attacking process, which significantly improves the adversarial transferability. We will release the code when the paper is accepted.", "one-sentence_summary": "We prove the close relationship between the interaction and adversarial transferability, provide a unified explanation for previous transferability-boosting methods, and develop a loss to improve adversarial transferability.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wang|a_unified_approach_to_interpreting_and_boosting_adversarial_transferability", "pdf": "/pdf/92ba2b486ce85a52e017691c5f53af8699796288.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nwang2021a,\ntitle={A Unified Approach to Interpreting and Boosting Adversarial Transferability},\nauthor={Xin Wang and Jie Ren and Shuyun Lin and Xiangming Zhu and Yisen Wang and Quanshi Zhang},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=X76iqnUbBjz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "X76iqnUbBjz", "replyto": "X76iqnUbBjz", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper273/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538146739, "tmdate": 1606915788371, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper273/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper273/-/Official_Review"}}}, {"id": "IaMI146e9hO", "original": null, "number": 4, "cdate": 1603994274259, "ddate": null, "tcdate": 1603994274259, "tmdate": 1605024726294, "tddate": null, "forum": "X76iqnUbBjz", "replyto": "X76iqnUbBjz", "invitation": "ICLR.cc/2021/Conference/Paper273/-/Official_Review", "content": {"title": "This work defines interaction of coordinates in the input data based on Shapley values, and shows a negative correlation between the adversarial transferability and the interaction.", "review": "The paper presents a negative correlation between the adversarial transferability and the interaction between coordinates.  The interaction is defined by the Shapley values used in the game theory to measure the contribution of players.  The author(s) defined the interaction between coordinates (players) as the difference between the joint contribution and the sum of conditional contributions.  They show a negative correlation between the adversarial transferability and the interaction with various known adversarial attacks.\n\nThis work also shows an improvement in the transferability of adversarial perturbations by incorporating the interactive loss with the classification loss. \n\nWhat is missing in the paper is the reason and motivation for using the Shapley values for defining the interaction.  No comparison and discussion is given the difference between their method and other methods that define the interaction between variables.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper273/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper273/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Unified Approach to Interpreting and Boosting Adversarial Transferability", "authorids": ["~Xin_Wang25", "~Jie_Ren1", "~Shuyun_Lin1", "~Xiangming_Zhu2", "~Yisen_Wang1", "~Quanshi_Zhang1"], "authors": ["Xin Wang", "Jie Ren", "Shuyun Lin", "Xiangming Zhu", "Yisen Wang", "Quanshi Zhang"], "keywords": ["Adversarial Learning", "Interpretability", "Adversarial Transferability"], "abstract": "In this paper, we use the interaction inside adversarial perturbations to explain and boost the adversarial transferability. We discover and prove the negative correlation between the adversarial transferability and the interaction inside adversarial perturbations. The negative correlation is further verified through different DNNs with various inputs. Moreover, this negative correlation can be regarded as a unified perspective to understand current transferability-boosting methods. To this end, we prove that some classic methods of enhancing the transferability essentially decease interactions inside adversarial perturbations. Based on this, we propose to directly penalize interactions during the attacking process, which significantly improves the adversarial transferability. We will release the code when the paper is accepted.", "one-sentence_summary": "We prove the close relationship between the interaction and adversarial transferability, provide a unified explanation for previous transferability-boosting methods, and develop a loss to improve adversarial transferability.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wang|a_unified_approach_to_interpreting_and_boosting_adversarial_transferability", "pdf": "/pdf/92ba2b486ce85a52e017691c5f53af8699796288.pdf", "supplementary_material": "", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nwang2021a,\ntitle={A Unified Approach to Interpreting and Boosting Adversarial Transferability},\nauthor={Xin Wang and Jie Ren and Shuyun Lin and Xiangming Zhu and Yisen Wang and Quanshi Zhang},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=X76iqnUbBjz}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "X76iqnUbBjz", "replyto": "X76iqnUbBjz", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper273/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538146739, "tmdate": 1606915788371, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper273/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper273/-/Official_Review"}}}], "count": 15}