{"notes": [{"id": "rJMw747l_4", "original": "BJxaBFrKvE", "number": 23, "cdate": 1553114143452, "ddate": null, "tcdate": 1553114143452, "tmdate": 1562082106342, "tddate": null, "forum": "rJMw747l_4", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "Seeing is Not Necessarily Believing: Limitations of BigGANs for Data Augmentation", "authors": ["Suman Ravuri", "Oriol Vinyals"], "authorids": ["ravuris@google.com", "vinyals@google.com"], "keywords": ["GANs", "data augmentation", "BigGAN"], "TL;DR": "BigGANs do not capture the ImageNet data distributions and are only modestly successful for data augmentation.", "abstract": "Recent advances in Generative Adversarial Networks (GANs) \u2013 in architectural design,  training strategies,  and empirical tricks \u2013 have led nearly photorealistic samples on large-scale datasets such as ImageNet.  In fact, for one model in particular, BigGAN, metrics such as Inception Score or Frechet Inception Distance nearly match those of the dataset, suggesting that these models are close to match-ing the distribution of the training set.   Given the quality of these models,  it is worth understanding to what extent these samples can be used for data augmentation, a task expressed as a long-term goal of the GAN research project.  To that end, we train ResNet-50 classifiers using either purely BigGAN images or mixtures of ImageNet and BigGAN images, and test on the ImageNet validation set.Our  preliminary  results  suggest  both a measured view of  state-of-the-art  GAN quality and highlight limitations of current metrics. Using only BigGAN images, we find that Top-1 and Top-5 error increased by 120% and 384%, respectively, and furthermore, adding more BigGAN data to the ImageNet training set at best only marginally improves classifier performance. Finally, we find that neither Inception Score, nor FID, nor combinations thereof are predictive of classification accuracy.   These results suggest that as GANs are beginning to be deployed in downstream tasks, we should create metrics that better measure downstream task performance.  We propose classification performance as one such metric that, in addition to assessing per-class sample quality, is more suited to such downstream tasks.", "pdf": "/pdf/2e47be9cb0e9d461a945f3f5839c92af9c1bafaf.pdf", "paperhash": "ravuri|seeing_is_not_necessarily_believing_limitations_of_biggans_for_data_augmentation"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "OpenReview.net"}, {"id": "BkgnPV1FKV", "original": null, "number": 1, "cdate": 1554736228399, "ddate": null, "tcdate": 1554736228399, "tmdate": 1555511883394, "tddate": null, "forum": "rJMw747l_4", "replyto": "rJMw747l_4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper23/Official_Review", "content": {"title": "Detailed exploration of GAN in a different setting", "review": "This paper clearly sets out a hypothesis, method to test the hypothesis, and the presents the core (negative) result \"BigGANs cannot be currently used for data augmentation and more work is required for it to be\nused in downstream tasks\". This work overall is clear and direct, and I enjoyed reading and reviewing it. I will focus the remainder of the review on suggestions, questions and ideas for perhaps pushing this work in some other directions.\n\nThe experiments here are quite detailed, though the nature of the work opens a whole new series of questions that I hope the authors continue exploring. Rather than only using the model for data augmentation, the images / representations for the classifier could also be augmented using discriminator features extracted learned by the learned-and-frozen GAN - this could perhaps still be an improvement even if the direct images / dataset augmentation isn't sufficient to improve classification. These types of \"bootstrapping\" of the GAN with discriminator features can be seen in papers such as \"Denoising Feature Matching\", though used in a different setting https://openreview.net/forum?id=S1X7nhsxl .\n\nOne big question I have is in regard to the use of GAN (trained on very large datasets, potentially) as a regularization technique for much smaller datasets than ImageNet. This setting might allow the use of much larger models on small data, due to better regularization - though ImageNet has been (slightly) overfit these days, it is still enormous compared to many practical \"in-the-wild\" datasets and seems a particularly hard test for this data augmentation setup. Out-of-domain generalization is potentially another area to explore with practical application.", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper23/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper23/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Seeing is Not Necessarily Believing: Limitations of BigGANs for Data Augmentation", "authors": ["Suman Ravuri", "Oriol Vinyals"], "authorids": ["ravuris@google.com", "vinyals@google.com"], "keywords": ["GANs", "data augmentation", "BigGAN"], "TL;DR": "BigGANs do not capture the ImageNet data distributions and are only modestly successful for data augmentation.", "abstract": "Recent advances in Generative Adversarial Networks (GANs) \u2013 in architectural design,  training strategies,  and empirical tricks \u2013 have led nearly photorealistic samples on large-scale datasets such as ImageNet.  In fact, for one model in particular, BigGAN, metrics such as Inception Score or Frechet Inception Distance nearly match those of the dataset, suggesting that these models are close to match-ing the distribution of the training set.   Given the quality of these models,  it is worth understanding to what extent these samples can be used for data augmentation, a task expressed as a long-term goal of the GAN research project.  To that end, we train ResNet-50 classifiers using either purely BigGAN images or mixtures of ImageNet and BigGAN images, and test on the ImageNet validation set.Our  preliminary  results  suggest  both a measured view of  state-of-the-art  GAN quality and highlight limitations of current metrics. Using only BigGAN images, we find that Top-1 and Top-5 error increased by 120% and 384%, respectively, and furthermore, adding more BigGAN data to the ImageNet training set at best only marginally improves classifier performance. Finally, we find that neither Inception Score, nor FID, nor combinations thereof are predictive of classification accuracy.   These results suggest that as GANs are beginning to be deployed in downstream tasks, we should create metrics that better measure downstream task performance.  We propose classification performance as one such metric that, in addition to assessing per-class sample quality, is more suited to such downstream tasks.", "pdf": "/pdf/2e47be9cb0e9d461a945f3f5839c92af9c1bafaf.pdf", "paperhash": "ravuri|seeing_is_not_necessarily_believing_limitations_of_biggans_for_data_augmentation"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper23/Official_Review", "cdate": 1553713418431, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "rJMw747l_4", "replyto": "rJMw747l_4", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper23/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper23/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713418431, "tmdate": 1555511816183, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper23/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "HkxRKaJct4", "original": null, "number": 2, "cdate": 1554804102045, "ddate": null, "tcdate": 1554804102045, "tmdate": 1555511881003, "tddate": null, "forum": "rJMw747l_4", "replyto": "rJMw747l_4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper23/Official_Review", "content": {"title": "Good systematic study of the inadequacy of GAN for data-augmentation", "review": "The authors train ResNet-50 networks on a mixture of ImageNet data and BigGAN samples and show that replacing ImageNet data with BigGAN samples leads to a decrease in performance.\n\nPositives:\n- This \"data-replacement\" experiment is very natural to make, therefore I am glad it was done.\n- The metric for identifying BigGAN failures per class is also an interesting byproduct.\n\nRemarks:\na) \"per-class FID\" is said to be likely \"making the per-class estimates unreliable\" due to high variance. I would still like to see what the per-class FID gives and how the best and worst-performing classes compare with the one found by this method. Indeed, even if per-class FID could perform worse, it has the great benefit of not necessitating to train new Resnet-50 networks.\nb) I would be interested to see some samples generated with the best truncation for replacement, and for addition, in order to have a better idea of what kind of \"diversity\" we are talking of (this could replace one of the two subplots of Fig. 2 since top1/top5 follow the same trends).\n\nOverall, I think this paper and its experiments is a nice contribution to the workshop.", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper23/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper23/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Seeing is Not Necessarily Believing: Limitations of BigGANs for Data Augmentation", "authors": ["Suman Ravuri", "Oriol Vinyals"], "authorids": ["ravuris@google.com", "vinyals@google.com"], "keywords": ["GANs", "data augmentation", "BigGAN"], "TL;DR": "BigGANs do not capture the ImageNet data distributions and are only modestly successful for data augmentation.", "abstract": "Recent advances in Generative Adversarial Networks (GANs) \u2013 in architectural design,  training strategies,  and empirical tricks \u2013 have led nearly photorealistic samples on large-scale datasets such as ImageNet.  In fact, for one model in particular, BigGAN, metrics such as Inception Score or Frechet Inception Distance nearly match those of the dataset, suggesting that these models are close to match-ing the distribution of the training set.   Given the quality of these models,  it is worth understanding to what extent these samples can be used for data augmentation, a task expressed as a long-term goal of the GAN research project.  To that end, we train ResNet-50 classifiers using either purely BigGAN images or mixtures of ImageNet and BigGAN images, and test on the ImageNet validation set.Our  preliminary  results  suggest  both a measured view of  state-of-the-art  GAN quality and highlight limitations of current metrics. Using only BigGAN images, we find that Top-1 and Top-5 error increased by 120% and 384%, respectively, and furthermore, adding more BigGAN data to the ImageNet training set at best only marginally improves classifier performance. Finally, we find that neither Inception Score, nor FID, nor combinations thereof are predictive of classification accuracy.   These results suggest that as GANs are beginning to be deployed in downstream tasks, we should create metrics that better measure downstream task performance.  We propose classification performance as one such metric that, in addition to assessing per-class sample quality, is more suited to such downstream tasks.", "pdf": "/pdf/2e47be9cb0e9d461a945f3f5839c92af9c1bafaf.pdf", "paperhash": "ravuri|seeing_is_not_necessarily_believing_limitations_of_biggans_for_data_augmentation"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper23/Official_Review", "cdate": 1553713418431, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "rJMw747l_4", "replyto": "rJMw747l_4", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper23/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper23/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713418431, "tmdate": 1555511816183, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper23/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "Hyg8TTYYtV", "original": null, "number": 1, "cdate": 1554779582069, "ddate": null, "tcdate": 1554779582069, "tmdate": 1555510984256, "tddate": null, "forum": "rJMw747l_4", "replyto": "rJMw747l_4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper23/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Seeing is Not Necessarily Believing: Limitations of BigGANs for Data Augmentation", "authors": ["Suman Ravuri", "Oriol Vinyals"], "authorids": ["ravuris@google.com", "vinyals@google.com"], "keywords": ["GANs", "data augmentation", "BigGAN"], "TL;DR": "BigGANs do not capture the ImageNet data distributions and are only modestly successful for data augmentation.", "abstract": "Recent advances in Generative Adversarial Networks (GANs) \u2013 in architectural design,  training strategies,  and empirical tricks \u2013 have led nearly photorealistic samples on large-scale datasets such as ImageNet.  In fact, for one model in particular, BigGAN, metrics such as Inception Score or Frechet Inception Distance nearly match those of the dataset, suggesting that these models are close to match-ing the distribution of the training set.   Given the quality of these models,  it is worth understanding to what extent these samples can be used for data augmentation, a task expressed as a long-term goal of the GAN research project.  To that end, we train ResNet-50 classifiers using either purely BigGAN images or mixtures of ImageNet and BigGAN images, and test on the ImageNet validation set.Our  preliminary  results  suggest  both a measured view of  state-of-the-art  GAN quality and highlight limitations of current metrics. Using only BigGAN images, we find that Top-1 and Top-5 error increased by 120% and 384%, respectively, and furthermore, adding more BigGAN data to the ImageNet training set at best only marginally improves classifier performance. Finally, we find that neither Inception Score, nor FID, nor combinations thereof are predictive of classification accuracy.   These results suggest that as GANs are beginning to be deployed in downstream tasks, we should create metrics that better measure downstream task performance.  We propose classification performance as one such metric that, in addition to assessing per-class sample quality, is more suited to such downstream tasks.", "pdf": "/pdf/2e47be9cb0e9d461a945f3f5839c92af9c1bafaf.pdf", "paperhash": "ravuri|seeing_is_not_necessarily_believing_limitations_of_biggans_for_data_augmentation"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper23/Decision", "cdate": 1554736067381, "reply": {"forum": "rJMw747l_4", "replyto": "rJMw747l_4", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736067381, "tmdate": 1555510971302, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 4}