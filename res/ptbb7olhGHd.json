{"notes": [{"id": "ptbb7olhGHd", "original": "2JG6CTMehzk", "number": 2665, "cdate": 1601308295217, "ddate": null, "tcdate": 1601308295217, "tmdate": 1614985641803, "tddate": null, "forum": "ptbb7olhGHd", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "On the Robustness of Sentiment Analysis for Stock Price Forecasting", "authorids": ["~Gabriel_Deza1", "c.rowat@bham.ac.uk", "~Nicolas_Papernot1"], "authors": ["Gabriel Deza", "Colin Rowat", "Nicolas Papernot"], "keywords": ["adversarial machine learning", "adversarial examples", "stock price forecasting", "finance"], "abstract": "Machine learning (ML) models are known to be vulnerable to attacks both at training and test time. Despite the extensive literature on adversarial ML, prior efforts focus primarily on applications of computer vision to object recognition or sentiment analysis to movie reviews. In these settings, the incentives for adversaries to manipulate the model's prediction are often unclear and attacks require extensive control of direct inputs to the model. This makes it difficult to evaluate how severe the impact of vulnerabilities exposed is on systems deploying ML with little provenance guarantees for the input data. In this paper, we study adversarial ML with stock price forecasting. Adversarial incentives are clear and may be quantified experimentally through a simulated portfolio.  We replicate an industry standard pipeline, which performs a sentiment analysis of Twitter data to forecast trends in stock prices. We show that an adversary can exploit the lack of provenance to indirectly use tweets to  manipulate the model's perceived sentiment about a target company and in turn force the model to forecast price erroneously. Our attack is mounted at test time and does not modify the training data. Given past market anomalies, we conclude with a series of recommendations for the use of machine learning as input signal to trading algorithms. ", "one-sentence_summary": "Replicate industry standard sentiment analysis of Twitter data for stock price forecasting, and demonstrate its vulnerability to adversarial manipulations of the model's inputs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "deza|on_the_robustness_of_sentiment_analysis_for_stock_price_forecasting", "pdf": "/pdf/e09c9c680c27d4ae123a208f4e30957460bb97f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=zz8VspX_v", "_bibtex": "@misc{\ndeza2021on,\ntitle={On the Robustness of Sentiment Analysis for Stock Price Forecasting},\nauthor={Gabriel Deza and Colin Rowat and Nicolas Papernot},\nyear={2021},\nurl={https://openreview.net/forum?id=ptbb7olhGHd}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "XI0nnh1rDpr", "original": null, "number": 1, "cdate": 1610040519994, "ddate": null, "tcdate": 1610040519994, "tmdate": 1610474128600, "tddate": null, "forum": "ptbb7olhGHd", "replyto": "ptbb7olhGHd", "invitation": "ICLR.cc/2021/Conference/Paper2665/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "One reviewer is positive, but that review is not of high quality. The other reviewers agree that this paper is interesting, but has too many limitations to be accepted by a highly competitive venue such as ICLR."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Robustness of Sentiment Analysis for Stock Price Forecasting", "authorids": ["~Gabriel_Deza1", "c.rowat@bham.ac.uk", "~Nicolas_Papernot1"], "authors": ["Gabriel Deza", "Colin Rowat", "Nicolas Papernot"], "keywords": ["adversarial machine learning", "adversarial examples", "stock price forecasting", "finance"], "abstract": "Machine learning (ML) models are known to be vulnerable to attacks both at training and test time. Despite the extensive literature on adversarial ML, prior efforts focus primarily on applications of computer vision to object recognition or sentiment analysis to movie reviews. In these settings, the incentives for adversaries to manipulate the model's prediction are often unclear and attacks require extensive control of direct inputs to the model. This makes it difficult to evaluate how severe the impact of vulnerabilities exposed is on systems deploying ML with little provenance guarantees for the input data. In this paper, we study adversarial ML with stock price forecasting. Adversarial incentives are clear and may be quantified experimentally through a simulated portfolio.  We replicate an industry standard pipeline, which performs a sentiment analysis of Twitter data to forecast trends in stock prices. We show that an adversary can exploit the lack of provenance to indirectly use tweets to  manipulate the model's perceived sentiment about a target company and in turn force the model to forecast price erroneously. Our attack is mounted at test time and does not modify the training data. Given past market anomalies, we conclude with a series of recommendations for the use of machine learning as input signal to trading algorithms. ", "one-sentence_summary": "Replicate industry standard sentiment analysis of Twitter data for stock price forecasting, and demonstrate its vulnerability to adversarial manipulations of the model's inputs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "deza|on_the_robustness_of_sentiment_analysis_for_stock_price_forecasting", "pdf": "/pdf/e09c9c680c27d4ae123a208f4e30957460bb97f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=zz8VspX_v", "_bibtex": "@misc{\ndeza2021on,\ntitle={On the Robustness of Sentiment Analysis for Stock Price Forecasting},\nauthor={Gabriel Deza and Colin Rowat and Nicolas Papernot},\nyear={2021},\nurl={https://openreview.net/forum?id=ptbb7olhGHd}\n}"}, "tags": [], "invitation": {"reply": {"forum": "ptbb7olhGHd", "replyto": "ptbb7olhGHd", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040519980, "tmdate": 1610474128584, "id": "ICLR.cc/2021/Conference/Paper2665/-/Decision"}}}, {"id": "t5i5WJnLXrC", "original": null, "number": 6, "cdate": 1606251572176, "ddate": null, "tcdate": 1606251572176, "tmdate": 1606251572176, "tddate": null, "forum": "ptbb7olhGHd", "replyto": "JlDtGQkgOV2", "invitation": "ICLR.cc/2021/Conference/Paper2665/-/Official_Comment", "content": {"title": "Goal of our work & additional dataset comments", "comment": "We thank the author for their comments and insight.\n\nThe goal of our paper was to develop a stock price forecasting pipeline and showcase the capabilities of an adversarial ML attack to the pipeline. We decided to investigate a single company as a proof of concept. We decided to work with Tesla in large part because of the significant volume of discussion on Twitter and Elon\u2019s Musk frequent use of Twitter. Although we agree with the reviewer that our work can be improved by testing other datasets, the purpose of our work is not to create a state of the art forecasting model for any company, rather showcase adversarial examples in a more meaningful setting compared to previous domains (movie reviews, image classification etc). \n\nNonetheless, we tried to collect tweets from another company, however Twitter updated their API at the end of September, breaking our scraping tool (and many others). Unfortunately, this severely limits the range of data we can collect (only a month of data) until the review stage. This is not enough data to train any of our models.\n\nRegarding the novelty of our work, the goal of this paper is to showcase the threat vector that may exist when using machine learning models on public data via adversarial crafting, not to showcase a novel pipeline or attack method. Implementing the pipeline used in our evaluation required non-trivial efforts which we hope will lay the foundations for others to study adversarial examples in a domain where adversarial incentives are clear. We hope our work serves as a benchmark for much more work within adversarial machine learning in high-risk domains such as finance, hence we believe that the value of our effort stems in the non-trivial forecasting model implementation combined with a dedicated robustness analysis\n\nLastly, the conclusion of our work is not as simple as the reviewer mentioned. The inputs are not perturbed randomly, rather they are perturbed such that the forecasts are changed following an adversary\u2019s objective. The adversary selects a distribution parameter and direction, and the algorithm returns a set of perturbations to achieve such a goal. For example, an adversary could wish to decrease the mean forecast by a fixed amount, and the algorithm would return a number of tweets to post with a specific negative score, along with the number of likes and retweets for each of them.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2665/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2665/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Robustness of Sentiment Analysis for Stock Price Forecasting", "authorids": ["~Gabriel_Deza1", "c.rowat@bham.ac.uk", "~Nicolas_Papernot1"], "authors": ["Gabriel Deza", "Colin Rowat", "Nicolas Papernot"], "keywords": ["adversarial machine learning", "adversarial examples", "stock price forecasting", "finance"], "abstract": "Machine learning (ML) models are known to be vulnerable to attacks both at training and test time. Despite the extensive literature on adversarial ML, prior efforts focus primarily on applications of computer vision to object recognition or sentiment analysis to movie reviews. In these settings, the incentives for adversaries to manipulate the model's prediction are often unclear and attacks require extensive control of direct inputs to the model. This makes it difficult to evaluate how severe the impact of vulnerabilities exposed is on systems deploying ML with little provenance guarantees for the input data. In this paper, we study adversarial ML with stock price forecasting. Adversarial incentives are clear and may be quantified experimentally through a simulated portfolio.  We replicate an industry standard pipeline, which performs a sentiment analysis of Twitter data to forecast trends in stock prices. We show that an adversary can exploit the lack of provenance to indirectly use tweets to  manipulate the model's perceived sentiment about a target company and in turn force the model to forecast price erroneously. Our attack is mounted at test time and does not modify the training data. Given past market anomalies, we conclude with a series of recommendations for the use of machine learning as input signal to trading algorithms. ", "one-sentence_summary": "Replicate industry standard sentiment analysis of Twitter data for stock price forecasting, and demonstrate its vulnerability to adversarial manipulations of the model's inputs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "deza|on_the_robustness_of_sentiment_analysis_for_stock_price_forecasting", "pdf": "/pdf/e09c9c680c27d4ae123a208f4e30957460bb97f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=zz8VspX_v", "_bibtex": "@misc{\ndeza2021on,\ntitle={On the Robustness of Sentiment Analysis for Stock Price Forecasting},\nauthor={Gabriel Deza and Colin Rowat and Nicolas Papernot},\nyear={2021},\nurl={https://openreview.net/forum?id=ptbb7olhGHd}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ptbb7olhGHd", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2665/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2665/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2665/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2665/Authors|ICLR.cc/2021/Conference/Paper2665/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2665/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923845736, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2665/-/Official_Comment"}}}, {"id": "8K42v4OjTd8", "original": null, "number": 5, "cdate": 1606251522324, "ddate": null, "tcdate": 1606251522324, "tmdate": 1606251522324, "tddate": null, "forum": "ptbb7olhGHd", "replyto": "NFfoYVJFxjn", "invitation": "ICLR.cc/2021/Conference/Paper2665/-/Official_Comment", "content": {"title": "Changing the title", "comment": "We thank the reviewer for their comments. We appreciate that the reviewer finds this as rewarding as ourselves.\n\nWe agree with the reviewer about the title of our work. We are thinking of another title to better reflect our methods.\nRegarding point #2, We are unsure what the reviewer meant by \u201cnot shown at implementation\u201d. We are willing to open-source all of our code and data collected upon publication of the work. We hope that our pipeline and data collections tools can be used as a baseline for further work in the underlying and combating the threats associated with machine learning in high-risk industrial applications like finance.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2665/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2665/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Robustness of Sentiment Analysis for Stock Price Forecasting", "authorids": ["~Gabriel_Deza1", "c.rowat@bham.ac.uk", "~Nicolas_Papernot1"], "authors": ["Gabriel Deza", "Colin Rowat", "Nicolas Papernot"], "keywords": ["adversarial machine learning", "adversarial examples", "stock price forecasting", "finance"], "abstract": "Machine learning (ML) models are known to be vulnerable to attacks both at training and test time. Despite the extensive literature on adversarial ML, prior efforts focus primarily on applications of computer vision to object recognition or sentiment analysis to movie reviews. In these settings, the incentives for adversaries to manipulate the model's prediction are often unclear and attacks require extensive control of direct inputs to the model. This makes it difficult to evaluate how severe the impact of vulnerabilities exposed is on systems deploying ML with little provenance guarantees for the input data. In this paper, we study adversarial ML with stock price forecasting. Adversarial incentives are clear and may be quantified experimentally through a simulated portfolio.  We replicate an industry standard pipeline, which performs a sentiment analysis of Twitter data to forecast trends in stock prices. We show that an adversary can exploit the lack of provenance to indirectly use tweets to  manipulate the model's perceived sentiment about a target company and in turn force the model to forecast price erroneously. Our attack is mounted at test time and does not modify the training data. Given past market anomalies, we conclude with a series of recommendations for the use of machine learning as input signal to trading algorithms. ", "one-sentence_summary": "Replicate industry standard sentiment analysis of Twitter data for stock price forecasting, and demonstrate its vulnerability to adversarial manipulations of the model's inputs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "deza|on_the_robustness_of_sentiment_analysis_for_stock_price_forecasting", "pdf": "/pdf/e09c9c680c27d4ae123a208f4e30957460bb97f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=zz8VspX_v", "_bibtex": "@misc{\ndeza2021on,\ntitle={On the Robustness of Sentiment Analysis for Stock Price Forecasting},\nauthor={Gabriel Deza and Colin Rowat and Nicolas Papernot},\nyear={2021},\nurl={https://openreview.net/forum?id=ptbb7olhGHd}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ptbb7olhGHd", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2665/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2665/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2665/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2665/Authors|ICLR.cc/2021/Conference/Paper2665/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2665/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923845736, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2665/-/Official_Comment"}}}, {"id": "Lg79HSNt9Ld", "original": null, "number": 4, "cdate": 1606251438775, "ddate": null, "tcdate": 1606251438775, "tmdate": 1606251438775, "tddate": null, "forum": "ptbb7olhGHd", "replyto": "dKj-JBD3QXa", "invitation": "ICLR.cc/2021/Conference/Paper2665/-/Official_Comment", "content": {"title": "Scope of our work", "comment": "We thank the reviewer for their review and time.\n\nThe goal of this paper is to showcase the threat vector that may exist when using machine learning models on public data via adversarial crafting, not to showcase a novel pipeline or attack method. Implementing the pipeline used in our evaluation required non-trivial efforts which we hope will lay the foundations for others to study adversarial examples in a domain where adversarial incentives are clear. We hope our work serves as a benchmark for much more work within adversarial machine learning in high-risk domains such as finance, hence we believe that the value of our effort stems in the non-trivial forecasting model implementation combined with a dedicated robustness analysis. Regarding our evaluation metrics, we described every metric in the appendix, but can be introduced in the body of our work and reference readers to the appendix for more detailed information. "}, "signatures": ["ICLR.cc/2021/Conference/Paper2665/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2665/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Robustness of Sentiment Analysis for Stock Price Forecasting", "authorids": ["~Gabriel_Deza1", "c.rowat@bham.ac.uk", "~Nicolas_Papernot1"], "authors": ["Gabriel Deza", "Colin Rowat", "Nicolas Papernot"], "keywords": ["adversarial machine learning", "adversarial examples", "stock price forecasting", "finance"], "abstract": "Machine learning (ML) models are known to be vulnerable to attacks both at training and test time. Despite the extensive literature on adversarial ML, prior efforts focus primarily on applications of computer vision to object recognition or sentiment analysis to movie reviews. In these settings, the incentives for adversaries to manipulate the model's prediction are often unclear and attacks require extensive control of direct inputs to the model. This makes it difficult to evaluate how severe the impact of vulnerabilities exposed is on systems deploying ML with little provenance guarantees for the input data. In this paper, we study adversarial ML with stock price forecasting. Adversarial incentives are clear and may be quantified experimentally through a simulated portfolio.  We replicate an industry standard pipeline, which performs a sentiment analysis of Twitter data to forecast trends in stock prices. We show that an adversary can exploit the lack of provenance to indirectly use tweets to  manipulate the model's perceived sentiment about a target company and in turn force the model to forecast price erroneously. Our attack is mounted at test time and does not modify the training data. Given past market anomalies, we conclude with a series of recommendations for the use of machine learning as input signal to trading algorithms. ", "one-sentence_summary": "Replicate industry standard sentiment analysis of Twitter data for stock price forecasting, and demonstrate its vulnerability to adversarial manipulations of the model's inputs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "deza|on_the_robustness_of_sentiment_analysis_for_stock_price_forecasting", "pdf": "/pdf/e09c9c680c27d4ae123a208f4e30957460bb97f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=zz8VspX_v", "_bibtex": "@misc{\ndeza2021on,\ntitle={On the Robustness of Sentiment Analysis for Stock Price Forecasting},\nauthor={Gabriel Deza and Colin Rowat and Nicolas Papernot},\nyear={2021},\nurl={https://openreview.net/forum?id=ptbb7olhGHd}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ptbb7olhGHd", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2665/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2665/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2665/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2665/Authors|ICLR.cc/2021/Conference/Paper2665/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2665/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923845736, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2665/-/Official_Comment"}}}, {"id": "-mQzFgE3fS", "original": null, "number": 3, "cdate": 1606251359983, "ddate": null, "tcdate": 1606251359983, "tmdate": 1606251359983, "tddate": null, "forum": "ptbb7olhGHd", "replyto": "R7dGc2Rm0jc", "invitation": "ICLR.cc/2021/Conference/Paper2665/-/Official_Comment", "content": {"title": "Scope of our work", "comment": "We thank the reviewer for their time and comments. \n\nWe will answer each comment separately:\nRegarding the scope of our work:The goal of our work is to showcase the threat vector that may exist when using stock price forecasting machine learning models on public data via adversarial crafting. Given the page limit of ICLR, we had to limit the work of each section of the pipeline to ensure that every part of the pipeline can be discussed. We hope our work serves as a benchmark for much more work within adversarial machine learning in high-risk domains such as finance, hence we believe that the depth of each section was meaningful enough to create a non-trivial forecasting model.\n\nRegarding filtering of tweets, traditionally text is not preprocessed when training BERT; BERT tokenizer does it for you. Hence we think that simple language filtering was adequate in our work. However, we do realize that more complex filtering such as filtering tweets with little financial weight would be more indicative of an industry standard pipeline. As a preliminary work in financial adversarial machine learning, we decided to omit this added complexity. Lastly, we did filter out tweets with less than 50 likes and 10 retweets, but found very similar results in model performance and adversarial crafting performance.\n\nRegarding considering only a single stock, we agree with the reviewers opinion.We have since started collecting tweets from other companies, however Twitter updated their API at the end of September, breaking our scraping tool (and many others). Unfortunately, this severely limits the range of data we can collect (only a month of data) during the review stage. This is not enough data to train any of our models. \n\nRegarding the knowledge of an adversary, there are a couple hypothetical scenarios. If you know nothing about your victim's internal system but suspect they use twitter for sentiment analysis, you can collect the buy and sell decisions they make on the market along with the tweets at that time. Using the tweets as inputs and their decisions as labels, you can try different models on this dataset to try to best approximate their model. As more information is known to you (type of architecture, filtering process, hyperparameters), the task is easier. This is analog to black-box attacks based on transferability in adversarial example research on images. \n\nLastly, we agree that other features can be of use for stock forecasting. Based on previous work mentioned in our work (Bollen et al, 2011), we believe textual sentiment is a good feature to detect financial information from tweets if such information exists. We experimented with the average length of tweets as a covariate, but found it uninformative for stock forecasting. Regarding additional features (for example, the author of the tweet, verified status, etc), we limited our work to features/covariates that can be manipulable by any member of the general public. For example, although the tweets from the CEO of the company in question are likely to be more meaningful then the tweet of a random individual, this is not manipulable by a random user (or at least, not without breaching the security of Twitter itself). This is part of the reason why we used tweets as a feature for stock forecasting (instead of other stocks, commodities etc) as they are more easily manipulable by anyone.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2665/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2665/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Robustness of Sentiment Analysis for Stock Price Forecasting", "authorids": ["~Gabriel_Deza1", "c.rowat@bham.ac.uk", "~Nicolas_Papernot1"], "authors": ["Gabriel Deza", "Colin Rowat", "Nicolas Papernot"], "keywords": ["adversarial machine learning", "adversarial examples", "stock price forecasting", "finance"], "abstract": "Machine learning (ML) models are known to be vulnerable to attacks both at training and test time. Despite the extensive literature on adversarial ML, prior efforts focus primarily on applications of computer vision to object recognition or sentiment analysis to movie reviews. In these settings, the incentives for adversaries to manipulate the model's prediction are often unclear and attacks require extensive control of direct inputs to the model. This makes it difficult to evaluate how severe the impact of vulnerabilities exposed is on systems deploying ML with little provenance guarantees for the input data. In this paper, we study adversarial ML with stock price forecasting. Adversarial incentives are clear and may be quantified experimentally through a simulated portfolio.  We replicate an industry standard pipeline, which performs a sentiment analysis of Twitter data to forecast trends in stock prices. We show that an adversary can exploit the lack of provenance to indirectly use tweets to  manipulate the model's perceived sentiment about a target company and in turn force the model to forecast price erroneously. Our attack is mounted at test time and does not modify the training data. Given past market anomalies, we conclude with a series of recommendations for the use of machine learning as input signal to trading algorithms. ", "one-sentence_summary": "Replicate industry standard sentiment analysis of Twitter data for stock price forecasting, and demonstrate its vulnerability to adversarial manipulations of the model's inputs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "deza|on_the_robustness_of_sentiment_analysis_for_stock_price_forecasting", "pdf": "/pdf/e09c9c680c27d4ae123a208f4e30957460bb97f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=zz8VspX_v", "_bibtex": "@misc{\ndeza2021on,\ntitle={On the Robustness of Sentiment Analysis for Stock Price Forecasting},\nauthor={Gabriel Deza and Colin Rowat and Nicolas Papernot},\nyear={2021},\nurl={https://openreview.net/forum?id=ptbb7olhGHd}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "ptbb7olhGHd", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2665/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2665/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2665/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2665/Authors|ICLR.cc/2021/Conference/Paper2665/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2665/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923845736, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2665/-/Official_Comment"}}}, {"id": "JlDtGQkgOV2", "original": null, "number": 1, "cdate": 1603636813030, "ddate": null, "tcdate": 1603636813030, "tmdate": 1605215167965, "tddate": null, "forum": "ptbb7olhGHd", "replyto": "ptbb7olhGHd", "invitation": "ICLR.cc/2021/Conference/Paper2665/-/Official_Review", "content": {"title": "An interesting topic but several issues in experiments", "review": "The authors in this paper propose to use the adversarial ML in the stock price forecasting scenario and demonstrate that an adversary can exploit the lack of provenance to indirectly use tweets to manipulate the prediction model\u2019s perceived sentiment about a target company and in turn force the model to forecast price erroneously. However, I have the following comments on the paper: \n\n- Dataset collection is not convinced. Authors collect only one company (i.e.,  Tesla) data from Twitter and Yahoo. Experiments in the entire paper are only based on the dataset containing just one company. The authors provide two reasons for not considering other companies (such as Microsoft or Amazon as discussed examples in the paper): \"homonyms\" and \"unintended discussion\". However, Tesla also has the similar issue. For example, when Elon Must was discussed on Twitter, it may be about Elon Musk\u2019s other companies (SpaceX) or his arguments that are not related to Tesla (similar to the Bill Gates case in the paper). When people talk about Tesla, they may talk about Nikola Tesla. When people discuss Model 3, they may only express their experience of driving Model 3. The dataset with only one company contains bias to the model that may not be generalized to other cases.\n\n- Lack of novelty. All the technical components in this paper are not new. FinBERT, DeepAR, and Gradient Attack are all from existing works. ", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2665/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2665/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Robustness of Sentiment Analysis for Stock Price Forecasting", "authorids": ["~Gabriel_Deza1", "c.rowat@bham.ac.uk", "~Nicolas_Papernot1"], "authors": ["Gabriel Deza", "Colin Rowat", "Nicolas Papernot"], "keywords": ["adversarial machine learning", "adversarial examples", "stock price forecasting", "finance"], "abstract": "Machine learning (ML) models are known to be vulnerable to attacks both at training and test time. Despite the extensive literature on adversarial ML, prior efforts focus primarily on applications of computer vision to object recognition or sentiment analysis to movie reviews. In these settings, the incentives for adversaries to manipulate the model's prediction are often unclear and attacks require extensive control of direct inputs to the model. This makes it difficult to evaluate how severe the impact of vulnerabilities exposed is on systems deploying ML with little provenance guarantees for the input data. In this paper, we study adversarial ML with stock price forecasting. Adversarial incentives are clear and may be quantified experimentally through a simulated portfolio.  We replicate an industry standard pipeline, which performs a sentiment analysis of Twitter data to forecast trends in stock prices. We show that an adversary can exploit the lack of provenance to indirectly use tweets to  manipulate the model's perceived sentiment about a target company and in turn force the model to forecast price erroneously. Our attack is mounted at test time and does not modify the training data. Given past market anomalies, we conclude with a series of recommendations for the use of machine learning as input signal to trading algorithms. ", "one-sentence_summary": "Replicate industry standard sentiment analysis of Twitter data for stock price forecasting, and demonstrate its vulnerability to adversarial manipulations of the model's inputs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "deza|on_the_robustness_of_sentiment_analysis_for_stock_price_forecasting", "pdf": "/pdf/e09c9c680c27d4ae123a208f4e30957460bb97f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=zz8VspX_v", "_bibtex": "@misc{\ndeza2021on,\ntitle={On the Robustness of Sentiment Analysis for Stock Price Forecasting},\nauthor={Gabriel Deza and Colin Rowat and Nicolas Papernot},\nyear={2021},\nurl={https://openreview.net/forum?id=ptbb7olhGHd}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "ptbb7olhGHd", "replyto": "ptbb7olhGHd", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2665/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538091170, "tmdate": 1606915805734, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2665/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2665/-/Official_Review"}}}, {"id": "dKj-JBD3QXa", "original": null, "number": 3, "cdate": 1603780901282, "ddate": null, "tcdate": 1603780901282, "tmdate": 1605024157881, "tddate": null, "forum": "ptbb7olhGHd", "replyto": "ptbb7olhGHd", "invitation": "ICLR.cc/2021/Conference/Paper2665/-/Official_Review", "content": {"title": "Official Blind Reviewer 2", "review": "In this paper, the authors studied the problem of adversarial ML in stock price forecasting. They first replicated an industry standard pipeline, which performs a sentiment analysis of Twitter data to forecast trends in stock prices. Then, they show that an adversary can exploit the lack of provenance to indirectly use tweets to manipulate the model\u2019s perceived sentiment about a target company and in turn force the model to forecast price erroneously.\n\nStrength:\n\n1. The topic is interesting. Adversarial ML attracts a lot of attention recently, and applying them to stock price forecasting has clear incentive.\n2. The authors plan to release the code and data when this is accepted, which is good for other researchers to reproduce this work.\n\nWeakness:\n\n1. The novelty of the methodology seems limited. Both the stock price forecasting model (FinBERT and DeepAR-G) and the gradient attack method (Papernot et al. 2016) are not proposed by the authors. \n2. The writing can be improved. For example, in the experiment section, the authors used a lot of evaluation metrics such as sharpe ratio, greedy, threshold. Though they might be familiar to the audience in finance industry, they are not very clear to me at first. I'd suggest to give a definition and explanation of those metrics in this section.\n\nOverall comments:\n\nI think the research topic of this paper is interesting, but the methodology seems lack of novelty. In addition, the writing can be further improved. ", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2665/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2665/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Robustness of Sentiment Analysis for Stock Price Forecasting", "authorids": ["~Gabriel_Deza1", "c.rowat@bham.ac.uk", "~Nicolas_Papernot1"], "authors": ["Gabriel Deza", "Colin Rowat", "Nicolas Papernot"], "keywords": ["adversarial machine learning", "adversarial examples", "stock price forecasting", "finance"], "abstract": "Machine learning (ML) models are known to be vulnerable to attacks both at training and test time. Despite the extensive literature on adversarial ML, prior efforts focus primarily on applications of computer vision to object recognition or sentiment analysis to movie reviews. In these settings, the incentives for adversaries to manipulate the model's prediction are often unclear and attacks require extensive control of direct inputs to the model. This makes it difficult to evaluate how severe the impact of vulnerabilities exposed is on systems deploying ML with little provenance guarantees for the input data. In this paper, we study adversarial ML with stock price forecasting. Adversarial incentives are clear and may be quantified experimentally through a simulated portfolio.  We replicate an industry standard pipeline, which performs a sentiment analysis of Twitter data to forecast trends in stock prices. We show that an adversary can exploit the lack of provenance to indirectly use tweets to  manipulate the model's perceived sentiment about a target company and in turn force the model to forecast price erroneously. Our attack is mounted at test time and does not modify the training data. Given past market anomalies, we conclude with a series of recommendations for the use of machine learning as input signal to trading algorithms. ", "one-sentence_summary": "Replicate industry standard sentiment analysis of Twitter data for stock price forecasting, and demonstrate its vulnerability to adversarial manipulations of the model's inputs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "deza|on_the_robustness_of_sentiment_analysis_for_stock_price_forecasting", "pdf": "/pdf/e09c9c680c27d4ae123a208f4e30957460bb97f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=zz8VspX_v", "_bibtex": "@misc{\ndeza2021on,\ntitle={On the Robustness of Sentiment Analysis for Stock Price Forecasting},\nauthor={Gabriel Deza and Colin Rowat and Nicolas Papernot},\nyear={2021},\nurl={https://openreview.net/forum?id=ptbb7olhGHd}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "ptbb7olhGHd", "replyto": "ptbb7olhGHd", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2665/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538091170, "tmdate": 1606915805734, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2665/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2665/-/Official_Review"}}}, {"id": "R7dGc2Rm0jc", "original": null, "number": 4, "cdate": 1603929496291, "ddate": null, "tcdate": 1603929496291, "tmdate": 1605024157820, "tddate": null, "forum": "ptbb7olhGHd", "replyto": "ptbb7olhGHd", "invitation": "ICLR.cc/2021/Conference/Paper2665/-/Official_Review", "content": {"title": "This is generally an interesting paper as it studies adversarial attacks for financial systems that rely on ML systems.", "review": "The paper studies the impact of adversarial attacks on a ML based system for forecasting stock prices. The authors leverage Twitter data in order to enhance stock price prediction. Then, by determining the sensitivity of the model when perturbing the inputs. Then, small changes are applied to the inputs and output is observed. The authors experimented with the Tesla stock price.\n\nThis is interesting work and the authors do good work at explaining the different parts. Generally it flows well.\n\nA first comment I have is about the focus of the paper as it studies both feasibility of forecasting as well as adversarial attacks. But, it does not go in depth in neither of these topics. For example, the first part for me is very interesting and having more forecasting approaches as well as adding more features with the additions of time-series would be very valuable.\n\nAnother comment I have is that there is a naive assumption. The fact that before sentiment classification we do not do any filtering. This does not make sense for an industrial system. Having a filtering step would greatly benefit the pipeline. The authors could have invested some space on such an approach.\n\nAs you conclude that an adversarial trader would need to know the details for the forecasting model in order to attack would you be able to suggest an approach that would not require this knowledge?\n\nA major issue of the paper is that the authors just do predictions in a single stock price. I am not sure how much we can trust the conclusions based on just a single stock. The authors need to add more datasets. It is not enough.\n\nWhat about having other type of textual features apart from the sentiment? Do you think there is more space to explore here?", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2665/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2665/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Robustness of Sentiment Analysis for Stock Price Forecasting", "authorids": ["~Gabriel_Deza1", "c.rowat@bham.ac.uk", "~Nicolas_Papernot1"], "authors": ["Gabriel Deza", "Colin Rowat", "Nicolas Papernot"], "keywords": ["adversarial machine learning", "adversarial examples", "stock price forecasting", "finance"], "abstract": "Machine learning (ML) models are known to be vulnerable to attacks both at training and test time. Despite the extensive literature on adversarial ML, prior efforts focus primarily on applications of computer vision to object recognition or sentiment analysis to movie reviews. In these settings, the incentives for adversaries to manipulate the model's prediction are often unclear and attacks require extensive control of direct inputs to the model. This makes it difficult to evaluate how severe the impact of vulnerabilities exposed is on systems deploying ML with little provenance guarantees for the input data. In this paper, we study adversarial ML with stock price forecasting. Adversarial incentives are clear and may be quantified experimentally through a simulated portfolio.  We replicate an industry standard pipeline, which performs a sentiment analysis of Twitter data to forecast trends in stock prices. We show that an adversary can exploit the lack of provenance to indirectly use tweets to  manipulate the model's perceived sentiment about a target company and in turn force the model to forecast price erroneously. Our attack is mounted at test time and does not modify the training data. Given past market anomalies, we conclude with a series of recommendations for the use of machine learning as input signal to trading algorithms. ", "one-sentence_summary": "Replicate industry standard sentiment analysis of Twitter data for stock price forecasting, and demonstrate its vulnerability to adversarial manipulations of the model's inputs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "deza|on_the_robustness_of_sentiment_analysis_for_stock_price_forecasting", "pdf": "/pdf/e09c9c680c27d4ae123a208f4e30957460bb97f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=zz8VspX_v", "_bibtex": "@misc{\ndeza2021on,\ntitle={On the Robustness of Sentiment Analysis for Stock Price Forecasting},\nauthor={Gabriel Deza and Colin Rowat and Nicolas Papernot},\nyear={2021},\nurl={https://openreview.net/forum?id=ptbb7olhGHd}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "ptbb7olhGHd", "replyto": "ptbb7olhGHd", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2665/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538091170, "tmdate": 1606915805734, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2665/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2665/-/Official_Review"}}}, {"id": "NFfoYVJFxjn", "original": null, "number": 2, "cdate": 1603714879700, "ddate": null, "tcdate": 1603714879700, "tmdate": 1605024157749, "tddate": null, "forum": "ptbb7olhGHd", "replyto": "ptbb7olhGHd", "invitation": "ICLR.cc/2021/Conference/Paper2665/-/Official_Review", "content": {"title": "On the Robustness of Sentiment Analysis for Stock Price Forecasting", "review": "Pros: \nThe paper is clear with a significant contribution. It performed a sentiment analysis task that can predict trends in the stock market and also showed how an adversary may attack the model using tweets thereby leading to false price prediction. The methodology and the probabilistic forecasting used are excellent in my opinion. \n\nCons: \n1. The title of the paper does not describe the actual work done. I suggest that the authors may consider giving a new title to reflect the method they applied. \n2. It is unclear why the attack was done on the test stage but was not shown at implementation. That is, how would this work be reproduced or be beneficial to the community? \n\nThe following can be corrected: \n1. The claim on Page 1, Para 2 of the Introduction needs a citation (Thales used his...) \n2. On page 5, para 1, please briefly describe BERT \n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2665/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2665/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the Robustness of Sentiment Analysis for Stock Price Forecasting", "authorids": ["~Gabriel_Deza1", "c.rowat@bham.ac.uk", "~Nicolas_Papernot1"], "authors": ["Gabriel Deza", "Colin Rowat", "Nicolas Papernot"], "keywords": ["adversarial machine learning", "adversarial examples", "stock price forecasting", "finance"], "abstract": "Machine learning (ML) models are known to be vulnerable to attacks both at training and test time. Despite the extensive literature on adversarial ML, prior efforts focus primarily on applications of computer vision to object recognition or sentiment analysis to movie reviews. In these settings, the incentives for adversaries to manipulate the model's prediction are often unclear and attacks require extensive control of direct inputs to the model. This makes it difficult to evaluate how severe the impact of vulnerabilities exposed is on systems deploying ML with little provenance guarantees for the input data. In this paper, we study adversarial ML with stock price forecasting. Adversarial incentives are clear and may be quantified experimentally through a simulated portfolio.  We replicate an industry standard pipeline, which performs a sentiment analysis of Twitter data to forecast trends in stock prices. We show that an adversary can exploit the lack of provenance to indirectly use tweets to  manipulate the model's perceived sentiment about a target company and in turn force the model to forecast price erroneously. Our attack is mounted at test time and does not modify the training data. Given past market anomalies, we conclude with a series of recommendations for the use of machine learning as input signal to trading algorithms. ", "one-sentence_summary": "Replicate industry standard sentiment analysis of Twitter data for stock price forecasting, and demonstrate its vulnerability to adversarial manipulations of the model's inputs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "deza|on_the_robustness_of_sentiment_analysis_for_stock_price_forecasting", "pdf": "/pdf/e09c9c680c27d4ae123a208f4e30957460bb97f3.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=zz8VspX_v", "_bibtex": "@misc{\ndeza2021on,\ntitle={On the Robustness of Sentiment Analysis for Stock Price Forecasting},\nauthor={Gabriel Deza and Colin Rowat and Nicolas Papernot},\nyear={2021},\nurl={https://openreview.net/forum?id=ptbb7olhGHd}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "ptbb7olhGHd", "replyto": "ptbb7olhGHd", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2665/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538091170, "tmdate": 1606915805734, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2665/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2665/-/Official_Review"}}}], "count": 10}