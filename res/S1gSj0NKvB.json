{"notes": [{"id": "S1gSj0NKvB", "original": "BkeL6WYODS", "number": 1317, "cdate": 1569439388701, "ddate": null, "tcdate": 1569439388701, "tmdate": 1583912034558, "tddate": null, "forum": "S1gSj0NKvB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["renda@csail.mit.edu", "jfrankle@csail.mit.edu", "mcarbin@csail.mit.edu"], "title": "Comparing Rewinding and Fine-tuning in Neural Network Pruning", "authors": ["Alex Renda", "Jonathan Frankle", "Michael Carbin"], "pdf": "/pdf/4b5ae42dbdeee4a77dfc03a1b2bde2897565891f.pdf", "TL;DR": "Instead of fine-tuning after pruning, rewind weights or learning rate schedule to their values earlier in training and retrain from there to achieve higher accuracy when pruning neural networks.", "abstract": "Many neural network pruning algorithms proceed in three steps: train the network to completion, remove unwanted structure to compress the network, and retrain the remaining structure to recover lost accuracy. The standard retraining technique, fine-tuning, trains the unpruned weights from their final trained values using a small fixed learning rate. In this paper, we compare fine-tuning to alternative retraining techniques. Weight rewinding (as proposed by Frankle et al., (2019)), rewinds unpruned weights to their values from earlier in training and retrains them from there using the original training schedule. Learning rate rewinding (which we propose) trains the unpruned weights from their final values using the same learning rate schedule as weight rewinding. Both rewinding techniques outperform fine-tuning, forming the basis of a network-agnostic pruning algorithm that matches the accuracy and compression ratios of several more network-specific state-of-the-art techniques.\n", "code": "https://github.com/lottery-ticket/rewinding-iclr20-public", "keywords": ["pruning", "sparsity", "fine-tuning", "lottery ticket"], "paperhash": "renda|comparing_rewinding_and_finetuning_in_neural_network_pruning", "_bibtex": "@inproceedings{\nRenda2020Comparing,\ntitle={Comparing Rewinding and Fine-tuning in Neural Network Pruning},\nauthor={Alex Renda and Jonathan Frankle and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gSj0NKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/8d81302f4aaca0ae2fc48efdc3f7be4efdd39729.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "HMVBJ3aZo", "original": null, "number": 11, "cdate": 1583198591551, "ddate": null, "tcdate": 1583198591551, "tmdate": 1583198591551, "tddate": null, "forum": "S1gSj0NKvB", "replyto": "S1gSj0NKvB", "invitation": "ICLR.cc/2020/Conference/Paper1317/-/Official_Comment", "content": {"title": "Uploaded camera-ready version", "comment": "We have made the following changes to improve the paper and address concerns raised in the reviews:\n# Changes requested by reviewers\n- (Reviewers 1 and 3): We have included more networks, datasets, and pruning methods. In particular, we include structured pruning (from Li et al. [1]) and a GNMT model (from Wu et al. [2]) trained on WMT16 EN-DE.\n- (Reviewer 1): We have included an analysis of the comparison of the methods based on their resultant FLOP-counts in Appendix F.\nThese results are consistent with the results initially reported in the rebuttal.\n\n\n# Additional results\n- Since submitting the paper, we have found that an alternative version of weight rewinding, which we name learning rate rewinding (rewinding just the learning rate and not the weights), outperforms weight rewinding by a small amount. We have updated our paper to additionally include this technique. The findings in the original submission still hold, and are still presented in the updated draft -- that weight rewinding outperforms standard fine-tuning, can match state-of-the-art results achieved by more complex techniques, and performs well for a wide range of hyperparameter choices.\n\n\n[1] Li et al. Pruning Filters for Efficient ConvNets. ICLR, 2017.\n[2] Wu et al. Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation. arXiv:1609.08144, 2016."}, "signatures": ["ICLR.cc/2020/Conference/Paper1317/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1317/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["renda@csail.mit.edu", "jfrankle@csail.mit.edu", "mcarbin@csail.mit.edu"], "title": "Comparing Rewinding and Fine-tuning in Neural Network Pruning", "authors": ["Alex Renda", "Jonathan Frankle", "Michael Carbin"], "pdf": "/pdf/4b5ae42dbdeee4a77dfc03a1b2bde2897565891f.pdf", "TL;DR": "Instead of fine-tuning after pruning, rewind weights or learning rate schedule to their values earlier in training and retrain from there to achieve higher accuracy when pruning neural networks.", "abstract": "Many neural network pruning algorithms proceed in three steps: train the network to completion, remove unwanted structure to compress the network, and retrain the remaining structure to recover lost accuracy. The standard retraining technique, fine-tuning, trains the unpruned weights from their final trained values using a small fixed learning rate. In this paper, we compare fine-tuning to alternative retraining techniques. Weight rewinding (as proposed by Frankle et al., (2019)), rewinds unpruned weights to their values from earlier in training and retrains them from there using the original training schedule. Learning rate rewinding (which we propose) trains the unpruned weights from their final values using the same learning rate schedule as weight rewinding. Both rewinding techniques outperform fine-tuning, forming the basis of a network-agnostic pruning algorithm that matches the accuracy and compression ratios of several more network-specific state-of-the-art techniques.\n", "code": "https://github.com/lottery-ticket/rewinding-iclr20-public", "keywords": ["pruning", "sparsity", "fine-tuning", "lottery ticket"], "paperhash": "renda|comparing_rewinding_and_finetuning_in_neural_network_pruning", "_bibtex": "@inproceedings{\nRenda2020Comparing,\ntitle={Comparing Rewinding and Fine-tuning in Neural Network Pruning},\nauthor={Alex Renda and Jonathan Frankle and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gSj0NKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/8d81302f4aaca0ae2fc48efdc3f7be4efdd39729.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gSj0NKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1317/Authors", "ICLR.cc/2020/Conference/Paper1317/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1317/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1317/Reviewers", "ICLR.cc/2020/Conference/Paper1317/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1317/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1317/Authors|ICLR.cc/2020/Conference/Paper1317/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157854, "tmdate": 1576860554726, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1317/Authors", "ICLR.cc/2020/Conference/Paper1317/Reviewers", "ICLR.cc/2020/Conference/Paper1317/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1317/-/Official_Comment"}}}, {"id": "J4zGVDFgq", "original": null, "number": 1, "cdate": 1576798720313, "ddate": null, "tcdate": 1576798720313, "tmdate": 1576800916257, "tddate": null, "forum": "S1gSj0NKvB", "replyto": "S1gSj0NKvB", "invitation": "ICLR.cc/2020/Conference/Paper1317/-/Decision", "content": {"decision": "Accept (Talk)", "comment": "Reviewers unanimously accepted this paper. ", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["renda@csail.mit.edu", "jfrankle@csail.mit.edu", "mcarbin@csail.mit.edu"], "title": "Comparing Rewinding and Fine-tuning in Neural Network Pruning", "authors": ["Alex Renda", "Jonathan Frankle", "Michael Carbin"], "pdf": "/pdf/4b5ae42dbdeee4a77dfc03a1b2bde2897565891f.pdf", "TL;DR": "Instead of fine-tuning after pruning, rewind weights or learning rate schedule to their values earlier in training and retrain from there to achieve higher accuracy when pruning neural networks.", "abstract": "Many neural network pruning algorithms proceed in three steps: train the network to completion, remove unwanted structure to compress the network, and retrain the remaining structure to recover lost accuracy. The standard retraining technique, fine-tuning, trains the unpruned weights from their final trained values using a small fixed learning rate. In this paper, we compare fine-tuning to alternative retraining techniques. Weight rewinding (as proposed by Frankle et al., (2019)), rewinds unpruned weights to their values from earlier in training and retrains them from there using the original training schedule. Learning rate rewinding (which we propose) trains the unpruned weights from their final values using the same learning rate schedule as weight rewinding. Both rewinding techniques outperform fine-tuning, forming the basis of a network-agnostic pruning algorithm that matches the accuracy and compression ratios of several more network-specific state-of-the-art techniques.\n", "code": "https://github.com/lottery-ticket/rewinding-iclr20-public", "keywords": ["pruning", "sparsity", "fine-tuning", "lottery ticket"], "paperhash": "renda|comparing_rewinding_and_finetuning_in_neural_network_pruning", "_bibtex": "@inproceedings{\nRenda2020Comparing,\ntitle={Comparing Rewinding and Fine-tuning in Neural Network Pruning},\nauthor={Alex Renda and Jonathan Frankle and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gSj0NKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/8d81302f4aaca0ae2fc48efdc3f7be4efdd39729.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "S1gSj0NKvB", "replyto": "S1gSj0NKvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795705382, "tmdate": 1576800253148, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1317/-/Decision"}}}, {"id": "Skl8Xog0cB", "original": null, "number": 3, "cdate": 1572895518080, "ddate": null, "tcdate": 1572895518080, "tmdate": 1574891942003, "tddate": null, "forum": "S1gSj0NKvB", "replyto": "S1gSj0NKvB", "invitation": "ICLR.cc/2020/Conference/Paper1317/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "8: Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #3", "review": "*Summary*\nExtending the observations of Frankle et al. (2019, \"The Lottery Ticket Hypothesis\"), this paper examines \"rewinding\" as an alternative to fine-tuning in a typical network pruning process. After training to convergence for T iterations, the k% of weights with the smallest magnitude are pruned (set to zero). Typically, in fine-tuning, the remaining weights are continued to be trained for several more iterations at a small learning rate. With \"rewinding\", the remaining weights are reset to their values in iteration 0<=t<T and are trained for T-t iterations with the original learning rate schedule.\n\nExperiments with this method (and an iterative variant) show that (a) rewinding achieves 2-5x smaller networks matching the unpruned accuracy (with comprehensive tuning of the rewinding parameter t); (b) selection of rewinding iteration is important, but is flexible within a large range for higher sparsity pruning.\n\n*Rating*\nThe paper is very well written with good exposition, thorough notes and citations for all methodological choices,\nand an explicit statement of the limitations of the work.\n\nA few considerations relevant to the rating:\n(1) Novelty: The idea for rewinding is not novel, as acknowledged clearly in the paper. Frankle et al. (2019, \"Stabilizing the Lottery Ticket Hypothesis\") showed that rewinding to an early iteration of training (0<t<T) yielded better accuracy than rewinding to iteration t=0 for VGG-19 and ResNet-18 on CIFAR-10. However, Frankle et al. did not consider fine-tuning as it was not relevant to lottery ticket discovery. This submission studies the tradeoffs of rewinding vs. fine-tuning.\n\n(2) Thoroughness: The paper considers ResNet-20 and VGG-16 with CIFAR-10 and ResNet-50 with ImageNet. Conclusions would be strengthened with additional combinations of networks and datasets.\n\n(3) Acknowledged limitations: As noted, the paper doesn't consider any pruning criteria other than weight magnitude, nor does it consider structured pruning. The latter in particular is important for applications where prediction speed on commodity hardware is a limiting factor.\n\nAs it is, I think this paper a worthy (if limited) contribution to the understanding of network pruning.\n\n*Notes*\nTable 1/Figures *: note which dataset is used for each architecture\nFigures 2-3: It seems that many values are clipped by the legend range of +/- 0.5%. Consider showing the figure with a larger range or adding such a figure to the appendix.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"}, "signatures": ["ICLR.cc/2020/Conference/Paper1317/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1317/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["renda@csail.mit.edu", "jfrankle@csail.mit.edu", "mcarbin@csail.mit.edu"], "title": "Comparing Rewinding and Fine-tuning in Neural Network Pruning", "authors": ["Alex Renda", "Jonathan Frankle", "Michael Carbin"], "pdf": "/pdf/4b5ae42dbdeee4a77dfc03a1b2bde2897565891f.pdf", "TL;DR": "Instead of fine-tuning after pruning, rewind weights or learning rate schedule to their values earlier in training and retrain from there to achieve higher accuracy when pruning neural networks.", "abstract": "Many neural network pruning algorithms proceed in three steps: train the network to completion, remove unwanted structure to compress the network, and retrain the remaining structure to recover lost accuracy. The standard retraining technique, fine-tuning, trains the unpruned weights from their final trained values using a small fixed learning rate. In this paper, we compare fine-tuning to alternative retraining techniques. Weight rewinding (as proposed by Frankle et al., (2019)), rewinds unpruned weights to their values from earlier in training and retrains them from there using the original training schedule. Learning rate rewinding (which we propose) trains the unpruned weights from their final values using the same learning rate schedule as weight rewinding. Both rewinding techniques outperform fine-tuning, forming the basis of a network-agnostic pruning algorithm that matches the accuracy and compression ratios of several more network-specific state-of-the-art techniques.\n", "code": "https://github.com/lottery-ticket/rewinding-iclr20-public", "keywords": ["pruning", "sparsity", "fine-tuning", "lottery ticket"], "paperhash": "renda|comparing_rewinding_and_finetuning_in_neural_network_pruning", "_bibtex": "@inproceedings{\nRenda2020Comparing,\ntitle={Comparing Rewinding and Fine-tuning in Neural Network Pruning},\nauthor={Alex Renda and Jonathan Frankle and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gSj0NKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/8d81302f4aaca0ae2fc48efdc3f7be4efdd39729.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "S1gSj0NKvB", "replyto": "S1gSj0NKvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1317/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1317/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575633525637, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1317/Reviewers"], "noninvitees": [], "tcdate": 1570237739144, "tmdate": 1575633525652, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1317/-/Official_Review"}}}, {"id": "r1l5tjbjtH", "original": null, "number": 1, "cdate": 1571654529519, "ddate": null, "tcdate": 1571654529519, "tmdate": 1574278443881, "tddate": null, "forum": "S1gSj0NKvB", "replyto": "S1gSj0NKvB", "invitation": "ICLR.cc/2020/Conference/Paper1317/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #1", "review": "This paper does an in-depth evaluation of the notion of rewinding pruned networks to the weights at a previous point in training, and then re-training the pruned network from then on. This is in comparison with fine-tuning a pruned network, where the retraining continues from the network's current weights. The authors focused on vision networks and unstructured magnitude pruning in their evaluation.\n\nThe paper is well-written and easy to follow, and the authors have done a good job of empirically comparing rewinding against fine-tuning in a number of different scenarios.\n\nMy main concern with the paper is that it seems too incremental to stand on its own. Rewinding is a notion that was already explored in the Lotter Ticket Hypothesis (Frankle et al., 2019), so this paper seems to be more of an extension of that work. The take-away message from this paper (stated by authors in their conclusion) is that practicioners \"should explore rewinding as an alternative to fine-tuning for neural network pruning\", but that's a case that was already made by the LTH paper. The current work certainly gives more weight to that claim, but I don't feel the contributions are strong enough on their own to justify a full conference publication.\n\nI encourage the authors to continue working on this, as it is very interesting and can be very useful. Some ideas to make the paper stronger:\n- Given that this is a purely empirical paper, it'd be better to not limit the experiments as much. Can you run on non-vision networks? What about mobile-net? Can you try different pruning techniques? etc.\n- How do the different methods compare in terms of accuracy/sparsity versus FLOPs?\n\nFinally, two minor comments to improve the writing:\n- First sentence of 3.1: s/that meet that the accuracy/that match the accuracy/\n- First sentence of 3.1: s/than fine-tuning can/compared to fine tuning", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"}, "signatures": ["ICLR.cc/2020/Conference/Paper1317/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1317/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["renda@csail.mit.edu", "jfrankle@csail.mit.edu", "mcarbin@csail.mit.edu"], "title": "Comparing Rewinding and Fine-tuning in Neural Network Pruning", "authors": ["Alex Renda", "Jonathan Frankle", "Michael Carbin"], "pdf": "/pdf/4b5ae42dbdeee4a77dfc03a1b2bde2897565891f.pdf", "TL;DR": "Instead of fine-tuning after pruning, rewind weights or learning rate schedule to their values earlier in training and retrain from there to achieve higher accuracy when pruning neural networks.", "abstract": "Many neural network pruning algorithms proceed in three steps: train the network to completion, remove unwanted structure to compress the network, and retrain the remaining structure to recover lost accuracy. The standard retraining technique, fine-tuning, trains the unpruned weights from their final trained values using a small fixed learning rate. In this paper, we compare fine-tuning to alternative retraining techniques. Weight rewinding (as proposed by Frankle et al., (2019)), rewinds unpruned weights to their values from earlier in training and retrains them from there using the original training schedule. Learning rate rewinding (which we propose) trains the unpruned weights from their final values using the same learning rate schedule as weight rewinding. Both rewinding techniques outperform fine-tuning, forming the basis of a network-agnostic pruning algorithm that matches the accuracy and compression ratios of several more network-specific state-of-the-art techniques.\n", "code": "https://github.com/lottery-ticket/rewinding-iclr20-public", "keywords": ["pruning", "sparsity", "fine-tuning", "lottery ticket"], "paperhash": "renda|comparing_rewinding_and_finetuning_in_neural_network_pruning", "_bibtex": "@inproceedings{\nRenda2020Comparing,\ntitle={Comparing Rewinding and Fine-tuning in Neural Network Pruning},\nauthor={Alex Renda and Jonathan Frankle and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gSj0NKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/8d81302f4aaca0ae2fc48efdc3f7be4efdd39729.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "S1gSj0NKvB", "replyto": "S1gSj0NKvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1317/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1317/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575633525637, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1317/Reviewers"], "noninvitees": [], "tcdate": 1570237739144, "tmdate": 1575633525652, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1317/-/Official_Review"}}}, {"id": "BJxOXBkhiB", "original": null, "number": 1, "cdate": 1573807391821, "ddate": null, "tcdate": 1573807391821, "tmdate": 1573807566087, "tddate": null, "forum": "S1gSj0NKvB", "replyto": "S1gSj0NKvB", "invitation": "ICLR.cc/2020/Conference/Paper1317/-/Official_Comment", "content": {"title": "Response to all reviewers", "comment": "# Novelty\n\nWe believe that we didn't fully articulate the novelty of our results in the submission.\n\nWhile this paper does not present a novel algorithm, it does presents novel insight, experiments, and analysis of the behavior of an existing algorithm, all of which are outside of the scope of the algorithm's original analysis. When Frankle et al. [1] introduced rewinding, they did not evaluate the efficacy of the algorithm as a pruning technique. Instead, they use it as a technique to analyze sparse neural network stability (robustness to noise during training), rewinding to at most 30% of the way through training in their experiments. Our analysis instead rewinds all throughout training, and then compares the resulting networks to those of fine-tuning for an equivalent number of epochs. Our analysis therefore does not overlap with, and does not follow from, the analysis in their paper.\n\nOur results demonstrate that rewinding is an effective pruning technique, and in certain settings can be a higher performing drop-in replacement for fine-tuning, a claim that Frankle et al. do not propose or evaluate. Moreover, these results are not to be expected, given that rewinding goes backwards in the training processes, whereas fine-tuning adds on additional training epochs.\n\n\n# Structured pruning (Reviewers 1 and 3)\n\nWe implemented Li et al. [2]'s filter pruning technique, and compared fine-tuning and rewinding using per-layer pruning rates reported in their paper. To compare across sparsity levels, we also apply the pruning rates iteratively to obtain sparser networks. We use the rates in Table 1 in [2], specifically VGG-16-pruned-A (CIFAR), ResNet-56-pruned-{A,B} (CIFAR), ResNet-110-pruned-{A,B} (CIFAR), and ResNet-34-pruned-{A,B} (ImageNet). The rest of our hyperparameters remain identical to our original experiments.\n\nAppendix B of the updated draft of the paper presents our results. We find that rewinding outperforms fine-tuning in the structured pruning setting. At the exact sparsity levels reported in [2], the techniques are indistinguishable. However, for sparser networks, rewinding outperforms fine-tuning, both in terms of epoch-for-epoch accuracy and max achievable accuracy. These results are consistent with our findings for unstructured pruning.\n\n# Non-vision network (Reviewers 1 and 3)\n\nWe compared fine-tuning and rewinding on the GNMT model (https://arxiv.org/abs/1609.08144) in the MLPerf benchmark (https://mlperf.org/training-overview), which is a seq-to-seq model based on stacked LSTMs, trained on the WMT English-German dataset. We used NVIDIA's implementation at https://github.com/NVIDIA/DeepLearningExamples/tree/4e00153/TensorFlow/Translation/GNMT. Due to hardware and time constraints, we use hidden layer sizes of 512 units rather than 1024 units. We prune all weights using global magnitude pruning. We compare across a small set of sparsities and re-training budgets.\n\nOur results are consistent with the results for vision networks, showing that at high sparsities (80%), rewinding outperforms fine-tuning on this LSTM-based network. At lower sparsities, fine-tuning outperforms rewinding, and at medium sparsities, the two techniques behave approximately equivalently. These results match those seen for vision networks, and are visualized in Appendix C.\n\n# FLOP comparison (Reviewer 1)\n\nReviewer 1:\n> How do the different methods compare in terms of accuracy/sparsity versus FLOPs?\n\nThis is a good question. We perform this comparison and include data and discussion in Appendix D of the updated draft of the paper.\n\n\nIn sum, for one-shot pruning, we use the same initial trained network for our comparisons between both methods, and prune using the same pruning technique. This means that both networks have the exact same sparsity pattern, and therefore same number of FLOPs. For iterative pruning the networks differ, meaning the FLOPs also differ, since we use a global pruning technique. Our results show that at any given sparsity, rewinding results in lower FLOP networks than fine-tuning: the techniques are roughly equivalent at low sparsities, but rewinding results in up to a 1.25x speedup at high sparsities. We will include FLOP counts for all networks in the final version of the paper.\n\n[1] Frankle et al. Stabilizing the Lottery Ticket Hypothesis. Arxiv.\n[2] Li et al. Pruning Filters for Efficient ConvNets. ICLR, 2017."}, "signatures": ["ICLR.cc/2020/Conference/Paper1317/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1317/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["renda@csail.mit.edu", "jfrankle@csail.mit.edu", "mcarbin@csail.mit.edu"], "title": "Comparing Rewinding and Fine-tuning in Neural Network Pruning", "authors": ["Alex Renda", "Jonathan Frankle", "Michael Carbin"], "pdf": "/pdf/4b5ae42dbdeee4a77dfc03a1b2bde2897565891f.pdf", "TL;DR": "Instead of fine-tuning after pruning, rewind weights or learning rate schedule to their values earlier in training and retrain from there to achieve higher accuracy when pruning neural networks.", "abstract": "Many neural network pruning algorithms proceed in three steps: train the network to completion, remove unwanted structure to compress the network, and retrain the remaining structure to recover lost accuracy. The standard retraining technique, fine-tuning, trains the unpruned weights from their final trained values using a small fixed learning rate. In this paper, we compare fine-tuning to alternative retraining techniques. Weight rewinding (as proposed by Frankle et al., (2019)), rewinds unpruned weights to their values from earlier in training and retrains them from there using the original training schedule. Learning rate rewinding (which we propose) trains the unpruned weights from their final values using the same learning rate schedule as weight rewinding. Both rewinding techniques outperform fine-tuning, forming the basis of a network-agnostic pruning algorithm that matches the accuracy and compression ratios of several more network-specific state-of-the-art techniques.\n", "code": "https://github.com/lottery-ticket/rewinding-iclr20-public", "keywords": ["pruning", "sparsity", "fine-tuning", "lottery ticket"], "paperhash": "renda|comparing_rewinding_and_finetuning_in_neural_network_pruning", "_bibtex": "@inproceedings{\nRenda2020Comparing,\ntitle={Comparing Rewinding and Fine-tuning in Neural Network Pruning},\nauthor={Alex Renda and Jonathan Frankle and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gSj0NKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/8d81302f4aaca0ae2fc48efdc3f7be4efdd39729.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gSj0NKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1317/Authors", "ICLR.cc/2020/Conference/Paper1317/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1317/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1317/Reviewers", "ICLR.cc/2020/Conference/Paper1317/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1317/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1317/Authors|ICLR.cc/2020/Conference/Paper1317/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157854, "tmdate": 1576860554726, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1317/Authors", "ICLR.cc/2020/Conference/Paper1317/Reviewers", "ICLR.cc/2020/Conference/Paper1317/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1317/-/Official_Comment"}}}, {"id": "ryxgprk3iH", "original": null, "number": 4, "cdate": 1573807544188, "ddate": null, "tcdate": 1573807544188, "tmdate": 1573807544188, "tddate": null, "forum": "S1gSj0NKvB", "replyto": "Skl8Xog0cB", "invitation": "ICLR.cc/2020/Conference/Paper1317/-/Official_Comment", "content": {"title": "Response to Reviewer 3", "comment": "> (1) Novelty...\n\nPlease see our overall response above for a full clarification of the novelty of our work, and its relationship to others' work.\n\n> (2) Thoroughness... (3) Acknowledged limitations...\n\nPlease see the overall response above for new sets of experiments, including machine translation and structured pruning.\n\n> Notes...\n\nThanks for the notes! We will incorporate the changes in the final version of the paper.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1317/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1317/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["renda@csail.mit.edu", "jfrankle@csail.mit.edu", "mcarbin@csail.mit.edu"], "title": "Comparing Rewinding and Fine-tuning in Neural Network Pruning", "authors": ["Alex Renda", "Jonathan Frankle", "Michael Carbin"], "pdf": "/pdf/4b5ae42dbdeee4a77dfc03a1b2bde2897565891f.pdf", "TL;DR": "Instead of fine-tuning after pruning, rewind weights or learning rate schedule to their values earlier in training and retrain from there to achieve higher accuracy when pruning neural networks.", "abstract": "Many neural network pruning algorithms proceed in three steps: train the network to completion, remove unwanted structure to compress the network, and retrain the remaining structure to recover lost accuracy. The standard retraining technique, fine-tuning, trains the unpruned weights from their final trained values using a small fixed learning rate. In this paper, we compare fine-tuning to alternative retraining techniques. Weight rewinding (as proposed by Frankle et al., (2019)), rewinds unpruned weights to their values from earlier in training and retrains them from there using the original training schedule. Learning rate rewinding (which we propose) trains the unpruned weights from their final values using the same learning rate schedule as weight rewinding. Both rewinding techniques outperform fine-tuning, forming the basis of a network-agnostic pruning algorithm that matches the accuracy and compression ratios of several more network-specific state-of-the-art techniques.\n", "code": "https://github.com/lottery-ticket/rewinding-iclr20-public", "keywords": ["pruning", "sparsity", "fine-tuning", "lottery ticket"], "paperhash": "renda|comparing_rewinding_and_finetuning_in_neural_network_pruning", "_bibtex": "@inproceedings{\nRenda2020Comparing,\ntitle={Comparing Rewinding and Fine-tuning in Neural Network Pruning},\nauthor={Alex Renda and Jonathan Frankle and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gSj0NKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/8d81302f4aaca0ae2fc48efdc3f7be4efdd39729.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gSj0NKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1317/Authors", "ICLR.cc/2020/Conference/Paper1317/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1317/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1317/Reviewers", "ICLR.cc/2020/Conference/Paper1317/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1317/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1317/Authors|ICLR.cc/2020/Conference/Paper1317/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157854, "tmdate": 1576860554726, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1317/Authors", "ICLR.cc/2020/Conference/Paper1317/Reviewers", "ICLR.cc/2020/Conference/Paper1317/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1317/-/Official_Comment"}}}, {"id": "ryg4srJnoH", "original": null, "number": 3, "cdate": 1573807515797, "ddate": null, "tcdate": 1573807515797, "tmdate": 1573807515797, "tddate": null, "forum": "S1gSj0NKvB", "replyto": "r1g3S9Nycr", "invitation": "ICLR.cc/2020/Conference/Paper1317/-/Official_Comment", "content": {"title": "Response to Reviewer 2", "comment": "> However, the paper itself is light on novelty...\n\nPlease see our overall response above for a full clarification of the novelty of our work, and its relationship to others' work.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1317/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1317/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["renda@csail.mit.edu", "jfrankle@csail.mit.edu", "mcarbin@csail.mit.edu"], "title": "Comparing Rewinding and Fine-tuning in Neural Network Pruning", "authors": ["Alex Renda", "Jonathan Frankle", "Michael Carbin"], "pdf": "/pdf/4b5ae42dbdeee4a77dfc03a1b2bde2897565891f.pdf", "TL;DR": "Instead of fine-tuning after pruning, rewind weights or learning rate schedule to their values earlier in training and retrain from there to achieve higher accuracy when pruning neural networks.", "abstract": "Many neural network pruning algorithms proceed in three steps: train the network to completion, remove unwanted structure to compress the network, and retrain the remaining structure to recover lost accuracy. The standard retraining technique, fine-tuning, trains the unpruned weights from their final trained values using a small fixed learning rate. In this paper, we compare fine-tuning to alternative retraining techniques. Weight rewinding (as proposed by Frankle et al., (2019)), rewinds unpruned weights to their values from earlier in training and retrains them from there using the original training schedule. Learning rate rewinding (which we propose) trains the unpruned weights from their final values using the same learning rate schedule as weight rewinding. Both rewinding techniques outperform fine-tuning, forming the basis of a network-agnostic pruning algorithm that matches the accuracy and compression ratios of several more network-specific state-of-the-art techniques.\n", "code": "https://github.com/lottery-ticket/rewinding-iclr20-public", "keywords": ["pruning", "sparsity", "fine-tuning", "lottery ticket"], "paperhash": "renda|comparing_rewinding_and_finetuning_in_neural_network_pruning", "_bibtex": "@inproceedings{\nRenda2020Comparing,\ntitle={Comparing Rewinding and Fine-tuning in Neural Network Pruning},\nauthor={Alex Renda and Jonathan Frankle and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gSj0NKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/8d81302f4aaca0ae2fc48efdc3f7be4efdd39729.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gSj0NKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1317/Authors", "ICLR.cc/2020/Conference/Paper1317/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1317/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1317/Reviewers", "ICLR.cc/2020/Conference/Paper1317/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1317/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1317/Authors|ICLR.cc/2020/Conference/Paper1317/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157854, "tmdate": 1576860554726, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1317/Authors", "ICLR.cc/2020/Conference/Paper1317/Reviewers", "ICLR.cc/2020/Conference/Paper1317/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1317/-/Official_Comment"}}}, {"id": "HyxKYBJhoB", "original": null, "number": 2, "cdate": 1573807488687, "ddate": null, "tcdate": 1573807488687, "tmdate": 1573807488687, "tddate": null, "forum": "S1gSj0NKvB", "replyto": "r1l5tjbjtH", "invitation": "ICLR.cc/2020/Conference/Paper1317/-/Official_Comment", "content": {"title": "Response to Reviewer 1", "comment": "> My main concern with the paper is that it seems too incremental to stand on its own...\n\nFrankle et al. do not make the case that practitioners should explore rewinding as an alternative to fine-tuning, as they do not provide any comparisons against fine-tuning. Please see our overall response above for a full clarification of the novelty of our work, and its relationship to others' work.\n\n> Given that this is a purely empirical paper, it'd be better to not limit the experiments as much...\n\nPlease see the overall response above for new sets of experiments, including machine translation and structured pruning.\n\n> How do the different methods compare in terms of accuracy/sparsity versus FLOPs?\n\nThis is a great question, and drew out an interesting set of new results, which are included in the overall response above.\n\n> Finally, two minor comments to improve the writing...\n\nThanks for the feedback! We have incorporated the changes.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1317/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1317/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["renda@csail.mit.edu", "jfrankle@csail.mit.edu", "mcarbin@csail.mit.edu"], "title": "Comparing Rewinding and Fine-tuning in Neural Network Pruning", "authors": ["Alex Renda", "Jonathan Frankle", "Michael Carbin"], "pdf": "/pdf/4b5ae42dbdeee4a77dfc03a1b2bde2897565891f.pdf", "TL;DR": "Instead of fine-tuning after pruning, rewind weights or learning rate schedule to their values earlier in training and retrain from there to achieve higher accuracy when pruning neural networks.", "abstract": "Many neural network pruning algorithms proceed in three steps: train the network to completion, remove unwanted structure to compress the network, and retrain the remaining structure to recover lost accuracy. The standard retraining technique, fine-tuning, trains the unpruned weights from their final trained values using a small fixed learning rate. In this paper, we compare fine-tuning to alternative retraining techniques. Weight rewinding (as proposed by Frankle et al., (2019)), rewinds unpruned weights to their values from earlier in training and retrains them from there using the original training schedule. Learning rate rewinding (which we propose) trains the unpruned weights from their final values using the same learning rate schedule as weight rewinding. Both rewinding techniques outperform fine-tuning, forming the basis of a network-agnostic pruning algorithm that matches the accuracy and compression ratios of several more network-specific state-of-the-art techniques.\n", "code": "https://github.com/lottery-ticket/rewinding-iclr20-public", "keywords": ["pruning", "sparsity", "fine-tuning", "lottery ticket"], "paperhash": "renda|comparing_rewinding_and_finetuning_in_neural_network_pruning", "_bibtex": "@inproceedings{\nRenda2020Comparing,\ntitle={Comparing Rewinding and Fine-tuning in Neural Network Pruning},\nauthor={Alex Renda and Jonathan Frankle and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gSj0NKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/8d81302f4aaca0ae2fc48efdc3f7be4efdd39729.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1gSj0NKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1317/Authors", "ICLR.cc/2020/Conference/Paper1317/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1317/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1317/Reviewers", "ICLR.cc/2020/Conference/Paper1317/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1317/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1317/Authors|ICLR.cc/2020/Conference/Paper1317/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157854, "tmdate": 1576860554726, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1317/Authors", "ICLR.cc/2020/Conference/Paper1317/Reviewers", "ICLR.cc/2020/Conference/Paper1317/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1317/-/Official_Comment"}}}, {"id": "r1g3S9Nycr", "original": null, "number": 2, "cdate": 1571928643954, "ddate": null, "tcdate": 1571928643954, "tmdate": 1572972484554, "tddate": null, "forum": "S1gSj0NKvB", "replyto": "S1gSj0NKvB", "invitation": "ICLR.cc/2020/Conference/Paper1317/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Building on the results of [Frankle et al, 2019], this paper seeks to utilize rewinding as a core procedure in pruning neural networks, in combination with the usual fine-tuning procedures.  Specifically, [Frankle et al, 2019] demonstrate that it is possible to find sparse subnetworks, such that rewinding weights to their initial values and retraining from that initialization, yields test accuracy similar to the original network.  While this is already a form of pruning, the submitted paper explores a wider space of pruning procedures that utilize rewinding as a subroutine.\n\nThis wider framework includes the choice of rewind point (e.g. rewinding to partway through training rather than to initialization) and how to balance computation budget between rewinding (and retraining for an equivalent number of epochs) vs continuing to fine-tune a network.  Experiments cover this hyperparameter space, as well as the range of desired sparsity level (pruning amount).  Results show rewinding (to a point 30% - 60% into training) dominates any amount of fine-tuning, if moderate to high sparsity is desired.\n\nThe empirical study conducted by this paper is useful and complements the results previously reported in [Frankle et al, 2019].  However, the paper itself is light on novelty, as the core ideas were already established by [Frankle et al], and the application of them here is relatively straightforward.  The extensive experiments here add value to the conversation about the lottery ticket hypothesis, but are not otherwise ground-breaking.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1317/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1317/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["renda@csail.mit.edu", "jfrankle@csail.mit.edu", "mcarbin@csail.mit.edu"], "title": "Comparing Rewinding and Fine-tuning in Neural Network Pruning", "authors": ["Alex Renda", "Jonathan Frankle", "Michael Carbin"], "pdf": "/pdf/4b5ae42dbdeee4a77dfc03a1b2bde2897565891f.pdf", "TL;DR": "Instead of fine-tuning after pruning, rewind weights or learning rate schedule to their values earlier in training and retrain from there to achieve higher accuracy when pruning neural networks.", "abstract": "Many neural network pruning algorithms proceed in three steps: train the network to completion, remove unwanted structure to compress the network, and retrain the remaining structure to recover lost accuracy. The standard retraining technique, fine-tuning, trains the unpruned weights from their final trained values using a small fixed learning rate. In this paper, we compare fine-tuning to alternative retraining techniques. Weight rewinding (as proposed by Frankle et al., (2019)), rewinds unpruned weights to their values from earlier in training and retrains them from there using the original training schedule. Learning rate rewinding (which we propose) trains the unpruned weights from their final values using the same learning rate schedule as weight rewinding. Both rewinding techniques outperform fine-tuning, forming the basis of a network-agnostic pruning algorithm that matches the accuracy and compression ratios of several more network-specific state-of-the-art techniques.\n", "code": "https://github.com/lottery-ticket/rewinding-iclr20-public", "keywords": ["pruning", "sparsity", "fine-tuning", "lottery ticket"], "paperhash": "renda|comparing_rewinding_and_finetuning_in_neural_network_pruning", "_bibtex": "@inproceedings{\nRenda2020Comparing,\ntitle={Comparing Rewinding and Fine-tuning in Neural Network Pruning},\nauthor={Alex Renda and Jonathan Frankle and Michael Carbin},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1gSj0NKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/8d81302f4aaca0ae2fc48efdc3f7be4efdd39729.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "S1gSj0NKvB", "replyto": "S1gSj0NKvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1317/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1317/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575633525637, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1317/Reviewers"], "noninvitees": [], "tcdate": 1570237739144, "tmdate": 1575633525652, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1317/-/Official_Review"}}}], "count": 10}