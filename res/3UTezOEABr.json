{"notes": [{"id": "3UTezOEABr", "original": "jN7ezNj8Vnk", "number": 2493, "cdate": 1601308275650, "ddate": null, "tcdate": 1601308275650, "tmdate": 1614985697639, "tddate": null, "forum": "3UTezOEABr", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "TimeAutoML: Autonomous Representation Learning for Multivariate Irregularly  Sampled Time Series", "authorids": ["yangjiao@tongji.edu.cn", "~Kai_Yang3", "shaoyu@tongji.edu.cn", "lp@tongji.edu.cn", "~Sijia_Liu1", "~Dongjin_Song2"], "authors": ["Yang Jiao", "Kai Yang", "shaoyu dou", "pan luo", "Sijia Liu", "Dongjin Song"], "keywords": ["representation learning", "AutoML", "irregularly sampled time series", "anomaly detection", "clustering"], "abstract": "Multivariate time series (MTS) data are becoming increasingly ubiquitous in diverse domains, e.g., IoT systems, health informatics, and 5G networks. To obtain an effective representation of MTS data, it is not only essential to consider unpredictable dynamics and highly variable lengths of these data but also important to address the irregularities in the sampling rates of MTS. Existing parametric approaches rely on manual hyperparameter tuning and may cost a huge amount of labor effort. Therefore, it is desirable to learn the representation automatically and efficiently. To this end, we propose an autonomous representation learning approach for multivariate time series (TimeAutoML) with irregular sampling rates and variable lengths. As opposed to previous works, we first present a representation learning pipeline in which the configuration and hyperparameter optimization\nare fully automatic and can be tailored for various tasks, e.g., anomaly detection, clustering, etc. Next, a negative sample generation approach and an auxiliary classification task are developed and integrated within TimeAutoML to enhance\nits representation capability. Extensive empirical studies on real-world datasets demonstrate that the proposed TimeAutoML outperforms competing approaches on various tasks by a large margin. In fact, it achieves the best anomaly detection\nperformance among all comparison algorithms on 78 out of all 85 UCR datasets, acquiring up to 20% performance improvement in terms of AUC score.", "one-sentence_summary": "This paper presents an autonomous representation learning approach for multivariate irregularly  sampled time series. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "jiao|timeautoml_autonomous_representation_learning_for_multivariate_irregularly_sampled_time_series", "pdf": "/pdf/07e9b62da12f86427970c15dfd458283541c23c1.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=6k1M5y8erZ", "_bibtex": "@misc{\njiao2021timeautoml,\ntitle={TimeAuto{\\{}ML{\\}}: Autonomous Representation Learning for Multivariate Irregularly  Sampled Time Series},\nauthor={Yang Jiao and Kai Yang and shaoyu dou and pan luo and Sijia Liu and Dongjin Song},\nyear={2021},\nurl={https://openreview.net/forum?id=3UTezOEABr}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "uuRm_sl0SrT", "original": null, "number": 1, "cdate": 1610040448980, "ddate": null, "tcdate": 1610040448980, "tmdate": 1610474051035, "tddate": null, "forum": "3UTezOEABr", "replyto": "3UTezOEABr", "invitation": "ICLR.cc/2021/Conference/Paper2493/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The paper introduces an AutoML method for irregular multivariate time series.   The method automates the selection of the configuration as well as the hyperparameter optimization depending on the task. A Bayesian approach handles the network structure search while VAEs + attention is used to learn  representations from irregularly sampled data. There is an additional contribution: anomaly detection via a sample energy function from a GMM on time windows.\n\nWhile there is some novelty in the proposed approach, mostly in the way in which existing techniques are combined, the paper also has some limitations:\n- running the framework over the set of possible models is computationally intensive; in their response, the authors indicate the search space can be constrained, however, doing so would also decrease the performance; in AutoML, added complexity cannot be avoided, but there is no notion of how much longer it takes to find suitable models compared to taking off-the-shelf methods.\n- although the paper is geared towards irregularly sampled time series, there are no experiments where the data is naturally irregularly samples; artificially introduced patterns are no substitute for this; (PhysioNet, as suggested by one of the reviewers or MIMIC III both have this type of data and are frequently used in benchmarks)\n- AutoML is presented as a general framework, but mostly handles clustering and anomaly detection;  unclear of how useful it would be for forecasting or regression; classification realists are shown in Appendix F against simple baselines (GRU-D is not considered, for instance) and even so AutoML does not achieve state of the art results in half of the cases"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "TimeAutoML: Autonomous Representation Learning for Multivariate Irregularly  Sampled Time Series", "authorids": ["yangjiao@tongji.edu.cn", "~Kai_Yang3", "shaoyu@tongji.edu.cn", "lp@tongji.edu.cn", "~Sijia_Liu1", "~Dongjin_Song2"], "authors": ["Yang Jiao", "Kai Yang", "shaoyu dou", "pan luo", "Sijia Liu", "Dongjin Song"], "keywords": ["representation learning", "AutoML", "irregularly sampled time series", "anomaly detection", "clustering"], "abstract": "Multivariate time series (MTS) data are becoming increasingly ubiquitous in diverse domains, e.g., IoT systems, health informatics, and 5G networks. To obtain an effective representation of MTS data, it is not only essential to consider unpredictable dynamics and highly variable lengths of these data but also important to address the irregularities in the sampling rates of MTS. Existing parametric approaches rely on manual hyperparameter tuning and may cost a huge amount of labor effort. Therefore, it is desirable to learn the representation automatically and efficiently. To this end, we propose an autonomous representation learning approach for multivariate time series (TimeAutoML) with irregular sampling rates and variable lengths. As opposed to previous works, we first present a representation learning pipeline in which the configuration and hyperparameter optimization\nare fully automatic and can be tailored for various tasks, e.g., anomaly detection, clustering, etc. Next, a negative sample generation approach and an auxiliary classification task are developed and integrated within TimeAutoML to enhance\nits representation capability. Extensive empirical studies on real-world datasets demonstrate that the proposed TimeAutoML outperforms competing approaches on various tasks by a large margin. In fact, it achieves the best anomaly detection\nperformance among all comparison algorithms on 78 out of all 85 UCR datasets, acquiring up to 20% performance improvement in terms of AUC score.", "one-sentence_summary": "This paper presents an autonomous representation learning approach for multivariate irregularly  sampled time series. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "jiao|timeautoml_autonomous_representation_learning_for_multivariate_irregularly_sampled_time_series", "pdf": "/pdf/07e9b62da12f86427970c15dfd458283541c23c1.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=6k1M5y8erZ", "_bibtex": "@misc{\njiao2021timeautoml,\ntitle={TimeAuto{\\{}ML{\\}}: Autonomous Representation Learning for Multivariate Irregularly  Sampled Time Series},\nauthor={Yang Jiao and Kai Yang and shaoyu dou and pan luo and Sijia Liu and Dongjin Song},\nyear={2021},\nurl={https://openreview.net/forum?id=3UTezOEABr}\n}"}, "tags": [], "invitation": {"reply": {"forum": "3UTezOEABr", "replyto": "3UTezOEABr", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040448968, "tmdate": 1610474051020, "id": "ICLR.cc/2021/Conference/Paper2493/-/Decision"}}}, {"id": "aDKFKTlQFDM", "original": null, "number": 1, "cdate": 1603420438031, "ddate": null, "tcdate": 1603420438031, "tmdate": 1606770992470, "tddate": null, "forum": "3UTezOEABr", "replyto": "3UTezOEABr", "invitation": "ICLR.cc/2021/Conference/Paper2493/-/Official_Review", "content": {"title": "Interesting results but lack of novelty and motivations", "review": "I carefully read the paper and it was interesting.\nThe results seem promising; however, the novelty and motivations are not that satisfied.\nDetailed comments are as follows.\n\n1. Challenge 1 (Trial / Error)\n- I think the first challenge (trial/error) is usual and many hyper-parameter tuning algorithms and tools are available. For instance, https://cloud.google.com/ai-platform/training/docs/using-hyperparameter-tuning\n- I am not sure how the proposed method is compared with other AutoML frameworks and hyper-parameter tuning methods?\n- Also, I am not sure what is \"special\" for AutoML for time-series technically.\n- The methodology is the same with previous Thomson sampling and Bayesian optimization.\u00a0\n\n2. Challenge 2: Irregularly sampled time-series\n- What do you think if we combine time-series imputation and previous time-series representation\u00a0learnings?\n- In that case, most time-series models can be directly applicable after imputation.\u00a0\n- Note that there are various imputation and interpolation methods for time-series data.\n- I think this can be an important baseline to be compared with.\n- Also, what is the proposed component for dealing with irregularly sampled data?\n\n3. Challenge\u00a03: Contrastive learning\n- I am not sure why contrastive learning is good for time-series.\n- And why does it guarantee suboptimal performance?\n- If you have some motivations, please provide it in the revised manuscript.\n\n4. Figure 1\n- It is not easy to understand the key ideas in figure 1.\n- There are too many equations but only one sentence in the caption.\n- So, in the revised manuscript, it would be great to improve the readability of this figure with enough caption for the readers.\n\n5. Motivations\n- Equation (3): Can you explain why you select y_i as the representation? It is not well motivated.\n- EM algorithm: Can you explain why EM algorithm is necessary for this?\n- RNNs: Why the RNNs can be used for the encoder and decoders?\n- Many selections in this paper have no underlying motivations even though there are many \"blocks\" in the proposed method.\n\n6. Novelty\n- I am not sure what is the novelty of this paper.\n- As can be seen in equation (8), it seems like the proposed model are some combinations of previous methods.\n- AutoML is definitely not the novel part because the authors utilize Thomson sampling and Bayesian optimization.\n- It would be great if the authors can clarify the novelty of this paper.\n\n7. Lambda 1 and Lambda 2\n- How to optimize those two critical hyper-parameters?\n- It would be good to add more ablation studies to check how much gain does each component in Equation (8) provide. Currently, I can only see the results without L_self.\n\n8. Datasets\n- In the title, abstract, and introduction, the authors highlight the \"multi-variate\" time-series.\u00a0\n- However, in the experiments, the authors provide the results on mostly univariate time-series dataset.\n- If the proposed model is scalable, it would be great to show the results on various multi-variate\u00a0and highly irregular time-series datasets.\u00a0\n- Here, it would be better if you use the dataset which already has missing components.\n\n9. Fair comparison\n- It is unclear how the authors optimize the hyper-parameters of other methods.\n- If the proposed method is well optimized (among various hyper-parameter sets) but the baselines do not, it is not a fair comparison.\n\n10. Computational load\n- AutoML takes much more computational load.\u00a0\n- It would be good to quantitatively analyze the computational complexity of the proposed method compared with other methods.\n\n11. Benchmarks\n- I think the benchmarks are too limited.\u00a0\n- The authors should provide various \"time-series\" clustering and anomaly detection algorithms as the benchmarks.\n- For instance, various algorithms in\u00a0https://blog.statsbot.co/time-series-anomaly-detection-algorithms-1cef5519aef2.\n- Note that K-mean, GMM type of things are not designed for time-series.\n\n----------------------After reading the rebuttals-------------------------------\n\nThanks authors for the detailed response to my review.\nUnfortunately, the responses are not satisfactory for me to increase the score.\nTherefore, I stand on my initial score (4) as my final score.\nThe below are the reasons for this.\n\n1. The authors failed to provide the comparison with other AutoML papers on time-series.\n2. Imputation/Interpolation is a basic data preprocessing step. Also, the additional complexity for the imputation is marginal (especially compared with AutoML). Therefore, excluding the comparisons with imputation is hard to be accepted.\n3. There are a bunch of self-supervised learning methods. It is unclear what is the motivation that the authors utilize \"contrastive learning\" as the self-supervised learning methods.\u00a0\n4. Also, motivations of many decisions in this paper are still missing. I think I am not the only person that raised this problem.\n5. I asked for \"quantitative\" analyses on computational complexity. However, I cannot find the \"quantitative\" analyses in the revised manuscript and rebuttals for the computational complexity.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2493/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2493/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "TimeAutoML: Autonomous Representation Learning for Multivariate Irregularly  Sampled Time Series", "authorids": ["yangjiao@tongji.edu.cn", "~Kai_Yang3", "shaoyu@tongji.edu.cn", "lp@tongji.edu.cn", "~Sijia_Liu1", "~Dongjin_Song2"], "authors": ["Yang Jiao", "Kai Yang", "shaoyu dou", "pan luo", "Sijia Liu", "Dongjin Song"], "keywords": ["representation learning", "AutoML", "irregularly sampled time series", "anomaly detection", "clustering"], "abstract": "Multivariate time series (MTS) data are becoming increasingly ubiquitous in diverse domains, e.g., IoT systems, health informatics, and 5G networks. To obtain an effective representation of MTS data, it is not only essential to consider unpredictable dynamics and highly variable lengths of these data but also important to address the irregularities in the sampling rates of MTS. Existing parametric approaches rely on manual hyperparameter tuning and may cost a huge amount of labor effort. Therefore, it is desirable to learn the representation automatically and efficiently. To this end, we propose an autonomous representation learning approach for multivariate time series (TimeAutoML) with irregular sampling rates and variable lengths. As opposed to previous works, we first present a representation learning pipeline in which the configuration and hyperparameter optimization\nare fully automatic and can be tailored for various tasks, e.g., anomaly detection, clustering, etc. Next, a negative sample generation approach and an auxiliary classification task are developed and integrated within TimeAutoML to enhance\nits representation capability. Extensive empirical studies on real-world datasets demonstrate that the proposed TimeAutoML outperforms competing approaches on various tasks by a large margin. In fact, it achieves the best anomaly detection\nperformance among all comparison algorithms on 78 out of all 85 UCR datasets, acquiring up to 20% performance improvement in terms of AUC score.", "one-sentence_summary": "This paper presents an autonomous representation learning approach for multivariate irregularly  sampled time series. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "jiao|timeautoml_autonomous_representation_learning_for_multivariate_irregularly_sampled_time_series", "pdf": "/pdf/07e9b62da12f86427970c15dfd458283541c23c1.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=6k1M5y8erZ", "_bibtex": "@misc{\njiao2021timeautoml,\ntitle={TimeAuto{\\{}ML{\\}}: Autonomous Representation Learning for Multivariate Irregularly  Sampled Time Series},\nauthor={Yang Jiao and Kai Yang and shaoyu dou and pan luo and Sijia Liu and Dongjin Song},\nyear={2021},\nurl={https://openreview.net/forum?id=3UTezOEABr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "3UTezOEABr", "replyto": "3UTezOEABr", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2493/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538095141, "tmdate": 1606915786451, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2493/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2493/-/Official_Review"}}}, {"id": "y3oTsxRIjFJ", "original": null, "number": 6, "cdate": 1606052395852, "ddate": null, "tcdate": 1606052395852, "tmdate": 1606052395852, "tddate": null, "forum": "3UTezOEABr", "replyto": "aDKFKTlQFDM", "invitation": "ICLR.cc/2021/Conference/Paper2493/-/Official_Comment", "content": {"title": "Response to Reviewer 2", "comment": "Thank you very much for your constructive suggestions. We give point-to-point response as follows:\n\n(1)\tThe proposed work differs significantly from the hyperparameters tuning algorithms you mentioned. First, we alternatively optimize the AutoML pipeline (unsupervised representation learning pipeline) and hyperparameters, rather than just optimize the hyperparameters. There are few AutoML works addressing machine learning tasks for time series, the proposed work is the first that constructs an AutoML framework for time series unsupervised representation learning. Please notice that our emphasis is not regard designing a more efficient Thomson sampling or Bayesian optimization algorithm. Instead, our focus is on utilizing the TS + BO for alternatively constructing the AutoML pipeline and optimizing the hyperparameters.\n\n(2)\tWe can certainly consider imputation in the time series analysis. However, this will incur additional computational complexity. In contrast, the proposed work does not require any imputation and can achieve excellent performance in the presence of missing data.  For fair comparison, we did not consider the imputation in the experiment. Actually, in most experiments, it is seen that the performance of TimeAutoML model degrades only slightly in the presence of irregular sampling. \n\n(3)\tThank you for this comment. We did not mention that \u201ccontrastive learning guarantees suboptimal performance\u201d. As far as we know, there are few works utilizing the contrastive methods for time series problems. The motivation is that we try to introduce a self-supervised contrastive loss to enhance unsupervised representation learning.\n\n(4)\tWe have updated the caption in Figure 1, which gives more details about the framework as shown in the revised version.\n\n(5)\tThe proposed model encodes the original time series into the latent space, and we combine the encoder hidden states h_i and reconstruction error z_i as the representation y_i. EM algorithm is then invoked to train of GMM. The reason about why we choose RNN as the encoder and decoder is that RNN are commonly used and very effective in capturing the temporal dynamics in time series data.\n\n(6)\tTo the best of our knowledge, there are few AutoML works addressing time series analysis, no prior works have considered AutoML framework for time series unsupervised representation learning. Moreover, a new self-supervised contrastive loss is proposed to enhance representation learning ability. \n\n(7)\tWe have analyzed the sensitivity about lambda 1 and lambda 2, which is detailed in Appendix G.\n\n(8)\tA substantial amount of experiments have been conducted based on different multivariate time series datasets, e.g., FingerMovements, LSST, RacketSports, PhonemeSpectra, Heartbeat, and so on. More details can be found in the experiments. \n\n(9)\tWe have optimized the hyperparameters of the state-of-the-art methods by grid-search. The proposed TimeAutoML combines an automatic pipeline construction and hyperparameter optimization, thus achieves excellent performance.\n\n(10)\tPlease note that the machine learning model obtained by TimeAutoML is not necessarily of higher computational complexity than those obtained by the traditional methods. We agree that the model searching process of TimeAutoML may incur additional computational complexity than the traditional methods. In the experiments, it turns out the searching process does not take much time because the searching algorithm is quite efficient. In addition, methods such as early stopping can help speed up the training process and obtain a model more efficiently in practice. \n\n(11)\tWe have compared our model with state-of-the-art methods for time series analysis. For anomaly detection, we utilized BeatGAN (2019 IJCAI) and Latent ODE (2019 NIPS) as the benchmarks. For the clustering task, we utilized SPIRAL (2019 IJCAI) and DTCR (2019 NIPS) as the benchmarks.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2493/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2493/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "TimeAutoML: Autonomous Representation Learning for Multivariate Irregularly  Sampled Time Series", "authorids": ["yangjiao@tongji.edu.cn", "~Kai_Yang3", "shaoyu@tongji.edu.cn", "lp@tongji.edu.cn", "~Sijia_Liu1", "~Dongjin_Song2"], "authors": ["Yang Jiao", "Kai Yang", "shaoyu dou", "pan luo", "Sijia Liu", "Dongjin Song"], "keywords": ["representation learning", "AutoML", "irregularly sampled time series", "anomaly detection", "clustering"], "abstract": "Multivariate time series (MTS) data are becoming increasingly ubiquitous in diverse domains, e.g., IoT systems, health informatics, and 5G networks. To obtain an effective representation of MTS data, it is not only essential to consider unpredictable dynamics and highly variable lengths of these data but also important to address the irregularities in the sampling rates of MTS. Existing parametric approaches rely on manual hyperparameter tuning and may cost a huge amount of labor effort. Therefore, it is desirable to learn the representation automatically and efficiently. To this end, we propose an autonomous representation learning approach for multivariate time series (TimeAutoML) with irregular sampling rates and variable lengths. As opposed to previous works, we first present a representation learning pipeline in which the configuration and hyperparameter optimization\nare fully automatic and can be tailored for various tasks, e.g., anomaly detection, clustering, etc. Next, a negative sample generation approach and an auxiliary classification task are developed and integrated within TimeAutoML to enhance\nits representation capability. Extensive empirical studies on real-world datasets demonstrate that the proposed TimeAutoML outperforms competing approaches on various tasks by a large margin. In fact, it achieves the best anomaly detection\nperformance among all comparison algorithms on 78 out of all 85 UCR datasets, acquiring up to 20% performance improvement in terms of AUC score.", "one-sentence_summary": "This paper presents an autonomous representation learning approach for multivariate irregularly  sampled time series. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "jiao|timeautoml_autonomous_representation_learning_for_multivariate_irregularly_sampled_time_series", "pdf": "/pdf/07e9b62da12f86427970c15dfd458283541c23c1.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=6k1M5y8erZ", "_bibtex": "@misc{\njiao2021timeautoml,\ntitle={TimeAuto{\\{}ML{\\}}: Autonomous Representation Learning for Multivariate Irregularly  Sampled Time Series},\nauthor={Yang Jiao and Kai Yang and shaoyu dou and pan luo and Sijia Liu and Dongjin Song},\nyear={2021},\nurl={https://openreview.net/forum?id=3UTezOEABr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "3UTezOEABr", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2493/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2493/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2493/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2493/Authors|ICLR.cc/2021/Conference/Paper2493/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2493/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923847764, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2493/-/Official_Comment"}}}, {"id": "Y2JPyJwZdGE", "original": null, "number": 5, "cdate": 1606052328477, "ddate": null, "tcdate": 1606052328477, "tmdate": 1606052328477, "tddate": null, "forum": "3UTezOEABr", "replyto": "96xIeYoxzX5", "invitation": "ICLR.cc/2021/Conference/Paper2493/-/Official_Comment", "content": {"title": "Response to Reviewer 1", "comment": "Thank you for your comments and suggestions.  We give a point-to-point response as follows. \n\n(1)\tMotivation. AutoML for time series analysis is a less-explored topic. As far as we are aware of, no prior works have considered AutoML for time series representation learning. Moreover, we propose a new self-supervised contrastive loss to enhance the model representation learning ability. These constitute two major contributions of our work.  \n\n(2)\tIrregularly sampled time series. What we emphasize on in this paper is a special type of irregularly sampled time series. We have made the classification in the revised manuscript. The experiments are conducted on UCR/UEA datasets with missing timestamps. More details have been given in Appendix E.\n\n(3)\tRepresentation learning. We really appreciate your comment. The representation learned from this framework can be used for other downstream tasks. We show the classification results of TimeAutoML in Appendix F.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2493/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2493/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "TimeAutoML: Autonomous Representation Learning for Multivariate Irregularly  Sampled Time Series", "authorids": ["yangjiao@tongji.edu.cn", "~Kai_Yang3", "shaoyu@tongji.edu.cn", "lp@tongji.edu.cn", "~Sijia_Liu1", "~Dongjin_Song2"], "authors": ["Yang Jiao", "Kai Yang", "shaoyu dou", "pan luo", "Sijia Liu", "Dongjin Song"], "keywords": ["representation learning", "AutoML", "irregularly sampled time series", "anomaly detection", "clustering"], "abstract": "Multivariate time series (MTS) data are becoming increasingly ubiquitous in diverse domains, e.g., IoT systems, health informatics, and 5G networks. To obtain an effective representation of MTS data, it is not only essential to consider unpredictable dynamics and highly variable lengths of these data but also important to address the irregularities in the sampling rates of MTS. Existing parametric approaches rely on manual hyperparameter tuning and may cost a huge amount of labor effort. Therefore, it is desirable to learn the representation automatically and efficiently. To this end, we propose an autonomous representation learning approach for multivariate time series (TimeAutoML) with irregular sampling rates and variable lengths. As opposed to previous works, we first present a representation learning pipeline in which the configuration and hyperparameter optimization\nare fully automatic and can be tailored for various tasks, e.g., anomaly detection, clustering, etc. Next, a negative sample generation approach and an auxiliary classification task are developed and integrated within TimeAutoML to enhance\nits representation capability. Extensive empirical studies on real-world datasets demonstrate that the proposed TimeAutoML outperforms competing approaches on various tasks by a large margin. In fact, it achieves the best anomaly detection\nperformance among all comparison algorithms on 78 out of all 85 UCR datasets, acquiring up to 20% performance improvement in terms of AUC score.", "one-sentence_summary": "This paper presents an autonomous representation learning approach for multivariate irregularly  sampled time series. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "jiao|timeautoml_autonomous_representation_learning_for_multivariate_irregularly_sampled_time_series", "pdf": "/pdf/07e9b62da12f86427970c15dfd458283541c23c1.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=6k1M5y8erZ", "_bibtex": "@misc{\njiao2021timeautoml,\ntitle={TimeAuto{\\{}ML{\\}}: Autonomous Representation Learning for Multivariate Irregularly  Sampled Time Series},\nauthor={Yang Jiao and Kai Yang and shaoyu dou and pan luo and Sijia Liu and Dongjin Song},\nyear={2021},\nurl={https://openreview.net/forum?id=3UTezOEABr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "3UTezOEABr", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2493/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2493/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2493/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2493/Authors|ICLR.cc/2021/Conference/Paper2493/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2493/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923847764, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2493/-/Official_Comment"}}}, {"id": "gKZwDDrnJ_U", "original": null, "number": 4, "cdate": 1606052287806, "ddate": null, "tcdate": 1606052287806, "tmdate": 1606052287806, "tddate": null, "forum": "3UTezOEABr", "replyto": "JA186rnDH2A", "invitation": "ICLR.cc/2021/Conference/Paper2493/-/Official_Comment", "content": {"title": "Response to Reviewer 4", "comment": "Thank you for your constructive comments. Per your suggestions, we have made the following modifications:\n\n(1)\tWe employ the GMM model to characterize the latent space representation distribution of the input data for two reasons. First, GMM is a flexible and powerful model that has been proved to be capable of approximating any continuous distribution arbitrarily well under mild assumptions. Second, once we obtain a GMM model using the training data, we can calculate the distances between an input time series and the centroids of GMM in the latent space, which are proportional to the sample energy function. Therefore, the GMM model, in combination with the sample energy function, help to characterize the level of abnormality of an input time series. The time series that is far away from the centroids of the GMM in the latent space will be deemed as an anomaly. For clarity, we have added the motivation of using GMM and the sample energy function into Appendix H.\n\n(2)\tNotice that the time series dataset under investigation in this work is much smaller than the image dataset used for the experiment in the literature. We therefore use all samples in the training dataset to train our model. Please note that the machine learning model obtained by TimeAutoML is not necessarily of higher computational complexity than those obtained by the traditional methods. We agree that the model searching process of TimeAutoML may incur additional computational complexity than the traditional methods. However, in practice, methods such as early stopping can help speed up the training process and obtain a model more efficiently. In addition, TimeAutoML is a flexible framework in which we can adjust the size of the searching space according to practical needs so that tradeoffs between the complexity and the model detection performance can be achieved. \n\n(3)\tThe hyperparameters in our model are automatically optimized. And we analyze the sensitivity of the weighting factors (Lambda 1 and Lambda 2 in Eq (8)) and Beta distribution priors (alpha_0 and beta_0) in Appendix G. Moreover, what we emphasize on is a special type of irregular sampling pattern of time series data, we have clarified this point in the revised manuscript.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2493/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2493/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "TimeAutoML: Autonomous Representation Learning for Multivariate Irregularly  Sampled Time Series", "authorids": ["yangjiao@tongji.edu.cn", "~Kai_Yang3", "shaoyu@tongji.edu.cn", "lp@tongji.edu.cn", "~Sijia_Liu1", "~Dongjin_Song2"], "authors": ["Yang Jiao", "Kai Yang", "shaoyu dou", "pan luo", "Sijia Liu", "Dongjin Song"], "keywords": ["representation learning", "AutoML", "irregularly sampled time series", "anomaly detection", "clustering"], "abstract": "Multivariate time series (MTS) data are becoming increasingly ubiquitous in diverse domains, e.g., IoT systems, health informatics, and 5G networks. To obtain an effective representation of MTS data, it is not only essential to consider unpredictable dynamics and highly variable lengths of these data but also important to address the irregularities in the sampling rates of MTS. Existing parametric approaches rely on manual hyperparameter tuning and may cost a huge amount of labor effort. Therefore, it is desirable to learn the representation automatically and efficiently. To this end, we propose an autonomous representation learning approach for multivariate time series (TimeAutoML) with irregular sampling rates and variable lengths. As opposed to previous works, we first present a representation learning pipeline in which the configuration and hyperparameter optimization\nare fully automatic and can be tailored for various tasks, e.g., anomaly detection, clustering, etc. Next, a negative sample generation approach and an auxiliary classification task are developed and integrated within TimeAutoML to enhance\nits representation capability. Extensive empirical studies on real-world datasets demonstrate that the proposed TimeAutoML outperforms competing approaches on various tasks by a large margin. In fact, it achieves the best anomaly detection\nperformance among all comparison algorithms on 78 out of all 85 UCR datasets, acquiring up to 20% performance improvement in terms of AUC score.", "one-sentence_summary": "This paper presents an autonomous representation learning approach for multivariate irregularly  sampled time series. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "jiao|timeautoml_autonomous_representation_learning_for_multivariate_irregularly_sampled_time_series", "pdf": "/pdf/07e9b62da12f86427970c15dfd458283541c23c1.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=6k1M5y8erZ", "_bibtex": "@misc{\njiao2021timeautoml,\ntitle={TimeAuto{\\{}ML{\\}}: Autonomous Representation Learning for Multivariate Irregularly  Sampled Time Series},\nauthor={Yang Jiao and Kai Yang and shaoyu dou and pan luo and Sijia Liu and Dongjin Song},\nyear={2021},\nurl={https://openreview.net/forum?id=3UTezOEABr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "3UTezOEABr", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2493/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2493/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2493/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2493/Authors|ICLR.cc/2021/Conference/Paper2493/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2493/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923847764, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2493/-/Official_Comment"}}}, {"id": "PPnnvyo2ftA", "original": null, "number": 3, "cdate": 1606052040872, "ddate": null, "tcdate": 1606052040872, "tmdate": 1606052085666, "tddate": null, "forum": "3UTezOEABr", "replyto": "3UTezOEABr", "invitation": "ICLR.cc/2021/Conference/Paper2493/-/Official_Comment", "content": {"title": "Response to all reviewers", "comment": "  We appreciate your constructive comments and suggestions. We have revised the manuscript according to your comments, as given below:\n\n(1)\tWe have revised the caption of Figure 1 to improve its readability.\n\n(2)\tWe have provided the experimental results for time series classification in Appendix F.\n\n(3)\tSensitivity analysis has been added into Appendix G.\n\n(4)\tDetails about the motivation of involving GMM in our model are given in Appendix H.\n\n  To facilitate reading, we have highlighted the revised part in blue.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2493/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2493/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "TimeAutoML: Autonomous Representation Learning for Multivariate Irregularly  Sampled Time Series", "authorids": ["yangjiao@tongji.edu.cn", "~Kai_Yang3", "shaoyu@tongji.edu.cn", "lp@tongji.edu.cn", "~Sijia_Liu1", "~Dongjin_Song2"], "authors": ["Yang Jiao", "Kai Yang", "shaoyu dou", "pan luo", "Sijia Liu", "Dongjin Song"], "keywords": ["representation learning", "AutoML", "irregularly sampled time series", "anomaly detection", "clustering"], "abstract": "Multivariate time series (MTS) data are becoming increasingly ubiquitous in diverse domains, e.g., IoT systems, health informatics, and 5G networks. To obtain an effective representation of MTS data, it is not only essential to consider unpredictable dynamics and highly variable lengths of these data but also important to address the irregularities in the sampling rates of MTS. Existing parametric approaches rely on manual hyperparameter tuning and may cost a huge amount of labor effort. Therefore, it is desirable to learn the representation automatically and efficiently. To this end, we propose an autonomous representation learning approach for multivariate time series (TimeAutoML) with irregular sampling rates and variable lengths. As opposed to previous works, we first present a representation learning pipeline in which the configuration and hyperparameter optimization\nare fully automatic and can be tailored for various tasks, e.g., anomaly detection, clustering, etc. Next, a negative sample generation approach and an auxiliary classification task are developed and integrated within TimeAutoML to enhance\nits representation capability. Extensive empirical studies on real-world datasets demonstrate that the proposed TimeAutoML outperforms competing approaches on various tasks by a large margin. In fact, it achieves the best anomaly detection\nperformance among all comparison algorithms on 78 out of all 85 UCR datasets, acquiring up to 20% performance improvement in terms of AUC score.", "one-sentence_summary": "This paper presents an autonomous representation learning approach for multivariate irregularly  sampled time series. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "jiao|timeautoml_autonomous_representation_learning_for_multivariate_irregularly_sampled_time_series", "pdf": "/pdf/07e9b62da12f86427970c15dfd458283541c23c1.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=6k1M5y8erZ", "_bibtex": "@misc{\njiao2021timeautoml,\ntitle={TimeAuto{\\{}ML{\\}}: Autonomous Representation Learning for Multivariate Irregularly  Sampled Time Series},\nauthor={Yang Jiao and Kai Yang and shaoyu dou and pan luo and Sijia Liu and Dongjin Song},\nyear={2021},\nurl={https://openreview.net/forum?id=3UTezOEABr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "3UTezOEABr", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2493/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2493/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2493/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2493/Authors|ICLR.cc/2021/Conference/Paper2493/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2493/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923847764, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2493/-/Official_Comment"}}}, {"id": "96xIeYoxzX5", "original": null, "number": 2, "cdate": 1603896934746, "ddate": null, "tcdate": 1603896934746, "tmdate": 1605024198838, "tddate": null, "forum": "3UTezOEABr", "replyto": "3UTezOEABr", "invitation": "ICLR.cc/2021/Conference/Paper2493/-/Official_Review", "content": {"title": "this AutoML framework integrates many existing things which makes their contributions unclear. ", "review": "This work proposes an AutoML framework for multivariate irregularly sampled time series. To achieve this, the proposed framework integrates different modules: data-augmentation self-supervised loss (Equation 7), an anomaly detection loss (Equation 5), and a reconstruction loss. Besides, hyperparameters and model\u2019s configuration is optimized by using AutoML (including Bayesian optimization). The model is evaluated on the well-known time-series datasets UCR and UAE. \n\nComments:\n\n***motivation***  this works combines different techniques including self-supervised learning and hyperparameter optimization. But I cannot clearly find what\u2019s their main contributions in this work since all of these techniques used in this work seems not to be new. I encourage authors to clarify their contributions formally. \n\n***irregularly sampled ts*** since this work is for irregularly sampled time series (see title), this work should consider how to model the irregularly sampled time series. But I cannot find any related mechanism to model or deal with irregularly sampled time series in the model section. Besides, as I know, both of the datasets UCR and UAE are not standard datasets for irregularly sampled time series. And in your experiments, you construct that time series by using an irregularly sampling rate \\beta. This may be problematic since it should be missing data, but not true irregularly sampled time series. There may be two different topics in the time series community. \n \n***representation learning*** since representation learning aims to learn some good representative features that can be easily transferred to other downstream tasks. But in this work, it seems that a single feature is learned from a segment of time series. I wonder whether the representation learned from this framework can be used for other more popular downstream tasks such as classification or prediction. \n\nBesides, since in the objective function, there are clustering loss and anomaly detection loss, I think we cannot say it is an unsupervised representation learning approach. It is more like a clustering model or an anomaly detection model. To demonstrate that the proposed framework can produce a good time-series representation, other downstream tasks such as classification or prediction need to be considered. \n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper2493/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2493/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "TimeAutoML: Autonomous Representation Learning for Multivariate Irregularly  Sampled Time Series", "authorids": ["yangjiao@tongji.edu.cn", "~Kai_Yang3", "shaoyu@tongji.edu.cn", "lp@tongji.edu.cn", "~Sijia_Liu1", "~Dongjin_Song2"], "authors": ["Yang Jiao", "Kai Yang", "shaoyu dou", "pan luo", "Sijia Liu", "Dongjin Song"], "keywords": ["representation learning", "AutoML", "irregularly sampled time series", "anomaly detection", "clustering"], "abstract": "Multivariate time series (MTS) data are becoming increasingly ubiquitous in diverse domains, e.g., IoT systems, health informatics, and 5G networks. To obtain an effective representation of MTS data, it is not only essential to consider unpredictable dynamics and highly variable lengths of these data but also important to address the irregularities in the sampling rates of MTS. Existing parametric approaches rely on manual hyperparameter tuning and may cost a huge amount of labor effort. Therefore, it is desirable to learn the representation automatically and efficiently. To this end, we propose an autonomous representation learning approach for multivariate time series (TimeAutoML) with irregular sampling rates and variable lengths. As opposed to previous works, we first present a representation learning pipeline in which the configuration and hyperparameter optimization\nare fully automatic and can be tailored for various tasks, e.g., anomaly detection, clustering, etc. Next, a negative sample generation approach and an auxiliary classification task are developed and integrated within TimeAutoML to enhance\nits representation capability. Extensive empirical studies on real-world datasets demonstrate that the proposed TimeAutoML outperforms competing approaches on various tasks by a large margin. In fact, it achieves the best anomaly detection\nperformance among all comparison algorithms on 78 out of all 85 UCR datasets, acquiring up to 20% performance improvement in terms of AUC score.", "one-sentence_summary": "This paper presents an autonomous representation learning approach for multivariate irregularly  sampled time series. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "jiao|timeautoml_autonomous_representation_learning_for_multivariate_irregularly_sampled_time_series", "pdf": "/pdf/07e9b62da12f86427970c15dfd458283541c23c1.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=6k1M5y8erZ", "_bibtex": "@misc{\njiao2021timeautoml,\ntitle={TimeAuto{\\{}ML{\\}}: Autonomous Representation Learning for Multivariate Irregularly  Sampled Time Series},\nauthor={Yang Jiao and Kai Yang and shaoyu dou and pan luo and Sijia Liu and Dongjin Song},\nyear={2021},\nurl={https://openreview.net/forum?id=3UTezOEABr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "3UTezOEABr", "replyto": "3UTezOEABr", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2493/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538095141, "tmdate": 1606915786451, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2493/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2493/-/Official_Review"}}}, {"id": "JA186rnDH2A", "original": null, "number": 3, "cdate": 1604051397460, "ddate": null, "tcdate": 1604051397460, "tmdate": 1605024198779, "tddate": null, "forum": "3UTezOEABr", "replyto": "3UTezOEABr", "invitation": "ICLR.cc/2021/Conference/Paper2493/-/Official_Review", "content": {"title": "the methodology is not well motivated.", "review": "This paper proposes an autonomous representation learning framework for multivariate time series with irregular sampling rates. Specifically, there are three major components proposed in the framework. 1) An AutoML solution for hyperparameters optimization under Bayesian framework is proposed to automatically seek optimal network structures and parameters. 2) Variational autoencoders based on generative approach and attention mechanism is employed to learn the semantic representation of time series with limitation of irregular sampling. 3) A sample energy function derived from Gaussian mixture model attempts to depict the level of anomaly of sliced time series.\n\nThe proposed unsupervised time series representation learning is novel in terms of AutoML methodology and contrastive learning approach. However, there are some concerns as follows:\n\n(1)\tThe motivation for involving GMM model is not clearly discussed. The proposed sample energy function to denote the level of anomaly is not properly motivated as well.\n\n(2)\tThere is no discussion about batching and computational complexity. Because of irregular sampling, one computational difficulty comes from the observation that times can be different for each time series in a minibatch. Furthermore, the overall AutoML pipeline without human experience suffers high computational complexity and is usually time-consuming in practice.\n\n(3)\tThe experiments are not convincing. First, there is no sensitivity analysis of the hyperparameters employed in the proposed framework. Then, the datasets are not all carefully selected. In this paper, datasets are generated from normal time series datasets with a specially designed irregular sampling policy. This paper lacks experiments on irregularly sampled time series data from real scenarios. For example, PhysioNet [1] (Physionet Challenge 2012 dataset) dataset is a widely used benchmark to handle irregularly sampled time series data in many previous papers. Consequently, the performance evaluation on PhysioNet or similar datasets should be included in this paper.\n\n[1] Silva, Ikaro et al. \u201cPredicting In-Hospital Mortality of ICU Patients: The PhysioNet/Computing in Cardiology Challenge 2012.\u201d Computing in cardiology vol. 39 (2012): 245-248.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2493/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2493/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "TimeAutoML: Autonomous Representation Learning for Multivariate Irregularly  Sampled Time Series", "authorids": ["yangjiao@tongji.edu.cn", "~Kai_Yang3", "shaoyu@tongji.edu.cn", "lp@tongji.edu.cn", "~Sijia_Liu1", "~Dongjin_Song2"], "authors": ["Yang Jiao", "Kai Yang", "shaoyu dou", "pan luo", "Sijia Liu", "Dongjin Song"], "keywords": ["representation learning", "AutoML", "irregularly sampled time series", "anomaly detection", "clustering"], "abstract": "Multivariate time series (MTS) data are becoming increasingly ubiquitous in diverse domains, e.g., IoT systems, health informatics, and 5G networks. To obtain an effective representation of MTS data, it is not only essential to consider unpredictable dynamics and highly variable lengths of these data but also important to address the irregularities in the sampling rates of MTS. Existing parametric approaches rely on manual hyperparameter tuning and may cost a huge amount of labor effort. Therefore, it is desirable to learn the representation automatically and efficiently. To this end, we propose an autonomous representation learning approach for multivariate time series (TimeAutoML) with irregular sampling rates and variable lengths. As opposed to previous works, we first present a representation learning pipeline in which the configuration and hyperparameter optimization\nare fully automatic and can be tailored for various tasks, e.g., anomaly detection, clustering, etc. Next, a negative sample generation approach and an auxiliary classification task are developed and integrated within TimeAutoML to enhance\nits representation capability. Extensive empirical studies on real-world datasets demonstrate that the proposed TimeAutoML outperforms competing approaches on various tasks by a large margin. In fact, it achieves the best anomaly detection\nperformance among all comparison algorithms on 78 out of all 85 UCR datasets, acquiring up to 20% performance improvement in terms of AUC score.", "one-sentence_summary": "This paper presents an autonomous representation learning approach for multivariate irregularly  sampled time series. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "jiao|timeautoml_autonomous_representation_learning_for_multivariate_irregularly_sampled_time_series", "pdf": "/pdf/07e9b62da12f86427970c15dfd458283541c23c1.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=6k1M5y8erZ", "_bibtex": "@misc{\njiao2021timeautoml,\ntitle={TimeAuto{\\{}ML{\\}}: Autonomous Representation Learning for Multivariate Irregularly  Sampled Time Series},\nauthor={Yang Jiao and Kai Yang and shaoyu dou and pan luo and Sijia Liu and Dongjin Song},\nyear={2021},\nurl={https://openreview.net/forum?id=3UTezOEABr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "3UTezOEABr", "replyto": "3UTezOEABr", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2493/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538095141, "tmdate": 1606915786451, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2493/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2493/-/Official_Review"}}}], "count": 9}