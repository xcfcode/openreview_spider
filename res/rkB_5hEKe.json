{"notes": [{"tddate": null, "ddate": null, "cdate": null, "original": null, "tmdate": 1490028602119, "tcdate": 1490028602119, "number": 1, "id": "S1fSuKTsg", "invitation": "ICLR.cc/2017/workshop/-/paper104/acceptance", "forum": "rkB_5hEKe", "replyto": "rkB_5hEKe", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Classless Association using Neural Networks", "abstract": "In this paper, we propose a model for the classless association between two instances of the same unknown class.  This scenario is inspired by the Symbol Grounding Problem and the association learning in infants.  Our model has two parallel Multilayer Perceptrons (MLPs) and relies on two components.  The first component is a EM-training rule that matches the output vectors of a MLP to a statistical distribution.  The second component exploits the output classification of one MLP as target of the another MLP in order to learn the agreement of the unknown class.   We generate four classless datasets (based on MNIST) with uniform distribution between the classes.  Our model is evaluated against totally supervised and totally unsupervised scenarios.  In the first scenario, our model reaches good performance in terms of accuracy and the classless constraint.  In the second scenario, our model reaches better results against two clustering algorithms.", "pdf": "/pdf/42f831b5c0312620c4d9d8e25846be04692ba7f4.pdf", "TL;DR": "Learning based on the relation between two instances of the same unknown class", "paperhash": "raue|classless_association_using_neural_networks", "keywords": [], "conflicts": ["dfki.de", "uni-kl.de"], "authors": ["Federico Raue", "Sebastian Palacio", "Andreas Dengel", "Marcus Liwicki"], "authorids": ["federico.raue@dfki.de", "sebastian.palacio@dfki.de", "andreas.dengel@dfki.de", "liwicki@cs.uni-kl.de"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1490028602721, "id": "ICLR.cc/2017/workshop/-/paper104/acceptance", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "rkB_5hEKe", "replyto": "rkB_5hEKe", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept", "Reject"]}}}, "nonreaders": [], "cdate": 1490028602721}}}, {"tddate": null, "tmdate": 1489422990917, "tcdate": 1489422990917, "number": 3, "id": "HkD59HVsl", "invitation": "ICLR.cc/2017/workshop/-/paper104/public/comment", "forum": "rkB_5hEKe", "replyto": "HJTkxXNsl", "signatures": ["~Federico_Raue1"], "readers": ["everyone"], "writers": ["~Federico_Raue1"], "content": {"title": "RE: classless association using Neural Networks", "comment": "\nThank you for your time.  Hopefully, our responses have addressed your concerns\n>>> This is what I understand: let's assume a young child is playing with toys from 2 different brands. The toys include several pieces of different  types (10 MNIST classes). \n>>>The aim is to learn to put the same brand types into same buckets. We want a bucket to have the same time of toy of the same brand (purity, all block type t of brand j is in \n>>>bucket b) also the object types are the same for 2 brands in the bucket (association, all block type t of both brands is in bucket b). The ultimate goal (future work) is to \n>>>learn association between diffferent streams (e.g. what parents say when the child holds a lego).\nThe analogy is correct.\n\n>>>This work models this problem with a MLP to first induce a feature vector z^{1,2} for 2 streams. A pseudo-class \\hat{z^{1,2}} is predicted using these feature vectors. In the M-step the parameters are updated so that the distribution defined by  \\hat{z^{1,2}} matches the target distribution \\phi.\nWe want to point out that the model has two MLPs  \n\n\n>>>two issues I observed:\n>>>>1) they do not provide any information about how they evaluated other clustering algorithms. If they are fed with raw pixels, I don't think the comparison would be fair \n>>>because there is no featurization of raw fixels where the proposed model have this power. Comparison on a single layer MLP autoencoder's hidden features or output of PCA\n>>>would be more fair.\n\nThe reported resuls of both clustering algorithms is based on raw pixels.  We have evaluated the same datasets using pca (64, 128, 256), and the results are quite similar to Table 1.  Moreover, these results are similar to Jenckel, et al, where they did not find any improve between raw pixels vs pca for character recognition in Historical documents.\n1) MNIST input 1, input 2\n* pca - 64: 64.1 (std:1.8), 63.9 (std:3.2) \n* pca - 128: 63.5 (std:2.3), 63.6 (std:2.1)\n* pca - 256: 63.6 (std:2.4), 63.4 (std:3.3)\n2) Rotated MNIST input 1, input 2\n* pca - 64: 63.9 (std:2.2), 63.3 (std:3.2) \n* pca - 128: 63.7 (std:3.8), 61.6 (std:2.8)\n* pca - 256: 65.1 (std:2.4), 63.9 (std:1.6)\n3) Inverted MNIST input 1, input 2\n* pca - 64: 64.9 (std:2.8), 64.1 (std:3.3) \n* pca - 128: 64.6 (std:2.0), 64.2 (std:3.3)\n* pca - 256: 65.1 (std:1.7), 63.5 (std:2.8)\n4) Random Rotated MNIST input 1, input 2\n* pca - 64: 64.4 (std:1.7), 14.9 (std:0.4) \n* pca - 128: 63.9 (std:1.9), 14.8 (std:0.3)\n* pca - 256: 65.5 (std:2.2), 14.9 (std:0.5)\n\n[1] Jenckel, et al (2016).  Clustering Benchmark for Characters in Historical Documents. Workshop on Document Analysis Systems, DAS16. \n\n>>2) The experiments are almost oracle type. The model knows the number of classes and the target distribution. I am not sure if other clustering algorithms make use of target \n>>distribution information. In a real life scenario, none of these assumptions are true. An early attempt in that direction would make this work acceptable for workshop \n>>publication.\nWe agree that the experiments are the ideal case, where the number of classes and the statistical distribution is known.  However, our model can be extended where the task is not constrained to the number of classes (which are defined by the language-linguistic).  For example, the classes in MNIST (one, two, three, ... zero) constraint that the input sample\ncan only be in those ten buckets (supervised tasks).  In contrast, our association task inspired by the symbol grounding problem is not constrained to the number of classes because we are only interested in learning two elements are the same based on their correlation.  \nWith this in mind, our model only requires changing the size of the vectors z^{1}, z^{2}, and \\phi for learning the association.   "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Classless Association using Neural Networks", "abstract": "In this paper, we propose a model for the classless association between two instances of the same unknown class.  This scenario is inspired by the Symbol Grounding Problem and the association learning in infants.  Our model has two parallel Multilayer Perceptrons (MLPs) and relies on two components.  The first component is a EM-training rule that matches the output vectors of a MLP to a statistical distribution.  The second component exploits the output classification of one MLP as target of the another MLP in order to learn the agreement of the unknown class.   We generate four classless datasets (based on MNIST) with uniform distribution between the classes.  Our model is evaluated against totally supervised and totally unsupervised scenarios.  In the first scenario, our model reaches good performance in terms of accuracy and the classless constraint.  In the second scenario, our model reaches better results against two clustering algorithms.", "pdf": "/pdf/42f831b5c0312620c4d9d8e25846be04692ba7f4.pdf", "TL;DR": "Learning based on the relation between two instances of the same unknown class", "paperhash": "raue|classless_association_using_neural_networks", "keywords": [], "conflicts": ["dfki.de", "uni-kl.de"], "authors": ["Federico Raue", "Sebastian Palacio", "Andreas Dengel", "Marcus Liwicki"], "authorids": ["federico.raue@dfki.de", "sebastian.palacio@dfki.de", "andreas.dengel@dfki.de", "liwicki@cs.uni-kl.de"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487354477798, "tcdate": 1487354477798, "id": "ICLR.cc/2017/workshop/-/paper104/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper104/reviewers"], "reply": {"forum": "rkB_5hEKe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487354477798}}}, {"tddate": null, "tmdate": 1489412069411, "tcdate": 1489412069411, "number": 2, "id": "HJTkxXNsl", "invitation": "ICLR.cc/2017/workshop/-/paper104/official/review", "forum": "rkB_5hEKe", "replyto": "rkB_5hEKe", "signatures": ["ICLR.cc/2017/workshop/paper104/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper104/AnonReviewer2"], "content": {"title": "classless association using neural networks", "rating": "4: Ok but not good enough - rejection", "review": "I agree with R1, the workshop format is too small to efficiently describe an idea. \n\nThis is what I understand: let's assume a young child is playing with toys from 2 different brands. The toys include several pieces of different  types (10 MNIST classes). The aim is to learn to put the same brand types into same buckets. We want a bucket to have the same time of toy of the same brand (purity, all block type t of brand j is in bucket b) also the object types are the same for 2 brands in the bucket (association, all block type t of both brands is in bucket b). The ultimate goal (future work) is to learn association between diffferent streams (e.g. what parents say when the child holds a lego).\n\nThis work models this problem with a MLP to first induce a feature vector z^{1,2} for 2 streams. A pseudo-class \\hat{z^{1,2}} is predicted using these feature vectors. In the M-step the parameters are updated so that the distribution defined by  \\hat{z^{1,2}} matches the target distribution \\phi.\n\ntwo issues I observed:\n1) they do not provide any information about how they evaluated other clustering algorithms. If they are fed with raw pixels, I don't think the comparison would be fair because there is no featurization of raw fixels where the proposed model have this power. Comparison on a single layer MLP autoencoder's hidden features or output of PCA would be more fair.\n2) The experiments are almost oracle type. The model knows the number of classes and the target distribution. I am not sure if other clustering algorithms make use of target distribution information. In a real life scenario, none of these assumptions are true. An early attempt in that direction would make this work acceptable for workshop publication.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Classless Association using Neural Networks", "abstract": "In this paper, we propose a model for the classless association between two instances of the same unknown class.  This scenario is inspired by the Symbol Grounding Problem and the association learning in infants.  Our model has two parallel Multilayer Perceptrons (MLPs) and relies on two components.  The first component is a EM-training rule that matches the output vectors of a MLP to a statistical distribution.  The second component exploits the output classification of one MLP as target of the another MLP in order to learn the agreement of the unknown class.   We generate four classless datasets (based on MNIST) with uniform distribution between the classes.  Our model is evaluated against totally supervised and totally unsupervised scenarios.  In the first scenario, our model reaches good performance in terms of accuracy and the classless constraint.  In the second scenario, our model reaches better results against two clustering algorithms.", "pdf": "/pdf/42f831b5c0312620c4d9d8e25846be04692ba7f4.pdf", "TL;DR": "Learning based on the relation between two instances of the same unknown class", "paperhash": "raue|classless_association_using_neural_networks", "keywords": [], "conflicts": ["dfki.de", "uni-kl.de"], "authors": ["Federico Raue", "Sebastian Palacio", "Andreas Dengel", "Marcus Liwicki"], "authorids": ["federico.raue@dfki.de", "sebastian.palacio@dfki.de", "andreas.dengel@dfki.de", "liwicki@cs.uni-kl.de"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489412070102, "id": "ICLR.cc/2017/workshop/-/paper104/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper104/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper104/AnonReviewer1", "ICLR.cc/2017/workshop/paper104/AnonReviewer2"], "reply": {"forum": "rkB_5hEKe", "replyto": "rkB_5hEKe", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper104/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper104/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489412070102}}}, {"tddate": null, "tmdate": 1489328050953, "tcdate": 1489328050953, "number": 1, "id": "SJsnwCMjl", "invitation": "ICLR.cc/2017/workshop/-/paper104/public/comment", "forum": "rkB_5hEKe", "replyto": "SyDke2lje", "signatures": ["~Federico_Raue1"], "readers": ["everyone"], "writers": ["~Federico_Raue1"], "content": {"title": "RE: Classless association using neural networks", "comment": "We thank the reviewer for the time.  Unfortunately, given the strict limit of 3 pages, it is challenging to give more information about the motivation and the elements of our model.  Hopefully, our responses have addressed your concerns. \n\n* The presented task is to learn the association between two disjoint input streams where both streams represent the same unknown class.  This task is motivated by the Symbol Grounding Problem, which is the binding of abstract concepts with the real world via sensory input, such as visual system.   More formally, our task is defined by two disjoint input streams x^(1) and x^(2)  that represent the same unlabeled class.  The goal is to learn the association by classifying both with the same pseudo-class c^(1) = c^(2).\n\n* Our training rule relies on matching a statistical distribution and a mini-batch of output vectors of MLPs as an alternative loss function that does not require classes.  With this in mind, we have introduced a new learning parameter (weighting vectors) that modifies the raw output vectors (z) based on the statistical constraint (\\phi).  In addition, the weighting vectors help to classify the input samples.  As a result, the pseudo-classes -obtained in the classification step in Equation 4- change during training and similar elements are grouped together (Figure 1, 2, and 3).\n\n* Motivated by the association learning between both streams.  We have proposed to use the pseudo-classes of one network as a target of the other network, and vice versa.  It can be seen in Figure 1, 2 and 3, each row in the first and second columns (MLP^(1) and MLP^(2)) represents a pseudo class (index) between 0-9.  After the model is trained, both networks agree on classifying similar input samples (or digits) with the same index.\n\n* In summary, the two previous components are used in an EM-approach.  \n    - Initial step: all input samples x(1) and x(2) have random pseudo-classes c(1) and c(2), where histogram of pseudo-classes is similar to the desired statistical distribution\n    -  E-step classifies the output vectors based on the weighting vectors (Equation 4)  and approximates the current statistical distribution of the mini-batch (Equation 3).  Note that the pseudo-classes are assigned to the samples after a number of iterations.  In other words, the updated of the pseudo-classes is not online. \n    - M-step updates the weighting vectors (\\gamma^(1), \\gamma^(2)) and the parameters of the networks (\\theta^(1),\\theta^(2))\n\nWe have updated our paper in order to clarify more the model and still keeping the page limit.\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Classless Association using Neural Networks", "abstract": "In this paper, we propose a model for the classless association between two instances of the same unknown class.  This scenario is inspired by the Symbol Grounding Problem and the association learning in infants.  Our model has two parallel Multilayer Perceptrons (MLPs) and relies on two components.  The first component is a EM-training rule that matches the output vectors of a MLP to a statistical distribution.  The second component exploits the output classification of one MLP as target of the another MLP in order to learn the agreement of the unknown class.   We generate four classless datasets (based on MNIST) with uniform distribution between the classes.  Our model is evaluated against totally supervised and totally unsupervised scenarios.  In the first scenario, our model reaches good performance in terms of accuracy and the classless constraint.  In the second scenario, our model reaches better results against two clustering algorithms.", "pdf": "/pdf/42f831b5c0312620c4d9d8e25846be04692ba7f4.pdf", "TL;DR": "Learning based on the relation between two instances of the same unknown class", "paperhash": "raue|classless_association_using_neural_networks", "keywords": [], "conflicts": ["dfki.de", "uni-kl.de"], "authors": ["Federico Raue", "Sebastian Palacio", "Andreas Dengel", "Marcus Liwicki"], "authorids": ["federico.raue@dfki.de", "sebastian.palacio@dfki.de", "andreas.dengel@dfki.de", "liwicki@cs.uni-kl.de"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487354477798, "tcdate": 1487354477798, "id": "ICLR.cc/2017/workshop/-/paper104/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper104/reviewers"], "reply": {"forum": "rkB_5hEKe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487354477798}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1489328041152, "tcdate": 1487354476727, "number": 104, "id": "rkB_5hEKe", "invitation": "ICLR.cc/2017/workshop/-/submission", "forum": "rkB_5hEKe", "original": "ryh_8f9lg", "signatures": ["~Federico_Raue1"], "readers": ["everyone"], "content": {"title": "Classless Association using Neural Networks", "abstract": "In this paper, we propose a model for the classless association between two instances of the same unknown class.  This scenario is inspired by the Symbol Grounding Problem and the association learning in infants.  Our model has two parallel Multilayer Perceptrons (MLPs) and relies on two components.  The first component is a EM-training rule that matches the output vectors of a MLP to a statistical distribution.  The second component exploits the output classification of one MLP as target of the another MLP in order to learn the agreement of the unknown class.   We generate four classless datasets (based on MNIST) with uniform distribution between the classes.  Our model is evaluated against totally supervised and totally unsupervised scenarios.  In the first scenario, our model reaches good performance in terms of accuracy and the classless constraint.  In the second scenario, our model reaches better results against two clustering algorithms.", "pdf": "/pdf/42f831b5c0312620c4d9d8e25846be04692ba7f4.pdf", "TL;DR": "Learning based on the relation between two instances of the same unknown class", "paperhash": "raue|classless_association_using_neural_networks", "keywords": [], "conflicts": ["dfki.de", "uni-kl.de"], "authors": ["Federico Raue", "Sebastian Palacio", "Andreas Dengel", "Marcus Liwicki"], "authorids": ["federico.raue@dfki.de", "sebastian.palacio@dfki.de", "andreas.dengel@dfki.de", "liwicki@cs.uni-kl.de"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": true, "tags": [], "original": {"tddate": null, "replyto": null, "ddate": null, "active": true, "tmdate": 1484350583490, "tcdate": 1478268531618, "number": 173, "id": "ryh_8f9lg", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "ryh_8f9lg", "signatures": ["~Federico_Raue1"], "readers": ["everyone"], "content": {"title": "Classless Association using Neural Networks", "abstract": "The goal of this paper is to train a model based on the relation between two instances that represent the same unknown class.  This scenario is inspired by the Symbol Grounding Problem and the association learning in infants.  We propose a novel model called Classless Association.  It has two parallel Multilayer Perceptrons (MLP) that uses one network as a target of the other network, and vice versa.  In addition, the presented model is trained based on an EM-approach, in which the output vectors are matched against a statistical distribution.  We generate four classless datasets based on MNIST, where the input is two different instances of the same digit.  In addition,  the digits have a uniform distribution.  Furthermore, our classless association model is evaluated against two scenarios: totally supervised and totally unsupervised.  In the first scenario, our model reaches a good performance in terms of accuracy and the classless constraint.  In the second scenario, our model reaches better results against two clustering algorithms.\n", "pdf": "/pdf/788a4cffe22f661847498b56c09f13aadd311e8c.pdf", "TL;DR": "Learning based on the relation between two instances of the same unknown class", "paperhash": "raue|classless_association_using_neural_networks", "keywords": [], "conflicts": ["dfki.de", "uni-kl.de"], "authors": ["Federico Raue", "Sebastian Palacio", "Andreas Dengel", "Marcus Liwicki"], "authorids": ["federico.raue@dfki.de", "sebastian.palacio@dfki.de", "andreas.dengel@dfki.de", "liwicki@cs.uni-kl.de"]}, "writers": [], "nonreaders": []}, "originalWritable": false, "originalInvitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}, "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1487690420000, "tmdate": 1484242559574, "id": "ICLR.cc/2017/workshop/-/submission", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1495466420000, "cdate": 1484242559574}}}, {"tddate": null, "tmdate": 1489186783013, "tcdate": 1489186783013, "number": 1, "id": "SyDke2lje", "invitation": "ICLR.cc/2017/workshop/-/paper104/official/review", "forum": "rkB_5hEKe", "replyto": "rkB_5hEKe", "signatures": ["ICLR.cc/2017/workshop/paper104/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper104/AnonReviewer1"], "content": {"title": "Classless association using neural networks", "rating": "3: Clear rejection", "review": "I can honestly say that despite several readings, I have no idea what this paper is actually about.  I believe the problem is relating two objects, despite not having a label that classifies the two objects as being of the same class.  From there, my comprehension goes downhill: EM algorithm mixed with pseudo-classes and a weighting scheme. Networks using the output from another network as the targets of other networks.  Target uniform statistical distributions.  Why a weighting scheme?  What's going on? \n\nI acknowledge that perhaps the workshop format is too small, and therefor limits too severely the required space to explain an idea.  Perhaps.  But I can safely say that almost nobody will glean any insight from this manuscript in the time that a reasonable person is willing to give a manuscript.  I would say that if the authors are confident of this work, they should write up a longer manuscript (or return to a longer one) that takes the time and space necessary to more effectively motivate the problem, and introduce the parts of the architecture, again with motivation, so that the reader has a chance of understanding the manuscript.\n", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Classless Association using Neural Networks", "abstract": "In this paper, we propose a model for the classless association between two instances of the same unknown class.  This scenario is inspired by the Symbol Grounding Problem and the association learning in infants.  Our model has two parallel Multilayer Perceptrons (MLPs) and relies on two components.  The first component is a EM-training rule that matches the output vectors of a MLP to a statistical distribution.  The second component exploits the output classification of one MLP as target of the another MLP in order to learn the agreement of the unknown class.   We generate four classless datasets (based on MNIST) with uniform distribution between the classes.  Our model is evaluated against totally supervised and totally unsupervised scenarios.  In the first scenario, our model reaches good performance in terms of accuracy and the classless constraint.  In the second scenario, our model reaches better results against two clustering algorithms.", "pdf": "/pdf/42f831b5c0312620c4d9d8e25846be04692ba7f4.pdf", "TL;DR": "Learning based on the relation between two instances of the same unknown class", "paperhash": "raue|classless_association_using_neural_networks", "keywords": [], "conflicts": ["dfki.de", "uni-kl.de"], "authors": ["Federico Raue", "Sebastian Palacio", "Andreas Dengel", "Marcus Liwicki"], "authorids": ["federico.raue@dfki.de", "sebastian.palacio@dfki.de", "andreas.dengel@dfki.de", "liwicki@cs.uni-kl.de"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489412070102, "id": "ICLR.cc/2017/workshop/-/paper104/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper104/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper104/AnonReviewer1", "ICLR.cc/2017/workshop/paper104/AnonReviewer2"], "reply": {"forum": "rkB_5hEKe", "replyto": "rkB_5hEKe", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper104/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper104/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489412070102}}}], "count": 6}