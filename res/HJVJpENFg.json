{"notes": [{"tddate": null, "ddate": null, "cdate": null, "original": null, "tmdate": 1490028582337, "tcdate": 1490028582337, "number": 1, "id": "Sye0XOY6og", "invitation": "ICLR.cc/2017/workshop/-/paper73/acceptance", "forum": "HJVJpENFg", "replyto": "HJVJpENFg", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Accept", "title": "ICLR committee final decision"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Pl@ntNet app in the era of deep learning", "abstract": "Pl@ntNet is a large-scale participatory platform and information system dedicated to the production of botanical data through image-based plant identification. In June 2015, Pl@ntNet mobile front-ends moved from classical hand-crafted visual features to deep-learning based image representations. This paper gives an overview of today's Pl@ntNet architecture and discusses how the introduction of convolutional neural networks did improve the whole workflow along the years.", "pdf": "/pdf/ca81444048088995ce463ec6810e57eddb086e4c.pdf", "TL;DR": "We synthetise the deep-learning based architecture of Pl@ntNet application and its societal impact", "paperhash": "affouard|plntnet_app_in_the_era_of_deep_learning", "conflicts": ["inria.fr"], "keywords": ["Computer vision", "Supervised Learning", "Applications"], "authors": ["Antoine Affouard", "Herv\u00e9 Goeau", "Pierre Bonnet", "Jean-Christophe Lombardo", "Alexis Joly"], "authorids": ["antoine.affouard@cirad.fr", "herve.goeau@cirad.fr", "pierre.bonnet@cirad.fr", "jean-christophe.lombardo@inria.fr", "alexis.joly@inria.fr"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1490028582899, "id": "ICLR.cc/2017/workshop/-/paper73/acceptance", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "HJVJpENFg", "replyto": "HJVJpENFg", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept", "Reject"]}}}, "nonreaders": [], "cdate": 1490028582899}}}, {"tddate": null, "tmdate": 1489744158002, "tcdate": 1489744158002, "number": 1, "id": "SkU7b4tje", "invitation": "ICLR.cc/2017/workshop/-/paper73/public/comment", "forum": "HJVJpENFg", "replyto": "Hkj35uxjl", "signatures": ["~alexis_joly1"], "readers": ["everyone"], "writers": ["~alexis_joly1"], "content": {"title": "What our talk will be about ?", "comment": "\nThanks for your feedback and recommendations (we will add the reference to LeafSnap). Overall, we agree that this is a system paper with no fundamental contribution with regard to machine learning. However, we are convinced that the presentation of Pl@ntNet at the workshop will be of interest to the ICLR crowd. Besides the technical and evaluation aspects described in the (3 pages...) paper , there are several societal and educational aspects that could be of interest for ICLR attendees (e.g. the perception of such tools by teachers and young childrens, the huge collection of geo-localized cannabis plants we collect each saturday evening, the diversion of the application by some artists, etc.). Also, we might discuss the scientific challenges towards covering the whole world's flora (300K species), including strongly imbalanced data issues, ultimately low inter-class variability for some species in the same genus, use of taxonomic regularization, etc. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Pl@ntNet app in the era of deep learning", "abstract": "Pl@ntNet is a large-scale participatory platform and information system dedicated to the production of botanical data through image-based plant identification. In June 2015, Pl@ntNet mobile front-ends moved from classical hand-crafted visual features to deep-learning based image representations. This paper gives an overview of today's Pl@ntNet architecture and discusses how the introduction of convolutional neural networks did improve the whole workflow along the years.", "pdf": "/pdf/ca81444048088995ce463ec6810e57eddb086e4c.pdf", "TL;DR": "We synthetise the deep-learning based architecture of Pl@ntNet application and its societal impact", "paperhash": "affouard|plntnet_app_in_the_era_of_deep_learning", "conflicts": ["inria.fr"], "keywords": ["Computer vision", "Supervised Learning", "Applications"], "authors": ["Antoine Affouard", "Herv\u00e9 Goeau", "Pierre Bonnet", "Jean-Christophe Lombardo", "Alexis Joly"], "authorids": ["antoine.affouard@cirad.fr", "herve.goeau@cirad.fr", "pierre.bonnet@cirad.fr", "jean-christophe.lombardo@inria.fr", "alexis.joly@inria.fr"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487322333180, "tcdate": 1487322333180, "id": "ICLR.cc/2017/workshop/-/paper73/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper73/reviewers"], "reply": {"forum": "HJVJpENFg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487322333180}}}, {"tddate": null, "tmdate": 1489173170655, "tcdate": 1489173170655, "number": 2, "id": "Hkj35uxjl", "invitation": "ICLR.cc/2017/workshop/-/paper73/official/review", "forum": "HJVJpENFg", "replyto": "HJVJpENFg", "signatures": ["ICLR.cc/2017/workshop/paper73/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper73/AnonReviewer1"], "content": {"title": "Shazam your plants", "rating": "5: Marginally below acceptance threshold", "review": "- A brief summary of the paper's contributions, in the context of prior work.\n\nThis paper describes a mobile and web app that identifies plant species using deep learning.  The paper describes the system components, and uses an inception CNN architecture for classification.  The system also performs efficient similarity search by hashing the last hidden layer feature responses.  The paper shows qualitative results and quantitatively compares against a prior system using hand-designed features.\n\n- An assessment of novelty, clarity, significance, and quality.\n\nThis is a systems paper and has little novelty as far as machine learning goes.  The paper is written clearly enough.  I\u2019d recommend adding a reference to the LeafSnap work.\n\n- A list of pros and cons (reasons to accept/reject).\n\nPro: The web app has quite a few users, and seems to work well enough in practice.\n\nCons: There is no technical novelty with respect to machine learning (similar systems have been deployed for large-scale image tagging and retrieval), so I\u2019m uncertain whether this paper would be of sufficient interest to the ICLR crowd.  A computer vision workshop or WACV may be other possible venues for this paper.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Pl@ntNet app in the era of deep learning", "abstract": "Pl@ntNet is a large-scale participatory platform and information system dedicated to the production of botanical data through image-based plant identification. In June 2015, Pl@ntNet mobile front-ends moved from classical hand-crafted visual features to deep-learning based image representations. This paper gives an overview of today's Pl@ntNet architecture and discusses how the introduction of convolutional neural networks did improve the whole workflow along the years.", "pdf": "/pdf/ca81444048088995ce463ec6810e57eddb086e4c.pdf", "TL;DR": "We synthetise the deep-learning based architecture of Pl@ntNet application and its societal impact", "paperhash": "affouard|plntnet_app_in_the_era_of_deep_learning", "conflicts": ["inria.fr"], "keywords": ["Computer vision", "Supervised Learning", "Applications"], "authors": ["Antoine Affouard", "Herv\u00e9 Goeau", "Pierre Bonnet", "Jean-Christophe Lombardo", "Alexis Joly"], "authorids": ["antoine.affouard@cirad.fr", "herve.goeau@cirad.fr", "pierre.bonnet@cirad.fr", "jean-christophe.lombardo@inria.fr", "alexis.joly@inria.fr"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489173171283, "id": "ICLR.cc/2017/workshop/-/paper73/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper73/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper73/AnonReviewer2", "ICLR.cc/2017/workshop/paper73/AnonReviewer1"], "reply": {"forum": "HJVJpENFg", "replyto": "HJVJpENFg", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper73/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper73/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489173171283}}}, {"tddate": null, "nonreaders": null, "tmdate": 1489057252380, "tcdate": 1489057074111, "number": 1, "id": "B1cErnA5e", "invitation": "ICLR.cc/2017/workshop/-/paper73/official/review", "forum": "HJVJpENFg", "replyto": "HJVJpENFg", "signatures": ["ICLR.cc/2017/workshop/paper73/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper73/AnonReviewer2"], "content": {"title": "A successful collaboration between two worlds", "rating": "8: Top 50% of accepted papers, clear accept", "review": "This paper describes the \"Pl@ntNet\" app (available on Android and iOS) and the CBIR system behind it. This application is rightfully nicknamed as \"the shazam of plants\", as it recognizes the plant (e.g. a flower) that the user is filming with the phone's camera. The application also enables researchers in botany to gather plenty of useful data on plant diversity and such.\nAfter roughly explaining how the whole system functions and giving a few implementation details, it more specifically highlights how the recognition performance was able to vastly improve after using a CNN to classify images rather than an old fashioned hand-crafted pipeline. Quantitative and qualitative evaluations are provided.\n\nPros:\n - The results are undeniably satisfying, given the tremendous difficulty of this very fine-grained task (more than 10K classes, some of them very similar, large intra-class variablities). Ranking of the app by users on the App store is proof of it.\n - Beyond the application working well, this is the perfect illustration of a successful application of CNNs to a difficult classification problem supported by a large-scale participatory platform (3M+ users). It is nice to see that this work allowed different research communities (here, CV and botanists) to collaborate and bond in a win-win situation. I believe that it is in the interest of everybody to advertise and encourage this type of collaborations.\n - overall, the paper reads well and the goal is clear and interesting\n\nCons:\n - it sems that not many implementation choices have been investigated. True, it is not the goal of the paper, but comparing different deep classification architectures (like ResNet) and/or image retrieval approaches would have been a plus.\n - no real scientific novelty, this is a system paper.\n\nIn my opinion this paper makes a good candidate as a workshop paper, not because of its poor scientific content but rather because it exemplifies how two a-priori remote communities can benefit from each other. Thanks to the app, the CV community can gather hundreds of thousands of images of fine-grained classes with detailed annotations for free, very challenging data, and the botanic community also get to form people to recognize plants and retrieve a lot of data on its own. This is worth appearing in a workshop in my opinion.\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Pl@ntNet app in the era of deep learning", "abstract": "Pl@ntNet is a large-scale participatory platform and information system dedicated to the production of botanical data through image-based plant identification. In June 2015, Pl@ntNet mobile front-ends moved from classical hand-crafted visual features to deep-learning based image representations. This paper gives an overview of today's Pl@ntNet architecture and discusses how the introduction of convolutional neural networks did improve the whole workflow along the years.", "pdf": "/pdf/ca81444048088995ce463ec6810e57eddb086e4c.pdf", "TL;DR": "We synthetise the deep-learning based architecture of Pl@ntNet application and its societal impact", "paperhash": "affouard|plntnet_app_in_the_era_of_deep_learning", "conflicts": ["inria.fr"], "keywords": ["Computer vision", "Supervised Learning", "Applications"], "authors": ["Antoine Affouard", "Herv\u00e9 Goeau", "Pierre Bonnet", "Jean-Christophe Lombardo", "Alexis Joly"], "authorids": ["antoine.affouard@cirad.fr", "herve.goeau@cirad.fr", "pierre.bonnet@cirad.fr", "jean-christophe.lombardo@inria.fr", "alexis.joly@inria.fr"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489173171283, "id": "ICLR.cc/2017/workshop/-/paper73/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper73/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper73/AnonReviewer2", "ICLR.cc/2017/workshop/paper73/AnonReviewer1"], "reply": {"forum": "HJVJpENFg", "replyto": "HJVJpENFg", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper73/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper73/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489173171283}}}, {"tddate": null, "replyto": null, "nonreaders": null, "ddate": null, "tmdate": 1487782955318, "tcdate": 1487322332447, "number": 73, "id": "HJVJpENFg", "invitation": "ICLR.cc/2017/workshop/-/submission", "forum": "HJVJpENFg", "signatures": ["~alexis_joly1"], "readers": ["everyone"], "content": {"title": "Pl@ntNet app in the era of deep learning", "abstract": "Pl@ntNet is a large-scale participatory platform and information system dedicated to the production of botanical data through image-based plant identification. In June 2015, Pl@ntNet mobile front-ends moved from classical hand-crafted visual features to deep-learning based image representations. This paper gives an overview of today's Pl@ntNet architecture and discusses how the introduction of convolutional neural networks did improve the whole workflow along the years.", "pdf": "/pdf/ca81444048088995ce463ec6810e57eddb086e4c.pdf", "TL;DR": "We synthetise the deep-learning based architecture of Pl@ntNet application and its societal impact", "paperhash": "affouard|plntnet_app_in_the_era_of_deep_learning", "conflicts": ["inria.fr"], "keywords": ["Computer vision", "Supervised Learning", "Applications"], "authors": ["Antoine Affouard", "Herv\u00e9 Goeau", "Pierre Bonnet", "Jean-Christophe Lombardo", "Alexis Joly"], "authorids": ["antoine.affouard@cirad.fr", "herve.goeau@cirad.fr", "pierre.bonnet@cirad.fr", "jean-christophe.lombardo@inria.fr", "alexis.joly@inria.fr"]}, "writers": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1487690420000, "tmdate": 1484242559574, "id": "ICLR.cc/2017/workshop/-/submission", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1495466420000, "cdate": 1484242559574}}}], "count": 5}