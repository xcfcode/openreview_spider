{"notes": [{"id": "BJeypMU5wE", "original": "SkgtOd8twN", "number": 3, "cdate": 1552732855144, "ddate": null, "tcdate": 1552732855144, "tmdate": 1562082914084, "tddate": null, "forum": "BJeypMU5wE", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/drlStructPred/-/Blind_Submission", "content": {"title": "Multi-agent query reformulation: Challenges and the role of diversity", "authors": ["Rodrigo Nogueira", "Jannis Bulian", "Massimiliano Ciaramita"], "authorids": ["rodrigonogueira@nyu.edu", "jbulian@google.com", "massi@google.com"], "keywords": ["natural language", "reinforcement learning", "structured prediction", "multi-agent learning", "deep learning"], "TL;DR": "We use reinforcement learning for query reformulation on two tasks and surprisingly find that when training multiple agents diversity of the reformulations is more important than specialisation.", "abstract": "We investigate methods to efficiently learn diverse strategies in reinforcement learning for a generative structured prediction problem: query reformulation. In the proposed framework an agent consists of multiple specialized sub-agents and a meta-agent that learns to aggregate the answers from sub-agents to produce a final answer. Sub-agents are trained on disjoint partitions of the training data, while the meta-agent is trained on the full training set. Our method makes learning faster, because it is highly parallelizable, and has better generalization performance than strong baselines, such as\nan ensemble of agents trained on the full data. We evaluate on the tasks of document retrieval and question answering. The\nimproved performance seems due to the increased diversity of reformulation strategies. This suggests that multi-agent, hierarchical approaches might play an important role in structured prediction tasks of this kind. However, we also find that it is not obvious how to characterize diversity in this context, and a first attempt based on clustering did not produce good results. Furthermore, reinforcement learning for the reformulation task is hard in high-performance regimes. At best, it only marginally improves over the state of the art, which highlights the complexity of training models in this framework for end-to-end language understanding problems.", "pdf": "/pdf/79f93f4278188aca1878961668716ba4e0595662.pdf", "paperhash": "nogueira|multiagent_query_reformulation_challenges_and_the_role_of_diversity"}, "signatures": ["ICLR.cc/2019/Workshop/drlStructPred"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/drlStructPred"], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/drlStructPred/-/Blind_Submission", "cdate": 1552732853551, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*", "values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2019/Workshop/drlStructPred"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/drlStructPred"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1552732853551, "tmdate": 1554911328507, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/drlStructPred"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/drlStructPred"]}}, "tauthor": "OpenReview.net"}, {"id": "BJxM_lc5YE", "original": null, "number": 1, "cdate": 1554845801579, "ddate": null, "tcdate": 1554845801579, "tmdate": 1554910463646, "tddate": null, "forum": "BJeypMU5wE", "replyto": "BJeypMU5wE", "invitation": "ICLR.cc/2019/Workshop/drlStructPred/-/Paper3/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/drlStructPred/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/drlStructPred/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-agent query reformulation: Challenges and the role of diversity", "authors": ["Rodrigo Nogueira", "Jannis Bulian", "Massimiliano Ciaramita"], "authorids": ["rodrigonogueira@nyu.edu", "jbulian@google.com", "massi@google.com"], "keywords": ["natural language", "reinforcement learning", "structured prediction", "multi-agent learning", "deep learning"], "TL;DR": "We use reinforcement learning for query reformulation on two tasks and surprisingly find that when training multiple agents diversity of the reformulations is more important than specialisation.", "abstract": "We investigate methods to efficiently learn diverse strategies in reinforcement learning for a generative structured prediction problem: query reformulation. In the proposed framework an agent consists of multiple specialized sub-agents and a meta-agent that learns to aggregate the answers from sub-agents to produce a final answer. Sub-agents are trained on disjoint partitions of the training data, while the meta-agent is trained on the full training set. Our method makes learning faster, because it is highly parallelizable, and has better generalization performance than strong baselines, such as\nan ensemble of agents trained on the full data. We evaluate on the tasks of document retrieval and question answering. The\nimproved performance seems due to the increased diversity of reformulation strategies. This suggests that multi-agent, hierarchical approaches might play an important role in structured prediction tasks of this kind. However, we also find that it is not obvious how to characterize diversity in this context, and a first attempt based on clustering did not produce good results. Furthermore, reinforcement learning for the reformulation task is hard in high-performance regimes. At best, it only marginally improves over the state of the art, which highlights the complexity of training models in this framework for end-to-end language understanding problems.", "pdf": "/pdf/79f93f4278188aca1878961668716ba4e0595662.pdf", "paperhash": "nogueira|multiagent_query_reformulation_challenges_and_the_role_of_diversity"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/drlStructPred/-/Paper3/Decision", "cdate": 1554496487778, "reply": {"forum": "BJeypMU5wE", "replyto": "BJeypMU5wE", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/drlStructPred/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/drlStructPred/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554496487778, "tmdate": 1554910462073, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/drlStructPred"], "invitees": ["ICLR.cc/2019/Workshop/drlStructPred/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/drlStructPred"]}}}, {"id": "HyxE-hwBtE", "original": null, "number": 4, "cdate": 1554508795688, "ddate": null, "tcdate": 1554508795688, "tmdate": 1554910456467, "tddate": null, "forum": "BJeypMU5wE", "replyto": "BJeypMU5wE", "invitation": "ICLR.cc/2019/Workshop/drlStructPred/-/Paper3/Official_Review", "content": {"title": "Elegant idea, preliminary results", "review": "This paper explores whether decomposing an agent-oriented structure prediction task into sub-agents and an aggregator improves performance on query reformulation tasks.  The paper considers both decomposing on random sub-sets of the data (bagging), and partitioning into semantically similar classes.  The results show that decomposing into sub-agents improves performance.\n\nThe method is applied to 2 tasks - document retrieval (on 3 datasets), and question answering.  One of the main results is that the same level of performance can be achieved with much less compute.\n\nThe basic idea is elegant, but I have 3 concerns. First, I found that some aspects were really unclear.  Second, it wasn\u2019t clear but I inferred that the results were created from a single run, which limits how much can be concluded.  Finally, it wasn\u2019t clear whether the method would generalize to other tasks.\n\n* Clarity.  I was unclear on the following:\n\n- Fig 1: why is there 1 search box in Fig 1b, but N+1 search boxes in Fig 1c?  If the idea is that the search in Fig 1b is doing a single search by simultaneously receiving all queries, that wasn\u2019t at all clear.\n\n- Sec 3.4, \u201cthe aggregator receives as input q_0\u2026\u201d: q_0 is not an input into the aggregator in Fig 1.  Should q_0 be a_0?\u2028\n- Sec 4.3, \u201cother metrics \u2026 resulted in similar or slightly worse performance than Recall@40.\u201d  Does this mean that the proposed method is strongest only when evaluated under certain metrics?\u2028\n- Table 1: I was unclear on how RL-10-Ensemble and RL-10-Full differ, since the descriptions in the text (Sec 4.4 and 4.5) are nearly identical.\u2028\n* Experimental procedure.  Were the results the product of a single run, or the results of averaging many runs?  I might have missed it but I inferred they were from a single run.  As a result, readers won\u2019t know what the variance of the methods are, and whether the relative orderings of the methods are reliable. \n\n* Generality.  Query re-writing is a very specific task, and both experiments here relied on an external search engine.  I\u2019m worried that the method may be \u201cfit\u201d to specific properties of the task \u2014 for example, in the current setting, all actions can effectively be executed to produce search results; in other settings, this isn\u2019t possible.  Moreover, because of the search engine, producing a diversity of responses seems to be important; in other settings, having a diverse set of outputs may be less important.  The results would be more impactful if other types of tasks were considered \u2014 even more text generation tasks, like dialog response generation, paraphrasing, translation, etc.  \n", "rating": "3: Marginally above acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/drlStructPred/Paper3/AnonReviewer5"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/drlStructPred/Paper3/AnonReviewer5"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-agent query reformulation: Challenges and the role of diversity", "authors": ["Rodrigo Nogueira", "Jannis Bulian", "Massimiliano Ciaramita"], "authorids": ["rodrigonogueira@nyu.edu", "jbulian@google.com", "massi@google.com"], "keywords": ["natural language", "reinforcement learning", "structured prediction", "multi-agent learning", "deep learning"], "TL;DR": "We use reinforcement learning for query reformulation on two tasks and surprisingly find that when training multiple agents diversity of the reformulations is more important than specialisation.", "abstract": "We investigate methods to efficiently learn diverse strategies in reinforcement learning for a generative structured prediction problem: query reformulation. In the proposed framework an agent consists of multiple specialized sub-agents and a meta-agent that learns to aggregate the answers from sub-agents to produce a final answer. Sub-agents are trained on disjoint partitions of the training data, while the meta-agent is trained on the full training set. Our method makes learning faster, because it is highly parallelizable, and has better generalization performance than strong baselines, such as\nan ensemble of agents trained on the full data. We evaluate on the tasks of document retrieval and question answering. The\nimproved performance seems due to the increased diversity of reformulation strategies. This suggests that multi-agent, hierarchical approaches might play an important role in structured prediction tasks of this kind. However, we also find that it is not obvious how to characterize diversity in this context, and a first attempt based on clustering did not produce good results. Furthermore, reinforcement learning for the reformulation task is hard in high-performance regimes. At best, it only marginally improves over the state of the art, which highlights the complexity of training models in this framework for end-to-end language understanding problems.", "pdf": "/pdf/79f93f4278188aca1878961668716ba4e0595662.pdf", "paperhash": "nogueira|multiagent_query_reformulation_challenges_and_the_role_of_diversity"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/drlStructPred/-/Paper3/Official_Review", "cdate": 1553778227795, "expdate": 1554526740000, "duedate": 1554526740000, "reply": {"forum": "BJeypMU5wE", "replyto": "BJeypMU5wE", "readers": {"values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/drlStructPred/Paper3/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/drlStructPred/Paper3/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553778227795, "tmdate": 1554911863408, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/drlStructPred"], "invitees": ["ICLR.cc/2019/Workshop/drlStructPred/Paper3/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/drlStructPred"]}}}, {"id": "S1eqGbqNtN", "original": null, "number": 3, "cdate": 1554452753945, "ddate": null, "tcdate": 1554452753945, "tmdate": 1554910455767, "tddate": null, "forum": "BJeypMU5wE", "replyto": "BJeypMU5wE", "invitation": "ICLR.cc/2019/Workshop/drlStructPred/-/Paper3/Official_Review", "content": {"title": "Simple idea, strong empirical results, but some results are surprising ", "review": "The authors propose a multi-agent approach for query reformulation. A set of sub-agents is trained on disjoint splits of the training data, and a meta-agent (the aggregator) is trained on the whole dataset and learns to combine outputs from the sub-agents.  The proposed approach is evaluated on two tasks: document retrieval and question answering. For document retrieval, recall@40 is used as the reward signal. The token level F1 score on the answer is used as the reward signal for question answering.\n\nStrength:\n========\n\n- The proposed approach is simple, easy to parallelize, and hence computational efficiency can be achieved.\n- Strong empirical results, although no significant improvement was observed when improving over a BERT model on the question answering task.\n- Paper is clear and easy to follow. \n\nWeakness:\n=========\n1) Some results are surprising and counterintuitive, and hence further analysis is needed for a better understanding:\n\na) What was the size of the random partitions used for training the sub-agents? I expect the dataset has been split equally between the agents in the RL-N-Sub setting, have the authors experimented with other partition sizes in addition to training the sub-agents on the full dataset?\nb) The results described in section 5.5 are surprising, perhaps the reason for this results is limited to K-means clustering which is prone to fail when the clusters have non-spherical structures. Have the authors experimented with other density based clustering algorithms (e.g. dbscan)?\nc) Not being able to significantly improve on BERT in the question answering task is concerning. \n\n2) Originality is limited, the main difference between the proposed approach and previous work seems to be the training on disjoint splits for the sub-agents, and then training an aggregator to combine the results. \n\nClarity:\n======\n\nThe paper is clear and well written.", "rating": "3: Marginally above acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/drlStructPred/Paper3/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/drlStructPred/Paper3/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-agent query reformulation: Challenges and the role of diversity", "authors": ["Rodrigo Nogueira", "Jannis Bulian", "Massimiliano Ciaramita"], "authorids": ["rodrigonogueira@nyu.edu", "jbulian@google.com", "massi@google.com"], "keywords": ["natural language", "reinforcement learning", "structured prediction", "multi-agent learning", "deep learning"], "TL;DR": "We use reinforcement learning for query reformulation on two tasks and surprisingly find that when training multiple agents diversity of the reformulations is more important than specialisation.", "abstract": "We investigate methods to efficiently learn diverse strategies in reinforcement learning for a generative structured prediction problem: query reformulation. In the proposed framework an agent consists of multiple specialized sub-agents and a meta-agent that learns to aggregate the answers from sub-agents to produce a final answer. Sub-agents are trained on disjoint partitions of the training data, while the meta-agent is trained on the full training set. Our method makes learning faster, because it is highly parallelizable, and has better generalization performance than strong baselines, such as\nan ensemble of agents trained on the full data. We evaluate on the tasks of document retrieval and question answering. The\nimproved performance seems due to the increased diversity of reformulation strategies. This suggests that multi-agent, hierarchical approaches might play an important role in structured prediction tasks of this kind. However, we also find that it is not obvious how to characterize diversity in this context, and a first attempt based on clustering did not produce good results. Furthermore, reinforcement learning for the reformulation task is hard in high-performance regimes. At best, it only marginally improves over the state of the art, which highlights the complexity of training models in this framework for end-to-end language understanding problems.", "pdf": "/pdf/79f93f4278188aca1878961668716ba4e0595662.pdf", "paperhash": "nogueira|multiagent_query_reformulation_challenges_and_the_role_of_diversity"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/drlStructPred/-/Paper3/Official_Review", "cdate": 1553778227795, "expdate": 1554526740000, "duedate": 1554526740000, "reply": {"forum": "BJeypMU5wE", "replyto": "BJeypMU5wE", "readers": {"values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/drlStructPred/Paper3/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/drlStructPred/Paper3/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553778227795, "tmdate": 1554911863408, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/drlStructPred"], "invitees": ["ICLR.cc/2019/Workshop/drlStructPred/Paper3/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/drlStructPred"]}}}, {"id": "BJg4Bsr4K4", "original": null, "number": 2, "cdate": 1554434876395, "ddate": null, "tcdate": 1554434876395, "tmdate": 1554910454738, "tddate": null, "forum": "BJeypMU5wE", "replyto": "BJeypMU5wE", "invitation": "ICLR.cc/2019/Workshop/drlStructPred/-/Paper3/Official_Review", "content": {"title": "Hierarchical RL applied to document retrieval and QA. Interesting but somewhat disappointing results.", "review": "This paper instantiates in the context of query reformulation an approach to structure prediction (seq2seq) that is inspired by hierarchical reinforcement learning methods proposed in the early nineties by Singh, Lin, Dietterich, and Hinton. \n\nThis is an experimental paper with well executed experimental design and a broad range of comparative results for doc retrieval and question answering. Although experimentally solid, the paper is light in terms of insights.\n\nOn the positive side, the approach is easily parallelizable and achieves better generalization performance than a model average ensemble. On the negative side, the approach does not lead to significant improvements.\n", "rating": "3: Marginally above acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/drlStructPred/Paper3/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/drlStructPred/Paper3/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-agent query reformulation: Challenges and the role of diversity", "authors": ["Rodrigo Nogueira", "Jannis Bulian", "Massimiliano Ciaramita"], "authorids": ["rodrigonogueira@nyu.edu", "jbulian@google.com", "massi@google.com"], "keywords": ["natural language", "reinforcement learning", "structured prediction", "multi-agent learning", "deep learning"], "TL;DR": "We use reinforcement learning for query reformulation on two tasks and surprisingly find that when training multiple agents diversity of the reformulations is more important than specialisation.", "abstract": "We investigate methods to efficiently learn diverse strategies in reinforcement learning for a generative structured prediction problem: query reformulation. In the proposed framework an agent consists of multiple specialized sub-agents and a meta-agent that learns to aggregate the answers from sub-agents to produce a final answer. Sub-agents are trained on disjoint partitions of the training data, while the meta-agent is trained on the full training set. Our method makes learning faster, because it is highly parallelizable, and has better generalization performance than strong baselines, such as\nan ensemble of agents trained on the full data. We evaluate on the tasks of document retrieval and question answering. The\nimproved performance seems due to the increased diversity of reformulation strategies. This suggests that multi-agent, hierarchical approaches might play an important role in structured prediction tasks of this kind. However, we also find that it is not obvious how to characterize diversity in this context, and a first attempt based on clustering did not produce good results. Furthermore, reinforcement learning for the reformulation task is hard in high-performance regimes. At best, it only marginally improves over the state of the art, which highlights the complexity of training models in this framework for end-to-end language understanding problems.", "pdf": "/pdf/79f93f4278188aca1878961668716ba4e0595662.pdf", "paperhash": "nogueira|multiagent_query_reformulation_challenges_and_the_role_of_diversity"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/drlStructPred/-/Paper3/Official_Review", "cdate": 1553778227795, "expdate": 1554526740000, "duedate": 1554526740000, "reply": {"forum": "BJeypMU5wE", "replyto": "BJeypMU5wE", "readers": {"values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/drlStructPred/Paper3/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/drlStructPred/Paper3/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553778227795, "tmdate": 1554911863408, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/drlStructPred"], "invitees": ["ICLR.cc/2019/Workshop/drlStructPred/Paper3/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/drlStructPred"]}}}, {"id": "SkeACccCdE", "original": null, "number": 1, "cdate": 1554062037903, "ddate": null, "tcdate": 1554062037903, "tmdate": 1554910452996, "tddate": null, "forum": "BJeypMU5wE", "replyto": "BJeypMU5wE", "invitation": "ICLR.cc/2019/Workshop/drlStructPred/-/Paper3/Official_Review", "content": {"title": "Clear paper but lack of novelty and marginal improvement", "review": "\nThis work applies the mixture-of-experts approach to the query reformulation task, where ones goals is to reformulate queries in order to optimize the quality of results returned by an underlying retrieval system. The authors propose to train multiple reformulators (sub-agents) each on a subset of the training dataset, leading to a diverse set of reformulators. Given a new query, each reformulator can thus propose different query reformulations, which are then fed (in addition to the initial query) to an underlying search engine. For each query, the search engine outputs a recommendation. All recommendations are sent to an aggregator (meta-agent), which decides which one to pick. The authors propose an architecture and loss function to train the aggregator.\n\nAs pointed out, the idea of using a mixture-of-experts trained on different subsets of data is old and well-known. Results showing that ensembles of such sub-agents produce diverse reformulations are therefore not surprising.\n\nImpact of aggregator:\nAppendix C shows the benefits of the ensemble of sub-agents independently from the effect of using an aggregator (Fig.1c) instead of a selector (Fig.1b). However, it seems like anything combined with BERT (alone or as an aggregator) increases the performance so much, therefore making the benefits of using diverse sub-agents appear as marginal. It is not clear that relying on diverse ensembles would even bring any improvement given a strong aggregator.\n\nDiversity of sub-agents:\nHow does the size of sub-datasets used by sub-agents affect the performance and diversity? Is there any overlap between sub-datasets used by sub-agents? If not, it means that the number of sub-agents affects the size of dataset available to each sub-agent. How would that affect the performance in return? If sub-datasets are allowed to overlap, should we expect a tradeoff between large sub-datasets (increasing overlap, therefore decreasing diversity) and small sub-datasets (more diversity, maybe worse generalization)?\n\nOverall, although the approach lacks novelty and results are either expected or not impressive, the paper is well written, easy to follow, and presents a decent empirical evaluation. I therefore think that this paper is suitable for a workshop.\n\nMinor questions/comments:\n* [Sec.2] Small communication overhead: A downside of the approach of Shazeer et al. (2017) is that it requires that \"output vectors of experts are exchanged between machines.\" The authors claim that their method instead \"requires only scalars (rewards) and short strings (original query, reformulations, and answers) to be exchanged.\" How are reformulations and answers different from the output vectors?\n* [Sec.3.3] Training of sub-agents: \"At training time, instead of using beam search, we sample reformulations.\" From which distribution are reformulation sampled?\n* [Sec.3.4] Training of aggregator: Why is the loss only using the relevance score (see Eq.3)?\n* [Sec.4.3] Reward: Any insights regarding why agent trained to optimize Recall@40 perform better than those trained to optimize MAP, even though MAP is used in evaluation?\n* [Sec.4.5] Proposed model RL-N-Full: What is the \"best reformulations of all the agents\"?\n* [Sec.4.6, 2nd paragraph] \"...an RL-10-Full with an ensemble of 10 aggregators yields a relative performance...\": Should \"aggregators\" be replaced by \"reformulators\"?\n* [Tables 1 and 2] Consistency of training time in sub-agents+BERT: Why does RL-10-Sub + BERT Aggregator require 10 training days (Tab.1) while BERT + AQA-10-Sub require 1 training day (Tab.2)?", "rating": "3: Marginally above acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/drlStructPred/Paper3/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/drlStructPred/Paper3/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-agent query reformulation: Challenges and the role of diversity", "authors": ["Rodrigo Nogueira", "Jannis Bulian", "Massimiliano Ciaramita"], "authorids": ["rodrigonogueira@nyu.edu", "jbulian@google.com", "massi@google.com"], "keywords": ["natural language", "reinforcement learning", "structured prediction", "multi-agent learning", "deep learning"], "TL;DR": "We use reinforcement learning for query reformulation on two tasks and surprisingly find that when training multiple agents diversity of the reformulations is more important than specialisation.", "abstract": "We investigate methods to efficiently learn diverse strategies in reinforcement learning for a generative structured prediction problem: query reformulation. In the proposed framework an agent consists of multiple specialized sub-agents and a meta-agent that learns to aggregate the answers from sub-agents to produce a final answer. Sub-agents are trained on disjoint partitions of the training data, while the meta-agent is trained on the full training set. Our method makes learning faster, because it is highly parallelizable, and has better generalization performance than strong baselines, such as\nan ensemble of agents trained on the full data. We evaluate on the tasks of document retrieval and question answering. The\nimproved performance seems due to the increased diversity of reformulation strategies. This suggests that multi-agent, hierarchical approaches might play an important role in structured prediction tasks of this kind. However, we also find that it is not obvious how to characterize diversity in this context, and a first attempt based on clustering did not produce good results. Furthermore, reinforcement learning for the reformulation task is hard in high-performance regimes. At best, it only marginally improves over the state of the art, which highlights the complexity of training models in this framework for end-to-end language understanding problems.", "pdf": "/pdf/79f93f4278188aca1878961668716ba4e0595662.pdf", "paperhash": "nogueira|multiagent_query_reformulation_challenges_and_the_role_of_diversity"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/drlStructPred/-/Paper3/Official_Review", "cdate": 1553778227795, "expdate": 1554526740000, "duedate": 1554526740000, "reply": {"forum": "BJeypMU5wE", "replyto": "BJeypMU5wE", "readers": {"values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/drlStructPred/Paper3/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/drlStructPred/Paper3/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553778227795, "tmdate": 1554911863408, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/drlStructPred"], "invitees": ["ICLR.cc/2019/Workshop/drlStructPred/Paper3/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/drlStructPred"]}}}], "count": 6}