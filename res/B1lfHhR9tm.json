{"notes": [{"id": "B1lfHhR9tm", "original": "SJe_6Cc5tX", "number": 1522, "cdate": 1538087994113, "ddate": null, "tcdate": 1538087994113, "tmdate": 1545355406124, "tddate": null, "forum": "B1lfHhR9tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 24, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "H1lNn9A1eE", "original": null, "number": 1, "cdate": 1544706732206, "ddate": null, "tcdate": 1544706732206, "tmdate": 1545354507483, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "B1lfHhR9tm", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Meta_Review", "content": {"metareview": "This paper presents a new multi-task training and evaluation set up called the Natural Language Decathlon, and evaluates models on it. While this AC is sympathetic to any work which introduces new datasets and evaluation tasks, the reviewers agreed amongst themselves that the paper is not quite ready for publication. The main concern is that multi-task learning should show benefits of transferring representations or other model components between tasks, demonstrating better generalisation and less task-specific overfitting, but that the results in the paper do not properly show this effect. A more thorough study of which tasks \"interact constructively\" and what model changes can properly exploit this needs to be done. With this further work, the AC has no doubt that this dataset and task suite, and associated models, will be very valuable to the NLP community.\n\nI should note that there were some issues during the review period which lead to AC-confidential communication between AC and authors, and AC and reviewers, to be leaked to the reviewers. It was due to an OpenReview bug, and no party is at fault. Through private discussion with the interested parties, we were able to resolve this matter, and through careful examination of the discussion, I am satisfied that the reviews and final recommendations of the reviewers were properly argued for and presented in good faith.", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "Some great contributions, but more work needed on cross-task transfer"}, "signatures": ["ICLR.cc/2019/Conference/Paper1522/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1522/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352808038, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1lfHhR9tm", "replyto": "B1lfHhR9tm", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1522/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1522/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1522/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352808038}}}, {"id": "SygF6GHkkN", "original": null, "number": 22, "cdate": 1543619265406, "ddate": null, "tcdate": 1543619265406, "tmdate": 1543627221122, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "HyeuPA-JkN", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "content": {"title": "No need to escalate", "comment": "[I'm following the AC lead with this post and setting Readers: Everyone, so like the AC I believe this response will only be seen by the authors, AC and above.]\n\nThank you for the notes. I don't think this should be escalated.\n\nI think the review does make some substantial arguments, so I'm perfectly content with the reviewer's explanations. It really demonstrates that there are two readings of this paper. We wrote it to show how QA can expand possibilities for multitask learning in NLP, but the other reading sees it as a paper trying to show multitask learning helps individual tasks. Depending on which reading you go in with, the results either look positive or negative, respectively. We'll have to keep this in mind for future work and see if we can address the second reading more effectively.\n\nCan you help me understand this system and its visibility settings? Why is it that R2 got an email with the text of my Red Flag post even though it has \"Readers:  ICLR 2019 Conference Paper1522 Area Chairs, Program Chairs\"? And why do they not get notified of the AC post with \"Readers: Everyone\"?\n\nI think this actually happened earlier as well. I got an email before reviews were released with this body:\n\n\"\"\"\nYour submission to ICLR 2019 has received a comment.\n\nComment title: Some comments\n\nComment: Thank you for your review, Reviewer 2. As AC, I should clarify two things.\n\n1. References to authors by first names are vague. It would be helpful for Reviewer 2 to clarify who they mean by \"Luheng and Omer\" (one would assume Luheng He and Omer Levy) and which paper they are referring to.\n\n2. Reserving judgement on whether or not the reviewer is right in suggesting that the paper tries to fit too much content in its main body, it is abiding by the formatting rules of the conference. Readers and reviewers are not required to read the supplementary materials, and thus the paper must stand on its own without them when you evaluate it. However, the length of the appendix is not grounds for desk rejecting it, and it should go through the full review process.\n\"\"\"\n\nThat doesn't seem like it was supposed to be sent to us, so I don't know what's going on with the email system. I'm disappointed that R2 got such an email, knew it was meant to be a private post from the authors, but posted it publicly anyways instead of following up privately. That felt like a betrayal, but I assume they had some positive intent that I can't see. There shouldn't be any more escalation here, and I apologize if I contributed to a negative or adversarial review environment even if unintentionally. I appreciate that you weighed in publicly, and I'll follow up in an attempt to convey my genuine respect for R2's constructive feedback while also responding to the requests in R2's better attempt at point 1 (which I found helpful).\n\nThanks again."}, "signatures": ["ICLR.cc/2019/Conference/Paper1522/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626604, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1lfHhR9tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1522/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1522/Authors|ICLR.cc/2019/Conference/Paper1522/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626604}}}, {"id": "HJeuil0sRX", "original": null, "number": 14, "cdate": 1543393439893, "ddate": null, "tcdate": 1543393439893, "tmdate": 1543627191793, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "BkekRkTsR7", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "content": {"title": "Thanks for the feedback!", "comment": "We\u2019ll keep working on the gaps and make sure to provide additional analysis of task relatedness in future work. "}, "signatures": ["ICLR.cc/2019/Conference/Paper1522/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626604, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1lfHhR9tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1522/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1522/Authors|ICLR.cc/2019/Conference/Paper1522/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626604}}}, {"id": "rJliXSXJ1E", "original": null, "number": 21, "cdate": 1543611683469, "ddate": null, "tcdate": 1543611683469, "tmdate": 1543611683469, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "H1eWSvGJk4", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "content": {"title": "response to AC", "comment": "Thank you for replying.  I understand the point you are making.  I have updated my scoring because, after re-reading the author responses, I think my rating needed to be updated to reflect their clarifications.  Thanks, again, for pointing this out."}, "signatures": ["ICLR.cc/2019/Conference/Paper1522/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1522/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626604, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1lfHhR9tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1522/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1522/Authors|ICLR.cc/2019/Conference/Paper1522/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626604}}}, {"id": "Syx1siQK37", "original": null, "number": 2, "cdate": 1541122966701, "ddate": null, "tcdate": 1541122966701, "tmdate": 1543611177451, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "B1lfHhR9tm", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Official_Review", "content": {"title": "New framework has a lot of potential, but the experiments, motivations, and related work are missing details", "review": "Update: I've updated my score based on the clarifications from the authors to some of my questions/concerns about the experimental set-up and multi-task/single-task differences.\n\nOriginal Review:\nThis paper provides a new framework for multitask learning in nlp by taking advantage of the similarities in 10 common NLP tasks. The modeling is building on pre-existing qa models but has some original aspects that were augmented to accommodate the various tasks.  The decaNLP framework could be a useful benchmark for other nlp researchers.  \n\nExperiments indicate that the multi-task set-up does worse on average than the single-task set-up.  I wish there was more analysis on why multi-task setups are helpful in some tasks and not others.  With a bit more fine-grained analysis, the experiments and framework in this paper could be very beneficial towards other researchers who want to experiment with multi-task learning or who want to use the decaNLP framework as a benchmark.\n\nI also found the adaptation to new tasks and zero-shot experiments very interesting but the set-up was not described very concretely: \n  -in the transfer learning section, I hope the writers will elaborate on whether the performance gain is coming from the model being pretrained on a multi-task objective or if there would still be performance gain by pretraining a model on only one of those tasks.  For example, would a model pre-trained solely on IWSLT see the same performance gain when transferred to English->Czech as in Figure 4? Or is it actually the multi-task training that is causing the improvement in transfer learning? \n  -Can you please add more detail about the setup for replacing +/- with happy/angry or supportive/unsupportive? What were the (empirical) results of that experiment?\n\nI think the paper doesn\u2019t quite stand on its own without the appendix, which is a major weakness in terms of clarity.  The related work, for example, should really be included in the main body of the paper.  I also recommend that more of the original insights (such as the experimentation with curriculum learning) should be included in the body of the text to count towards original contributions.  \n\nAs a suggestion, the authors may be able to condense the discussion of the 10 tasks in order to make more room in the main text for a related work section plus more of their motivations and experimental results.  If necessary, the main paper *can* exceed 8 pages and still fit ICLR guidelines.\n\nVery minor detail: I noticed some inconsistency in the bibliography regarding full names vs. first initials only.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1522/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Official_Review", "cdate": 1542234211946, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "B1lfHhR9tm", "replyto": "B1lfHhR9tm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1522/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335964271, "tmdate": 1552335964271, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1522/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "H1eWSvGJk4", "original": null, "number": 20, "cdate": 1543608121222, "ddate": null, "tcdate": 1543608121222, "tmdate": 1543608155412, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "BklnA4fkyE", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "content": {"title": "response", "comment": "Thank you for giving further details of your concerns.\n\nI do not wish for you to think that my comment was compelling you to change your score, although you are welcome to do so if you think it right. \n\nUltimately, you should give a score which you think reflects the strength and suitability of the paper for the conference. The only thing that matters to me (and, I suspect, to the authors) is that if you are going to recommend rejection, it be for clear reasons and with sufficient detail to permit the authors to properly revise their paper for further resubmission.\n\nAC"}, "signatures": ["ICLR.cc/2019/Conference/Paper1522/Area_Chair1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1522/Area_Chair1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626604, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1lfHhR9tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1522/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1522/Authors|ICLR.cc/2019/Conference/Paper1522/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626604}}}, {"id": "BklnA4fkyE", "original": null, "number": 19, "cdate": 1543607507661, "ddate": null, "tcdate": 1543607507661, "tmdate": 1543607507661, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "H1lMai-1kN", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "content": {"title": "response to AC", "comment": "Thanks for commenting!  I'm sorry if my review was unclear.\n\nI agree that it seems that most of what they moved to the appendix was not done in bad faith.  I'm sorry if my review suggested that was the case.  However, I did think that there were some interesting details (aside from the related work) mentioned briefly in the appendix that I would have appreciated more analysis on, such as the experiments on curriculum learning strategies or the comparison of which tasks were more similar to each other (and therefore more beneficial for multi-task learning).  But, again, I don't think that was done in bad faith.  I really just wanted to provide feedback for the authors on that point.  I was not recommending rejection on those grounds.\n\nRather, I had some difficulty determining the original contributions of this paper.  One problem for me was that some of the experiments were unclear (which I asked the authors about in my review), which made it difficult to understand what we can conclude from them.  This was particularly the case in the transfer-learning experiment which seemed to suggest that the benefits in transfer learning were coming from the multi-task set-up directly, without showing a single-task transfer-learning baseline (which the authors responded to in their review).  \n\nAnother question I had was about what the advantages of multi-task/single-task set-ups were.  In the paper's tables, it is clear that multi-task set-ups are outperformed by the single-task set-up in nearly all tasks (as well as overall by a nontrivial margin).  This goes against the main point of the paper (which seems to be that multi-task setups are beneficial), but it isn't discussed much in the running text.  I was hoping the authors would clarify a bit more about why we should use multi-task set-ups if single-task set-ups typically outperform them.  Because of the discrepancy in performance, I would have appreciated a more detailed discussion/analysis of the advantages of multi-task learning (this is brought up by Reviewer 3 as well).\n\nI appreciate the response/clarifications of the authors to many of my comments and questions.  I'm not sure that I could recommend a strong acceptance, but I would probably be inclined to raise my initial rating slightly based on their clarifications."}, "signatures": ["ICLR.cc/2019/Conference/Paper1522/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1522/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626604, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1lfHhR9tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1522/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1522/Authors|ICLR.cc/2019/Conference/Paper1522/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626604}}}, {"id": "BJxWFWzyy4", "original": null, "number": 18, "cdate": 1543606649178, "ddate": null, "tcdate": 1543606649178, "tmdate": 1543606649178, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "S1lkWIVjCm", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "content": {"title": "Review", "comment": "Dear Reviewer 2 and Authors\n\nThe aim of the peer review process is to ensure that the work presented at conferences is of a sufficient scientific standard. To this end, while not necessarily so, it can end up being an adversarial process: results must be examined, comparisons must be called for, assumptions must be questioned, and so on. We must not let these moments where constructive criticism, and even rejection, is called for poison the well of communication, community, and collaboration which permits our field to grow. To this end, it is extremely important that the authors of negative reviews be especially mindful of their language and of how criticism is framed.\n\nUpon examining Reviewer 2's initial comments, I agree with the authors that\u2014while not explicitly insulting\u2014the tone is unpleasant. Reviewer 2 perhaps did not intend this, and has apologized for any offense caused. The content of the review is detailed and objective enough that I am not worried about the authors being treated unfairly, when it comes to the assessment of the paper. I encourage the reviewer to consider one last time their score in view of the discussion that has been had, and other reviews, and consider whether they wish to keep it (if so, why) or adjust it. I also encourage the reviewer to consider, in future reviews, how their well-meaning and expert counsel might be perceived by authors\u2014who may perhaps be students or otherwise fairly new to our field\u2014if improperly presented.\n\nAC"}, "signatures": ["ICLR.cc/2019/Conference/Paper1522/Area_Chair1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1522/Area_Chair1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626604, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1lfHhR9tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1522/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1522/Authors|ICLR.cc/2019/Conference/Paper1522/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626604}}}, {"id": "HyeuPA-JkN", "original": null, "number": 17, "cdate": 1543605855888, "ddate": null, "tcdate": 1543605855888, "tmdate": 1543605855888, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "Hyx1DISKCQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "content": {"title": "Notes", "comment": "[I believe this response will only be seen by the authors, AC and above.]\n\nSorry for only coming onto this now. I agree the wording of the review and title is not ideal. The reviewer states that they did not intend to come across as a rude, and has apologized. I will make a public comment to weigh in.\n\nIt is still my opinion that the review makes some substantive arguments, and that while its author has failed to be pleasant in a way we would all like even critical reviews to be, they have not failed to be reasonably objective in the case they make for their score.\n\nIf the authors wish for me to further escalate this issue, it can be done, but in the absence of such a request or further notice I will assume they accept R2's apology. I commend the authors for their calm and professional response.\n\nAC"}, "signatures": ["ICLR.cc/2019/Conference/Paper1522/Area_Chair1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1522/Area_Chair1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626604, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1lfHhR9tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1522/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1522/Authors|ICLR.cc/2019/Conference/Paper1522/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626604}}}, {"id": "H1lMai-1kN", "original": null, "number": 16, "cdate": 1543605178038, "ddate": null, "tcdate": 1543605178038, "tmdate": 1543605178038, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "Syx1siQK37", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "content": {"title": "Related work sections", "comment": "I am uncomfortable with this assessment. The reviewer is right that the related work section should not be in the appendix. The reviewer is also correct that the paper should stand on its own without the supplementary material. The role of the paper is to advertise and motivate the work, describing the key experiments, and the supplementary exists to provide enough detail for, say, reproduction or further analysis. Authors should not take advantage of supplementary materials to compensate for a poorly written or organized paper, or to bypass page limits while preserving large swathes of material in overall their submission.\n\nFrom looking over this paper, and without prejudice to whatever faults it may or may not otherwise have, it is clear that while the authors made a mistake in moving the contents of Appendices B and C out of the main paper, it was clearly not done in bad faith. The paper is under 8 pages, and the content of these appendices could clearly be moved into the main paper with minor and workable changes while remaining under 10 pages. It seems unfair to me to strongly argue the paper is worthy of rejection on these grounds.\n\nPlease, could Reviewer 1 explain in further detail why they are recommending clear rejection: other than the relevant work sections, are there any sections currently in the appendix for which the paper suffers by not having them in the main body? Are there any other strong grounds for rejection? I must admit it is not clear to me from reading the review, in its current form.\n\nYou are welcome to discuss these issues with the authors and other reviewers, as there is about a week left before I must provide preliminary decisions.\n\nAC"}, "signatures": ["ICLR.cc/2019/Conference/Paper1522/Area_Chair1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1522/Area_Chair1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626604, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1lfHhR9tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1522/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1522/Authors|ICLR.cc/2019/Conference/Paper1522/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626604}}}, {"id": "S1equDZkJN", "original": null, "number": 15, "cdate": 1543604082037, "ddate": null, "tcdate": 1543604082037, "tmdate": 1543604082037, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "Bye7ZuVKCX", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "content": {"title": "Response for authors", "comment": "Thank you for clarifying!  I agree with several of the points you make above, and I appreciate your argument about the potential of the multi-task set-ups for transferability and compression.  I hope that you are able to revise future iterations of the paper to reflect some of the strong points you've made in the comments section here."}, "signatures": ["ICLR.cc/2019/Conference/Paper1522/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1522/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626604, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1lfHhR9tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1522/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1522/Authors|ICLR.cc/2019/Conference/Paper1522/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626604}}}, {"id": "BkekRkTsR7", "original": null, "number": 13, "cdate": 1543389127292, "ddate": null, "tcdate": 1543389127292, "tmdate": 1543389127292, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "r1xjw4VK0Q", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "content": {"title": "comments to authors", "comment": "I agreed on the point that the paper raises an interesting challenge and a potentially interesting research direction. I also agree that not any set of tasks can be combined together for the multi-task learning. More analysis and study should be done to decide which tasks can benefit each other. I am interested in seeing that authors give more study in this direction and/or narrow the gaps (as mentioned in the response) in the future work.\n\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1522/AnonReviewer3"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1522/AnonReviewer3", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626604, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1lfHhR9tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1522/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1522/Authors|ICLR.cc/2019/Conference/Paper1522/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626604}}}, {"id": "S1lkWIVjCm", "original": null, "number": 12, "cdate": 1543353846595, "ddate": null, "tcdate": 1543353846595, "tmdate": 1543353846595, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "BJgYq03KCQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "content": {"title": "A better attempt at point 1", "comment": "It seems my idiolect has a different connotation for \"misguided\" than yours, and I apologize for using a term that was offensive.  What I meant was essentially, \"fundamentally the wrong way of thinking about the problem.\"  If I'm not supposed to comment on the framing of a research problem in a review, I'm not sure what the point of the review is.  You called my paragraphs in point 1 \"pontificating\" - I read them as arguments explaining _why_ I think this is the wrong way of thinking about the problem.  I have seen no counter-arguments from you, either in the paper or in your response to my review.\n\nSo, some constructive criticism: provide me some arguments for why we should be thinking about \"question answering\" as a general phenomenon, or show empirically that we can get some benefit from thinking about things this way.  I see no empirical results that demonstrate that this is worthwhile, in fact I see quite the opposite.  While ELMo and BERT improve performance through multi-task learning, treating everything as QA and training them jointly hurts performance in almost all cases.\n\nYou've mentioned SOTA on WikiSQL, but recall that those results were from _single task_ performance of MQAN and have nothing to do with transfer.  Performance unsurprisingly drops, quite a lot, when you try to jointly train WikiSQL with other \"QA\" tasks.\n\nIf you're able to show that some gains can be had for translation or classification by thinking of them as QA (more than you can get by doing the same kind of label replacement but without QA), then I will be quite happy to give your paper a positive review.  Until then, this really feels like it's going down the wrong path and will give people the wrong impression about QA research.  I have had conversations with senior researchers who do not take QA research seriously because of papers saying that \"everything is QA\" - this is not theoretical harm that I am talking about."}, "signatures": ["ICLR.cc/2019/Conference/Paper1522/AnonReviewer2"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1522/AnonReviewer2", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626604, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1lfHhR9tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1522/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1522/Authors|ICLR.cc/2019/Conference/Paper1522/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626604}}}, {"id": "BJgYq03KCQ", "original": null, "number": 11, "cdate": 1543257745292, "ddate": null, "tcdate": 1543257745292, "tmdate": 1543257798940, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "HJeLFjOtA7", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "content": {"title": "Clarifications and thanks for your helpful feedback", "comment": "Yes, I understand that your intent was probably not rudeness. I didn't think it was my place to publicly comment on your writing compared to say, R1, who makes nearly all the same criticisms and gives an equally low score without using terms that are condescending like 'misguided'. I did not post this publicly because I am both an author and a reviewer, and I understand that I am biased towards reading this review  as more negative than it should be read. That is why I posted this to ACs and Higher so that they could evaluate. For some reason, the system must have some unintuitive behavior (too me at least) that sends you an email for comments on your posts regardless of the chosen visibility. Not sure what happened since the original post is still visible to me and was not deleted. Now that you've posted it to Everyone, I might as well clarify.\n\nAs a reviewer, my criticism of this review has nothing to do with QA or the paper itself. Title and 1) seem to be written too combatively (perhaps to use this platform to balance out \"very prominent, public voice[s] advocating for it\"?). I don't think this is the place for that. On my view, authors submit for review to get valuable criticism. The reviewer's ultimate goal should be to tell authors how to improve their research; it should not be to combat the research agenda. The paper has problems, especially in total content and organization. As mentioned in the post to ACs and Higher, you raise important criticisms in points 2) and 3). But, I think Title and 1) deviated from what I see as a reviewer's goal too much. I just think you could have done without 1), and you should also avoid using words like 'misguided' unless you intend to up the rudeness factor by a few notches. We might just have to agree to disagree here about tone and word choice, maybe even about the goal of reviewing. \n\nNow switching back into author mode.  \n\n2) You're right that the transfer learning experiments for any one task are not new results. What we find interesting here is that the multi-task model retains transferability to all of the tasks it has been trained on. In this sense, these experiments verify that the representations of the multi-task model are somehow compressing the transferable utility of ten single-task models into a single model (10x smaller).\n\nRegarding your point about the gap between single- and multi-task performance, I'll point you to our response to R3 so that you don't have to do redundant reading. \n\nRegarding switching classification labels. Yes, this is a rough approximation for something we were trying to study -- whether the model could adapt to new, but related kinds of questions and adapt its output space. Certainly this experimental design has some problems, but we do think it demonstrates the more general capacity of the model to switch output spaces based on the question because the model must realize that even though the context is the same, it must use different output labels based on different questions.\n\n3) No objections here. Organizing all this information into a reasonable order is tough, and clearly one big take-away from this reviewing process is to break things down into more conference-sized chunks rather than cram everything into appendices. Definitely don't put related works in an appendix -- it is disrespectful even if the intentions were good (more space to expand on it all).\n\nFinal paragraph) A lot of additional valuable feedback here. This gives a good sense of how we might restructure and support claims with new experiments. Very much appreciated.\n\nOverall, thanks for the discussion. Even though I disagreed with your reviewing style for 1), I think you make really good points in the remainder of your review. Thanks for offering so much of your time."}, "signatures": ["ICLR.cc/2019/Conference/Paper1522/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626604, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1lfHhR9tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1522/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1522/Authors|ICLR.cc/2019/Conference/Paper1522/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626604}}}, {"id": "HJeLFjOtA7", "original": null, "number": 10, "cdate": 1543240574440, "ddate": null, "tcdate": 1543240574440, "tmdate": 1543241093246, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "Bkl_SsOYRm", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "content": {"title": "Response", "comment": "I apologize that my review came off to you as rude.  That was not my intent.  I knew that my review was quite negative, and I read it several times trying to make sure the criticisms were of the ideas in the paper, not the people who did the work.  I apparently did not do a good enough job of that, and I am sorry.  When I read it again, even having seen your response, I still have a hard time finding ad hominem attacks (and even you have to say that it's \"in disguise\").  I can imagine that when it's your work it feels more ad hominem than it was intended.\n                                                                                                     \nI stand by my criticisms of the paper, however.  I strongly feel that this framing of translation and classification as QA harms QA research, and you have a very prominent, public voice advocating for it.  You say that my claim is \"baseless\" and you \"can find any number of people to disagree with\" it.  Citation please (or better yet, just give the arguments themselves instead of appealing to a nameless authoritative crowd).  I provided evidence in my second point - treating everything as QA makes performance on most tasks drop, except in cases where the task was designed to be QA and makes sense as QA."}, "signatures": ["ICLR.cc/2019/Conference/Paper1522/AnonReviewer2"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1522/AnonReviewer2", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626604, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1lfHhR9tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1522/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1522/Authors|ICLR.cc/2019/Conference/Paper1522/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626604}}}, {"id": "Bkl_SsOYRm", "original": null, "number": 9, "cdate": 1543240511809, "ddate": null, "tcdate": 1543240511809, "tmdate": 1543240511809, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "S1lGsQAShm", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "content": {"title": "Reply deleted", "comment": "I received an email with a response; I'm assuming the authors posted the response and then deleted it, so that it only showed up to reviewers.  At the risk of escalating things further, I'm posting the reply here so I can respond to it.\n\nResponse title: Red Flag\n\nResponse comment: I'll respond to this review's points 2) and 3) eventually in a way that is visible to everyone without discussing this particular aspect of the review, but I have to say that the title and complaint 1) come off as condescending and, frankly, just plain mean.\n\nAs a fellow ICLR reviewer, I can't imagine titling a review as \"Misguided and Overcrowded\". How about \"Concerns with QA as a general framework; too much material in appendices\"? That took me about a second to rephrase in a way that is more informative and avoids conveying an intention to humiliate and demean.\n\nSimilarly, there are plenty of ways to politely raise concerns about multi-task learning and framing multi-task learning as question answering, but the reviewer chooses an alternative approach. Take for example this excerpt:\n\n\"this paper does more harm than good, because it perpetuates a misguided view of question answering... Question answering is not a unified phenomenon.... There is no such thing as general question answering... All of these questions require very different systems to answer, and trying to pretend they are the same doesn't help anyone solve any problems.\"  \n\nThe above starts out by repeating the same baseless claim that I can find any number of people to disagree with. The way that paragraph ends makes it read as if the whole thing is really an ad hominem attack in disguise. In my opinion as a fellow reviewer, I do not think we should be entering into ideological arguments. Rather, the reviewer should be basing their claims in the empirical results of the paper and prior published literature. This reviewer is not doing that; they are just stating their opinion despite the fact that the idea of \"general QA\" has been used as an idea in this paper to get SOTA on WikiSQL and make significant progress on two crucial multi-task learning problems (see response to R3).\n\nI'm quite shocked that anyone that considers themselves part of a professional community would talk to someone else in that community so rudely. I'm not writing this so much as an author because the review eventually does raise some good concerns. I acknowledge that the paper has issues with the amount of information in the appendices. But -- as a reviewer I find myself asking, \"Why did they have to have all the condescending meanness before getting to helpful, critical feedback? How does all that pontificating help the authors improve their research?\" It is clear to me that it did not need to be there because such pontificating does not help. For this reason, I think this kind of review should be discouraged by ACs and Higher."}, "signatures": ["ICLR.cc/2019/Conference/Paper1522/AnonReviewer2"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1522/AnonReviewer2", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626604, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1lfHhR9tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1522/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1522/Authors|ICLR.cc/2019/Conference/Paper1522/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626604}}}, {"id": "BkgxS6EKAm", "original": null, "number": 7, "cdate": 1543224631757, "ddate": null, "tcdate": 1543224631757, "tmdate": 1543224847527, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "HJe-iuo5qm", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "content": {"title": "Related work", "comment": "Thanks for taking the time to suggest how we could prioritize all of this information more effectively. \n\nYou're right that even though we cite the work you mention (Collobert and Weston 2008) along with the follow up (Collobert et al. 2011) in our original submission, we only do so in the related works, which are currently placed in the appendices. \n\nI assure you that we meant no disrespect to these related works by placing them in an appendix. Our thinking at the time was that we could only do justice to the significant literature in both multi-task learning and single-task learning for all these tasks by moving such discussions to sections that had no page limit. \n\nWe have a lot of information in the appendices that we view as just as important as the information in the main body. We just didn't have the same interpretation of appendices (as lesser material) going into this submission. We simply ordered on what we thought would need to be read first in order to understand the benchmark and the progress so far. For example, the details on anti-curriculum pre-training are actually quite important to us as a contribution, but they didn't seem as essential as understanding the nature of all the tasks. Our motivations for the tasks, the related works, and the task-specific related works are all important. The fact that they are in appendices is only because of the total amount of information in the submission.\n\nThat being said, feedback from multiple sources has indicated that at least some of these related works need to be in the main body, and we will reorganize the paper accordingly."}, "signatures": ["ICLR.cc/2019/Conference/Paper1522/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626604, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1lfHhR9tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1522/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1522/Authors|ICLR.cc/2019/Conference/Paper1522/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626604}}}, {"id": "rJglodNF0Q", "original": null, "number": 6, "cdate": 1543223448120, "ddate": null, "tcdate": 1543223448120, "tmdate": 1543223448120, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "S1gNRnjt5m", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "content": {"title": "50k most common words across all tasks in decaNLP", "comment": "Exciting! Glad you're finding decaNLP to be a good resource for further research!\n\nIn our experiments, the generative vocabulary in Eq. 11 contains the most frequent 50000 words in the\ncombined training sets for all tasks in decaNLP. A lot of these training details are way down in Appendix D on Preprocessing and Training Details. They aren't necessarily optimal if you have a bigger memory budget than we did or have a more clever motivation for how these kinds of decsision should be based on individual tasks. "}, "signatures": ["ICLR.cc/2019/Conference/Paper1522/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626604, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1lfHhR9tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1522/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1522/Authors|ICLR.cc/2019/Conference/Paper1522/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626604}}}, {"id": "Bye7ZuVKCX", "original": null, "number": 5, "cdate": 1543223290893, "ddate": null, "tcdate": 1543223290893, "tmdate": 1543223290893, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "Syx1siQK37", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "content": {"title": "Response to R1: Thanks for your review, and some clarificaitons", "comment": "Regarding your point about the gap between single- and multi-task performance, I'll point you to our response to R3 so that you don't have redundant reading. \n\nRegarding the transfer learning experiments. The performance gain does not come from the multi-task objective, as single-task models would exhibit similar behavior for their respective task. What we find interesting here is that the multi-task model retains transferability to all of the tasks it has been trained on. In this sense, these experiments verify that the representations of the multi-task model are somehow compressing the transferable utility of ten single task models into a single model (10x smaller!).\n\nFor the label replacement on the SST dataset, the empirical results show a minor degradation in performance (~1%, so ~86 vs ~87 according to Table 2 and subsection 4.3). This was a naive replacement mapping all answers that were 'positive' to 'happy' and all answers that were 'negative' to 'angry'. This shows how the model is learning to capitalize on the common output space (all of English in GloVe) to adapt to new labels without any additional training. This is advantageous over models that do not actually generate answer sequences because it allows them to be more robust in intuitive ways.\n\nYou're certainly right that the appendix carries a lot of useful information and some of the details about contributions. We had moved the related works to the appendix because that was the only way we found we could sufficiently do justice to the long line of literature in multi-task learning as well as all of the literature for each task, but it does seem we will need to include at least a part of our full related works in the main body. There is quite a bit of material overall, and we thank you for your suggestions about where to cut/condense and how to prioritize information.\n\nThank you again for your questions and your feedback about organization."}, "signatures": ["ICLR.cc/2019/Conference/Paper1522/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626604, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1lfHhR9tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1522/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1522/Authors|ICLR.cc/2019/Conference/Paper1522/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626604}}}, {"id": "r1xjw4VK0Q", "original": null, "number": 4, "cdate": 1543222371038, "ddate": null, "tcdate": 1543222371038, "tmdate": 1543222371038, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "B1xIPcoqh7", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "content": {"title": "Respone to R3: Thank you for your review; more on single- vs. multi-task performance", "comment": "First of all, thank you for your review. You touch upon a crucial point that does require clarification: the gap between the single- and multi-task performance.\n\nAs you mentioned, the multi-task learning literature has taught us at least one thing: related tasks tend to help each other, and unrelated tasks tend to interfere with each other. The latter is an interesting phenomenon, and it is what we see as the primary multi-task learning problem of concern in this paper, and we are proposing decaNLP as a benchmark for measuring progress on this problem.\n\nThere are two ways in which unrelated tasks tend to interfere. The first is during the modeling phase where some tasks prevent us from using priors (like span prediction for QA or a German-only output vocabulary) that would be useful for some tasks. The second is during the training phase where some tasks tend to interfere with representation learning.\n\nThese two kinds of interference lead to two kinds of gaps that we measure with this benchmark. The first is the gap between the current best decaNLP model (in the single- and multi-task settings) and a combination of state-of-the-art models for each task. The second is the gap between the best decaNLP model in the multi-task setting and a combination of ten of those best decaNLP models each trained for a single task. \n\nThe concrete contributions of this paper are 1) the preparation of benchmark along with reasonable sequence-to-sequence baselines, 2) progress on the first kind of gap by switching from seq2seq to multi-sequence-to-sequence with MQAN (by transforming problems into QA triplets), and 3) progress on the second kind of gap by demonstrating the superiority of anti-curriculum learning (or pre-training on harder tasks) over the baseline fully joint training. 3) actually ties multi-task learning back to transfer learning as an effective means of representation learning.\n\nBut yes, we have not yet entirely closed these gaps; as you mentioned, that is a key part of the challenge to the community. We have chosen to introduce this challenge now because we believe solutions to this problems are within reach in the near future if the community focuses on them.\n\nAnd yes, though this approach will likely be successful whenever tasks are related (just based on what we know from the rest of the multi-task learning literature), it is sometimes not yet the best way to optimize for single-task performance. Keep in mind though that it did lead to new state-of-the-art results on WikiSQL despite no direct modeling or tuning for that task. \n\nThanks again for your time. "}, "signatures": ["ICLR.cc/2019/Conference/Paper1522/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626604, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1lfHhR9tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1522/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1522/Authors|ICLR.cc/2019/Conference/Paper1522/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626604}}}, {"id": "B1xIPcoqh7", "original": null, "number": 3, "cdate": 1541220958111, "ddate": null, "tcdate": 1541220958111, "tmdate": 1541533066705, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "B1lfHhR9tm", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Official_Review", "content": {"title": "A good example to treat different NLP problems as Q&A and trained together. Results for some problems are worse than their state-of-the-art.", "review": "The paper formulates several different NLP problems as Q&A problem and proposed a general deep learning architecture. All these tasks are trained together. \n\nIf the goal is to achieve general AI, the paper gives a good starting point. One technical novelty is the deep learning architecture for this general Q&A problem including the multi-pointer-generator. The paper presents an example of how to do a multi-task learning for 10 different tasks. It raises a very challenging problem or in some way release a new dataset.\n\nIf our goal is to optimize a single task, the usefulness of the method proposed by the paper is questionable. \nAs we know, multi-task learning works well if some important knowledge shared by different tasks can be learned and leveraged. From table 2, we see for many problems, the results of the single task training are better than the multi-task training, meaning that other tasks can't really help at least under this framework. This makes me doubt if this multi-task learning is useful if our goal is to optimize the performance of a single task. This general model also sacrifices some important prior knowledge of an individual task. For example, for the Squad, the prior that the answer is a continuous span. Ideally, the prior knowledge should be leveraged.\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1522/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Official_Review", "cdate": 1542234211946, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "B1lfHhR9tm", "replyto": "B1lfHhR9tm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1522/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335964271, "tmdate": 1552335964271, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1522/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "S1lGsQAShm", "original": null, "number": 1, "cdate": 1540903833775, "ddate": null, "tcdate": 1540903833775, "tmdate": 1541533066214, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "B1lfHhR9tm", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Official_Review", "content": {"title": "Misguided and overcrowded", "review": "I appreciate the work that went into creating this paper, but I'm afraid I see little justification for accepting it.  I have three major complaints with this paper:                                                                         \n                                                                                                     \n1. I think the framing of decaNLP presented in this paper does more harm than good, because it perpetuates a misguided view of question answering.\n                                                                                                     \nQuestion answering is not a unified phenomenon.  There is no such thing as \"general question answering\", not even for humans.  Consider \"What is 2 + 3?\", \"What's the terminal velocity of a rain drop?\", and \"What is the meaning of life?\"  All of these questions require very different systems to answer, and trying to pretend they are the same doesn't help anyone solve any problems.\n                                                                                                     \nQuestion answering is a _format_ for studying particular phenomena.  Sometimes it is useful to pose a task as QA, and sometimes it is not.  QA is not a useful format for studying problems when you only have a single question (like \"what is the sentiment?\" or \"what is the translation?\"), and there is no hope of transfer from a related task.  Posing translation or classification as QA serves no useful purpose and gives people the wrong impression about question answering as a format for studying problems.\n\nWe have plenty of work that studies multiple datasets at a time (including in the context of semi-supervised / transfer learning), without doing this misguided framing of all of them as QA (see, e.g., the ELMo and BERT papers, which evaluated on many separate tasks).  I don't see any compelling justification for setting things up this way.\n                                                                                                     \n2. One of the main claims of this paper is transfer from one task to another by posing them all as question answering.  There is nothing new in the transfer results that were presented here, however.  For QA-SRL / QA-ZRE, transfer from SQuAD / other QA tasks has already been shown by Luheng He (http://aclweb.org/anthology/N18-2089) and Omer Levy (that was the whole point of the QA-ZRE paper), so this is merely reproducing that result (without mentioning that they did it first).  For all other tasks, performance drops when you try to train all tasks together, sometimes significantly (as in translation, unsurprisingly).  For the Czech task, fine tuning a pre-trained model has already been shown to help.  Transfer from MNLI to SNLI is known already and not surprising - one of the main points of MNLI was domain transfer, so obviously this has been studied before.  The claims about transfer to new classification tasks are misleading, as you really have the _same_ classification task, you've just arbitrarily changed how you're encoding the class label.  It _might_ be the case that you still get transfer if you actually switch to a related classification task, but you haven't examined that case.\n                                                                                                     \n3. This paper tries to put three separate ideas into a single conference paper, and all three ideas suffer as a result, because there is not enough space to do any of them justice.  Giving 15 pages of appendix for an 8 page paper, where some of the main content of the paper is pushed to the appendix, is egregious.  Putting your work in the context of related work is not something that should be pushed into an appendix, and we should not encourage this behavior.\n                                                                                                     \nThe three ideas here seem to me to be (1) decaNLP, (2) the model architecture of MQAN, (3) transfer results.  Any of these three could have been a single conference paper, had it been done well.  As it stands, decaNLP isn't described or motivated well enough, and there isn't any space left in the paper to address my severe criticisms of it in my first point.  Perhaps if you had dedicated the paper to decaNLP, you could have given arguments that the framing is worthwhile, and described the tasks and their setup as QA sufficiently (as it is, I don't see any description anywhere of how the context is constructed for WikiSQL; did I miss it somewhere?).  For MQAN, there's more than a page of the core new architecture that's pushed into the appendix.  And for the transfer results, there is very little comparison to other transfer methods (e.g., ELMo, CoVe), or any deep analysis of what's going on - as I mentioned above, basically all of the results presented are just confirming what has already been done elsewhere.", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1522/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Official_Review", "cdate": 1542234211946, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "B1lfHhR9tm", "replyto": "B1lfHhR9tm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1522/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335964271, "tmdate": 1552335964271, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1522/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HJe-iuo5qm", "original": null, "number": 2, "cdate": 1539123352772, "ddate": null, "tcdate": 1539123352772, "tmdate": 1539123352772, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "B1lfHhR9tm", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Public_Comment", "content": {"comment": "The related work section should not be buried in Appendix B on page 17.\n\nFrom the text of the main paper, a reader would have no indication that multi-task NLP has been around for 10+ years, and that the main novelty here is the particular selection of tasks and aggregating performance across those tasks as a benchmark. The authors should be more clear and honest about what their contribution is.\n\nAs an example, I'll point to [1], a well known paper (2.7k cites) from ICML 2008, titled \"A Unified Architecture for Natural Language Processing: Deep Neural Networks with Multitask Learning\". \n\n[1] https://ronan.collobert.com/pub/matos/2008_nlp_icml.pdf", "title": "Please respect prior work"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311577584, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "B1lfHhR9tm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311577584}}}, {"id": "S1gNRnjt5m", "original": null, "number": 1, "cdate": 1539058891825, "ddate": null, "tcdate": 1539058891825, "tmdate": 1539058891825, "tddate": null, "forum": "B1lfHhR9tm", "replyto": "B1lfHhR9tm", "invitation": "ICLR.cc/2019/Conference/-/Paper1522/Public_Comment", "content": {"comment": "Thanks for the paper and the collections of datasets!\n\nI'm using decaNLP in my research and would like to ask a clarification question. Section 3 mentions \"We gives it access to v additional vocabulary tokens\". What are the v additional tokens and how were they chosen?", "title": "Clarifications"}, "signatures": ["~quan_vuong1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1522/Reviewers/Unsubmitted"], "writers": ["~quan_vuong1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The Natural Language Decathlon: Multitask Learning as Question Answering", "abstract": "Deep learning has improved performance on many natural language processing (NLP) tasks individually.\nHowever, general NLP models cannot emerge within a paradigm that focuses on the particularities of a single metric, dataset, and task.\nWe introduce the Natural Language Decathlon (decaNLP), a challenge that spans ten tasks:\nquestion answering, machine translation, summarization, natural language inference, sentiment analysis, semantic role labeling, relation extraction, goal-oriented dialogue, semantic parsing, and commonsense pronoun resolution.\nWe cast all tasks as question answering over a context.\nFurthermore, we present a new multitask question answering network (MQAN) that jointly learns all tasks in decaNLP without any task-specific modules or parameters more effectively than sequence-to-sequence and reading comprehension baselines.\nMQAN shows improvements in transfer learning for machine translation and named entity recognition, domain adaptation for sentiment analysis and natural language inference, and zero-shot capabilities for text classification.\nWe demonstrate that the MQAN's multi-pointer-generator decoder is key to this success and that performance further improves with an anti-curriculum training strategy.\nThough designed for decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic parsing task in the single-task setting. \nWe also release code for procuring and processing data, training and evaluating models, and reproducing all experiments for decaNLP.", "keywords": ["multitask learning", "natural language processing", "question answering", "machine translation", "relation extraction", "semantic parsing", "commensense reasoning", "summarization", "entailment", "sentiment", "dialog"], "authorids": ["bmccann@salesforce.com", "nkeskar@salesforce.com", "cxiong@salesforce.com", "rsocher@salesforce.com"], "authors": ["Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher"], "TL;DR": "We introduce a multitask learning challenge that spans ten natural language processing tasks and propose a new model that jointly learns them. ", "pdf": "/pdf/901feb60fcffbcba4ee393030349abf5c7dde39b.pdf", "paperhash": "mccann|the_natural_language_decathlon_multitask_learning_as_question_answering", "_bibtex": "@misc{\nmccann2019the,\ntitle={The Natural Language Decathlon: Multitask Learning as Question Answering},\nauthor={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lfHhR9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1522/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311577584, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "B1lfHhR9tm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1522/Authors", "ICLR.cc/2019/Conference/Paper1522/Reviewers", "ICLR.cc/2019/Conference/Paper1522/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311577584}}}], "count": 25}