{"notes": [{"id": "jQSBcVURlpW", "original": "PITiYzGVggHz", "number": 950, "cdate": 1601308107962, "ddate": null, "tcdate": 1601308107962, "tmdate": 1614985749004, "tddate": null, "forum": "jQSBcVURlpW", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning", "authorids": ["~Chi_Zhang12", "~Sirui_Xie1", "~Baoxiong_Jia1", "~Yixin_Zhu1", "~Ying_Nian_Wu1", "~Song-Chun_Zhu1"], "authors": ["Chi Zhang", "Sirui Xie", "Baoxiong Jia", "Yixin Zhu", "Ying Nian Wu", "Song-Chun Zhu"], "keywords": [], "abstract": "Is intelligence realized by connectionist or classicist? While connectionist approaches have achieved superhuman performance, there has been growing evidence that such task-specific superiority is particularly fragile in systematic generalization. This observation lies in the central debate (Fodor et al., 1988; Fodor &McLaughlin, 1990) between connectionist and classicist, wherein the latter continually advocates an algebraic treatment in cognitive architectures. In this work, we follow the classicist's call and propose a hybrid approach to improve systematic generalization in reasoning. Specifically, we showcase a prototype with algebraic representations for the abstract spatial-temporal reasoning task of Raven\u2019s Progressive Matrices (RPM) and present the ALgebra-Aware Neuro-Semi-Symbolic (ALANS$^2$) learner. The ALANS$^2$ learner is motivated by abstract algebra and the representation theory. It consists of a neural visual perception frontend and an algebraic abstract reasoning backend: the frontend summarizes the visual information from object-based representations, while the backend transforms it into an algebraic structure and induces the hidden operator on-the-fly. The induced operator is later executed to predict the answer's representation, and the choice most similar to the prediction is selected as the solution. Extensive experiments show that by incorporating an algebraic treatment, the ALANS$^2$ learner outperforms various pure connectionist models in domains requiring systematic generalization. We further show that the algebraic representation learned can be decoded by isomorphism and used to generate an answer.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhang|learning_algebraic_representation_for_abstract_spatialtemporal_reasoning", "supplementary_material": "/attachment/1905d01393d3b6b39a0ab54a34cf1c9b1d585d48.zip", "pdf": "/pdf/41ae92cb56eedb90e61a7e95df7ebc94984b6696.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=kFcWuOmDoz", "_bibtex": "@misc{\nzhang2021learning,\ntitle={Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning},\nauthor={Chi Zhang and Sirui Xie and Baoxiong Jia and Yixin Zhu and Ying Nian Wu and Song-Chun Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=jQSBcVURlpW}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 13, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "T-TDPcSYHRO", "original": null, "number": 1, "cdate": 1610040386790, "ddate": null, "tcdate": 1610040386790, "tmdate": 1610473980522, "tddate": null, "forum": "jQSBcVURlpW", "replyto": "jQSBcVURlpW", "invitation": "ICLR.cc/2021/Conference/Paper950/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "This paper was reviewed by 4 experts in the field. The reviewers raised their concerns on lack of novelty, unconvincing experiment, and the presentation of this paper, While the paper clearly has merit, the decision is not to recommend acceptance. The authors are encouraged to consider the reviewers' comments when revising the paper for submission elsewhere."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning", "authorids": ["~Chi_Zhang12", "~Sirui_Xie1", "~Baoxiong_Jia1", "~Yixin_Zhu1", "~Ying_Nian_Wu1", "~Song-Chun_Zhu1"], "authors": ["Chi Zhang", "Sirui Xie", "Baoxiong Jia", "Yixin Zhu", "Ying Nian Wu", "Song-Chun Zhu"], "keywords": [], "abstract": "Is intelligence realized by connectionist or classicist? While connectionist approaches have achieved superhuman performance, there has been growing evidence that such task-specific superiority is particularly fragile in systematic generalization. This observation lies in the central debate (Fodor et al., 1988; Fodor &McLaughlin, 1990) between connectionist and classicist, wherein the latter continually advocates an algebraic treatment in cognitive architectures. In this work, we follow the classicist's call and propose a hybrid approach to improve systematic generalization in reasoning. Specifically, we showcase a prototype with algebraic representations for the abstract spatial-temporal reasoning task of Raven\u2019s Progressive Matrices (RPM) and present the ALgebra-Aware Neuro-Semi-Symbolic (ALANS$^2$) learner. The ALANS$^2$ learner is motivated by abstract algebra and the representation theory. It consists of a neural visual perception frontend and an algebraic abstract reasoning backend: the frontend summarizes the visual information from object-based representations, while the backend transforms it into an algebraic structure and induces the hidden operator on-the-fly. The induced operator is later executed to predict the answer's representation, and the choice most similar to the prediction is selected as the solution. Extensive experiments show that by incorporating an algebraic treatment, the ALANS$^2$ learner outperforms various pure connectionist models in domains requiring systematic generalization. We further show that the algebraic representation learned can be decoded by isomorphism and used to generate an answer.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhang|learning_algebraic_representation_for_abstract_spatialtemporal_reasoning", "supplementary_material": "/attachment/1905d01393d3b6b39a0ab54a34cf1c9b1d585d48.zip", "pdf": "/pdf/41ae92cb56eedb90e61a7e95df7ebc94984b6696.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=kFcWuOmDoz", "_bibtex": "@misc{\nzhang2021learning,\ntitle={Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning},\nauthor={Chi Zhang and Sirui Xie and Baoxiong Jia and Yixin Zhu and Ying Nian Wu and Song-Chun Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=jQSBcVURlpW}\n}"}, "tags": [], "invitation": {"reply": {"forum": "jQSBcVURlpW", "replyto": "jQSBcVURlpW", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040386774, "tmdate": 1610473980505, "id": "ICLR.cc/2021/Conference/Paper950/-/Decision"}}}, {"id": "B6Ovhp6gZjT", "original": null, "number": 11, "cdate": 1606169548861, "ddate": null, "tcdate": 1606169548861, "tmdate": 1606169548861, "tddate": null, "forum": "jQSBcVURlpW", "replyto": "1eiBFIYEcR3", "invitation": "ICLR.cc/2021/Conference/Paper950/-/Official_Comment", "content": {"title": "Reply to R3", "comment": "Thank you for your reply.\n\nWe'll include the two points in another revision of the work. We also hope that the reviewer can clarify on which point he/she is not clear about, so that we can do our best to clarify.\n\nIn a theoretic point of view, the task of RPM was initially proposed as a challenge on few-shot abstract reasoning. The task is meaningful at least in the following aspects:\n\n* The problem of inducing the hidden relations from a few examples is, in itself, an interesting problem. Human performance on this abstract reasoning task has been found to be correlated with *general intelligence* (the *g* factor) and *fluid intelligence* (the ability to quickly reason with information to solve new, unfamiliar problems, independent of prior knowledge) [5]. Therefore, improvement on performance on this task may potentially lead to improvement on general AI.\n* Early works found out [3, 4] that Amazonians, absent of schooling, could still correctly answer a nontrivial number of RPM-style problems. How do they transfer knowledge from their living experience into the relational learning problem?\n* We quote from the recent [**AAAI Fall Symposium on Conceptual Abstraction and Analogy in Natural and Artificial Intelligence**](https://sites.google.com/pdx.edu/abstractionfall2020) (click to see details) to support the meaningfulness of this task: \"Understanding what concepts are\u2014how they are formed, can be abstracted and flexibly used in diverse situations via analogy, how they compose to produce new concepts\u2014is not only key to a deeper understanding of intelligence, but will be essential for engineering non-brittle AI systems, ones that can robustly adapt their knowledge to diverse situations and modalities.\" \n\nBut we admit that solving abstract reasoning problems in a human-like way could be only a quest for general intelligence and, at the current stage, may not have found a practical application in the real world: the same question is proposed in the Symposium mentioned above and unfortunately not resolved yet. However, we are optimistic that some techniques developed for solving the task may be adopted for other reasoning problems in the future.\n\n[3] Dehaene, Stanislas, et al. \"Core knowledge of geometry in an Amazonian indigene group.\" Science 311.5759 (2006): 381-384.  \n[4] Izard, V\u00e9ronique, et al. \"Flexible intuitions of Euclidean geometry in an Amazonian indigene group.\" Proceedings of the National Academy of Sciences 108.24 (2011): 9782-9787.  \n[5] Hofstadter, Douglas R. Fluid concepts and creative analogies: Computer models of the fundamental mechanisms of thought. Basic books, 1995.  \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper950/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper950/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning", "authorids": ["~Chi_Zhang12", "~Sirui_Xie1", "~Baoxiong_Jia1", "~Yixin_Zhu1", "~Ying_Nian_Wu1", "~Song-Chun_Zhu1"], "authors": ["Chi Zhang", "Sirui Xie", "Baoxiong Jia", "Yixin Zhu", "Ying Nian Wu", "Song-Chun Zhu"], "keywords": [], "abstract": "Is intelligence realized by connectionist or classicist? While connectionist approaches have achieved superhuman performance, there has been growing evidence that such task-specific superiority is particularly fragile in systematic generalization. This observation lies in the central debate (Fodor et al., 1988; Fodor &McLaughlin, 1990) between connectionist and classicist, wherein the latter continually advocates an algebraic treatment in cognitive architectures. In this work, we follow the classicist's call and propose a hybrid approach to improve systematic generalization in reasoning. Specifically, we showcase a prototype with algebraic representations for the abstract spatial-temporal reasoning task of Raven\u2019s Progressive Matrices (RPM) and present the ALgebra-Aware Neuro-Semi-Symbolic (ALANS$^2$) learner. The ALANS$^2$ learner is motivated by abstract algebra and the representation theory. It consists of a neural visual perception frontend and an algebraic abstract reasoning backend: the frontend summarizes the visual information from object-based representations, while the backend transforms it into an algebraic structure and induces the hidden operator on-the-fly. The induced operator is later executed to predict the answer's representation, and the choice most similar to the prediction is selected as the solution. Extensive experiments show that by incorporating an algebraic treatment, the ALANS$^2$ learner outperforms various pure connectionist models in domains requiring systematic generalization. We further show that the algebraic representation learned can be decoded by isomorphism and used to generate an answer.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhang|learning_algebraic_representation_for_abstract_spatialtemporal_reasoning", "supplementary_material": "/attachment/1905d01393d3b6b39a0ab54a34cf1c9b1d585d48.zip", "pdf": "/pdf/41ae92cb56eedb90e61a7e95df7ebc94984b6696.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=kFcWuOmDoz", "_bibtex": "@misc{\nzhang2021learning,\ntitle={Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning},\nauthor={Chi Zhang and Sirui Xie and Baoxiong Jia and Yixin Zhu and Ying Nian Wu and Song-Chun Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=jQSBcVURlpW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "jQSBcVURlpW", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper950/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper950/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper950/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper950/Authors|ICLR.cc/2021/Conference/Paper950/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper950/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923865429, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper950/-/Official_Comment"}}}, {"id": "1eiBFIYEcR3", "original": null, "number": 10, "cdate": 1606160447898, "ddate": null, "tcdate": 1606160447898, "tmdate": 1606160447898, "tddate": null, "forum": "jQSBcVURlpW", "replyto": "5vO8faqBSY3", "invitation": "ICLR.cc/2021/Conference/Paper950/-/Official_Comment", "content": {"title": "Final comment", "comment": "Thank you for your reply and explanations. It makes more sense now.\n\nI think the paper would benefit from the two explanations you gave in your first 2 points, namely:\n- explaining why you can't train the CNN to predict more attributes. That point is still not 100% clear to me.\n- saying that \"the CNN outputs 4 softmaxed vectors\" and that \"The spaces for these attributes are pre-defined.\" and that you \"performs marginalization and reasoning **as if** they are ground-truth attribute distributions\".\n\nEventually, I think that saying \"the RPM problem is so unique in few-shot induction and logic numerical reasoning that we have not found a more practical vision application to apply\" is a potential weakness. I would suggest the authors to mention a few motivating points why it is useful to train neural models to solve the RPM task. Maybe it shares similar challenges as other real-world problems and working with RPM makes progress more tractable?"}, "signatures": ["ICLR.cc/2021/Conference/Paper950/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper950/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning", "authorids": ["~Chi_Zhang12", "~Sirui_Xie1", "~Baoxiong_Jia1", "~Yixin_Zhu1", "~Ying_Nian_Wu1", "~Song-Chun_Zhu1"], "authors": ["Chi Zhang", "Sirui Xie", "Baoxiong Jia", "Yixin Zhu", "Ying Nian Wu", "Song-Chun Zhu"], "keywords": [], "abstract": "Is intelligence realized by connectionist or classicist? While connectionist approaches have achieved superhuman performance, there has been growing evidence that such task-specific superiority is particularly fragile in systematic generalization. This observation lies in the central debate (Fodor et al., 1988; Fodor &McLaughlin, 1990) between connectionist and classicist, wherein the latter continually advocates an algebraic treatment in cognitive architectures. In this work, we follow the classicist's call and propose a hybrid approach to improve systematic generalization in reasoning. Specifically, we showcase a prototype with algebraic representations for the abstract spatial-temporal reasoning task of Raven\u2019s Progressive Matrices (RPM) and present the ALgebra-Aware Neuro-Semi-Symbolic (ALANS$^2$) learner. The ALANS$^2$ learner is motivated by abstract algebra and the representation theory. It consists of a neural visual perception frontend and an algebraic abstract reasoning backend: the frontend summarizes the visual information from object-based representations, while the backend transforms it into an algebraic structure and induces the hidden operator on-the-fly. The induced operator is later executed to predict the answer's representation, and the choice most similar to the prediction is selected as the solution. Extensive experiments show that by incorporating an algebraic treatment, the ALANS$^2$ learner outperforms various pure connectionist models in domains requiring systematic generalization. We further show that the algebraic representation learned can be decoded by isomorphism and used to generate an answer.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhang|learning_algebraic_representation_for_abstract_spatialtemporal_reasoning", "supplementary_material": "/attachment/1905d01393d3b6b39a0ab54a34cf1c9b1d585d48.zip", "pdf": "/pdf/41ae92cb56eedb90e61a7e95df7ebc94984b6696.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=kFcWuOmDoz", "_bibtex": "@misc{\nzhang2021learning,\ntitle={Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning},\nauthor={Chi Zhang and Sirui Xie and Baoxiong Jia and Yixin Zhu and Ying Nian Wu and Song-Chun Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=jQSBcVURlpW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "jQSBcVURlpW", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper950/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper950/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper950/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper950/Authors|ICLR.cc/2021/Conference/Paper950/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper950/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923865429, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper950/-/Official_Comment"}}}, {"id": "GWAWjhce9O1", "original": null, "number": 9, "cdate": 1606160434556, "ddate": null, "tcdate": 1606160434556, "tmdate": 1606160434556, "tddate": null, "forum": "jQSBcVURlpW", "replyto": "ztMKEwjUmeH", "invitation": "ICLR.cc/2021/Conference/Paper950/-/Official_Comment", "content": {"title": "Reply to R4", "comment": "Thank you for the reply. \n\nOur work tests models' generalization in *relation learning* rather than *attribute learning*. For example, the extrapolation split focuses on how a model trained on the lower half of an attribute can performs on the upper half.  But in this paper, we focus on how relation learning can be generalized. Say, how learning of the relation of **+1** enables the understanding of **+2**. \n\nWe do not use PGM because \n\n* PGM's rule set does not support such generalization tests: we cannot control systematicity (variations) in a rule and there are not rule pairs that support productivity (recursion) and localism (converse of recursion).\n* PGM's generalization focus is not on *relations*, but more on *across attributes*. And the splits do no follow the principles of *systematic generalization*.\n\nThat's the reason why we believe \"The visual generalization part is essential, and a more generalizable visual perception part is undoubtedly desirable, but it is not the point of this work.\""}, "signatures": ["ICLR.cc/2021/Conference/Paper950/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper950/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning", "authorids": ["~Chi_Zhang12", "~Sirui_Xie1", "~Baoxiong_Jia1", "~Yixin_Zhu1", "~Ying_Nian_Wu1", "~Song-Chun_Zhu1"], "authors": ["Chi Zhang", "Sirui Xie", "Baoxiong Jia", "Yixin Zhu", "Ying Nian Wu", "Song-Chun Zhu"], "keywords": [], "abstract": "Is intelligence realized by connectionist or classicist? While connectionist approaches have achieved superhuman performance, there has been growing evidence that such task-specific superiority is particularly fragile in systematic generalization. This observation lies in the central debate (Fodor et al., 1988; Fodor &McLaughlin, 1990) between connectionist and classicist, wherein the latter continually advocates an algebraic treatment in cognitive architectures. In this work, we follow the classicist's call and propose a hybrid approach to improve systematic generalization in reasoning. Specifically, we showcase a prototype with algebraic representations for the abstract spatial-temporal reasoning task of Raven\u2019s Progressive Matrices (RPM) and present the ALgebra-Aware Neuro-Semi-Symbolic (ALANS$^2$) learner. The ALANS$^2$ learner is motivated by abstract algebra and the representation theory. It consists of a neural visual perception frontend and an algebraic abstract reasoning backend: the frontend summarizes the visual information from object-based representations, while the backend transforms it into an algebraic structure and induces the hidden operator on-the-fly. The induced operator is later executed to predict the answer's representation, and the choice most similar to the prediction is selected as the solution. Extensive experiments show that by incorporating an algebraic treatment, the ALANS$^2$ learner outperforms various pure connectionist models in domains requiring systematic generalization. We further show that the algebraic representation learned can be decoded by isomorphism and used to generate an answer.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhang|learning_algebraic_representation_for_abstract_spatialtemporal_reasoning", "supplementary_material": "/attachment/1905d01393d3b6b39a0ab54a34cf1c9b1d585d48.zip", "pdf": "/pdf/41ae92cb56eedb90e61a7e95df7ebc94984b6696.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=kFcWuOmDoz", "_bibtex": "@misc{\nzhang2021learning,\ntitle={Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning},\nauthor={Chi Zhang and Sirui Xie and Baoxiong Jia and Yixin Zhu and Ying Nian Wu and Song-Chun Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=jQSBcVURlpW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "jQSBcVURlpW", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper950/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper950/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper950/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper950/Authors|ICLR.cc/2021/Conference/Paper950/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper950/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923865429, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper950/-/Official_Comment"}}}, {"id": "ztMKEwjUmeH", "original": null, "number": 8, "cdate": 1606156340913, "ddate": null, "tcdate": 1606156340913, "tmdate": 1606156340913, "tddate": null, "forum": "jQSBcVURlpW", "replyto": "xuByeeQMosJ", "invitation": "ICLR.cc/2021/Conference/Paper950/-/Official_Comment", "content": {"title": "About Systematic Generlization", "comment": "Thank you for your reply. Could you explain a bit more why the PGM dataset's splits is out of the scope? Your definition of systemacity is: \n\nSystematicity: the training set contains only a subset of instances for each type of relation, while\nthe test set all other relation instances.\n\nI am not sure why certain splits in PGM are not testing this. For example the training set of extrapolation split contains only objects with attributes lower than a certain threshold for each type of relation, while the test set contains objects with attributes higher than the threshold. Can you explain the differences? Thanks."}, "signatures": ["ICLR.cc/2021/Conference/Paper950/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper950/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning", "authorids": ["~Chi_Zhang12", "~Sirui_Xie1", "~Baoxiong_Jia1", "~Yixin_Zhu1", "~Ying_Nian_Wu1", "~Song-Chun_Zhu1"], "authors": ["Chi Zhang", "Sirui Xie", "Baoxiong Jia", "Yixin Zhu", "Ying Nian Wu", "Song-Chun Zhu"], "keywords": [], "abstract": "Is intelligence realized by connectionist or classicist? While connectionist approaches have achieved superhuman performance, there has been growing evidence that such task-specific superiority is particularly fragile in systematic generalization. This observation lies in the central debate (Fodor et al., 1988; Fodor &McLaughlin, 1990) between connectionist and classicist, wherein the latter continually advocates an algebraic treatment in cognitive architectures. In this work, we follow the classicist's call and propose a hybrid approach to improve systematic generalization in reasoning. Specifically, we showcase a prototype with algebraic representations for the abstract spatial-temporal reasoning task of Raven\u2019s Progressive Matrices (RPM) and present the ALgebra-Aware Neuro-Semi-Symbolic (ALANS$^2$) learner. The ALANS$^2$ learner is motivated by abstract algebra and the representation theory. It consists of a neural visual perception frontend and an algebraic abstract reasoning backend: the frontend summarizes the visual information from object-based representations, while the backend transforms it into an algebraic structure and induces the hidden operator on-the-fly. The induced operator is later executed to predict the answer's representation, and the choice most similar to the prediction is selected as the solution. Extensive experiments show that by incorporating an algebraic treatment, the ALANS$^2$ learner outperforms various pure connectionist models in domains requiring systematic generalization. We further show that the algebraic representation learned can be decoded by isomorphism and used to generate an answer.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhang|learning_algebraic_representation_for_abstract_spatialtemporal_reasoning", "supplementary_material": "/attachment/1905d01393d3b6b39a0ab54a34cf1c9b1d585d48.zip", "pdf": "/pdf/41ae92cb56eedb90e61a7e95df7ebc94984b6696.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=kFcWuOmDoz", "_bibtex": "@misc{\nzhang2021learning,\ntitle={Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning},\nauthor={Chi Zhang and Sirui Xie and Baoxiong Jia and Yixin Zhu and Ying Nian Wu and Song-Chun Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=jQSBcVURlpW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "jQSBcVURlpW", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper950/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper950/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper950/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper950/Authors|ICLR.cc/2021/Conference/Paper950/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper950/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923865429, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper950/-/Official_Comment"}}}, {"id": "5vO8faqBSY3", "original": null, "number": 7, "cdate": 1605167380782, "ddate": null, "tcdate": 1605167380782, "tmdate": 1605582542476, "tddate": null, "forum": "jQSBcVURlpW", "replyto": "Z8GIw34AoSu", "invitation": "ICLR.cc/2021/Conference/Paper950/-/Official_Comment", "content": {"title": "Response to R3", "comment": "Thank you for your support and appreciation in our work to improve systematic generalization in the visual reasoning task.\n\nIt is an excellent question on the broader application of the proposed algebraic representation and the optimization-as-reasoning method---it is also a question we ask ourselves. However, the RPM problem is so unique in few-shot induction and logic numerical reasoning that we have not found a more practical vision application to apply; designing alternative or better problems has been challenging in cognitive science for decades. On this point, any advice on a broader application is welcome. And we are happy to report the performance if the limited time permits.\n\nFor your questions:\n\n* The CNN is trained to predict the type, size, color, and *object existence in a window*. The object existence in windows is marginalized to be a Number distribution and Position distribution. This is a light-weight method for object detection. Nevertheless, it is also possible to use a Fast-RCNN like method to predict object positions (this implies number) directly. However, in this way, the framework loses the probabilistic interpretation (the object proposal branch is currently still deterministic), and we cannot perform end-to-end learning.\n\n* For each window, the CNN outputs 4 softmaxed vectors, corresponding to the probability distributions of object existence, object type, object size, and object color. The spaces for these attributes are pre-defined. CNN's weights are then jointly trained in the framework. Such a design follows recent neuro-symbolic methods [1, 2] that also rely on the implicitly trained representation. In short, we assign semantics to the implicitly trained representation (probability distributions for attributes), performs marginalization and reasoning as if they are ground-truth attribute distributions, and jointly train using only the problem's target label.\n\n* In fact, the visual representation is essential. Keeping the visual CNN as randomly initialized and training only the symbolic part gives a chance-level performance of around 12.5%. This is actually expected: if your vision cannot correctly tell you what you are looking at, there are minimum chances that you get the problems right.\n\n* We will update the related work section to include a discussion on Neural Theorem Proving if accepted. For now, please refer to a new section in appendix for a draft version of it, and if some essential references are missing, we will include them after another revision. \n\n[1] Mao et al. The neurosymbolic concept learner: Interpreting scenes, words, and sentences from natural supervision. ICLR 2019.\n\n[2] Han et al. Visual concept-metaconcept learning. NeurIPS 2019.\n\nIf there is still anything unclear, please let us know and we are more than happy to discuss."}, "signatures": ["ICLR.cc/2021/Conference/Paper950/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper950/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning", "authorids": ["~Chi_Zhang12", "~Sirui_Xie1", "~Baoxiong_Jia1", "~Yixin_Zhu1", "~Ying_Nian_Wu1", "~Song-Chun_Zhu1"], "authors": ["Chi Zhang", "Sirui Xie", "Baoxiong Jia", "Yixin Zhu", "Ying Nian Wu", "Song-Chun Zhu"], "keywords": [], "abstract": "Is intelligence realized by connectionist or classicist? While connectionist approaches have achieved superhuman performance, there has been growing evidence that such task-specific superiority is particularly fragile in systematic generalization. This observation lies in the central debate (Fodor et al., 1988; Fodor &McLaughlin, 1990) between connectionist and classicist, wherein the latter continually advocates an algebraic treatment in cognitive architectures. In this work, we follow the classicist's call and propose a hybrid approach to improve systematic generalization in reasoning. Specifically, we showcase a prototype with algebraic representations for the abstract spatial-temporal reasoning task of Raven\u2019s Progressive Matrices (RPM) and present the ALgebra-Aware Neuro-Semi-Symbolic (ALANS$^2$) learner. The ALANS$^2$ learner is motivated by abstract algebra and the representation theory. It consists of a neural visual perception frontend and an algebraic abstract reasoning backend: the frontend summarizes the visual information from object-based representations, while the backend transforms it into an algebraic structure and induces the hidden operator on-the-fly. The induced operator is later executed to predict the answer's representation, and the choice most similar to the prediction is selected as the solution. Extensive experiments show that by incorporating an algebraic treatment, the ALANS$^2$ learner outperforms various pure connectionist models in domains requiring systematic generalization. We further show that the algebraic representation learned can be decoded by isomorphism and used to generate an answer.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhang|learning_algebraic_representation_for_abstract_spatialtemporal_reasoning", "supplementary_material": "/attachment/1905d01393d3b6b39a0ab54a34cf1c9b1d585d48.zip", "pdf": "/pdf/41ae92cb56eedb90e61a7e95df7ebc94984b6696.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=kFcWuOmDoz", "_bibtex": "@misc{\nzhang2021learning,\ntitle={Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning},\nauthor={Chi Zhang and Sirui Xie and Baoxiong Jia and Yixin Zhu and Ying Nian Wu and Song-Chun Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=jQSBcVURlpW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "jQSBcVURlpW", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper950/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper950/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper950/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper950/Authors|ICLR.cc/2021/Conference/Paper950/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper950/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923865429, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper950/-/Official_Comment"}}}, {"id": "xuByeeQMosJ", "original": null, "number": 5, "cdate": 1605167215561, "ddate": null, "tcdate": 1605167215561, "tmdate": 1605582250714, "tddate": null, "forum": "jQSBcVURlpW", "replyto": "wJnh5H9k8Z", "invitation": "ICLR.cc/2021/Conference/Paper950/-/Official_Comment", "content": {"title": "Response to R4", "comment": "Thank you for your time in reviewing our work and pointing out our potential issues. Thanks for your advice.\n\nFor your concerns:\n\n* Column and row: adding the relations in columns is not the primary problem; we can compare the best rule column-wise and the best rule row-wise and measure the probability as done in Eq (4). Nevertheless, adding this one more step will indeed add noise in gradients.\n\n* PGM and PGM splits: the main point in this work is not to claim superiority in the traditional I.I.D. learning setting but how the specific algebraic inductive bias can improve neural methods in O.O.D. settings in *systematic generalization for different relations*. The PGM dataset's splits focus on generalization in visual attributes and *not on the systematic generalization in relational reasoning*. The visual generalization part is essential, and a more generalizable visual perception part is undoubtedly desirable, but it is not the point of this work.\n\n* CNN disentanglement: the CNN predicts for each window the object existence, object type, object size, and object color. The object existence in windows is marginalized to be a Number distribution and Position distribution. This is a light-weight method for object detection. However, it is also possible to use a Fast-RCNN like method to predict object positions (this implies number) directly. We choose the light-weight method and jointly train the CNN in the entire framework, *without object attributes*. The disentanglement is achieved in a way similar to [1, 2]; in short, we assign semantics to the hidden representation (probability distributions for attributes), performs marginalization and reasoning as if they are ground-truth attribute distributions, and jointly train using only the problem's target label. We show the marginalization process for other attributes in a new section in the appendix.\n\n* Neural Theorem Proving: We included a draft version for related work in neural theorem proving in a new section in the appendix; we welcome any comments on this part.\n\n[1] Mao et al. The neurosymbolic concept learner: Interpreting scenes, words, and sentences from natural supervision. ICLR 2019.\n\n[2] Han et al. Visual concept-metaconcept learning. NeurIPS 2019.\n\nIf there is still anything unclear, please let us know and we are more than happy to discuss."}, "signatures": ["ICLR.cc/2021/Conference/Paper950/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper950/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning", "authorids": ["~Chi_Zhang12", "~Sirui_Xie1", "~Baoxiong_Jia1", "~Yixin_Zhu1", "~Ying_Nian_Wu1", "~Song-Chun_Zhu1"], "authors": ["Chi Zhang", "Sirui Xie", "Baoxiong Jia", "Yixin Zhu", "Ying Nian Wu", "Song-Chun Zhu"], "keywords": [], "abstract": "Is intelligence realized by connectionist or classicist? While connectionist approaches have achieved superhuman performance, there has been growing evidence that such task-specific superiority is particularly fragile in systematic generalization. This observation lies in the central debate (Fodor et al., 1988; Fodor &McLaughlin, 1990) between connectionist and classicist, wherein the latter continually advocates an algebraic treatment in cognitive architectures. In this work, we follow the classicist's call and propose a hybrid approach to improve systematic generalization in reasoning. Specifically, we showcase a prototype with algebraic representations for the abstract spatial-temporal reasoning task of Raven\u2019s Progressive Matrices (RPM) and present the ALgebra-Aware Neuro-Semi-Symbolic (ALANS$^2$) learner. The ALANS$^2$ learner is motivated by abstract algebra and the representation theory. It consists of a neural visual perception frontend and an algebraic abstract reasoning backend: the frontend summarizes the visual information from object-based representations, while the backend transforms it into an algebraic structure and induces the hidden operator on-the-fly. The induced operator is later executed to predict the answer's representation, and the choice most similar to the prediction is selected as the solution. Extensive experiments show that by incorporating an algebraic treatment, the ALANS$^2$ learner outperforms various pure connectionist models in domains requiring systematic generalization. We further show that the algebraic representation learned can be decoded by isomorphism and used to generate an answer.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhang|learning_algebraic_representation_for_abstract_spatialtemporal_reasoning", "supplementary_material": "/attachment/1905d01393d3b6b39a0ab54a34cf1c9b1d585d48.zip", "pdf": "/pdf/41ae92cb56eedb90e61a7e95df7ebc94984b6696.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=kFcWuOmDoz", "_bibtex": "@misc{\nzhang2021learning,\ntitle={Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning},\nauthor={Chi Zhang and Sirui Xie and Baoxiong Jia and Yixin Zhu and Ying Nian Wu and Song-Chun Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=jQSBcVURlpW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "jQSBcVURlpW", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper950/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper950/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper950/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper950/Authors|ICLR.cc/2021/Conference/Paper950/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper950/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923865429, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper950/-/Official_Comment"}}}, {"id": "Q8zp1zWS9C6", "original": null, "number": 4, "cdate": 1605167043424, "ddate": null, "tcdate": 1605167043424, "tmdate": 1605579324911, "tddate": null, "forum": "jQSBcVURlpW", "replyto": "XJq4_kMFABe", "invitation": "ICLR.cc/2021/Conference/Paper950/-/Official_Comment", "content": {"title": "Response to R2", "comment": "Thanks for your time in reviewing our work and pointing out our potential issues. Thanks for your advice.\n\nFor your concerns:\n\n* Algebraic inductive bias: our answer to the algebraic inductive bias is the Peano-Axiom-based encodings together with the representation-theory-based linear operations. Such representation supports easy encode and decode and is potentially more interpretable than a general feature map. The matrix product also enables easy optimization under our current formulation. It is also possible to formulate a more complex optimization problem under the representation, such as a general convex optimization. And very luckily, the gradients can still be backpropagated through using the implicit function theorem. From this perspective, we propose a prototype of the Peano-Axiom-based encodings and the representation-theory-based linear operations, and we believe there is room for future extension.\n\n* Symbolic methods: we have run a search-based symbolic method used for benchmarking in [1]. The method assumes knowledge for the hidden rules and perfect perception, and searches for the most appropriate rule when it encounters a new problem. As reported in [1], the method achieves 100% accuracy. If the reviewer believes there are any other search-based or symbolic methods that need comparing, we will do so if time permits. From this perspective, our work can be positioned as: we need to learn to perceive (there is perception uncertainty), and the hidden rule is to be induced on-the-fly based on constraints realized from vision, rather than given.\n\n* Accuracy: the metrics for each of the split is indeed accuracy; it is the proportion of the problems that are answered correctly. The main point in this work is not to claim superiority in the traditional I.I.D. learning setting but how the specific algebraic inductive bias can improve neural methods in O.O.D. settings in systematic generalization.\n\n* Examples: we have included a few examples for each of the split in a new section of the appendix. However, the differences actually lie in the distribution of relations; the visual part is the same.\n\n[1] Zhang et al. Raven: A dataset for relational and analogical visual reasoning. CVPR 2019.\n\nIf there is still anything unclear, please let us know and we are more than happy to discuss."}, "signatures": ["ICLR.cc/2021/Conference/Paper950/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper950/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning", "authorids": ["~Chi_Zhang12", "~Sirui_Xie1", "~Baoxiong_Jia1", "~Yixin_Zhu1", "~Ying_Nian_Wu1", "~Song-Chun_Zhu1"], "authors": ["Chi Zhang", "Sirui Xie", "Baoxiong Jia", "Yixin Zhu", "Ying Nian Wu", "Song-Chun Zhu"], "keywords": [], "abstract": "Is intelligence realized by connectionist or classicist? While connectionist approaches have achieved superhuman performance, there has been growing evidence that such task-specific superiority is particularly fragile in systematic generalization. This observation lies in the central debate (Fodor et al., 1988; Fodor &McLaughlin, 1990) between connectionist and classicist, wherein the latter continually advocates an algebraic treatment in cognitive architectures. In this work, we follow the classicist's call and propose a hybrid approach to improve systematic generalization in reasoning. Specifically, we showcase a prototype with algebraic representations for the abstract spatial-temporal reasoning task of Raven\u2019s Progressive Matrices (RPM) and present the ALgebra-Aware Neuro-Semi-Symbolic (ALANS$^2$) learner. The ALANS$^2$ learner is motivated by abstract algebra and the representation theory. It consists of a neural visual perception frontend and an algebraic abstract reasoning backend: the frontend summarizes the visual information from object-based representations, while the backend transforms it into an algebraic structure and induces the hidden operator on-the-fly. The induced operator is later executed to predict the answer's representation, and the choice most similar to the prediction is selected as the solution. Extensive experiments show that by incorporating an algebraic treatment, the ALANS$^2$ learner outperforms various pure connectionist models in domains requiring systematic generalization. We further show that the algebraic representation learned can be decoded by isomorphism and used to generate an answer.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhang|learning_algebraic_representation_for_abstract_spatialtemporal_reasoning", "supplementary_material": "/attachment/1905d01393d3b6b39a0ab54a34cf1c9b1d585d48.zip", "pdf": "/pdf/41ae92cb56eedb90e61a7e95df7ebc94984b6696.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=kFcWuOmDoz", "_bibtex": "@misc{\nzhang2021learning,\ntitle={Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning},\nauthor={Chi Zhang and Sirui Xie and Baoxiong Jia and Yixin Zhu and Ying Nian Wu and Song-Chun Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=jQSBcVURlpW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "jQSBcVURlpW", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper950/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper950/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper950/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper950/Authors|ICLR.cc/2021/Conference/Paper950/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper950/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923865429, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper950/-/Official_Comment"}}}, {"id": "nl6zTUk3y2G", "original": null, "number": 6, "cdate": 1605167246381, "ddate": null, "tcdate": 1605167246381, "tmdate": 1605167246381, "tddate": null, "forum": "jQSBcVURlpW", "replyto": "TH7PBUGUOmu", "invitation": "ICLR.cc/2021/Conference/Paper950/-/Official_Comment", "content": {"title": "Response to R1", "comment": "Thank you for your time and efforts in reviewing our work, and most importantly, thanks for the support. \n\nWe corrected the typo in the latest revision and will include any essential references you believe are missing."}, "signatures": ["ICLR.cc/2021/Conference/Paper950/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper950/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning", "authorids": ["~Chi_Zhang12", "~Sirui_Xie1", "~Baoxiong_Jia1", "~Yixin_Zhu1", "~Ying_Nian_Wu1", "~Song-Chun_Zhu1"], "authors": ["Chi Zhang", "Sirui Xie", "Baoxiong Jia", "Yixin Zhu", "Ying Nian Wu", "Song-Chun Zhu"], "keywords": [], "abstract": "Is intelligence realized by connectionist or classicist? While connectionist approaches have achieved superhuman performance, there has been growing evidence that such task-specific superiority is particularly fragile in systematic generalization. This observation lies in the central debate (Fodor et al., 1988; Fodor &McLaughlin, 1990) between connectionist and classicist, wherein the latter continually advocates an algebraic treatment in cognitive architectures. In this work, we follow the classicist's call and propose a hybrid approach to improve systematic generalization in reasoning. Specifically, we showcase a prototype with algebraic representations for the abstract spatial-temporal reasoning task of Raven\u2019s Progressive Matrices (RPM) and present the ALgebra-Aware Neuro-Semi-Symbolic (ALANS$^2$) learner. The ALANS$^2$ learner is motivated by abstract algebra and the representation theory. It consists of a neural visual perception frontend and an algebraic abstract reasoning backend: the frontend summarizes the visual information from object-based representations, while the backend transforms it into an algebraic structure and induces the hidden operator on-the-fly. The induced operator is later executed to predict the answer's representation, and the choice most similar to the prediction is selected as the solution. Extensive experiments show that by incorporating an algebraic treatment, the ALANS$^2$ learner outperforms various pure connectionist models in domains requiring systematic generalization. We further show that the algebraic representation learned can be decoded by isomorphism and used to generate an answer.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhang|learning_algebraic_representation_for_abstract_spatialtemporal_reasoning", "supplementary_material": "/attachment/1905d01393d3b6b39a0ab54a34cf1c9b1d585d48.zip", "pdf": "/pdf/41ae92cb56eedb90e61a7e95df7ebc94984b6696.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=kFcWuOmDoz", "_bibtex": "@misc{\nzhang2021learning,\ntitle={Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning},\nauthor={Chi Zhang and Sirui Xie and Baoxiong Jia and Yixin Zhu and Ying Nian Wu and Song-Chun Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=jQSBcVURlpW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "jQSBcVURlpW", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper950/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper950/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper950/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper950/Authors|ICLR.cc/2021/Conference/Paper950/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper950/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923865429, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper950/-/Official_Comment"}}}, {"id": "Z8GIw34AoSu", "original": null, "number": 1, "cdate": 1603484083547, "ddate": null, "tcdate": 1603484083547, "tmdate": 1605024567482, "tddate": null, "forum": "jQSBcVURlpW", "replyto": "jQSBcVURlpW", "invitation": "ICLR.cc/2021/Conference/Paper950/-/Official_Review", "content": {"title": "Good but could benefit further clarification and discussion on the applications of this work", "review": "**Summary**.\nThis work proposes a new learner bridging the gap between connectionists and classicists in the task of Raven\u2019s Progressive Matrices (RPM). It relies on a CNN to extract visual features and then uses an algebraic abstract reasoning module to infer the operators of an RPM instance, which allows applying the inferred operator on the RPM instance to predict potential solutions according to various attributes. The most likely solution according to the ensemble of the attributes is then selected as an answer.\n\n**Pros**.\n- This work is significant as neural models still struggle in systematically generalizing in reasoning tasks.\n- The general idea of the paper is easy to follow but that does not mean the proposed method is trivial, far from it.\n- Experiments are clearly described and the authors give particular attention to split their dataset to systematically test for generalization.\n\n**Cons**.\n- Additional clarifications and motivations could benefit the paper (see **Questions & Suggestions** below).\n- While yielding impressive results and targeting a fundamental issue of neural models, it is not clear how the proposed technique could be applied to other domains. As of now the paper focus only on the RPM task. It would be beneficial to open up the discussion to potential applications. It would be nice to know what the authors think are the potential applications of their learner. How would it be applied to other reasoning tasks?\n\n**Questions & Suggestions**.\n- The CNN is used to predict the presence of an object, its type, its size, and its color while a belief inference engine is used to predict the position and number of objects. It is not clear why the CNN was not also used to predict the position and number of objects, thus questioning the motivation behind the belief inference engine.\nWould training a CNN to predict the position and number of objects also help?\n- It is not clear how the CNN predicts the presence of an object, its type, size, and color given that it is not trained to do that. Do you produce 4 feature vectors, apply a softmax to each, and arbitrarily decide which feature vector will predict each object attribute? If so the results in Table2 are very impressive and hard to believe. How do you decide which feature vector will predict each object attribute?\n- Suggestion: as an ablation study, it would be nice to also compare the performance of ALANSS with randomly initialized and fixed CNNs. This would give an estimate on the advantage of using CNNs as neural modules. One could hypothesize that the robustness of the method comes mostly from the symbolic abstraction rather than the neural representation.\n- Neural Theorem Proving also tries to bridge the gap between connectionists and classicist approaches. Can it be related to this work? It would be nice to discuss this in the Related Work section.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper950/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper950/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning", "authorids": ["~Chi_Zhang12", "~Sirui_Xie1", "~Baoxiong_Jia1", "~Yixin_Zhu1", "~Ying_Nian_Wu1", "~Song-Chun_Zhu1"], "authors": ["Chi Zhang", "Sirui Xie", "Baoxiong Jia", "Yixin Zhu", "Ying Nian Wu", "Song-Chun Zhu"], "keywords": [], "abstract": "Is intelligence realized by connectionist or classicist? While connectionist approaches have achieved superhuman performance, there has been growing evidence that such task-specific superiority is particularly fragile in systematic generalization. This observation lies in the central debate (Fodor et al., 1988; Fodor &McLaughlin, 1990) between connectionist and classicist, wherein the latter continually advocates an algebraic treatment in cognitive architectures. In this work, we follow the classicist's call and propose a hybrid approach to improve systematic generalization in reasoning. Specifically, we showcase a prototype with algebraic representations for the abstract spatial-temporal reasoning task of Raven\u2019s Progressive Matrices (RPM) and present the ALgebra-Aware Neuro-Semi-Symbolic (ALANS$^2$) learner. The ALANS$^2$ learner is motivated by abstract algebra and the representation theory. It consists of a neural visual perception frontend and an algebraic abstract reasoning backend: the frontend summarizes the visual information from object-based representations, while the backend transforms it into an algebraic structure and induces the hidden operator on-the-fly. The induced operator is later executed to predict the answer's representation, and the choice most similar to the prediction is selected as the solution. Extensive experiments show that by incorporating an algebraic treatment, the ALANS$^2$ learner outperforms various pure connectionist models in domains requiring systematic generalization. We further show that the algebraic representation learned can be decoded by isomorphism and used to generate an answer.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhang|learning_algebraic_representation_for_abstract_spatialtemporal_reasoning", "supplementary_material": "/attachment/1905d01393d3b6b39a0ab54a34cf1c9b1d585d48.zip", "pdf": "/pdf/41ae92cb56eedb90e61a7e95df7ebc94984b6696.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=kFcWuOmDoz", "_bibtex": "@misc{\nzhang2021learning,\ntitle={Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning},\nauthor={Chi Zhang and Sirui Xie and Baoxiong Jia and Yixin Zhu and Ying Nian Wu and Song-Chun Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=jQSBcVURlpW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "jQSBcVURlpW", "replyto": "jQSBcVURlpW", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper950/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538130898, "tmdate": 1606915768674, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper950/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper950/-/Official_Review"}}}, {"id": "wJnh5H9k8Z", "original": null, "number": 3, "cdate": 1603894587170, "ddate": null, "tcdate": 1603894587170, "tmdate": 1605024567415, "tddate": null, "forum": "jQSBcVURlpW", "replyto": "jQSBcVURlpW", "invitation": "ICLR.cc/2021/Conference/Paper950/-/Official_Review", "content": {"title": "Paper 950 Review", "review": "This paper proposed ALANS, a semi neuro-symbolic learner specifically designed for improved systematic generalization on RAVEN dataset.\n\nPros:\n1. The proposed model integrates learnable symbolic operators that are similar to the ones used in Neural Theorem Proving. The operators are shown to have improved systematic generalization performance.\n2. Introduced a new generalization testing dataset based on RAVEN dataset.\n\nCons:\n1. The proposed model relies on strong assumptions specific to RPM, and even RAVEN dataset. For example, In Equation 3, the authors assume the knowledge that relations can only exist in rows of the RAVEN dataset. However for PGM dataset (another well-known RPM dataset), the relations can exist either in rows or columns, or both. I hypothesize that training operators when there is no guaranteed existence of relations will lead to noisy gradients. I have doubts that the proposed method can be readily adapted to PGM, not to mention other types of reasoning tasks.\n2. While the proposed model is shown to perform well on the dataset generated based on RAVEN, I think the authors should show results on PGM dataset as well, considering that PGM already have a few data splits to test systematic generalization.\n\nClarity:\nIn general the paper is written in a clear and understandable manner. The only part that confuses me is about the perception CNN module. It is not clear to me how the model learns to disentangle object attributes such as color and position? Is there any auxiliary labels to help induce such disentanglement, or does the model learn to disentangle the attributes because of the way authors marginalize the object attributes in a diagram? The authors only show the marginalization for the attribute 'number'. I suggest the authors to include the marginalization for all other attributes in the Appendix for better understandability. \n\nSummary:\nOverall I think this paper propose an interesting approach that improves systematic generalization on RAVEN datasets. But I have doubts on its adaptabilities to PGM dataset and other types of reasoning tasks. And there is also some lacking details that hinders understanding of the paper. I will raise my score if the authors can (1) show improved performance on generalization data splits on PGM dataset, and (2) clarify about how the model learns to disentanglement the object attributes.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper950/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper950/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning", "authorids": ["~Chi_Zhang12", "~Sirui_Xie1", "~Baoxiong_Jia1", "~Yixin_Zhu1", "~Ying_Nian_Wu1", "~Song-Chun_Zhu1"], "authors": ["Chi Zhang", "Sirui Xie", "Baoxiong Jia", "Yixin Zhu", "Ying Nian Wu", "Song-Chun Zhu"], "keywords": [], "abstract": "Is intelligence realized by connectionist or classicist? While connectionist approaches have achieved superhuman performance, there has been growing evidence that such task-specific superiority is particularly fragile in systematic generalization. This observation lies in the central debate (Fodor et al., 1988; Fodor &McLaughlin, 1990) between connectionist and classicist, wherein the latter continually advocates an algebraic treatment in cognitive architectures. In this work, we follow the classicist's call and propose a hybrid approach to improve systematic generalization in reasoning. Specifically, we showcase a prototype with algebraic representations for the abstract spatial-temporal reasoning task of Raven\u2019s Progressive Matrices (RPM) and present the ALgebra-Aware Neuro-Semi-Symbolic (ALANS$^2$) learner. The ALANS$^2$ learner is motivated by abstract algebra and the representation theory. It consists of a neural visual perception frontend and an algebraic abstract reasoning backend: the frontend summarizes the visual information from object-based representations, while the backend transforms it into an algebraic structure and induces the hidden operator on-the-fly. The induced operator is later executed to predict the answer's representation, and the choice most similar to the prediction is selected as the solution. Extensive experiments show that by incorporating an algebraic treatment, the ALANS$^2$ learner outperforms various pure connectionist models in domains requiring systematic generalization. We further show that the algebraic representation learned can be decoded by isomorphism and used to generate an answer.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhang|learning_algebraic_representation_for_abstract_spatialtemporal_reasoning", "supplementary_material": "/attachment/1905d01393d3b6b39a0ab54a34cf1c9b1d585d48.zip", "pdf": "/pdf/41ae92cb56eedb90e61a7e95df7ebc94984b6696.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=kFcWuOmDoz", "_bibtex": "@misc{\nzhang2021learning,\ntitle={Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning},\nauthor={Chi Zhang and Sirui Xie and Baoxiong Jia and Yixin Zhu and Ying Nian Wu and Song-Chun Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=jQSBcVURlpW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "jQSBcVURlpW", "replyto": "jQSBcVURlpW", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper950/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538130898, "tmdate": 1606915768674, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper950/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper950/-/Official_Review"}}}, {"id": "TH7PBUGUOmu", "original": null, "number": 2, "cdate": 1603872678138, "ddate": null, "tcdate": 1603872678138, "tmdate": 1605024567338, "tddate": null, "forum": "jQSBcVURlpW", "replyto": "jQSBcVURlpW", "invitation": "ICLR.cc/2021/Conference/Paper950/-/Official_Review", "content": {"title": "Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning", "review": "The author(s) propose an architecture ALANS^2, primarily focused on the task\nof Raven's Progressive Matrices (RPM, popularly known as IQ tests).\nTo solve it, they join an image classifier on the individual fields\nof the 3x3 picture matrix with a \"reasoning backend\". In the backend,\nthey model the high level rules of the task by matrix multiplication.\nGiven a problem instance, they find a such an operator (matrix) that fits\nthe first two rows of the instance the best, and use this operator\nto determine what picture belongs to the missing field.\n\nFor training, they use not only the knowledge of the correct answer but also\nthe correct operator which should be found (the \"rule\" which should be discovered).\nExperimental results show that they exceed by a margin\nthe previous models used for this task.\n\nThe task is interesting, in fact some research has been done on trying to\nlearn intelligence tests in various ways and a number of the relevant ones\nare properly cited in the paper.\n\nThe results presented show an improvement with respect to previous\nresults that I find enough to deserve publication.\n\nThe article is well written apart from the typo mentioned below.\n\nTypo:\nPg3, part \"Abstract Visual Reasoning\" last sentence: fronend -> frontend\n", "rating": "7: Good paper, accept", "confidence": "1: The reviewer's evaluation is an educated guess"}, "signatures": ["ICLR.cc/2021/Conference/Paper950/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper950/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning", "authorids": ["~Chi_Zhang12", "~Sirui_Xie1", "~Baoxiong_Jia1", "~Yixin_Zhu1", "~Ying_Nian_Wu1", "~Song-Chun_Zhu1"], "authors": ["Chi Zhang", "Sirui Xie", "Baoxiong Jia", "Yixin Zhu", "Ying Nian Wu", "Song-Chun Zhu"], "keywords": [], "abstract": "Is intelligence realized by connectionist or classicist? While connectionist approaches have achieved superhuman performance, there has been growing evidence that such task-specific superiority is particularly fragile in systematic generalization. This observation lies in the central debate (Fodor et al., 1988; Fodor &McLaughlin, 1990) between connectionist and classicist, wherein the latter continually advocates an algebraic treatment in cognitive architectures. In this work, we follow the classicist's call and propose a hybrid approach to improve systematic generalization in reasoning. Specifically, we showcase a prototype with algebraic representations for the abstract spatial-temporal reasoning task of Raven\u2019s Progressive Matrices (RPM) and present the ALgebra-Aware Neuro-Semi-Symbolic (ALANS$^2$) learner. The ALANS$^2$ learner is motivated by abstract algebra and the representation theory. It consists of a neural visual perception frontend and an algebraic abstract reasoning backend: the frontend summarizes the visual information from object-based representations, while the backend transforms it into an algebraic structure and induces the hidden operator on-the-fly. The induced operator is later executed to predict the answer's representation, and the choice most similar to the prediction is selected as the solution. Extensive experiments show that by incorporating an algebraic treatment, the ALANS$^2$ learner outperforms various pure connectionist models in domains requiring systematic generalization. We further show that the algebraic representation learned can be decoded by isomorphism and used to generate an answer.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhang|learning_algebraic_representation_for_abstract_spatialtemporal_reasoning", "supplementary_material": "/attachment/1905d01393d3b6b39a0ab54a34cf1c9b1d585d48.zip", "pdf": "/pdf/41ae92cb56eedb90e61a7e95df7ebc94984b6696.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=kFcWuOmDoz", "_bibtex": "@misc{\nzhang2021learning,\ntitle={Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning},\nauthor={Chi Zhang and Sirui Xie and Baoxiong Jia and Yixin Zhu and Ying Nian Wu and Song-Chun Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=jQSBcVURlpW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "jQSBcVURlpW", "replyto": "jQSBcVURlpW", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper950/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538130898, "tmdate": 1606915768674, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper950/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper950/-/Official_Review"}}}, {"id": "XJq4_kMFABe", "original": null, "number": 4, "cdate": 1604249353163, "ddate": null, "tcdate": 1604249353163, "tmdate": 1605024567264, "tddate": null, "forum": "jQSBcVURlpW", "replyto": "jQSBcVURlpW", "invitation": "ICLR.cc/2021/Conference/Paper950/-/Official_Review", "content": {"title": "initial review", "review": "Initial review (2020.11.01)\n\nReview: \nThis paper addresses a specialized solution to combine neural networks and linear models for Raven progressive matrices (RPM). The solver is composed of convolutional neural networks (CNN) as an image perception module and a reasoning module with linearly parameterized operators to represent successive operations in the RPM. The operators are trained with regularized linear regressors, which are lightweight capable to adapt on-the-fly for each instance. The overall architecture enables end-to-end training and can be used for generation. For performance evaluation on two kinds of automatically generated problem sets, the authors test the proposed method with respect to 3 extrapolatory settings such as systematicity, productivity, and localism, which seems to be newly defined tasks for RPM. Their method outperforms pure neural state-of-the-art methods with a large margin over all of settings. \nThe proposed methods solve RPMs well with available components such as CNNs and linear models, which are able to be tuned on-the-fly. Also, this paper provides systematic results to easily comprehend the role of modules with new settings (systematicity, productivity, and localism) for RPMs. On the other hands, my major concerns are two-fold: (1) one of important research questions introduced in this work, \u201cwhat constitutes such an algebraic inductive bias?\u201d seems not so clearly answered in this paper. (2) the comparative result in the paper just considers only pure connectionist methods without considering other (semi-)symbolic approaches. Since this work utilizes additional problem information (e.g., specified features) for modeling than compared neural methods, I think it would be better to justify the position of this work by comparing various approaches including search-based solver, symbolic, and the neural methods to figure out the superiority of this approach.\nAs a result, I vote for marginally below acceptance threshold.\n\nPros:\n-\tThe authors provide a specialized solution for RPM well with CNNs and linear models.\n-\tThey introduce new 3 settings of RPMs and report systematic experimental results.\n\nConcerns:\n-\tIn the comparative study, the authors report only the systematicity, the productivity, and the localism, not the \"accuracy\" used in the cited related works. Due to the lack of the information, the readers can not directly compare them with respect to the previous viewpoint.\n-\tIf the result of other various approaches for RPM not only pure connectionist methods but also search-based solver, symbolic, and neuro-symbolic approaches, it would be easier to find the niche of this work and its superiority.\n-\tAs I mentioned above, the research questions, \u201cwhat constitutes such an algebraic inductive bias?\u201d seems not so clearly answered in this paper. Could you discuss this issue with the result in the paper?\n\nMinors:\n-\tIt would be better understandable to show examples for 3 settings of systematicity, productivity and localism on RPMs.\n-\tfare -> far?\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper950/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper950/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning", "authorids": ["~Chi_Zhang12", "~Sirui_Xie1", "~Baoxiong_Jia1", "~Yixin_Zhu1", "~Ying_Nian_Wu1", "~Song-Chun_Zhu1"], "authors": ["Chi Zhang", "Sirui Xie", "Baoxiong Jia", "Yixin Zhu", "Ying Nian Wu", "Song-Chun Zhu"], "keywords": [], "abstract": "Is intelligence realized by connectionist or classicist? While connectionist approaches have achieved superhuman performance, there has been growing evidence that such task-specific superiority is particularly fragile in systematic generalization. This observation lies in the central debate (Fodor et al., 1988; Fodor &McLaughlin, 1990) between connectionist and classicist, wherein the latter continually advocates an algebraic treatment in cognitive architectures. In this work, we follow the classicist's call and propose a hybrid approach to improve systematic generalization in reasoning. Specifically, we showcase a prototype with algebraic representations for the abstract spatial-temporal reasoning task of Raven\u2019s Progressive Matrices (RPM) and present the ALgebra-Aware Neuro-Semi-Symbolic (ALANS$^2$) learner. The ALANS$^2$ learner is motivated by abstract algebra and the representation theory. It consists of a neural visual perception frontend and an algebraic abstract reasoning backend: the frontend summarizes the visual information from object-based representations, while the backend transforms it into an algebraic structure and induces the hidden operator on-the-fly. The induced operator is later executed to predict the answer's representation, and the choice most similar to the prediction is selected as the solution. Extensive experiments show that by incorporating an algebraic treatment, the ALANS$^2$ learner outperforms various pure connectionist models in domains requiring systematic generalization. We further show that the algebraic representation learned can be decoded by isomorphism and used to generate an answer.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhang|learning_algebraic_representation_for_abstract_spatialtemporal_reasoning", "supplementary_material": "/attachment/1905d01393d3b6b39a0ab54a34cf1c9b1d585d48.zip", "pdf": "/pdf/41ae92cb56eedb90e61a7e95df7ebc94984b6696.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=kFcWuOmDoz", "_bibtex": "@misc{\nzhang2021learning,\ntitle={Learning Algebraic Representation for Abstract Spatial-Temporal Reasoning},\nauthor={Chi Zhang and Sirui Xie and Baoxiong Jia and Yixin Zhu and Ying Nian Wu and Song-Chun Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=jQSBcVURlpW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "jQSBcVURlpW", "replyto": "jQSBcVURlpW", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper950/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538130898, "tmdate": 1606915768674, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper950/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper950/-/Official_Review"}}}], "count": 14}