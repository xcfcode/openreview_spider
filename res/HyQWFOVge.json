{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396311332, "tcdate": 1486396311332, "number": 1, "id": "BkJsizLOg", "invitation": "ICLR.cc/2017/conference/-/paper23/acceptance", "forum": "HyQWFOVge", "replyto": "HyQWFOVge", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "The paper aims to compare the representations learnt by metric learning and classification objectives. While this is an interesting topic, the presented evaluation is not sufficiently clear for the paper to be accepted."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396311841, "id": "ICLR.cc/2017/conference/-/paper23/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "HyQWFOVge", "replyto": "HyQWFOVge", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396311841}}}, {"tddate": null, "tmdate": 1485835967938, "tcdate": 1485835967938, "number": 14, "id": "rydTAFaPx", "invitation": "ICLR.cc/2017/conference/-/paper23/public/comment", "forum": "HyQWFOVge", "replyto": "rJhLMYiPg", "signatures": ["~Daiki_Ikami1"], "readers": ["everyone"], "writers": ["~Daiki_Ikami1"], "content": {"title": "Re: revision more problematic than the original", "comment": "Let us clarify the story.\n\nIn the first place, we can interpret Rippel's training strategy by two ways: (1) 3-epoch pretraining on ImageNet and (2) 3-epoch finetuning on each dataset after full pretraining on ImageNet. Although we have not get Rippel's reply for about a month, we examined which interpretation is correct by our reproductive experiments.\n\nWe managed to reimplement Magnet loss and we can reproduce Rippel's results by the latter interpretation and can not reproduce by the former interpretation. This duplication suggests that the latter interpretation is right.\n\nFor the softmax results in Rippel's paper, no one can identify the cause of his worse results than ours, just because he does not describe the training strategies, such as learning rate, in his paper; thus, the softmax results in Rippel's paper are not contradictions."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287760585, "id": "ICLR.cc/2017/conference/-/paper23/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyQWFOVge", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper23/reviewers", "ICLR.cc/2017/conference/paper23/areachairs"], "cdate": 1485287760585}}}, {"tddate": null, "tmdate": 1485701716147, "tcdate": 1485701716147, "number": 9, "id": "rJhLMYiPg", "invitation": "ICLR.cc/2017/conference/-/paper23/official/comment", "forum": "HyQWFOVge", "replyto": "HyVWsbiDe", "signatures": ["ICLR.cc/2017/conference/paper23/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper23/AnonReviewer3"], "content": {"title": "Re: revision more problematic than the original", "comment": "This is a paper with essentially no novelty that aims to show that softmax can outperform DML. As such, the experimental correctness is of fundamental importance. However, the experiments are not up to par.\n\nThe authors have not been able to reproduce Rippel's result, and Rippel has not released code. This is unfortunate. Nevertheless, it does not change the main concern with this paper.\n\nAnd to reiterate: none of the discussion in these comments below appears in the paper. The authors' current hypothesis is that Rippel does full pre-training on ImageNet, which directly contradicts what is written in Rippel's paper (and the authors' experiments don't fully support this either, as it does not explain the softmax results in Rippel's paper). But, let me not quibble about the details: the damning concern is that the paper simply hides all this and says that under identical conditions they outperform Rippel, which is likely false.\n\nRegardless, let me reaffirm my recommendation that this paper should not be accepted.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287760453, "id": "ICLR.cc/2017/conference/-/paper23/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "HyQWFOVge", "writers": {"values-regex": "ICLR.cc/2017/conference/paper23/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper23/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper23/reviewers", "ICLR.cc/2017/conference/paper23/areachairs"], "cdate": 1485287760453}}}, {"tddate": null, "tmdate": 1485671163820, "tcdate": 1485671163820, "number": 13, "id": "HyVWsbiDe", "invitation": "ICLR.cc/2017/conference/-/paper23/public/comment", "forum": "HyQWFOVge", "replyto": "ryhPQ-tPl", "signatures": ["~Shota_Horiguchi1"], "readers": ["everyone"], "writers": ["~Shota_Horiguchi1"], "content": {"title": "Re: revision more problematic than the original", "comment": "What we found in our reproductive experiments is \"when finetuned from fully-pretrained weights, softmax outperformed Magnet Loss.\"\nWe think this fact is very important for the community.\n\nPS\nHe said that he could not release his codes in his first reply.\nHe did not respond about the details of his experiments.\nThe objective contains an additional hyperparameter, so perfect reproduction is very hard.\nWe tried a lot of experimental settings to reproduce his results, and managed to reproduce them.\nOur result is still significantly better and our claim does not change.\nIs it a confusing result?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287760585, "id": "ICLR.cc/2017/conference/-/paper23/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyQWFOVge", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper23/reviewers", "ICLR.cc/2017/conference/paper23/areachairs"], "cdate": 1485287760585}}}, {"tddate": null, "tmdate": 1485538148259, "tcdate": 1485538148259, "number": 8, "id": "ryhPQ-tPl", "invitation": "ICLR.cc/2017/conference/-/paper23/official/comment", "forum": "HyQWFOVge", "replyto": "HyQWFOVge", "signatures": ["ICLR.cc/2017/conference/paper23/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper23/AnonReviewer3"], "content": {"title": "revision more problematic than the original", "comment": "The revision raises even more concern and red flags than the original version.\n\nMy main concern originally was that the comparisons to Rippel et al. were not apples-to-apples due to different ImageNet pre-training strategies. Those strategies were discussed in the original draft, but in the experiments were not highlighted, so the experiments felt quite misleading.\n\nThe authors now claim that in the paoer \"These strategies are exactly the same as those of the previous method (Rippel et al., 2016).\" So instead of modifying the experiments and the tone of the paper to account for the differences, now the differences are entirely removed from the paper! The authors provided extended discussion in the comment thread here, but it was inconclusive. The paper now contains no discussion of this absolutely critical issue.\n\nWhile I was originally sympathetic to this work, at this stage I am concerned it will create much more confusion in the community rather than resolve it. As such, I cannot recommend acceptance.\n\nMy updated recommendation is: \"4: Ok but not good enough - rejection\""}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287760453, "id": "ICLR.cc/2017/conference/-/paper23/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "HyQWFOVge", "writers": {"values-regex": "ICLR.cc/2017/conference/paper23/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper23/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper23/reviewers", "ICLR.cc/2017/conference/paper23/areachairs"], "cdate": 1485287760453}}}, {"tddate": null, "tmdate": 1484290492290, "tcdate": 1484290492290, "number": 12, "id": "ry4TKl8Ux", "invitation": "ICLR.cc/2017/conference/-/paper23/public/comment", "forum": "HyQWFOVge", "replyto": "SJZ6q-zEx", "signatures": ["~Shota_Horiguchi1"], "readers": ["everyone"], "writers": ["~Shota_Horiguchi1"], "content": {"title": "Re: review", "comment": "We posted about the reproductive experiments of Magnet Loss.\nplease see our comments"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287760585, "id": "ICLR.cc/2017/conference/-/paper23/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyQWFOVge", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper23/reviewers", "ICLR.cc/2017/conference/paper23/areachairs"], "cdate": 1485287760585}}}, {"tddate": null, "tmdate": 1484290446855, "tcdate": 1484290446855, "number": 11, "id": "BJw9FeULe", "invitation": "ICLR.cc/2017/conference/-/paper23/public/comment", "forum": "HyQWFOVge", "replyto": "B1Lus18Ex", "signatures": ["~Shota_Horiguchi1"], "readers": ["everyone"], "writers": ["~Shota_Horiguchi1"], "content": {"title": "Re: Interesting discussion but sharing concern with reviewer 3 ", "comment": "We posted about the reproductive experiments of Magnet Loss.\nPlease see our comments."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287760585, "id": "ICLR.cc/2017/conference/-/paper23/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyQWFOVge", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper23/reviewers", "ICLR.cc/2017/conference/paper23/areachairs"], "cdate": 1485287760585}}}, {"tddate": null, "tmdate": 1484290323189, "tcdate": 1484290323189, "number": 10, "id": "HJjfteLUx", "invitation": "ICLR.cc/2017/conference/-/paper23/public/comment", "forum": "HyQWFOVge", "replyto": "HyQWFOVge", "signatures": ["~Shota_Horiguchi1"], "readers": ["everyone"], "writers": ["~Shota_Horiguchi1"], "content": {"title": "Results of reproductive experiments", "comment": "We asked Rippel about unclear points of his proposed method, and from his reply we came to know that the actual Magnet Loss contains another hyper parameter which is not explicitly described in his paper. We also requested him to give us his source codes but were refused because the code is internally and proprietary. We reproduced his Magnet loss and obtained results which seems similar to Rippel's under different interpretation of \"3 epochs\". We asked him about the interpretation of \"3 epochs\", but so far we have not received his reply. We will report our findings below.\n\nAt first we quote from Rippel's paper as follows:\n\"We find that it is useful to warm-start any DML optimization with weights of a partly-trained a standard softmax classifier. It is important to not use weights of a net trained to completion, as this would result in information dissipation and as such defeat the purpose of pursuing DML in the first place. Hence, we initialize all models with the weights of a net trained on ImageNet (Russakovsky et al., 2015) for 3 epochs only.\"\n(1) We had been interpreting this sentence as \"the network is trained on ImageNet for 3 epochs.\" First we conducted the experiments based on this interpretation, but the results were completely worse than those Rippel reported in his paper.\n   Stanford Dogs: 52.6 % (Rippel's result: 24.9 %)\n   Oxford 102 Flower: 43.7 % (Rippel's result: 8.6 %)\n   Oxford-IIIT Pet: 32.0 % (Rippel's result: 10.6 %)\n(2) However, the sentence can be interpreted as another way: \"the network is fully trained on ImageNet, and then the network is trained on each datasets, e.g. Stanford Dogs, for 3 epochs.\" We did the experiment by this interpretation and we could reproduce the Rippel's results as:\n   Stanford Dogs: 25.5 % (Rippel's result: 24.9 %)\n   Oxford 102 Flower: 7.4 % (Rippel's result: 8.6 %)\n   Oxford-IIIT Pet: 12.2 % (Rippel's result: 10.6 %)\nFrom these results, we believe that the second interpretation is true. But if so, we cannot explain why Rippel's results of softmax were completely worse than our results:\n   Stanford Dogs: 18.3 % (Rippel's result: 26.6 %)\n   Oxford 102 Flower: 8.69 % (Rippel's result: 11.2%)\n   Oxford-IIIT Pet: 9.04 % (Rippel's result: 11.3 %)\nAccording to our experiment, their softmax results do not seem the best ones. The training strategies for softmax were not described in his paper, so we cannot confirm whether his experiments were conducted in a fair manner.\n\nOur claim is that softmax-based feature is underestimated in many DML-based studies and must be taken into consideration as the baseline when evaluating DML-based features. (In fact, new DML papers without comparison to softmax-based features appeared during this rebuttal period.) We show that softmax-based features outperform lifted structed embedding, one of the latest DML method, by equitable comparison. Our softmax-based features also outperform Magnet loss which are presented in Rippel's paper. We think this fact is important to make sure that softmax is a strong baseline for feature representation."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287760585, "id": "ICLR.cc/2017/conference/-/paper23/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyQWFOVge", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper23/reviewers", "ICLR.cc/2017/conference/paper23/areachairs"], "cdate": 1485287760585}}}, {"tddate": null, "tmdate": 1484290155372, "tcdate": 1484290155372, "number": 8, "id": "HJm_dg88e", "invitation": "ICLR.cc/2017/conference/-/paper23/public/comment", "forum": "HyQWFOVge", "replyto": "HyQWFOVge", "signatures": ["~Shota_Horiguchi1"], "readers": ["everyone"], "writers": ["~Shota_Horiguchi1"], "content": {"title": "Paper revision", "comment": "We revised our paper responding to reviewers' comments.\nChanges are as follows:\n\n* We revise about Magnet Loss (Section 2.1, 4.2).\n\n* We added limitations to the end of \"Conclusion\".\n\n* We clarified network architectures in \"Procedure\".\n\n* Other minor clarifications."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287760585, "id": "ICLR.cc/2017/conference/-/paper23/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyQWFOVge", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper23/reviewers", "ICLR.cc/2017/conference/paper23/areachairs"], "cdate": 1485287760585}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1484287024070, "tcdate": 1477900541619, "number": 23, "id": "HyQWFOVge", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "HyQWFOVge", "signatures": ["~Shota_Horiguchi1"], "readers": ["everyone"], "content": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 24, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1483751417607, "tcdate": 1483751417607, "number": 5, "id": "rJfWl66Sl", "invitation": "ICLR.cc/2017/conference/-/paper23/official/comment", "forum": "HyQWFOVge", "replyto": "r1sW2gtNe", "signatures": ["ICLR.cc/2017/conference/paper23/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper23/AnonReviewer1"], "content": {"title": "Re: Thanks for clarifications.", "comment": "I'm certainly not going to demand new experiments, although more can only help.\n\nI'm not really seeking clarifications, either, just trying to adjust the narrative of the paper.\n\nIt seems like there's a pool of tasks where DML strategies like contrastive loss / triplet loss / etc. make more sense. And there's a pool of tasks where softmax is the natural thing (because you're only interested in categorization). There is some overlap in these, though -- tasks where the number of categories isn't huge, where multiple types of labels are available and some of them are categorical, where you're interested in retrieval and not categorization, and your paper shows that you can use softmax to learn a good feature embedding. That's great. But you want to define the boundaries of where this strategy is fruitful and cite situations where maybe it's not ideal (or even viable, as you say is the case with millions of labels)."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287760453, "id": "ICLR.cc/2017/conference/-/paper23/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "HyQWFOVge", "writers": {"values-regex": "ICLR.cc/2017/conference/paper23/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper23/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper23/reviewers", "ICLR.cc/2017/conference/paper23/areachairs"], "cdate": 1485287760453}}}, {"tddate": null, "tmdate": 1482394729376, "tcdate": 1482393934243, "number": 7, "id": "Hk88YbFVl", "invitation": "ICLR.cc/2017/conference/-/paper23/public/comment", "forum": "HyQWFOVge", "replyto": "SJZ6q-zEx", "signatures": ["~Shota_Horiguchi1"], "readers": ["everyone"], "writers": ["~Shota_Horiguchi1"], "content": {"title": "Re: review", "comment": "Thank you for your review, \nWe're still doing experiments of Magnet loss.\nWe tried Magnet@fullPT and Magnet@3epochPT for comparison, but it reaches lower accuracies than those in Rippel's paper.\n(For example, we got about 25% classification error on Oxford-102Flowers dataset for both Magnet@3epochPT and Magnet@FullPT.)\nWe have sent an email to Rippel, and waiting for his reply.\nPlease wait for a while.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287760585, "id": "ICLR.cc/2017/conference/-/paper23/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyQWFOVge", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper23/reviewers", "ICLR.cc/2017/conference/paper23/areachairs"], "cdate": 1485287760585}}}, {"tddate": null, "tmdate": 1482393475958, "tcdate": 1482390531501, "number": 5, "id": "r1sW2gtNe", "invitation": "ICLR.cc/2017/conference/-/paper23/public/comment", "forum": "HyQWFOVge", "replyto": "SyDIjA44e", "signatures": ["~Shota_Horiguchi1"], "readers": ["everyone"], "writers": ["~Shota_Horiguchi1"], "content": {"title": "Re: Thanks for clarifications.", "comment": "1) Table 2:\nImageNet Attribute dataset, which we used in section 4.3, is a subset of ImageNet and it contains 116,836 samples and 90 classes with attributes. As we described, networks were trained by class labels, not attributes.\nTable 2 is \"Classification error rates for the ImageNet Attribute dataset\", we mean classification error on 90 class prediction. The reason we show Table 2 is that the same table is shown in the paper (Rippel+, 2016) and we wanted to show the performance of the softmax classifier is different when properly used.\n\n2) few training samples\nYou are right. It was misleading. As you wrote, we meant \"few training samples per class,\" like Online Product dataset and data-restricted CUB and CAR.\n\nWe thank you again that your comments make the significance of our paper clear. Discussion on learning good feature embedding is the theme of this paper. We will revise our paper to clarify this point.\n\nWe would like to make sure your intentions about some previous studies you introduced, which used DML (Sangkloy et al, Vo and Hays, Bell et al, Wang et al, Taigman et al, etc.).\nWe think these studies address following problems:\ni) huge number of categories (e.g. \"more than 1 million matched pairs of street-view and overhead-view\" in Vo and Hays)\nii) cross-domain representation (sketch-photo, aerial-ground)\niii) few training samples per class\nWe write our thoughts on these points one by one.\n\ni) \u201chuge number of categories\u201d is not evaluated in our paper because fully connected layer with millions of outputs cannot be on the GPU memory. This is a softmax's limitation. (It is  possible to learn about ten thousands of classes on single K40 GPU, as shown in our experiment on the OP dataset.)\n\nii) DML can solve \u201ccross-domain\u201d problem by siamese-like network architecture without weight sharing. For softmax, we introduced the study of Castrejon et al, however their learning strategy is complicated. Our main concern is in the basic framework of feature embedding.\n\niii) \u201cfew training samples per class\u201d is evaluated on Online Product (Fig. 7) and data-restricted CUB and CAR (Fig. 8 and 9). For example, 5% of the CUB datasets contains 5864*0.05 training samples, about 3 samples per class. It is already very small number. We think the case of 2 samples per class maybe not very different, but if you want to see the case of 2 samples per class, we can do the extra experiments."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287760585, "id": "ICLR.cc/2017/conference/-/paper23/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyQWFOVge", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper23/reviewers", "ICLR.cc/2017/conference/paper23/areachairs"], "cdate": 1485287760585}}}, {"tddate": null, "tmdate": 1482391610333, "tcdate": 1482391597363, "number": 6, "id": "ryr4xZK4g", "invitation": "ICLR.cc/2017/conference/-/paper23/public/comment", "forum": "HyQWFOVge", "replyto": "B1Lus18Ex", "signatures": ["~Shota_Horiguchi1"], "readers": ["everyone"], "writers": ["~Shota_Horiguchi1"], "content": {"title": "Answers for your questions", "comment": "Thank you for your review. \nThis is a paper that shows the equitable comparisons between softmax features and DML features under the same networks, which leads to clarification of performance of softmax based feature embedding. It was not clear in the previous studies.\n\nLet us clarify questions you raised in the comments.\n\na) We used 1-NN classification for fair comparison to Rippel. Note that nearest neighbor is used for classification, such as Nearest Class Mean (Mensink et al., 2013). We think the difference between classification and retrieval is whether the class sets of the training data and test data are the same or not.\n\nb) In section 4.2 and 4.3, we used vanilla GoogLeNet w/ batch normalization. We'll revise to specify the network architectures.\n\nc) We show w/ and w/o L2 normalization in our results. For Magnet loss, we note that L2 normalization reduces the performance. This is a natural result we can expect from Fig 1.\n\nThe reason of our improvement of softmax is the strategy of fine-tuning (and this is only difference from Rippel's softmax result). Rippel used the networks pretrained on ImageNet for only three epochs, and we used those of fully pretrained, as we described in our paper."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287760585, "id": "ICLR.cc/2017/conference/-/paper23/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyQWFOVge", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper23/reviewers", "ICLR.cc/2017/conference/paper23/areachairs"], "cdate": 1485287760585}}}, {"tddate": null, "tmdate": 1482189678224, "tcdate": 1482189678224, "number": 3, "id": "B1Lus18Ex", "invitation": "ICLR.cc/2017/conference/-/paper23/official/review", "forum": "HyQWFOVge", "replyto": "HyQWFOVge", "signatures": ["ICLR.cc/2017/conference/paper23/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper23/AnonReviewer2"], "content": {"title": "Interesting discussion but sharing concern with reviewer 3 ", "rating": "5: Marginally below acceptance threshold", "review": "I agree with the other two reviewers that it is an interesting topic to investigate the feature learned by DML. For classification task though, I feel intuitively softmax should have advantages over distance metric learning method because the loss function is designed to assign the correct class for the given image. All the experimental results show that the softmax features work better than Rippel et al DML method. However, does it support the claim that softmax-based features work much better than DML learned features? I have doubts on this claim. \n\nAlso the experiments are a little bit misleading. What is vanilla googleNet softmax finetuned results? It seems it is not Rippel et al. (softmax prob) result. I am wondering whether the improvement comes from a) using retrieval (nearest neighbor) for classification or b) adding a new layer on top of pool5 or c) L2 normalization of the features. It is not clear to me at all. It appears to me the comparison is not apple vs apple between the proposed method and Rippel et al. \n\nIt would be great if we know adding feature reduction or adding another layer on top of pool5 can improve finetued softmax result. However, I am not sure what is the biggest contributing factor to the superior results. Before getting more clarifications from the authors, I lean toward rejection. \n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512723768, "id": "ICLR.cc/2017/conference/-/paper23/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper23/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper23/AnonReviewer3", "ICLR.cc/2017/conference/paper23/AnonReviewer1", "ICLR.cc/2017/conference/paper23/AnonReviewer2"], "reply": {"forum": "HyQWFOVge", "replyto": "HyQWFOVge", "writers": {"values-regex": "ICLR.cc/2017/conference/paper23/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper23/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512723768}}}, {"tddate": null, "tmdate": 1482120022908, "tcdate": 1481951337083, "number": 2, "id": "HkW_uHzVl", "invitation": "ICLR.cc/2017/conference/-/paper23/official/review", "forum": "HyQWFOVge", "replyto": "HyQWFOVge", "signatures": ["ICLR.cc/2017/conference/paper23/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper23/AnonReviewer1"], "content": {"title": "Interesting observations, but the paper seems misguided or incomplete", "rating": "7: Good paper, accept", "review": "I have a huge, big picture concern about this paper and the papers it most closely addresses (MagnetLoss and Lifted Feature Structure Embedding). I don't understand why Distance Metric Learning (DML) is being used for classification tasks (Stanford Cars 196, UCSD Birds 200, Oxford 102 flowers, Stanford Dogs, ImageNet attributes, etc). As far as I can tell, there is really only a single \"retrieval\"-like benchmark being used here - the Stanford Online Products database. All the other datasets are used in a \"classification-by-retrieval\" approach which seems contrived. While ostensibly evaluating \"retrieval\", the retrieval ground truth is totally defined by category membership so these are still classification tasks with many instances in each category. With the Online Products dataset the correspondence between queries and correct results is much more fine grained so it makes sense to think of it as a retrieval task.\n\nIt seems obvious that if your task is classification, a network trained with a classification loss will be best. Even when these datasets are used in a \"retrieval\" setting, the ground truth is still defined by category membership. It's still a classification task. \n\nI don't really see the point of using DML in these scenarios. I guess prior work claims to outperform SoftMax in these settings so this paper is fighting back against this and I should be thankful for this paper. But I think this paper's narrative is a bit off. The narrative shouldn't be \"We can get good retrieval features from softmax networks with appropriate normalization\". It should be \"It never made sense to train or evaluate these things as retrieval tasks. Direct classification is better\". For example, why are you taking the second to last layer or pool5 layer from these networks? Why aren't you taking the last layer? That should do well in these evaluations, right? Table 1 and 2 do show that using softmax probabilities directly tends to be better than doing classification-by-retrieval (works better or the same as doing retrieval with an earlier layer of features, except on Oxford flowers).\n\nGoogLeNet is quite deep and gets auxiliary supervision. By the second-to-last layer of the network, the activations could look a lot like category membership already. And category membership is all that's needed for the tasks in 4.2 and 4.3. \n \nI don't think my pre-review question was adequately addressed. I was getting at this concern by pointing out numerous scenarios where distance metric learning makes sense because you have fine-grained associations between instances at training time, NOT categorical associations -- e.g. this product photo corresponds to this photo of the object in a scene [Bell et al. 2015], this 3d model correspond to this sketch [Wang et al. 2015], this sketch corresponds to this photo [Sangkloy et al. 2016], this ground view corresponds to this aerial view [Lin et al., 2015]. DeepFace and follow-up works on LFW could also fit into this space because there are few training samples per class (few training samples per person identity). You cite DeepFace and Bell et al. 2015 but you don't compare on those benchmarks. I think those are exactly the tasks where DML makes sense.\n\nMaybe the \"retrieval on classification datasets\" would be a reasonable benchmark if the test and train classes were completely different. Then you could argue that softmax is learning a useful representation yet the last layer isn't directly useful since the categories change. But that's not the case here, is it?\n\nWith all of this said, I'm not sure whether I'm positive or negative about this paper. I think you're onto something significant -- people have been using DML where it is not appropriate -- but addressed it in the wrong way -- by using softmax for \"classification by retrieval\". But you don't need to do retrieval! Softmax is already telling you the class prediction! Why go through the extra step of finding nearest neighbors with some intermediate feature?\n\nAnonReviewer3 also raises some good points and you should be thankful that a reviewer is willing to dig so deep to help make your experiments sound! I don't think his/her concerns are disqualifying for this paper, though, as long as it is fixed.\n\nI look forward to hearing your response. I want this paper to be published, but I think it needs to be tweaked.\n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512723768, "id": "ICLR.cc/2017/conference/-/paper23/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper23/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper23/AnonReviewer3", "ICLR.cc/2017/conference/paper23/AnonReviewer1", "ICLR.cc/2017/conference/paper23/AnonReviewer2"], "reply": {"forum": "HyQWFOVge", "replyto": "HyQWFOVge", "writers": {"values-regex": "ICLR.cc/2017/conference/paper23/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper23/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512723768}}}, {"tddate": null, "tmdate": 1482120015511, "tcdate": 1482120015511, "number": 3, "id": "SyDIjA44e", "invitation": "ICLR.cc/2017/conference/-/paper23/official/comment", "forum": "HyQWFOVge", "replyto": "rkyESQE4e", "signatures": ["ICLR.cc/2017/conference/paper23/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper23/AnonReviewer1"], "content": {"title": "Thanks for clarifications.", "comment": "1) Ok, great, thanks for the clarifications. That does make your experiments more reasonable.\n\nI guess I was confused about this line in Table 2 \"Ours (Softmax prob) 7.68%\". If it wasn't trained with attributes, what is this saying? You're using the activations after softmax as the feature for retrieval? Or you've trained another network to predict the attributes directly?\n\n2) I don't think those examples have \"few training samples\" -- they have 10's of thousands or more. They have few samples per category, though. But I think that's what you meant. \n\n3) You can find some of the datasets for papers I mentioned (Sangkloy et al, Vo and Hays).\n\nAnyway, I'll raise my score based on your clarifications. I still think you need to change the narrative of your paper a bit, though. It should be less about beating Magnet loss and more about the value of using class labels (when available) to learn good feature embeddings, and it would be better to take this to the extreme with a dataset of 2 instances per \"class\", a truly fine grained retrieval task, and see how things work.\n\n "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287760453, "id": "ICLR.cc/2017/conference/-/paper23/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "HyQWFOVge", "writers": {"values-regex": "ICLR.cc/2017/conference/paper23/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper23/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper23/reviewers", "ICLR.cc/2017/conference/paper23/areachairs"], "cdate": 1485287760453}}}, {"tddate": null, "tmdate": 1482078379680, "tcdate": 1482073383296, "number": 4, "id": "rkyESQE4e", "invitation": "ICLR.cc/2017/conference/-/paper23/public/comment", "forum": "HyQWFOVge", "replyto": "HkW_uHzVl", "signatures": ["~Daiki_Ikami1"], "readers": ["everyone"], "writers": ["~Daiki_Ikami1"], "content": {"title": "Re: Interesting observations, but the paper seems misguided or incomplete", "comment": "We thank you for your helpful review.\n\n1) classification and retrieval\nWe think there might be some misunderstanding about our experimental settings. In section 4.2 we evaluated the classification performances, as you pointed out, and it was not surprising that softmax-based features outperformed DML-based features. However, in section 4.3 \"we used only the images and their class labels during our training of the softmax classifier and did not use attributes\" (described in our paper). And in section 4.4, the classes of training data are completely different from those of test data, as in table 3. Therefore we evaluated the retrieval (clustering) performance, not the classification performance.\n\n2) comparison to DML\nWe agree with that DML is suitable in cases of non-categorical problems (e.g. Bell+, Wang+, etc.) or problems with few training samples.\nOur main concern is \"learning beneficial deep features\", i.e. useful for such as retrieval, clustering, one-shot and zero-shot learning. In these problems, we can often use class labels during the training, however the classes of test data is different from those of training. Therefore we cannot use class prediction and extracting useful intermediate features is important for these problems.\nIn section 4.4, we showed that softmax-based features are superior to DML-based features in image retrieval and clustering if we have enough training samples. Even in the case of few training samples, softmax-based features achieved comparable performance in the OP dataset, which contains only about 5.5 training samples per class.\n\n3) about Learning visual product design[Bell+, 2015], DeepFace [Taigman+, 2014], facenet [Schroff+, 2015]\nAs far as we know, these studies used private datasets for training. Moreover, they used simple siamese or triplet based networks. Therefore we compared with more sophisticated methods, Magnet loss and Lifted structed feature embedding, on publicly available datasets."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287760585, "id": "ICLR.cc/2017/conference/-/paper23/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyQWFOVge", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper23/reviewers", "ICLR.cc/2017/conference/paper23/areachairs"], "cdate": 1485287760585}}}, {"tddate": null, "tmdate": 1481946889420, "tcdate": 1481429639584, "number": 2, "id": "Byg9MI9Qg", "invitation": "ICLR.cc/2017/conference/-/paper23/pre-review/question", "forum": "HyQWFOVge", "replyto": "HyQWFOVge", "signatures": ["ICLR.cc/2017/conference/paper23/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper23/AnonReviewer1"], "content": {"title": "Applicability to Geolocalization and cross-domain DML", "question": "One area where DML is popular is Image Geolocalization, e.g. Lin et al. Learning Deep Representations for Ground-to-Aerial Geolocalization, CVPR 2015. In this domain the number of categories would be the number of locations, which could be in the tens of thousands to millions, with one pair of training examples per location. I suppose this would be an even more extreme situation than the Stanford Products (OP) dataset you evaluated on. Works in that domain have proposed improvements to the contrastive loss or triplet loss. See Vo and Hays, ECCV 2016. That work also proposes a way to address another problem you identify -- \"DML optimization converges very slowly\" -- by using all possible triplets in each training batch of N, you can get O(N^2) training samples instead of the typical O(N).\n\nAnother element of these particular geolocalization works is that they are cross domain (e.g. ground images and overhead images, also the case in Workman et al. Wide-Area Image Geolocalization with Aerial Reference Imagery. ICCV 2015, but they don't use DML). Another example is sketch-based image retrieval, e.g. Yu et al. Sketch Me That Shoe, CVPR 2016. Sangkloy et al. The Sketchy Database: Learning to Retrieve Badly Drawn Bunnies, Siggraph 2016. and sketch-based 3d model retrieval e.g. Wang et al. Sketch-based 3D Shape Retrieval using Convolutional Neural Networks. CVPR 2015. With DML it's trivial to have multiple networks, trained on different domains with independent weights, and have a loss on the final layer which asks them to place matching inputs nearby in feature space. What is the analog in the softmax approach? You can't have two fully independent networks, because the layers prior to the final layer won't learn comparable embeddings. You would need partially fused classification networks of some sort?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481429640203, "id": "ICLR.cc/2017/conference/-/paper23/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper23/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper23/AnonReviewer3", "ICLR.cc/2017/conference/paper23/AnonReviewer1"], "reply": {"forum": "HyQWFOVge", "replyto": "HyQWFOVge", "writers": {"values-regex": "ICLR.cc/2017/conference/paper23/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper23/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481429640203}}}, {"tddate": null, "tmdate": 1481935545031, "tcdate": 1481935545031, "number": 1, "id": "SJZ6q-zEx", "invitation": "ICLR.cc/2017/conference/-/paper23/official/review", "forum": "HyQWFOVge", "replyto": "HyQWFOVge", "signatures": ["ICLR.cc/2017/conference/paper23/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper23/AnonReviewer3"], "content": {"title": "review", "rating": "4: Ok but not good enough - rejection", "review": "There has been substantial recent interest in representation learning, and specifically, using distance metric learning (DML) to learn representations where semantic distance between inputs can be measured. This is a topic of particular relevance / interest to ICLR. This paper poses a simple yet provocative question: can a standard SoftMax based approach learn features that match or even outperform recent state-of-the-art DML approaches? Thorough experiments seem to indicate that this is indeed the case. Comparisons are made to recent DML approaches including Magnet Loss (ICLR2016) and Lifted structure embedding (CVPR2016) and superior results are shown across a number of datasets / tasks for which the DML approaches were designed. \n\nThis main result is a bit surprising since SoftMax is a natural and trivial baseline, so it should have been properly evaluated in previous DML literature. The authors argue that previous approaches did not fully/properly tune the softmax baselines, or that comparisons were not apples-to-apples. Also, one change in the current paper is the addition of L2 normalization, which is well motivated and helps improve SoftMax feature distances. Different dimensionality reduction approaches are also tested. These changes are minor, but especially the L2 normalization proves to be a simple but effective improvement for SoftMax features.\n\nA big issue is with how pre-training is performed (in Magnet Loss the softmax baselines were pretrained for less time on ImageNet). The approach taken here is reasonable, but so is the approach in Magnet Loss (for different reasons). Ultimately, both are fine. Unfortunately, due to use of different schemes, the results are not comparable. Let me copy-paste what I wrote in an earlier comment: \n\nMy main concern about the paper is that the comparisons in Tables 1 and 2 and Figure 4 to Rippel et al. are not apples-to-apples. Basically, the papers shows that absolute results of using SoftMax w full pre-training (PT) on ImageNet is superior to any of the results in Rippel's paper (including both the Softmax and Magnet results). But as the current results show, PT appears to be critical to obtaining such good numbers - The Rippel SoftMax numbers use only 3 PT stages and are dramatically worse than the full PT on ImageNet. As it stands, I am not convinced that SoftMax is actually better than Magnet. Here is the evidence we have (I'll use Stanford Dogs as an example, but any of the datasets have the same conclusion): (1) Softmax w 3 stages of PT: 26.6% (from Rippel paper) and 32.7% (from authors' reproduction) (2) Magnet w 3 stages of PT: 24.9% (3) Softmax w full PT: 18.3% (4) Magnet w full PT: not shown From this all I see is that PT is critical for getting absolute good results. However, what about Magnet w full PT? These results are not shown either here or in the original Rippel paper (I went back and looked). As such, I do not think it is justifiable to claim superiority of Softmax to Magnet based on available evidence. (Note: I looked back carefully at Rippel's paper, and it appears that the authors use 3 PT stages as a form of \"warmup\". There is a statement that using full PT would \"defeat the purpose of pursuing DML\". I'm not sure if I agree w Rippel's statement since in the present paper there is clear evidence that full PT is hugely helpful, at least for softmax. That being said, I did not see any evidence in the Rippel paper that PT is harmful or that DML wouldn't work with full PT.)\n\nThe authors responded to my concern by claiming that \u201cfrom Rippel's results, it is no doubt that Magnet@3epochPT > Magnet@FullPT and Magnet@3epoch > Softmax@3epochPT.\u201d However, I went back to Rippel\u2019s paper, and simply the Magnet@FullPT experiment never appears. I further went and contacted Oren Rippel himself, and he verified he never ran the Magnet@FullPT experiment. I encourage the authors to contact Oren Rippel regarding this if they wish to verify (I have asked Oren Rippel to not reveal my identity). [Disclaimer: I am NOT Oren Rippel]. The authors mentioned that they are training Magnet@FullPT. If results were shown for Magnet@FullPT and also retrain the Magnet@3epochPT as a sanity check, that would help alleviate this concern. Alternatively, the language in Section 4 and the Tables could be altered to make clear that the methods use different pretraining and hence are not comparable.\n\nOverall, I am actually quite sympathetic to this work. I think it could serve as an important sanity-check paper for the community and quite relevant to ICLR. Having proper and strong SoftMax baselines should prove quite useful to the DML community and to this line of work.\n\nHowever, currently I find the main results (table 1, table 2, figure 4, etc.) to be misleading. If indeed it were the case that Magnet@3epochPT > Magnet@FullPT, then it would be fine. However, at this point as far as I know no one has actually tried Magnet@FullPT. And, given the general importance and effectiveness of pre-training, especially when transferring to small dataset, I would be hugely surprised if Magnet@FullPT was not superior by a large margin. I think either having this experiment in place or altering the writing / presentation of the results would be critical to allow for publishing.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512723768, "id": "ICLR.cc/2017/conference/-/paper23/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper23/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper23/AnonReviewer3", "ICLR.cc/2017/conference/paper23/AnonReviewer1", "ICLR.cc/2017/conference/paper23/AnonReviewer2"], "reply": {"forum": "HyQWFOVge", "replyto": "HyQWFOVge", "writers": {"values-regex": "ICLR.cc/2017/conference/paper23/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper23/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512723768}}}, {"tddate": null, "tmdate": 1481641661088, "tcdate": 1481628320856, "number": 3, "id": "r1Ys5IpXg", "invitation": "ICLR.cc/2017/conference/-/paper23/public/comment", "forum": "HyQWFOVge", "replyto": "Byg9MI9Qg", "signatures": ["~Shota_Horiguchi1"], "readers": ["everyone"], "writers": ["~Shota_Horiguchi1"], "content": {"title": "Re: Applicability to Geolocalization and cross-domain DML", "comment": "Thank you for your review.\n\nFor cross domain image retrieval, there is an existing work in CVPR 2016: Castrejon+ ''Learning Aligned Cross-Modal Representations from Weakly Aligned Data.'' They learned cross-modal representations of natural images, sketches, clip art, spatial text, and descriptions by using softmax-based classifier.\n\nWe agree that DML based features might be better in such as image geolocalization. Based on our results, in OP and data-restricted CAR and CUB, which the number of samples per class is limited, we showed the difference between the performance of softmax-based features and that of DML-based features is little. As far as we know, this paper is the first work which made clear about this tendency by equitable comparisons.\nWe finally note that lifted structured feature embedding, which we used in our paper as a baseline in clustering and retrieval tasks, used all possible pairs in a batch to use O(N^2) distances from O(N) samples.\n\nThanks."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287760585, "id": "ICLR.cc/2017/conference/-/paper23/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyQWFOVge", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper23/reviewers", "ICLR.cc/2017/conference/paper23/areachairs"], "cdate": 1485287760585}}}, {"tddate": null, "tmdate": 1480741144691, "tcdate": 1480673796900, "number": 2, "id": "Bk6Zc6Cfg", "invitation": "ICLR.cc/2017/conference/-/paper23/public/comment", "forum": "HyQWFOVge", "replyto": "H1t7Z_Afg", "signatures": ["~Shota_Horiguchi1"], "readers": ["everyone"], "writers": ["~Shota_Horiguchi1"], "content": {"title": "Re: main concern", "comment": "Thanks for your reply.\n\nRippel wrote that \"We find that it is useful to warm-start any DML optimization with weights of a partly-trained a standard softmax classifier. It is important to not use weights of a net trained to completion, as this would result in information dissipation and as such defeat the purpose of pursuing DML in the first place.\" \"the purpose of pursuing DML\" is in Rippel's abstract: \"Distance metric learning (DML) approaches learn a transformation to a representation space where distance is in correspondence with a predefined notion of similarity.\"\nRipppel verified whether Magnet could \"learn a transformation to a representation space where distance is in correspondence with a predefined notion of similarity\" by calculating attribute precision, and they found that 3-epoch model is better than full PT model, which caused \"information dissipation\".\nThus, from Rippel's results, it is no doubt that Magnet@3epochPT > Magnet@FullPT and Magnet@3epoch > Softmax@3epochPT.\nIn our paper, Softmax@FullPT > Magnet@3epochPT, as shown in Fig.4.\n\nAs above, it is reported in Rippel's paper that Magnet@FullPT was worse than Magnet@3epoch.\nAnd, at least in clustering and retrieval task, Softmax@FullPT significantly outperformed DML-based model(lifted)@FullPT.\n\nFor confirmation, we just started to train Magnet from FullPT model now.\nWe will report results if possible.\n\nThanks again."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287760585, "id": "ICLR.cc/2017/conference/-/paper23/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyQWFOVge", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper23/reviewers", "ICLR.cc/2017/conference/paper23/areachairs"], "cdate": 1485287760585}}}, {"tddate": null, "tmdate": 1480651040659, "tcdate": 1480651040653, "number": 2, "id": "H1t7Z_Afg", "invitation": "ICLR.cc/2017/conference/-/paper23/official/comment", "forum": "HyQWFOVge", "replyto": "H1xDXZhGl", "signatures": ["ICLR.cc/2017/conference/paper23/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper23/AnonReviewer3"], "content": {"title": "main concern", "comment": "Thank you for the clarification, that is quite helpful.\n\nMy main concern about the paper is that the comparisons in Tables 1 and 2 and Figure 4 to Rippel et al. are not apples-to-apples. Basically, the papers shows that absolute results of using SoftMax w full pre-training (PT) on ImageNet is superior to any of the results in Rippel's paper (including both the Softmax and Magnet results). But as the current results show, PT appears to be critical to obtaining such good numbers - The Rippel SoftMax numbers use only 3 PT stages and are dramatically worse than the full PT on ImageNet. \n\nAs it stands, I am not convinced that SoftMax is actually better than Magnet. Here is the evidence we have (I'll use Stanford Dogs as an example, but any of the datasets have the same conclusion):\n(1) Softmax w 3 stages of PT: 26.6% (from Rippel paper) and 32.7% (from authors' reproduction)\n(2) Magnet w 3 stages of PT: 24.9%\n(3) Softmax w full PT: 18.3%\n(4) Magnet w full PT: not shown\nFrom this all I see is that PT is critical for getting absolute good results. However, what about Magnet w full PT? These results are not shown either here or in the original Rippel paper (I went back and looked). \n\nAs such, I do not think it is justifiable to claim superiority of Softmax to Magnet based on available evidence.\n\n(Note: I looked back carefully at Rippel's paper, and it appears that the authors use 3 PT stages as a form of \"warmup\". There is a statement that using full PT would \"defeat the purpose of pursuing DML\". I'm not sure if I agree w Rippel's statement since in the present paper there is clear evidence that full PT is hugely helpful, at least for softmax. That being said, I did not see any evidence in the Rippel paper that PT is harmful or that DML wouldn't work with full PT.)\n\nIf the authors have any response to my comments (or proposed changes they could make to the paper) I'd be happy to take them into account before posting a full review.\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287760453, "id": "ICLR.cc/2017/conference/-/paper23/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "HyQWFOVge", "writers": {"values-regex": "ICLR.cc/2017/conference/paper23/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper23/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper23/reviewers", "ICLR.cc/2017/conference/paper23/areachairs"], "cdate": 1485287760453}}}, {"tddate": null, "tmdate": 1480504344264, "tcdate": 1480491864359, "number": 1, "id": "H1xDXZhGl", "invitation": "ICLR.cc/2017/conference/-/paper23/public/comment", "forum": "HyQWFOVge", "replyto": "B1-BV3DMg", "signatures": ["~Shota_Horiguchi1"], "readers": ["everyone"], "writers": ["~Shota_Horiguchi1"], "content": {"title": "Re: questions about experiments", "comment": "Thank you very much for your review.\n\n>>L2 normalization seemed to very important for experiments in S4.4. Yet in table 1 the experiments show little difference w and w/o normalization. Why? (Did you use cosine distance in any of the experiments, or was it all L2?)\n\nWe consider that the difference between these results is caused by the difference of tasks and evaluation metrics.\nFig.1(b) shows the reason why the L2 normalization is especially important for specific tasks.\nFor classification, attribute estimation, and retrieval, the evaluation is based on nearest neighbor method thus unnormalized features, which are radially distributed like Fig.1(b), can perform well to some extent.\nHowever, for clustering, unnormalized features cause serious decline of performance. \n(We have used Euclidean distance in all of our experiments)\nWe finally note that L2 normalization could improve all of our experimental performances of pool5 features.\n\n\n>>Could you please report the pool5 / pool5+L2 results in table 2? (Or is there a reason these were not included in table 2?)\n\nWe added the results to table 2.\nFor the ImageNet attribute dataset, pool5 features are better than Magnet, and the L2 normalization works effectively.\n\n\n>>And one more question: if you train SoftMax but only pre-train for 3 epochs (as in Rippel), do you get the same number in table 1 / table 2 as Rippel (Softmax prob)? I would like to see this verified to understand if this is the only difference between these results. Otherwise I am concerned about the large gap here.\n\nThere are no detailed information about training strategies of pre-training in Rippel's paper.\nWe tried to reproduce Rippel's experiments: first, we trained 3-epoch model using BN-x30 strategy of [1], and then fine-tuned for each dataset.\nWe obtained the following error rates in fine-grained recognition tasks.\n    Stanford dogs: 32.7%\n    Oxford 102 flowers: 12.5%\n    Oxford-IIIT Pet: 19.8%\nThese results are different (even worse) from Rippel's results.\nThere are two main reasons which make reproduction of their results difficult.\n    (i) 3-epoch trained models are very different between their training strategies. See Fig.2 of [1]. The difference of final performance between various training strategies are small, but at 3-epoch the loss values are very different.\n    (ii) The training is \"on the way\" at 3-epoch so that loss values are not stable.\nFor these reasons, we could not get exact values of Rippel's results.\nHowever, it is obvious that the halfway models perform worse than the fully-trained model.\n\nThanks again for your feedback.\n\n[1] S. Ioffe and C. Szegedy, \"Batch normalization: accelerating deep network trained by reducing internal covariate shift.\""}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287760585, "id": "ICLR.cc/2017/conference/-/paper23/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "HyQWFOVge", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper23/reviewers", "ICLR.cc/2017/conference/paper23/areachairs"], "cdate": 1485287760585}}}, {"tddate": null, "tmdate": 1480211137727, "tcdate": 1480209464700, "number": 1, "id": "B1-BV3DMg", "invitation": "ICLR.cc/2017/conference/-/paper23/pre-review/question", "forum": "HyQWFOVge", "replyto": "HyQWFOVge", "signatures": ["ICLR.cc/2017/conference/paper23/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper23/AnonReviewer3"], "content": {"title": "questions about experiments", "question": "L2 normalization seemed to very important for experiments in S4.4. Yet in table 1 the experiments show little difference w and w/o normalization. Why? (Did you use cosine distance in any of the experiments, or was it all L2?) \n\nCould you please report the pool5 / pool5+L2 results in table 2? (Or is there a reason these were not included in table 2?)\n\nAnd one more question: if you train SoftMax but only pre-train for 3 epochs (as in Rippel), do you get the same number in table 1 / table 2 as Rippel (Softmax prob)? I would like to see this verified to understand if this is the only difference between these results. Otherwise I am concerned about the large gap here."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Significance of Softmax-Based Features over Metric Learning-Based Features", "abstract": "The extraction of useful deep features is important for many computer vision tasks.\nDeep features extracted from classification networks have proved to perform well in those tasks.\nTo obtain features of greater usefulness, end-to-end distance metric learning (DML) has been applied to train the feature extractor directly.\nEnd-to-end DML approaches such as Magnet Loss and lifted structured feature embedding show state-of-the-art performance in several image recognition tasks.\nHowever, in these DML studies, there were no equitable comparisons between features extracted from a DML-based network and those from a softmax-based network.\nIn this paper, by presenting objective comparisons between these two approaches under the same network architecture, we show that the softmax-based features are markedly better than the state-of-the-art DML features for tasks such as fine-grained recognition, attribute estimation, clustering, and retrieval.", "pdf": "/pdf/a75e869d17ffc25adb6467b38dfe0189d75f5a75.pdf", "TL;DR": "We show softmax-based features are markedly better than state-of-the-art metric learning-based features by conducting fair comparison between them.", "paperhash": "horiguchi|significance_of_softmaxbased_features_over_metric_learningbased_features", "conflicts": ["t.u-tokyo.ac.jp"], "keywords": ["Computer vision", "Deep learning"], "authors": ["Shota Horiguchi", "Daiki Ikami", "Kiyoharu Aizawa"], "authorids": ["horiguchi@hal.t.u-tokyo.ac.jp", "ikami@hal.t.u-tokyo.ac.jp", "aizawa@hal.t.u-tokyo.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481429640203, "id": "ICLR.cc/2017/conference/-/paper23/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper23/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper23/AnonReviewer3", "ICLR.cc/2017/conference/paper23/AnonReviewer1"], "reply": {"forum": "HyQWFOVge", "replyto": "HyQWFOVge", "writers": {"values-regex": "ICLR.cc/2017/conference/paper23/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper23/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481429640203}}}], "count": 25}