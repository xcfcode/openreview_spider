{"notes": [{"id": "HklKEUUY_E", "original": "SJgvFIUGdE", "number": 30, "cdate": 1553716785511, "ddate": null, "tcdate": 1553716785511, "tmdate": 1562083047076, "tddate": null, "forum": "HklKEUUY_E", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Blind_Submission", "content": {"title": "On the relationship between Normalising Flows and Variational- and Denoising Autoencoders", "authors": ["Alexey A. Gritsenko", "Jasper Snoek", "Tim Salimans"], "authorids": ["agritsenko@google.com", "salimanstim@gmail.com", "jsnoek@google.com"], "keywords": ["variational autoencoders", "denoising variational autoencoders", "normalizing flows", "generative modelling", "image synthesis", "denoising autoencoders", "VAE", "DAE", "VDAE", "NF"], "TL;DR": "We explore the relationship between Normalising Flows and Variational- and Denoising Autoencoders, and propose a novel model that generalises them.", "abstract": "Normalising Flows (NFs) are a class of likelihood-based generative models that have recently gained popularity. They are based on the idea of transforming a simple density into that of the data. We seek to better understand this class of models, and how they compare to previously proposed techniques for generative modeling and unsupervised representation learning. For this purpose we reinterpret NFs in the framework of Variational Autoencoders (VAEs), and present a new form of VAE that generalises normalising flows. The new generalised model also reveals a close connection to denoising autoencoders, and we therefore call our model the Variational Denoising Autoencoder (VDAE). Using our unified model, we systematically examine the model space between flows, variational autoencoders, and denoising autoencoders, in a set of preliminary experiments on the MNIST handwritten digits. The experiments shed light on the modeling assumptions implicit in these models, and they suggest multiple new directions for future research in this space.", "pdf": "/pdf/c18dc425a3fb7ee6e5fea04ca857be21a2b1e8e7.pdf", "paperhash": "gritsenko|on_the_relationship_between_normalising_flows_and_variational_and_denoising_autoencoders"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Blind_Submission", "cdate": 1547567085825, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": [".*"]}, "writers": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1547567085825, "tmdate": 1555704438520, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}}, "tauthor": "OpenReview.net"}, {"id": "BygFOVRG5E", "original": null, "number": 2, "cdate": 1555387505022, "ddate": null, "tcdate": 1555387505022, "tmdate": 1556906140171, "tddate": null, "forum": "HklKEUUY_E", "replyto": "HklKEUUY_E", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper30/Official_Review", "content": {"title": "Interesting exposition of unifying NFs, VAEs, and DAEs", "review": "This paper proposes a model family that unifies NFs, VAEs and DAEs. It also introduces an extension of this model that allows for using non-invertible encoders (e.g. projection to a smaller dimensionality) and discrete data. Overall, the idea is promising, but the empirical results are not strong enough to warrant a strong commendation.\n\nPros\n- The proposed model that blends NFs, VAEs and DAEs is original, and generalises over standard NFs in that it allows non-zero noise levels.\n- When latent dimensionality is smaller than the input space, the model consistently outperforms the VAE baseline.\n\nCons\n- Performance deteriorates for bigger latent dimensionalities (e.g. when n=m)", "rating": "3: Marginally above acceptance threshold", "confidence": "3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper30/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper30/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the relationship between Normalising Flows and Variational- and Denoising Autoencoders", "authors": ["Alexey A. Gritsenko", "Jasper Snoek", "Tim Salimans"], "authorids": ["agritsenko@google.com", "salimanstim@gmail.com", "jsnoek@google.com"], "keywords": ["variational autoencoders", "denoising variational autoencoders", "normalizing flows", "generative modelling", "image synthesis", "denoising autoencoders", "VAE", "DAE", "VDAE", "NF"], "TL;DR": "We explore the relationship between Normalising Flows and Variational- and Denoising Autoencoders, and propose a novel model that generalises them.", "abstract": "Normalising Flows (NFs) are a class of likelihood-based generative models that have recently gained popularity. They are based on the idea of transforming a simple density into that of the data. We seek to better understand this class of models, and how they compare to previously proposed techniques for generative modeling and unsupervised representation learning. For this purpose we reinterpret NFs in the framework of Variational Autoencoders (VAEs), and present a new form of VAE that generalises normalising flows. The new generalised model also reveals a close connection to denoising autoencoders, and we therefore call our model the Variational Denoising Autoencoder (VDAE). Using our unified model, we systematically examine the model space between flows, variational autoencoders, and denoising autoencoders, in a set of preliminary experiments on the MNIST handwritten digits. The experiments shed light on the modeling assumptions implicit in these models, and they suggest multiple new directions for future research in this space.", "pdf": "/pdf/c18dc425a3fb7ee6e5fea04ca857be21a2b1e8e7.pdf", "paperhash": "gritsenko|on_the_relationship_between_normalising_flows_and_variational_and_denoising_autoencoders"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper30/Official_Review", "cdate": 1554234174711, "reply": {"forum": "HklKEUUY_E", "replyto": "HklKEUUY_E", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper30/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper30/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1554234174711, "tmdate": 1556906089695, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper30/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}, {"id": "Syep7Jnz5E", "original": null, "number": 1, "cdate": 1555377957514, "ddate": null, "tcdate": 1555377957514, "tmdate": 1556906139953, "tddate": null, "forum": "HklKEUUY_E", "replyto": "HklKEUUY_E", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper30/Official_Review", "content": {"title": "review", "review": "This paper applies normalizing flows into denoising autoencoders, and derives a variational lower bound when the posterior has this form. Experiments on MNIST show improvements over VAE, but worse than other NF models.\n\npros: The paper is well written and easy to follow. It does a good job in reviewing related work.\n\ncons: While it combines VAE, NF and DAE, no particular novel technique is introduced, and it\u2018s no better than existing models, so the significance of the proposed framework is unclear. In addition, the expensive complexity of L-VDAE makes it  difficult to scale to high-dimensional data. Nevertheless, the topic is very relevant and I think it's worth discussing at this workshop.", "rating": "3: Marginally above acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper30/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper30/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the relationship between Normalising Flows and Variational- and Denoising Autoencoders", "authors": ["Alexey A. Gritsenko", "Jasper Snoek", "Tim Salimans"], "authorids": ["agritsenko@google.com", "salimanstim@gmail.com", "jsnoek@google.com"], "keywords": ["variational autoencoders", "denoising variational autoencoders", "normalizing flows", "generative modelling", "image synthesis", "denoising autoencoders", "VAE", "DAE", "VDAE", "NF"], "TL;DR": "We explore the relationship between Normalising Flows and Variational- and Denoising Autoencoders, and propose a novel model that generalises them.", "abstract": "Normalising Flows (NFs) are a class of likelihood-based generative models that have recently gained popularity. They are based on the idea of transforming a simple density into that of the data. We seek to better understand this class of models, and how they compare to previously proposed techniques for generative modeling and unsupervised representation learning. For this purpose we reinterpret NFs in the framework of Variational Autoencoders (VAEs), and present a new form of VAE that generalises normalising flows. The new generalised model also reveals a close connection to denoising autoencoders, and we therefore call our model the Variational Denoising Autoencoder (VDAE). Using our unified model, we systematically examine the model space between flows, variational autoencoders, and denoising autoencoders, in a set of preliminary experiments on the MNIST handwritten digits. The experiments shed light on the modeling assumptions implicit in these models, and they suggest multiple new directions for future research in this space.", "pdf": "/pdf/c18dc425a3fb7ee6e5fea04ca857be21a2b1e8e7.pdf", "paperhash": "gritsenko|on_the_relationship_between_normalising_flows_and_variational_and_denoising_autoencoders"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper30/Official_Review", "cdate": 1554234174711, "reply": {"forum": "HklKEUUY_E", "replyto": "HklKEUUY_E", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper30/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper30/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1554234174711, "tmdate": 1556906089695, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper30/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}, {"id": "Bkeix4_vqN", "original": null, "number": 1, "cdate": 1555690482666, "ddate": null, "tcdate": 1555690482666, "tmdate": 1556906139743, "tddate": null, "forum": "HklKEUUY_E", "replyto": "HklKEUUY_E", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper30/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept", "comment": "Accepted"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the relationship between Normalising Flows and Variational- and Denoising Autoencoders", "authors": ["Alexey A. Gritsenko", "Jasper Snoek", "Tim Salimans"], "authorids": ["agritsenko@google.com", "salimanstim@gmail.com", "jsnoek@google.com"], "keywords": ["variational autoencoders", "denoising variational autoencoders", "normalizing flows", "generative modelling", "image synthesis", "denoising autoencoders", "VAE", "DAE", "VDAE", "NF"], "TL;DR": "We explore the relationship between Normalising Flows and Variational- and Denoising Autoencoders, and propose a novel model that generalises them.", "abstract": "Normalising Flows (NFs) are a class of likelihood-based generative models that have recently gained popularity. They are based on the idea of transforming a simple density into that of the data. We seek to better understand this class of models, and how they compare to previously proposed techniques for generative modeling and unsupervised representation learning. For this purpose we reinterpret NFs in the framework of Variational Autoencoders (VAEs), and present a new form of VAE that generalises normalising flows. The new generalised model also reveals a close connection to denoising autoencoders, and we therefore call our model the Variational Denoising Autoencoder (VDAE). Using our unified model, we systematically examine the model space between flows, variational autoencoders, and denoising autoencoders, in a set of preliminary experiments on the MNIST handwritten digits. The experiments shed light on the modeling assumptions implicit in these models, and they suggest multiple new directions for future research in this space.", "pdf": "/pdf/c18dc425a3fb7ee6e5fea04ca857be21a2b1e8e7.pdf", "paperhash": "gritsenko|on_the_relationship_between_normalising_flows_and_variational_and_denoising_autoencoders"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper30/Decision", "cdate": 1554814605611, "reply": {"forum": "HklKEUUY_E", "replyto": "HklKEUUY_E", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554814605611, "tmdate": 1556906099751, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}], "count": 4}