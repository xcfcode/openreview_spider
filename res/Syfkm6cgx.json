{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396668336, "tcdate": 1486396668336, "number": 1, "id": "rJ4WpzIdx", "invitation": "ICLR.cc/2017/conference/-/paper545/acceptance", "forum": "Syfkm6cgx", "replyto": "Syfkm6cgx", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "The authors have withdrawn the submission."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving Invariance and Equivariance Properties of Convolutional Neural Networks", "abstract": "Convolutional Neural Networks (CNNs) learn highly discriminative representations from data, but how robust and structured are these representations? How does the data shape the internal network representation? We shed light on these questions by empirically measuring the invariance and equivariance properties of a large number of CNNs trained with various types of input transformations. We find that CNNs learn invariance wrt all 9 tested transformation types and that invariance extends to transformations outside the training range. We also measure the distance between CNN representations and show that similar input transformations lead to more similar internal representations. Transforms can be grouped by the way they affect the learned representation. Additionally, we also propose a loss function that aims to improve CNN equivariance.", "pdf": "/pdf/c88ba30dec14bf324db81647ef68e43bbb50aee2.pdf", "TL;DR": "Data augmentation shapes internal network representation and makes predictions robust to input transformations.", "paperhash": "tensmeyer|improving_invariance_and_equivariance_properties_of_convolutional_neural_networks", "keywords": ["Deep learning"], "conflicts": ["byu.edu"], "authors": ["Christopher Tensmeyer", "Tony Martinez"], "authorids": ["tensmeyer@byu.edu", "martinez@cs.byu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396668862, "id": "ICLR.cc/2017/conference/-/paper545/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "Syfkm6cgx", "replyto": "Syfkm6cgx", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396668862}}}, {"tddate": null, "tmdate": 1482273008855, "tcdate": 1482273008855, "number": 4, "id": "SJKg-EDVx", "invitation": "ICLR.cc/2017/conference/-/paper545/public/comment", "forum": "Syfkm6cgx", "replyto": "Syfkm6cgx", "signatures": ["~Christopher_Tensmeyer1"], "readers": ["everyone"], "writers": ["~Christopher_Tensmeyer1"], "content": {"title": "Response to Reviews", "comment": "We thank the reviewers for their helpful and candid feedback on our work.  We will withdraw the paper from submission at ICLR 2017 and perform major revisions to address reviewer feedback before submission to another venue.\n\nIn particular, we will remove the portion of the paper dealing with improving invariance/equivariance and focus more on the empirical study and conclusions that can be drawn from it.  We appreciate the suggestion that more meaningful conclusions could be drawn from a comparative study of the invariances of different layers or architectures.  A more meaningful contribution in characterizing the structure of CNN representations would be finding some relationship between the M_g's for a particular transform.  For example, if M_g1 is rotation by 5 degrees and M_g2 is rotation by 10 degrees, does M_g2(x) = M_g1(M_g1(x)).\n\nAgain, we thank you for your time and attention."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving Invariance and Equivariance Properties of Convolutional Neural Networks", "abstract": "Convolutional Neural Networks (CNNs) learn highly discriminative representations from data, but how robust and structured are these representations? How does the data shape the internal network representation? We shed light on these questions by empirically measuring the invariance and equivariance properties of a large number of CNNs trained with various types of input transformations. We find that CNNs learn invariance wrt all 9 tested transformation types and that invariance extends to transformations outside the training range. We also measure the distance between CNN representations and show that similar input transformations lead to more similar internal representations. Transforms can be grouped by the way they affect the learned representation. Additionally, we also propose a loss function that aims to improve CNN equivariance.", "pdf": "/pdf/c88ba30dec14bf324db81647ef68e43bbb50aee2.pdf", "TL;DR": "Data augmentation shapes internal network representation and makes predictions robust to input transformations.", "paperhash": "tensmeyer|improving_invariance_and_equivariance_properties_of_convolutional_neural_networks", "keywords": ["Deep learning"], "conflicts": ["byu.edu"], "authors": ["Christopher Tensmeyer", "Tony Martinez"], "authorids": ["tensmeyer@byu.edu", "martinez@cs.byu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287528594, "id": "ICLR.cc/2017/conference/-/paper545/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Syfkm6cgx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper545/reviewers", "ICLR.cc/2017/conference/paper545/areachairs"], "cdate": 1485287528594}}}, {"tddate": null, "tmdate": 1481929092273, "tcdate": 1481929092273, "number": 3, "id": "SJ3K-lGNx", "invitation": "ICLR.cc/2017/conference/-/paper545/official/review", "forum": "Syfkm6cgx", "replyto": "Syfkm6cgx", "signatures": ["ICLR.cc/2017/conference/paper545/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper545/AnonReviewer3"], "content": {"title": "Not clear what we learn from the results", "rating": "4: Ok but not good enough - rejection", "review": "This paper empirically studies the invariance, equivariance and equivalence properties of representations learned by convolutional networks under various kinds of data augmentation. Additional loss terms are presented which can make a representation more invariant or equivariant.\n\nThe idea of measuring invariance, equivariance and equivalence of representations is not new (Lenc & Vedaldi). The authors are the first to systematically study the effect of data augmentation on these properties, but it is unclear in what way the results are surprising, interesting, or useful. It is not really surprising that data augmentation increases invariance, or that training with the same augmentation leads to more similar representations than training with different augmentations.\n\nRegarding the presented method to increase invariance and equivariance: while it could be that a representation will generalize better if it is invariant or equivariant, it is not clear why one would want to increase in/equivariance if it does not indeed lead to improvements in performance. The paper presents no evidence that training for increased invariance / equivariance leads to substantial improvements in performance. Combined with the fact that the loss (eq. 6) would substantially increase the computational burden, I don\u2019t think this technique will be very useful.\n\nMinor comments:\n-R^{nxn} should be R^{n \\times n}\n-In eq. 2: \u2018equivaraince\u2019\n-In 3.3, argmax is not properly formatted\n-I think data augmentation was already considered essential before Krizhevsky et al. Not really correct to attribute this to them.\n- About the claim \u201cThis is related to the idea of whether CNNs collapse (invariance) or linearize (equivariance) view manifolds of 3D objects\u201d. The idea that equivariance means that the manifold (orbit) is linearized, is incorrect. A linear representation M_g can create nonlinear manifolds. A simple example is given by a rotation matrix in 2D (clearly linear), generating a nonlinear manifold (the circle). \n- Equivariance in eq. 2 should be called \u201cnon-equivariance\u201d. If the value is low, the representation is equivariant, while if it is high it is non-equivariant.\n- \u201cEq. 2  also uses the paradigm that\u201d, uses the word paradigm in a strange manner\n- In the definition of x\u2019_ij, should one of the g_j be inverted? Otherwise it seems like the transformation is applied twice, instead of being undone.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving Invariance and Equivariance Properties of Convolutional Neural Networks", "abstract": "Convolutional Neural Networks (CNNs) learn highly discriminative representations from data, but how robust and structured are these representations? How does the data shape the internal network representation? We shed light on these questions by empirically measuring the invariance and equivariance properties of a large number of CNNs trained with various types of input transformations. We find that CNNs learn invariance wrt all 9 tested transformation types and that invariance extends to transformations outside the training range. We also measure the distance between CNN representations and show that similar input transformations lead to more similar internal representations. Transforms can be grouped by the way they affect the learned representation. Additionally, we also propose a loss function that aims to improve CNN equivariance.", "pdf": "/pdf/c88ba30dec14bf324db81647ef68e43bbb50aee2.pdf", "TL;DR": "Data augmentation shapes internal network representation and makes predictions robust to input transformations.", "paperhash": "tensmeyer|improving_invariance_and_equivariance_properties_of_convolutional_neural_networks", "keywords": ["Deep learning"], "conflicts": ["byu.edu"], "authors": ["Christopher Tensmeyer", "Tony Martinez"], "authorids": ["tensmeyer@byu.edu", "martinez@cs.byu.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512546945, "id": "ICLR.cc/2017/conference/-/paper545/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper545/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper545/AnonReviewer2", "ICLR.cc/2017/conference/paper545/AnonReviewer1", "ICLR.cc/2017/conference/paper545/AnonReviewer3"], "reply": {"forum": "Syfkm6cgx", "replyto": "Syfkm6cgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper545/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper545/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512546945}}}, {"tddate": null, "tmdate": 1481928613768, "tcdate": 1481928613768, "number": 2, "id": "HJAs1lG4g", "invitation": "ICLR.cc/2017/conference/-/paper545/official/review", "forum": "Syfkm6cgx", "replyto": "Syfkm6cgx", "signatures": ["ICLR.cc/2017/conference/paper545/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper545/AnonReviewer1"], "content": {"title": "Review", "rating": "5: Marginally below acceptance threshold", "review": "This work presents an empirical study of the influence of different types of data augmentation on the performance of CNNs. It also proposes to incorporate additional loss functions to encourage approximate invariance or equivariance, and shows there are some benefits.\n\nThe paper reads well and the objectives are clear. The study of invariances in CNNs is a very important topic, and advances in this area are greatly appreciated. The paper splits itself in two very different parts -- the empirical study of equivariances in existing CNNs, and the proposal of equivariance objectives. However, taken separately each of these two parts could be better executed.\n\nOn the empirical study, its breath is relatively limited, and it's hard to draw any far-reaching conclusions from it:\n- Only one network is studied; at least one other architecture would have made for better generalization.\n- Only one layer (fc7) is studied; this presents issues as the top layer is the most invariant. At least one convolutional layer (possibly more) should have been considered.\n- The reliance on the scanned text dataset does not help; however the ImageNet results are definitely very encouraging.\n\nIt is nice to see how performance degrades with the degree of transformations, and the authors do interpret the results, but it would be better to see more analysis. There is only a limited set of conclusions that can be drawn from evaluating networks with jittered data. If the authors could propose some other interesting ways to assess the invariance and equivariance, they would potentially draw more insightful conclusions from it.\n\nOn the proposed loss function, only a very quick treatment of it is given (Section 4, half a page). It does not differ too much from known invariance/equivariance objectives studied in the literature previously, e.g. Decoste and Scholkopf, \"Training Invariant Support Vector Machines\", Machine Learning, 2002.\n\nI'm not sure that dividing the paper into these two different contributions is the best approach; they both feel a bit incomplete, and a full treatment of only one of them would make for an overall better paper.\n\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving Invariance and Equivariance Properties of Convolutional Neural Networks", "abstract": "Convolutional Neural Networks (CNNs) learn highly discriminative representations from data, but how robust and structured are these representations? How does the data shape the internal network representation? We shed light on these questions by empirically measuring the invariance and equivariance properties of a large number of CNNs trained with various types of input transformations. We find that CNNs learn invariance wrt all 9 tested transformation types and that invariance extends to transformations outside the training range. We also measure the distance between CNN representations and show that similar input transformations lead to more similar internal representations. Transforms can be grouped by the way they affect the learned representation. Additionally, we also propose a loss function that aims to improve CNN equivariance.", "pdf": "/pdf/c88ba30dec14bf324db81647ef68e43bbb50aee2.pdf", "TL;DR": "Data augmentation shapes internal network representation and makes predictions robust to input transformations.", "paperhash": "tensmeyer|improving_invariance_and_equivariance_properties_of_convolutional_neural_networks", "keywords": ["Deep learning"], "conflicts": ["byu.edu"], "authors": ["Christopher Tensmeyer", "Tony Martinez"], "authorids": ["tensmeyer@byu.edu", "martinez@cs.byu.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512546945, "id": "ICLR.cc/2017/conference/-/paper545/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper545/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper545/AnonReviewer2", "ICLR.cc/2017/conference/paper545/AnonReviewer1", "ICLR.cc/2017/conference/paper545/AnonReviewer3"], "reply": {"forum": "Syfkm6cgx", "replyto": "Syfkm6cgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper545/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper545/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512546945}}}, {"tddate": null, "tmdate": 1481911653071, "tcdate": 1481911653071, "number": 1, "id": "B16DasZNx", "invitation": "ICLR.cc/2017/conference/-/paper545/official/review", "forum": "Syfkm6cgx", "replyto": "Syfkm6cgx", "signatures": ["ICLR.cc/2017/conference/paper545/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper545/AnonReviewer2"], "content": {"title": "Few novel outcomes with too many issues", "rating": "4: Ok but not good enough - rejection", "review": "This paper is an extension of Lenc&Vedaldi15 paper, showing CNN representations at FC7 layer are to certain extent equivariant to various classes of transformations and that training with a certain group of transformation makes the representations more equivalent.\n\nAuthors performed a large amount of experiments, training over 30 networks with different forms of jitter, which is quite impressive. However it is rather difficult to find a main message of this work. Yes, authors measured the properties on a different layer than the Lenc&Vedaldi15, however it is hard to find some novel insights other than the known fact that jitter helps to achieve invariance. The evaluation seems to be mostly correct, however the paper does not seem to be solving the task advertised in its title really well.\n\nMajor issues are in the experiments with the representation distances:\n* The selection of only FC7 is a bit controversial - it is followed only by a single classification layer (FC8) to the common output - class likelyhoods. Because the FC8 is just a linear projections, what the equivalence map does is just to re-project the FC8 weights of the attached network to the weights of the original network. Probably performing similar experiments but on more layers may be more useful (as the networks are already trained).\n* The experiment with representation distance is missing what is the classification error on the testing dataset. This would answer whether the representations are actually compatible up to linear transformation at all...\n* It is not clear for the experiment with K-NN whether this is measured per each test set example? After training the equivalence map? More clear would be to show that networks trained on similar group of jitter transformations are more compatible on the target task.\n* The proposed method does not seem to improve equivariance consistently on all tasks. Especially with \\lambda_1 and \\lambda_2 having such small values, the loss is basically equal to simple data jitter as it just adds up the loss of the original and transformed image. Maybe the issue is in the selection of the FC7 layer?\n\nIn general, this paper shows some interesting results on the FC7 equivariance, but it does not seem to be drawing many interesting new observations out of these experiments. Due to some issues with the equivalence experiments and the finetuning of equivariance, I would not recommend acceptance of this manuscript. However, refining the experiments on already trained networks and restructuring this manuscript into more investigative work may lead to interesting contribution to the field.\n\nThere are also few minor issues:\n* It is not experimentally verified that the new criterion for equivariance mapping helps to gain better results.\n* The angles on page 1 and 5 are missing units (degrees?).\n* On page three, \"In practice, it is difficult... \", it is not M_g which is maximised/minimised, but the loss over the M_g\n* Page 4, footnote 2 - if you are just halving the activations, it is hard to call it a dropout as this constant factor can be passed to the following/preceding weights\n* Is the network for RVL-CDIP the same architecture as Alexnet?\n* On page 7, Figure 3a+3b - in my opinion, turning the diagonal elements to white is really misleading, and probably even incorrect, as the distance between the same representations should be zero (which is also a way how to verify that the experiments are performed correctly).", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving Invariance and Equivariance Properties of Convolutional Neural Networks", "abstract": "Convolutional Neural Networks (CNNs) learn highly discriminative representations from data, but how robust and structured are these representations? How does the data shape the internal network representation? We shed light on these questions by empirically measuring the invariance and equivariance properties of a large number of CNNs trained with various types of input transformations. We find that CNNs learn invariance wrt all 9 tested transformation types and that invariance extends to transformations outside the training range. We also measure the distance between CNN representations and show that similar input transformations lead to more similar internal representations. Transforms can be grouped by the way they affect the learned representation. Additionally, we also propose a loss function that aims to improve CNN equivariance.", "pdf": "/pdf/c88ba30dec14bf324db81647ef68e43bbb50aee2.pdf", "TL;DR": "Data augmentation shapes internal network representation and makes predictions robust to input transformations.", "paperhash": "tensmeyer|improving_invariance_and_equivariance_properties_of_convolutional_neural_networks", "keywords": ["Deep learning"], "conflicts": ["byu.edu"], "authors": ["Christopher Tensmeyer", "Tony Martinez"], "authorids": ["tensmeyer@byu.edu", "martinez@cs.byu.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512546945, "id": "ICLR.cc/2017/conference/-/paper545/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper545/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper545/AnonReviewer2", "ICLR.cc/2017/conference/paper545/AnonReviewer1", "ICLR.cc/2017/conference/paper545/AnonReviewer3"], "reply": {"forum": "Syfkm6cgx", "replyto": "Syfkm6cgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper545/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper545/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512546945}}}, {"tddate": null, "tmdate": 1481728649647, "tcdate": 1481728649640, "number": 2, "id": "SkM5M1yEx", "invitation": "ICLR.cc/2017/conference/-/paper545/official/comment", "forum": "Syfkm6cgx", "replyto": "BJPYIkCXg", "signatures": ["ICLR.cc/2017/conference/paper545/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper545/AnonReviewer1"], "content": {"title": "Follow-up", "comment": "Thank you for answering my questions. As a follow-up to 2), Lenc and Vedaldi performed their investigation *before* the ReLU, so that they wouldn't have to deal with the problem of non-negative values that you describe. However, this is a minor point, and both approaches are acceptable.\n\nAbout 3), I don't really see a place for RVL-CDIP except in the appendix. I think it is okay to discuss it briefly in the main text, e.g. saying that the conclusions are similar and thus there is a degree of cross-dataset consistency. However, the bulk of the main text should really focus on ImageNet instead. The statistics of natural images, and artificial transformations that correlate well with them, are important and broadly applicable; the scanned text doesn't help much in that regard.\n\n\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving Invariance and Equivariance Properties of Convolutional Neural Networks", "abstract": "Convolutional Neural Networks (CNNs) learn highly discriminative representations from data, but how robust and structured are these representations? How does the data shape the internal network representation? We shed light on these questions by empirically measuring the invariance and equivariance properties of a large number of CNNs trained with various types of input transformations. We find that CNNs learn invariance wrt all 9 tested transformation types and that invariance extends to transformations outside the training range. We also measure the distance between CNN representations and show that similar input transformations lead to more similar internal representations. Transforms can be grouped by the way they affect the learned representation. Additionally, we also propose a loss function that aims to improve CNN equivariance.", "pdf": "/pdf/c88ba30dec14bf324db81647ef68e43bbb50aee2.pdf", "TL;DR": "Data augmentation shapes internal network representation and makes predictions robust to input transformations.", "paperhash": "tensmeyer|improving_invariance_and_equivariance_properties_of_convolutional_neural_networks", "keywords": ["Deep learning"], "conflicts": ["byu.edu"], "authors": ["Christopher Tensmeyer", "Tony Martinez"], "authorids": ["tensmeyer@byu.edu", "martinez@cs.byu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287528466, "id": "ICLR.cc/2017/conference/-/paper545/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "Syfkm6cgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper545/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper545/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper545/reviewers", "ICLR.cc/2017/conference/paper545/areachairs"], "cdate": 1485287528466}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1481673107799, "tcdate": 1478312665928, "number": 545, "id": "Syfkm6cgx", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "Syfkm6cgx", "signatures": ["~Christopher_Tensmeyer1"], "readers": ["everyone"], "content": {"title": "Improving Invariance and Equivariance Properties of Convolutional Neural Networks", "abstract": "Convolutional Neural Networks (CNNs) learn highly discriminative representations from data, but how robust and structured are these representations? How does the data shape the internal network representation? We shed light on these questions by empirically measuring the invariance and equivariance properties of a large number of CNNs trained with various types of input transformations. We find that CNNs learn invariance wrt all 9 tested transformation types and that invariance extends to transformations outside the training range. We also measure the distance between CNN representations and show that similar input transformations lead to more similar internal representations. Transforms can be grouped by the way they affect the learned representation. Additionally, we also propose a loss function that aims to improve CNN equivariance.", "pdf": "/pdf/c88ba30dec14bf324db81647ef68e43bbb50aee2.pdf", "TL;DR": "Data augmentation shapes internal network representation and makes predictions robust to input transformations.", "paperhash": "tensmeyer|improving_invariance_and_equivariance_properties_of_convolutional_neural_networks", "keywords": ["Deep learning"], "conflicts": ["byu.edu"], "authors": ["Christopher Tensmeyer", "Tony Martinez"], "authorids": ["tensmeyer@byu.edu", "martinez@cs.byu.edu"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 12, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1481664126752, "tcdate": 1481664126741, "number": 3, "id": "BJPYIkCXg", "invitation": "ICLR.cc/2017/conference/-/paper545/public/comment", "forum": "Syfkm6cgx", "replyto": "SyuILpTQe", "signatures": ["~Christopher_Tensmeyer1"], "readers": ["everyone"], "writers": ["~Christopher_Tensmeyer1"], "content": {"title": "Response to Clarifications", "comment": "1) You are correct that requiring E1 to be invertible would yield the desired definition of equivalence.  If E1 and E2 exist (under our definition), then E2 does indeed invert E1.  The invertiblility of the mapping is discussed in Lenc and Vedaldi 2015, but not required in the definition.  However, it is also useful to consider the idea of sub-representation, which introduces a partial ordering over representations.  A different example may be more motivating for Eq 5.  The two representations could be the RGB pixel representation vs Grayscale pixel representation.\n\n2) The residual mapping is used for equivariance because the equivariance mapping is likely close to identity.  Through data augmentation, the CNN classification layer has learned to classify both transformed and untransformed images before any equivariance mapping is applied.  The residual aspect does not change the space of possible mappings, but allows the optimization procedure to start nearer a good solution.  When computing correspondences between two CNNs, there is no motivation to bias toward an identity mapping due to lack of correspondence between neurons with the same index.\nWe chose to apply the ReLU non-linearity (in contrast the pure linear model of Lenc and Vedaldi 2015) because the representation we aim to predict (fc7) has been rectified.  The pure linear model may predict negative values during training, which we know apriori are not in the target outputs.  We argue that it is better to incorporate this into the learning process rather than training a linear model agnostic to the fact that the outputs will rectified.\n\n3) This is a good point.  We initially performed this work primarily for RVL-CDIP (and hence personally considered the results on this dataset as primary) and added ILSVRC for broader applicability.  However, the broader community is more interested in ILSVRC.  We will move the majority of Section 6.1 to the Appendix and move the ILSVRC results and discussion into the main paper as a replacement.  The results agree as far as the conclusions go, but differ based on some properties of the datasets.In your opinion, would it be considered an appropriate use of space (in excess of 8 pages) to include figures for both ILSVRC and RVL-CDIP in Section 6.1?\n\n4) A good suggestion.  The first plot of Figure 3a gives something similar to a hierarchical clustering plot, but in a more summarized and less detailed format.  We\u2019ll investigate this.\n\n\nYou can expect a revision incorporating this feedback in the next couple days.\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving Invariance and Equivariance Properties of Convolutional Neural Networks", "abstract": "Convolutional Neural Networks (CNNs) learn highly discriminative representations from data, but how robust and structured are these representations? How does the data shape the internal network representation? We shed light on these questions by empirically measuring the invariance and equivariance properties of a large number of CNNs trained with various types of input transformations. We find that CNNs learn invariance wrt all 9 tested transformation types and that invariance extends to transformations outside the training range. We also measure the distance between CNN representations and show that similar input transformations lead to more similar internal representations. Transforms can be grouped by the way they affect the learned representation. Additionally, we also propose a loss function that aims to improve CNN equivariance.", "pdf": "/pdf/c88ba30dec14bf324db81647ef68e43bbb50aee2.pdf", "TL;DR": "Data augmentation shapes internal network representation and makes predictions robust to input transformations.", "paperhash": "tensmeyer|improving_invariance_and_equivariance_properties_of_convolutional_neural_networks", "keywords": ["Deep learning"], "conflicts": ["byu.edu"], "authors": ["Christopher Tensmeyer", "Tony Martinez"], "authorids": ["tensmeyer@byu.edu", "martinez@cs.byu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287528594, "id": "ICLR.cc/2017/conference/-/paper545/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Syfkm6cgx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper545/reviewers", "ICLR.cc/2017/conference/paper545/areachairs"], "cdate": 1485287528594}}}, {"tddate": null, "tmdate": 1481655887563, "tcdate": 1481655887555, "number": 3, "id": "SyuILpTQe", "invitation": "ICLR.cc/2017/conference/-/paper545/pre-review/question", "forum": "Syfkm6cgx", "replyto": "Syfkm6cgx", "signatures": ["ICLR.cc/2017/conference/paper545/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper545/AnonReviewer1"], "content": {"title": "Clarifications", "question": "1. In Section 3.2, the counter-example to symmetry seems to be easily addressed by requiring that E1 be invertible. In that case, one obtains trivially E2 = inverse of E1. As such, it seems that it does not work as a motivation for Eq. 5.\nIn the context of a loss function, however, the authors' intuition seems to be right: ||E2 phi2(x) - phi1(x)|| is different from ||phi2(x) - E1 phi1(x)||. This should be enough to justify the form of Eq. 5, which enforces symmetry. Can the authors comment on this?\n\n2. In Sections 5.2 and 5.3, many functional forms of the mapping are discussed. Why not use the same in both sections? Also, why wasn't a direct linear mapping used instead of these forms (as in Lenc and Vedaldi 2015)?\n\n3. The fact that the main experiments are conducted on scanned text reduces the generality of the conclusions a lot. Most computer vision deals with natural images, and as the authors admit in the paper, the studied transformations do not even appear naturally in the scanned text images. Why weren't the ImageNet experiments included in the main paper instead?\n\n4. As a final suggestion, a hierarchical clustering algorithm may yield a better (tree-like) visualization of the distance matrices (as opposed to t-SNE)."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving Invariance and Equivariance Properties of Convolutional Neural Networks", "abstract": "Convolutional Neural Networks (CNNs) learn highly discriminative representations from data, but how robust and structured are these representations? How does the data shape the internal network representation? We shed light on these questions by empirically measuring the invariance and equivariance properties of a large number of CNNs trained with various types of input transformations. We find that CNNs learn invariance wrt all 9 tested transformation types and that invariance extends to transformations outside the training range. We also measure the distance between CNN representations and show that similar input transformations lead to more similar internal representations. Transforms can be grouped by the way they affect the learned representation. Additionally, we also propose a loss function that aims to improve CNN equivariance.", "pdf": "/pdf/c88ba30dec14bf324db81647ef68e43bbb50aee2.pdf", "TL;DR": "Data augmentation shapes internal network representation and makes predictions robust to input transformations.", "paperhash": "tensmeyer|improving_invariance_and_equivariance_properties_of_convolutional_neural_networks", "keywords": ["Deep learning"], "conflicts": ["byu.edu"], "authors": ["Christopher Tensmeyer", "Tony Martinez"], "authorids": ["tensmeyer@byu.edu", "martinez@cs.byu.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481655888185, "id": "ICLR.cc/2017/conference/-/paper545/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper545/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper545/AnonReviewer3", "ICLR.cc/2017/conference/paper545/AnonReviewer2", "ICLR.cc/2017/conference/paper545/AnonReviewer1"], "reply": {"forum": "Syfkm6cgx", "replyto": "Syfkm6cgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper545/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper545/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481655888185}}}, {"tddate": null, "tmdate": 1481089098595, "tcdate": 1481089098586, "number": 2, "id": "SJ7UemHXl", "invitation": "ICLR.cc/2017/conference/-/paper545/public/comment", "forum": "Syfkm6cgx", "replyto": "BkpouukXe", "signatures": ["~Christopher_Tensmeyer1"], "readers": ["everyone"], "writers": ["~Christopher_Tensmeyer1"], "content": {"title": "Clarification of Questions and Notice of Changes", "comment": "I'll address each point in turn:\n\nThe values of lambda_1 and lambda_2 are small to adjust for the different scales of the loss function.  The first term (without weighting coefficient) is cross entropy over 16 or 1000 categories, depending on the dataset.  The terms utilizing lambda_{1,2} as weights are Euclidean distance between vectors with dimension 4096 (hence the denominator for these values).  We could not extensively tune these parameters as we focused more of our effort and compute resources on finding reasonable values for lambda_3, which is a more important parameter in determining the success of the method.  Our initial prototyping experiments did indicate that the L2 loss on the feature vectors did slightly increase equivariance.\n\nThe paper has been updated with results for equivariance fine tuning for ILSVRC.  We had to rerun experiments with a larger batch size to get reasonable results due to having more classes in ILSVRC than in RVL-CDIP.\n\nYes, an equivariance measurement consists of learning a M_g using images that were transformed by g.  The measurement is then the error of the learned M_g. If a network is completely invariant to a transformation, then M_g should learn the identity mapping (assuming sufficient data).  The caption of Figure 1 has been updated with this explanation.\n\nWe have not explored other layers yet. We studied fc7 as it is the most invariant layer.  Comparing the equivariance of previous layers to fc7 would be an interesting direction for future work.  It might be difficult because it is reasonable to expect good M_g functions to be approximately linear for fc7 because a linear classifier is applied directly to this layer.  Mappings could exist in e.g. fc6, but the optimization procedure is not necessarily pushing such equivariance to be linear."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving Invariance and Equivariance Properties of Convolutional Neural Networks", "abstract": "Convolutional Neural Networks (CNNs) learn highly discriminative representations from data, but how robust and structured are these representations? How does the data shape the internal network representation? We shed light on these questions by empirically measuring the invariance and equivariance properties of a large number of CNNs trained with various types of input transformations. We find that CNNs learn invariance wrt all 9 tested transformation types and that invariance extends to transformations outside the training range. We also measure the distance between CNN representations and show that similar input transformations lead to more similar internal representations. Transforms can be grouped by the way they affect the learned representation. Additionally, we also propose a loss function that aims to improve CNN equivariance.", "pdf": "/pdf/c88ba30dec14bf324db81647ef68e43bbb50aee2.pdf", "TL;DR": "Data augmentation shapes internal network representation and makes predictions robust to input transformations.", "paperhash": "tensmeyer|improving_invariance_and_equivariance_properties_of_convolutional_neural_networks", "keywords": ["Deep learning"], "conflicts": ["byu.edu"], "authors": ["Christopher Tensmeyer", "Tony Martinez"], "authorids": ["tensmeyer@byu.edu", "martinez@cs.byu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287528594, "id": "ICLR.cc/2017/conference/-/paper545/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Syfkm6cgx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper545/reviewers", "ICLR.cc/2017/conference/paper545/areachairs"], "cdate": 1485287528594}}}, {"tddate": null, "tmdate": 1480718500608, "tcdate": 1480718500602, "number": 2, "id": "BkpouukXe", "invitation": "ICLR.cc/2017/conference/-/paper545/pre-review/question", "forum": "Syfkm6cgx", "replyto": "Syfkm6cgx", "signatures": ["ICLR.cc/2017/conference/paper545/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper545/AnonReviewer2"], "content": {"title": "Pre-review Questions", "question": "- The values of lambda_1 and lambda_2 seems to be extremely small. Are those terms even needed? Would the performance change if you would omit those terms completely?\n- Does the equivariance fine tuning work on the ILSVRC dataset as well?\n- Can you clarify the labels for Figure 1 and 2 - does an equivariance measurement mean that an appropriate M_g for the g transformation has been used? E.g. that the network gets completely invariant against Gaussian blur and the M_g does not have any effect...\n- Have you performed similar investigation on lower layers then fc7? "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving Invariance and Equivariance Properties of Convolutional Neural Networks", "abstract": "Convolutional Neural Networks (CNNs) learn highly discriminative representations from data, but how robust and structured are these representations? How does the data shape the internal network representation? We shed light on these questions by empirically measuring the invariance and equivariance properties of a large number of CNNs trained with various types of input transformations. We find that CNNs learn invariance wrt all 9 tested transformation types and that invariance extends to transformations outside the training range. We also measure the distance between CNN representations and show that similar input transformations lead to more similar internal representations. Transforms can be grouped by the way they affect the learned representation. Additionally, we also propose a loss function that aims to improve CNN equivariance.", "pdf": "/pdf/c88ba30dec14bf324db81647ef68e43bbb50aee2.pdf", "TL;DR": "Data augmentation shapes internal network representation and makes predictions robust to input transformations.", "paperhash": "tensmeyer|improving_invariance_and_equivariance_properties_of_convolutional_neural_networks", "keywords": ["Deep learning"], "conflicts": ["byu.edu"], "authors": ["Christopher Tensmeyer", "Tony Martinez"], "authorids": ["tensmeyer@byu.edu", "martinez@cs.byu.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481655888185, "id": "ICLR.cc/2017/conference/-/paper545/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper545/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper545/AnonReviewer3", "ICLR.cc/2017/conference/paper545/AnonReviewer2", "ICLR.cc/2017/conference/paper545/AnonReviewer1"], "reply": {"forum": "Syfkm6cgx", "replyto": "Syfkm6cgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper545/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper545/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481655888185}}}, {"tddate": null, "tmdate": 1480351573520, "tcdate": 1480351573515, "number": 1, "id": "B168Jk9Ml", "invitation": "ICLR.cc/2017/conference/-/paper545/public/comment", "forum": "Syfkm6cgx", "replyto": "BymqepPMl", "signatures": ["~Christopher_Tensmeyer1"], "readers": ["everyone"], "writers": ["~Christopher_Tensmeyer1"], "content": {"title": "Clarification of \"structure wrt\"", "comment": "Each input image is mapped to some point in the representation space.  When input images undergo some transformation in the input space, they are mapped to different points in the representation space.  We characterize the representation function as structured wrt some input transformation (e.g. blur) if there is a linear mapping between these two sets of points.  We interpret this as structure because a transform in the input space leads to a corresponding transform in the representation space.\n\nIn practice, no linear mapping is exact, but we can quantify the degree of structure by measuring the error of the best linear mapping we can find from the data.\n\nYes, eq. 2 should say min.  This has been corrected."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving Invariance and Equivariance Properties of Convolutional Neural Networks", "abstract": "Convolutional Neural Networks (CNNs) learn highly discriminative representations from data, but how robust and structured are these representations? How does the data shape the internal network representation? We shed light on these questions by empirically measuring the invariance and equivariance properties of a large number of CNNs trained with various types of input transformations. We find that CNNs learn invariance wrt all 9 tested transformation types and that invariance extends to transformations outside the training range. We also measure the distance between CNN representations and show that similar input transformations lead to more similar internal representations. Transforms can be grouped by the way they affect the learned representation. Additionally, we also propose a loss function that aims to improve CNN equivariance.", "pdf": "/pdf/c88ba30dec14bf324db81647ef68e43bbb50aee2.pdf", "TL;DR": "Data augmentation shapes internal network representation and makes predictions robust to input transformations.", "paperhash": "tensmeyer|improving_invariance_and_equivariance_properties_of_convolutional_neural_networks", "keywords": ["Deep learning"], "conflicts": ["byu.edu"], "authors": ["Christopher Tensmeyer", "Tony Martinez"], "authorids": ["tensmeyer@byu.edu", "martinez@cs.byu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287528594, "id": "ICLR.cc/2017/conference/-/paper545/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Syfkm6cgx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper545/reviewers", "ICLR.cc/2017/conference/paper545/areachairs"], "cdate": 1485287528594}}}, {"tddate": null, "tmdate": 1480212618612, "tcdate": 1480212618607, "number": 1, "id": "BymqepPMl", "invitation": "ICLR.cc/2017/conference/-/paper545/pre-review/question", "forum": "Syfkm6cgx", "replyto": "Syfkm6cgx", "signatures": ["ICLR.cc/2017/conference/paper545/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper545/AnonReviewer3"], "content": {"title": "Meaning of \"structured wrt\"", "question": "Please clarify what you mean by a representation being \"structured wrt blur\" (or other kinds of transformations).\n\nIn eq. 2, do you mean min instead of max?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improving Invariance and Equivariance Properties of Convolutional Neural Networks", "abstract": "Convolutional Neural Networks (CNNs) learn highly discriminative representations from data, but how robust and structured are these representations? How does the data shape the internal network representation? We shed light on these questions by empirically measuring the invariance and equivariance properties of a large number of CNNs trained with various types of input transformations. We find that CNNs learn invariance wrt all 9 tested transformation types and that invariance extends to transformations outside the training range. We also measure the distance between CNN representations and show that similar input transformations lead to more similar internal representations. Transforms can be grouped by the way they affect the learned representation. Additionally, we also propose a loss function that aims to improve CNN equivariance.", "pdf": "/pdf/c88ba30dec14bf324db81647ef68e43bbb50aee2.pdf", "TL;DR": "Data augmentation shapes internal network representation and makes predictions robust to input transformations.", "paperhash": "tensmeyer|improving_invariance_and_equivariance_properties_of_convolutional_neural_networks", "keywords": ["Deep learning"], "conflicts": ["byu.edu"], "authors": ["Christopher Tensmeyer", "Tony Martinez"], "authorids": ["tensmeyer@byu.edu", "martinez@cs.byu.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481655888185, "id": "ICLR.cc/2017/conference/-/paper545/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper545/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper545/AnonReviewer3", "ICLR.cc/2017/conference/paper545/AnonReviewer2", "ICLR.cc/2017/conference/paper545/AnonReviewer1"], "reply": {"forum": "Syfkm6cgx", "replyto": "Syfkm6cgx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper545/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper545/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481655888185}}}], "count": 13}