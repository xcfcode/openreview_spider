{"notes": [{"tddate": null, "ddate": null, "tmdate": 1524232272098, "tcdate": 1520000610403, "number": 363, "cdate": 1520000610403, "id": "rycPR0Luz", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "rycPR0Luz", "original": "ryALZdAT-", "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Feature Incay for Representation Regularization", "abstract": "Softmax-based loss is widely used in deep learning for multi-class classification, where each class is represented by a weight vector and each sample is represented as a feature vector. Different from traditional learning algorithms where features are pre-defined and only weight vectors are tunable through training, feature vectors are also tunable as representation learning in deep learning. Thus we investigate how to improve the classification performance by better adjusting the features. One main observation is that elongating the feature norm of both correctly-classified and mis-classified feature vectors improves learning: (1) increasing the feature norm of correctly-classified examples induce smaller training loss; (2) increasing the feature norm of mis-classified examples can upweight the contribution from hard examples. Accordingly, we propose feature incay to regularize representation learning by encouraging larger feature norm. In contrast to weight decay which shrinks the weight norm, feature incay is proposed to stretch the feature norm. Extensive empirical results on MNIST, CIFAR10, CIFAR100 and LFW demonstrate the effectiveness of feature incay. ", "pdf": "/pdf/68143ab8c37b4d43eb14e7d7b849ab2fd0f5758b.pdf", "paperhash": "yuan|feature_incay_for_representation_regularization", "_bibtex": "@misc{\nyuan2018feature,\ntitle={Feature Incay for Representation Regularization},\nauthor={Yuhui Yuan and Kuiyuan Yang and Jianyuan Guo and Jingdong Wang and Chao Zhang},\nyear={2018},\nurl={https://openreview.net/forum?id=ryALZdAT-},\n}", "keywords": ["feature norm", "regularization", "softmax loss", "feature incay"], "authors": ["Yuhui Yuan", "Kuiyuan Yang", "Jianyuan Guo", "Chao Zhang", "Jingdong Wang"], "authorids": ["yuyua@microsoft.com", "kuiyuanyang@deepmotion.ai", "1701214082@pku.edu.cn", "chzhang@cis.pku.edu.cn", "jingdw@microsoft.com"]}, "nonreaders": [], "details": {"replyCount": 1, "writable": false, "overwriting": [], "revisions": true, "tags": [], "original": {"tddate": null, "ddate": null, "tmdate": 1524232272098, "tcdate": 1508962646459, "number": 95, "cdate": 1518730189282, "id": "ryALZdAT-", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "ryALZdAT-", "original": "BkCLb_0T-", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "Feature Incay for Representation Regularization", "abstract": "Softmax-based loss is widely used in deep learning for multi-class classification, where each class is represented by a weight vector and each sample is represented as a feature vector. Different from traditional learning algorithms where features are pre-defined and only weight vectors are tunable through training, feature vectors are also tunable as representation learning in deep learning. Thus we investigate how to improve the classification performance by better adjusting the features. One main observation is that elongating the feature norm of both correctly-classified and mis-classified feature vectors improves learning: (1) increasing the feature norm of correctly-classified examples induce smaller training loss; (2) increasing the feature norm of mis-classified examples can upweight the contribution from hard examples. Accordingly, we propose feature incay to regularize representation learning by encouraging larger feature norm. In contrast to weight decay which shrinks the weight norm, feature incay is proposed to stretch the feature norm. Extensive empirical results on MNIST, CIFAR10, CIFAR100 and LFW demonstrate the effectiveness of feature incay. ", "pdf": "/pdf/31551e5bc86c3c11034c71a6cbff7afa8c0efcba.pdf", "paperhash": "yuan|feature_incay_for_representation_regularization", "_bibtex": "@misc{\nyuan2018feature,\ntitle={Feature Incay for Representation Regularization},\nauthor={Yuhui Yuan and Kuiyuan Yang and Jianyuan Guo and Jingdong Wang and Chao Zhang},\nyear={2018},\nurl={https://openreview.net/forum?id=ryALZdAT-},\n}", "keywords": ["feature norm", "regularization", "softmax loss", "feature incay"], "authors": ["Yuhui Yuan", "Kuiyuan Yang", "Jianyuan Guo", "Jingdong Wang", "Chao Zhang"], "authorids": ["yuyua@microsoft.com", "kuiyuanyang@deepmotion.ai", "1701214082@pku.edu.cn", "jingdw@microsoft.com", "chzhang@cis.pku.edu.cn"]}, "nonreaders": []}, "originalWritable": false, "originalInvitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}, "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}, "tauthor": "ICLR.cc/2018/Workshop"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573625802, "tcdate": 1521573625802, "number": 346, "cdate": 1521573625452, "id": "S1M-ky1qz", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "rycPR0Luz", "replyto": "rycPR0Luz", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "This paper was invited to the workshop track based on reviews at the main conference."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Incay for Representation Regularization", "abstract": "Softmax-based loss is widely used in deep learning for multi-class classification, where each class is represented by a weight vector and each sample is represented as a feature vector. Different from traditional learning algorithms where features are pre-defined and only weight vectors are tunable through training, feature vectors are also tunable as representation learning in deep learning. Thus we investigate how to improve the classification performance by better adjusting the features. One main observation is that elongating the feature norm of both correctly-classified and mis-classified feature vectors improves learning: (1) increasing the feature norm of correctly-classified examples induce smaller training loss; (2) increasing the feature norm of mis-classified examples can upweight the contribution from hard examples. Accordingly, we propose feature incay to regularize representation learning by encouraging larger feature norm. In contrast to weight decay which shrinks the weight norm, feature incay is proposed to stretch the feature norm. Extensive empirical results on MNIST, CIFAR10, CIFAR100 and LFW demonstrate the effectiveness of feature incay. ", "pdf": "/pdf/68143ab8c37b4d43eb14e7d7b849ab2fd0f5758b.pdf", "paperhash": "yuan|feature_incay_for_representation_regularization", "_bibtex": "@misc{\nyuan2018feature,\ntitle={Feature Incay for Representation Regularization},\nauthor={Yuhui Yuan and Kuiyuan Yang and Jianyuan Guo and Jingdong Wang and Chao Zhang},\nyear={2018},\nurl={https://openreview.net/forum?id=ryALZdAT-},\n}", "keywords": ["feature norm", "regularization", "softmax loss", "feature incay"], "authors": ["Yuhui Yuan", "Kuiyuan Yang", "Jianyuan Guo", "Chao Zhang", "Jingdong Wang"], "authorids": ["yuyua@microsoft.com", "kuiyuanyang@deepmotion.ai", "1701214082@pku.edu.cn", "chzhang@cis.pku.edu.cn", "jingdw@microsoft.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 2}