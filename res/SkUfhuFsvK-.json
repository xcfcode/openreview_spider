{"notes": [{"id": "SkUfhuFsvK-", "original": "99jSMETG7hCp", "number": 989, "cdate": 1601308112182, "ddate": null, "tcdate": 1601308112182, "tmdate": 1614985628592, "tddate": null, "forum": "SkUfhuFsvK-", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "FASG: Feature Aggregation Self-training GCN for Semi-supervised Node Classification", "authorids": ["~Gongpei_Zhao1", "~Tao_Wang1", "~Yidong_Li1", "~Yi_Jin2"], "authors": ["Gongpei Zhao", "Tao Wang", "Yidong Li", "Yi Jin"], "keywords": [], "abstract": "Recently, Graph Convolutioal Networks (GCNs) have achieved significant success in many graph-based learning tasks, especially for node classification, due to its excellent ability in representation learning. Nevertheless, it remains challenging for GCN models to obtain satisfying prediction on graphs where few nodes are with known labels. In this paper, we propose a novel self-training algorithm based on GCN to boost semi-supervised node classification on graphs with little supervised information. Inspired by self-supervision strategy, the proposed method introduces an ingenious checking part to add new nodes as supervision after each training epoch to enhance node prediction. In particular, the embedded checking part is designed based on aggregated features, which is more accurate than previous methods and boosts node classification significantly. The proposed algorithm is validated on three public benchmarks in comparison with several state-of-the-art baseline algorithms, and the results illustrate its excellent performance.", "pdf": "/pdf/c14804b5e5e02c92cb071f950c7f1d748585b65b.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhao|fasg_feature_aggregation_selftraining_gcn_for_semisupervised_node_classification", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=g5jvuFmEsw", "_bibtex": "@misc{\nzhao2021fasg,\ntitle={{\\{}FASG{\\}}: Feature Aggregation Self-training {\\{}GCN{\\}} for Semi-supervised Node Classification},\nauthor={Gongpei Zhao and Tao Wang and Yidong Li and Yi Jin},\nyear={2021},\nurl={https://openreview.net/forum?id=SkUfhuFsvK-}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "F_K9g5fHwp7", "original": null, "number": 1, "cdate": 1610040531628, "ddate": null, "tcdate": 1610040531628, "tmdate": 1610474141247, "tddate": null, "forum": "SkUfhuFsvK-", "replyto": "SkUfhuFsvK-", "invitation": "ICLR.cc/2021/Conference/Paper989/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "This paper presents a self-training idea for GCN models to help improve the node classification. The reviewers agreed that the technical contribution of the proposed approach is limited and the performance improvement seems marginal. "}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "FASG: Feature Aggregation Self-training GCN for Semi-supervised Node Classification", "authorids": ["~Gongpei_Zhao1", "~Tao_Wang1", "~Yidong_Li1", "~Yi_Jin2"], "authors": ["Gongpei Zhao", "Tao Wang", "Yidong Li", "Yi Jin"], "keywords": [], "abstract": "Recently, Graph Convolutioal Networks (GCNs) have achieved significant success in many graph-based learning tasks, especially for node classification, due to its excellent ability in representation learning. Nevertheless, it remains challenging for GCN models to obtain satisfying prediction on graphs where few nodes are with known labels. In this paper, we propose a novel self-training algorithm based on GCN to boost semi-supervised node classification on graphs with little supervised information. Inspired by self-supervision strategy, the proposed method introduces an ingenious checking part to add new nodes as supervision after each training epoch to enhance node prediction. In particular, the embedded checking part is designed based on aggregated features, which is more accurate than previous methods and boosts node classification significantly. The proposed algorithm is validated on three public benchmarks in comparison with several state-of-the-art baseline algorithms, and the results illustrate its excellent performance.", "pdf": "/pdf/c14804b5e5e02c92cb071f950c7f1d748585b65b.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhao|fasg_feature_aggregation_selftraining_gcn_for_semisupervised_node_classification", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=g5jvuFmEsw", "_bibtex": "@misc{\nzhao2021fasg,\ntitle={{\\{}FASG{\\}}: Feature Aggregation Self-training {\\{}GCN{\\}} for Semi-supervised Node Classification},\nauthor={Gongpei Zhao and Tao Wang and Yidong Li and Yi Jin},\nyear={2021},\nurl={https://openreview.net/forum?id=SkUfhuFsvK-}\n}"}, "tags": [], "invitation": {"reply": {"forum": "SkUfhuFsvK-", "replyto": "SkUfhuFsvK-", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040531614, "tmdate": 1610474141232, "id": "ICLR.cc/2021/Conference/Paper989/-/Decision"}}}, {"id": "D6U1I1zHCr", "original": null, "number": 1, "cdate": 1603751390487, "ddate": null, "tcdate": 1603751390487, "tmdate": 1605024557815, "tddate": null, "forum": "SkUfhuFsvK-", "replyto": "SkUfhuFsvK-", "invitation": "ICLR.cc/2021/Conference/Paper989/-/Official_Review", "content": {"title": "my review", "review": "This paper presents a self-training algorithm based on GCN to improve the semi-supervised node classification on graphs. The key idea is to add new nodes with high confidence as supervision to enlarge the labeled nodes. Although the experimental results show the proposed method outperforms or performs similarly to baseline methods, the paper has several weaknesses. First the presented approach is not clearly introduced, with inconsistent statements on building the checking part, and lack of details on how to calculate the confidence to add the new nodes. Second, the novelty of the presented approach is limited, as adding unlabeled samples with high confidence is not a novel idea. Third, the paper writing should be improved, as there are errors.  \n\nIn Table 2, GAT has better or similar performance comparing to feat5+SVM. Why not using GAT feature aggregation for building the checking part? And, in page 5, it says \u201cAt the beginning, we concatenate features from feat0 to feat10 and put them into a linear SVM to build the checking part. \u201d.  So, it is confusing how the checking part is built. In Algorithm 1,  feat1 to feat9 were concatenated in line 2. The statements are not consistent in the whole paper.\n\nIn the line 6 of Algorithm 1, Train GCN model and get predictions and confidence matix:   How the confidence is calculated? \n\nThere are writing errors to correct, such as   Due to its its excellent,   confidence matix: \n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper989/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper989/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "FASG: Feature Aggregation Self-training GCN for Semi-supervised Node Classification", "authorids": ["~Gongpei_Zhao1", "~Tao_Wang1", "~Yidong_Li1", "~Yi_Jin2"], "authors": ["Gongpei Zhao", "Tao Wang", "Yidong Li", "Yi Jin"], "keywords": [], "abstract": "Recently, Graph Convolutioal Networks (GCNs) have achieved significant success in many graph-based learning tasks, especially for node classification, due to its excellent ability in representation learning. Nevertheless, it remains challenging for GCN models to obtain satisfying prediction on graphs where few nodes are with known labels. In this paper, we propose a novel self-training algorithm based on GCN to boost semi-supervised node classification on graphs with little supervised information. Inspired by self-supervision strategy, the proposed method introduces an ingenious checking part to add new nodes as supervision after each training epoch to enhance node prediction. In particular, the embedded checking part is designed based on aggregated features, which is more accurate than previous methods and boosts node classification significantly. The proposed algorithm is validated on three public benchmarks in comparison with several state-of-the-art baseline algorithms, and the results illustrate its excellent performance.", "pdf": "/pdf/c14804b5e5e02c92cb071f950c7f1d748585b65b.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhao|fasg_feature_aggregation_selftraining_gcn_for_semisupervised_node_classification", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=g5jvuFmEsw", "_bibtex": "@misc{\nzhao2021fasg,\ntitle={{\\{}FASG{\\}}: Feature Aggregation Self-training {\\{}GCN{\\}} for Semi-supervised Node Classification},\nauthor={Gongpei Zhao and Tao Wang and Yidong Li and Yi Jin},\nyear={2021},\nurl={https://openreview.net/forum?id=SkUfhuFsvK-}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "SkUfhuFsvK-", "replyto": "SkUfhuFsvK-", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper989/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538129850, "tmdate": 1606915808885, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper989/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper989/-/Official_Review"}}}, {"id": "A7zZTNVsMP0", "original": null, "number": 2, "cdate": 1603885232716, "ddate": null, "tcdate": 1603885232716, "tmdate": 1605024557754, "tddate": null, "forum": "SkUfhuFsvK-", "replyto": "SkUfhuFsvK-", "invitation": "ICLR.cc/2021/Conference/Paper989/-/Official_Review", "content": {"title": "Review comments for FASG", "review": "The paper proposes an algorithm combining SVM and GCN to solve the node classification problem in label-less scenarios. The proposed model uses a self-training mechanism to generate labels and features and integrates SVM to improve the confidence level of the labels.\n\nStrong points:\n-It first uses relationship information among nodes for training an SVM. The algorithm based on the SVM-checking mechanism achieves remarkable improvement in prediction accuracy, especially when the label rate is quite small.\n\nWeak points: \n- The description in the SVM classifier experiment section is not clear and detailed enough. How does it deal with different multi-class classification problems?   Perhaps, it should verify whether updating the SVM with pseudo-labels can improve the performance of the model in the case of low labeling rates.\n\n- According to the analysis in the paper, GAT and SVM have similar performance. Why did the authors choose to use SVM as the checking part rather than GAT? Some experiments may be required to show the advantages of using SVM checking.\n\n- The proposed method should be compared with some previous SOTA methods (e.g., Union and Intersection method proposed in \"Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning.\" (2018).)\n\n- The proposed method is not innovative enough, because it just employs a different check algorithm.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper989/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper989/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "FASG: Feature Aggregation Self-training GCN for Semi-supervised Node Classification", "authorids": ["~Gongpei_Zhao1", "~Tao_Wang1", "~Yidong_Li1", "~Yi_Jin2"], "authors": ["Gongpei Zhao", "Tao Wang", "Yidong Li", "Yi Jin"], "keywords": [], "abstract": "Recently, Graph Convolutioal Networks (GCNs) have achieved significant success in many graph-based learning tasks, especially for node classification, due to its excellent ability in representation learning. Nevertheless, it remains challenging for GCN models to obtain satisfying prediction on graphs where few nodes are with known labels. In this paper, we propose a novel self-training algorithm based on GCN to boost semi-supervised node classification on graphs with little supervised information. Inspired by self-supervision strategy, the proposed method introduces an ingenious checking part to add new nodes as supervision after each training epoch to enhance node prediction. In particular, the embedded checking part is designed based on aggregated features, which is more accurate than previous methods and boosts node classification significantly. The proposed algorithm is validated on three public benchmarks in comparison with several state-of-the-art baseline algorithms, and the results illustrate its excellent performance.", "pdf": "/pdf/c14804b5e5e02c92cb071f950c7f1d748585b65b.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhao|fasg_feature_aggregation_selftraining_gcn_for_semisupervised_node_classification", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=g5jvuFmEsw", "_bibtex": "@misc{\nzhao2021fasg,\ntitle={{\\{}FASG{\\}}: Feature Aggregation Self-training {\\{}GCN{\\}} for Semi-supervised Node Classification},\nauthor={Gongpei Zhao and Tao Wang and Yidong Li and Yi Jin},\nyear={2021},\nurl={https://openreview.net/forum?id=SkUfhuFsvK-}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "SkUfhuFsvK-", "replyto": "SkUfhuFsvK-", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper989/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538129850, "tmdate": 1606915808885, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper989/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper989/-/Official_Review"}}}, {"id": "Au0mWE9chC7", "original": null, "number": 3, "cdate": 1603889870962, "ddate": null, "tcdate": 1603889870962, "tmdate": 1605024557693, "tddate": null, "forum": "SkUfhuFsvK-", "replyto": "SkUfhuFsvK-", "invitation": "ICLR.cc/2021/Conference/Paper989/-/Official_Review", "content": {"title": "Well motivated self-training based semi-supervised framework for node classification", "review": "### Summary\nThis paper proposes a self-training based semi-supervised framework for node classification using Graph Neural Networks when the amount of labelled data is very limited. Self-training is performed by incorporating highly confident samples with their corresponding predicted class as the pseudo label. Authors show that incorporation of correct pseudo labels is a crucial step as the performance degrades rapidly with the incorporation of wrong labels. This work ensures high quality of pseudo labels by a \"checking part\" with feature aggregation. Aggregated features with linear SVM performs comparably with GNN methods.\n\n### Strong Points\n 1. Well motivated paper with good performance\n 2. Proposed approach uses self-training based approach with linear SVM which performs well when the amount of labelled data is scarce.\n 3. The framework can be easily incorporated with any GNN based approaches.\n\n### Weak Points\n 1. I am little surprised that the feature aggregation performs comparably to GCN considering the fact that it is essentially the forward pass of GCN. The improvement could be influenced more because of incorporating the extra examples using self-training than feature aggregation.\n 2. Generally easy (very similar to training distribution) examples end up with high confidence scores. Incorporating such nodes might make hard nodes (closer to decision boundary) harder to classify, thoughts on this point is required.\n 3. Choice of \"t\" seemed adhoc, incorporation of how \"t\" impacted the performance of the model would be interesting to see.\n \n### Other comments\n * Section 4.1: It was not clear to me how exactly the \"bad nodes\" were introduced to the model. A little more details would be helpful for readers.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper989/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper989/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "FASG: Feature Aggregation Self-training GCN for Semi-supervised Node Classification", "authorids": ["~Gongpei_Zhao1", "~Tao_Wang1", "~Yidong_Li1", "~Yi_Jin2"], "authors": ["Gongpei Zhao", "Tao Wang", "Yidong Li", "Yi Jin"], "keywords": [], "abstract": "Recently, Graph Convolutioal Networks (GCNs) have achieved significant success in many graph-based learning tasks, especially for node classification, due to its excellent ability in representation learning. Nevertheless, it remains challenging for GCN models to obtain satisfying prediction on graphs where few nodes are with known labels. In this paper, we propose a novel self-training algorithm based on GCN to boost semi-supervised node classification on graphs with little supervised information. Inspired by self-supervision strategy, the proposed method introduces an ingenious checking part to add new nodes as supervision after each training epoch to enhance node prediction. In particular, the embedded checking part is designed based on aggregated features, which is more accurate than previous methods and boosts node classification significantly. The proposed algorithm is validated on three public benchmarks in comparison with several state-of-the-art baseline algorithms, and the results illustrate its excellent performance.", "pdf": "/pdf/c14804b5e5e02c92cb071f950c7f1d748585b65b.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhao|fasg_feature_aggregation_selftraining_gcn_for_semisupervised_node_classification", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=g5jvuFmEsw", "_bibtex": "@misc{\nzhao2021fasg,\ntitle={{\\{}FASG{\\}}: Feature Aggregation Self-training {\\{}GCN{\\}} for Semi-supervised Node Classification},\nauthor={Gongpei Zhao and Tao Wang and Yidong Li and Yi Jin},\nyear={2021},\nurl={https://openreview.net/forum?id=SkUfhuFsvK-}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "SkUfhuFsvK-", "replyto": "SkUfhuFsvK-", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper989/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538129850, "tmdate": 1606915808885, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper989/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper989/-/Official_Review"}}}, {"id": "WSxIgbI7FH", "original": null, "number": 4, "cdate": 1604087561043, "ddate": null, "tcdate": 1604087561043, "tmdate": 1605024557632, "tddate": null, "forum": "SkUfhuFsvK-", "replyto": "SkUfhuFsvK-", "invitation": "ICLR.cc/2021/Conference/Paper989/-/Official_Review", "content": {"title": "limited novelty", "review": "This manuscript proposes FASG, a self-training model with GCN to improve node classification in graph. FASG introduces a checking part to add new nodes as supervision to enhance classification model. Experiments on several datasets show that FASG is better than some baseline methods. \n\nPros\n1. The problem is important. \n2. The presentation is good. \n3. Introduce a new method to generate nodes with pseudo-labels. \n\nCons\n1. The novelty of this work limited. According to my understanding, the contribution lies in the checking part and the checking part just uses GCN and SVM for generating pseudo-labeled nodes. In my opinion, it is a general choice and the novelty is limited. \n\n2. The improvement over baseline methods is not significant. Most improvement percentages are smaller than 1% especially in Cora and PubMed datasets. \n\n3. Experiments should be improved. Baseline methods are relatively weak, there are many work [1,2,3] for graph pre-training or self-training that could be compared and discussed.  \n\n[1] Strategies for Pre-training Graph Neural Networks, ICLR 2020\n\n[2] GCC: Graph Contrastive Coding for Graph Neural Network Pre-Training, KDD 2020\n\n[3] Gpt-gnn: Generative pre-training of graph neural networks, KDD 2020\n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper989/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper989/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "FASG: Feature Aggregation Self-training GCN for Semi-supervised Node Classification", "authorids": ["~Gongpei_Zhao1", "~Tao_Wang1", "~Yidong_Li1", "~Yi_Jin2"], "authors": ["Gongpei Zhao", "Tao Wang", "Yidong Li", "Yi Jin"], "keywords": [], "abstract": "Recently, Graph Convolutioal Networks (GCNs) have achieved significant success in many graph-based learning tasks, especially for node classification, due to its excellent ability in representation learning. Nevertheless, it remains challenging for GCN models to obtain satisfying prediction on graphs where few nodes are with known labels. In this paper, we propose a novel self-training algorithm based on GCN to boost semi-supervised node classification on graphs with little supervised information. Inspired by self-supervision strategy, the proposed method introduces an ingenious checking part to add new nodes as supervision after each training epoch to enhance node prediction. In particular, the embedded checking part is designed based on aggregated features, which is more accurate than previous methods and boosts node classification significantly. The proposed algorithm is validated on three public benchmarks in comparison with several state-of-the-art baseline algorithms, and the results illustrate its excellent performance.", "pdf": "/pdf/c14804b5e5e02c92cb071f950c7f1d748585b65b.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "zhao|fasg_feature_aggregation_selftraining_gcn_for_semisupervised_node_classification", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=g5jvuFmEsw", "_bibtex": "@misc{\nzhao2021fasg,\ntitle={{\\{}FASG{\\}}: Feature Aggregation Self-training {\\{}GCN{\\}} for Semi-supervised Node Classification},\nauthor={Gongpei Zhao and Tao Wang and Yidong Li and Yi Jin},\nyear={2021},\nurl={https://openreview.net/forum?id=SkUfhuFsvK-}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "SkUfhuFsvK-", "replyto": "SkUfhuFsvK-", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper989/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538129850, "tmdate": 1606915808885, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper989/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper989/-/Official_Review"}}}], "count": 6}