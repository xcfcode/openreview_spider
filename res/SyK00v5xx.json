{"notes": [{"tddate": null, "replyto": null, "ddate": null, "writable": true, "revisions": false, "tmdate": 1544202244497, "tcdate": 1478291152993, "number": 448, "replyCount": 1, "id": "SyK00v5xx", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "SyK00v5xx", "signatures": ["~Yingyu_Liang1"], "readers": ["everyone"], "content": {"title": "A Simple but Tough-to-Beat Baseline for Sentence Embeddings", "abstract": "\nThe success of neural network methods for computing word embeddings has motivated methods for generating semantic embeddings of longer pieces of text, such as sentences and paragraphs. Surprisingly, Wieting et al (ICLR'16) showed that such complicated methods are outperformed, especially in out-of-domain (transfer learning) settings, by simpler methods involving mild retraining of word embeddings and basic linear regression. The  method of Wieting et al. requires retraining with a substantial labeled dataset such as Paraphrase Database (Ganitkevitch et al., 2013). \n\nThe current paper goes further, showing that the following completely unsupervised sentence embedding is a formidable baseline: Use word embeddings computed using one of the popular methods on unlabeled corpus like Wikipedia, represent the sentence by a weighted average of the word vectors, and then modify them a bit using PCA/SVD. This weighting improves performance by about 10% to 30% in textual similarity tasks, and beats sophisticated supervised methods including RNN's and LSTM's. It even improves Wieting et al.'s embeddings. \n This simple method should be used as the baseline to beat in future, especially when labeled training data is scarce or nonexistent. \n\nThe paper also gives a theoretical explanation of the success of the above unsupervised method using a latent variable generative model for sentences, which is a simple extension of the model in Arora et al. (TACL'16) with new \"smoothing\" terms that allow for \nwords occurring out of context, as well as high probabilities for words like and, not in all contexts. ", "pdf": "/pdf/3cd3d0e6d510ec56313971e66701feb35abde02d.pdf", "TL;DR": "A simple unsupervised method for sentence embedding that can get results comparable to sophisticated models like RNN's and LSTM's", "conflicts": ["cs.princeton.edu"], "authors": ["Sanjeev Arora", "Yingyu Liang", "Tengyu Ma"], "keywords": ["Natural language processing", "Unsupervised Learning"], "authorids": ["arora@cs.princeton.edu", "yingyul@cs.princeton.edu", "tengyu@cs.princeton.edu"], "paperhash": "arora|a_simple_but_toughtobeat_baseline_for_sentence_embeddings"}, "writers": [], "nonreaders": [], "details": {"replyCount": 19, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396590816, "tcdate": 1486396590816, "number": 1, "id": "SJPn2zI_e", "invitation": "ICLR.cc/2017/conference/-/paper448/acceptance", "forum": "SyK00v5xx", "replyto": "SyK00v5xx", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "A new method for sentence embedding that is simple and performs well. Important contribution that will attract attention and help move the field forward.", "decision": "Accept (Poster)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple but Tough-to-Beat Baseline for Sentence Embeddings", "abstract": "\nThe success of neural network methods for computing word embeddings has motivated methods for generating semantic embeddings of longer pieces of text, such as sentences and paragraphs. Surprisingly, Wieting et al (ICLR'16) showed that such complicated methods are outperformed, especially in out-of-domain (transfer learning) settings, by simpler methods involving mild retraining of word embeddings and basic linear regression. The  method of Wieting et al. requires retraining with a substantial labeled dataset such as Paraphrase Database (Ganitkevitch et al., 2013). \n\nThe current paper goes further, showing that the following completely unsupervised sentence embedding is a formidable baseline: Use word embeddings computed using one of the popular methods on unlabeled corpus like Wikipedia, represent the sentence by a weighted average of the word vectors, and then modify them a bit using PCA/SVD. This weighting improves performance by about 10% to 30% in textual similarity tasks, and beats sophisticated supervised methods including RNN's and LSTM's. It even improves Wieting et al.'s embeddings. \n This simple method should be used as the baseline to beat in future, especially when labeled training data is scarce or nonexistent. \n\nThe paper also gives a theoretical explanation of the success of the above unsupervised method using a latent variable generative model for sentences, which is a simple extension of the model in Arora et al. (TACL'16) with new \"smoothing\" terms that allow for \nwords occurring out of context, as well as high probabilities for words like and, not in all contexts. ", "pdf": "/pdf/3cd3d0e6d510ec56313971e66701feb35abde02d.pdf", "TL;DR": "A simple unsupervised method for sentence embedding that can get results comparable to sophisticated models like RNN's and LSTM's", "conflicts": ["cs.princeton.edu"], "authors": ["Sanjeev Arora", "Yingyu Liang", "Tengyu Ma"], "keywords": ["Natural language processing", "Unsupervised Learning"], "authorids": ["arora@cs.princeton.edu", "yingyul@cs.princeton.edu", "tengyu@cs.princeton.edu"], "paperhash": "arora|a_simple_but_toughtobeat_baseline_for_sentence_embeddings"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396591326, "id": "ICLR.cc/2017/conference/-/paper448/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "SyK00v5xx", "replyto": "SyK00v5xx", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396591326}}}, {"tddate": null, "tmdate": 1484946378756, "tcdate": 1484946378756, "number": 12, "id": "ry7AsxlPx", "invitation": "ICLR.cc/2017/conference/-/paper448/public/comment", "forum": "SyK00v5xx", "replyto": "SyZev7JQe", "signatures": ["~Yingyu_Liang1"], "readers": ["everyone"], "writers": ["~Yingyu_Liang1"], "content": {"title": "evaluation on SNLI", "comment": "Thanks for suggesting the SNLI dataset! We compared to the standard RNN/LSTM-RNN approaches used in the paper publishing the dataset: \"A large annotated corpus for learning natural language inference\" by Bowman, Angeli, Potts, and Manning. Our method indeed shows slightly better performance. \n\nSentence model              Train    Test \n100d Sum of words           79.3     75.3 \n100d RNN                    73.1     72.2 \n100d LSTM RNN               84.8     77.6 \nOur method                  83.9     78.2\n\nOur test accuracy is worse than those using more sophisticated models (e.g., using attention mechanism), which are typically 83% - 88%; see the website of the SNLI project for a summary. An interesting direction is to study whether our idea can be combined with these sophisticated models to get improved performance.\n\nTechnical details: We used the code provided by the authors of the SNLI paper (we thank the authors!). We trained their classifier on our sentence embedding for 120 passes over the data, using their default hyperparameters. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple but Tough-to-Beat Baseline for Sentence Embeddings", "abstract": "\nThe success of neural network methods for computing word embeddings has motivated methods for generating semantic embeddings of longer pieces of text, such as sentences and paragraphs. Surprisingly, Wieting et al (ICLR'16) showed that such complicated methods are outperformed, especially in out-of-domain (transfer learning) settings, by simpler methods involving mild retraining of word embeddings and basic linear regression. The  method of Wieting et al. requires retraining with a substantial labeled dataset such as Paraphrase Database (Ganitkevitch et al., 2013). \n\nThe current paper goes further, showing that the following completely unsupervised sentence embedding is a formidable baseline: Use word embeddings computed using one of the popular methods on unlabeled corpus like Wikipedia, represent the sentence by a weighted average of the word vectors, and then modify them a bit using PCA/SVD. This weighting improves performance by about 10% to 30% in textual similarity tasks, and beats sophisticated supervised methods including RNN's and LSTM's. It even improves Wieting et al.'s embeddings. \n This simple method should be used as the baseline to beat in future, especially when labeled training data is scarce or nonexistent. \n\nThe paper also gives a theoretical explanation of the success of the above unsupervised method using a latent variable generative model for sentences, which is a simple extension of the model in Arora et al. (TACL'16) with new \"smoothing\" terms that allow for \nwords occurring out of context, as well as high probabilities for words like and, not in all contexts. ", "pdf": "/pdf/3cd3d0e6d510ec56313971e66701feb35abde02d.pdf", "TL;DR": "A simple unsupervised method for sentence embedding that can get results comparable to sophisticated models like RNN's and LSTM's", "conflicts": ["cs.princeton.edu"], "authors": ["Sanjeev Arora", "Yingyu Liang", "Tengyu Ma"], "keywords": ["Natural language processing", "Unsupervised Learning"], "authorids": ["arora@cs.princeton.edu", "yingyul@cs.princeton.edu", "tengyu@cs.princeton.edu"], "paperhash": "arora|a_simple_but_toughtobeat_baseline_for_sentence_embeddings"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287571376, "id": "ICLR.cc/2017/conference/-/paper448/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SyK00v5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper448/reviewers", "ICLR.cc/2017/conference/paper448/areachairs"], "cdate": 1485287571376}}}, {"tddate": null, "tmdate": 1483380216504, "tcdate": 1483380216504, "number": 11, "id": "BJxbIM_Be", "invitation": "ICLR.cc/2017/conference/-/paper448/public/comment", "forum": "SyK00v5xx", "replyto": "ByLN-sYEe", "signatures": ["~Yingyu_Liang1"], "readers": ["everyone"], "writers": ["~Yingyu_Liang1"], "content": {"title": "Response", "comment": "Thanks for the positive review!\nWe will fix the typos pointed out and add the comparisons with NB-SVM. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple but Tough-to-Beat Baseline for Sentence Embeddings", "abstract": "\nThe success of neural network methods for computing word embeddings has motivated methods for generating semantic embeddings of longer pieces of text, such as sentences and paragraphs. Surprisingly, Wieting et al (ICLR'16) showed that such complicated methods are outperformed, especially in out-of-domain (transfer learning) settings, by simpler methods involving mild retraining of word embeddings and basic linear regression. The  method of Wieting et al. requires retraining with a substantial labeled dataset such as Paraphrase Database (Ganitkevitch et al., 2013). \n\nThe current paper goes further, showing that the following completely unsupervised sentence embedding is a formidable baseline: Use word embeddings computed using one of the popular methods on unlabeled corpus like Wikipedia, represent the sentence by a weighted average of the word vectors, and then modify them a bit using PCA/SVD. This weighting improves performance by about 10% to 30% in textual similarity tasks, and beats sophisticated supervised methods including RNN's and LSTM's. It even improves Wieting et al.'s embeddings. \n This simple method should be used as the baseline to beat in future, especially when labeled training data is scarce or nonexistent. \n\nThe paper also gives a theoretical explanation of the success of the above unsupervised method using a latent variable generative model for sentences, which is a simple extension of the model in Arora et al. (TACL'16) with new \"smoothing\" terms that allow for \nwords occurring out of context, as well as high probabilities for words like and, not in all contexts. ", "pdf": "/pdf/3cd3d0e6d510ec56313971e66701feb35abde02d.pdf", "TL;DR": "A simple unsupervised method for sentence embedding that can get results comparable to sophisticated models like RNN's and LSTM's", "conflicts": ["cs.princeton.edu"], "authors": ["Sanjeev Arora", "Yingyu Liang", "Tengyu Ma"], "keywords": ["Natural language processing", "Unsupervised Learning"], "authorids": ["arora@cs.princeton.edu", "yingyul@cs.princeton.edu", "tengyu@cs.princeton.edu"], "paperhash": "arora|a_simple_but_toughtobeat_baseline_for_sentence_embeddings"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287571376, "id": "ICLR.cc/2017/conference/-/paper448/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SyK00v5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper448/reviewers", "ICLR.cc/2017/conference/paper448/areachairs"], "cdate": 1485287571376}}}, {"tddate": null, "tmdate": 1483380170842, "tcdate": 1483380170842, "number": 10, "id": "HJmRSMdBl", "invitation": "ICLR.cc/2017/conference/-/paper448/public/comment", "forum": "SyK00v5xx", "replyto": "S1Zxy81Nx", "signatures": ["~Yingyu_Liang1"], "readers": ["everyone"], "writers": ["~Yingyu_Liang1"], "content": {"title": "Response", "comment": "Thanks for the positive review!\nWe agree that our results suggest the benchmarks need to be rethought. \nAt the same time, we did a simple experiment suggesting that word order does play some role in the benchmarks. We trained and tested RNN/LSTM on the supervised tasks where the words in each sentence are randomly shuffled. Performance drops noticeably. Thus our method ---which does ignore word order---must be much better at exploiting the semantics than RNN/LSTM. We will further explore if some ensemble idea can combine the advantages of both approaches. \n\n1) Pearson\u2019s r x 100 on similarity task:\n\n           rnn    lstm(no)   lstm(o.g.)\n\nrandom:    54.50   77.24     79.39  \n\nnormal:    73.13   85.45     83.41\n\n\n2) accuracy on entailment task:\n\n           rnn    lstm(no)   lstm(o.g.)\n\nrandom:    61.7   78.2       81.0 \n\nnormal:    76.4   83.2       82.0\n\n\n3) accuracy on sentiment task:\n\n           rnn    lstm(no)   lstm(o.g.)\n\nrandom:    84.2   82.9       84.1\n\nnormal:    86.5   86.6       89.2\n\nTechnical detail: on the random order datasets, the hyperparameters are enumerated as in the paper, and the best results are reported.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple but Tough-to-Beat Baseline for Sentence Embeddings", "abstract": "\nThe success of neural network methods for computing word embeddings has motivated methods for generating semantic embeddings of longer pieces of text, such as sentences and paragraphs. Surprisingly, Wieting et al (ICLR'16) showed that such complicated methods are outperformed, especially in out-of-domain (transfer learning) settings, by simpler methods involving mild retraining of word embeddings and basic linear regression. The  method of Wieting et al. requires retraining with a substantial labeled dataset such as Paraphrase Database (Ganitkevitch et al., 2013). \n\nThe current paper goes further, showing that the following completely unsupervised sentence embedding is a formidable baseline: Use word embeddings computed using one of the popular methods on unlabeled corpus like Wikipedia, represent the sentence by a weighted average of the word vectors, and then modify them a bit using PCA/SVD. This weighting improves performance by about 10% to 30% in textual similarity tasks, and beats sophisticated supervised methods including RNN's and LSTM's. It even improves Wieting et al.'s embeddings. \n This simple method should be used as the baseline to beat in future, especially when labeled training data is scarce or nonexistent. \n\nThe paper also gives a theoretical explanation of the success of the above unsupervised method using a latent variable generative model for sentences, which is a simple extension of the model in Arora et al. (TACL'16) with new \"smoothing\" terms that allow for \nwords occurring out of context, as well as high probabilities for words like and, not in all contexts. ", "pdf": "/pdf/3cd3d0e6d510ec56313971e66701feb35abde02d.pdf", "TL;DR": "A simple unsupervised method for sentence embedding that can get results comparable to sophisticated models like RNN's and LSTM's", "conflicts": ["cs.princeton.edu"], "authors": ["Sanjeev Arora", "Yingyu Liang", "Tengyu Ma"], "keywords": ["Natural language processing", "Unsupervised Learning"], "authorids": ["arora@cs.princeton.edu", "yingyul@cs.princeton.edu", "tengyu@cs.princeton.edu"], "paperhash": "arora|a_simple_but_toughtobeat_baseline_for_sentence_embeddings"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287571376, "id": "ICLR.cc/2017/conference/-/paper448/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SyK00v5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper448/reviewers", "ICLR.cc/2017/conference/paper448/areachairs"], "cdate": 1485287571376}}}, {"tddate": null, "tmdate": 1483380096029, "tcdate": 1483380096029, "number": 9, "id": "rydFHG_rx", "invitation": "ICLR.cc/2017/conference/-/paper448/public/comment", "forum": "SyK00v5xx", "replyto": "HJAs-fr4x", "signatures": ["~Yingyu_Liang1"], "readers": ["everyone"], "writers": ["~Yingyu_Liang1"], "content": {"title": "Response", "comment": "Thanks for the positive review! \n\n- The \"discourse\" in \"discourse vector c_s\" and the one in \"most frequent discourse\" have the same meaning. \n\n- The top singular vector $c_0$ of the datasets seems to roughly correspond to the syntactic information or common words. \nClosest words (by cosine similarity) to $c_0$ in the SICK dataset are: \"just\" \"when\" \"even\" \"one\" \"up\" \"little\" \"way\" \"there\" \"while\" \"but\".\n\n- Sorry for the clumsy phrasing. We meant to say that we empirically discovered the significant common component $c_0$ in word vectors built by existing methods, which inspired us to propose our theoretical model of this paper.\n\n- We speculate that our method doesn't outperform RNNs and LSTMs for sentiment tasks because (a) the word vectors ---and more generally the distributional hypothesis of meaning ---has known limitations for capturing sentiment due to the \"antonym problem\", (b) also in our weighted average scheme, words like \"not\" that may be important for sentiment analysis are downweighted a lot. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple but Tough-to-Beat Baseline for Sentence Embeddings", "abstract": "\nThe success of neural network methods for computing word embeddings has motivated methods for generating semantic embeddings of longer pieces of text, such as sentences and paragraphs. Surprisingly, Wieting et al (ICLR'16) showed that such complicated methods are outperformed, especially in out-of-domain (transfer learning) settings, by simpler methods involving mild retraining of word embeddings and basic linear regression. The  method of Wieting et al. requires retraining with a substantial labeled dataset such as Paraphrase Database (Ganitkevitch et al., 2013). \n\nThe current paper goes further, showing that the following completely unsupervised sentence embedding is a formidable baseline: Use word embeddings computed using one of the popular methods on unlabeled corpus like Wikipedia, represent the sentence by a weighted average of the word vectors, and then modify them a bit using PCA/SVD. This weighting improves performance by about 10% to 30% in textual similarity tasks, and beats sophisticated supervised methods including RNN's and LSTM's. It even improves Wieting et al.'s embeddings. \n This simple method should be used as the baseline to beat in future, especially when labeled training data is scarce or nonexistent. \n\nThe paper also gives a theoretical explanation of the success of the above unsupervised method using a latent variable generative model for sentences, which is a simple extension of the model in Arora et al. (TACL'16) with new \"smoothing\" terms that allow for \nwords occurring out of context, as well as high probabilities for words like and, not in all contexts. ", "pdf": "/pdf/3cd3d0e6d510ec56313971e66701feb35abde02d.pdf", "TL;DR": "A simple unsupervised method for sentence embedding that can get results comparable to sophisticated models like RNN's and LSTM's", "conflicts": ["cs.princeton.edu"], "authors": ["Sanjeev Arora", "Yingyu Liang", "Tengyu Ma"], "keywords": ["Natural language processing", "Unsupervised Learning"], "authorids": ["arora@cs.princeton.edu", "yingyul@cs.princeton.edu", "tengyu@cs.princeton.edu"], "paperhash": "arora|a_simple_but_toughtobeat_baseline_for_sentence_embeddings"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287571376, "id": "ICLR.cc/2017/conference/-/paper448/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SyK00v5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper448/reviewers", "ICLR.cc/2017/conference/paper448/areachairs"], "cdate": 1485287571376}}}, {"tddate": null, "tmdate": 1482432813902, "tcdate": 1482432813902, "number": 3, "id": "ByLN-sYEe", "invitation": "ICLR.cc/2017/conference/-/paper448/official/review", "forum": "SyK00v5xx", "replyto": "SyK00v5xx", "signatures": ["ICLR.cc/2017/conference/paper448/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper448/AnonReviewer3"], "content": {"title": "Accept", "rating": "7: Good paper, accept", "review": "This is a good paper with an interesting probabilistic motivation for weighted bag of words models.\nThe (hopefully soon) added comparison to Wang and Manning will make it stronger. \nThough it is sad that for sufficiently large datasets, NB-SVM still works better.\n\nIn the second to last paragraph of the introduction you describe a problem of large cooccurrence counts which was already fixed by the Glove embeddings with their weighting function f.\n\nMinor comments:\n\n\"The capturing the similarities\" -- typo in line 2 of intro.\n\"Recently, (Wieting et al.,2016) learned\" -- use citet instead of parenthesized citation\n ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple but Tough-to-Beat Baseline for Sentence Embeddings", "abstract": "\nThe success of neural network methods for computing word embeddings has motivated methods for generating semantic embeddings of longer pieces of text, such as sentences and paragraphs. Surprisingly, Wieting et al (ICLR'16) showed that such complicated methods are outperformed, especially in out-of-domain (transfer learning) settings, by simpler methods involving mild retraining of word embeddings and basic linear regression. The  method of Wieting et al. requires retraining with a substantial labeled dataset such as Paraphrase Database (Ganitkevitch et al., 2013). \n\nThe current paper goes further, showing that the following completely unsupervised sentence embedding is a formidable baseline: Use word embeddings computed using one of the popular methods on unlabeled corpus like Wikipedia, represent the sentence by a weighted average of the word vectors, and then modify them a bit using PCA/SVD. This weighting improves performance by about 10% to 30% in textual similarity tasks, and beats sophisticated supervised methods including RNN's and LSTM's. It even improves Wieting et al.'s embeddings. \n This simple method should be used as the baseline to beat in future, especially when labeled training data is scarce or nonexistent. \n\nThe paper also gives a theoretical explanation of the success of the above unsupervised method using a latent variable generative model for sentences, which is a simple extension of the model in Arora et al. (TACL'16) with new \"smoothing\" terms that allow for \nwords occurring out of context, as well as high probabilities for words like and, not in all contexts. ", "pdf": "/pdf/3cd3d0e6d510ec56313971e66701feb35abde02d.pdf", "TL;DR": "A simple unsupervised method for sentence embedding that can get results comparable to sophisticated models like RNN's and LSTM's", "conflicts": ["cs.princeton.edu"], "authors": ["Sanjeev Arora", "Yingyu Liang", "Tengyu Ma"], "keywords": ["Natural language processing", "Unsupervised Learning"], "authorids": ["arora@cs.princeton.edu", "yingyul@cs.princeton.edu", "tengyu@cs.princeton.edu"], "paperhash": "arora|a_simple_but_toughtobeat_baseline_for_sentence_embeddings"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512582421, "id": "ICLR.cc/2017/conference/-/paper448/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper448/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper448/AnonReviewer2", "ICLR.cc/2017/conference/paper448/AnonReviewer1", "ICLR.cc/2017/conference/paper448/AnonReviewer3"], "reply": {"forum": "SyK00v5xx", "replyto": "SyK00v5xx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper448/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper448/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512582421}}}, {"tddate": null, "tmdate": 1482133925803, "tcdate": 1482133925803, "number": 2, "id": "HJAs-fr4x", "invitation": "ICLR.cc/2017/conference/-/paper448/official/review", "forum": "SyK00v5xx", "replyto": "SyK00v5xx", "signatures": ["ICLR.cc/2017/conference/paper448/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper448/AnonReviewer1"], "content": {"title": "Interesting model and analysis", "rating": "7: Good paper, accept", "review": "This paper proposes a simple way to reweight the word embedding in the simple composition function for sentence representation. This paper also shows the connection between this new weighting scheme and some previous work.\n\nHere are some comments on technical details:\n\n- The word \"discourse\" is confusing. I am not sure whether the words \"discourse\" in \"discourse vector c_s\" and the one in \"most frequent discourse\" have the same meaning.\n- Is there any justification about $c_0$ related to syntac?\n- Not sure what thie line means: \"In fact the new model was discovered by our detecting the common component c0 in existing embeddings.\" in section \"Computing the sentence embedding\"\n- Is there any explanation about the results on sentiment in Table 2?", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple but Tough-to-Beat Baseline for Sentence Embeddings", "abstract": "\nThe success of neural network methods for computing word embeddings has motivated methods for generating semantic embeddings of longer pieces of text, such as sentences and paragraphs. Surprisingly, Wieting et al (ICLR'16) showed that such complicated methods are outperformed, especially in out-of-domain (transfer learning) settings, by simpler methods involving mild retraining of word embeddings and basic linear regression. The  method of Wieting et al. requires retraining with a substantial labeled dataset such as Paraphrase Database (Ganitkevitch et al., 2013). \n\nThe current paper goes further, showing that the following completely unsupervised sentence embedding is a formidable baseline: Use word embeddings computed using one of the popular methods on unlabeled corpus like Wikipedia, represent the sentence by a weighted average of the word vectors, and then modify them a bit using PCA/SVD. This weighting improves performance by about 10% to 30% in textual similarity tasks, and beats sophisticated supervised methods including RNN's and LSTM's. It even improves Wieting et al.'s embeddings. \n This simple method should be used as the baseline to beat in future, especially when labeled training data is scarce or nonexistent. \n\nThe paper also gives a theoretical explanation of the success of the above unsupervised method using a latent variable generative model for sentences, which is a simple extension of the model in Arora et al. (TACL'16) with new \"smoothing\" terms that allow for \nwords occurring out of context, as well as high probabilities for words like and, not in all contexts. ", "pdf": "/pdf/3cd3d0e6d510ec56313971e66701feb35abde02d.pdf", "TL;DR": "A simple unsupervised method for sentence embedding that can get results comparable to sophisticated models like RNN's and LSTM's", "conflicts": ["cs.princeton.edu"], "authors": ["Sanjeev Arora", "Yingyu Liang", "Tengyu Ma"], "keywords": ["Natural language processing", "Unsupervised Learning"], "authorids": ["arora@cs.princeton.edu", "yingyul@cs.princeton.edu", "tengyu@cs.princeton.edu"], "paperhash": "arora|a_simple_but_toughtobeat_baseline_for_sentence_embeddings"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512582421, "id": "ICLR.cc/2017/conference/-/paper448/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper448/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper448/AnonReviewer2", "ICLR.cc/2017/conference/paper448/AnonReviewer1", "ICLR.cc/2017/conference/paper448/AnonReviewer3"], "reply": {"forum": "SyK00v5xx", "replyto": "SyK00v5xx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper448/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper448/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512582421}}}, {"tddate": null, "tmdate": 1481756393499, "tcdate": 1481756393493, "number": 1, "id": "S1Zxy81Nx", "invitation": "ICLR.cc/2017/conference/-/paper448/official/review", "forum": "SyK00v5xx", "replyto": "SyK00v5xx", "signatures": ["ICLR.cc/2017/conference/paper448/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper448/AnonReviewer2"], "content": {"title": "Accept", "rating": "8: Top 50% of accepted papers, clear accept", "review": "This paper presents a new theoretically-principled method of representing sentences as vectors. The experiments show that vectors produced by this method perform well on similarity and entailment benchmarks, surpassing some RNN-based methods too.\n\nOverall, this is an interesting empirical result, especially since the model is not order-sensitive (as far as I can tell). I would like to see some more discussion on why such a simple model does better than LSTMs at capturing similarity and entailment. Could this be an artifact of these benchmarks?", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple but Tough-to-Beat Baseline for Sentence Embeddings", "abstract": "\nThe success of neural network methods for computing word embeddings has motivated methods for generating semantic embeddings of longer pieces of text, such as sentences and paragraphs. Surprisingly, Wieting et al (ICLR'16) showed that such complicated methods are outperformed, especially in out-of-domain (transfer learning) settings, by simpler methods involving mild retraining of word embeddings and basic linear regression. The  method of Wieting et al. requires retraining with a substantial labeled dataset such as Paraphrase Database (Ganitkevitch et al., 2013). \n\nThe current paper goes further, showing that the following completely unsupervised sentence embedding is a formidable baseline: Use word embeddings computed using one of the popular methods on unlabeled corpus like Wikipedia, represent the sentence by a weighted average of the word vectors, and then modify them a bit using PCA/SVD. This weighting improves performance by about 10% to 30% in textual similarity tasks, and beats sophisticated supervised methods including RNN's and LSTM's. It even improves Wieting et al.'s embeddings. \n This simple method should be used as the baseline to beat in future, especially when labeled training data is scarce or nonexistent. \n\nThe paper also gives a theoretical explanation of the success of the above unsupervised method using a latent variable generative model for sentences, which is a simple extension of the model in Arora et al. (TACL'16) with new \"smoothing\" terms that allow for \nwords occurring out of context, as well as high probabilities for words like and, not in all contexts. ", "pdf": "/pdf/3cd3d0e6d510ec56313971e66701feb35abde02d.pdf", "TL;DR": "A simple unsupervised method for sentence embedding that can get results comparable to sophisticated models like RNN's and LSTM's", "conflicts": ["cs.princeton.edu"], "authors": ["Sanjeev Arora", "Yingyu Liang", "Tengyu Ma"], "keywords": ["Natural language processing", "Unsupervised Learning"], "authorids": ["arora@cs.princeton.edu", "yingyul@cs.princeton.edu", "tengyu@cs.princeton.edu"], "paperhash": "arora|a_simple_but_toughtobeat_baseline_for_sentence_embeddings"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512582421, "id": "ICLR.cc/2017/conference/-/paper448/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper448/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper448/AnonReviewer2", "ICLR.cc/2017/conference/paper448/AnonReviewer1", "ICLR.cc/2017/conference/paper448/AnonReviewer3"], "reply": {"forum": "SyK00v5xx", "replyto": "SyK00v5xx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper448/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper448/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512582421}}}, {"tddate": null, "tmdate": 1480975214515, "tcdate": 1480975214508, "number": 8, "id": "H1UdmPXmx", "invitation": "ICLR.cc/2017/conference/-/paper448/public/comment", "forum": "SyK00v5xx", "replyto": "r1stWSRMe", "signatures": ["~Yingyu_Liang1"], "readers": ["everyone"], "writers": ["~Yingyu_Liang1"], "content": {"title": "Experiments on IMDB", "comment": "Thanks for the question! We checked on IMDB dataset, studied by Wang and Manning. Since the intended application is semisupervised or transfer learning, we also compared performance with fewer labeled examples.\n\n# labeled examples    NBSVM        Our method (PP-WR)\n\n50k                                 0.91         0.85\n\n1K                                  0.84         0.82\n\n200                                 0.73         0.77\n\nAnother comment is that sentiment analysis appears to be the best case for BOW methods, whereas it may be the worst case for word embedding methods (See Table 2) due to the well-known antonymy problem ---distributional hypothesis fails for distinguishing \"good\" from \"bad.\""}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple but Tough-to-Beat Baseline for Sentence Embeddings", "abstract": "\nThe success of neural network methods for computing word embeddings has motivated methods for generating semantic embeddings of longer pieces of text, such as sentences and paragraphs. Surprisingly, Wieting et al (ICLR'16) showed that such complicated methods are outperformed, especially in out-of-domain (transfer learning) settings, by simpler methods involving mild retraining of word embeddings and basic linear regression. The  method of Wieting et al. requires retraining with a substantial labeled dataset such as Paraphrase Database (Ganitkevitch et al., 2013). \n\nThe current paper goes further, showing that the following completely unsupervised sentence embedding is a formidable baseline: Use word embeddings computed using one of the popular methods on unlabeled corpus like Wikipedia, represent the sentence by a weighted average of the word vectors, and then modify them a bit using PCA/SVD. This weighting improves performance by about 10% to 30% in textual similarity tasks, and beats sophisticated supervised methods including RNN's and LSTM's. It even improves Wieting et al.'s embeddings. \n This simple method should be used as the baseline to beat in future, especially when labeled training data is scarce or nonexistent. \n\nThe paper also gives a theoretical explanation of the success of the above unsupervised method using a latent variable generative model for sentences, which is a simple extension of the model in Arora et al. (TACL'16) with new \"smoothing\" terms that allow for \nwords occurring out of context, as well as high probabilities for words like and, not in all contexts. ", "pdf": "/pdf/3cd3d0e6d510ec56313971e66701feb35abde02d.pdf", "TL;DR": "A simple unsupervised method for sentence embedding that can get results comparable to sophisticated models like RNN's and LSTM's", "conflicts": ["cs.princeton.edu"], "authors": ["Sanjeev Arora", "Yingyu Liang", "Tengyu Ma"], "keywords": ["Natural language processing", "Unsupervised Learning"], "authorids": ["arora@cs.princeton.edu", "yingyul@cs.princeton.edu", "tengyu@cs.princeton.edu"], "paperhash": "arora|a_simple_but_toughtobeat_baseline_for_sentence_embeddings"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287571376, "id": "ICLR.cc/2017/conference/-/paper448/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SyK00v5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper448/reviewers", "ICLR.cc/2017/conference/paper448/areachairs"], "cdate": 1485287571376}}}, {"tddate": null, "tmdate": 1480719428282, "tcdate": 1480719428277, "number": 7, "id": "BJnB2_JQl", "invitation": "ICLR.cc/2017/conference/-/paper448/public/comment", "forum": "SyK00v5xx", "replyto": "S1yoIIRGl", "signatures": ["~Yingyu_Liang1"], "readers": ["everyone"], "writers": ["~Yingyu_Liang1"], "content": {"title": "details about removing the common components", "comment": "For the textual similarity tasks, since our method is unsupervised, we do not use the training dataset and we compute the principle component on all the test examples.\n\nFor the supervised task, we do not remove the common component, since it can be absorbed into the classifier. Please see Section A.2 in the appendix for the details.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple but Tough-to-Beat Baseline for Sentence Embeddings", "abstract": "\nThe success of neural network methods for computing word embeddings has motivated methods for generating semantic embeddings of longer pieces of text, such as sentences and paragraphs. Surprisingly, Wieting et al (ICLR'16) showed that such complicated methods are outperformed, especially in out-of-domain (transfer learning) settings, by simpler methods involving mild retraining of word embeddings and basic linear regression. The  method of Wieting et al. requires retraining with a substantial labeled dataset such as Paraphrase Database (Ganitkevitch et al., 2013). \n\nThe current paper goes further, showing that the following completely unsupervised sentence embedding is a formidable baseline: Use word embeddings computed using one of the popular methods on unlabeled corpus like Wikipedia, represent the sentence by a weighted average of the word vectors, and then modify them a bit using PCA/SVD. This weighting improves performance by about 10% to 30% in textual similarity tasks, and beats sophisticated supervised methods including RNN's and LSTM's. It even improves Wieting et al.'s embeddings. \n This simple method should be used as the baseline to beat in future, especially when labeled training data is scarce or nonexistent. \n\nThe paper also gives a theoretical explanation of the success of the above unsupervised method using a latent variable generative model for sentences, which is a simple extension of the model in Arora et al. (TACL'16) with new \"smoothing\" terms that allow for \nwords occurring out of context, as well as high probabilities for words like and, not in all contexts. ", "pdf": "/pdf/3cd3d0e6d510ec56313971e66701feb35abde02d.pdf", "TL;DR": "A simple unsupervised method for sentence embedding that can get results comparable to sophisticated models like RNN's and LSTM's", "conflicts": ["cs.princeton.edu"], "authors": ["Sanjeev Arora", "Yingyu Liang", "Tengyu Ma"], "keywords": ["Natural language processing", "Unsupervised Learning"], "authorids": ["arora@cs.princeton.edu", "yingyul@cs.princeton.edu", "tengyu@cs.princeton.edu"], "paperhash": "arora|a_simple_but_toughtobeat_baseline_for_sentence_embeddings"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287571376, "id": "ICLR.cc/2017/conference/-/paper448/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SyK00v5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper448/reviewers", "ICLR.cc/2017/conference/paper448/areachairs"], "cdate": 1485287571376}}}, {"tddate": null, "tmdate": 1480719164369, "tcdate": 1480719164365, "number": 6, "id": "ByVHsOkXg", "invitation": "ICLR.cc/2017/conference/-/paper448/public/comment", "forum": "SyK00v5xx", "replyto": "SyZev7JQe", "signatures": ["~Tengyu_Ma1"], "readers": ["everyone"], "writers": ["~Tengyu_Ma1"], "content": {"title": "evaluation on SNLI", "comment": "Thanks! We will test on it soon. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple but Tough-to-Beat Baseline for Sentence Embeddings", "abstract": "\nThe success of neural network methods for computing word embeddings has motivated methods for generating semantic embeddings of longer pieces of text, such as sentences and paragraphs. Surprisingly, Wieting et al (ICLR'16) showed that such complicated methods are outperformed, especially in out-of-domain (transfer learning) settings, by simpler methods involving mild retraining of word embeddings and basic linear regression. The  method of Wieting et al. requires retraining with a substantial labeled dataset such as Paraphrase Database (Ganitkevitch et al., 2013). \n\nThe current paper goes further, showing that the following completely unsupervised sentence embedding is a formidable baseline: Use word embeddings computed using one of the popular methods on unlabeled corpus like Wikipedia, represent the sentence by a weighted average of the word vectors, and then modify them a bit using PCA/SVD. This weighting improves performance by about 10% to 30% in textual similarity tasks, and beats sophisticated supervised methods including RNN's and LSTM's. It even improves Wieting et al.'s embeddings. \n This simple method should be used as the baseline to beat in future, especially when labeled training data is scarce or nonexistent. \n\nThe paper also gives a theoretical explanation of the success of the above unsupervised method using a latent variable generative model for sentences, which is a simple extension of the model in Arora et al. (TACL'16) with new \"smoothing\" terms that allow for \nwords occurring out of context, as well as high probabilities for words like and, not in all contexts. ", "pdf": "/pdf/3cd3d0e6d510ec56313971e66701feb35abde02d.pdf", "TL;DR": "A simple unsupervised method for sentence embedding that can get results comparable to sophisticated models like RNN's and LSTM's", "conflicts": ["cs.princeton.edu"], "authors": ["Sanjeev Arora", "Yingyu Liang", "Tengyu Ma"], "keywords": ["Natural language processing", "Unsupervised Learning"], "authorids": ["arora@cs.princeton.edu", "yingyul@cs.princeton.edu", "tengyu@cs.princeton.edu"], "paperhash": "arora|a_simple_but_toughtobeat_baseline_for_sentence_embeddings"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287571376, "id": "ICLR.cc/2017/conference/-/paper448/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SyK00v5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper448/reviewers", "ICLR.cc/2017/conference/paper448/areachairs"], "cdate": 1485287571376}}}, {"tddate": null, "tmdate": 1480719110825, "tcdate": 1480719110820, "number": 5, "id": "Sk1GjdyQx", "invitation": "ICLR.cc/2017/conference/-/paper448/public/comment", "forum": "SyK00v5xx", "replyto": "r1stWSRMe", "signatures": ["~Tengyu_Ma1"], "readers": ["everyone"], "writers": ["~Tengyu_Ma1"], "content": {"title": "comparing on other datasets", "comment": "Thanks for the suggestion! We have tested on the Stanford Sentiment Treebank (Table 2), though we didn't find Wang and Manning'12 tested on it. We will try IMDB and potentially other datasets reported in Wang and Manning'12. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple but Tough-to-Beat Baseline for Sentence Embeddings", "abstract": "\nThe success of neural network methods for computing word embeddings has motivated methods for generating semantic embeddings of longer pieces of text, such as sentences and paragraphs. Surprisingly, Wieting et al (ICLR'16) showed that such complicated methods are outperformed, especially in out-of-domain (transfer learning) settings, by simpler methods involving mild retraining of word embeddings and basic linear regression. The  method of Wieting et al. requires retraining with a substantial labeled dataset such as Paraphrase Database (Ganitkevitch et al., 2013). \n\nThe current paper goes further, showing that the following completely unsupervised sentence embedding is a formidable baseline: Use word embeddings computed using one of the popular methods on unlabeled corpus like Wikipedia, represent the sentence by a weighted average of the word vectors, and then modify them a bit using PCA/SVD. This weighting improves performance by about 10% to 30% in textual similarity tasks, and beats sophisticated supervised methods including RNN's and LSTM's. It even improves Wieting et al.'s embeddings. \n This simple method should be used as the baseline to beat in future, especially when labeled training data is scarce or nonexistent. \n\nThe paper also gives a theoretical explanation of the success of the above unsupervised method using a latent variable generative model for sentences, which is a simple extension of the model in Arora et al. (TACL'16) with new \"smoothing\" terms that allow for \nwords occurring out of context, as well as high probabilities for words like and, not in all contexts. ", "pdf": "/pdf/3cd3d0e6d510ec56313971e66701feb35abde02d.pdf", "TL;DR": "A simple unsupervised method for sentence embedding that can get results comparable to sophisticated models like RNN's and LSTM's", "conflicts": ["cs.princeton.edu"], "authors": ["Sanjeev Arora", "Yingyu Liang", "Tengyu Ma"], "keywords": ["Natural language processing", "Unsupervised Learning"], "authorids": ["arora@cs.princeton.edu", "yingyul@cs.princeton.edu", "tengyu@cs.princeton.edu"], "paperhash": "arora|a_simple_but_toughtobeat_baseline_for_sentence_embeddings"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287571376, "id": "ICLR.cc/2017/conference/-/paper448/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SyK00v5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper448/reviewers", "ICLR.cc/2017/conference/paper448/areachairs"], "cdate": 1485287571376}}}, {"tddate": null, "tmdate": 1480697577202, "tcdate": 1480697577197, "number": 3, "id": "SyZev7JQe", "invitation": "ICLR.cc/2017/conference/-/paper448/pre-review/question", "forum": "SyK00v5xx", "replyto": "SyK00v5xx", "signatures": ["ICLR.cc/2017/conference/paper448/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper448/AnonReviewer2"], "content": {"title": "Performance on the SNLI dataset", "question": "Have you considered evaluating on the SNLI dataset as well? This dataset is broader than SICK in certain ways, and might be more challenging. I am curious to see if the summation-based method presented here can do as well as the attention-based systems.\nHaving said that, the evaluation is quite comprehensive as is!"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple but Tough-to-Beat Baseline for Sentence Embeddings", "abstract": "\nThe success of neural network methods for computing word embeddings has motivated methods for generating semantic embeddings of longer pieces of text, such as sentences and paragraphs. Surprisingly, Wieting et al (ICLR'16) showed that such complicated methods are outperformed, especially in out-of-domain (transfer learning) settings, by simpler methods involving mild retraining of word embeddings and basic linear regression. The  method of Wieting et al. requires retraining with a substantial labeled dataset such as Paraphrase Database (Ganitkevitch et al., 2013). \n\nThe current paper goes further, showing that the following completely unsupervised sentence embedding is a formidable baseline: Use word embeddings computed using one of the popular methods on unlabeled corpus like Wikipedia, represent the sentence by a weighted average of the word vectors, and then modify them a bit using PCA/SVD. This weighting improves performance by about 10% to 30% in textual similarity tasks, and beats sophisticated supervised methods including RNN's and LSTM's. It even improves Wieting et al.'s embeddings. \n This simple method should be used as the baseline to beat in future, especially when labeled training data is scarce or nonexistent. \n\nThe paper also gives a theoretical explanation of the success of the above unsupervised method using a latent variable generative model for sentences, which is a simple extension of the model in Arora et al. (TACL'16) with new \"smoothing\" terms that allow for \nwords occurring out of context, as well as high probabilities for words like and, not in all contexts. ", "pdf": "/pdf/3cd3d0e6d510ec56313971e66701feb35abde02d.pdf", "TL;DR": "A simple unsupervised method for sentence embedding that can get results comparable to sophisticated models like RNN's and LSTM's", "conflicts": ["cs.princeton.edu"], "authors": ["Sanjeev Arora", "Yingyu Liang", "Tengyu Ma"], "keywords": ["Natural language processing", "Unsupervised Learning"], "authorids": ["arora@cs.princeton.edu", "yingyul@cs.princeton.edu", "tengyu@cs.princeton.edu"], "paperhash": "arora|a_simple_but_toughtobeat_baseline_for_sentence_embeddings"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959273774, "id": "ICLR.cc/2017/conference/-/paper448/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper448/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper448/AnonReviewer3", "ICLR.cc/2017/conference/paper448/AnonReviewer1", "ICLR.cc/2017/conference/paper448/AnonReviewer2"], "reply": {"forum": "SyK00v5xx", "replyto": "SyK00v5xx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper448/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper448/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959273774}}}, {"tddate": null, "tmdate": 1480644247356, "tcdate": 1480644247351, "number": 2, "id": "S1yoIIRGl", "invitation": "ICLR.cc/2017/conference/-/paper448/pre-review/question", "forum": "SyK00v5xx", "replyto": "SyK00v5xx", "signatures": ["ICLR.cc/2017/conference/paper448/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper448/AnonReviewer1"], "content": {"title": "Experimental setup", "question": "In the experiments, did the sentence set S mentioned in algorithm 1 include both training and test examples? If the test examples were not included, then how to do the projection step in line 6 on the test examples?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple but Tough-to-Beat Baseline for Sentence Embeddings", "abstract": "\nThe success of neural network methods for computing word embeddings has motivated methods for generating semantic embeddings of longer pieces of text, such as sentences and paragraphs. Surprisingly, Wieting et al (ICLR'16) showed that such complicated methods are outperformed, especially in out-of-domain (transfer learning) settings, by simpler methods involving mild retraining of word embeddings and basic linear regression. The  method of Wieting et al. requires retraining with a substantial labeled dataset such as Paraphrase Database (Ganitkevitch et al., 2013). \n\nThe current paper goes further, showing that the following completely unsupervised sentence embedding is a formidable baseline: Use word embeddings computed using one of the popular methods on unlabeled corpus like Wikipedia, represent the sentence by a weighted average of the word vectors, and then modify them a bit using PCA/SVD. This weighting improves performance by about 10% to 30% in textual similarity tasks, and beats sophisticated supervised methods including RNN's and LSTM's. It even improves Wieting et al.'s embeddings. \n This simple method should be used as the baseline to beat in future, especially when labeled training data is scarce or nonexistent. \n\nThe paper also gives a theoretical explanation of the success of the above unsupervised method using a latent variable generative model for sentences, which is a simple extension of the model in Arora et al. (TACL'16) with new \"smoothing\" terms that allow for \nwords occurring out of context, as well as high probabilities for words like and, not in all contexts. ", "pdf": "/pdf/3cd3d0e6d510ec56313971e66701feb35abde02d.pdf", "TL;DR": "A simple unsupervised method for sentence embedding that can get results comparable to sophisticated models like RNN's and LSTM's", "conflicts": ["cs.princeton.edu"], "authors": ["Sanjeev Arora", "Yingyu Liang", "Tengyu Ma"], "keywords": ["Natural language processing", "Unsupervised Learning"], "authorids": ["arora@cs.princeton.edu", "yingyul@cs.princeton.edu", "tengyu@cs.princeton.edu"], "paperhash": "arora|a_simple_but_toughtobeat_baseline_for_sentence_embeddings"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959273774, "id": "ICLR.cc/2017/conference/-/paper448/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper448/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper448/AnonReviewer3", "ICLR.cc/2017/conference/paper448/AnonReviewer1", "ICLR.cc/2017/conference/paper448/AnonReviewer2"], "reply": {"forum": "SyK00v5xx", "replyto": "SyK00v5xx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper448/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper448/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959273774}}}, {"tddate": null, "tmdate": 1480638851545, "tcdate": 1480638851541, "number": 1, "id": "r1stWSRMe", "invitation": "ICLR.cc/2017/conference/-/paper448/pre-review/question", "forum": "SyK00v5xx", "replyto": "SyK00v5xx", "signatures": ["ICLR.cc/2017/conference/paper448/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper448/AnonReviewer3"], "content": {"title": "Comparison", "question": "It'd be great to compare on some of the dataset used in Wang and Manning who use simple Naive Bayes SVM hybrids.\nFor example: IMDB or Stanford Sentiment Treebank.\nHow does your model do on those?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple but Tough-to-Beat Baseline for Sentence Embeddings", "abstract": "\nThe success of neural network methods for computing word embeddings has motivated methods for generating semantic embeddings of longer pieces of text, such as sentences and paragraphs. Surprisingly, Wieting et al (ICLR'16) showed that such complicated methods are outperformed, especially in out-of-domain (transfer learning) settings, by simpler methods involving mild retraining of word embeddings and basic linear regression. The  method of Wieting et al. requires retraining with a substantial labeled dataset such as Paraphrase Database (Ganitkevitch et al., 2013). \n\nThe current paper goes further, showing that the following completely unsupervised sentence embedding is a formidable baseline: Use word embeddings computed using one of the popular methods on unlabeled corpus like Wikipedia, represent the sentence by a weighted average of the word vectors, and then modify them a bit using PCA/SVD. This weighting improves performance by about 10% to 30% in textual similarity tasks, and beats sophisticated supervised methods including RNN's and LSTM's. It even improves Wieting et al.'s embeddings. \n This simple method should be used as the baseline to beat in future, especially when labeled training data is scarce or nonexistent. \n\nThe paper also gives a theoretical explanation of the success of the above unsupervised method using a latent variable generative model for sentences, which is a simple extension of the model in Arora et al. (TACL'16) with new \"smoothing\" terms that allow for \nwords occurring out of context, as well as high probabilities for words like and, not in all contexts. ", "pdf": "/pdf/3cd3d0e6d510ec56313971e66701feb35abde02d.pdf", "TL;DR": "A simple unsupervised method for sentence embedding that can get results comparable to sophisticated models like RNN's and LSTM's", "conflicts": ["cs.princeton.edu"], "authors": ["Sanjeev Arora", "Yingyu Liang", "Tengyu Ma"], "keywords": ["Natural language processing", "Unsupervised Learning"], "authorids": ["arora@cs.princeton.edu", "yingyul@cs.princeton.edu", "tengyu@cs.princeton.edu"], "paperhash": "arora|a_simple_but_toughtobeat_baseline_for_sentence_embeddings"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959273774, "id": "ICLR.cc/2017/conference/-/paper448/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper448/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper448/AnonReviewer3", "ICLR.cc/2017/conference/paper448/AnonReviewer1", "ICLR.cc/2017/conference/paper448/AnonReviewer2"], "reply": {"forum": "SyK00v5xx", "replyto": "SyK00v5xx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper448/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper448/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959273774}}}, {"tddate": null, "tmdate": 1479435271896, "tcdate": 1479435271891, "number": 4, "id": "ByxMN1hbg", "invitation": "ICLR.cc/2017/conference/-/paper448/public/comment", "forum": "SyK00v5xx", "replyto": "Hk3-uc5We", "signatures": ["~Yingyu_Liang1"], "readers": ["everyone"], "writers": ["~Yingyu_Liang1"], "content": {"title": "Removing function word leads to similar performance as unweighted average  ", "comment": "Thanks for your interest!\n\nI experimented the idea of removing function words. It gets similar performance as unweighted average on STS tasks.\n                                 avg-GloVe   remove-function-word\n                 STS-2012-average     52.5            52.7 \n                 STS-2013-average     42.3            38.7\n                 STS-2014-average     54.2            53.6 \n                 STS-2015-average     52.7            54.0\n\nOne possible reason is that the content words have various frequencies, and our weighting does more than removing the function words. \n\nDetails: use NLTK software package to find noun, verb, adjective and adverb; use only these types of words in a sentence, compute the average of their word vectors as the sentence embedding.  "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple but Tough-to-Beat Baseline for Sentence Embeddings", "abstract": "\nThe success of neural network methods for computing word embeddings has motivated methods for generating semantic embeddings of longer pieces of text, such as sentences and paragraphs. Surprisingly, Wieting et al (ICLR'16) showed that such complicated methods are outperformed, especially in out-of-domain (transfer learning) settings, by simpler methods involving mild retraining of word embeddings and basic linear regression. The  method of Wieting et al. requires retraining with a substantial labeled dataset such as Paraphrase Database (Ganitkevitch et al., 2013). \n\nThe current paper goes further, showing that the following completely unsupervised sentence embedding is a formidable baseline: Use word embeddings computed using one of the popular methods on unlabeled corpus like Wikipedia, represent the sentence by a weighted average of the word vectors, and then modify them a bit using PCA/SVD. This weighting improves performance by about 10% to 30% in textual similarity tasks, and beats sophisticated supervised methods including RNN's and LSTM's. It even improves Wieting et al.'s embeddings. \n This simple method should be used as the baseline to beat in future, especially when labeled training data is scarce or nonexistent. \n\nThe paper also gives a theoretical explanation of the success of the above unsupervised method using a latent variable generative model for sentences, which is a simple extension of the model in Arora et al. (TACL'16) with new \"smoothing\" terms that allow for \nwords occurring out of context, as well as high probabilities for words like and, not in all contexts. ", "pdf": "/pdf/3cd3d0e6d510ec56313971e66701feb35abde02d.pdf", "TL;DR": "A simple unsupervised method for sentence embedding that can get results comparable to sophisticated models like RNN's and LSTM's", "conflicts": ["cs.princeton.edu"], "authors": ["Sanjeev Arora", "Yingyu Liang", "Tengyu Ma"], "keywords": ["Natural language processing", "Unsupervised Learning"], "authorids": ["arora@cs.princeton.edu", "yingyul@cs.princeton.edu", "tengyu@cs.princeton.edu"], "paperhash": "arora|a_simple_but_toughtobeat_baseline_for_sentence_embeddings"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287571376, "id": "ICLR.cc/2017/conference/-/paper448/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SyK00v5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper448/reviewers", "ICLR.cc/2017/conference/paper448/areachairs"], "cdate": 1485287571376}}}, {"tddate": null, "tmdate": 1479350276504, "tcdate": 1479350276499, "number": 3, "id": "Hk3-uc5We", "invitation": "ICLR.cc/2017/conference/-/paper448/public/comment", "forum": "SyK00v5xx", "replyto": "SyK00v5xx", "signatures": ["~Jiaqi_Mu1"], "readers": ["everyone"], "writers": ["~Jiaqi_Mu1"], "content": {"title": "a simpler baseline?", "comment": "We (J. Mu and P. Viswanath) thoroughly enjoyed the authors' previous work on linear algebraic structure of word senses (cf. https://arxiv.org/abs/1601.03764) and read this paper with great interest. \n\nVery interesting stuff here --  a weighted sum of individual word vectors does a pretty strong job of representing the sentence.  \n\nThe weightings are done based on the (unigram) frequency of the word -- with the choice of a (=10^-3) and $p(w)$ (=unigram distribution over the entire corpus), the weight ($\\frac{a}{a+p(w)}$) will approximately be 1 for content words since $p(w) \\ll a$ and will be approximately 0 for function words since $p(w) \\gg a$. Based on this rough calculation, it seems that the effect of the weighting is to simply  get rid of all function words. \n\nQuestion: how does this baseline, i.e., representing a sentence by the average embedding over all non-functional words, perform?  We are curious to see if this even simpler algorithm can be comparable to the weighted method presented here. \n\nA few typos:\n1. line 2 in introduction: they capturing -> they capture\n2. line 4 in introduction: recent work ... that capture -> that captures\n3. line 4 in page 6: can also be shared [by] the same form\n4. line 4 in page 6: we derive form -> we derive from\n5. line 5 in the second paragraph of page 7: it achieves better performance... and [is] comparable to \n6. line 2 in the third paragraph of page 7: the semi-supervised method ... and are comparable -> is comparable\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple but Tough-to-Beat Baseline for Sentence Embeddings", "abstract": "\nThe success of neural network methods for computing word embeddings has motivated methods for generating semantic embeddings of longer pieces of text, such as sentences and paragraphs. Surprisingly, Wieting et al (ICLR'16) showed that such complicated methods are outperformed, especially in out-of-domain (transfer learning) settings, by simpler methods involving mild retraining of word embeddings and basic linear regression. The  method of Wieting et al. requires retraining with a substantial labeled dataset such as Paraphrase Database (Ganitkevitch et al., 2013). \n\nThe current paper goes further, showing that the following completely unsupervised sentence embedding is a formidable baseline: Use word embeddings computed using one of the popular methods on unlabeled corpus like Wikipedia, represent the sentence by a weighted average of the word vectors, and then modify them a bit using PCA/SVD. This weighting improves performance by about 10% to 30% in textual similarity tasks, and beats sophisticated supervised methods including RNN's and LSTM's. It even improves Wieting et al.'s embeddings. \n This simple method should be used as the baseline to beat in future, especially when labeled training data is scarce or nonexistent. \n\nThe paper also gives a theoretical explanation of the success of the above unsupervised method using a latent variable generative model for sentences, which is a simple extension of the model in Arora et al. (TACL'16) with new \"smoothing\" terms that allow for \nwords occurring out of context, as well as high probabilities for words like and, not in all contexts. ", "pdf": "/pdf/3cd3d0e6d510ec56313971e66701feb35abde02d.pdf", "TL;DR": "A simple unsupervised method for sentence embedding that can get results comparable to sophisticated models like RNN's and LSTM's", "conflicts": ["cs.princeton.edu"], "authors": ["Sanjeev Arora", "Yingyu Liang", "Tengyu Ma"], "keywords": ["Natural language processing", "Unsupervised Learning"], "authorids": ["arora@cs.princeton.edu", "yingyul@cs.princeton.edu", "tengyu@cs.princeton.edu"], "paperhash": "arora|a_simple_but_toughtobeat_baseline_for_sentence_embeddings"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287571376, "id": "ICLR.cc/2017/conference/-/paper448/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SyK00v5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper448/reviewers", "ICLR.cc/2017/conference/paper448/areachairs"], "cdate": 1485287571376}}}, {"tddate": null, "tmdate": 1478719842514, "tcdate": 1478719842507, "number": 2, "id": "SJ5wYeWZl", "invitation": "ICLR.cc/2017/conference/-/paper448/public/comment", "forum": "SyK00v5xx", "replyto": "H1FlxvCxg", "signatures": ["~Yingyu_Liang1"], "readers": ["everyone"], "writers": ["~Yingyu_Liang1"], "content": {"title": "The paper is updated. ", "comment": "Thanks for pointing out the font issue!"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple but Tough-to-Beat Baseline for Sentence Embeddings", "abstract": "\nThe success of neural network methods for computing word embeddings has motivated methods for generating semantic embeddings of longer pieces of text, such as sentences and paragraphs. Surprisingly, Wieting et al (ICLR'16) showed that such complicated methods are outperformed, especially in out-of-domain (transfer learning) settings, by simpler methods involving mild retraining of word embeddings and basic linear regression. The  method of Wieting et al. requires retraining with a substantial labeled dataset such as Paraphrase Database (Ganitkevitch et al., 2013). \n\nThe current paper goes further, showing that the following completely unsupervised sentence embedding is a formidable baseline: Use word embeddings computed using one of the popular methods on unlabeled corpus like Wikipedia, represent the sentence by a weighted average of the word vectors, and then modify them a bit using PCA/SVD. This weighting improves performance by about 10% to 30% in textual similarity tasks, and beats sophisticated supervised methods including RNN's and LSTM's. It even improves Wieting et al.'s embeddings. \n This simple method should be used as the baseline to beat in future, especially when labeled training data is scarce or nonexistent. \n\nThe paper also gives a theoretical explanation of the success of the above unsupervised method using a latent variable generative model for sentences, which is a simple extension of the model in Arora et al. (TACL'16) with new \"smoothing\" terms that allow for \nwords occurring out of context, as well as high probabilities for words like and, not in all contexts. ", "pdf": "/pdf/3cd3d0e6d510ec56313971e66701feb35abde02d.pdf", "TL;DR": "A simple unsupervised method for sentence embedding that can get results comparable to sophisticated models like RNN's and LSTM's", "conflicts": ["cs.princeton.edu"], "authors": ["Sanjeev Arora", "Yingyu Liang", "Tengyu Ma"], "keywords": ["Natural language processing", "Unsupervised Learning"], "authorids": ["arora@cs.princeton.edu", "yingyul@cs.princeton.edu", "tengyu@cs.princeton.edu"], "paperhash": "arora|a_simple_but_toughtobeat_baseline_for_sentence_embeddings"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287571376, "id": "ICLR.cc/2017/conference/-/paper448/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SyK00v5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper448/reviewers", "ICLR.cc/2017/conference/paper448/areachairs"], "cdate": 1485287571376}}}, {"tddate": null, "tmdate": 1478554255226, "tcdate": 1478549488983, "number": 1, "id": "H1FlxvCxg", "invitation": "ICLR.cc/2017/conference/-/paper448/public/comment", "forum": "SyK00v5xx", "replyto": "SyK00v5xx", "signatures": ["~Tara_N_Sainath1"], "readers": ["everyone"], "writers": ["~Tara_N_Sainath1"], "content": {"title": "ICLR Paper Format", "comment": "Dear Authors,\n\nPlease resubmit your paper in the ICLR 2017 format with the correct font for your submission to be considered. Thank you!"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Simple but Tough-to-Beat Baseline for Sentence Embeddings", "abstract": "\nThe success of neural network methods for computing word embeddings has motivated methods for generating semantic embeddings of longer pieces of text, such as sentences and paragraphs. Surprisingly, Wieting et al (ICLR'16) showed that such complicated methods are outperformed, especially in out-of-domain (transfer learning) settings, by simpler methods involving mild retraining of word embeddings and basic linear regression. The  method of Wieting et al. requires retraining with a substantial labeled dataset such as Paraphrase Database (Ganitkevitch et al., 2013). \n\nThe current paper goes further, showing that the following completely unsupervised sentence embedding is a formidable baseline: Use word embeddings computed using one of the popular methods on unlabeled corpus like Wikipedia, represent the sentence by a weighted average of the word vectors, and then modify them a bit using PCA/SVD. This weighting improves performance by about 10% to 30% in textual similarity tasks, and beats sophisticated supervised methods including RNN's and LSTM's. It even improves Wieting et al.'s embeddings. \n This simple method should be used as the baseline to beat in future, especially when labeled training data is scarce or nonexistent. \n\nThe paper also gives a theoretical explanation of the success of the above unsupervised method using a latent variable generative model for sentences, which is a simple extension of the model in Arora et al. (TACL'16) with new \"smoothing\" terms that allow for \nwords occurring out of context, as well as high probabilities for words like and, not in all contexts. ", "pdf": "/pdf/3cd3d0e6d510ec56313971e66701feb35abde02d.pdf", "TL;DR": "A simple unsupervised method for sentence embedding that can get results comparable to sophisticated models like RNN's and LSTM's", "conflicts": ["cs.princeton.edu"], "authors": ["Sanjeev Arora", "Yingyu Liang", "Tengyu Ma"], "keywords": ["Natural language processing", "Unsupervised Learning"], "authorids": ["arora@cs.princeton.edu", "yingyul@cs.princeton.edu", "tengyu@cs.princeton.edu"], "paperhash": "arora|a_simple_but_toughtobeat_baseline_for_sentence_embeddings"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287571376, "id": "ICLR.cc/2017/conference/-/paper448/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "SyK00v5xx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper448/reviewers", "ICLR.cc/2017/conference/paper448/areachairs"], "cdate": 1485287571376}}}], "count": 20}