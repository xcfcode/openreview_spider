{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124475102, "tcdate": 1518426024148, "number": 102, "cdate": 1518426024148, "id": "Byehv0A8M", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "Byehv0A8M", "signatures": ["~Sandesh_Kamath1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Understanding Adversarial Robustness of Symmetric Networks", "abstract": "Neural network-based models for vision are known to be vulnerable to various\nadversarial attacks. Some adversarial perturbations are model-dependent, and ex-\nploit the loss function gradients of the models to make very small, pixel-wise\nchanges. Other adversarial perturbations are model-agnostic, and include spatial\ntransformations such as rotations, translations, scaling etc. Convolutional Neural\nNetworks (CNNs) are translation equivariant by construction but recent work by\nEngstrom et al. (2017) has shown that they too are vulnerable to natural adversar-\nial attacks based on rotation and translation.\nIn this paper, we consider Group-equivariant Convolutional Neural Networks\n(GCNNs) proposed by Cohen & Welling (2016) that are rotation equivariant by\nconstruction, and study their robustness to adversarial attacks based on rotations\nas well as pixel-wise perturbations. We observe that GCNNs are robust to small\ndegrees of rotations away from the ones present in the training data. We also\nobserve that applying data augmentation increases their robustness.", "paperhash": "kamath|understanding_adversarial_robustness_of_symmetric_networks", "_bibtex": "@misc{\n  kamath2018understanding,\n  title={Understanding Adversarial Robustness of Symmetric Networks},\n  author={Sandesh Kamath and Amit Deshpande},\n  year={2018},\n  url={https://openreview.net/forum?id=Byehv0A8M}\n}", "authorids": ["ksandeshk@cmi.ac.in", "amitdesh@microsoft.com"], "authors": ["Sandesh Kamath", "Amit Deshpande"], "keywords": [], "pdf": "/pdf/35a73e207468906d7852c90e374330c71f138023.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582956600, "tcdate": 1520161968303, "number": 1, "cdate": 1520161968303, "id": "HyOn48tOG", "invitation": "ICLR.cc/2018/Workshop/-/Paper102/Official_Review", "forum": "Byehv0A8M", "replyto": "Byehv0A8M", "signatures": ["ICLR.cc/2018/Workshop/Paper102/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper102/AnonReviewer3"], "content": {"title": "Understanding Adversarial Robustness of Symmetric Networks", "rating": "5: Marginally below acceptance threshold", "review": "The robustness of GCNNs to adversarial samples based on pixel-wise perturbations as well as rotation-based adversarial samples is investigated. Several experiments are presented that seem to corroborate the finding that GCNNs are significantly more data-efficient, and possibly more robust to adversarial samples.\n\nIt is interesting to study the robustness of various models, including equivariant ones, to geometric and l_p-bounded / pixelwise adversarial attacks. However, the current paper is insufficiently clear about what experiments were performed exactly, and the CNN and GCNN model may not be comparable (see below).\n\nTable 1 shows that the GCNN is obtained from the CNN by replacing Conv with P4ConvP4. As stated by Cohen & Welling in their paper \u201cGroup Equivariant Convolutional Networks\u201d, this will increase the number of parameters, unless the number of channels is reduced. To keep the number of parameters the same, the GCNN should have 2x fewer \u201cp4 group channels\u201d than the CNN has planar channels. A GCNN with 2x fewer \u201cp4 group channels\u201d has 2x *more* planar channels, (because 4 rotations are applied to each filter), while retaining the same number of parameters.\n\nGiven that the number of parameters is different, it is hard to interpret most of the results in this paper. I would suggest re-running everything with comparable models. It is probably a good idea to increase the model size (e.g. width) of both models a bit, because the current models are quite small. Another architectural question to consider is whether the GCNN should be made rotation-invariant (by pooling over rotations), or not (by using an FC layer at the end). This will have implications for the interpretation of the results.\n\nSeveral things are not clear from the paper:\n- The main findings in the first paragraph of section 2 refers to \u201crobustness\u201d but does not say whether these models are robust to adversarial or random rotations.\n- \u201cFor Figure (1)(left), we train the networks normally and use test time augmentation.\u201d The phrase \u201ctest time augmentation\u201d is not clear, as it could refer to either\n  1) Testing on randomly rotated test data\n  2) Feeding n rotated copies of an input to the model, and averaging predictions (at test time).\nMy understanding is that option 1) is what was done.\n- For figure 1 (right), it is not clear what kind of adversarial training is performed. Did you use rotation-based adversarial samples, or pixel-wise adversarial samples? The introduction mentions both: \u201cGCNNs provide good representative networks to understand the effect of l_p-bounded and spatial transformation adversaries on symmetry networks.\u201d. From the rest of the paper I would guess that only l_p-bounded (i.e. pixel-wise) adversarial training was used in the experiments. \n- \u201cIn the adversarial test case, our observation strengthens GCNNs case that it\u2019s still robust to FGSM attacks to small rotations\". I don\u2019t understand this statement. GCNNs were not designed to withstand pixel-wise adversarial attacks, so how is their case strengthened? (The robustness to random rotation does strengthen the case for GCNNs, of course)\n- In figure 2 (middle), how are the \u201cCNN\u201d and \u201cGCNN\u201d models trained and tested? The middle plot is labelled \u201cwithout FGSM training and test FGSM perturbed\u201d, so one would think that all 4 lines correspond to test-time FGSM-perturbed results. But then it\u2019s not clear what the difference is between StdCNN and StdCNNAdv or GCNN and GCNNAdv. I guess CNN and GCNN are not adversarially perturbed at all?\n- Is it really fair to interpret the GCNNAdv vs CNNAdv results in fig 2 (middle) as showing that GCNNs are more robust to adversarial samples? I\u2019m not sure this is what the paper claims, but the difference does not seem to be very large, and given that this is only one MNIST experiment with one architecture, with no error bars, I don\u2019t think it provides sufficient evidence for this claim.\n\nSuggestion: for plot 1 (right), I would use a logarithmic spacing of sample sizes. E.g. train on 10, 100, 1000, 55000 (max), and space each 10x by one unit on the x-axis. This should make it easier to read off approximately how much more data the CNN needs than the GCNN. E.g. GCNN might need 10x less data to reach the same performance. Right now a large part of the graph is used for the range where all models achieve near-maximal performance.\n\nAlthough this review mainly focussed on the weak points in this paper, I think the paper does have potential. If the missing details are provided and the comparability of CNN/GCNN is ensured, I would be willing to recommend acceptance of this paper.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding Adversarial Robustness of Symmetric Networks", "abstract": "Neural network-based models for vision are known to be vulnerable to various\nadversarial attacks. Some adversarial perturbations are model-dependent, and ex-\nploit the loss function gradients of the models to make very small, pixel-wise\nchanges. Other adversarial perturbations are model-agnostic, and include spatial\ntransformations such as rotations, translations, scaling etc. Convolutional Neural\nNetworks (CNNs) are translation equivariant by construction but recent work by\nEngstrom et al. (2017) has shown that they too are vulnerable to natural adversar-\nial attacks based on rotation and translation.\nIn this paper, we consider Group-equivariant Convolutional Neural Networks\n(GCNNs) proposed by Cohen & Welling (2016) that are rotation equivariant by\nconstruction, and study their robustness to adversarial attacks based on rotations\nas well as pixel-wise perturbations. We observe that GCNNs are robust to small\ndegrees of rotations away from the ones present in the training data. We also\nobserve that applying data augmentation increases their robustness.", "paperhash": "kamath|understanding_adversarial_robustness_of_symmetric_networks", "_bibtex": "@misc{\n  kamath2018understanding,\n  title={Understanding Adversarial Robustness of Symmetric Networks},\n  author={Sandesh Kamath and Amit Deshpande},\n  year={2018},\n  url={https://openreview.net/forum?id=Byehv0A8M}\n}", "authorids": ["ksandeshk@cmi.ac.in", "amitdesh@microsoft.com"], "authors": ["Sandesh Kamath", "Amit Deshpande"], "keywords": [], "pdf": "/pdf/35a73e207468906d7852c90e374330c71f138023.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582956361, "id": "ICLR.cc/2018/Workshop/-/Paper102/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper102/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper102/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper102/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper102/AnonReviewer1"], "reply": {"forum": "Byehv0A8M", "replyto": "Byehv0A8M", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper102/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper102/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582956361}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582775470, "tcdate": 1520635710861, "number": 2, "cdate": 1520635710861, "id": "HJPSyqxYM", "invitation": "ICLR.cc/2018/Workshop/-/Paper102/Official_Review", "forum": "Byehv0A8M", "replyto": "Byehv0A8M", "signatures": ["ICLR.cc/2018/Workshop/Paper102/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper102/AnonReviewer2"], "content": {"title": "Official review", "rating": "4: Ok but not good enough - rejection", "review": "The paper compares the robustness of ordinary CNNs and Group CNNs (GCNNs) to image rotation and adversarial perturbations. The authors find that (quote from the paper) \u201c(a) GCNNs are robust to small degrees of rotations away from the ones present in the training data, (b) applying data augmentation increases their robustness, (c) GCNNs achieve state of the art results with smaller sample size.\u201d\n\nPros:\n- Analysis of CNNs and their more advanced variants is an important direction of research\n- I am not aware of other papers performing experiments similar to those made by the authors\n\nCons:\n- The paper does not make any technical contribution, but concentrates on analysis. This is not a problem by itself, but the analysis then has to be extremely interesting, insightful or surprising.\n- However, the claimed contributions seem very expected: advanced network design improves the invariance to rotations and the sample complexity (this is exactly what it was designed for), and it is not a surprise that data augmentation improves the robustness. \n- The authors make use of adversarial training, but to my knowledge this technique only allows fighting a specific type of adversarial perturbations used during training. This limits the practical applicability of the method. Thus the relevance of the proposed analysis, based on adversarial training, is questionable.\n\nTo conclude, the paper addresses a generally interesting problem, but does not seem to make a very significant contribution. Therefore I tend to recommend rejection.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding Adversarial Robustness of Symmetric Networks", "abstract": "Neural network-based models for vision are known to be vulnerable to various\nadversarial attacks. Some adversarial perturbations are model-dependent, and ex-\nploit the loss function gradients of the models to make very small, pixel-wise\nchanges. Other adversarial perturbations are model-agnostic, and include spatial\ntransformations such as rotations, translations, scaling etc. Convolutional Neural\nNetworks (CNNs) are translation equivariant by construction but recent work by\nEngstrom et al. (2017) has shown that they too are vulnerable to natural adversar-\nial attacks based on rotation and translation.\nIn this paper, we consider Group-equivariant Convolutional Neural Networks\n(GCNNs) proposed by Cohen & Welling (2016) that are rotation equivariant by\nconstruction, and study their robustness to adversarial attacks based on rotations\nas well as pixel-wise perturbations. We observe that GCNNs are robust to small\ndegrees of rotations away from the ones present in the training data. We also\nobserve that applying data augmentation increases their robustness.", "paperhash": "kamath|understanding_adversarial_robustness_of_symmetric_networks", "_bibtex": "@misc{\n  kamath2018understanding,\n  title={Understanding Adversarial Robustness of Symmetric Networks},\n  author={Sandesh Kamath and Amit Deshpande},\n  year={2018},\n  url={https://openreview.net/forum?id=Byehv0A8M}\n}", "authorids": ["ksandeshk@cmi.ac.in", "amitdesh@microsoft.com"], "authors": ["Sandesh Kamath", "Amit Deshpande"], "keywords": [], "pdf": "/pdf/35a73e207468906d7852c90e374330c71f138023.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582956361, "id": "ICLR.cc/2018/Workshop/-/Paper102/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper102/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper102/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper102/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper102/AnonReviewer1"], "reply": {"forum": "Byehv0A8M", "replyto": "Byehv0A8M", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper102/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper102/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582956361}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582660415, "tcdate": 1520767441727, "number": 3, "cdate": 1520767441727, "id": "SkcCbczYf", "invitation": "ICLR.cc/2018/Workshop/-/Paper102/Official_Review", "forum": "Byehv0A8M", "replyto": "Byehv0A8M", "signatures": ["ICLR.cc/2018/Workshop/Paper102/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper102/AnonReviewer1"], "content": {"title": "Random rotations are not adversarial", "rating": "4: Ok but not good enough - rejection", "review": "The paper shows that GCNNs are resistant to small rotations away from those in the training data and that applying data augmentation increases their robustness to these rotations.\n\nThe paper describes these rotations as adversarial even though they are standard image transformations. The adversarial rotations don't target any specific class. In this sense, I could call adding random noise or darkening an image to be 'adversarial'. The results given are also unsurprising, in particular that the GCNN has better accuracy than a standard CNN when the test data is rotated. The fact that performing data augmentation improves this is also unsurprising.\n\nWhat might be more interesting is to explain why GCNN performance still drops so much with rotations but this is not attempted.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding Adversarial Robustness of Symmetric Networks", "abstract": "Neural network-based models for vision are known to be vulnerable to various\nadversarial attacks. Some adversarial perturbations are model-dependent, and ex-\nploit the loss function gradients of the models to make very small, pixel-wise\nchanges. Other adversarial perturbations are model-agnostic, and include spatial\ntransformations such as rotations, translations, scaling etc. Convolutional Neural\nNetworks (CNNs) are translation equivariant by construction but recent work by\nEngstrom et al. (2017) has shown that they too are vulnerable to natural adversar-\nial attacks based on rotation and translation.\nIn this paper, we consider Group-equivariant Convolutional Neural Networks\n(GCNNs) proposed by Cohen & Welling (2016) that are rotation equivariant by\nconstruction, and study their robustness to adversarial attacks based on rotations\nas well as pixel-wise perturbations. We observe that GCNNs are robust to small\ndegrees of rotations away from the ones present in the training data. We also\nobserve that applying data augmentation increases their robustness.", "paperhash": "kamath|understanding_adversarial_robustness_of_symmetric_networks", "_bibtex": "@misc{\n  kamath2018understanding,\n  title={Understanding Adversarial Robustness of Symmetric Networks},\n  author={Sandesh Kamath and Amit Deshpande},\n  year={2018},\n  url={https://openreview.net/forum?id=Byehv0A8M}\n}", "authorids": ["ksandeshk@cmi.ac.in", "amitdesh@microsoft.com"], "authors": ["Sandesh Kamath", "Amit Deshpande"], "keywords": [], "pdf": "/pdf/35a73e207468906d7852c90e374330c71f138023.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582956361, "id": "ICLR.cc/2018/Workshop/-/Paper102/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper102/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper102/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper102/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper102/AnonReviewer1"], "reply": {"forum": "Byehv0A8M", "replyto": "Byehv0A8M", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper102/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper102/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582956361}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573597888, "tcdate": 1521573597888, "number": 235, "cdate": 1521573597536, "id": "rJUy1k1cz", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "Byehv0A8M", "replyto": "Byehv0A8M", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Understanding Adversarial Robustness of Symmetric Networks", "abstract": "Neural network-based models for vision are known to be vulnerable to various\nadversarial attacks. Some adversarial perturbations are model-dependent, and ex-\nploit the loss function gradients of the models to make very small, pixel-wise\nchanges. Other adversarial perturbations are model-agnostic, and include spatial\ntransformations such as rotations, translations, scaling etc. Convolutional Neural\nNetworks (CNNs) are translation equivariant by construction but recent work by\nEngstrom et al. (2017) has shown that they too are vulnerable to natural adversar-\nial attacks based on rotation and translation.\nIn this paper, we consider Group-equivariant Convolutional Neural Networks\n(GCNNs) proposed by Cohen & Welling (2016) that are rotation equivariant by\nconstruction, and study their robustness to adversarial attacks based on rotations\nas well as pixel-wise perturbations. We observe that GCNNs are robust to small\ndegrees of rotations away from the ones present in the training data. We also\nobserve that applying data augmentation increases their robustness.", "paperhash": "kamath|understanding_adversarial_robustness_of_symmetric_networks", "_bibtex": "@misc{\n  kamath2018understanding,\n  title={Understanding Adversarial Robustness of Symmetric Networks},\n  author={Sandesh Kamath and Amit Deshpande},\n  year={2018},\n  url={https://openreview.net/forum?id=Byehv0A8M}\n}", "authorids": ["ksandeshk@cmi.ac.in", "amitdesh@microsoft.com"], "authors": ["Sandesh Kamath", "Amit Deshpande"], "keywords": [], "pdf": "/pdf/35a73e207468906d7852c90e374330c71f138023.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}