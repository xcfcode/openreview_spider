{"notes": [{"tddate": null, "ddate": null, "cdate": null, "original": null, "tmdate": 1490028553403, "tcdate": 1490028553403, "number": 1, "id": "S1-Gutpsg", "invitation": "ICLR.cc/2017/workshop/-/paper14/acceptance", "forum": "ryBDyehOl", "replyto": "ryBDyehOl", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Accept", "title": "ICLR committee final decision"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "REBAR: Low-variance, unbiased gradient estimates for discrete latent variable models", "abstract": "Learning in models with discrete latent variables is challenging due to high variance gradient estimators. Generally, approaches have relied on control variates to reduce the variance of the REINFORCE estimator. Recent work (Jang et al. 2016, Maddison et al. 2016) has taken a different approach, introducing a continuous relaxation of discrete variables to produce low-variance, but biased, gradient estimates. In this work, we combine the two approaches through a novel control variate that produces low-variance, unbiased gradient estimates. We present encouraging preliminary results on a toy problem and on learning sigmoid belief networks. ", "pdf": "/pdf/8c5487e8c222c09c4a6f89bfc2d7f494b351c67f.pdf", "TL;DR": "Combining REINFORCE with the Concrete relaxation to get low variance, unbiased gradient estimates.", "paperhash": "tucker|rebar_lowvariance_unbiased_gradient_estimates_for_discrete_latent_variable_models", "keywords": ["Unsupervised Learning", "Reinforcement Learning", "Optimization"], "conflicts": ["google.com", "stats.ox.ac.uk"], "authors": ["George Tucker", "Andriy Mnih", "Chris J. Maddison", "Jascha Sohl-Dickstein"], "authorids": ["gjt@google.com", "amnih@google.com", "cmaddis@stats.ox.ac.uk", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1490028553976, "id": "ICLR.cc/2017/workshop/-/paper14/acceptance", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "ryBDyehOl", "replyto": "ryBDyehOl", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept", "Reject"]}}}, "nonreaders": [], "cdate": 1490028553976}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1489774931798, "tcdate": 1486778205203, "number": 14, "id": "ryBDyehOl", "invitation": "ICLR.cc/2017/workshop/-/submission", "forum": "ryBDyehOl", "signatures": ["~George_Tucker1"], "readers": ["everyone"], "content": {"title": "REBAR: Low-variance, unbiased gradient estimates for discrete latent variable models", "abstract": "Learning in models with discrete latent variables is challenging due to high variance gradient estimators. Generally, approaches have relied on control variates to reduce the variance of the REINFORCE estimator. Recent work (Jang et al. 2016, Maddison et al. 2016) has taken a different approach, introducing a continuous relaxation of discrete variables to produce low-variance, but biased, gradient estimates. In this work, we combine the two approaches through a novel control variate that produces low-variance, unbiased gradient estimates. We present encouraging preliminary results on a toy problem and on learning sigmoid belief networks. ", "pdf": "/pdf/8c5487e8c222c09c4a6f89bfc2d7f494b351c67f.pdf", "TL;DR": "Combining REINFORCE with the Concrete relaxation to get low variance, unbiased gradient estimates.", "paperhash": "tucker|rebar_lowvariance_unbiased_gradient_estimates_for_discrete_latent_variable_models", "keywords": ["Unsupervised Learning", "Reinforcement Learning", "Optimization"], "conflicts": ["google.com", "stats.ox.ac.uk"], "authors": ["George Tucker", "Andriy Mnih", "Chris J. Maddison", "Jascha Sohl-Dickstein"], "authorids": ["gjt@google.com", "amnih@google.com", "cmaddis@stats.ox.ac.uk", "jaschasd@google.com"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1487690420000, "tmdate": 1484242559574, "id": "ICLR.cc/2017/workshop/-/submission", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1495466420000, "cdate": 1484242559574}}}, {"tddate": null, "tmdate": 1489554633301, "tcdate": 1489554633301, "number": 2, "id": "rJWCnSLig", "invitation": "ICLR.cc/2017/workshop/-/paper14/official/review", "forum": "ryBDyehOl", "replyto": "ryBDyehOl", "signatures": ["ICLR.cc/2017/workshop/paper14/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper14/AnonReviewer1"], "content": {"title": "Introduces new control variate for REINFORCE gradient", "rating": "8: Top 50% of accepted papers, clear accept", "review": "This paper introduces a new gradient estimator for discrete variables. The estimator is based on a conditionally marginalized control variate scheme. The control variate is based on a combination of the REINFORCE estimator and the recently proposed Concrete distribution, a continuous relaxation of the discrete disribution. \n\nAn important improvement upon the estimator of the Concrete distribution, is the unbiasedness. The authors show in experiments that theirs indeed result in better solutions. Unfortunately, it is not reported what the performance is at convergence.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "REBAR: Low-variance, unbiased gradient estimates for discrete latent variable models", "abstract": "Learning in models with discrete latent variables is challenging due to high variance gradient estimators. Generally, approaches have relied on control variates to reduce the variance of the REINFORCE estimator. Recent work (Jang et al. 2016, Maddison et al. 2016) has taken a different approach, introducing a continuous relaxation of discrete variables to produce low-variance, but biased, gradient estimates. In this work, we combine the two approaches through a novel control variate that produces low-variance, unbiased gradient estimates. We present encouraging preliminary results on a toy problem and on learning sigmoid belief networks. ", "pdf": "/pdf/8c5487e8c222c09c4a6f89bfc2d7f494b351c67f.pdf", "TL;DR": "Combining REINFORCE with the Concrete relaxation to get low variance, unbiased gradient estimates.", "paperhash": "tucker|rebar_lowvariance_unbiased_gradient_estimates_for_discrete_latent_variable_models", "keywords": ["Unsupervised Learning", "Reinforcement Learning", "Optimization"], "conflicts": ["google.com", "stats.ox.ac.uk"], "authors": ["George Tucker", "Andriy Mnih", "Chris J. Maddison", "Jascha Sohl-Dickstein"], "authorids": ["gjt@google.com", "amnih@google.com", "cmaddis@stats.ox.ac.uk", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489554634180, "id": "ICLR.cc/2017/workshop/-/paper14/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper14/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper14/AnonReviewer2", "ICLR.cc/2017/workshop/paper14/AnonReviewer1"], "reply": {"forum": "ryBDyehOl", "replyto": "ryBDyehOl", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper14/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper14/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489554634180}}}, {"tddate": null, "tmdate": 1489363642193, "tcdate": 1489363642193, "number": 1, "id": "B1fpfvQse", "invitation": "ICLR.cc/2017/workshop/-/paper14/official/review", "forum": "ryBDyehOl", "replyto": "ryBDyehOl", "signatures": ["ICLR.cc/2017/workshop/paper14/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper14/AnonReviewer2"], "content": {"title": "Solid idea for variance reduction in latent variable models", "rating": "8: Top 50% of accepted papers, clear accept", "review": "This paper introduces a way of training models with discrete latent variables using a low-variance unbiased stochastic estimate of the true gradient. The trick is to take the recently proposed Gumbel/softmax (or concrete) distribution, but use it to construct a control variate for the stochastic gradient.\n\nOverall, I find the idea both clever and convincing. Since the concrete distribution was already shown in previous work to be directly convertible into a discrete model, it ought to give a good approximation to the gradient for the discrete model. Therefore, the stochasticity in the REINFORCE gradient for the continuous model ought to be a strong control variate for the REINFORCE gradient in the discrete one. \n\nThe experiments show that REBAR is able to reduce the variance of the gradient estimates by almost an order of magnitude on binary MNIST (still a challenging benchmark for discrete latent variable models). The method still appears to underperform the concrete distribution itself; I expect with a bit more effort, one should be able to find cases where the discrete model pays off. But the idea seems sound, and overall I think this is a strong workshop paper.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "REBAR: Low-variance, unbiased gradient estimates for discrete latent variable models", "abstract": "Learning in models with discrete latent variables is challenging due to high variance gradient estimators. Generally, approaches have relied on control variates to reduce the variance of the REINFORCE estimator. Recent work (Jang et al. 2016, Maddison et al. 2016) has taken a different approach, introducing a continuous relaxation of discrete variables to produce low-variance, but biased, gradient estimates. In this work, we combine the two approaches through a novel control variate that produces low-variance, unbiased gradient estimates. We present encouraging preliminary results on a toy problem and on learning sigmoid belief networks. ", "pdf": "/pdf/8c5487e8c222c09c4a6f89bfc2d7f494b351c67f.pdf", "TL;DR": "Combining REINFORCE with the Concrete relaxation to get low variance, unbiased gradient estimates.", "paperhash": "tucker|rebar_lowvariance_unbiased_gradient_estimates_for_discrete_latent_variable_models", "keywords": ["Unsupervised Learning", "Reinforcement Learning", "Optimization"], "conflicts": ["google.com", "stats.ox.ac.uk"], "authors": ["George Tucker", "Andriy Mnih", "Chris J. Maddison", "Jascha Sohl-Dickstein"], "authorids": ["gjt@google.com", "amnih@google.com", "cmaddis@stats.ox.ac.uk", "jaschasd@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489554634180, "id": "ICLR.cc/2017/workshop/-/paper14/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper14/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper14/AnonReviewer2", "ICLR.cc/2017/workshop/paper14/AnonReviewer1"], "reply": {"forum": "ryBDyehOl", "replyto": "ryBDyehOl", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper14/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper14/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489554634180}}}], "count": 4}