{"notes": [{"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1457663887282, "tcdate": 1457663887282, "id": "5QzBNOovjCZgXpo7i3xE", "invitation": "ICLR.cc/2016/workshop/-/paper/174/review/10", "forum": "1WvOZmpo0HMnPB1oinGx", "replyto": "1WvOZmpo0HMnPB1oinGx", "signatures": ["ICLR.cc/2016/workshop/paper/174/reviewer/10"], "readers": ["everyone"], "writers": ["ICLR.cc/2016/workshop/paper/174/reviewer/10"], "content": {"title": "This paper contributes in the sense of obtaining high level object saliency map by using CNN and semantic information.", "rating": "5: Marginally below acceptance threshold", "review": "Pros: \nNovelty&Significance: I think this paper is interesting in the sense of combining the semantic information into traditional saliency problems under the weakly supervised scenario. It computes local contrast with CNN feature and then output a semantic mask of the targeting object. Actually, I think it is a good complementary to current strong supervised saliency detection such as bounding box salient object detection, salient object segmentation. \n\nClarity: The paper is clearly descriptive and easy to understand. \n\nCons: \n    It lacks of numerical comparison and evaluation, with some standard criteria. \n\n    Currently, rather than saliency,  it is more close to weakly supervised segmentation. So maybe the authors need to refer to some weakly supervised segmentation works using CNN, e.g. Chen et.al ICCV 2015. \n\n    For general saliency. I am not clear whether it can transfer to unknown object domain, which could also be interesting. \n\n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Distinct Class Saliency Maps for Multiple Object Images", "abstract": "This paper proposes a method to obtain more distinct class saliency maps than\nSimonyan et al. (2014). We made three improvements over their method: (1) using\nCNN derivatives with respect to feature maps of the intermediate convolutional\nlayers with up-sampling instead of an input image; (2) subtracting saliency\nmaps of the other classes from saliency maps of the target class to differentiate\ntarget objects from other objects; (3) aggregating multi-scale class saliency maps\nto compensate lower resolution of the feature maps.", "pdf": "/pdf/1WvOZmpo0HMnPB1oinGx.pdf", "paperhash": "shimoda|distinct_class_saliency_maps_for_multiple_object_images", "conflicts": ["uec.ac.jp"], "authors": ["Wataru Shimoda", "Keiji Yanai"], "authorids": ["shimoda-k@mm.inf.uec.ac.jp", "yanai@cs.uec.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456580086347, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456580086347, "id": "ICLR.cc/2016/workshop/-/paper/174/review/10", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "1WvOZmpo0HMnPB1oinGx", "replyto": "1WvOZmpo0HMnPB1oinGx", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/174/reviewer/10", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1457378518867, "tcdate": 1457378518867, "id": "P7VOZyVqzuKvjNORtJ13", "invitation": "ICLR.cc/2016/workshop/-/paper/174/review/11", "forum": "1WvOZmpo0HMnPB1oinGx", "replyto": "1WvOZmpo0HMnPB1oinGx", "signatures": ["ICLR.cc/2016/workshop/paper/174/reviewer/11"], "readers": ["everyone"], "writers": ["ICLR.cc/2016/workshop/paper/174/reviewer/11"], "content": {"title": "This paper proposes a method to produce class-specific saliency maps by combining gradient-like values from different layers of the network.", "rating": "3: Clear rejection", "review": "The objective of this paper is to improve the saliency map generation approach of Simonyan et al. 2014.\n\nStrengths:\n+ The output look significantly better than Simonyan et al. 2014\n+ The submission is well written and easy to follow\n\nWeaknesses:\n- The paper contains no evidence or argument for why the proposed method produces maps that cover salient objects and not non-salient objects\n- Even though some saliency benchmarks exist, the submission does not provide any numerical results\n\nThe submission proposes a method that significantly improves the saliency maps produced by Simonyan et al. 2014. This reviewer, however, does not think that progress in this direction is generally useful. The task of image saliency is not well-defined, in general or in this paper. It's not clear that the proposed method captures \"saliency\" even if one tries to define it: it is not demonstrated that the method highlights objects that are considered salient while leaving objects that are not considered salient dark. There do exist image saliency benchmarks (e.g., salicon), but no numerical results are presents so it's not clear that the method improves anything.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Distinct Class Saliency Maps for Multiple Object Images", "abstract": "This paper proposes a method to obtain more distinct class saliency maps than\nSimonyan et al. (2014). We made three improvements over their method: (1) using\nCNN derivatives with respect to feature maps of the intermediate convolutional\nlayers with up-sampling instead of an input image; (2) subtracting saliency\nmaps of the other classes from saliency maps of the target class to differentiate\ntarget objects from other objects; (3) aggregating multi-scale class saliency maps\nto compensate lower resolution of the feature maps.", "pdf": "/pdf/1WvOZmpo0HMnPB1oinGx.pdf", "paperhash": "shimoda|distinct_class_saliency_maps_for_multiple_object_images", "conflicts": ["uec.ac.jp"], "authors": ["Wataru Shimoda", "Keiji Yanai"], "authorids": ["shimoda-k@mm.inf.uec.ac.jp", "yanai@cs.uec.ac.jp"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456580085636, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456580085636, "id": "ICLR.cc/2016/workshop/-/paper/174/review/11", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "1WvOZmpo0HMnPB1oinGx", "replyto": "1WvOZmpo0HMnPB1oinGx", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/174/reviewer/11", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "replyto": null, "ddate": null, "cdate": null, "tmdate": 1455831562016, "tcdate": 1455831562016, "id": "1WvOZmpo0HMnPB1oinGx", "invitation": "ICLR.cc/2016/workshop/-/submission", "forum": "1WvOZmpo0HMnPB1oinGx", "signatures": ["~Keiji_Yanai1"], "readers": ["everyone"], "writers": ["~Keiji_Yanai1"], "content": {"CMT_id": "", "title": "Distinct Class Saliency Maps for Multiple Object Images", "abstract": "This paper proposes a method to obtain more distinct class saliency maps than\nSimonyan et al. (2014). We made three improvements over their method: (1) using\nCNN derivatives with respect to feature maps of the intermediate convolutional\nlayers with up-sampling instead of an input image; (2) subtracting saliency\nmaps of the other classes from saliency maps of the target class to differentiate\ntarget objects from other objects; (3) aggregating multi-scale class saliency maps\nto compensate lower resolution of the feature maps.", "pdf": "/pdf/1WvOZmpo0HMnPB1oinGx.pdf", "paperhash": "shimoda|distinct_class_saliency_maps_for_multiple_object_images", "conflicts": ["uec.ac.jp"], "authors": ["Wataru Shimoda", "Keiji Yanai"], "authorids": ["shimoda-k@mm.inf.uec.ac.jp", "yanai@cs.uec.ac.jp"]}, "nonreaders": [], "details": {"replyCount": 2, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1454464564200, "ddate": null, "super": null, "final": null, "duedate": 1455833700000, "tcdate": 1454464564200, "id": "ICLR.cc/2016/workshop/-/submission", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "readers": ["everyone"], "reply": {"pdf": null, "forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"order": 4, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv.", "value-regex": "upload|http://arxiv.org/pdf/.+"}, "title": {"order": 3, "description": "Title of paper.", "value-regex": ".{0,500}"}, "abstract": {"order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"order": 1, "description": "Comma separated list of author names, as they appear in the paper.", "value-regex": "[^,\\n]+(,[^,\\n]+)*"}, "author_emails": {"order": 2, "description": "Comma separated list of author email addresses, in the same order as above.", "value-regex": "[^,\\n]+(,[^,\\n]+)*"}, "conflicts": {"order": 100, "description": "Semi-colon separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.).", "value-regex": "^([a-zA-Z0-9][a-zA-Z0-9-_]{0,61}[a-zA-Z0-9]{0,1}\\.([a-zA-Z]{1,6}|[a-zA-Z0-9-]{1,30}\\.[a-zA-Z]{2,3}))+(;[a-zA-Z0-9][a-zA-Z0-9-_]{0,61}[a-zA-Z0-9]{0,1}\\.([a-zA-Z]{1,6}|[a-zA-Z0-9-]{1,30}\\.[a-zA-Z]{2,3}))*$"}, "CMT_id": {"order": 5, "value-regex": ".*", "description": "If the paper is a resubmission from the ICLR 2016 Conference Track, enter its CMT ID; otherwise, leave blank."}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "expdate": 1463609700000}}}], "count": 3}