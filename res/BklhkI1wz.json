{"notes": [{"id": "HygDxZh2LV", "original": null, "number": 1, "cdate": 1551839470823, "ddate": null, "tcdate": 1551839470823, "tmdate": 1551839470823, "tddate": null, "forum": "BklhkI1wz", "replyto": "BklhkI1wz", "invitation": "ICLR.cc/2018/Workshop/-/Paper168/Public_Comment", "content": {"title": "Question about classification results", "comment": "Hi,\n\nIn your classification results the transfer learning model used extracted features from a deep learning model. But non-transfer model just use traditional ML method with hand-crafted features. Have you compared the transfer learning model with LSTMs trained directly on the target data?\n\nIs it possible that the transfer learning method has better performance just because it utilizes representation learning while the non-transferred one does not?"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Applied timeseries Transfer learning", "abstract": "Reliable and accurate time-series modeling is critical in many fields including energy, finance, and manufacturing.\nMany time-series tasks, however, suffer from a limited amount of clean training data resulting in poor forecasting, classification or clustering performance. Recently, convolutional neural networks (CNNs) have shown outstanding image classification performance even on tasks with small-scale training sets. The performance can be attributed to transfer learning through ability of CNNs to learn rich mid-level image representations. For time-series, however, no prior work exists on general transfer learning. In this short paper, motivated by recent success of transfer learning in image-related tasks, we are the first to show that using an LSTM auto-encoder with attention trained on a large-scale timeseries dataset with pre-processing we can effectively transfer time-series features across diverse domains.", "paperhash": "laptev|applied_timeseries_transfer_learning", "keywords": ["time-series", "transfer-learning"], "_bibtex": "@misc{\n  laptev2018applied,\n  title={Applied timeseries Transfer learning},\n  author={Nikolay Laptev and Jiafan Yu and Ram Rajagopal},\n  year={2018},\n  url={https://openreview.net/forum?id=BklhkI1wz}\n}", "authorids": ["nlaptev@stanford.edu", "jfy@stanford.edu", "ramr@stanford.edu"], "authors": ["Nikolay Laptev", "Jiafan Yu", "Ram Rajagopal"], "TL;DR": "transfer learning in time-series", "pdf": "/pdf/1f263eee5ab5b65382b8973960c1c319cdd27e6e.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712625578, "id": "ICLR.cc/2018/Workshop/-/Paper168/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper168/Reviewers"], "reply": {"replyto": null, "forum": "BklhkI1wz", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712625578}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124282928, "tcdate": 1518456744168, "number": 168, "cdate": 1518456744168, "id": "BklhkI1wz", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "BklhkI1wz", "signatures": ["~Nikolay_Laptev1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Applied timeseries Transfer learning", "abstract": "Reliable and accurate time-series modeling is critical in many fields including energy, finance, and manufacturing.\nMany time-series tasks, however, suffer from a limited amount of clean training data resulting in poor forecasting, classification or clustering performance. Recently, convolutional neural networks (CNNs) have shown outstanding image classification performance even on tasks with small-scale training sets. The performance can be attributed to transfer learning through ability of CNNs to learn rich mid-level image representations. For time-series, however, no prior work exists on general transfer learning. In this short paper, motivated by recent success of transfer learning in image-related tasks, we are the first to show that using an LSTM auto-encoder with attention trained on a large-scale timeseries dataset with pre-processing we can effectively transfer time-series features across diverse domains.", "paperhash": "laptev|applied_timeseries_transfer_learning", "keywords": ["time-series", "transfer-learning"], "_bibtex": "@misc{\n  laptev2018applied,\n  title={Applied timeseries Transfer learning},\n  author={Nikolay Laptev and Jiafan Yu and Ram Rajagopal},\n  year={2018},\n  url={https://openreview.net/forum?id=BklhkI1wz}\n}", "authorids": ["nlaptev@stanford.edu", "jfy@stanford.edu", "ramr@stanford.edu"], "authors": ["Nikolay Laptev", "Jiafan Yu", "Ram Rajagopal"], "TL;DR": "transfer learning in time-series", "pdf": "/pdf/1f263eee5ab5b65382b8973960c1c319cdd27e6e.pdf"}, "nonreaders": [], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582954751, "tcdate": 1520182056338, "number": 1, "cdate": 1520182056338, "id": "HkgVmsYuG", "invitation": "ICLR.cc/2018/Workshop/-/Paper168/Official_Review", "forum": "BklhkI1wz", "replyto": "BklhkI1wz", "signatures": ["ICLR.cc/2018/Workshop/Paper168/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper168/AnonReviewer2"], "content": {"title": "Solid - nothing too surprising", "rating": "6: Marginally above acceptance threshold", "review": "This is a solid workshop paper. It is well-written; motivation, approach and experimental evaluation are mostly clear. The description of the attention mechanism is a bit vague (\"identify the part of the time-series that the model should focus on\"); I think that paragraph could be improved. Moreover, what is the unit of errors in Figure 1 b)?\n\nIn terms of originality or significance, this seems to be a solid proof of concept. It's good to see that transfer learning works for time series using LSTM models. On the other hand, this is not too surprising, either; overall the approach seems straight forward.\n\nIn summary\n+ well-written\n+ solid experiments demonstrating the approach on different datasets\n- somewhat limited in terms of originality", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Applied timeseries Transfer learning", "abstract": "Reliable and accurate time-series modeling is critical in many fields including energy, finance, and manufacturing.\nMany time-series tasks, however, suffer from a limited amount of clean training data resulting in poor forecasting, classification or clustering performance. Recently, convolutional neural networks (CNNs) have shown outstanding image classification performance even on tasks with small-scale training sets. The performance can be attributed to transfer learning through ability of CNNs to learn rich mid-level image representations. For time-series, however, no prior work exists on general transfer learning. In this short paper, motivated by recent success of transfer learning in image-related tasks, we are the first to show that using an LSTM auto-encoder with attention trained on a large-scale timeseries dataset with pre-processing we can effectively transfer time-series features across diverse domains.", "paperhash": "laptev|applied_timeseries_transfer_learning", "keywords": ["time-series", "transfer-learning"], "_bibtex": "@misc{\n  laptev2018applied,\n  title={Applied timeseries Transfer learning},\n  author={Nikolay Laptev and Jiafan Yu and Ram Rajagopal},\n  year={2018},\n  url={https://openreview.net/forum?id=BklhkI1wz}\n}", "authorids": ["nlaptev@stanford.edu", "jfy@stanford.edu", "ramr@stanford.edu"], "authors": ["Nikolay Laptev", "Jiafan Yu", "Ram Rajagopal"], "TL;DR": "transfer learning in time-series", "pdf": "/pdf/1f263eee5ab5b65382b8973960c1c319cdd27e6e.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582954557, "id": "ICLR.cc/2018/Workshop/-/Paper168/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper168/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper168/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper168/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper168/AnonReviewer1"], "reply": {"forum": "BklhkI1wz", "replyto": "BklhkI1wz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper168/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper168/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582954557}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582845425, "tcdate": 1520586710615, "number": 2, "cdate": 1520586710615, "id": "Hk1kxRyKf", "invitation": "ICLR.cc/2018/Workshop/-/Paper168/Official_Review", "forum": "BklhkI1wz", "replyto": "BklhkI1wz", "signatures": ["ICLR.cc/2018/Workshop/Paper168/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper168/AnonReviewer3"], "content": {"title": "Interesting paper but in my view not good fit for workshop track ", "rating": "5: Marginally below acceptance threshold", "review": "This paper proposes a method to transfer features across diverse domains. In order to do that, they trained an LSTM auto-encoder with attention on large-scale time series. Then learned time-series features are used for transfer learning on different tasks such as classification, disaggregation, and forecasting tasks. As mentioned in the paper, preprocessing such as detrending, deseasoning, and normalizing of time-series data play an important role to deal with diverse target domains.\n\nEven though this paper shows interesting results, I am not sure if there is enough contribution either on the model side or even on the task side. In my view, this paper belongs to application paper category (and it is a solid application paper) rather than late-breaking development, very novel ideas, or position paper which are the main focuses of the workshop.\n\nAs a result, I am not convinced this paper is a good fit for the workshop track. \n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Applied timeseries Transfer learning", "abstract": "Reliable and accurate time-series modeling is critical in many fields including energy, finance, and manufacturing.\nMany time-series tasks, however, suffer from a limited amount of clean training data resulting in poor forecasting, classification or clustering performance. Recently, convolutional neural networks (CNNs) have shown outstanding image classification performance even on tasks with small-scale training sets. The performance can be attributed to transfer learning through ability of CNNs to learn rich mid-level image representations. For time-series, however, no prior work exists on general transfer learning. In this short paper, motivated by recent success of transfer learning in image-related tasks, we are the first to show that using an LSTM auto-encoder with attention trained on a large-scale timeseries dataset with pre-processing we can effectively transfer time-series features across diverse domains.", "paperhash": "laptev|applied_timeseries_transfer_learning", "keywords": ["time-series", "transfer-learning"], "_bibtex": "@misc{\n  laptev2018applied,\n  title={Applied timeseries Transfer learning},\n  author={Nikolay Laptev and Jiafan Yu and Ram Rajagopal},\n  year={2018},\n  url={https://openreview.net/forum?id=BklhkI1wz}\n}", "authorids": ["nlaptev@stanford.edu", "jfy@stanford.edu", "ramr@stanford.edu"], "authors": ["Nikolay Laptev", "Jiafan Yu", "Ram Rajagopal"], "TL;DR": "transfer learning in time-series", "pdf": "/pdf/1f263eee5ab5b65382b8973960c1c319cdd27e6e.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582954557, "id": "ICLR.cc/2018/Workshop/-/Paper168/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper168/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper168/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper168/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper168/AnonReviewer1"], "reply": {"forum": "BklhkI1wz", "replyto": "BklhkI1wz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper168/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper168/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582954557}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582712884, "tcdate": 1520687828228, "number": 3, "cdate": 1520687828228, "id": "Hk2A9U-Kf", "invitation": "ICLR.cc/2018/Workshop/-/Paper168/Official_Review", "forum": "BklhkI1wz", "replyto": "BklhkI1wz", "signatures": ["ICLR.cc/2018/Workshop/Paper168/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper168/AnonReviewer1"], "content": {"title": "review", "rating": "3: Clear rejection", "review": "This paper proposes an LSTM based model for transfer learning in time series data. It is not entirely clear to me what the experiment setting is. For example, in the time series classification with UCR datasets, what is the source and target domains for these plots? What method is \"traditional ML without TL\"? Why is this an autoencoder instead of just an encoder model? The writing needs to be improved so that people can understand exactly what the model is and what the experiment settings are.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Applied timeseries Transfer learning", "abstract": "Reliable and accurate time-series modeling is critical in many fields including energy, finance, and manufacturing.\nMany time-series tasks, however, suffer from a limited amount of clean training data resulting in poor forecasting, classification or clustering performance. Recently, convolutional neural networks (CNNs) have shown outstanding image classification performance even on tasks with small-scale training sets. The performance can be attributed to transfer learning through ability of CNNs to learn rich mid-level image representations. For time-series, however, no prior work exists on general transfer learning. In this short paper, motivated by recent success of transfer learning in image-related tasks, we are the first to show that using an LSTM auto-encoder with attention trained on a large-scale timeseries dataset with pre-processing we can effectively transfer time-series features across diverse domains.", "paperhash": "laptev|applied_timeseries_transfer_learning", "keywords": ["time-series", "transfer-learning"], "_bibtex": "@misc{\n  laptev2018applied,\n  title={Applied timeseries Transfer learning},\n  author={Nikolay Laptev and Jiafan Yu and Ram Rajagopal},\n  year={2018},\n  url={https://openreview.net/forum?id=BklhkI1wz}\n}", "authorids": ["nlaptev@stanford.edu", "jfy@stanford.edu", "ramr@stanford.edu"], "authors": ["Nikolay Laptev", "Jiafan Yu", "Ram Rajagopal"], "TL;DR": "transfer learning in time-series", "pdf": "/pdf/1f263eee5ab5b65382b8973960c1c319cdd27e6e.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582954557, "id": "ICLR.cc/2018/Workshop/-/Paper168/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper168/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper168/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper168/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper168/AnonReviewer1"], "reply": {"forum": "BklhkI1wz", "replyto": "BklhkI1wz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper168/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper168/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582954557}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573589686, "tcdate": 1521573589686, "number": 200, "cdate": 1521573589353, "id": "HJC0RARYf", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "BklhkI1wz", "replyto": "BklhkI1wz", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Applied timeseries Transfer learning", "abstract": "Reliable and accurate time-series modeling is critical in many fields including energy, finance, and manufacturing.\nMany time-series tasks, however, suffer from a limited amount of clean training data resulting in poor forecasting, classification or clustering performance. Recently, convolutional neural networks (CNNs) have shown outstanding image classification performance even on tasks with small-scale training sets. The performance can be attributed to transfer learning through ability of CNNs to learn rich mid-level image representations. For time-series, however, no prior work exists on general transfer learning. In this short paper, motivated by recent success of transfer learning in image-related tasks, we are the first to show that using an LSTM auto-encoder with attention trained on a large-scale timeseries dataset with pre-processing we can effectively transfer time-series features across diverse domains.", "paperhash": "laptev|applied_timeseries_transfer_learning", "keywords": ["time-series", "transfer-learning"], "_bibtex": "@misc{\n  laptev2018applied,\n  title={Applied timeseries Transfer learning},\n  author={Nikolay Laptev and Jiafan Yu and Ram Rajagopal},\n  year={2018},\n  url={https://openreview.net/forum?id=BklhkI1wz}\n}", "authorids": ["nlaptev@stanford.edu", "jfy@stanford.edu", "ramr@stanford.edu"], "authors": ["Nikolay Laptev", "Jiafan Yu", "Ram Rajagopal"], "TL;DR": "transfer learning in time-series", "pdf": "/pdf/1f263eee5ab5b65382b8973960c1c319cdd27e6e.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 6}