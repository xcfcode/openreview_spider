{"notes": [{"id": "BJelsDvo84", "original": "Hyx1jDPoUN", "number": 3, "cdate": 1551755159880, "ddate": null, "tcdate": 1551755159880, "tmdate": 1562082110433, "tddate": null, "forum": "BJelsDvo84", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks", "authors": ["Jason Wei", "Kai Zou"], "authorids": ["jason.20@dartmouth.edu", "kz56@georgetown.edu"], "keywords": ["Data Augmentation", "Text Classification", "Natural Language Processing"], "TL;DR": "Simple text augmentation techniques can significantly boost performance on text classification tasks, especially for small datasets.", "abstract": "We present EDA: easy data augmentation techniques for boosting performance on text classification tasks. EDA consists of four simple but powerful operations: synonym replacement, random insertion, random swap, and random deletion. On five text classification tasks, we show that EDA improves performance for both convolutional and recurrent neural networks. EDA demonstrates particularly strong results for smaller datasets; on average, across five datasets, training with EDA while using only 50% of the available training set achieved the same accuracy as normal training with all available data. We also performed extensive ablation studies and suggest parameters for practical use.", "pdf": "/pdf/219276dd2145eb81c23b4d76c2c4dd0b7999534c.pdf", "paperhash": "wei|eda_easy_data_augmentation_techniques_for_boosting_performance_on_text_classification_tasks"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "ICLR.cc/2019/Workshop/LLD"}, {"id": "SJeisCOTOE", "original": null, "number": 1, "cdate": 1553989282867, "ddate": null, "tcdate": 1553989282867, "tmdate": 1555512029404, "tddate": null, "forum": "BJelsDvo84", "replyto": "BJelsDvo84", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper3/Official_Review", "content": {"title": "Simple data augmentation techniques for text that work well especially on small datasets", "review": "Summary: The paper proposes 4 data augmentation techniques for text: synonym replacement, random insertion, random swap, and random deletion. These techniques are validated on 5 text classification datasets, showing increased performance of up to 3% when the dataset size is small. Ablation studies show that all four techniques can be helpful, and suggest sensible values of hyperparameters to set.\n\nStrengths:\n1. The proposed techniques are simple and easily implemented. There's no need to train complicated language models.\n2. The careful ablation studies (Section 3.3 and 3.4) reveals insights about how much these techniques help and in which context.\n3. Situating the proposed scheme in the context of data augmentation for text (Section 4 and 7) is very helpful.\n\nMinor point: the name EDA (easy data augmentation) might be too generic.\n\nA reference for the authors: A related technique for data augmentation for text is called data recombination:\nRobin Jia and Percy Liang. Data Recombination for Neural Semantic Parsing. ACL 2016.", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper3/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper3/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks", "authors": ["Jason Wei", "Kai Zou"], "authorids": ["jason.20@dartmouth.edu", "kz56@georgetown.edu"], "keywords": ["Data Augmentation", "Text Classification", "Natural Language Processing"], "TL;DR": "Simple text augmentation techniques can significantly boost performance on text classification tasks, especially for small datasets.", "abstract": "We present EDA: easy data augmentation techniques for boosting performance on text classification tasks. EDA consists of four simple but powerful operations: synonym replacement, random insertion, random swap, and random deletion. On five text classification tasks, we show that EDA improves performance for both convolutional and recurrent neural networks. EDA demonstrates particularly strong results for smaller datasets; on average, across five datasets, training with EDA while using only 50% of the available training set achieved the same accuracy as normal training with all available data. We also performed extensive ablation studies and suggest parameters for practical use.", "pdf": "/pdf/219276dd2145eb81c23b4d76c2c4dd0b7999534c.pdf", "paperhash": "wei|eda_easy_data_augmentation_techniques_for_boosting_performance_on_text_classification_tasks"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper3/Official_Review", "cdate": 1553713421973, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "BJelsDvo84", "replyto": "BJelsDvo84", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper3/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper3/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713421973, "tmdate": 1555511819785, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper3/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "rkeqEYSLFV", "original": null, "number": 2, "cdate": 1554565426079, "ddate": null, "tcdate": 1554565426079, "tmdate": 1555512023508, "tddate": null, "forum": "BJelsDvo84", "replyto": "BJelsDvo84", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper3/Official_Review", "content": {"title": "A nice clear paper for text-related fast data augmentation techniques", "review": "The authors present a framework of fast and easy methods for boosting text classification. The methods include synonym replacement, random insertion of a word, random swap of two words and last random deletion. They empirically prove that their approach can increase accuracy, especially in small training set sizes.\n\nThe writing of the paper was very clear and easy to understand. The authors had a very extensive section with experiments, analysis, ablation studies as well as comparison to related previous work. The actual contributions of the paper are random insertions, swaps, and deletions as synonym replacement was previously \n\nPros:\n- fast and easy methods \n- compared with training techniques\n\nCons: \n- no learning or training\n- theoretical explanation \n\nI really liked the frequently asked questions section in the appendix, where the authors respond to questions that easily arise. \n\nBecause the gains are indeed marginal, statistical significance is something that should be added. As the authors state in the conclusion, a small theoretical explanation of the EDA operations could be done here, as the methods themselves did not include something extremely complex. The methods should be first compared with a non-training or learning approach, for example adding knn words as augmentation.\n\nSome questions that could be answered as well are: did you explore which replacements affected the model more? for example verbs, nouns or what was their POS-tag? Did you observe any pattern concerning that? As the random deletion seems to be the most effective for small training set sizes, what were the words that were deleted and what can you comment about this phenomenon?", "rating": "3: Marginally above acceptance threshold", "confidence": "3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper3/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper3/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks", "authors": ["Jason Wei", "Kai Zou"], "authorids": ["jason.20@dartmouth.edu", "kz56@georgetown.edu"], "keywords": ["Data Augmentation", "Text Classification", "Natural Language Processing"], "TL;DR": "Simple text augmentation techniques can significantly boost performance on text classification tasks, especially for small datasets.", "abstract": "We present EDA: easy data augmentation techniques for boosting performance on text classification tasks. EDA consists of four simple but powerful operations: synonym replacement, random insertion, random swap, and random deletion. On five text classification tasks, we show that EDA improves performance for both convolutional and recurrent neural networks. EDA demonstrates particularly strong results for smaller datasets; on average, across five datasets, training with EDA while using only 50% of the available training set achieved the same accuracy as normal training with all available data. We also performed extensive ablation studies and suggest parameters for practical use.", "pdf": "/pdf/219276dd2145eb81c23b4d76c2c4dd0b7999534c.pdf", "paperhash": "wei|eda_easy_data_augmentation_techniques_for_boosting_performance_on_text_classification_tasks"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper3/Official_Review", "cdate": 1553713421973, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "BJelsDvo84", "replyto": "BJelsDvo84", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper3/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper3/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713421973, "tmdate": 1555511819785, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper3/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "rklN-bVYt4", "original": null, "number": 1, "cdate": 1554755836446, "ddate": null, "tcdate": 1554755836446, "tmdate": 1555510984902, "tddate": null, "forum": "BJelsDvo84", "replyto": "BJelsDvo84", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper3/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks", "authors": ["Jason Wei", "Kai Zou"], "authorids": ["jason.20@dartmouth.edu", "kz56@georgetown.edu"], "keywords": ["Data Augmentation", "Text Classification", "Natural Language Processing"], "TL;DR": "Simple text augmentation techniques can significantly boost performance on text classification tasks, especially for small datasets.", "abstract": "We present EDA: easy data augmentation techniques for boosting performance on text classification tasks. EDA consists of four simple but powerful operations: synonym replacement, random insertion, random swap, and random deletion. On five text classification tasks, we show that EDA improves performance for both convolutional and recurrent neural networks. EDA demonstrates particularly strong results for smaller datasets; on average, across five datasets, training with EDA while using only 50% of the available training set achieved the same accuracy as normal training with all available data. We also performed extensive ablation studies and suggest parameters for practical use.", "pdf": "/pdf/219276dd2145eb81c23b4d76c2c4dd0b7999534c.pdf", "paperhash": "wei|eda_easy_data_augmentation_techniques_for_boosting_performance_on_text_classification_tasks"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper3/Decision", "cdate": 1554736071054, "reply": {"forum": "BJelsDvo84", "replyto": "BJelsDvo84", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736071054, "tmdate": 1555510967800, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 4}