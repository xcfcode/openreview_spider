{"notes": [{"tddate": null, "ddate": null, "tmdate": 1518730157216, "tcdate": 1509138751536, "number": 1126, "cdate": 1518730157205, "id": "H1BHbmWCZ", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "H1BHbmWCZ", "original": "r1_z-7-CW", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "TOWARDS ROBOT VISION MODULE DEVELOPMENT WITH EXPERIENTIAL ROBOT LEARNING", "abstract": "n this paper we present a thrust in three directions of visual development us- ing supervised and semi-supervised techniques. The first is an implementation of semi-supervised object detection and recognition using the principles of Soft At- tention and Generative Adversarial Networks (GANs). The second and the third are supervised networks that learn basic concepts of spatial locality and quantity respectively using Convolutional Neural Networks (CNNs). The three thrusts to- gether are based on the approach of Experiential Robot Learning, introduced in previous publication. While the results are unripe for implementation, we believe they constitute a stepping stone towards autonomous development of robotic vi- sual modules.", "pdf": "/pdf/00e5c4aefc80d0396ee745c032d27e0bccb43079.pdf", "TL;DR": "3 thrusts serving as stepping stones for robot experiential learning of vision module", "paperhash": "aly|towards_robot_vision_module_development_with_experiential_robot_learning", "_bibtex": "@misc{\na2018towards,\ntitle={{TOWARDS} {ROBOT} {VISION} {MODULE} {DEVELOPMENT} {WITH} {EXPERIENTIAL} {ROBOT} {LEARNING}},\nauthor={Ahmed A Aly and Joanne Bechta Dugan},\nyear={2018},\nurl={https://openreview.net/forum?id=H1BHbmWCZ},\n}", "keywords": ["Deep Learning", "Robotics", "Artificial Intelligence", "Computer Vision"], "authors": ["Ahmed A Aly", "Joanne Bechta Dugan"], "authorids": ["aaa2cn@virginia.edu", "jbd@virginia.edu"]}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}}, "tauthor": "ICLR.cc/2018/Conference"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1517260077414, "tcdate": 1517250165001, "number": 822, "cdate": 1517250164976, "id": "H16uIyTHG", "invitation": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "forum": "H1BHbmWCZ", "replyto": "H1BHbmWCZ", "signatures": ["ICLR.cc/2018/Conference/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Conference Acceptance Decision", "comment": "Reviewers unanimous on rejection.\nAuthors don't maintain anonymity.\nNo rebuttal from authors.\nPoorly written"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "TOWARDS ROBOT VISION MODULE DEVELOPMENT WITH EXPERIENTIAL ROBOT LEARNING", "abstract": "n this paper we present a thrust in three directions of visual development us- ing supervised and semi-supervised techniques. The first is an implementation of semi-supervised object detection and recognition using the principles of Soft At- tention and Generative Adversarial Networks (GANs). The second and the third are supervised networks that learn basic concepts of spatial locality and quantity respectively using Convolutional Neural Networks (CNNs). The three thrusts to- gether are based on the approach of Experiential Robot Learning, introduced in previous publication. While the results are unripe for implementation, we believe they constitute a stepping stone towards autonomous development of robotic vi- sual modules.", "pdf": "/pdf/00e5c4aefc80d0396ee745c032d27e0bccb43079.pdf", "TL;DR": "3 thrusts serving as stepping stones for robot experiential learning of vision module", "paperhash": "aly|towards_robot_vision_module_development_with_experiential_robot_learning", "_bibtex": "@misc{\na2018towards,\ntitle={{TOWARDS} {ROBOT} {VISION} {MODULE} {DEVELOPMENT} {WITH} {EXPERIENTIAL} {ROBOT} {LEARNING}},\nauthor={Ahmed A Aly and Joanne Bechta Dugan},\nyear={2018},\nurl={https://openreview.net/forum?id=H1BHbmWCZ},\n}", "keywords": ["Deep Learning", "Robotics", "Artificial Intelligence", "Computer Vision"], "authors": ["Ahmed A Aly", "Joanne Bechta Dugan"], "authorids": ["aaa2cn@virginia.edu", "jbd@virginia.edu"]}, "tags": [], "invitation": {"id": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "rdate": null, "ddate": null, "expdate": 1541175629000, "duedate": null, "tmdate": 1541177635767, "tddate": null, "super": null, "final": null, "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": {"values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Conference/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Conference Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": [], "noninvitees": [], "writers": ["ICLR.cc/2018/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1541177635767}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642386395, "tcdate": 1511695071005, "number": 1, "cdate": 1511695071005, "id": "S1w1mX_xG", "invitation": "ICLR.cc/2018/Conference/-/Paper1126/Official_Review", "forum": "H1BHbmWCZ", "replyto": "H1BHbmWCZ", "signatures": ["ICLR.cc/2018/Conference/Paper1126/AnonReviewer1"], "readers": ["everyone"], "content": {"title": "Nothing new", "rating": "3: Clear rejection", "review": "The paper is motivated with building robots that learn in an open-ended way, which is really interesting. What it actually investigates is the performance of existing image classifiers and object detectors. I could not find any technical contribution or something sufficiently mature and interesting for presenting in ICLR.\n\nSome issues:\n- submission is supposed to be double blind but authors reveal their identity at the start of section 2.1.\n- implementation details all over the place (section 3. is called \"Implementation\", but at that point no concrete idea has been proposed, so it seems too early for talking about tensorflow and keras).\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "TOWARDS ROBOT VISION MODULE DEVELOPMENT WITH EXPERIENTIAL ROBOT LEARNING", "abstract": "n this paper we present a thrust in three directions of visual development us- ing supervised and semi-supervised techniques. The first is an implementation of semi-supervised object detection and recognition using the principles of Soft At- tention and Generative Adversarial Networks (GANs). The second and the third are supervised networks that learn basic concepts of spatial locality and quantity respectively using Convolutional Neural Networks (CNNs). The three thrusts to- gether are based on the approach of Experiential Robot Learning, introduced in previous publication. While the results are unripe for implementation, we believe they constitute a stepping stone towards autonomous development of robotic vi- sual modules.", "pdf": "/pdf/00e5c4aefc80d0396ee745c032d27e0bccb43079.pdf", "TL;DR": "3 thrusts serving as stepping stones for robot experiential learning of vision module", "paperhash": "aly|towards_robot_vision_module_development_with_experiential_robot_learning", "_bibtex": "@misc{\na2018towards,\ntitle={{TOWARDS} {ROBOT} {VISION} {MODULE} {DEVELOPMENT} {WITH} {EXPERIENTIAL} {ROBOT} {LEARNING}},\nauthor={Ahmed A Aly and Joanne Bechta Dugan},\nyear={2018},\nurl={https://openreview.net/forum?id=H1BHbmWCZ},\n}", "keywords": ["Deep Learning", "Robotics", "Artificial Intelligence", "Computer Vision"], "authors": ["Ahmed A Aly", "Joanne Bechta Dugan"], "authorids": ["aaa2cn@virginia.edu", "jbd@virginia.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642386306, "id": "ICLR.cc/2018/Conference/-/Paper1126/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper1126/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper1126/AnonReviewer1", "ICLR.cc/2018/Conference/Paper1126/AnonReviewer3", "ICLR.cc/2018/Conference/Paper1126/AnonReviewer2"], "reply": {"forum": "H1BHbmWCZ", "replyto": "H1BHbmWCZ", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper1126/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642386306}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642386358, "tcdate": 1511794958460, "number": 2, "cdate": 1511794958460, "id": "B1IfKjYgM", "invitation": "ICLR.cc/2018/Conference/-/Paper1126/Official_Review", "forum": "H1BHbmWCZ", "replyto": "H1BHbmWCZ", "signatures": ["ICLR.cc/2018/Conference/Paper1126/AnonReviewer3"], "readers": ["everyone"], "content": {"title": "Random ideas about object detection with poor discussion", "rating": "2: Strong rejection", "review": "This work explores some approaches in the object detection field of computer vision: (a) a soft attention map based on the activations on convolutional layers, (b) a classification regarding the location of an object in a 3x3 grid over the image, (c) an autoencoder that the authors claim to be aware of the multiple object instances in the image. These three proposals are presented in a framework of a robot vision module, although neither the experiments nor the dataset correspond to this domain.\n\nFrom my perspective, the work is very immature and seems away from current state of the art on object detection, both in the vocabulary, performance or challenges. The proposed techniques are assessed in a dataset which is not described and whose results are not compared with any other technique. This important flaw in the evaluation prevents any fair comparison with the state of the art.\n\nThe text is also difficult to follow. The three contributions seem disconnected and could have been presented in separate works with a more deeper discussion. In particular, I have serious problems understanding:\n\n1. What is exactly the contribution of the CNN pre-trained with IMageNet when learning the soft-attention maps ? The reference to a GAN architecture seems very forced and out of the scope.\n\n2. What is the interest of the localization network ? The task it addresses seems very simple and in any case it requires a manual annotation of a dataset of objects in each of the predefined locations in the 3x3 grid.\n\n3. The authors talk about an autoencoder architecture, but also on a classification network where the labels correspond to the object count. I could not undertstand what is exactly assessed in this section.\n\nFinally, the authors violate the double-bind review policy by clearly referring to their previous work on Experiental Robot Learning.\n\nI would encourage the authors to focus in one of the research lines they point in the paper and go deeper into it, with a clear understanding of the state of the art and the specific challenges these state of the art techniques may encounter in the case of robotic vision.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "TOWARDS ROBOT VISION MODULE DEVELOPMENT WITH EXPERIENTIAL ROBOT LEARNING", "abstract": "n this paper we present a thrust in three directions of visual development us- ing supervised and semi-supervised techniques. The first is an implementation of semi-supervised object detection and recognition using the principles of Soft At- tention and Generative Adversarial Networks (GANs). The second and the third are supervised networks that learn basic concepts of spatial locality and quantity respectively using Convolutional Neural Networks (CNNs). The three thrusts to- gether are based on the approach of Experiential Robot Learning, introduced in previous publication. While the results are unripe for implementation, we believe they constitute a stepping stone towards autonomous development of robotic vi- sual modules.", "pdf": "/pdf/00e5c4aefc80d0396ee745c032d27e0bccb43079.pdf", "TL;DR": "3 thrusts serving as stepping stones for robot experiential learning of vision module", "paperhash": "aly|towards_robot_vision_module_development_with_experiential_robot_learning", "_bibtex": "@misc{\na2018towards,\ntitle={{TOWARDS} {ROBOT} {VISION} {MODULE} {DEVELOPMENT} {WITH} {EXPERIENTIAL} {ROBOT} {LEARNING}},\nauthor={Ahmed A Aly and Joanne Bechta Dugan},\nyear={2018},\nurl={https://openreview.net/forum?id=H1BHbmWCZ},\n}", "keywords": ["Deep Learning", "Robotics", "Artificial Intelligence", "Computer Vision"], "authors": ["Ahmed A Aly", "Joanne Bechta Dugan"], "authorids": ["aaa2cn@virginia.edu", "jbd@virginia.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642386306, "id": "ICLR.cc/2018/Conference/-/Paper1126/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper1126/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper1126/AnonReviewer1", "ICLR.cc/2018/Conference/Paper1126/AnonReviewer3", "ICLR.cc/2018/Conference/Paper1126/AnonReviewer2"], "reply": {"forum": "H1BHbmWCZ", "replyto": "H1BHbmWCZ", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper1126/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642386306}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642386323, "tcdate": 1511976859203, "number": 3, "cdate": 1511976859203, "id": "B1XsJ_3lf", "invitation": "ICLR.cc/2018/Conference/-/Paper1126/Official_Review", "forum": "H1BHbmWCZ", "replyto": "H1BHbmWCZ", "signatures": ["ICLR.cc/2018/Conference/Paper1126/AnonReviewer2"], "readers": ["everyone"], "content": {"title": "Paper violates double bind", "rating": "2: Strong rejection", "review": "The authors disclosed their identity and violated the terms of double blind reviews.\nPage 2 \"In our previous work (Aly & Dugan, 2017)\n\nAlso the page 1 is full of typos and hard to read.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "TOWARDS ROBOT VISION MODULE DEVELOPMENT WITH EXPERIENTIAL ROBOT LEARNING", "abstract": "n this paper we present a thrust in three directions of visual development us- ing supervised and semi-supervised techniques. The first is an implementation of semi-supervised object detection and recognition using the principles of Soft At- tention and Generative Adversarial Networks (GANs). The second and the third are supervised networks that learn basic concepts of spatial locality and quantity respectively using Convolutional Neural Networks (CNNs). The three thrusts to- gether are based on the approach of Experiential Robot Learning, introduced in previous publication. While the results are unripe for implementation, we believe they constitute a stepping stone towards autonomous development of robotic vi- sual modules.", "pdf": "/pdf/00e5c4aefc80d0396ee745c032d27e0bccb43079.pdf", "TL;DR": "3 thrusts serving as stepping stones for robot experiential learning of vision module", "paperhash": "aly|towards_robot_vision_module_development_with_experiential_robot_learning", "_bibtex": "@misc{\na2018towards,\ntitle={{TOWARDS} {ROBOT} {VISION} {MODULE} {DEVELOPMENT} {WITH} {EXPERIENTIAL} {ROBOT} {LEARNING}},\nauthor={Ahmed A Aly and Joanne Bechta Dugan},\nyear={2018},\nurl={https://openreview.net/forum?id=H1BHbmWCZ},\n}", "keywords": ["Deep Learning", "Robotics", "Artificial Intelligence", "Computer Vision"], "authors": ["Ahmed A Aly", "Joanne Bechta Dugan"], "authorids": ["aaa2cn@virginia.edu", "jbd@virginia.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642386306, "id": "ICLR.cc/2018/Conference/-/Paper1126/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper1126/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper1126/AnonReviewer1", "ICLR.cc/2018/Conference/Paper1126/AnonReviewer3", "ICLR.cc/2018/Conference/Paper1126/AnonReviewer2"], "reply": {"forum": "H1BHbmWCZ", "replyto": "H1BHbmWCZ", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper1126/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642386306}}}], "count": 5}