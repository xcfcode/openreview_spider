{"notes": [{"id": "1GTma8HwlYp", "original": "9NAVvcF1f5", "number": 2750, "cdate": 1601308304953, "ddate": null, "tcdate": 1601308304953, "tmdate": 1615764193479, "tddate": null, "forum": "1GTma8HwlYp", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "AUXILIARY TASK UPDATE DECOMPOSITION: THE GOOD, THE BAD AND THE NEUTRAL", "authorids": ["~Lucio_M._Dery1", "~Yann_Dauphin1", "~David_Grangier1"], "authors": ["Lucio M. Dery", "Yann Dauphin", "David Grangier"], "keywords": ["pre-training", "multitask learning", "deeplearning", "gradient decomposition"], "abstract": "While deep learning has been very beneficial in data-rich settings, tasks with smaller training set\noften resort to pre-training or multitask learning to leverage data from other tasks. In this case,\ncareful consideration is needed to select tasks and model parameterizations such that updates from\nthe auxiliary tasks actually help the primary task. We seek to alleviate this burden by formulating a model-agnostic framework that performs fine-grained manipulation of the auxiliary task gradients. We propose to decompose auxiliary updates into directions which help, damage or leave the primary task loss unchanged. This allows weighting the update directions \ndifferently depending on their impact on the problem of interest. We present a novel and efficient algorithm for that\npurpose and show its advantage in practice. Our method leverages efficient automatic differentiation \nprocedures and randomized singular value decomposition for scalability. We show that our framework is \ngeneric and encompasses some prior work as particular cases. Our approach consistently outperforms strong and widely used baselines when leveraging out-of-distribution data for Text and Image classification tasks.", "one-sentence_summary": "We improve how we use auxiliary task data for model pre-training by decomposing gradient updates into components guided by the primary task", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dery|auxiliary_task_update_decomposition_the_good_the_bad_and_the_neutral", "supplementary_material": "/attachment/0f0d441cd3fd43ccb236d60f9e2f0bb5385e32ff.zip", "pdf": "/pdf/abc70350e11147c46076e6b97c615c42e2ab46d5.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ndery2021auxiliary,\ntitle={{\\{}AUXILIARY{\\}} {\\{}TASK{\\}} {\\{}UPDATE{\\}} {\\{}DECOMPOSITION{\\}}: {\\{}THE{\\}} {\\{}GOOD{\\}}, {\\{}THE{\\}} {\\{}BAD{\\}} {\\{}AND{\\}} {\\{}THE{\\}} {\\{}NEUTRAL{\\}}},\nauthor={Lucio M. Dery and Yann Dauphin and David Grangier},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=1GTma8HwlYp}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 12, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "RSvLhREmBG", "original": null, "number": 1, "cdate": 1610040490928, "ddate": null, "tcdate": 1610040490928, "tmdate": 1610474096805, "tddate": null, "forum": "1GTma8HwlYp", "replyto": "1GTma8HwlYp", "invitation": "ICLR.cc/2021/Conference/Paper2750/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Poster)", "comment": "After engaging in some good interactive discussions all but one reviewer settled on a rating of marginal accept. The most negative reviewer didn't really provide a clear enough explanation of what was lacking in the work. The other reviewers felt that the observed gains for this multi-task learning framework were clear enough that the work is worthy of some attention by the community. The AC recommends acceptance, but one may consider this recommendation as a just past the line for acceptance recommendation."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AUXILIARY TASK UPDATE DECOMPOSITION: THE GOOD, THE BAD AND THE NEUTRAL", "authorids": ["~Lucio_M._Dery1", "~Yann_Dauphin1", "~David_Grangier1"], "authors": ["Lucio M. Dery", "Yann Dauphin", "David Grangier"], "keywords": ["pre-training", "multitask learning", "deeplearning", "gradient decomposition"], "abstract": "While deep learning has been very beneficial in data-rich settings, tasks with smaller training set\noften resort to pre-training or multitask learning to leverage data from other tasks. In this case,\ncareful consideration is needed to select tasks and model parameterizations such that updates from\nthe auxiliary tasks actually help the primary task. We seek to alleviate this burden by formulating a model-agnostic framework that performs fine-grained manipulation of the auxiliary task gradients. We propose to decompose auxiliary updates into directions which help, damage or leave the primary task loss unchanged. This allows weighting the update directions \ndifferently depending on their impact on the problem of interest. We present a novel and efficient algorithm for that\npurpose and show its advantage in practice. Our method leverages efficient automatic differentiation \nprocedures and randomized singular value decomposition for scalability. We show that our framework is \ngeneric and encompasses some prior work as particular cases. Our approach consistently outperforms strong and widely used baselines when leveraging out-of-distribution data for Text and Image classification tasks.", "one-sentence_summary": "We improve how we use auxiliary task data for model pre-training by decomposing gradient updates into components guided by the primary task", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dery|auxiliary_task_update_decomposition_the_good_the_bad_and_the_neutral", "supplementary_material": "/attachment/0f0d441cd3fd43ccb236d60f9e2f0bb5385e32ff.zip", "pdf": "/pdf/abc70350e11147c46076e6b97c615c42e2ab46d5.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ndery2021auxiliary,\ntitle={{\\{}AUXILIARY{\\}} {\\{}TASK{\\}} {\\{}UPDATE{\\}} {\\{}DECOMPOSITION{\\}}: {\\{}THE{\\}} {\\{}GOOD{\\}}, {\\{}THE{\\}} {\\{}BAD{\\}} {\\{}AND{\\}} {\\{}THE{\\}} {\\{}NEUTRAL{\\}}},\nauthor={Lucio M. Dery and Yann Dauphin and David Grangier},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=1GTma8HwlYp}\n}"}, "tags": [], "invitation": {"reply": {"forum": "1GTma8HwlYp", "replyto": "1GTma8HwlYp", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040490914, "tmdate": 1610474096789, "id": "ICLR.cc/2021/Conference/Paper2750/-/Decision"}}}, {"id": "9fXahovi5GL", "original": null, "number": 2, "cdate": 1603879534071, "ddate": null, "tcdate": 1603879534071, "tmdate": 1607272217089, "tddate": null, "forum": "1GTma8HwlYp", "replyto": "1GTma8HwlYp", "invitation": "ICLR.cc/2021/Conference/Paper2750/-/Official_Review", "content": {"title": "A simple yet insightful idea is implemented while the experiments might not demonstrate the algorithm's full potential.", "review": "The work studies the auxiliary task selection in deep learning to resolve the burden of selecting relevant tasks for pre-training or the multitask learning. By decomposing the auxiliary updates, one can reweight separately the beneficial and harmful directions so that the net contribution to the update of the primary task is always positive. The efficient implementation is experimented in text classification, image classification, and medical imaging transfer tasks.\n\nThe first contribution is the decomposition algorithm and reweighting of the auxiliary updates. It is a simple idea with a nice insight of treating the primary task and the auxiliary tasks in different manners. The decomposition allows a reweighting on the updates to optimize the primary task as much as possible while keeping the auxiliary tasks providing improvable directions. The second contribution is an efficient mechanism to approximate and calculate the SVD of the Jacobian of the primary task. The mechanism is implemented from an existing randomized approximation method. The third contribution is a set of experiments verifying the proposed method. The experiments include text classification, image classification, and medical imaging transfer tasks. The most salient result is the 99% data efficiency to achieve improvable performance in the medical imaging transfer task.\n\nConcerns\n\nBesides the above positive contributions, following are some concerns from the observations:\n\n1. The relative improvements comparing to the baselines in Table 1 and Table 2 do not seem as much as that in (Gururangan et al. 2020) and (Yu et al., 2020), respectively. \n\n2. The weights reported in the experiments are 1 or -1 in the experiments. For instance, \\eta_aux = (1, 1, -1) is reported in the image classification task.\n\nThe reader would expect much better improvements when given the freedom to reassign the weights on the decomposed directions, especially when the harmful part has a negated weight. Moreover, why are the values chosen in \\eta 1 or -1? Would there be a nicer balance between, say, the beneficial and the harmful parts? For instance, would \\eta = (1, 0.8, -0.9) be a better choice? It would be crucial that the authors can explain furthermore or support further experiments to confirm whether the potential of this decomposition algorithm is fully demonstrated or not.\n\n\n=====================\n\nPost Rebuttal\n\nI have read the authors' response. All my concerns are addressed properly. However, I still doubt that even the corner cases of \\eta have a better performance, would there be a systematic way to find the optimal parameters reflecting the true potential of this method. Thus, I will keep my score unchanged.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2750/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2750/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AUXILIARY TASK UPDATE DECOMPOSITION: THE GOOD, THE BAD AND THE NEUTRAL", "authorids": ["~Lucio_M._Dery1", "~Yann_Dauphin1", "~David_Grangier1"], "authors": ["Lucio M. Dery", "Yann Dauphin", "David Grangier"], "keywords": ["pre-training", "multitask learning", "deeplearning", "gradient decomposition"], "abstract": "While deep learning has been very beneficial in data-rich settings, tasks with smaller training set\noften resort to pre-training or multitask learning to leverage data from other tasks. In this case,\ncareful consideration is needed to select tasks and model parameterizations such that updates from\nthe auxiliary tasks actually help the primary task. We seek to alleviate this burden by formulating a model-agnostic framework that performs fine-grained manipulation of the auxiliary task gradients. We propose to decompose auxiliary updates into directions which help, damage or leave the primary task loss unchanged. This allows weighting the update directions \ndifferently depending on their impact on the problem of interest. We present a novel and efficient algorithm for that\npurpose and show its advantage in practice. Our method leverages efficient automatic differentiation \nprocedures and randomized singular value decomposition for scalability. We show that our framework is \ngeneric and encompasses some prior work as particular cases. Our approach consistently outperforms strong and widely used baselines when leveraging out-of-distribution data for Text and Image classification tasks.", "one-sentence_summary": "We improve how we use auxiliary task data for model pre-training by decomposing gradient updates into components guided by the primary task", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dery|auxiliary_task_update_decomposition_the_good_the_bad_and_the_neutral", "supplementary_material": "/attachment/0f0d441cd3fd43ccb236d60f9e2f0bb5385e32ff.zip", "pdf": "/pdf/abc70350e11147c46076e6b97c615c42e2ab46d5.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ndery2021auxiliary,\ntitle={{\\{}AUXILIARY{\\}} {\\{}TASK{\\}} {\\{}UPDATE{\\}} {\\{}DECOMPOSITION{\\}}: {\\{}THE{\\}} {\\{}GOOD{\\}}, {\\{}THE{\\}} {\\{}BAD{\\}} {\\{}AND{\\}} {\\{}THE{\\}} {\\{}NEUTRAL{\\}}},\nauthor={Lucio M. Dery and Yann Dauphin and David Grangier},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=1GTma8HwlYp}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "1GTma8HwlYp", "replyto": "1GTma8HwlYp", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2750/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538089426, "tmdate": 1606915797704, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2750/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2750/-/Official_Review"}}}, {"id": "aI_k3y3S0yt", "original": null, "number": 1, "cdate": 1603762355768, "ddate": null, "tcdate": 1603762355768, "tmdate": 1606340487560, "tddate": null, "forum": "1GTma8HwlYp", "replyto": "1GTma8HwlYp", "invitation": "ICLR.cc/2021/Conference/Paper2750/-/Official_Review", "content": {"title": "Interesting idea, but questionable experimental setting", "review": "[Summary] This paper studies auxiliary learning, and propose a decomposition method on the auxiliary gradient into several components, and to select relevant/useful decomposed gradients to maximize the assistance of the primary task.\n\n[Strength] How to adjust auxiliary tasks in a beneficial way is always a challenging problem in multi-task learning. The proposed solution on gradient decomposition is novel and interesting. The improved performance based on the proposed method seems to be non-trivial.\n\n[Weakness] This paper however has some significant weaknesses which I will outline below.\n-- Missing details. The subspace of the primary task gradient is composed of all training samples in the primary task, based on the definition of $\\mathcal{S}$. However, for any reasonable-size training dataset which contains at least 10k training samples, this process seems to be extremely expensive to compute? The authors have introduced randomised approximation on decomposition step, but accumulate gradients seem to be already taking a lot of computation. I hope the authors could justify this.\n\n-- Unfair experimental setting. My biggest concern is on hyper-parameter tuning on each component of the decomposed auxiliary task gradient. In Eq. 1, the authors decompose each auxiliary task gradient into three components: i) one is lying in the subspace of primary task gradient, ii) one is orthogonal to the primary task gradient ii) the final one is in conflict to the primary task gradient. By selecting different weightings on each component, the authors claim that this formulation can be degraded into prior auxiliary learning methods. I agree that this formulation is general. However, all of these component weightings are selected by hand, and seem to be very different across different datasets and tasks. \n\nThis gives a very unfair comparison to previous methods, simply because these methods are included in one of the hyper-parameter sets of corresponding weighting values. I have noticed that the authors have constrained the search space into 4 sets of weighting, but this does not justify this problem. Ideally, these weighting should be automatically computed during training, and varied based on the dataset.\n\nIn addition, the weighting for the primary task also varies across different datasets. So I am wondering whether these task weightings are consistent in baselines, and did authors perform a similar hyper-parameter search on baseline methods as well?\n\nOther minor issues:\nThis formulation *cannot* be used as pre-training with only auxiliary gradients which are helpful to the primary task, since we do not know the primary task gradient beforehand. Even we know the primary task gradient, (0, 1, 0) is simply putting more weighting on the existing primary task gradient, so it's the same as to tune up the learning rate.\n\n=======================\n\nRated up after authors' clarification.", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper2750/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2750/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AUXILIARY TASK UPDATE DECOMPOSITION: THE GOOD, THE BAD AND THE NEUTRAL", "authorids": ["~Lucio_M._Dery1", "~Yann_Dauphin1", "~David_Grangier1"], "authors": ["Lucio M. Dery", "Yann Dauphin", "David Grangier"], "keywords": ["pre-training", "multitask learning", "deeplearning", "gradient decomposition"], "abstract": "While deep learning has been very beneficial in data-rich settings, tasks with smaller training set\noften resort to pre-training or multitask learning to leverage data from other tasks. In this case,\ncareful consideration is needed to select tasks and model parameterizations such that updates from\nthe auxiliary tasks actually help the primary task. We seek to alleviate this burden by formulating a model-agnostic framework that performs fine-grained manipulation of the auxiliary task gradients. We propose to decompose auxiliary updates into directions which help, damage or leave the primary task loss unchanged. This allows weighting the update directions \ndifferently depending on their impact on the problem of interest. We present a novel and efficient algorithm for that\npurpose and show its advantage in practice. Our method leverages efficient automatic differentiation \nprocedures and randomized singular value decomposition for scalability. We show that our framework is \ngeneric and encompasses some prior work as particular cases. Our approach consistently outperforms strong and widely used baselines when leveraging out-of-distribution data for Text and Image classification tasks.", "one-sentence_summary": "We improve how we use auxiliary task data for model pre-training by decomposing gradient updates into components guided by the primary task", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dery|auxiliary_task_update_decomposition_the_good_the_bad_and_the_neutral", "supplementary_material": "/attachment/0f0d441cd3fd43ccb236d60f9e2f0bb5385e32ff.zip", "pdf": "/pdf/abc70350e11147c46076e6b97c615c42e2ab46d5.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ndery2021auxiliary,\ntitle={{\\{}AUXILIARY{\\}} {\\{}TASK{\\}} {\\{}UPDATE{\\}} {\\{}DECOMPOSITION{\\}}: {\\{}THE{\\}} {\\{}GOOD{\\}}, {\\{}THE{\\}} {\\{}BAD{\\}} {\\{}AND{\\}} {\\{}THE{\\}} {\\{}NEUTRAL{\\}}},\nauthor={Lucio M. Dery and Yann Dauphin and David Grangier},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=1GTma8HwlYp}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "1GTma8HwlYp", "replyto": "1GTma8HwlYp", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2750/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538089426, "tmdate": 1606915797704, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2750/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2750/-/Official_Review"}}}, {"id": "oXs6XuKEpG8", "original": null, "number": 8, "cdate": 1605820381973, "ddate": null, "tcdate": 1605820381973, "tmdate": 1605820381973, "tddate": null, "forum": "1GTma8HwlYp", "replyto": "qciojB2hIL8", "invitation": "ICLR.cc/2021/Conference/Paper2750/-/Official_Comment", "content": {"title": "Response to clarification", "comment": "\u201cBut since PCGrad is having a fixed set of auxiliary weightings, I think it would be unfair to compare it with non-fixed auxiliary weightings from your formulation.\u201d - Thank you for your clarification. Please note that whilst it might appear that for PCGrad  $\\alpha_{aux}$ is fixed, it actually is not. Given the relationship \n\n$(\\alpha_{prim} \\cdot g_{prim} +   \\alpha_{aux} \\cdot g_{aux}^{\\perp} +  \\alpha_{aux} \\cdot g_{aux}^{+})$\n\nwe can reduce this to :\n\n$\\alpha_{aux}  \\big(  (\\frac{ \\alpha_{prim}}{\\alpha_{aux}} ) \\cdot g_{prim} +   g_{aux}^{\\perp} +  g_{aux}^{+} \\big) $\n\nNote that re-writing this way reveals that we can have 1 degree of freedom - the ratio $\\frac{\\alpha_{prim} }{\\alpha_{aux}}$ and we can massage $\\alpha_{aux}$ into a scaling of the learning rate.  We note that in our Common Concerns section, we mention that we cross validated more values of $\\alpha_{prim}$ for PCGrad : {0.1, 0.05, 0.01, 0.001} than for ATTITUD. Combining these parameters with other hyper-parameters means we actually give a higher hyper-parameter budget to PCGrad than ATTITUD overall. We mention this in Section 5 of the revised paper : \u201ce.g. for Cifar10-Cat-vs-Dog, we ran a grid search with 16 configurations for regular pretraining, 16 configurations for PCGrad and 12 configurations for ATTITUD\u201d  \n\n\n\u201cFurther clarification to the last comment\u201d - Thank you for the clarification on this comment. To show that we now understand you better, we restate your claim - The (0, 1, 0) configuration reduces to \u201c ... just training the primary task as itself with a different learning rate\u201d. We note that this is not exactly correct. The configuration (0, 1, 0) is actually doing more than a simple weighting of the whole primary task gradient. It is upweighting only specific parts of the primary task gradients that agree with the auxiliary task. It only reduces to a simple upweighting of the whole primary task gradient if all the primary task gradient directions agree with that of the auxiliary task.  For example, assume our primary task decomposes to [1, 1, -1]. Naive upweighting the primary task gradient corresponds to a * [1, 1, -1] = [a, a, -a], where a > 1.0, which is equivalent to changing the learning rate. When we have an auxiliary task decomposition of [-1, 1, -1], this results in a final decomposition result of [0, 1, -1] under the \\eta_{aux} choice of (0, 1, 0). Note that the first component has been completely removed, and not just weighed up. Thus, (0, 1, 0) isn\u2019t just upweighting the whole primary task gradient, it is rather selecting the parts of the primary task gradient that agree with the auxiliary task gradient. This can be viewed as \u201creinforcing\u201d directions that are mutually agreeable to both primary and auxiliary tasks - thus, this can prevent the traditional over-fitting associated with descent on the primary task alone (since we now only descend on directions with evidence from another task of being a 'good' direction of descent).\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2750/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2750/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AUXILIARY TASK UPDATE DECOMPOSITION: THE GOOD, THE BAD AND THE NEUTRAL", "authorids": ["~Lucio_M._Dery1", "~Yann_Dauphin1", "~David_Grangier1"], "authors": ["Lucio M. Dery", "Yann Dauphin", "David Grangier"], "keywords": ["pre-training", "multitask learning", "deeplearning", "gradient decomposition"], "abstract": "While deep learning has been very beneficial in data-rich settings, tasks with smaller training set\noften resort to pre-training or multitask learning to leverage data from other tasks. In this case,\ncareful consideration is needed to select tasks and model parameterizations such that updates from\nthe auxiliary tasks actually help the primary task. We seek to alleviate this burden by formulating a model-agnostic framework that performs fine-grained manipulation of the auxiliary task gradients. We propose to decompose auxiliary updates into directions which help, damage or leave the primary task loss unchanged. This allows weighting the update directions \ndifferently depending on their impact on the problem of interest. We present a novel and efficient algorithm for that\npurpose and show its advantage in practice. Our method leverages efficient automatic differentiation \nprocedures and randomized singular value decomposition for scalability. We show that our framework is \ngeneric and encompasses some prior work as particular cases. Our approach consistently outperforms strong and widely used baselines when leveraging out-of-distribution data for Text and Image classification tasks.", "one-sentence_summary": "We improve how we use auxiliary task data for model pre-training by decomposing gradient updates into components guided by the primary task", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dery|auxiliary_task_update_decomposition_the_good_the_bad_and_the_neutral", "supplementary_material": "/attachment/0f0d441cd3fd43ccb236d60f9e2f0bb5385e32ff.zip", "pdf": "/pdf/abc70350e11147c46076e6b97c615c42e2ab46d5.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ndery2021auxiliary,\ntitle={{\\{}AUXILIARY{\\}} {\\{}TASK{\\}} {\\{}UPDATE{\\}} {\\{}DECOMPOSITION{\\}}: {\\{}THE{\\}} {\\{}GOOD{\\}}, {\\{}THE{\\}} {\\{}BAD{\\}} {\\{}AND{\\}} {\\{}THE{\\}} {\\{}NEUTRAL{\\}}},\nauthor={Lucio M. Dery and Yann Dauphin and David Grangier},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=1GTma8HwlYp}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "1GTma8HwlYp", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2750/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2750/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2750/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2750/Authors|ICLR.cc/2021/Conference/Paper2750/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2750/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923844866, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2750/-/Official_Comment"}}}, {"id": "qciojB2hIL8", "original": null, "number": 7, "cdate": 1605715582175, "ddate": null, "tcdate": 1605715582175, "tmdate": 1605715582175, "tddate": null, "forum": "1GTma8HwlYp", "replyto": "CnFSU5MBZD", "invitation": "ICLR.cc/2021/Conference/Paper2750/-/Official_Comment", "content": {"title": "Clarification", "comment": "Thanks for your detailed feedback and comments. Since they are still some confusion here, let me further clarify my concerns.\n\n-- Fair Comparison to PCGrad. At the end of section 3, you have mentioned that PCGrad is one specific case under your general formulation, by setting $\\eta_{aux} = (\\alpha_{aux}, \\alpha_{aux}, 0.0)$, which I agree. But when $\\alpha_{aux} = 1.0$, PCGrad would be included as one of your 4 hyper-parameter sets in your evaluation, for which then of cause your method would out-perform it, since you can easily search a better weighting for $\\alpha_{aux}$. I am not questioning the novelty of formulation. But since PCGrad is having a fixed set of auxiliary weightings, I think it would be unfair to compare it with non-fixed auxiliary weightings from your formulation.\n\n--  Further clarification to the last comment. We are not able to compute the gradient of the primary task, since the primary task is not used during auxiliary task pre-training. Even if you still compute the primary task gradient (not updating it by setting primary task weighting as zero), we only preserve the auxiliary gradient with the same descent direction from the primary task, then this is equivalent to just training the primary task as itself, with a different learning rate (1.0 in your case).\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2750/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2750/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AUXILIARY TASK UPDATE DECOMPOSITION: THE GOOD, THE BAD AND THE NEUTRAL", "authorids": ["~Lucio_M._Dery1", "~Yann_Dauphin1", "~David_Grangier1"], "authors": ["Lucio M. Dery", "Yann Dauphin", "David Grangier"], "keywords": ["pre-training", "multitask learning", "deeplearning", "gradient decomposition"], "abstract": "While deep learning has been very beneficial in data-rich settings, tasks with smaller training set\noften resort to pre-training or multitask learning to leverage data from other tasks. In this case,\ncareful consideration is needed to select tasks and model parameterizations such that updates from\nthe auxiliary tasks actually help the primary task. We seek to alleviate this burden by formulating a model-agnostic framework that performs fine-grained manipulation of the auxiliary task gradients. We propose to decompose auxiliary updates into directions which help, damage or leave the primary task loss unchanged. This allows weighting the update directions \ndifferently depending on their impact on the problem of interest. We present a novel and efficient algorithm for that\npurpose and show its advantage in practice. Our method leverages efficient automatic differentiation \nprocedures and randomized singular value decomposition for scalability. We show that our framework is \ngeneric and encompasses some prior work as particular cases. Our approach consistently outperforms strong and widely used baselines when leveraging out-of-distribution data for Text and Image classification tasks.", "one-sentence_summary": "We improve how we use auxiliary task data for model pre-training by decomposing gradient updates into components guided by the primary task", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dery|auxiliary_task_update_decomposition_the_good_the_bad_and_the_neutral", "supplementary_material": "/attachment/0f0d441cd3fd43ccb236d60f9e2f0bb5385e32ff.zip", "pdf": "/pdf/abc70350e11147c46076e6b97c615c42e2ab46d5.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ndery2021auxiliary,\ntitle={{\\{}AUXILIARY{\\}} {\\{}TASK{\\}} {\\{}UPDATE{\\}} {\\{}DECOMPOSITION{\\}}: {\\{}THE{\\}} {\\{}GOOD{\\}}, {\\{}THE{\\}} {\\{}BAD{\\}} {\\{}AND{\\}} {\\{}THE{\\}} {\\{}NEUTRAL{\\}}},\nauthor={Lucio M. Dery and Yann Dauphin and David Grangier},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=1GTma8HwlYp}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "1GTma8HwlYp", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2750/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2750/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2750/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2750/Authors|ICLR.cc/2021/Conference/Paper2750/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2750/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923844866, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2750/-/Official_Comment"}}}, {"id": "CnFSU5MBZD", "original": null, "number": 6, "cdate": 1605642223903, "ddate": null, "tcdate": 1605642223903, "tmdate": 1605642223903, "tddate": null, "forum": "1GTma8HwlYp", "replyto": "aI_k3y3S0yt", "invitation": "ICLR.cc/2021/Conference/Paper2750/-/Official_Comment", "content": {"title": "Addressing AnonReviewer2 Concerns", "comment": "We express our gratitude for providing feedback on our paper. We address your comments below. \n\n\u201cThis gives a very unfair comparison to previous methods, simply because these methods are included in one of the hyper-parameter sets of corresponding weighting values\u201d -> This is inaccurate because we never report weight value configurations corresponding to baselines as our method in the paper. Note that for MultiCifar100 and Cat-vs-Dog, (where we compare against PCGrad) we report in Section 6 the best performing configurations as (1, 1, -1)  and (1, 0, 0) respectively. These configurations are novel under our formulation and so we are not simply reporting a setting of PCGrad as our optimal value. Sorry for the confusion, we have updated Section 5 to make this clearer.\n\n\u201cThe subspace of the primary task gradient is composed of all training samples in the primary task, based on the definition of S\u201d - > We do not use all the available examples to estimate the subspace but rather a mini-batch of samples, since as you rightly pointed out, this would present a significant computational burden. We mention this in Section 4 under implementation \u201cAs stochastic optimization is prevalent in this setting, we construct subspace S from a mini-batch of primary task data\u201d\n\n\u201cIdeally, these weighting should be automatically computed during training, and varied based on the dataset.\u201d ->  We agree that this would be the ideal setting. We decide to leave this as future work because automatic hyper-parameter selection is a challenging problem on its own. We however provide 4 hyper-parameter configurations that perform well across a reasonable set of tasks as guidance for practitioners.\n\n\u201cThis formulation cannot be used as pre-training with only auxiliary gradients which are helpful to the primary task, since we do not know the primary task gradient beforehand. Even we know the primary task gradient, (0, 1, 0) is simply putting more weighting on the existing primary task gradient, so it's the same as tuning up the learning rate\u201d -> We would like to request further clarification on this point. Please note that our formulation relies on the fact that the primary task is known beforehand and thus cases where the primary task is unknown are outside the scope of our work\n\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2750/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2750/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AUXILIARY TASK UPDATE DECOMPOSITION: THE GOOD, THE BAD AND THE NEUTRAL", "authorids": ["~Lucio_M._Dery1", "~Yann_Dauphin1", "~David_Grangier1"], "authors": ["Lucio M. Dery", "Yann Dauphin", "David Grangier"], "keywords": ["pre-training", "multitask learning", "deeplearning", "gradient decomposition"], "abstract": "While deep learning has been very beneficial in data-rich settings, tasks with smaller training set\noften resort to pre-training or multitask learning to leverage data from other tasks. In this case,\ncareful consideration is needed to select tasks and model parameterizations such that updates from\nthe auxiliary tasks actually help the primary task. We seek to alleviate this burden by formulating a model-agnostic framework that performs fine-grained manipulation of the auxiliary task gradients. We propose to decompose auxiliary updates into directions which help, damage or leave the primary task loss unchanged. This allows weighting the update directions \ndifferently depending on their impact on the problem of interest. We present a novel and efficient algorithm for that\npurpose and show its advantage in practice. Our method leverages efficient automatic differentiation \nprocedures and randomized singular value decomposition for scalability. We show that our framework is \ngeneric and encompasses some prior work as particular cases. Our approach consistently outperforms strong and widely used baselines when leveraging out-of-distribution data for Text and Image classification tasks.", "one-sentence_summary": "We improve how we use auxiliary task data for model pre-training by decomposing gradient updates into components guided by the primary task", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dery|auxiliary_task_update_decomposition_the_good_the_bad_and_the_neutral", "supplementary_material": "/attachment/0f0d441cd3fd43ccb236d60f9e2f0bb5385e32ff.zip", "pdf": "/pdf/abc70350e11147c46076e6b97c615c42e2ab46d5.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ndery2021auxiliary,\ntitle={{\\{}AUXILIARY{\\}} {\\{}TASK{\\}} {\\{}UPDATE{\\}} {\\{}DECOMPOSITION{\\}}: {\\{}THE{\\}} {\\{}GOOD{\\}}, {\\{}THE{\\}} {\\{}BAD{\\}} {\\{}AND{\\}} {\\{}THE{\\}} {\\{}NEUTRAL{\\}}},\nauthor={Lucio M. Dery and Yann Dauphin and David Grangier},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=1GTma8HwlYp}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "1GTma8HwlYp", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2750/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2750/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2750/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2750/Authors|ICLR.cc/2021/Conference/Paper2750/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2750/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923844866, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2750/-/Official_Comment"}}}, {"id": "I7viOlzc_-M", "original": null, "number": 5, "cdate": 1605642168949, "ddate": null, "tcdate": 1605642168949, "tmdate": 1605642168949, "tddate": null, "forum": "1GTma8HwlYp", "replyto": "9fXahovi5GL", "invitation": "ICLR.cc/2021/Conference/Paper2750/-/Official_Comment", "content": {"title": "Addressing AnonReviewer3 Concerns", "comment": "Thank you for your helpful feedback on our paper. We would like to address your concerns below. \n\n\u201cThe relative improvements comparing to the baselines in Table 1 and Table 2 do not seem as much as that in (Gururangan et al. 2020) and (Yu et al., 2020), respectively\u201d -> Please see the Comparison to (Gururanga 2020) and (Yue 2020) under Common Concerns. We address this there but please let us know if you would like further clarification \n\n\u201cThe weights reported in the experiments are 1 or -1 in the experiments. For instance, \\eta_aux = (1, 1, -1) is reported in the image classification task \u2026 For instance, would \\eta = (1, 0.8, -0.9) be a better choice?\u201d -> Please see the Hyperparameter Settings under Common Concerns, where we address this. We note that we are happy to include a more granular exploration of \\eta_{aux} in the final version of the paper but as noted widening the search space would mean we allocate a much higher search budget to ATTITUD as opposed to the methods we compare to.  Please let us know if we can provide further clarification. "}, "signatures": ["ICLR.cc/2021/Conference/Paper2750/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2750/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AUXILIARY TASK UPDATE DECOMPOSITION: THE GOOD, THE BAD AND THE NEUTRAL", "authorids": ["~Lucio_M._Dery1", "~Yann_Dauphin1", "~David_Grangier1"], "authors": ["Lucio M. Dery", "Yann Dauphin", "David Grangier"], "keywords": ["pre-training", "multitask learning", "deeplearning", "gradient decomposition"], "abstract": "While deep learning has been very beneficial in data-rich settings, tasks with smaller training set\noften resort to pre-training or multitask learning to leverage data from other tasks. In this case,\ncareful consideration is needed to select tasks and model parameterizations such that updates from\nthe auxiliary tasks actually help the primary task. We seek to alleviate this burden by formulating a model-agnostic framework that performs fine-grained manipulation of the auxiliary task gradients. We propose to decompose auxiliary updates into directions which help, damage or leave the primary task loss unchanged. This allows weighting the update directions \ndifferently depending on their impact on the problem of interest. We present a novel and efficient algorithm for that\npurpose and show its advantage in practice. Our method leverages efficient automatic differentiation \nprocedures and randomized singular value decomposition for scalability. We show that our framework is \ngeneric and encompasses some prior work as particular cases. Our approach consistently outperforms strong and widely used baselines when leveraging out-of-distribution data for Text and Image classification tasks.", "one-sentence_summary": "We improve how we use auxiliary task data for model pre-training by decomposing gradient updates into components guided by the primary task", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dery|auxiliary_task_update_decomposition_the_good_the_bad_and_the_neutral", "supplementary_material": "/attachment/0f0d441cd3fd43ccb236d60f9e2f0bb5385e32ff.zip", "pdf": "/pdf/abc70350e11147c46076e6b97c615c42e2ab46d5.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ndery2021auxiliary,\ntitle={{\\{}AUXILIARY{\\}} {\\{}TASK{\\}} {\\{}UPDATE{\\}} {\\{}DECOMPOSITION{\\}}: {\\{}THE{\\}} {\\{}GOOD{\\}}, {\\{}THE{\\}} {\\{}BAD{\\}} {\\{}AND{\\}} {\\{}THE{\\}} {\\{}NEUTRAL{\\}}},\nauthor={Lucio M. Dery and Yann Dauphin and David Grangier},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=1GTma8HwlYp}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "1GTma8HwlYp", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2750/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2750/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2750/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2750/Authors|ICLR.cc/2021/Conference/Paper2750/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2750/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923844866, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2750/-/Official_Comment"}}}, {"id": "DoxTKl1wckg", "original": null, "number": 4, "cdate": 1605642122600, "ddate": null, "tcdate": 1605642122600, "tmdate": 1605642122600, "tddate": null, "forum": "1GTma8HwlYp", "replyto": "r1CUpI3QzsX", "invitation": "ICLR.cc/2021/Conference/Paper2750/-/Official_Comment", "content": {"title": "Addressing AnonReviewer4 Concerns", "comment": "Thank you for your feedback. You mention that \n\u201cAuthors need to perform more qualitative and quantitative analysis on the datasets to vilify the effectiveness of the proposed methodology.\u201d ->\nWe have a hard time acting on this comment specifically. We would like to highlight that the experimental section already includes results testing how performance degrades in the scenario when the number of samples or the size of the subspace are very small. We also consider how that is affected by being in a low-resource and high-resource regime. We are happy to improve it. It would be helpful if you point at specific weaknesses or aspects we could address or improve.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2750/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2750/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AUXILIARY TASK UPDATE DECOMPOSITION: THE GOOD, THE BAD AND THE NEUTRAL", "authorids": ["~Lucio_M._Dery1", "~Yann_Dauphin1", "~David_Grangier1"], "authors": ["Lucio M. Dery", "Yann Dauphin", "David Grangier"], "keywords": ["pre-training", "multitask learning", "deeplearning", "gradient decomposition"], "abstract": "While deep learning has been very beneficial in data-rich settings, tasks with smaller training set\noften resort to pre-training or multitask learning to leverage data from other tasks. In this case,\ncareful consideration is needed to select tasks and model parameterizations such that updates from\nthe auxiliary tasks actually help the primary task. We seek to alleviate this burden by formulating a model-agnostic framework that performs fine-grained manipulation of the auxiliary task gradients. We propose to decompose auxiliary updates into directions which help, damage or leave the primary task loss unchanged. This allows weighting the update directions \ndifferently depending on their impact on the problem of interest. We present a novel and efficient algorithm for that\npurpose and show its advantage in practice. Our method leverages efficient automatic differentiation \nprocedures and randomized singular value decomposition for scalability. We show that our framework is \ngeneric and encompasses some prior work as particular cases. Our approach consistently outperforms strong and widely used baselines when leveraging out-of-distribution data for Text and Image classification tasks.", "one-sentence_summary": "We improve how we use auxiliary task data for model pre-training by decomposing gradient updates into components guided by the primary task", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dery|auxiliary_task_update_decomposition_the_good_the_bad_and_the_neutral", "supplementary_material": "/attachment/0f0d441cd3fd43ccb236d60f9e2f0bb5385e32ff.zip", "pdf": "/pdf/abc70350e11147c46076e6b97c615c42e2ab46d5.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ndery2021auxiliary,\ntitle={{\\{}AUXILIARY{\\}} {\\{}TASK{\\}} {\\{}UPDATE{\\}} {\\{}DECOMPOSITION{\\}}: {\\{}THE{\\}} {\\{}GOOD{\\}}, {\\{}THE{\\}} {\\{}BAD{\\}} {\\{}AND{\\}} {\\{}THE{\\}} {\\{}NEUTRAL{\\}}},\nauthor={Lucio M. Dery and Yann Dauphin and David Grangier},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=1GTma8HwlYp}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "1GTma8HwlYp", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2750/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2750/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2750/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2750/Authors|ICLR.cc/2021/Conference/Paper2750/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2750/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923844866, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2750/-/Official_Comment"}}}, {"id": "XeBEyJt5Dz", "original": null, "number": 3, "cdate": 1605642076448, "ddate": null, "tcdate": 1605642076448, "tmdate": 1605642076448, "tddate": null, "forum": "1GTma8HwlYp", "replyto": "CuBHK5kZR_I", "invitation": "ICLR.cc/2021/Conference/Paper2750/-/Official_Comment", "content": {"title": "Addressing AnonReviewer1 Concerns", "comment": "We appreciate the time and effort you took to provide us with feedback. We address your comments one by one below.\n\n\u201cSince k<<D, the sum of all gradients in g_aux will clearly still have a big influence on the performance of the primary task\u201d  ->\nThe choice of a lower dimensional space (k) is a computational necessity and indeed the decomposition is not perfect. However, our strategy performs well despite its low dimension:\nfigure 3 shows that with k = 5 and D = O(1M), we are able to capture up to 20% of the gradient norm. Thus, even though we don't capture all of the norm if k is small,  we capture a comparably large fraction with very few components.  With a large enough choice of k, but still with k << D, we can reduce the norm of the out-of-span component significantly so as to mitigate its influence on the primary task. Note that increasing k creates a tradeoff between computational efficiency and performance - we are encouraged that we observe significant improvement with relatively small values of k.\n\n\u201cNot all of those hyper parameters are properly discussed\u201d, \u201cCalculating the randomized_lowrank_approx is only done every n steps but there is no mention of n later\u201d -> We address this concern under the  Hyperparameter Settings section of Common Concerns. Please let us know if you would like any further clarification.\n\n\u201cFigure 2 shows an ablation study but does not help practitioners to set the discussed values, given the large variance over 5 runs\u201d ->  We attribute the higher variance as an unfortunate side effect of the limited data regime. The settings we explore, even when dubbed \u2018high-resource\u2019, involve training a relatively large model on much smaller datasets than typical. Moving to typical levels of data availability would distract from the low-resource setting we are most interested in.\n\n\u201cSome experimental results should be provided to convince the reader that the basis does not change too much given 2 different batches from the primary task\u201d -> We acknowledge that this would be a good ablation to include. We plan on including this experiment in the final version of the paper but we are still brainstorming an effective way to showcase this. This is especially  challenging because we use a randomized algorithm for computing the subspace, so we necessarily get a different subspace from batch to batch and measuring the difference between 2 subspaces is itself a non-trivial problem\n\n\u201cHow can a random choice of subspace basis improve the results\u201d ->  For a \u2018random\u2019 basis, since very little of the gradient norm falls within the subspace, the auxiliary task gradient does not change much after gradient decomposition and this essentially reduces to normal end-task agnostic pre-training. \n\n\u201cThe result in Table 2 is much better than the best result in Table 4 on the Cat-vs-Dogs experiment. What is the difference?\u201d -> For our ablation studies, we dedicated a limited computational budget for hyper-parameter selection for the methods explored in Table 4. Table 2 reflects a more expanded set of hyper-parameter configurations to reflect the strength of the baselines being compared to. Note that the baselines in Table 2 also enjoy expanded resources for hyper-parameter search\n\n\u201cEarly stopping after 10 epochs seems quite short and might explain some of the large variance in the results.\u201d -> We note that we do not early stop after just 10 epochs. Rather, we early stop if there has been no improvement on the end-task validation loss after 10 epochs. We run all experiments for a maximum of 150 pre-training epochs and 500 fine-tuning epochs. We updated the appendix to make this clearer."}, "signatures": ["ICLR.cc/2021/Conference/Paper2750/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2750/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AUXILIARY TASK UPDATE DECOMPOSITION: THE GOOD, THE BAD AND THE NEUTRAL", "authorids": ["~Lucio_M._Dery1", "~Yann_Dauphin1", "~David_Grangier1"], "authors": ["Lucio M. Dery", "Yann Dauphin", "David Grangier"], "keywords": ["pre-training", "multitask learning", "deeplearning", "gradient decomposition"], "abstract": "While deep learning has been very beneficial in data-rich settings, tasks with smaller training set\noften resort to pre-training or multitask learning to leverage data from other tasks. In this case,\ncareful consideration is needed to select tasks and model parameterizations such that updates from\nthe auxiliary tasks actually help the primary task. We seek to alleviate this burden by formulating a model-agnostic framework that performs fine-grained manipulation of the auxiliary task gradients. We propose to decompose auxiliary updates into directions which help, damage or leave the primary task loss unchanged. This allows weighting the update directions \ndifferently depending on their impact on the problem of interest. We present a novel and efficient algorithm for that\npurpose and show its advantage in practice. Our method leverages efficient automatic differentiation \nprocedures and randomized singular value decomposition for scalability. We show that our framework is \ngeneric and encompasses some prior work as particular cases. Our approach consistently outperforms strong and widely used baselines when leveraging out-of-distribution data for Text and Image classification tasks.", "one-sentence_summary": "We improve how we use auxiliary task data for model pre-training by decomposing gradient updates into components guided by the primary task", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dery|auxiliary_task_update_decomposition_the_good_the_bad_and_the_neutral", "supplementary_material": "/attachment/0f0d441cd3fd43ccb236d60f9e2f0bb5385e32ff.zip", "pdf": "/pdf/abc70350e11147c46076e6b97c615c42e2ab46d5.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ndery2021auxiliary,\ntitle={{\\{}AUXILIARY{\\}} {\\{}TASK{\\}} {\\{}UPDATE{\\}} {\\{}DECOMPOSITION{\\}}: {\\{}THE{\\}} {\\{}GOOD{\\}}, {\\{}THE{\\}} {\\{}BAD{\\}} {\\{}AND{\\}} {\\{}THE{\\}} {\\{}NEUTRAL{\\}}},\nauthor={Lucio M. Dery and Yann Dauphin and David Grangier},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=1GTma8HwlYp}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "1GTma8HwlYp", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2750/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2750/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2750/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2750/Authors|ICLR.cc/2021/Conference/Paper2750/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2750/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923844866, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2750/-/Official_Comment"}}}, {"id": "Vde2r-IFvsI", "original": null, "number": 2, "cdate": 1605641905251, "ddate": null, "tcdate": 1605641905251, "tmdate": 1605641970682, "tddate": null, "forum": "1GTma8HwlYp", "replyto": "1GTma8HwlYp", "invitation": "ICLR.cc/2021/Conference/Paper2750/-/Official_Comment", "content": {"title": "Common Concerns", "comment": "We would like to thank all reviewers for their thoughtful comments and for spending time to provide feedback on our work. We address some common concerns amongst  the reviews here.\n\n[General Correction]\n\nWe would like to submit the following correction to our paper.\nFor Table 2, our model is actually initialized from the Imagenet pretrained ResNet model and not from scratch. We have updated this table to reflect this fact. Thus, to further clarify, row 2 in Table 2 is the result obtained from finetuning a pre-trained ResNet-18 directly on the ChexPert-5k dataset. For rows 3 of Table 2, we start with a pre-trained ResNet-18 and finetune with further Imagenet data using ATTITUD before final direct training with ChexPert-5k.\nWe  sincerely apologize for any confusion. We have updated Table 2 and the text describing the result to reflect this fact.\n\n\n\n[Comparison to (Gururanga 2020) and (Yue 2020)]\n\nFor our text classification experiments, since we are directly comparing to (Gururangan et al 2020), we used exactly the same hyper-parameters they used to train their classification heads. Our hyper-parameter optimization diverges from theirs when considering the pre-training done on BERT before final classification. Here, we downloaded their (already extensively cross-validated) pretrained TAPT models to compare against our model whose hyper-parameter settings are provided in Appendix C. We note that our reported results are slightly higher, ~0.5%, than those presented in (Gururangan et al 2020) but the gaps between methods are consistent. We attribute this to using a slightly different environment with a newer version of pytorch and the huggingface library.\n\nRegarding Yue 2020, we note that the following differences between our experimental setup and theirs as noted in Section 5 and Appendix C respectively\nWe use a different architecture than used in (Yue 2020) and (Rosenbaum  2017) because that architecture can only be trained using Reinforcement-Learning. We use classical optimization for training with ATTITUD and hence defaulted to a simpler architecture amenable to this type of optimization. \nWhilst (Yue 2020) and (Rosenbaum  2017) use a 500-100 train test split, we use a 400-100-100 train-val-test split. We thus train on less data\nSince we are operating in the asymmetrical task setting, we train a different model for each of the 20 tasks, treating the remaining 19 tasks as auxiliary tasks. Yue 2020 train a single model (specialized architecture and different training regime from ours) to perform all 20 tasks at once\n\n\n\n[Hyperparameter Settings]\n\nAnonReviewer2 expresses concern that our hyper-parameter settings are unfair to the methods we compared with.\nAs already mentioned above under the comparison section, for our text classification experiments, we use the same set of hyper-parameters used by Gururangan et al. Gururangan et al make available extensively cross-validated TAPT models which we compare against our method thus we believe this presents a fair comparison. \nFor Yue et al (PCGrad), note that they treat all tasks symmetrically which is different from our primary-auxiliary task setting. We thus introduced \\alpha_{prim} as an extra hyper-parameter for PCGrad to reflect this asymmetry. We cross validated values of  \\alpha_{prim} in {0.1, 0.05, 0.01, 0.001} .  We also cross-validated dropout values as mentioned in Appendix C. We apologize for not making this clearer in the paper and have updated the appendix to reflect this. \n\nBoth AnonReviewer2 and AnonReviewer3 express concern over the fact that we explore 4 configurations for our auxiliary task parameters \\eta_{aux}. We explored other configurations, though not extensively, but decided to highlight these 4 because they are more interpretable and thus easily justifiable by practitioners. Note that these 4 configurations were further cross validated via grid search with different values of \\eta_{prim} and dropout, with the optimal values discovered discussed in Section 6. We view the fact that we are able to get performance improvements by restricting ourselves to the corners of the search space as an indicator of the strength of our method.\n\nAnonReviewer1 raises concern about the lack of information about, n, how frequently we recompute the basis. For our Vision experiments, we cross-validate n = {5, 10}, and for Text classification, we explore n = {1, 4}. As we mention in Section 4, we apply gradient clipping and use a relatively small learning rate such that infrequently computing the basis does not degrade performance. We have updated Appendix to reflect this and we will include more extensive exploration of the impact of varying n in the final paper."}, "signatures": ["ICLR.cc/2021/Conference/Paper2750/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2750/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AUXILIARY TASK UPDATE DECOMPOSITION: THE GOOD, THE BAD AND THE NEUTRAL", "authorids": ["~Lucio_M._Dery1", "~Yann_Dauphin1", "~David_Grangier1"], "authors": ["Lucio M. Dery", "Yann Dauphin", "David Grangier"], "keywords": ["pre-training", "multitask learning", "deeplearning", "gradient decomposition"], "abstract": "While deep learning has been very beneficial in data-rich settings, tasks with smaller training set\noften resort to pre-training or multitask learning to leverage data from other tasks. In this case,\ncareful consideration is needed to select tasks and model parameterizations such that updates from\nthe auxiliary tasks actually help the primary task. We seek to alleviate this burden by formulating a model-agnostic framework that performs fine-grained manipulation of the auxiliary task gradients. We propose to decompose auxiliary updates into directions which help, damage or leave the primary task loss unchanged. This allows weighting the update directions \ndifferently depending on their impact on the problem of interest. We present a novel and efficient algorithm for that\npurpose and show its advantage in practice. Our method leverages efficient automatic differentiation \nprocedures and randomized singular value decomposition for scalability. We show that our framework is \ngeneric and encompasses some prior work as particular cases. Our approach consistently outperforms strong and widely used baselines when leveraging out-of-distribution data for Text and Image classification tasks.", "one-sentence_summary": "We improve how we use auxiliary task data for model pre-training by decomposing gradient updates into components guided by the primary task", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dery|auxiliary_task_update_decomposition_the_good_the_bad_and_the_neutral", "supplementary_material": "/attachment/0f0d441cd3fd43ccb236d60f9e2f0bb5385e32ff.zip", "pdf": "/pdf/abc70350e11147c46076e6b97c615c42e2ab46d5.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ndery2021auxiliary,\ntitle={{\\{}AUXILIARY{\\}} {\\{}TASK{\\}} {\\{}UPDATE{\\}} {\\{}DECOMPOSITION{\\}}: {\\{}THE{\\}} {\\{}GOOD{\\}}, {\\{}THE{\\}} {\\{}BAD{\\}} {\\{}AND{\\}} {\\{}THE{\\}} {\\{}NEUTRAL{\\}}},\nauthor={Lucio M. Dery and Yann Dauphin and David Grangier},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=1GTma8HwlYp}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "1GTma8HwlYp", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2750/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2750/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2750/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2750/Authors|ICLR.cc/2021/Conference/Paper2750/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2750/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923844866, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2750/-/Official_Comment"}}}, {"id": "r1CUpI3QzsX", "original": null, "number": 3, "cdate": 1603889496695, "ddate": null, "tcdate": 1603889496695, "tmdate": 1605024140348, "tddate": null, "forum": "1GTma8HwlYp", "replyto": "1GTma8HwlYp", "invitation": "ICLR.cc/2021/Conference/Paper2750/-/Official_Review", "content": {"title": "Review on \"Auxiliary task update decomposition: the good, the bad and the neutral\"", "review": "##########################################################################\n\nSummary:\nLeveraging the power of the data-rich related tasks have been studied (e.g., pre-training and multitask learning). This paper points out that careful utilization of auxiliary task is required to gain enhanced performance in primary tasks. In order to prevent harming the performance of primary tasks, they suggest the method to decompose auxiliary updates into three directions which have positive, negative and neutral impact on the primary task.\n\n##########################################################################\n\nReasons for score:\u00a0\n\nIn this paper, it is highly interesting to see how to use a decomposition from the span of the primary task Jacobian to adapt auxiliary gradients and validate the proposed methodology on image and textual data. Even though this is an interesting setting and the technical solutions presented in the paper look reasonable, the idea seems to be pretty incremental as it stacks multiple existing techniques without many innovations.\u00a0\n\n##########################################################################\n\nPros:\u00a0\n1. The proposed methodology utilizes  automatic differentiation procedures and randomized singular value decomposition for efficient scalability. \n2. The proposed framework allows the model to treat each auxiliary update independently by its impact on the task of interest, which seems to be interesting.\n\n##########################################################################\n\nCons:\u00a0\nAuthors need to perform more qualitative and quantitative analysis on the datasets to vilify the effectiveness of the proposed methodology.\n\n##########################################################################\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2021/Conference/Paper2750/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2750/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AUXILIARY TASK UPDATE DECOMPOSITION: THE GOOD, THE BAD AND THE NEUTRAL", "authorids": ["~Lucio_M._Dery1", "~Yann_Dauphin1", "~David_Grangier1"], "authors": ["Lucio M. Dery", "Yann Dauphin", "David Grangier"], "keywords": ["pre-training", "multitask learning", "deeplearning", "gradient decomposition"], "abstract": "While deep learning has been very beneficial in data-rich settings, tasks with smaller training set\noften resort to pre-training or multitask learning to leverage data from other tasks. In this case,\ncareful consideration is needed to select tasks and model parameterizations such that updates from\nthe auxiliary tasks actually help the primary task. We seek to alleviate this burden by formulating a model-agnostic framework that performs fine-grained manipulation of the auxiliary task gradients. We propose to decompose auxiliary updates into directions which help, damage or leave the primary task loss unchanged. This allows weighting the update directions \ndifferently depending on their impact on the problem of interest. We present a novel and efficient algorithm for that\npurpose and show its advantage in practice. Our method leverages efficient automatic differentiation \nprocedures and randomized singular value decomposition for scalability. We show that our framework is \ngeneric and encompasses some prior work as particular cases. Our approach consistently outperforms strong and widely used baselines when leveraging out-of-distribution data for Text and Image classification tasks.", "one-sentence_summary": "We improve how we use auxiliary task data for model pre-training by decomposing gradient updates into components guided by the primary task", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dery|auxiliary_task_update_decomposition_the_good_the_bad_and_the_neutral", "supplementary_material": "/attachment/0f0d441cd3fd43ccb236d60f9e2f0bb5385e32ff.zip", "pdf": "/pdf/abc70350e11147c46076e6b97c615c42e2ab46d5.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ndery2021auxiliary,\ntitle={{\\{}AUXILIARY{\\}} {\\{}TASK{\\}} {\\{}UPDATE{\\}} {\\{}DECOMPOSITION{\\}}: {\\{}THE{\\}} {\\{}GOOD{\\}}, {\\{}THE{\\}} {\\{}BAD{\\}} {\\{}AND{\\}} {\\{}THE{\\}} {\\{}NEUTRAL{\\}}},\nauthor={Lucio M. Dery and Yann Dauphin and David Grangier},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=1GTma8HwlYp}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "1GTma8HwlYp", "replyto": "1GTma8HwlYp", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2750/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538089426, "tmdate": 1606915797704, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2750/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2750/-/Official_Review"}}}, {"id": "CuBHK5kZR_I", "original": null, "number": 4, "cdate": 1604247440392, "ddate": null, "tcdate": 1604247440392, "tmdate": 1605024140201, "tddate": null, "forum": "1GTma8HwlYp", "replyto": "1GTma8HwlYp", "invitation": "ICLR.cc/2021/Conference/Paper2750/-/Official_Review", "content": {"title": "A good overall idea and well written, but the resulting algorithm might be too tedious to use in practice", "review": "Summary:\nThe authors present a general formulation of different settings in multitask learning (including pretraining regimes), in a setting where the goal is to get best performance for a pre-specified primary task and additional auxiliary tasks. The main idea is to divide the gradients on the auxiliary task into 2 subspaces: a subspace where the gradients influence performance of the primary task and a subspace where they only influence the auxiliary task without changing the loss on the primary task. Within the subspace that does have influence on the primary task, it is easy to compute directions that have a positive or negative effect on the primary task, which allows to create different learning schemes given the gradients that point toward: i) auxiliary influence only, ii) positive influence on auxiliary tass, iii) negative influence on primary task. Experimental results show improvements over previously identified meta learning methods on 2 natural language datasets and 3 image datasets.\n\nStrengths:\nThe authors present a general framework for an important problem. It has many applications in a wide variety of fields and contributes to thinking about meta learning and pretraining in a more general way.\nExplanations, illustrations and mathematical derivations are clear and easy to understand.\nThe authors show that with a careful choice of hyperparameters, their approach can improve performance, especially in settings with limited data on the primary task. The results on natural language datasets are also interesting, showing that they achieve a higher performance when the auxiliary task doesn\u2019t exactly match the primary task data.\n\nWeaknesses:\nSome of the explanations and especially the proof fall apart, when considering the k-largest principal vector of J*. Since k<<D, the sum of all gradients in g_aux will clearly still have a big influence on the performance of the primary task.\nThe proposed algorithm introduces a lot of additional hyperparameters and not all of those hyper parameters are properly discussed. Eta_aux and eta_prim are properly discussed and the authors convincingly show that these parameters are implicitly set by other methods as well. Figure 2 shows an ablation study but does not help practitioners to set the discussed values, given the large variance over 5 runs.\nThe choice of the subspace for g_aux seems very critical and the provided experimental results and discussion are somewhat lacking. How can a random choice of subspace basis improve the results? Calculating the randomized_lowrank_approx is only done every n steps, but there is no mention of n later. Some experimental results should be provided to convince the reader that the basis does not change too much given 2 different batches from the primary task.\n\nOther remarks:\nThe result in Table 2 is much better than the best result in Table 4 on the Cat-vs-Dogs experiment. What is the difference? Can the experiments in Table 4 be repeated to be more comparable to Table 2?\nPCGrad most closely resembles this work. What type of subspace basis is used in that work? It would be interesting to see a direct comparison between PCGrad and the proposed method with eta_aux = (alpha_aux, alpha_aux,- alpha_aux) and using the same basis.\nEarly stopping after 10 epochs seems quite short and might explain some of the large variance in the results.\n\nMinor remarks:\nk is introduced without much explanation, which was a bit confusing on first reading. It should be clearly stated that it is a hyper parameter on first mention.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2750/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2750/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AUXILIARY TASK UPDATE DECOMPOSITION: THE GOOD, THE BAD AND THE NEUTRAL", "authorids": ["~Lucio_M._Dery1", "~Yann_Dauphin1", "~David_Grangier1"], "authors": ["Lucio M. Dery", "Yann Dauphin", "David Grangier"], "keywords": ["pre-training", "multitask learning", "deeplearning", "gradient decomposition"], "abstract": "While deep learning has been very beneficial in data-rich settings, tasks with smaller training set\noften resort to pre-training or multitask learning to leverage data from other tasks. In this case,\ncareful consideration is needed to select tasks and model parameterizations such that updates from\nthe auxiliary tasks actually help the primary task. We seek to alleviate this burden by formulating a model-agnostic framework that performs fine-grained manipulation of the auxiliary task gradients. We propose to decompose auxiliary updates into directions which help, damage or leave the primary task loss unchanged. This allows weighting the update directions \ndifferently depending on their impact on the problem of interest. We present a novel and efficient algorithm for that\npurpose and show its advantage in practice. Our method leverages efficient automatic differentiation \nprocedures and randomized singular value decomposition for scalability. We show that our framework is \ngeneric and encompasses some prior work as particular cases. Our approach consistently outperforms strong and widely used baselines when leveraging out-of-distribution data for Text and Image classification tasks.", "one-sentence_summary": "We improve how we use auxiliary task data for model pre-training by decomposing gradient updates into components guided by the primary task", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dery|auxiliary_task_update_decomposition_the_good_the_bad_and_the_neutral", "supplementary_material": "/attachment/0f0d441cd3fd43ccb236d60f9e2f0bb5385e32ff.zip", "pdf": "/pdf/abc70350e11147c46076e6b97c615c42e2ab46d5.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\ndery2021auxiliary,\ntitle={{\\{}AUXILIARY{\\}} {\\{}TASK{\\}} {\\{}UPDATE{\\}} {\\{}DECOMPOSITION{\\}}: {\\{}THE{\\}} {\\{}GOOD{\\}}, {\\{}THE{\\}} {\\{}BAD{\\}} {\\{}AND{\\}} {\\{}THE{\\}} {\\{}NEUTRAL{\\}}},\nauthor={Lucio M. Dery and Yann Dauphin and David Grangier},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=1GTma8HwlYp}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "1GTma8HwlYp", "replyto": "1GTma8HwlYp", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2750/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538089426, "tmdate": 1606915797704, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2750/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2750/-/Official_Review"}}}], "count": 13}