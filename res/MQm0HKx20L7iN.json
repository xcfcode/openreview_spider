{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1362172860000, "tcdate": 1362172860000, "number": 2, "id": "Z9bz9yXn_F9nA", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "MQm0HKx20L7iN", "replyto": "MQm0HKx20L7iN", "signatures": ["anonymous reviewer cce9"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Kernelized Locality-Sensitive Hashing for Semi-Supervised Agglomerative Clustering", "review": "This workshop submission proposes a method for clustering data which applies a semi-supervised distance metric to the data prior to applying kernelized locality-sensitive hashing for agglom\r\nerative clustering. The intuition is that distance learning on a subset of data pairs will improve overall performance, and that the LSH-based clustering will be a better match for high-dimension data than k\r\n-means. The method is evaluated on MNIST data.\r\n\r\nThere is little to no innovation in this paper, and, considering that there is no learned representation to speak of, it is of little interest for ICLR. The authors do not adequately explain the approach, an\r\nd the experimental evaluation is unclear. The semi-supervised distance metric learning is not discussed fully, and the number and distribution of labeled data is not given.\r\n\r\nMoreover, the results are not promising. Although it is difficult to compare raw precision/recall numbers (F-measure or other metrics would be preferable), it is clear that the proposed method has much lower\r\n recall than the kmeans baseline, with only moderate improvement in precision. The submission would also be improved by a visualization of the clustering obtained with the different methods."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"decision": "reject", "title": "Kernelized Locality-Sensitive Hashing for Semi-Supervised Agglomerative Clustering", "abstract": "Large scale agglomerative clustering is hindered by computational burdens. We propose a novel scheme where exact inter-instance distance calculation is replaced by the Hamming distance between Kernelized Locality-Sensitive Hashing (KLSH) hashed values. This results in a method that drastically decreases computation time. Additionally, we take advantage of certain labeled data points via distance metric learning to achieve a competitive precision and recall comparing to K-Means but in much less computation time.", "pdf": "https://arxiv.org/abs/1301.3575", "paperhash": "xie|kernelized_localitysensitive_hashing_for_semisupervised_agglomerative_clustering", "authorids": ["xie@cs.columbia.edu", "sz2228@columbia.edu"], "keywords": [], "conflicts": [], "authors": ["Boyi Xie", "Shuheng Zheng"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362080280000, "tcdate": 1362080280000, "number": 1, "id": "vpc3vyRo-2AFM", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "MQm0HKx20L7iN", "replyto": "MQm0HKx20L7iN", "signatures": ["anonymous reviewer c8d7"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Kernelized Locality-Sensitive Hashing for Semi-Supervised Agglomerative Clustering", "review": "This paper proposes to use kernelized locality-sensitive hashing (KLSH), based on a similarity metric learned from labeled data, to accelerate agglomerative (hierarchical) clustering. Agglomerative clustering requires, at each iteration, to find the pair of closest clusters. The idea behind this paper is that KLSH can be used to accelerate the search for these pairs of clusters. Also, the use of a learned, supervised metric should encourage the extraction of a clustering that reflects the class structure of the data distribution, even if computed from a relatively small subset of labeled data. Comparisons with k-means, k-means with distance learning, agglomerative clustering with KLSH and agglomerative clustering with KLSH and distance learning are reported.\r\n\r\nUnfortunately, I find this paper to be quite incremental. It essentially corresponds to a straightforward combination of 3 ideas 1) agglomerative clustering, 2) kernelized LSH [7] and 3) supervised metric learning [5].\r\n\r\nI find that details about the approach are also missing, about how to combine KLSH with agglomerative clustering. First, the authors do not explain how KLSH is leveraged to find the pair of closest clusters C_i and C_j. Are they iterating over each cluster C_i, finding its closest neighbour C_j using KLSH? This would correspond to a complexity linear in the number of clusters, and thus initially linear in the number of data points N. In a large scale setting, isn't this still too expensive? Are the authors doing something more clever? Algorithm 1 also mentions a proximity matrix P. Isn't its size N^2 initially? Again, in a large scale setting, it would be impossible to store such a matrix. The authors also do not specify how to compute distances between two clusters consisting in more than a single data point. I believe this is sometimes referred to as the linkage distance or criteria between clusters, which can be the min distance over all pairs or max distance over all pairs. What did the authors use, and how does KLSH allow for an efficient computation?\r\n\r\nMoreover, I'm not convinced of the benefit of the algorithm, based on the experiments reported in table 1. Indeed, agglomerative clustering with KLSH and distance learning does not dominate all other algorithm for both the precision and recall. In fact, it's doing terribly in terms of recall, compared to k-means. Also, it is not exactly clear to me what precision and recall correspond to in the context of this clustering experiment. I would suggest the author explicitly define what they mean here. I'm more familiar with adjusted rand index, as an evaluation metric for clustering...\r\n\r\nFinally, the writing of the paper is quite poor. I already mentioned that many details are lacking. Moreover, the paper is filled with typos and oddly phrased sentences."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"decision": "reject", "title": "Kernelized Locality-Sensitive Hashing for Semi-Supervised Agglomerative Clustering", "abstract": "Large scale agglomerative clustering is hindered by computational burdens. We propose a novel scheme where exact inter-instance distance calculation is replaced by the Hamming distance between Kernelized Locality-Sensitive Hashing (KLSH) hashed values. This results in a method that drastically decreases computation time. Additionally, we take advantage of certain labeled data points via distance metric learning to achieve a competitive precision and recall comparing to K-Means but in much less computation time.", "pdf": "https://arxiv.org/abs/1301.3575", "paperhash": "xie|kernelized_localitysensitive_hashing_for_semisupervised_agglomerative_clustering", "authorids": ["xie@cs.columbia.edu", "sz2228@columbia.edu"], "keywords": [], "conflicts": [], "authors": ["Boyi Xie", "Shuheng Zheng"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1358448300000, "tcdate": 1358448300000, "number": 26, "id": "MQm0HKx20L7iN", "invitation": "ICLR.cc/2013/conference/-/submission", "forum": "MQm0HKx20L7iN", "signatures": ["xie@cs.columbia.edu"], "readers": ["everyone"], "content": {"decision": "reject", "title": "Kernelized Locality-Sensitive Hashing for Semi-Supervised Agglomerative Clustering", "abstract": "Large scale agglomerative clustering is hindered by computational burdens. We propose a novel scheme where exact inter-instance distance calculation is replaced by the Hamming distance between Kernelized Locality-Sensitive Hashing (KLSH) hashed values. This results in a method that drastically decreases computation time. Additionally, we take advantage of certain labeled data points via distance metric learning to achieve a competitive precision and recall comparing to K-Means but in much less computation time.", "pdf": "https://arxiv.org/abs/1301.3575", "paperhash": "xie|kernelized_localitysensitive_hashing_for_semisupervised_agglomerative_clustering", "authorids": ["xie@cs.columbia.edu", "sz2228@columbia.edu"], "keywords": [], "conflicts": [], "authors": ["Boyi Xie", "Shuheng Zheng"]}, "writers": [], "details": {"replyCount": 2, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496673673639, "cdate": 1496673673639, "tcdate": 1496673673639, "id": "ICLR.cc/2013/conference/-/submission", "writers": ["ICLR.cc/2013"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717}}}], "count": 3}