{"notes": [{"id": "B1lj20NFDS", "original": "rkgW25KdwS", "number": 1368, "cdate": 1569439410681, "ddate": null, "tcdate": 1569439410681, "tmdate": 1583912029476, "tddate": null, "forum": "B1lj20NFDS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Variational Autoencoders for Highly Multivariate Spatial Point Processes Intensities", "authors": ["Baichuan Yuan", "Xiaowei Wang", "Jianxin Ma", "Chang Zhou", "Andrea L. Bertozzi", "Hongxia Yang"], "authorids": ["ybcmath@gmail.com", "daemon.wxw@alibaba-inc.com", "majx13fromthu@gmail.com", "ericzhou.zc@alibaba-inc.com", "bertozzi@math.ucla.edu", "yang.yhx@alibaba-inc.com"], "keywords": ["VAE", "collaborative filtering", "recommender systems", "spatial point process"], "abstract": "Multivariate spatial point process models can describe heterotopic data over space. However, highly multivariate intensities are computationally challenging due to the curse of dimensionality. To bridge this gap, we introduce a declustering based hidden variable model that leads to an efficient inference procedure via a variational autoencoder (VAE). We also prove that this model is a generalization of the VAE-based model for collaborative filtering. This leads to an interesting application of spatial point process models to recommender systems. Experimental results show the method's utility on both synthetic data and real-world data sets.\n", "pdf": "/pdf/e76b11a460c49fcd85d7c7218adf083c049877f1.pdf", "paperhash": "yuan|variational_autoencoders_for_highly_multivariate_spatial_point_processes_intensities", "_bibtex": "@inproceedings{\nYuan2020Variational,\ntitle={Variational Autoencoders for Highly Multivariate Spatial Point Processes Intensities},\nauthor={Baichuan Yuan and Xiaowei Wang and Jianxin Ma and Chang Zhou and Andrea L. Bertozzi and Hongxia Yang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=B1lj20NFDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/90cca014066ce5012911e148689a8ea97dcfb04a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "5o6FyNBW9x", "original": null, "number": 1, "cdate": 1576798721649, "ddate": null, "tcdate": 1576798721649, "tmdate": 1576800914937, "tddate": null, "forum": "B1lj20NFDS", "replyto": "B1lj20NFDS", "invitation": "ICLR.cc/2020/Conference/Paper1368/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "This paper presents a novel VAE-based model for multivariate spatial point process which can realize efficient inference by amortization and handle missing points via smooth intensity estimation. Authors also provide interesting theoretical analysis to connect their method to a popular VAE-based collaborative filtering method.\nOverall, all reviewers appreciate the methodological and theoretical contributions of the paper. During the reviewer discussion, one reviewer decided to update to the score to Weak Acceptance. There are still some concerns regarding experimental validation, I think the paper provides enough theoretical contribution to the community and would like to recommend acceptance. ", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Autoencoders for Highly Multivariate Spatial Point Processes Intensities", "authors": ["Baichuan Yuan", "Xiaowei Wang", "Jianxin Ma", "Chang Zhou", "Andrea L. Bertozzi", "Hongxia Yang"], "authorids": ["ybcmath@gmail.com", "daemon.wxw@alibaba-inc.com", "majx13fromthu@gmail.com", "ericzhou.zc@alibaba-inc.com", "bertozzi@math.ucla.edu", "yang.yhx@alibaba-inc.com"], "keywords": ["VAE", "collaborative filtering", "recommender systems", "spatial point process"], "abstract": "Multivariate spatial point process models can describe heterotopic data over space. However, highly multivariate intensities are computationally challenging due to the curse of dimensionality. To bridge this gap, we introduce a declustering based hidden variable model that leads to an efficient inference procedure via a variational autoencoder (VAE). We also prove that this model is a generalization of the VAE-based model for collaborative filtering. This leads to an interesting application of spatial point process models to recommender systems. Experimental results show the method's utility on both synthetic data and real-world data sets.\n", "pdf": "/pdf/e76b11a460c49fcd85d7c7218adf083c049877f1.pdf", "paperhash": "yuan|variational_autoencoders_for_highly_multivariate_spatial_point_processes_intensities", "_bibtex": "@inproceedings{\nYuan2020Variational,\ntitle={Variational Autoencoders for Highly Multivariate Spatial Point Processes Intensities},\nauthor={Baichuan Yuan and Xiaowei Wang and Jianxin Ma and Chang Zhou and Andrea L. Bertozzi and Hongxia Yang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=B1lj20NFDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/90cca014066ce5012911e148689a8ea97dcfb04a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "B1lj20NFDS", "replyto": "B1lj20NFDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795716591, "tmdate": 1576800266769, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1368/-/Decision"}}}, {"id": "SkxY1KDaKH", "original": null, "number": 1, "cdate": 1571809505109, "ddate": null, "tcdate": 1571809505109, "tmdate": 1574530192405, "tddate": null, "forum": "B1lj20NFDS", "replyto": "B1lj20NFDS", "invitation": "ICLR.cc/2020/Conference/Paper1368/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "title": "Official Blind Review #2", "review": "In this paper, the authors propose a VAE model for spatial point processes. The model generalizes the kernel density-based intensity and applies variational inference. The model is applied to synthetic datasets, a location-based social network dataset, and a recommender system dataset. \n\nThe paper is well motivated and clearly written. I found the probabilistic modeling interesting. My major concern is that, with added complexity, the experimental results suggest that VAE-SPP is not significantly better than the existing VAE-CF on most tasks.\n\nFor the MovieLens task, it seems that the GNN is an important component in the pipeline, but no further detail is provided about it, including the network architecture. The authors might also want to provide the definitions of NDCG@k and Recall@k, at least in the appendix.\n\n---\n\nI appreciate the author's detailed response and updated paper. I have changed my rating.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"}, "signatures": ["ICLR.cc/2020/Conference/Paper1368/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1368/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Autoencoders for Highly Multivariate Spatial Point Processes Intensities", "authors": ["Baichuan Yuan", "Xiaowei Wang", "Jianxin Ma", "Chang Zhou", "Andrea L. Bertozzi", "Hongxia Yang"], "authorids": ["ybcmath@gmail.com", "daemon.wxw@alibaba-inc.com", "majx13fromthu@gmail.com", "ericzhou.zc@alibaba-inc.com", "bertozzi@math.ucla.edu", "yang.yhx@alibaba-inc.com"], "keywords": ["VAE", "collaborative filtering", "recommender systems", "spatial point process"], "abstract": "Multivariate spatial point process models can describe heterotopic data over space. However, highly multivariate intensities are computationally challenging due to the curse of dimensionality. To bridge this gap, we introduce a declustering based hidden variable model that leads to an efficient inference procedure via a variational autoencoder (VAE). We also prove that this model is a generalization of the VAE-based model for collaborative filtering. This leads to an interesting application of spatial point process models to recommender systems. Experimental results show the method's utility on both synthetic data and real-world data sets.\n", "pdf": "/pdf/e76b11a460c49fcd85d7c7218adf083c049877f1.pdf", "paperhash": "yuan|variational_autoencoders_for_highly_multivariate_spatial_point_processes_intensities", "_bibtex": "@inproceedings{\nYuan2020Variational,\ntitle={Variational Autoencoders for Highly Multivariate Spatial Point Processes Intensities},\nauthor={Baichuan Yuan and Xiaowei Wang and Jianxin Ma and Chang Zhou and Andrea L. Bertozzi and Hongxia Yang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=B1lj20NFDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/90cca014066ce5012911e148689a8ea97dcfb04a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "B1lj20NFDS", "replyto": "B1lj20NFDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1368/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1368/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575691692068, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1368/Reviewers"], "noninvitees": [], "tcdate": 1570237738397, "tmdate": 1575691692082, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1368/-/Official_Review"}}}, {"id": "BkgknwV9jr", "original": null, "number": 3, "cdate": 1573697446582, "ddate": null, "tcdate": 1573697446582, "tmdate": 1573697446582, "tddate": null, "forum": "B1lj20NFDS", "replyto": "SkxY1KDaKH", "invitation": "ICLR.cc/2020/Conference/Paper1368/-/Official_Comment", "content": {"title": "Response to Reviewer 2", "comment": "We thank reviewer 2 for valuable comments. We update the paper accordingly, especially in the appendix, providing more details about the experiments and metrics. \n\n1. \u201cMy major concern is that, with added complexity, the experimental results suggest that VAE-SPP is not significantly better than the existing VAE-CF on most tasks.\u201d\n\n- In recommender systems, even a small percentage improvement is non-trivial, especially with the strong VAE-CF baseline here. Comparing with the state-of-the-art methods in the SPP literature, this amortized method significantly outperforms them and extends the capability of handling highly multivariate SPPs. \n\nMoreover, SPPs contain great potential for drawing inspiration from or building further on top of, for future work extending the simple intensity function considered here. Our paper establishes a foundation to build from in that regard. This has the impact of introducing a new state of the art in VAE based collaborative \ufb01ltering techniques that will either inspire further point process-based methods or will at the very least be used to compare against. However, we are not claiming that we solve the classic CF problem completely with the VAE-SPP. In the updated version, we modify the paper to clearly state the applicability of the current approach. \n\n2. \u201cFor the MovieLens task, it seems that the GNN is an important component in the pipeline, but no further detail is provided about it, including the network architecture. The authors might also want to provide the definitions of NDCG@k and Recall@k, at least in the appendix.\u201d\n\n- Thanks for the great suggestion! We are using a one-layer GNN on the graph which consists of the edges between users and items (ratings) as well as the edges between items based on their Jaccard similarity. The training of GNN is based on the GraphSAGE with a mean aggregator. \n\nMore details are provided in Appendix D.2 along with all other network architectures used in this paper, including MLP in VAE and classic SPP methods. We also provide the definitions for NDCG@K and Recall@K in Appendix D.1 instead of simply citing Liang\u2019s paper. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1368/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1368/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Autoencoders for Highly Multivariate Spatial Point Processes Intensities", "authors": ["Baichuan Yuan", "Xiaowei Wang", "Jianxin Ma", "Chang Zhou", "Andrea L. Bertozzi", "Hongxia Yang"], "authorids": ["ybcmath@gmail.com", "daemon.wxw@alibaba-inc.com", "majx13fromthu@gmail.com", "ericzhou.zc@alibaba-inc.com", "bertozzi@math.ucla.edu", "yang.yhx@alibaba-inc.com"], "keywords": ["VAE", "collaborative filtering", "recommender systems", "spatial point process"], "abstract": "Multivariate spatial point process models can describe heterotopic data over space. However, highly multivariate intensities are computationally challenging due to the curse of dimensionality. To bridge this gap, we introduce a declustering based hidden variable model that leads to an efficient inference procedure via a variational autoencoder (VAE). We also prove that this model is a generalization of the VAE-based model for collaborative filtering. This leads to an interesting application of spatial point process models to recommender systems. Experimental results show the method's utility on both synthetic data and real-world data sets.\n", "pdf": "/pdf/e76b11a460c49fcd85d7c7218adf083c049877f1.pdf", "paperhash": "yuan|variational_autoencoders_for_highly_multivariate_spatial_point_processes_intensities", "_bibtex": "@inproceedings{\nYuan2020Variational,\ntitle={Variational Autoencoders for Highly Multivariate Spatial Point Processes Intensities},\nauthor={Baichuan Yuan and Xiaowei Wang and Jianxin Ma and Chang Zhou and Andrea L. Bertozzi and Hongxia Yang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=B1lj20NFDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/90cca014066ce5012911e148689a8ea97dcfb04a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "B1lj20NFDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1368/Authors", "ICLR.cc/2020/Conference/Paper1368/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1368/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1368/Reviewers", "ICLR.cc/2020/Conference/Paper1368/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1368/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1368/Authors|ICLR.cc/2020/Conference/Paper1368/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157061, "tmdate": 1576860554131, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1368/Authors", "ICLR.cc/2020/Conference/Paper1368/Reviewers", "ICLR.cc/2020/Conference/Paper1368/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1368/-/Official_Comment"}}}, {"id": "Bke8PvN9or", "original": null, "number": 2, "cdate": 1573697374054, "ddate": null, "tcdate": 1573697374054, "tmdate": 1573697374054, "tddate": null, "forum": "B1lj20NFDS", "replyto": "rylSHQ6aYH", "invitation": "ICLR.cc/2020/Conference/Paper1368/-/Official_Comment", "content": {"title": "Response to Reviewer 3", "comment": "We thank reviewer 3 for valuable comments and suggestions. The wording in the introduction, conclusion and experiment sections are changed to specify the applicability of our approach and avoid the impression that we claim to solve the CF task. Sorry about the confusion. \n\nWe aim to establish a theoretical foundation for various spatial point processes models for the usage of collaborative \ufb01ltering. This will be signi\ufb01cant for researchers who wish to further this direct line of work. \n\nThe interesting comparison paper of [Dacrema, Cremonesi, Jannach 2019] and many of your comments bring to us several important future works. We cite the paper and summarize our future plan in the conclusion, including investigating the performance of GNN with simpler methods and improve the scalability of the joint training approach. We address the computational cost of adding GNN in the updated paper. Training GNN separately can reduce the cost but it could harm the performance in CF applications (see Appendix D. 3). A possible solution is to perform a graph-cut in order to reduce the complexity of GNN. Finally, we fix a few typos in the text in the updated version.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1368/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1368/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Autoencoders for Highly Multivariate Spatial Point Processes Intensities", "authors": ["Baichuan Yuan", "Xiaowei Wang", "Jianxin Ma", "Chang Zhou", "Andrea L. Bertozzi", "Hongxia Yang"], "authorids": ["ybcmath@gmail.com", "daemon.wxw@alibaba-inc.com", "majx13fromthu@gmail.com", "ericzhou.zc@alibaba-inc.com", "bertozzi@math.ucla.edu", "yang.yhx@alibaba-inc.com"], "keywords": ["VAE", "collaborative filtering", "recommender systems", "spatial point process"], "abstract": "Multivariate spatial point process models can describe heterotopic data over space. However, highly multivariate intensities are computationally challenging due to the curse of dimensionality. To bridge this gap, we introduce a declustering based hidden variable model that leads to an efficient inference procedure via a variational autoencoder (VAE). We also prove that this model is a generalization of the VAE-based model for collaborative filtering. This leads to an interesting application of spatial point process models to recommender systems. Experimental results show the method's utility on both synthetic data and real-world data sets.\n", "pdf": "/pdf/e76b11a460c49fcd85d7c7218adf083c049877f1.pdf", "paperhash": "yuan|variational_autoencoders_for_highly_multivariate_spatial_point_processes_intensities", "_bibtex": "@inproceedings{\nYuan2020Variational,\ntitle={Variational Autoencoders for Highly Multivariate Spatial Point Processes Intensities},\nauthor={Baichuan Yuan and Xiaowei Wang and Jianxin Ma and Chang Zhou and Andrea L. Bertozzi and Hongxia Yang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=B1lj20NFDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/90cca014066ce5012911e148689a8ea97dcfb04a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "B1lj20NFDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1368/Authors", "ICLR.cc/2020/Conference/Paper1368/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1368/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1368/Reviewers", "ICLR.cc/2020/Conference/Paper1368/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1368/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1368/Authors|ICLR.cc/2020/Conference/Paper1368/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157061, "tmdate": 1576860554131, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1368/Authors", "ICLR.cc/2020/Conference/Paper1368/Reviewers", "ICLR.cc/2020/Conference/Paper1368/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1368/-/Official_Comment"}}}, {"id": "H1xqmDNqjH", "original": null, "number": 1, "cdate": 1573697314449, "ddate": null, "tcdate": 1573697314449, "tmdate": 1573697314449, "tddate": null, "forum": "B1lj20NFDS", "replyto": "rygQxkld9B", "invitation": "ICLR.cc/2020/Conference/Paper1368/-/Official_Comment", "content": {"title": "Response to Reviewer 4", "comment": "We thank reviewer 4 for valuable comments. The paper is updated to address the questions, including additional experiments and a paragraph discussing the relationship between our model and VAE-CF after Thm. 1. As you mentioned here, our VAE framework incorporating SPPs as the underlying generating mechanism is a generalization of VAE-CF, which is, in fact, a special case when one ignores the spatial heterogeneity (use a delta function). This is one of the main contributions of our work. Moreover, the SPP likelihood in Eq. (9) cannot be directly applied to VAE due to the definition of the hidden variable. Another main contribution of this paper is to develop the alternative model that uses VAE for the amortized inference of spatial point process and show the equivalence of VAE-CF and VAE-SPP with Thm. 1. \n\n1. \u201cIn Liang's paper, I see they report the evaluation results on both ML-1M and ML-20M dataset. However, in this paper, the results are reported on ML-100K and ML-1M. Why not evaluate the model on the bigger ML-20M dataset?\u201d\n\n- Thanks for mentioning this. We will work on this in the future, especially on the joint training of GNN and VAE-SPP for the larger datasets, as mentioned in the updated paper. The main focus of this paper is on highly multivariate SPPs and it is showing potentials on collaborative filtering. We modify several sections of the paper to clarify that we are not claiming that the collaborative filtering problem is completely solved here. Instead, we hope to inspire further point process-based CF methods based on this framework. \n\nOne way to reduce the computational complexity is to obtain the embedding separately.  However, based on our experiments, if the embeddings of items are obtained separately, then the gap between the VAE-CF and VAE-SPP models becomes smaller. For Movie Lens 100k, training GNN and VAE separately leads to a smaller NDCG@100 (see Appendix D). We would love to explore other approaches such as graph-cut based methods to reduce the computational complexity of GNN.\n\n2. \u201cIn Liang's paper and also He's paper (Neural Collaborative Filtering), they report NDCG@10 on ML-1M dataset. The NCF approach reaches a NDCG@10 of 0.426, Multi-DAE (denoising version of Liang's model) reaches 0.446. You are reporting NDCG@100, which is a different measure. However, the numbers in Table 4 seem to be lower than what I expected. Can you compare with them in the same condition?\u201d\n\n- In fact, there are two different ways of training in VAE-CF and NCF paper. In NCF, they split the data in (user, item) level to learn the embedding for all users in the data. In VAE-CF, the training-validation-test splitting is done at the user level, i.e. users are split into train/test/validation sets: Users with their full rating histories are used to train the model; For testing and validation users, the model is trying to infer the held-out ratings based on part of their history. In the area of SPPs, the setting is more similar to the case of VAE-CF where one wants to infer the missing data for subprocesses that are unseen during the training. As a result, our experiments in ML are *not* comparable to results using the NCF setting such as Table 3 in Liang\u2019s paper (see section 4.4 in Liang\u2019s paper about their splitting methods when comparing with NCF). The choice of different splitting methods definitely plays an important role in the NDCG numbers and is worth further investigation, which is however not the focus of this paper.\n\nWe add the additional experiments comparing with DAE-CF (Multi-DAE), a point estimation version of VAE-CF, in the setting of user splitting. In terms of the NDCG@100, the DAE-CF is 0.4098 for ML-100K (see Appendix D for more details) and 0.4153 for ML-1M, which is better than VAE-CF but lower than VAE-SPP. Moreover, we believe that a better comparison with the DAE-CF could be a point estimation version of VAE-SPP (DAE-SPP?) for CF applications. It could achieve an even better NDCG number in these experiments as the data is less sparse."}, "signatures": ["ICLR.cc/2020/Conference/Paper1368/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1368/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Autoencoders for Highly Multivariate Spatial Point Processes Intensities", "authors": ["Baichuan Yuan", "Xiaowei Wang", "Jianxin Ma", "Chang Zhou", "Andrea L. Bertozzi", "Hongxia Yang"], "authorids": ["ybcmath@gmail.com", "daemon.wxw@alibaba-inc.com", "majx13fromthu@gmail.com", "ericzhou.zc@alibaba-inc.com", "bertozzi@math.ucla.edu", "yang.yhx@alibaba-inc.com"], "keywords": ["VAE", "collaborative filtering", "recommender systems", "spatial point process"], "abstract": "Multivariate spatial point process models can describe heterotopic data over space. However, highly multivariate intensities are computationally challenging due to the curse of dimensionality. To bridge this gap, we introduce a declustering based hidden variable model that leads to an efficient inference procedure via a variational autoencoder (VAE). We also prove that this model is a generalization of the VAE-based model for collaborative filtering. This leads to an interesting application of spatial point process models to recommender systems. Experimental results show the method's utility on both synthetic data and real-world data sets.\n", "pdf": "/pdf/e76b11a460c49fcd85d7c7218adf083c049877f1.pdf", "paperhash": "yuan|variational_autoencoders_for_highly_multivariate_spatial_point_processes_intensities", "_bibtex": "@inproceedings{\nYuan2020Variational,\ntitle={Variational Autoencoders for Highly Multivariate Spatial Point Processes Intensities},\nauthor={Baichuan Yuan and Xiaowei Wang and Jianxin Ma and Chang Zhou and Andrea L. Bertozzi and Hongxia Yang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=B1lj20NFDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/90cca014066ce5012911e148689a8ea97dcfb04a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "B1lj20NFDS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1368/Authors", "ICLR.cc/2020/Conference/Paper1368/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1368/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1368/Reviewers", "ICLR.cc/2020/Conference/Paper1368/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1368/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1368/Authors|ICLR.cc/2020/Conference/Paper1368/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504157061, "tmdate": 1576860554131, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1368/Authors", "ICLR.cc/2020/Conference/Paper1368/Reviewers", "ICLR.cc/2020/Conference/Paper1368/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1368/-/Official_Comment"}}}, {"id": "rylSHQ6aYH", "original": null, "number": 2, "cdate": 1571832637321, "ddate": null, "tcdate": 1571832637321, "tmdate": 1572972477754, "tddate": null, "forum": "B1lj20NFDS", "replyto": "B1lj20NFDS", "invitation": "ICLR.cc/2020/Conference/Paper1368/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The work describes an application of a spatial point process for solving problems with missing data. The authors introduce a novel method based on a non-parametric definition of point intensities for the multivariate case. The method incorporates VAE framework to effectively handle missing points via smooth intensity estimation and enjoys amortized inference for efficient computations and quick prediction generation. Using a sequence of mild assumptions, the authors show connection to a popular VAE-based collaborative filtering model, which turns out to be a special case of their approach.\n \n\nThis is a rigorous study providing theoretically justified evidence on the effectiveness of the proposed approach. Apart from the issues in the last part of experiments with classical collaborative filtering task (which will be detailed below), the work presents a solid research. I would therefore vote for accepting it.\n\n\nThe text is well structured, and all key points are clearly explained. The problem solved by the authors is well described, and the motivation for this work is convincing. The way point process theory is applied constitutes a rigorous probabilistic approach. The authors convincingly justify the need for all approximations and simplifications made in the model. One of key results making the entire model feasible is supported by the corresponding theorem proved by the authors. I haven\u2019t carefully verified all the derivations, though.\n\n \nMy major concern is related to the last part with experiments on the Movielens data. As the authors state, \u201capplications without explicit spatial information, we embed each event into a latent space as a vector.\u201d \u201cNo spatial information\u201d is exactly the case with the standard collaborative filtering task, which the authors attempt to solve. This leads to an introduction of an additional model like GNN, which is unrelated to the main approach. As GNN is involved it\u2019s not immediately obvious that the improvement over standard VAE architecture, observed in the experiments on ML-100K and ML-1M, is due to a better point process modelling.  No evidence is provided to argue that this is not simply due to a good compression or a good data preprocessing achieved by a GNN architecture itself. Therefore, the results on a pure recommender systems part are not convincing. What would happen if GNN was trained and fed into another (simpler) algorithm? Maybe a simple KNN based algorithm would produce comparable or even better results? As indicated by the work of [Dacrema, Cremonesi, Jannach 2019] on \u201cA Worrying Analysis of Recent Neural Recommendation Approaches\u201d, VAE-CF (along with several other recently proposed neural network-based methods) is inferior to even properly tuned kNN-based models. I would not be surprised, if a kNN model trained on GNN output would produce even better results than the proposed VAE-SPP.\n\nAnother related question is how incorporating GNN affects the training time? Is it comparable to that of VAE-CF or is it much worse? Computational performance is an important part in making practical decisions and should be also considered.\n\nFurthermore, both ML datasets used for tests are too small and not very representative to make any generalized conclusions. Even on a larger ML-20M dataset an optimal SVD-based model can be trained within several minutes on a standard CPU on a laptop (according to my experiments, VAE-CF would take at least twice longer on Tesla K80). Therefore, it can hardly be considered a realistic example. In practice, there could be millions and hundreds of millions of items. The authors even mention it in the in the introduction, using it as a vehicle to motivate their approach. However, computing similarities between that many entities can be a laborious task on its own, which adds an extra layer of complexity and again is not directly related to the main approach. It can easily become a bottleneck or make further computations inefficient. More efficient similarity computations may in contrast reduce the resulting accuracy.\nThe issue can get even worse, because, unlike classical MF methods, there\u2019s still no proper support for sparse operations in NN frameworks. In the VAE framework it means that, during the training, user batches will be converted into dense arrays and may become inefficient to work with in terms of memory and CPU utilization (a few non-zero entries vs. hundreds of millions of explicitly stored zeroes).\nIn spite of all this, I\u2019d also suggest rephrasing \u201cWe validate these bene\ufb01ts through extensive experiments\u201d as it sounds a bit exaggerated (if we are considering real recommender systems applications). I agree that the proposed approach is potentially applicable in real cases for recommender systems, however, there\u2019s still not enough evidence for this. In fact, I don\u2019t even think that completely removing the part with ML-100K and ML-1M datasets would make the whole work any worse. Clearly stating the region of applicability of the proposed approach would be enough. Right now some statements in this section in contrast are raising concerns rather than convincing the reader. The wording should be at least changed, so that readers do not get an impression that the case with classical CF task is solved purely by the proposed VAE-SPP approach.\n\nOther remarks to help improve the text:\n1) \u201c\u2026 points are more likely to \u2026 form clusters than the simple Poisson process \u2026\u201d the sentence seems to be inconsistent.\n2) \u201cThe generative process of our model can be described as follow:\u201d -> \u2026 as follows:\n3) Page 4, last paragraph, line 6 \u2013 shouldn\u2019t the upper bound for summation be N_u instead of just N?\n\nReferences:\nDacrema, Maurizio Ferrari, Paolo Cremonesi, and Dietmar Jannach. \"Are we really making much progress? A worrying analysis of recent neural recommendation approaches.\" In Proceedings of the 13th ACM Conference on Recommender Systems, pp. 101-109. ACM, 2019."}, "signatures": ["ICLR.cc/2020/Conference/Paper1368/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1368/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Autoencoders for Highly Multivariate Spatial Point Processes Intensities", "authors": ["Baichuan Yuan", "Xiaowei Wang", "Jianxin Ma", "Chang Zhou", "Andrea L. Bertozzi", "Hongxia Yang"], "authorids": ["ybcmath@gmail.com", "daemon.wxw@alibaba-inc.com", "majx13fromthu@gmail.com", "ericzhou.zc@alibaba-inc.com", "bertozzi@math.ucla.edu", "yang.yhx@alibaba-inc.com"], "keywords": ["VAE", "collaborative filtering", "recommender systems", "spatial point process"], "abstract": "Multivariate spatial point process models can describe heterotopic data over space. However, highly multivariate intensities are computationally challenging due to the curse of dimensionality. To bridge this gap, we introduce a declustering based hidden variable model that leads to an efficient inference procedure via a variational autoencoder (VAE). We also prove that this model is a generalization of the VAE-based model for collaborative filtering. This leads to an interesting application of spatial point process models to recommender systems. Experimental results show the method's utility on both synthetic data and real-world data sets.\n", "pdf": "/pdf/e76b11a460c49fcd85d7c7218adf083c049877f1.pdf", "paperhash": "yuan|variational_autoencoders_for_highly_multivariate_spatial_point_processes_intensities", "_bibtex": "@inproceedings{\nYuan2020Variational,\ntitle={Variational Autoencoders for Highly Multivariate Spatial Point Processes Intensities},\nauthor={Baichuan Yuan and Xiaowei Wang and Jianxin Ma and Chang Zhou and Andrea L. Bertozzi and Hongxia Yang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=B1lj20NFDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/90cca014066ce5012911e148689a8ea97dcfb04a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "B1lj20NFDS", "replyto": "B1lj20NFDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1368/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1368/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575691692068, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1368/Reviewers"], "noninvitees": [], "tcdate": 1570237738397, "tmdate": 1575691692082, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1368/-/Official_Review"}}}, {"id": "rygQxkld9B", "original": null, "number": 3, "cdate": 1572499178996, "ddate": null, "tcdate": 1572499178996, "tmdate": 1572972477709, "tddate": null, "forum": "B1lj20NFDS", "replyto": "B1lj20NFDS", "invitation": "ICLR.cc/2020/Conference/Paper1368/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "ICLR review\n\nIn this paper, the authors propose to tackle the multivariate spatial point process model with a variational inference approach. The variational inference is implemented with MLP (amortized inference). In experiments, the results show that the proposed approach outperforms VAE-based collaborative filtering on Gowalla datasets and MovieLens datasets.\n\nMy overall judgement of this paper leans to acceptation. However, by doing a quick comparison with Liang's VAE-CF paper. The proposed algorithm seems to be an extension or modification of Liang's framework. Therefore I guess the main contribution of this paper is Eq. (9). If so, I'm expecting more detailed comparison with VAE-CF in the paper (not only quantitive evaluation).\n\nQuestions:\n\n- In Liang's paper, I see they report the evaluation results on both ML-1M and ML-20M dataset. However, in this paper, the results are reported on ML-100K and ML-1M. Why not evaluate the model on the bigger ML-20M dataset?\n\n- In Liang's paper and also He's paper (Neural Collaborative Filtering), they report NDCG@10 on ML-1M dataset. The NCF approach reaches a NDCG@10 of 0.426, Multi-DAE (denoising version of Liang's model) reaches 0.446. You are reporting NDCG@100, which is a different measure. However, the numbers in Table 4 seem to be lower than what I expected. Can you compare with them in the same condition?"}, "signatures": ["ICLR.cc/2020/Conference/Paper1368/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1368/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Autoencoders for Highly Multivariate Spatial Point Processes Intensities", "authors": ["Baichuan Yuan", "Xiaowei Wang", "Jianxin Ma", "Chang Zhou", "Andrea L. Bertozzi", "Hongxia Yang"], "authorids": ["ybcmath@gmail.com", "daemon.wxw@alibaba-inc.com", "majx13fromthu@gmail.com", "ericzhou.zc@alibaba-inc.com", "bertozzi@math.ucla.edu", "yang.yhx@alibaba-inc.com"], "keywords": ["VAE", "collaborative filtering", "recommender systems", "spatial point process"], "abstract": "Multivariate spatial point process models can describe heterotopic data over space. However, highly multivariate intensities are computationally challenging due to the curse of dimensionality. To bridge this gap, we introduce a declustering based hidden variable model that leads to an efficient inference procedure via a variational autoencoder (VAE). We also prove that this model is a generalization of the VAE-based model for collaborative filtering. This leads to an interesting application of spatial point process models to recommender systems. Experimental results show the method's utility on both synthetic data and real-world data sets.\n", "pdf": "/pdf/e76b11a460c49fcd85d7c7218adf083c049877f1.pdf", "paperhash": "yuan|variational_autoencoders_for_highly_multivariate_spatial_point_processes_intensities", "_bibtex": "@inproceedings{\nYuan2020Variational,\ntitle={Variational Autoencoders for Highly Multivariate Spatial Point Processes Intensities},\nauthor={Baichuan Yuan and Xiaowei Wang and Jianxin Ma and Chang Zhou and Andrea L. Bertozzi and Hongxia Yang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=B1lj20NFDS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/90cca014066ce5012911e148689a8ea97dcfb04a.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "B1lj20NFDS", "replyto": "B1lj20NFDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1368/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1368/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575691692068, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1368/Reviewers"], "noninvitees": [], "tcdate": 1570237738397, "tmdate": 1575691692082, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1368/-/Official_Review"}}}], "count": 8}