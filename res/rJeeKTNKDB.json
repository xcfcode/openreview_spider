{"notes": [{"id": "rJeeKTNKDB", "original": "Byl66ohwPB", "number": 657, "cdate": 1569439096258, "ddate": null, "tcdate": 1569439096258, "tmdate": 1577168269667, "tddate": null, "forum": "rJeeKTNKDB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["wengong@csail.mit.edu", "regina@csail.mit.edu", "tommi@csail.mit.edu"], "title": "Hierarchical Graph-to-Graph Translation for Molecules", "authors": ["Wengong Jin", "Regina Barzilay", "Tommi Jaakkola"], "pdf": "/pdf/92715f6776aa78d64a734109bcc45d4233a11cbf.pdf", "TL;DR": "We propose a multi-resolution, hierarchically coupled encoder-decoder for graph-to-graph translation.", "abstract": "The problem of accelerating drug discovery relies heavily on automatic tools to optimize precursor molecules to afford them with better biochemical properties. Our work in this paper substantially extends prior state-of-the-art on graph-to-graph translation methods for molecular optimization. In particular, we realize coherent multi-resolution representations by interweaving the encoding of substructure components with the atom-level encoding of the original molecular graph. Moreover, our graph decoder is fully autoregressive, and interleaves each step of adding a new substructure with the process of resolving its attachment to the emerging molecule. We evaluate our model on multiple molecular optimization tasks and show that our model significantly outperforms previous state-of-the-art baselines.", "code": "https://www.dropbox.com/sh/6lem7o23f3ds6rw/AAC8N7mqYYrGvWtuZd-o01Usa?dl=0", "keywords": ["graph generation", "deep learning"], "paperhash": "jin|hierarchical_graphtograph_translation_for_molecules", "original_pdf": "/attachment/b3901f73d0b58a8932a020deadd32140fb99e355.pdf", "_bibtex": "@misc{\njin2020hierarchical,\ntitle={Hierarchical Graph-to-Graph Translation for Molecules},\nauthor={Wengong Jin and Regina Barzilay and Tommi Jaakkola},\nyear={2020},\nurl={https://openreview.net/forum?id=rJeeKTNKDB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "IyNIqO03jK", "original": null, "number": 1, "cdate": 1576798702500, "ddate": null, "tcdate": 1576798702500, "tmdate": 1576800933506, "tddate": null, "forum": "rJeeKTNKDB", "replyto": "rJeeKTNKDB", "invitation": "ICLR.cc/2020/Conference/Paper657/-/Decision", "content": {"decision": "Reject", "comment": "Two reviewers are negative on this paper while the other reviewer is slightly positive. Overall, the paper does not make the bar of ICLR. A reject is recommended.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["wengong@csail.mit.edu", "regina@csail.mit.edu", "tommi@csail.mit.edu"], "title": "Hierarchical Graph-to-Graph Translation for Molecules", "authors": ["Wengong Jin", "Regina Barzilay", "Tommi Jaakkola"], "pdf": "/pdf/92715f6776aa78d64a734109bcc45d4233a11cbf.pdf", "TL;DR": "We propose a multi-resolution, hierarchically coupled encoder-decoder for graph-to-graph translation.", "abstract": "The problem of accelerating drug discovery relies heavily on automatic tools to optimize precursor molecules to afford them with better biochemical properties. Our work in this paper substantially extends prior state-of-the-art on graph-to-graph translation methods for molecular optimization. In particular, we realize coherent multi-resolution representations by interweaving the encoding of substructure components with the atom-level encoding of the original molecular graph. Moreover, our graph decoder is fully autoregressive, and interleaves each step of adding a new substructure with the process of resolving its attachment to the emerging molecule. We evaluate our model on multiple molecular optimization tasks and show that our model significantly outperforms previous state-of-the-art baselines.", "code": "https://www.dropbox.com/sh/6lem7o23f3ds6rw/AAC8N7mqYYrGvWtuZd-o01Usa?dl=0", "keywords": ["graph generation", "deep learning"], "paperhash": "jin|hierarchical_graphtograph_translation_for_molecules", "original_pdf": "/attachment/b3901f73d0b58a8932a020deadd32140fb99e355.pdf", "_bibtex": "@misc{\njin2020hierarchical,\ntitle={Hierarchical Graph-to-Graph Translation for Molecules},\nauthor={Wengong Jin and Regina Barzilay and Tommi Jaakkola},\nyear={2020},\nurl={https://openreview.net/forum?id=rJeeKTNKDB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "rJeeKTNKDB", "replyto": "rJeeKTNKDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795722398, "tmdate": 1576800273689, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper657/-/Decision"}}}, {"id": "SJx0vc3Bsr", "original": null, "number": 3, "cdate": 1573403238430, "ddate": null, "tcdate": 1573403238430, "tmdate": 1573684480817, "tddate": null, "forum": "rJeeKTNKDB", "replyto": "Bkep99YXqr", "invitation": "ICLR.cc/2020/Conference/Paper657/-/Official_Comment", "content": {"title": "Response (with a new figure in the paper)", "comment": "Thank you for your insightful comments. We would like to first clarify the difference between our method and previous junction tree approach:\n\nJunction tree method of [Jin et al. 2019]:\n - Two independently operating encoders, one for the junction tree, the other for the original graph\n - Decoding is a strictly two-stage process (latent vectors -> junction tree -> graph) where the decoded junction tree is not affected by how the substructures are attached together\n - The graph decoder operates locally and predicts attachments between connected substructures in the junction tree independently during training.\n\nThe proposed approach:\n - Our encoder is a unified hierarchical message passing network where lower levels directly impact higher level (substructure) representations.\n - Previous attachment choices directly guide which substructures are/can be added to the expanding molecular structure.\n - Our hierarchical decoder unravels substructure choices together with their attachments in an autoregressive manner.\n\n\nQ1: What\u2019s the novelty / contribution of our approach?\nOur approach seeks to address two key limitations of the junction tree method [Jin et al. 2019], which is illustrated in Figure 1 in the paper (page 2):\n - Their decoding is a strictly two-stage process. In the first stage, substructures are chosen without regard to how they can be attached to each other in the second stage. Therefore, it can result in invalid junction trees that cannot be realized into any molecule (see Figure 1a).\n - Their local graph decoder can lead to inconsistent substructure attachments (see Figure 1b).\n\nThe first problem is addressed by our hierarchical decoding process, where the predicted attachments are fed into decoder message passing network to guide substructure prediction. We solve the second problem by using an autoregressive decoder where previous attachment choices directly impact later substructure and attachment predictions.\n\nQ2: What\u2019s the merit of autoregressive decoder?\nAutoregressive decoding prevents the model from predicting inconsistent substructure attachments (as illustrated by Figure 1b in the paper). As shown in the experiment, our autoregressive decoder indeed outperforms JTNN (e.g., 85.9% vs 77.8% on the DRD2 task).\n\nQ3: What does \"coherent multi-resolution representations\" mean?\n\u201cMulti-resolution representation\u201d refers to the substructure and atom embeddings. They together represent molecules at multiple levels. We used the word \u201ccoherent\u201d because our substructure and atom encodings are learned by one hierarchical MPN instead of two separate MPNs as in the junction tree method."}, "signatures": ["ICLR.cc/2020/Conference/Paper657/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper657/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["wengong@csail.mit.edu", "regina@csail.mit.edu", "tommi@csail.mit.edu"], "title": "Hierarchical Graph-to-Graph Translation for Molecules", "authors": ["Wengong Jin", "Regina Barzilay", "Tommi Jaakkola"], "pdf": "/pdf/92715f6776aa78d64a734109bcc45d4233a11cbf.pdf", "TL;DR": "We propose a multi-resolution, hierarchically coupled encoder-decoder for graph-to-graph translation.", "abstract": "The problem of accelerating drug discovery relies heavily on automatic tools to optimize precursor molecules to afford them with better biochemical properties. Our work in this paper substantially extends prior state-of-the-art on graph-to-graph translation methods for molecular optimization. In particular, we realize coherent multi-resolution representations by interweaving the encoding of substructure components with the atom-level encoding of the original molecular graph. Moreover, our graph decoder is fully autoregressive, and interleaves each step of adding a new substructure with the process of resolving its attachment to the emerging molecule. We evaluate our model on multiple molecular optimization tasks and show that our model significantly outperforms previous state-of-the-art baselines.", "code": "https://www.dropbox.com/sh/6lem7o23f3ds6rw/AAC8N7mqYYrGvWtuZd-o01Usa?dl=0", "keywords": ["graph generation", "deep learning"], "paperhash": "jin|hierarchical_graphtograph_translation_for_molecules", "original_pdf": "/attachment/b3901f73d0b58a8932a020deadd32140fb99e355.pdf", "_bibtex": "@misc{\njin2020hierarchical,\ntitle={Hierarchical Graph-to-Graph Translation for Molecules},\nauthor={Wengong Jin and Regina Barzilay and Tommi Jaakkola},\nyear={2020},\nurl={https://openreview.net/forum?id=rJeeKTNKDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rJeeKTNKDB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper657/Authors", "ICLR.cc/2020/Conference/Paper657/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper657/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper657/Reviewers", "ICLR.cc/2020/Conference/Paper657/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper657/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper657/Authors|ICLR.cc/2020/Conference/Paper657/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504168202, "tmdate": 1576860539763, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper657/Authors", "ICLR.cc/2020/Conference/Paper657/Reviewers", "ICLR.cc/2020/Conference/Paper657/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper657/-/Official_Comment"}}}, {"id": "rygYKu3HjS", "original": null, "number": 2, "cdate": 1573402753038, "ddate": null, "tcdate": 1573402753038, "tmdate": 1573684471457, "tddate": null, "forum": "rJeeKTNKDB", "replyto": "B1lPC22v5H", "invitation": "ICLR.cc/2020/Conference/Paper657/-/Official_Comment", "content": {"title": "Response (with a new figure in the paper)", "comment": "Thank you for your insightful comments. We want to first explain the motivation of our approach. The proposed hierarchical architecture seeks to address two key limitations of the junction tree method [Jin et al. 2019], which is illustrated in Figure 1 in the paper (page 2):\n - Their decoding is a strictly two-stage process (latent vectors -> junction tree -> graph). In the first stage, substructures are chosen without regard to how they can be attached to each other in the second stage. Therefore, it can result in invalid junction trees that cannot be realized into any molecule (see Figure 1a).\n - Their local graph decoder can lead to inconsistent substructure attachments (see Figure 1b).\n\nThe first problem is addressed by our hierarchical decoding process, where the predicted attachments are fed into decoder message passing network to guide substructure prediction. We solve the second problem by using an autoregressive decoder where previous attachment choices directly impact later substructure and attachment predictions.\n\nSome clarifications:\n - The encoder is the hierarchical message passing network that outputs substructure and atom vectors (not MLP). MLP is the variational inference module that learns the latent vector z, which is in addition to the message passing network.\n - The model achieves pretty large improvements on some tasks. For example, on the DRD2 task our model shows large improvement over previous SOTA (77.8% -> 85.9%).\n\nQ1: How are the substructures generated?\nSubstructures are automatically extracted from the molecules in the training set, in order to ensure structural coverage. For a given molecule, we extract its (smallest) rings and bonds as substructures and add them to the vocabulary. This procedure is purely data-driven. \nIndeed, the substructure vocabulary provides a lot of inductive bias for the algorithm and optimizing the vocabulary for downstream task is an interesting future work.\n\nQ2: Variational decoding is not well motivated. Why not using a stochastic decoding procedure?\nWe used variational decoding for two reasons:\n - All the prior work (Seq2Seq and JTNN) used variational decoding. Therefore we adopted the same strategy to establish a direct comparison.\n - Recent work has shown that variational decoding can generate more diverse outputs than stochastic decoding (e.g., in image translation [Zhu et al., 2017] and machine translation [Shen et al., 2019]). The reason is that stochastic decoding tends to learn small, local variations (e.g., replacing single atoms), while variational decoding captures diversity beyond local variations. To show this, we trained our model without variational inference and used stochastic decoding at test time. On the logP (sim $\\geq$ 0.6) dataset, the performance drops from 2.49 to 2.06 and diversity drops from 0.381 to 0.342. On the logP (sim $\\geq$ 0.4) dataset, the performance drops from 3.98 to 3.72 and diversity drops from 0.564 to 0.502. \n\nQ3: Why not use a Transformer instead of an LSTM or GRU?\nWe used LSTM / GRU because message passing networks (MPN) are standard choices for molecules and many previous works build upon MPNs (with various parameterizations). We agree that transformer is a promising architecture for graphs (especially if further tailored to graphs) but the gains are unclear at this point. \n\nQ4: Topological Prediction: the attention is over $c_{X}^{S}$ but the text claims it should be over $c_{X}^{G}$?\nWe apologize for the confusion. This is a typo and it should be $c_{X}^{S}$. The typo is now fixed.\n\nQ5: Attachment Layer MPN: the A_i seem to be a tuple $(S_i, {v_j})$. The set of attaching atoms is limited to 2 right?\nThe set of attaching atoms can be more than 2 because two rings can have three or more overlapping atoms.\n\nQ6: Since tree decompositions are not unique, does this work use different tree decompositions and DFS traversals as data augmentations?\nWe didn\u2019t use different tree decompositions / DFS traversals for data augmentation because none of the baselines used any data augmentation strategies. \n\nQ7: Table 2b: What is a \"two-layer\" and \"one-layer\" encoder? \nTwo-layer encoder means the top substructure layer MPN is removed. One-layer encoder means the attachment layer MPN is also removed. \n\nQ8: Ablation studies, number of parameters.\nFor ablation studies, all models have a similar number of parameters. For both datasets, all the model parameters are between 6M to 6.2M. \n\nReferences\nZhu et al. \"Toward multimodal image-to-image translation.\" Advances in Neural Information Processing Systems. 2017.\nShen et al. \"Mixture Models for Diverse Machine Translation: Tricks of the Trade.\" International Conference on Machine Learning. 2019."}, "signatures": ["ICLR.cc/2020/Conference/Paper657/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper657/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["wengong@csail.mit.edu", "regina@csail.mit.edu", "tommi@csail.mit.edu"], "title": "Hierarchical Graph-to-Graph Translation for Molecules", "authors": ["Wengong Jin", "Regina Barzilay", "Tommi Jaakkola"], "pdf": "/pdf/92715f6776aa78d64a734109bcc45d4233a11cbf.pdf", "TL;DR": "We propose a multi-resolution, hierarchically coupled encoder-decoder for graph-to-graph translation.", "abstract": "The problem of accelerating drug discovery relies heavily on automatic tools to optimize precursor molecules to afford them with better biochemical properties. Our work in this paper substantially extends prior state-of-the-art on graph-to-graph translation methods for molecular optimization. In particular, we realize coherent multi-resolution representations by interweaving the encoding of substructure components with the atom-level encoding of the original molecular graph. Moreover, our graph decoder is fully autoregressive, and interleaves each step of adding a new substructure with the process of resolving its attachment to the emerging molecule. We evaluate our model on multiple molecular optimization tasks and show that our model significantly outperforms previous state-of-the-art baselines.", "code": "https://www.dropbox.com/sh/6lem7o23f3ds6rw/AAC8N7mqYYrGvWtuZd-o01Usa?dl=0", "keywords": ["graph generation", "deep learning"], "paperhash": "jin|hierarchical_graphtograph_translation_for_molecules", "original_pdf": "/attachment/b3901f73d0b58a8932a020deadd32140fb99e355.pdf", "_bibtex": "@misc{\njin2020hierarchical,\ntitle={Hierarchical Graph-to-Graph Translation for Molecules},\nauthor={Wengong Jin and Regina Barzilay and Tommi Jaakkola},\nyear={2020},\nurl={https://openreview.net/forum?id=rJeeKTNKDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rJeeKTNKDB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper657/Authors", "ICLR.cc/2020/Conference/Paper657/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper657/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper657/Reviewers", "ICLR.cc/2020/Conference/Paper657/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper657/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper657/Authors|ICLR.cc/2020/Conference/Paper657/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504168202, "tmdate": 1576860539763, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper657/Authors", "ICLR.cc/2020/Conference/Paper657/Reviewers", "ICLR.cc/2020/Conference/Paper657/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper657/-/Official_Comment"}}}, {"id": "SyxQENG8oB", "original": null, "number": 4, "cdate": 1573426219375, "ddate": null, "tcdate": 1573426219375, "tmdate": 1573426219375, "tddate": null, "forum": "rJeeKTNKDB", "replyto": "r1l4ndZq5r", "invitation": "ICLR.cc/2020/Conference/Paper657/-/Official_Comment", "content": {"title": "Response", "comment": "Thank you for your insightful comments. We have fixed the typo you pointed out (and some others).\n\nQ1: In the training, the authors apply teacher forcing to the generation process with depth-first order. Why do you use depth-first order instead of other orders?\nOur hierarchical decoding process leverages the fact that graphs are generated in a depth-first order, especially topological prediction step. To use other orders such as breadth-first order, the graph decoding process needs to be modified accordingly. We chose depth-first order in order to make a fair comparison with JTNN, which also uses depth-first order."}, "signatures": ["ICLR.cc/2020/Conference/Paper657/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper657/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["wengong@csail.mit.edu", "regina@csail.mit.edu", "tommi@csail.mit.edu"], "title": "Hierarchical Graph-to-Graph Translation for Molecules", "authors": ["Wengong Jin", "Regina Barzilay", "Tommi Jaakkola"], "pdf": "/pdf/92715f6776aa78d64a734109bcc45d4233a11cbf.pdf", "TL;DR": "We propose a multi-resolution, hierarchically coupled encoder-decoder for graph-to-graph translation.", "abstract": "The problem of accelerating drug discovery relies heavily on automatic tools to optimize precursor molecules to afford them with better biochemical properties. Our work in this paper substantially extends prior state-of-the-art on graph-to-graph translation methods for molecular optimization. In particular, we realize coherent multi-resolution representations by interweaving the encoding of substructure components with the atom-level encoding of the original molecular graph. Moreover, our graph decoder is fully autoregressive, and interleaves each step of adding a new substructure with the process of resolving its attachment to the emerging molecule. We evaluate our model on multiple molecular optimization tasks and show that our model significantly outperforms previous state-of-the-art baselines.", "code": "https://www.dropbox.com/sh/6lem7o23f3ds6rw/AAC8N7mqYYrGvWtuZd-o01Usa?dl=0", "keywords": ["graph generation", "deep learning"], "paperhash": "jin|hierarchical_graphtograph_translation_for_molecules", "original_pdf": "/attachment/b3901f73d0b58a8932a020deadd32140fb99e355.pdf", "_bibtex": "@misc{\njin2020hierarchical,\ntitle={Hierarchical Graph-to-Graph Translation for Molecules},\nauthor={Wengong Jin and Regina Barzilay and Tommi Jaakkola},\nyear={2020},\nurl={https://openreview.net/forum?id=rJeeKTNKDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rJeeKTNKDB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper657/Authors", "ICLR.cc/2020/Conference/Paper657/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper657/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper657/Reviewers", "ICLR.cc/2020/Conference/Paper657/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper657/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper657/Authors|ICLR.cc/2020/Conference/Paper657/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504168202, "tmdate": 1576860539763, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper657/Authors", "ICLR.cc/2020/Conference/Paper657/Reviewers", "ICLR.cc/2020/Conference/Paper657/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper657/-/Official_Comment"}}}, {"id": "Bkep99YXqr", "original": null, "number": 1, "cdate": 1572211348615, "ddate": null, "tcdate": 1572211348615, "tmdate": 1572972568349, "tddate": null, "forum": "rJeeKTNKDB", "replyto": "rJeeKTNKDB", "invitation": "ICLR.cc/2020/Conference/Paper657/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper developed a hierarchical graph-to-graph translation model to generate molecular graphs using chemical substructures as building blocks. In contrast to previous work, the proposed model is fully autoregressive and learns coherent multi-resolution representations. The experimental results show that the proposed method outperforms previous models.\n\nA few comments: \n\n1.The novelty\n- The method seems to be almost the same as the previous junction tree based formulation.  The paper includes a straightforward hierarchical extension and provides limited novelty with respect to deep learning.  \n- Can the method be used for other types of graph generation? \n\n2. Some minor wording issues\n- For instance, in the abstract, \" In particular, we realize coherent multi-resolution representations ..\" What does this mean? \n\n3. The main claim : \" ... our graph decoder is fully autoregressive..\"  why is this a merit? \n\n4.  The paper provided results from multiple molecular optimization tasks. The results and analysis seem comprehensive. The model was shown to significantly outperform baseline methods in discovering molecules with desired properties. The model runs faster during decoding and can perform conditional translation. \n "}, "signatures": ["ICLR.cc/2020/Conference/Paper657/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper657/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["wengong@csail.mit.edu", "regina@csail.mit.edu", "tommi@csail.mit.edu"], "title": "Hierarchical Graph-to-Graph Translation for Molecules", "authors": ["Wengong Jin", "Regina Barzilay", "Tommi Jaakkola"], "pdf": "/pdf/92715f6776aa78d64a734109bcc45d4233a11cbf.pdf", "TL;DR": "We propose a multi-resolution, hierarchically coupled encoder-decoder for graph-to-graph translation.", "abstract": "The problem of accelerating drug discovery relies heavily on automatic tools to optimize precursor molecules to afford them with better biochemical properties. Our work in this paper substantially extends prior state-of-the-art on graph-to-graph translation methods for molecular optimization. In particular, we realize coherent multi-resolution representations by interweaving the encoding of substructure components with the atom-level encoding of the original molecular graph. Moreover, our graph decoder is fully autoregressive, and interleaves each step of adding a new substructure with the process of resolving its attachment to the emerging molecule. We evaluate our model on multiple molecular optimization tasks and show that our model significantly outperforms previous state-of-the-art baselines.", "code": "https://www.dropbox.com/sh/6lem7o23f3ds6rw/AAC8N7mqYYrGvWtuZd-o01Usa?dl=0", "keywords": ["graph generation", "deep learning"], "paperhash": "jin|hierarchical_graphtograph_translation_for_molecules", "original_pdf": "/attachment/b3901f73d0b58a8932a020deadd32140fb99e355.pdf", "_bibtex": "@misc{\njin2020hierarchical,\ntitle={Hierarchical Graph-to-Graph Translation for Molecules},\nauthor={Wengong Jin and Regina Barzilay and Tommi Jaakkola},\nyear={2020},\nurl={https://openreview.net/forum?id=rJeeKTNKDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rJeeKTNKDB", "replyto": "rJeeKTNKDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper657/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper657/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575088431832, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper657/Reviewers"], "noninvitees": [], "tcdate": 1570237748970, "tmdate": 1575088431848, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper657/-/Official_Review"}}}, {"id": "B1lPC22v5H", "original": null, "number": 2, "cdate": 1572486351035, "ddate": null, "tcdate": 1572486351035, "tmdate": 1572972568308, "tddate": null, "forum": "rJeeKTNKDB", "replyto": "rJeeKTNKDB", "invitation": "ICLR.cc/2020/Conference/Paper657/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "The authors present a heirarchical graph-to-graph translation method for generating novel organic molecules.\nWorking from the model of Jin et al. (2019), the authors introduce a three step heirarchy - the model first determines where a substructure should be generated, what is the substructure, then the attachments to the existing molecule.\nAll steps of this uses embeddings generated from a message passing network - these embeddings are input into a few bilinear attention layers to obtain the heirarchical generation scheme.\nThe model is trained with molecular pairs (X, Y), and a VAE loss - a hidden z vector controls the way to modify X to improve its properties.\nThe encoder is just a MLP over the difference between sum of embeddings at a atom level and at the substructure level.\nThe model is evaluated on accuracy and diversity, in both conditional and unconditional settings.\nThe experiments show a small improvement over previous SOTA algorithms.\n\nThis is a borderline paper, and I'm leaning towards a weak reject, because I don't believe the model is well motivated enough:\n- Sec 3.1 it's unclear how the substructures are generated - they provide a lot of inductive bias for the algorithm. \n  Are they automatically generated or built from a database of substructures?\n- Variational decoding does not seem well motivated enough - would a stochastic decoding procedure not work as well as having a latent vector that essentially adds noise to the training?\n- The experiments seem interesting and comprehensive - it seems that the model learns to exploit the biases and increase logP, as well as showing the ability to conditionally turn off DRD2-active properties of the molecules.\n\nSome questions:\n- Why not use a Transformer instead of an LSTM or GRU? The cell naturally acts over sets of neighbors and transformers are a natural model to tackle this problem.\n- Sec 3.1 Topological Prediction, the attention is over c_{X}^{S} but the text claims it should be over c_{X}^{G}? Is ^G the attention substructure?\n- Sec 3.1 Attachment Layer MPN: the A_i seem to be a tuple (S_i, {v_j}). The set of attaching atoms is limited to 2 right? It might be more clear to simply enumerate them here if so.\n- Sec 3.1 Substructure Tree: Since tree decompositions are not unique, does this work use the different tree decompositions and DFS traversals as data augmentations?\n- Table 2b: What is a \"two-layer\" and \"one layer\" encoder? Is it the size of the MLP or the removal of the attachment MPNs?\n- Ablation study: Since the Attachment Layer has all the substructure information, this ablation should ideally make sure the models all have a similar number of parameters, and the decrease in performance isn't due to the decrease in parameters.\n\nNits:\n- Sec 3.1 \"bi-linear\" should not have a dash, bilinear is one word.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper657/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper657/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["wengong@csail.mit.edu", "regina@csail.mit.edu", "tommi@csail.mit.edu"], "title": "Hierarchical Graph-to-Graph Translation for Molecules", "authors": ["Wengong Jin", "Regina Barzilay", "Tommi Jaakkola"], "pdf": "/pdf/92715f6776aa78d64a734109bcc45d4233a11cbf.pdf", "TL;DR": "We propose a multi-resolution, hierarchically coupled encoder-decoder for graph-to-graph translation.", "abstract": "The problem of accelerating drug discovery relies heavily on automatic tools to optimize precursor molecules to afford them with better biochemical properties. Our work in this paper substantially extends prior state-of-the-art on graph-to-graph translation methods for molecular optimization. In particular, we realize coherent multi-resolution representations by interweaving the encoding of substructure components with the atom-level encoding of the original molecular graph. Moreover, our graph decoder is fully autoregressive, and interleaves each step of adding a new substructure with the process of resolving its attachment to the emerging molecule. We evaluate our model on multiple molecular optimization tasks and show that our model significantly outperforms previous state-of-the-art baselines.", "code": "https://www.dropbox.com/sh/6lem7o23f3ds6rw/AAC8N7mqYYrGvWtuZd-o01Usa?dl=0", "keywords": ["graph generation", "deep learning"], "paperhash": "jin|hierarchical_graphtograph_translation_for_molecules", "original_pdf": "/attachment/b3901f73d0b58a8932a020deadd32140fb99e355.pdf", "_bibtex": "@misc{\njin2020hierarchical,\ntitle={Hierarchical Graph-to-Graph Translation for Molecules},\nauthor={Wengong Jin and Regina Barzilay and Tommi Jaakkola},\nyear={2020},\nurl={https://openreview.net/forum?id=rJeeKTNKDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rJeeKTNKDB", "replyto": "rJeeKTNKDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper657/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper657/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575088431832, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper657/Reviewers"], "noninvitees": [], "tcdate": 1570237748970, "tmdate": 1575088431848, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper657/-/Official_Review"}}}, {"id": "r1l4ndZq5r", "original": null, "number": 3, "cdate": 1572636844402, "ddate": null, "tcdate": 1572636844402, "tmdate": 1572972568266, "tddate": null, "forum": "rJeeKTNKDB", "replyto": "rJeeKTNKDB", "invitation": "ICLR.cc/2020/Conference/Paper657/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposed a hierarchical graph-to-graph translation method to modify compounds to improve the biochemical properties. The authors proposed to generate the new molecular in a autoregressive manner. To improve the performance of the model, the input molecular is encoded into different resolutions including atom, attachment, and substructure layer. The paper is well written and the figures in the paper also enable the paper easy to read. In the experiments, the authors compare the proposed method with serval state-of-the-art methods. The results well analyzed and the ablation study is provided. Overall, this is a good paper considering its technical contribution and writing.\n\nHowever, there are some small issues should be addressed:\n\n1. There are some typos in the paper. For example, in the topological prediction section in page 3,  \"the hidden representation of $S_k$ learned be the decoder \" -> learned be encoder.\n\n2. In the training, the authors apply teacher forcing to the generation process with depth-first order. Why do you use depth-first order not any other orders?  \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper657/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper657/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["wengong@csail.mit.edu", "regina@csail.mit.edu", "tommi@csail.mit.edu"], "title": "Hierarchical Graph-to-Graph Translation for Molecules", "authors": ["Wengong Jin", "Regina Barzilay", "Tommi Jaakkola"], "pdf": "/pdf/92715f6776aa78d64a734109bcc45d4233a11cbf.pdf", "TL;DR": "We propose a multi-resolution, hierarchically coupled encoder-decoder for graph-to-graph translation.", "abstract": "The problem of accelerating drug discovery relies heavily on automatic tools to optimize precursor molecules to afford them with better biochemical properties. Our work in this paper substantially extends prior state-of-the-art on graph-to-graph translation methods for molecular optimization. In particular, we realize coherent multi-resolution representations by interweaving the encoding of substructure components with the atom-level encoding of the original molecular graph. Moreover, our graph decoder is fully autoregressive, and interleaves each step of adding a new substructure with the process of resolving its attachment to the emerging molecule. We evaluate our model on multiple molecular optimization tasks and show that our model significantly outperforms previous state-of-the-art baselines.", "code": "https://www.dropbox.com/sh/6lem7o23f3ds6rw/AAC8N7mqYYrGvWtuZd-o01Usa?dl=0", "keywords": ["graph generation", "deep learning"], "paperhash": "jin|hierarchical_graphtograph_translation_for_molecules", "original_pdf": "/attachment/b3901f73d0b58a8932a020deadd32140fb99e355.pdf", "_bibtex": "@misc{\njin2020hierarchical,\ntitle={Hierarchical Graph-to-Graph Translation for Molecules},\nauthor={Wengong Jin and Regina Barzilay and Tommi Jaakkola},\nyear={2020},\nurl={https://openreview.net/forum?id=rJeeKTNKDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rJeeKTNKDB", "replyto": "rJeeKTNKDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper657/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper657/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575088431832, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper657/Reviewers"], "noninvitees": [], "tcdate": 1570237748970, "tmdate": 1575088431848, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper657/-/Official_Review"}}}], "count": 8}