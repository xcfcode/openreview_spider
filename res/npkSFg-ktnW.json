{"notes": [{"id": "npkSFg-ktnW", "original": "3nLb0DWqeX", "number": 2146, "cdate": 1601308236362, "ddate": null, "tcdate": 1601308236362, "tmdate": 1614985762220, "tddate": null, "forum": "npkSFg-ktnW", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration", "authorids": ["~Yunhao_Ge1", "~Gan_Xin1", "~Zhi_Xu2", "~Yao_Xiao3", "~Yunkui_Pang1", "~Yining_HE1", "~Laurent_Itti1"], "authors": ["Yunhao Ge", "Gan Xin", "Zhi Xu", "Yao Xiao", "Yunkui Pang", "Yining HE", "Laurent Itti"], "keywords": ["Generative autoencoder", "disentangled representation learning", "attribute controllable synthesis"], "abstract": "Autoencoders perform a powerful information compression framework with are construction loss and can be a regularization module in different tasks, which has no generative ability itself. We wondering if an autoencoder gains generative ability without using GAN and VAE based modification, which are two mature methods.   Here we propose a new method:  Disentanglement and ExplorationAutoencoder (DEAE), DEAE using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  For instance, given only red, green, and blue object color while mining new object color expressions in the image domain. The encoder of DEAE first turn the input sample into a disentangled latent code, then explore the latent codespace by attribute oriented interpolation.  To encourage interpolated latent code successfully output a semantically meaningful sample by the decoder, we propose a regularization procedure by \u2019reuse\u2019 encoder and constrain the output latent value which implicitly improves the quality of the interpolated sample. DEAE can become a generative model and synthesis semantic controllable samples by interpolating latent code, which can even synthesis novel attribute value never is shown in the original dataset. Experiments demonstrate how disentanglement and exploration can boost each other which empowers autoencoder generative ability. We also demonstrate that DEAE can improve the performance of downstream tasks compared with GANand VAE based generative model, especially in controllable data augmentation, dataset bias elimination (Fairness)", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ge|generative_autoencoder_controllable_synthesis_with_disentangled_exploration", "one-sentence_summary": "Disentanglement and ExplorationAutoencoder (DEAE) using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  ", "pdf": "/pdf/54f7a0173ee8280639cebee1bf852d217e73ddb5.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=8SwyiPvw_k", "_bibtex": "@misc{\nge2021generative,\ntitle={Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration},\nauthor={Yunhao Ge and Gan Xin and Zhi Xu and Yao Xiao and Yunkui Pang and Yining HE and Laurent Itti},\nyear={2021},\nurl={https://openreview.net/forum?id=npkSFg-ktnW}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 11, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "x34tFDMSjk_", "original": null, "number": 1, "cdate": 1610040371581, "ddate": null, "tcdate": 1610040371581, "tmdate": 1610473963124, "tddate": null, "forum": "npkSFg-ktnW", "replyto": "npkSFg-ktnW", "invitation": "ICLR.cc/2021/Conference/Paper2146/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "Overall, the paper makes some interesting and intuitive observations regarding the autoencoders with a cycle consistency, and aims at achieving controllable synthesis via a disentangled representation. However, the overall consensus was that the manuscript needs further iterations:\n\nIn particular:\nThe ideas should be made more precise using mathematical arguments, as it stands some ideas are (e.g. DEAE and UDV) disconnected.\n\nThe scope needs to be clarified, e.g. respective contributions of GSL-AE and DEAE, use of label information \n\nMore numerical/quantitative evaluations, the current experimentation is not convincing enough, needed for better justification (spurious and not convincing experimentations)\n\nThe English of the manuscript could be improved as it occasionally hampers the flow.\n"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration", "authorids": ["~Yunhao_Ge1", "~Gan_Xin1", "~Zhi_Xu2", "~Yao_Xiao3", "~Yunkui_Pang1", "~Yining_HE1", "~Laurent_Itti1"], "authors": ["Yunhao Ge", "Gan Xin", "Zhi Xu", "Yao Xiao", "Yunkui Pang", "Yining HE", "Laurent Itti"], "keywords": ["Generative autoencoder", "disentangled representation learning", "attribute controllable synthesis"], "abstract": "Autoencoders perform a powerful information compression framework with are construction loss and can be a regularization module in different tasks, which has no generative ability itself. We wondering if an autoencoder gains generative ability without using GAN and VAE based modification, which are two mature methods.   Here we propose a new method:  Disentanglement and ExplorationAutoencoder (DEAE), DEAE using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  For instance, given only red, green, and blue object color while mining new object color expressions in the image domain. The encoder of DEAE first turn the input sample into a disentangled latent code, then explore the latent codespace by attribute oriented interpolation.  To encourage interpolated latent code successfully output a semantically meaningful sample by the decoder, we propose a regularization procedure by \u2019reuse\u2019 encoder and constrain the output latent value which implicitly improves the quality of the interpolated sample. DEAE can become a generative model and synthesis semantic controllable samples by interpolating latent code, which can even synthesis novel attribute value never is shown in the original dataset. Experiments demonstrate how disentanglement and exploration can boost each other which empowers autoencoder generative ability. We also demonstrate that DEAE can improve the performance of downstream tasks compared with GANand VAE based generative model, especially in controllable data augmentation, dataset bias elimination (Fairness)", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ge|generative_autoencoder_controllable_synthesis_with_disentangled_exploration", "one-sentence_summary": "Disentanglement and ExplorationAutoencoder (DEAE) using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  ", "pdf": "/pdf/54f7a0173ee8280639cebee1bf852d217e73ddb5.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=8SwyiPvw_k", "_bibtex": "@misc{\nge2021generative,\ntitle={Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration},\nauthor={Yunhao Ge and Gan Xin and Zhi Xu and Yao Xiao and Yunkui Pang and Yining HE and Laurent Itti},\nyear={2021},\nurl={https://openreview.net/forum?id=npkSFg-ktnW}\n}"}, "tags": [], "invitation": {"reply": {"forum": "npkSFg-ktnW", "replyto": "npkSFg-ktnW", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040371565, "tmdate": 1610473963105, "id": "ICLR.cc/2021/Conference/Paper2146/-/Decision"}}}, {"id": "TmhImuIOn8", "original": null, "number": 4, "cdate": 1603909057511, "ddate": null, "tcdate": 1603909057511, "tmdate": 1606771779163, "tddate": null, "forum": "npkSFg-ktnW", "replyto": "npkSFg-ktnW", "invitation": "ICLR.cc/2021/Conference/Paper2146/-/Official_Review", "content": {"title": "Need to clearly state scope, method, contributions and to provide a more rigorous experimental setup.", "review": "# Summary\nThis paper proposes a new method called Disentangled Exploration Auto-Encoder (DEAE). This new method is based on \u201c(Ge at al.) Zero-shot synthesis with group-supervised learning\u201d to which a modified cyclic loss term is added. This method is trained on datasets with label supervision.\n\n# Pros\n1. Compared to \u201c(Ge at al.) Zero-shot synthesis with group-supervised learning\u201d the results seem to be more visually pleasing.\n\n# Cons\n1. The method is not clearly presented. In particular the loss terms are not mathematically expressed as equations. I don\u2019t know if we\u2019re expected to read the paper this method is based on to have detailed equations. In any case, the added cyclic loss is expressed as an equation either, so it\u2019s really hard to say what the method really does. It\u2019s also unspecified how the latent space is allocated to attributes.\n2. The scope of the method is not clearly presented either: I was under the impression that the proposed method was comparable to other unsupervised auto-encoders while in fact it requires label supervision\n3. It seems the paper claims to be more than it actually is: if I understand correctly, the sole contribution of this paper is a cyclic loss term, compared the (Ge et al) paper which can be seen as a regularizer.\n4. Experiments are mostly focused on visual inspection of images and do not appear impressive to me (except for the toy dataset of colored letters, but then I don\u2019t know what the SotA is like). Very few numerical results (save for dataset bias elimination) are presented. Results are not compared to other SotA methods, except the (Ge at al) paper which the method is based upon. Experimental setup is very incomplete.\n\n# Questions and nits\n1. It would have benefited my comprehension to mention in the abstract that the proposed method requires attribute/label supervision. In its current form, it seems to claim to solve disentanglement for unsupervised auto-encoders and I find it misleading.\n2. The mention of the generative ability without GAN based training in the abstract is also confusing: the proposed method seems orthogonal to GANs and could be combined with them.\n3. Several times I see the term \u201cperfect disentanglement\u201d to describe the improved disentanglement that this method offers compared to (Ge et al). What I don\u2019t understand is what makes it \u201cperfect\u201d, can\u2019t it be further improved?\n4. \u201c<mention unsupervised auto-encoders>. We propose a different solution to empower precise attribute controllable synthesis ability on autoencoders: DEAE\u201d. To be fair, it\u2019s also a solution to a different problem scope. The proposed method uses attributes while the cited methods don\u2019t. So it\u2019s really a solution to a different problem altogether.\n5. Typo \u201cwhic h\u201d => \u201cwhich\u201d\n6. \u201cFig. 4 (d) shows that we can combine the UDVs to dicover new attribute values.\u201d Aside from the typo on \"discover\", it\u2019s unclear how you discover new attributes values (which I assume are centroid like the example you mentioned before for the blue color). Here instead, my understanding is that UDV just provides a vector along which values of interest may lie. It seems the eventual decision to make a value an attribute is manually decided by a human after inspecting the effects along an UDV axe.\n7. Downstream task performance. It is a toy dataset and it\u2019s hard to really tell the real power of the proposed method. A lot of information is missing, what are the sizes the $D_S$ and $D_L$? The only reported numbers are $D_S$ vs $D_{S+DEAE}$. What is the unreported accuracy gap between $D_{S+DEAE}$ and $D_{S+GSL-AE}$ that leads to the later conclusion that DEAE performs better? What is the accuracy for $D_L$? No information is known about the classifier network architecture(s), parameter sizes, tuning and whether or not they overfit or what other causes could be responsible for the observed results.\n\n=====POST-REBUTTAL COMMENTS======== \nI thank the authors for the response and the efforts in the updated draft. Some of my queries were clarified, particularly concerning missing experimental details. However, unfortunately, I still think more needs to be clarified in the actual paper write up, notably on the points of non-adversarial as well as the method description.", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2146/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2146/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration", "authorids": ["~Yunhao_Ge1", "~Gan_Xin1", "~Zhi_Xu2", "~Yao_Xiao3", "~Yunkui_Pang1", "~Yining_HE1", "~Laurent_Itti1"], "authors": ["Yunhao Ge", "Gan Xin", "Zhi Xu", "Yao Xiao", "Yunkui Pang", "Yining HE", "Laurent Itti"], "keywords": ["Generative autoencoder", "disentangled representation learning", "attribute controllable synthesis"], "abstract": "Autoencoders perform a powerful information compression framework with are construction loss and can be a regularization module in different tasks, which has no generative ability itself. We wondering if an autoencoder gains generative ability without using GAN and VAE based modification, which are two mature methods.   Here we propose a new method:  Disentanglement and ExplorationAutoencoder (DEAE), DEAE using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  For instance, given only red, green, and blue object color while mining new object color expressions in the image domain. The encoder of DEAE first turn the input sample into a disentangled latent code, then explore the latent codespace by attribute oriented interpolation.  To encourage interpolated latent code successfully output a semantically meaningful sample by the decoder, we propose a regularization procedure by \u2019reuse\u2019 encoder and constrain the output latent value which implicitly improves the quality of the interpolated sample. DEAE can become a generative model and synthesis semantic controllable samples by interpolating latent code, which can even synthesis novel attribute value never is shown in the original dataset. Experiments demonstrate how disentanglement and exploration can boost each other which empowers autoencoder generative ability. We also demonstrate that DEAE can improve the performance of downstream tasks compared with GANand VAE based generative model, especially in controllable data augmentation, dataset bias elimination (Fairness)", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ge|generative_autoencoder_controllable_synthesis_with_disentangled_exploration", "one-sentence_summary": "Disentanglement and ExplorationAutoencoder (DEAE) using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  ", "pdf": "/pdf/54f7a0173ee8280639cebee1bf852d217e73ddb5.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=8SwyiPvw_k", "_bibtex": "@misc{\nge2021generative,\ntitle={Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration},\nauthor={Yunhao Ge and Gan Xin and Zhi Xu and Yao Xiao and Yunkui Pang and Yining HE and Laurent Itti},\nyear={2021},\nurl={https://openreview.net/forum?id=npkSFg-ktnW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "npkSFg-ktnW", "replyto": "npkSFg-ktnW", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2146/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538103001, "tmdate": 1606915764526, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2146/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2146/-/Official_Review"}}}, {"id": "tq8HMJeqPs8", "original": null, "number": 1, "cdate": 1603415938927, "ddate": null, "tcdate": 1603415938927, "tmdate": 1606686155807, "tddate": null, "forum": "npkSFg-ktnW", "replyto": "npkSFg-ktnW", "invitation": "ICLR.cc/2021/Conference/Paper2146/-/Official_Review", "content": {"title": "Interesting problem but novelty and evaluation are limited  ", "review": "Summary:\n\nThe paper presents an approach for controllable generation with auto-ecoders. It uses interpolation in a disentangled latent space using Group Supervised Learning. Generated samples are encoded back to the latent space as additional regularization to improve sample quality. The authors perform experiments on Fonts and RaFD datasets for controllable generation. They also show applications of their model in improving performance of classifiers and reducing bias.  \n  \n###########################################################\n\nStrengths: \n\nThe problem of controllable image generation is important and current approaches are far from perfect. Autoencoders with disentangled latent space are a promising candidate for this problem as they can both reconstruct the input and control the attributes. \n\n###########################################################\n\nWeaknesses:\n1. Literature review is inadequate and there are limited comparisons with related work. There are several other approaches that are not mentioned in the paper. Fader networks [A] also uses an encoder-decoder architecture trained to reconstruct images by disentangling salient information of the image and the values of attributes directly in the latent space. They provide a more comprehensive evaluation on CelebA and Flowers datasets while this paper use relatively simpler datasets, Fonts and RaFD. The authors need to clarify differences of their approach with [A] and provide comparisons with them. They need to include quantitative scores for their controllable generation. There are also other relevant papers such as Deep Feature Interpolation [B].\n2. Experiments are mostly performed on the Fonts dataset which is relatively simple. It would be better to perform experiments on datasets such as CelebA which has attribute annotations. \n3. Novelty of the proposed approach is limited as the authors use an existing method (GSL) for disentangling the latent space and also encoding the image back to latent space is proposed in other works such as InfoGAN and BicycleGAN.\n4. To obtain UDVs the authors train a binary classifier for each color value which is not efficient. \n5. It seems the bias experiment assumes that we know which attributes are entangled which might not be realistic. \n6. In figure 7(a) changes of colors are discrete while continuous changes are more desirable. \n7. In the results in Figure 2, it seems changing one attribute also affects the other.   \n\n############################################################\n\nReason for Rating:\n\nOverall, while autoencoders with disentangled latent space are a promising candidate for controllable generation, experimental results and novelty of the proposed approach are inadequate for publication. \n\n############################################################\n\nReferences: \n\n[A] Fader Networks: Manipulating Images by Sliding Attributes, Lample et al., NIPS 2017 \n\n[B] Deep Feature Interpolation for Image Content Changes, Upchurch et al., CVPR 2017\n\n#############################################################\n\nAfter author response: I thank the authors for their answers. However, as noted by other reviewers, experimental results and comparisons with related work are lacking, and I cannot increase my score without major changes to the paper. ", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper2146/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2146/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration", "authorids": ["~Yunhao_Ge1", "~Gan_Xin1", "~Zhi_Xu2", "~Yao_Xiao3", "~Yunkui_Pang1", "~Yining_HE1", "~Laurent_Itti1"], "authors": ["Yunhao Ge", "Gan Xin", "Zhi Xu", "Yao Xiao", "Yunkui Pang", "Yining HE", "Laurent Itti"], "keywords": ["Generative autoencoder", "disentangled representation learning", "attribute controllable synthesis"], "abstract": "Autoencoders perform a powerful information compression framework with are construction loss and can be a regularization module in different tasks, which has no generative ability itself. We wondering if an autoencoder gains generative ability without using GAN and VAE based modification, which are two mature methods.   Here we propose a new method:  Disentanglement and ExplorationAutoencoder (DEAE), DEAE using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  For instance, given only red, green, and blue object color while mining new object color expressions in the image domain. The encoder of DEAE first turn the input sample into a disentangled latent code, then explore the latent codespace by attribute oriented interpolation.  To encourage interpolated latent code successfully output a semantically meaningful sample by the decoder, we propose a regularization procedure by \u2019reuse\u2019 encoder and constrain the output latent value which implicitly improves the quality of the interpolated sample. DEAE can become a generative model and synthesis semantic controllable samples by interpolating latent code, which can even synthesis novel attribute value never is shown in the original dataset. Experiments demonstrate how disentanglement and exploration can boost each other which empowers autoencoder generative ability. We also demonstrate that DEAE can improve the performance of downstream tasks compared with GANand VAE based generative model, especially in controllable data augmentation, dataset bias elimination (Fairness)", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ge|generative_autoencoder_controllable_synthesis_with_disentangled_exploration", "one-sentence_summary": "Disentanglement and ExplorationAutoencoder (DEAE) using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  ", "pdf": "/pdf/54f7a0173ee8280639cebee1bf852d217e73ddb5.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=8SwyiPvw_k", "_bibtex": "@misc{\nge2021generative,\ntitle={Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration},\nauthor={Yunhao Ge and Gan Xin and Zhi Xu and Yao Xiao and Yunkui Pang and Yining HE and Laurent Itti},\nyear={2021},\nurl={https://openreview.net/forum?id=npkSFg-ktnW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "npkSFg-ktnW", "replyto": "npkSFg-ktnW", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2146/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538103001, "tmdate": 1606915764526, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2146/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2146/-/Official_Review"}}}, {"id": "iNLAHtrspaV", "original": null, "number": 4, "cdate": 1606285008249, "ddate": null, "tcdate": 1606285008249, "tmdate": 1606286778773, "tddate": null, "forum": "npkSFg-ktnW", "replyto": "TmhImuIOn8", "invitation": "ICLR.cc/2021/Conference/Paper2146/-/Official_Comment", "content": {"title": "Reviewer3 Response - Thanks for your feedback", "comment": "We want to thank the reviewer for their time spent and useful comments that will help us improve this paper. \n\nSome additional details on the paper:\nCons:\n1. Equation: We have updated the detailed equation of the regularization reconstruction loss as Eq. 1 and 2 in the updated paper.\n2. ~ 4. As we mentioned above (to all reviewers), the preprocess, GSL, does need the attribute label of data, however, the DEAE itself is an unsupervised manner to constrain the latent space which achieves controllable synthesis.\nOur method can further increase the controllable synthesis performance given a disentangled latent space (GSL), so most of our experiments compared with our baseline model, GSL-AE. There may be no clear controllable synthesis baselines that are similar to our settings. But we are trying to use other synthesis methods, GAN-based controllable synthesis which also needs the attribute label during training, to conduct attribute controllable synthesis and compare with our DEAE.\n\nQuestions and nits:\n1. See comments to all reviewers.\n2. Yes, as we mentioned above, DEAE can be compatible with GAN based methods by regularizing the latent space with disentangled interpolation. However, GANs intrinsically have the generative ability while auto-encoders do not. DEAE can empower the attribute controllable synthesis ability to an autoencoder based method.\n3. The term \u201cperfect disentanglement property\u201d (defined in Sec. 2.2) is an ideal property for the latent space where we can achieve attribute controllable synthesis by freely interpolating. DEAE creates a positive loop where the disentangled representation and exploration can help each other, which helps create a perfect disentangled autoencoder.\n4. See comments to all reviewers.\n5. We have corrected this typo and all other grammar errors we find.\n6. Yes, the combination of UDVs provides directions to find new attribute values with high probability. We can log the synthesized image along the path and find the new attribute value. We can also use the latent distance between synthesized images and know images in disentangled latent space to distinguish the new attribute value. Basically, UDVs provide a method to explore the distribution of each attribute value in a disentangled latent space.\n7. All dataset and accuracy information is reported in Table 1. We use Resnet-18 as our classifier, we will provide more training details in the final version.\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2146/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2146/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration", "authorids": ["~Yunhao_Ge1", "~Gan_Xin1", "~Zhi_Xu2", "~Yao_Xiao3", "~Yunkui_Pang1", "~Yining_HE1", "~Laurent_Itti1"], "authors": ["Yunhao Ge", "Gan Xin", "Zhi Xu", "Yao Xiao", "Yunkui Pang", "Yining HE", "Laurent Itti"], "keywords": ["Generative autoencoder", "disentangled representation learning", "attribute controllable synthesis"], "abstract": "Autoencoders perform a powerful information compression framework with are construction loss and can be a regularization module in different tasks, which has no generative ability itself. We wondering if an autoencoder gains generative ability without using GAN and VAE based modification, which are two mature methods.   Here we propose a new method:  Disentanglement and ExplorationAutoencoder (DEAE), DEAE using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  For instance, given only red, green, and blue object color while mining new object color expressions in the image domain. The encoder of DEAE first turn the input sample into a disentangled latent code, then explore the latent codespace by attribute oriented interpolation.  To encourage interpolated latent code successfully output a semantically meaningful sample by the decoder, we propose a regularization procedure by \u2019reuse\u2019 encoder and constrain the output latent value which implicitly improves the quality of the interpolated sample. DEAE can become a generative model and synthesis semantic controllable samples by interpolating latent code, which can even synthesis novel attribute value never is shown in the original dataset. Experiments demonstrate how disentanglement and exploration can boost each other which empowers autoencoder generative ability. We also demonstrate that DEAE can improve the performance of downstream tasks compared with GANand VAE based generative model, especially in controllable data augmentation, dataset bias elimination (Fairness)", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ge|generative_autoencoder_controllable_synthesis_with_disentangled_exploration", "one-sentence_summary": "Disentanglement and ExplorationAutoencoder (DEAE) using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  ", "pdf": "/pdf/54f7a0173ee8280639cebee1bf852d217e73ddb5.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=8SwyiPvw_k", "_bibtex": "@misc{\nge2021generative,\ntitle={Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration},\nauthor={Yunhao Ge and Gan Xin and Zhi Xu and Yao Xiao and Yunkui Pang and Yining HE and Laurent Itti},\nyear={2021},\nurl={https://openreview.net/forum?id=npkSFg-ktnW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "npkSFg-ktnW", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2146/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2146/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2146/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2146/Authors|ICLR.cc/2021/Conference/Paper2146/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2146/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923851722, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2146/-/Official_Comment"}}}, {"id": "SJL8rwe9B2r", "original": null, "number": 3, "cdate": 1606284978578, "ddate": null, "tcdate": 1606284978578, "tmdate": 1606286155773, "tddate": null, "forum": "npkSFg-ktnW", "replyto": "x0SRbSVjht", "invitation": "ICLR.cc/2021/Conference/Paper2146/-/Official_Comment", "content": {"title": "Regarding the reviewer's concern", "comment": "We want to thank the reviewer for their time spent and useful comments that will help us improve this paper.\n\nAs for Weaknesses:\nYes, the theoretical proof is hard but we give the explanation in 2.2.\n\nAs for Questions:\n1.  We now have a formal description of the regularization reconstruction loss in the updated main paper (Eq.1 and 2)\n2.  Yes, as we mentioned in the main paper 2.2, adding the regularization will help enrich the latent space that the decoder can \u2019understand\u2019, and the perfect disentanglement regularization enforce the latent representation of every attribute is understandable by the decoder, i.e., it forces, in the limit of infinite interpolated samples, the disentangled latent representation of every attribute to be convex. we have several experiments to qualitatively demonstrate that:\nAs shown in Fig.5, when doing controllable synthesis on background, size, and fonts, compared with GSL-AE, DEAE can synthesize high-quality images that change only the background-color attribute while keeping the other attributes unmodified.\n3.  We will cite this paper in the final version. Thanks!\n4.  We will add the standard deviations in the final version. Thanks!\n5.  Other baselines:\n(1) we are running comparison experiments for more VAE and GAN based methods for comparison.\n(2) We use GSL-AE and show the results in Table. 1\n(3) Yes, we will add more results in the appendix of the final version.\n\nAs for minor:\n1. Thank you for pointing out, GAE may look like generative AE or other AEs which will be confusing. What we used is a simple autoencoder.\n2. We changed our title regarding the part of non-adversarial.\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2146/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2146/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration", "authorids": ["~Yunhao_Ge1", "~Gan_Xin1", "~Zhi_Xu2", "~Yao_Xiao3", "~Yunkui_Pang1", "~Yining_HE1", "~Laurent_Itti1"], "authors": ["Yunhao Ge", "Gan Xin", "Zhi Xu", "Yao Xiao", "Yunkui Pang", "Yining HE", "Laurent Itti"], "keywords": ["Generative autoencoder", "disentangled representation learning", "attribute controllable synthesis"], "abstract": "Autoencoders perform a powerful information compression framework with are construction loss and can be a regularization module in different tasks, which has no generative ability itself. We wondering if an autoencoder gains generative ability without using GAN and VAE based modification, which are two mature methods.   Here we propose a new method:  Disentanglement and ExplorationAutoencoder (DEAE), DEAE using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  For instance, given only red, green, and blue object color while mining new object color expressions in the image domain. The encoder of DEAE first turn the input sample into a disentangled latent code, then explore the latent codespace by attribute oriented interpolation.  To encourage interpolated latent code successfully output a semantically meaningful sample by the decoder, we propose a regularization procedure by \u2019reuse\u2019 encoder and constrain the output latent value which implicitly improves the quality of the interpolated sample. DEAE can become a generative model and synthesis semantic controllable samples by interpolating latent code, which can even synthesis novel attribute value never is shown in the original dataset. Experiments demonstrate how disentanglement and exploration can boost each other which empowers autoencoder generative ability. We also demonstrate that DEAE can improve the performance of downstream tasks compared with GANand VAE based generative model, especially in controllable data augmentation, dataset bias elimination (Fairness)", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ge|generative_autoencoder_controllable_synthesis_with_disentangled_exploration", "one-sentence_summary": "Disentanglement and ExplorationAutoencoder (DEAE) using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  ", "pdf": "/pdf/54f7a0173ee8280639cebee1bf852d217e73ddb5.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=8SwyiPvw_k", "_bibtex": "@misc{\nge2021generative,\ntitle={Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration},\nauthor={Yunhao Ge and Gan Xin and Zhi Xu and Yao Xiao and Yunkui Pang and Yining HE and Laurent Itti},\nyear={2021},\nurl={https://openreview.net/forum?id=npkSFg-ktnW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "npkSFg-ktnW", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2146/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2146/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2146/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2146/Authors|ICLR.cc/2021/Conference/Paper2146/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2146/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923851722, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2146/-/Official_Comment"}}}, {"id": "YrLEiWTbPPh", "original": null, "number": 7, "cdate": 1606285616549, "ddate": null, "tcdate": 1606285616549, "tmdate": 1606285872773, "tddate": null, "forum": "npkSFg-ktnW", "replyto": "tq8HMJeqPs8", "invitation": "ICLR.cc/2021/Conference/Paper2146/-/Official_Comment", "content": {"title": "Reviewer2 Response - Thanks for your feedback", "comment": "We want to thank the reviewer for their time spent and useful comments that will help us improve this paper.\n\nSome additional details on the paper:\n\n1. We will investigate more related works and compare these works with our model. The main difference between DEAE and Fader network is that we don\u2019t need an extra discriminator to examine whether an attribute has been changed when training. Instead, we reuse the Encoder to guarantee the rest attributes are not changed while leaving the desired attribute free of inspection and we have an advantage compared with GAN based method: GAN training should carefully design and select the hyperparameters of G and D, while can not guarantee the convergence of training.\n2. We will test our model on CelebA and Flowers datasets as suggested. But the Fonts dataset is still complex to some extent, with 52 letters, 10 colors (foreground and background), 3 sizes, and 100 font styles, producing 1,404,000 different combinations. This is enough to illustrate the distinction between our model and others, especially in attribute controllable synthesis tasks.\n3. Similar to AnonReviewer3 Cons 3.\n4. Because we use the decision boundary of an SVM to compute UDV. Since SVM is designed for binary classification problems, the most prevailing strategy for an SVM to solve multi-class classification problems is one-versus-rest. Maybe we can try different methods to derive UDV, but using SVM is the most direct method that follows intuition.\n\n5. We do not need to know which attribute is entangled with the letter because after DEAE creates a disentangled latent space, we can use only the letter related dimensions as input for letter classification which has similar results. \n\n6. Since we didn\u2019t add loss in the training process constraining the change rate of the value of latent space and that of the corresponding attribute to be the same, a small change in latent space value might cause a huge change in the corresponding attribute or vice versa. Therefore, when we interpolate the latent space continuously, the attribute is not guaranteed to change continuously. \n7. Figure 2 is confusing. We will reorganize this figure. The \u2018original\u2019 row presents all possible background colors. There is no vertical relationship among the three lines: \u2018original\u2019, \u2018GSL-AE\u2019, and \u2018DEAE\u2019, which means the \u2018original\u2019 row does not represent the input of the next two rows. All images are randomly picked and we want to show controllable generation for new background and font colors by interpolation in latent space while keeping the unmodified attribute as is.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2146/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2146/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration", "authorids": ["~Yunhao_Ge1", "~Gan_Xin1", "~Zhi_Xu2", "~Yao_Xiao3", "~Yunkui_Pang1", "~Yining_HE1", "~Laurent_Itti1"], "authors": ["Yunhao Ge", "Gan Xin", "Zhi Xu", "Yao Xiao", "Yunkui Pang", "Yining HE", "Laurent Itti"], "keywords": ["Generative autoencoder", "disentangled representation learning", "attribute controllable synthesis"], "abstract": "Autoencoders perform a powerful information compression framework with are construction loss and can be a regularization module in different tasks, which has no generative ability itself. We wondering if an autoencoder gains generative ability without using GAN and VAE based modification, which are two mature methods.   Here we propose a new method:  Disentanglement and ExplorationAutoencoder (DEAE), DEAE using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  For instance, given only red, green, and blue object color while mining new object color expressions in the image domain. The encoder of DEAE first turn the input sample into a disentangled latent code, then explore the latent codespace by attribute oriented interpolation.  To encourage interpolated latent code successfully output a semantically meaningful sample by the decoder, we propose a regularization procedure by \u2019reuse\u2019 encoder and constrain the output latent value which implicitly improves the quality of the interpolated sample. DEAE can become a generative model and synthesis semantic controllable samples by interpolating latent code, which can even synthesis novel attribute value never is shown in the original dataset. Experiments demonstrate how disentanglement and exploration can boost each other which empowers autoencoder generative ability. We also demonstrate that DEAE can improve the performance of downstream tasks compared with GANand VAE based generative model, especially in controllable data augmentation, dataset bias elimination (Fairness)", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ge|generative_autoencoder_controllable_synthesis_with_disentangled_exploration", "one-sentence_summary": "Disentanglement and ExplorationAutoencoder (DEAE) using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  ", "pdf": "/pdf/54f7a0173ee8280639cebee1bf852d217e73ddb5.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=8SwyiPvw_k", "_bibtex": "@misc{\nge2021generative,\ntitle={Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration},\nauthor={Yunhao Ge and Gan Xin and Zhi Xu and Yao Xiao and Yunkui Pang and Yining HE and Laurent Itti},\nyear={2021},\nurl={https://openreview.net/forum?id=npkSFg-ktnW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "npkSFg-ktnW", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2146/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2146/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2146/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2146/Authors|ICLR.cc/2021/Conference/Paper2146/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2146/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923851722, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2146/-/Official_Comment"}}}, {"id": "22cMt-lRzSq", "original": null, "number": 6, "cdate": 1606285469605, "ddate": null, "tcdate": 1606285469605, "tmdate": 1606285778766, "tddate": null, "forum": "npkSFg-ktnW", "replyto": "s9mFCTSA7JW", "invitation": "ICLR.cc/2021/Conference/Paper2146/-/Official_Comment", "content": {"title": "Regarding the reviewer's questions and minor comments", "comment": "We want to thank the reviewer for their time spent and useful comments that will help us improve this paper.\n\nQuestions:\n1. As we mentioned in the comments to all reviewers, the DEAE approach does not necessarily depend on the supervised approach, it can be applied to any method with a latent space like GANs. We are working on more experiments on other models.\n2. Please refer to comment 3. DEAE is the foundation of exploration using UDV.\n3. Random interpolation is used because there are multiple dimensions in that latent space. There is no guarantee that different dimensions in latent space are co-related so that normal interpolation won't give good results in finding new attribute values.\n4. The MSE loss needs normalization, we are working on conducting more experiments on the quantitative comparison.\n5. D_L serves the role of baseline. We evaluate the ability for helping downstream tasks by creating an augmented training set based on D_S. It turns out that under the same setting, the augmented set generated by DEAE has the best performance. \n\nMinor comments:\n1. We will have more related works cited in the introduction including Flow-based methods in the final version.\n2. Yes GANs are easier to train and VAEs can have HD generation results, and we will have more cited works like InfoGAN in the paper. What we want to do is to have more insight into the area of attribute controllable synthesis. Our method has advantages like it\u2019s easy to train, and it\u2019s more like a module that can be used to models like GANs and VAEs. Our approach now does have many drawbacks but we will improve it in the future.\n3. Figure 2 is confusing. We retitled this figure. The \u2018original\u2019 row only presents all possible background colors. There is no vertical relationship among the three lines: \u2018original\u2019, \u2018GSL-AE\u2019, and \u2018DEAE\u2019, which means the \u2018original\u2019 row does not represent the input of the next two rows. All images are randomly picked and we only want to illustrate that DEAE generates images with less noise and more clarity compared with GSL-AE.\n4. Thank you for pointing out the typo.\n5. f_^theta is the notation of the encoder in the model while g_^phi is the decoder\n6. We will add an explanation and equation of the L_reg.\n7. We will try to use another foreground color. Actually, the target background color in the figure is red instead of orange, the exploration along UDV of red gives the result of new colors like orange.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2146/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2146/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration", "authorids": ["~Yunhao_Ge1", "~Gan_Xin1", "~Zhi_Xu2", "~Yao_Xiao3", "~Yunkui_Pang1", "~Yining_HE1", "~Laurent_Itti1"], "authors": ["Yunhao Ge", "Gan Xin", "Zhi Xu", "Yao Xiao", "Yunkui Pang", "Yining HE", "Laurent Itti"], "keywords": ["Generative autoencoder", "disentangled representation learning", "attribute controllable synthesis"], "abstract": "Autoencoders perform a powerful information compression framework with are construction loss and can be a regularization module in different tasks, which has no generative ability itself. We wondering if an autoencoder gains generative ability without using GAN and VAE based modification, which are two mature methods.   Here we propose a new method:  Disentanglement and ExplorationAutoencoder (DEAE), DEAE using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  For instance, given only red, green, and blue object color while mining new object color expressions in the image domain. The encoder of DEAE first turn the input sample into a disentangled latent code, then explore the latent codespace by attribute oriented interpolation.  To encourage interpolated latent code successfully output a semantically meaningful sample by the decoder, we propose a regularization procedure by \u2019reuse\u2019 encoder and constrain the output latent value which implicitly improves the quality of the interpolated sample. DEAE can become a generative model and synthesis semantic controllable samples by interpolating latent code, which can even synthesis novel attribute value never is shown in the original dataset. Experiments demonstrate how disentanglement and exploration can boost each other which empowers autoencoder generative ability. We also demonstrate that DEAE can improve the performance of downstream tasks compared with GANand VAE based generative model, especially in controllable data augmentation, dataset bias elimination (Fairness)", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ge|generative_autoencoder_controllable_synthesis_with_disentangled_exploration", "one-sentence_summary": "Disentanglement and ExplorationAutoencoder (DEAE) using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  ", "pdf": "/pdf/54f7a0173ee8280639cebee1bf852d217e73ddb5.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=8SwyiPvw_k", "_bibtex": "@misc{\nge2021generative,\ntitle={Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration},\nauthor={Yunhao Ge and Gan Xin and Zhi Xu and Yao Xiao and Yunkui Pang and Yining HE and Laurent Itti},\nyear={2021},\nurl={https://openreview.net/forum?id=npkSFg-ktnW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "npkSFg-ktnW", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2146/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2146/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2146/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2146/Authors|ICLR.cc/2021/Conference/Paper2146/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2146/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923851722, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2146/-/Official_Comment"}}}, {"id": "zlhD_Jz5V-X", "original": null, "number": 5, "cdate": 1606285332837, "ddate": null, "tcdate": 1606285332837, "tmdate": 1606285756362, "tddate": null, "forum": "npkSFg-ktnW", "replyto": "s9mFCTSA7JW", "invitation": "ICLR.cc/2021/Conference/Paper2146/-/Official_Comment", "content": {"title": "Regarding the reviewer's cons ", "comment": "We want to thank the reviewer for their time spent and useful comments that will help us improve this paper.\nCons:\n1. For the contribution of DEAE please refer to the part for all reviewers.\n2. The method for exploration in latent space can be used in different latent spaces such as GANs, and the preprocessing is not necessary to be a supervised approach. Please refer to comments for all reviewers for the contribution of DEAE.\n3. DEAE creates a disentangled, convex latent space and makes the latent space more robust through the interpolation. UDV is designed for explaining the latent space and exploring the distribution for each disentangled attribute-related latent space created by DEAE. To some extent, DEAE is the foundation of UDV and UDV provides more insight to understand the performance of DEAE, such as gain more explainable attribute values like new colors unseen in the training set.\nThe dataset bias elimination is a downstream task of the DEAE. DEAE can help disentangle the latent space, which can help to eliminate the bias in the dataset since the entangled attributes will be disentangled in latent space. Please refer to section 3.5 for more details.\n4. \n(1) We are working on conducting more experiments on the quantitative comparison.  \n(2) When we use interpolation to controllably change the background color, the results from GSL shows that other attribute values also changed: foreground letter merged with background and the boundary has artifacts. The results of DEAE shows a clear controllable synthesis with no artifacts on other attributes out of background color.  \n(3) The interpolation results of colors are not guaranteed to be continuous in the latent space since we didn\u2019t have a loss function to constrain the change rate of the latent space, a tiny change while interpolation may cause a huge change in the attribute.  \n(4) The evaluation of generative methods can be conducted in many aspects and the augmentation of biased datasets is a downstream task of the generative method. A classifier trained using a biased dataset can usually result in bad performance on the test set. DEAE can generate more instances with new attribute values which can aid the problem for the biased dataset.  \n(5) The Gradcam result shows that when deciding the output of the classification, the biased model focuses on the wrong areas like background information, while the unbiased model focuses on the character itself. Therefore the DEAE model can help train an unbiased model that has a more meaningful \u2018attention\u2019 on the input data.  \n5. (1) The dataset bias elimination is a downstream task of the DEAE. DEAE can help disentangle the latent space, which can help to eliminate the bias in the dataset since the entangled attributes will be disentangled in latent space. This experiment shows the quality of disentanglement through a downstream task.  \n(2) Yes, the source of bias, in reality, is not known most of the time. But in our experiment, it doesn\u2019t matter whether we know about the source of the bias since all attributes will be disentangled in the latent space. The information about the source of bias in our manually created dataset is not used for training the classifiers.  \n6. Please refer to comment 3.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2146/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2146/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration", "authorids": ["~Yunhao_Ge1", "~Gan_Xin1", "~Zhi_Xu2", "~Yao_Xiao3", "~Yunkui_Pang1", "~Yining_HE1", "~Laurent_Itti1"], "authors": ["Yunhao Ge", "Gan Xin", "Zhi Xu", "Yao Xiao", "Yunkui Pang", "Yining HE", "Laurent Itti"], "keywords": ["Generative autoencoder", "disentangled representation learning", "attribute controllable synthesis"], "abstract": "Autoencoders perform a powerful information compression framework with are construction loss and can be a regularization module in different tasks, which has no generative ability itself. We wondering if an autoencoder gains generative ability without using GAN and VAE based modification, which are two mature methods.   Here we propose a new method:  Disentanglement and ExplorationAutoencoder (DEAE), DEAE using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  For instance, given only red, green, and blue object color while mining new object color expressions in the image domain. The encoder of DEAE first turn the input sample into a disentangled latent code, then explore the latent codespace by attribute oriented interpolation.  To encourage interpolated latent code successfully output a semantically meaningful sample by the decoder, we propose a regularization procedure by \u2019reuse\u2019 encoder and constrain the output latent value which implicitly improves the quality of the interpolated sample. DEAE can become a generative model and synthesis semantic controllable samples by interpolating latent code, which can even synthesis novel attribute value never is shown in the original dataset. Experiments demonstrate how disentanglement and exploration can boost each other which empowers autoencoder generative ability. We also demonstrate that DEAE can improve the performance of downstream tasks compared with GANand VAE based generative model, especially in controllable data augmentation, dataset bias elimination (Fairness)", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ge|generative_autoencoder_controllable_synthesis_with_disentangled_exploration", "one-sentence_summary": "Disentanglement and ExplorationAutoencoder (DEAE) using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  ", "pdf": "/pdf/54f7a0173ee8280639cebee1bf852d217e73ddb5.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=8SwyiPvw_k", "_bibtex": "@misc{\nge2021generative,\ntitle={Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration},\nauthor={Yunhao Ge and Gan Xin and Zhi Xu and Yao Xiao and Yunkui Pang and Yining HE and Laurent Itti},\nyear={2021},\nurl={https://openreview.net/forum?id=npkSFg-ktnW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "npkSFg-ktnW", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2146/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2146/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2146/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2146/Authors|ICLR.cc/2021/Conference/Paper2146/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2146/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923851722, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2146/-/Official_Comment"}}}, {"id": "BgsvytcWq9L", "original": null, "number": 2, "cdate": 1606284299122, "ddate": null, "tcdate": 1606284299122, "tmdate": 1606284299122, "tddate": null, "forum": "npkSFg-ktnW", "replyto": "npkSFg-ktnW", "invitation": "ICLR.cc/2021/Conference/Paper2146/-/Official_Comment", "content": {"title": "Equation of loss function, contribution and novelty", "comment": "We want to thank all the reviewers for their time spent and useful comments that will help us improve this paper!\n\n1 Contribution and novelty compared with baseline GSL.\n\nOur proposed DEAE is designed to achieve attribute controllable synthesis based on disentangled exploration. However, the results we showed are based on a preliminary disentangled latent space which is created by GSL (need attribute label during training). To achieve attribute controllable synthesis, DEAE trying to create a positive loop between disentanglement and interpolation which achieve two things: (1) trying to create a \u2018perfect disentanglement\u2019 latent space (Sec. 2.2) (2) turn the \u2019non-convex\u2019 latent space for each attribute to be convex (Sec. 2.2).  Theoretically, our DEAE can be used on different latent spaces, we are trying to conduct more experiments on the latent space of VAE and GAN to show the improvement of controllable synthesis.\n\n2 We have updated the detailed equation of the regularization reconstruction loss as Eq. 1 and 2 in the updated paper.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2146/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2146/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration", "authorids": ["~Yunhao_Ge1", "~Gan_Xin1", "~Zhi_Xu2", "~Yao_Xiao3", "~Yunkui_Pang1", "~Yining_HE1", "~Laurent_Itti1"], "authors": ["Yunhao Ge", "Gan Xin", "Zhi Xu", "Yao Xiao", "Yunkui Pang", "Yining HE", "Laurent Itti"], "keywords": ["Generative autoencoder", "disentangled representation learning", "attribute controllable synthesis"], "abstract": "Autoencoders perform a powerful information compression framework with are construction loss and can be a regularization module in different tasks, which has no generative ability itself. We wondering if an autoencoder gains generative ability without using GAN and VAE based modification, which are two mature methods.   Here we propose a new method:  Disentanglement and ExplorationAutoencoder (DEAE), DEAE using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  For instance, given only red, green, and blue object color while mining new object color expressions in the image domain. The encoder of DEAE first turn the input sample into a disentangled latent code, then explore the latent codespace by attribute oriented interpolation.  To encourage interpolated latent code successfully output a semantically meaningful sample by the decoder, we propose a regularization procedure by \u2019reuse\u2019 encoder and constrain the output latent value which implicitly improves the quality of the interpolated sample. DEAE can become a generative model and synthesis semantic controllable samples by interpolating latent code, which can even synthesis novel attribute value never is shown in the original dataset. Experiments demonstrate how disentanglement and exploration can boost each other which empowers autoencoder generative ability. We also demonstrate that DEAE can improve the performance of downstream tasks compared with GANand VAE based generative model, especially in controllable data augmentation, dataset bias elimination (Fairness)", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ge|generative_autoencoder_controllable_synthesis_with_disentangled_exploration", "one-sentence_summary": "Disentanglement and ExplorationAutoencoder (DEAE) using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  ", "pdf": "/pdf/54f7a0173ee8280639cebee1bf852d217e73ddb5.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=8SwyiPvw_k", "_bibtex": "@misc{\nge2021generative,\ntitle={Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration},\nauthor={Yunhao Ge and Gan Xin and Zhi Xu and Yao Xiao and Yunkui Pang and Yining HE and Laurent Itti},\nyear={2021},\nurl={https://openreview.net/forum?id=npkSFg-ktnW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "npkSFg-ktnW", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2146/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2146/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2146/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2146/Authors|ICLR.cc/2021/Conference/Paper2146/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2146/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923851722, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2146/-/Official_Comment"}}}, {"id": "s9mFCTSA7JW", "original": null, "number": 2, "cdate": 1603707279124, "ddate": null, "tcdate": 1603707279124, "tmdate": 1605024277920, "tddate": null, "forum": "npkSFg-ktnW", "replyto": "npkSFg-ktnW", "invitation": "ICLR.cc/2021/Conference/Paper2146/-/Official_Review", "content": {"title": "This paper proposed to refine an encoding by latent code interpolation followed by decoding/reencoding for cycle reconstruction. A further exploration approach UDV is proposed to generate unseen combination of attributes.", "review": "Summary\n\nThis paper proposed to explore a given disentangled latent code and explore it through random interpolations. The idea is to ensure these interpolated codes rely inside data convex hull by enforcing latent code reconstruction by first decoding and then reencoding this explored codes. The authors proposed a way to manipulate the final latent space by using Unit Direction Vector (UDV) to generate unseen attribute values. The results are illustrated on 2 datasets (Fonts and RaFD) both qualitatively and quantitatively.\n\nReason for score\n\nOverall I vote for reject, this paper has limited contribution and lack of consistency (disconnected ideas: DEAE and UDV), clarity (respective contributions of GSL-AE and DEAE) and justification (spurious and not convincing experimentations).\n\n\nPros\n1. The general topic of having more controlable synthesis by having more disentangled representation if of clear interest for the field. \n2. The idea of reconstructing random interpolations of valid latent codes by decoding/reencoding is interesting. I don't think this is novel, but not widspread enough in the field so far, so the interest remains. \n\nCons\n1. While the topic is of interest for the field, the interest of the proposed approach is clearly limited since it relies on a preprocessing step (GSL-AE) of which it is already the role. A clearer distinction of the contributions of each step would help to illustrate the additional interest of DEAE. Unfortunatly the paper relies too much on GSL-AE which limits the potential scope of their main contribution which could be wider.\n2. The title is misleading since it presents the approach to proposed a \"disentangled exploration\" while it is essentially provided by GSL-AE used as a preprocessing step. Thus, it would also be good to mention that the approach is supervised (like GSL-AE).\n3. The paper lacks of clarity: UDV or \"dataset bias elimination\" seems to be  spurious addition and are not really well connected in the paper. It's hard to understand how it contributes to illustrate the interest of DEAE.\n4. Results are not convincing.\n- MSE loss between latent spaces from different methods cannot be compared at all. We can imagine spurious differences only due to scale differences for instance.\n- Fig 2. is mentioned p.5 to illustrate the qualitative superiority of DEAE over GSL-AE: not really obvious of this state.\n- Section 3.3 + fig 7.: interpolation is not smooth which contradicts the quality of the representation and the interest of UDV.\n- Section 3.4: the idea of evaluating the performance of generative methods through their capacity of improving a classification task by augmenting the initial dataset, is very indirect and not really convincing.\n- Gradcam results (Fig. 8) does not illustrate any improvement in favor of background information for the \"unbiased model\"\n5. \"Dataset bias elimination\"\n- This section seems spurious. Nothing in the proposed approach is really specific to such an application appart the global context to which it is attached. I don't see what this section brings to the paper.\n- The way the unbias model is obtained is not realistic since you need to know what information has to be dropped, whereas in real applications you generally don't know the source of bias.\n6. While having thinner way of exploring the latent space is interesting, the proposed UDV approach sounds spurious and ad hoc and does not seem to be connected to DEAE.\n\nQuestions\n1. What is the context of application of your approaches since it relies on a supervised approach to create the initial disentangled embedding ? Coutrolable synthesis is generally understood in an unsupervised setting.\n2. Is there a link between UDV exploration and the way DEAE is learnt ?\n3. Why using \"random interpolation\" for inference and illustrating performance (in Fig. 5) ? It would be clearer with standard interpolation between left and right bounds. I also would expect that interpolations would reach (or at least get closer to) the targeted right bound.\n4. How do you ensure that MSE (from section 3.2) can be compared between totally different latent spaces ?\n5. Section 3.4: Why D_S is used rather than D_L for further analyses ? (to get augmented datasets)\n\n\nMinor comments\n1. Intro: Flows could be mentionned on top of VAE and GANs\n2. Intro on GAN & VAE limits are too much like a caricature regarding recent results. VAE can be used to generate HD images now, and GAN are much easier to train these days with GP strategy or different learning rates between generator and discriminator for instance. Approaches like InfoGAN could be mentioned to illustrate standard strategies to control GANs.\n3. Fig 2. Not clear which kind of interpolation has been used for GSL-AE and DEAE since neither font, font size, font color, letter nor background color are interpolated in the figures. This figure would be more powerful to stick to one (or a few) letter(s) and change only the considered attribute (background or font color). Here the comparison and the illustration of the effect is not easy.\n4. Section 2. \"whic h maps\" \uf0e0 \"which maps\"\n5. notation \"*\" has not been introduced (like in f_theta^* and g_phi^*)\n6. L_reg has not been introduced or referred in the paper.\n7. Fig 7. Choosing a fg color different from the targeted bg color would be better", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper2146/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2146/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration", "authorids": ["~Yunhao_Ge1", "~Gan_Xin1", "~Zhi_Xu2", "~Yao_Xiao3", "~Yunkui_Pang1", "~Yining_HE1", "~Laurent_Itti1"], "authors": ["Yunhao Ge", "Gan Xin", "Zhi Xu", "Yao Xiao", "Yunkui Pang", "Yining HE", "Laurent Itti"], "keywords": ["Generative autoencoder", "disentangled representation learning", "attribute controllable synthesis"], "abstract": "Autoencoders perform a powerful information compression framework with are construction loss and can be a regularization module in different tasks, which has no generative ability itself. We wondering if an autoencoder gains generative ability without using GAN and VAE based modification, which are two mature methods.   Here we propose a new method:  Disentanglement and ExplorationAutoencoder (DEAE), DEAE using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  For instance, given only red, green, and blue object color while mining new object color expressions in the image domain. The encoder of DEAE first turn the input sample into a disentangled latent code, then explore the latent codespace by attribute oriented interpolation.  To encourage interpolated latent code successfully output a semantically meaningful sample by the decoder, we propose a regularization procedure by \u2019reuse\u2019 encoder and constrain the output latent value which implicitly improves the quality of the interpolated sample. DEAE can become a generative model and synthesis semantic controllable samples by interpolating latent code, which can even synthesis novel attribute value never is shown in the original dataset. Experiments demonstrate how disentanglement and exploration can boost each other which empowers autoencoder generative ability. We also demonstrate that DEAE can improve the performance of downstream tasks compared with GANand VAE based generative model, especially in controllable data augmentation, dataset bias elimination (Fairness)", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ge|generative_autoencoder_controllable_synthesis_with_disentangled_exploration", "one-sentence_summary": "Disentanglement and ExplorationAutoencoder (DEAE) using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  ", "pdf": "/pdf/54f7a0173ee8280639cebee1bf852d217e73ddb5.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=8SwyiPvw_k", "_bibtex": "@misc{\nge2021generative,\ntitle={Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration},\nauthor={Yunhao Ge and Gan Xin and Zhi Xu and Yao Xiao and Yunkui Pang and Yining HE and Laurent Itti},\nyear={2021},\nurl={https://openreview.net/forum?id=npkSFg-ktnW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "npkSFg-ktnW", "replyto": "npkSFg-ktnW", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2146/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538103001, "tmdate": 1606915764526, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2146/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2146/-/Official_Review"}}}, {"id": "x0SRbSVjht", "original": null, "number": 3, "cdate": 1603807010999, "ddate": null, "tcdate": 1603807010999, "tmdate": 1605024277857, "tddate": null, "forum": "npkSFg-ktnW", "replyto": "npkSFg-ktnW", "invitation": "ICLR.cc/2021/Conference/Paper2146/-/Official_Review", "content": {"title": "Good paper however the results can to be more exhaustive ", "review": "Summary: The paper proposes a new framework for adding a generative component to autoencoders without using adversarial or variational techniques. Further, the true motivation is to overcome issues due to naive interpolation (resulting in out of distribution samples) and to provide a semantic controllable synthesis in autoencoders. Empirical results show the proposed DEAE succeeds in both.\n\nStrengths:\n* I appreciate the intuition and examples throughout the paper, regarding the method itself and description of the experiments and desired outputs. This makes the paper easy to read and follow.\n* The provided results support the claims (although they lack exhaustiveness, see below).\n\n\nWeaknesses:\n* Although I agree with the intuition of the method, no theoretical analysis is provided to justify the proposed solution. \nThe empirical results seem to confirm the statements of contribution but in a very limited setup. A more exhaustive presentation would be more convincing.\n\nAlthough the paper builds on previous work, I find it quite interesting and significant to have a method for controllable synthesis. If the authors address my concerns, I am willing to increase my score.  \n\nQuestions:\n\nMethodology:\nThe main novelty in the proposed method is the L_{reg} loss term in the training of the DEAE, which was never explicitly written or explained beyond the intuitive interpretations. \n\n\nIs there any theoretical direction you can propose for justifying the claim that adding the regularisation loss helps to turn non-convex to convex latent spaces? If not, at least a toy experiment to validate this assumption might help.\n\nMissing reference:\nThe technique proposed for novel attribute mining, UVD is quite similar to the concept vectors proposed in TCAV [1].\n\nExperiments:\nOnly a few quantitative results were presented, and those are also missing standard deviations. Please add those to make the results complete.\n\nThe results for experiment 3.2, were the MSE losses normalized? If the latent spaces correspond to different models, how do we know if the numbers are comparable?\n\nOther baselines:\n- Generative models: at least some comparison to vanilla VAE, GANs as a sanity check (if the claim is generative AE)\n- Why is GSL-AE not used in 3.4?\n- Could you please provide more plots of the nice results (Figures 5 and 6) in the appendix just to confirm the presented results were not \u201ccherry-picked\u201d.\n\n\nMinor:\n- In Figure 5 the acronym for general AE is \u2018AE\u2019 instead of \u2018GAE\u2019\n- I don\u2019t see the need for  \u2018non-adversarial\u2019 in the title.\n\n[1] Kim, Been, et al. \"Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav).\"\u00a0International conference on machine learning. PMLR, 2018 ", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2146/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2146/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration", "authorids": ["~Yunhao_Ge1", "~Gan_Xin1", "~Zhi_Xu2", "~Yao_Xiao3", "~Yunkui_Pang1", "~Yining_HE1", "~Laurent_Itti1"], "authors": ["Yunhao Ge", "Gan Xin", "Zhi Xu", "Yao Xiao", "Yunkui Pang", "Yining HE", "Laurent Itti"], "keywords": ["Generative autoencoder", "disentangled representation learning", "attribute controllable synthesis"], "abstract": "Autoencoders perform a powerful information compression framework with are construction loss and can be a regularization module in different tasks, which has no generative ability itself. We wondering if an autoencoder gains generative ability without using GAN and VAE based modification, which are two mature methods.   Here we propose a new method:  Disentanglement and ExplorationAutoencoder (DEAE), DEAE using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  For instance, given only red, green, and blue object color while mining new object color expressions in the image domain. The encoder of DEAE first turn the input sample into a disentangled latent code, then explore the latent codespace by attribute oriented interpolation.  To encourage interpolated latent code successfully output a semantically meaningful sample by the decoder, we propose a regularization procedure by \u2019reuse\u2019 encoder and constrain the output latent value which implicitly improves the quality of the interpolated sample. DEAE can become a generative model and synthesis semantic controllable samples by interpolating latent code, which can even synthesis novel attribute value never is shown in the original dataset. Experiments demonstrate how disentanglement and exploration can boost each other which empowers autoencoder generative ability. We also demonstrate that DEAE can improve the performance of downstream tasks compared with GANand VAE based generative model, especially in controllable data augmentation, dataset bias elimination (Fairness)", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "ge|generative_autoencoder_controllable_synthesis_with_disentangled_exploration", "one-sentence_summary": "Disentanglement and ExplorationAutoencoder (DEAE) using a disentangle and exploration positive iteration achieve semantic controllable synthesis especially controllable mining the novel semantic value.  ", "pdf": "/pdf/54f7a0173ee8280639cebee1bf852d217e73ddb5.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=8SwyiPvw_k", "_bibtex": "@misc{\nge2021generative,\ntitle={Generative Auto-Encoder: Controllable Synthesis with Disentangled Exploration},\nauthor={Yunhao Ge and Gan Xin and Zhi Xu and Yao Xiao and Yunkui Pang and Yining HE and Laurent Itti},\nyear={2021},\nurl={https://openreview.net/forum?id=npkSFg-ktnW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "npkSFg-ktnW", "replyto": "npkSFg-ktnW", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2146/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538103001, "tmdate": 1606915764526, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2146/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2146/-/Official_Review"}}}], "count": 12}