{"notes": [{"id": "Syxwsp4KDB", "original": "rkl5VXJdwH", "number": 746, "cdate": 1569439134539, "ddate": null, "tcdate": 1569439134539, "tmdate": 1577168226087, "tddate": null, "forum": "Syxwsp4KDB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "TED: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising", "authors": ["Ziyi Yang", "Chenguang Zhu", "Michael Zeng", "Xuedong Huang", "Eric Darve"], "authorids": ["ziyi.yang@stanford.edu", "chezhu@microsoft.com", "nzeng@microsoft.com", "xdh@microsoft.com", "darve@stanford.edu"], "keywords": ["text summarization", "unsupervised learning", "natural language processing"], "TL;DR": "A new state-of-the-art for unsupervised abstractive text summarization", "abstract": "Text summarization aims to extract essential information from a piece of text and transform it into a concise version. Existing unsupervised abstractive summarization models use recurrent neural networks framework and ignore abundant unlabeled corpora resources. In order to address these issues, we propose TED, a transformer-based unsupervised summarization system with dataset-agnostic pretraining. We first leverage the lead bias in news articles to pretrain the model on large-scale corpora. Then, we finetune TED on target domains through theme modeling and a denoising autoencoder to enhance the quality of summaries. Notably, TED outperforms all unsupervised abstractive baselines on NYT, CNN/DM and English Gigaword datasets with various document styles. Further analysis shows that the summaries generated by TED are abstractive and containing even higher proportions of novel tokens than those from supervised models.", "pdf": "/pdf/972b259f50fbbfcf3fab290c945bda4be815a6f4.pdf", "code": "https://drive.google.com/file/d/17pp6coa19oOTbW3JEXlS_WMb7vjcCGWJ/view?usp=sharing", "paperhash": "yang|ted_a_pretrained_unsupervised_summarization_model_with_theme_modeling_and_denoising", "original_pdf": "/attachment/4ead5f3043b51de02bc82aae239a1814800e04a8.pdf", "_bibtex": "@misc{\nyang2020ted,\ntitle={{\\{}TED{\\}}: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising},\nauthor={Ziyi Yang and Chenguang Zhu and Michael Zeng and Xuedong Huang and Eric Darve},\nyear={2020},\nurl={https://openreview.net/forum?id=Syxwsp4KDB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "45SZRyirvS", "original": null, "number": 1, "cdate": 1576798704876, "ddate": null, "tcdate": 1576798704876, "tmdate": 1576800931197, "tddate": null, "forum": "Syxwsp4KDB", "replyto": "Syxwsp4KDB", "invitation": "ICLR.cc/2020/Conference/Paper746/-/Decision", "content": {"decision": "Reject", "comment": "This paper proposes an abstractive text summarization model that takes advantage of lead bias for pretraining on unlabeled corpora and a combination of reconstruction and theme modeling loss for finetuning. Experiments on NYT, CNN/DM, and Gigaword datasets demonstrate the benefit of the proposed approach. \n\nI think this is an interesting paper and the results are reasonably convincing. My only concern is regarding a parallel submission that contains a significant overlap in terms contributions, as originally pointed out by R2 (https://openreview.net/forum?id=ryxAY34YwB). All of us had an internal discussion regarding this submission and agree that if the lead bias is considered a contribution of another paper this paper is not strong enough. \n\nDue to space constraint and the above concern, along with the issue that the two submissions contain a significant overlap in terms of authors as well, I recommend to reject this paper.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "TED: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising", "authors": ["Ziyi Yang", "Chenguang Zhu", "Michael Zeng", "Xuedong Huang", "Eric Darve"], "authorids": ["ziyi.yang@stanford.edu", "chezhu@microsoft.com", "nzeng@microsoft.com", "xdh@microsoft.com", "darve@stanford.edu"], "keywords": ["text summarization", "unsupervised learning", "natural language processing"], "TL;DR": "A new state-of-the-art for unsupervised abstractive text summarization", "abstract": "Text summarization aims to extract essential information from a piece of text and transform it into a concise version. Existing unsupervised abstractive summarization models use recurrent neural networks framework and ignore abundant unlabeled corpora resources. In order to address these issues, we propose TED, a transformer-based unsupervised summarization system with dataset-agnostic pretraining. We first leverage the lead bias in news articles to pretrain the model on large-scale corpora. Then, we finetune TED on target domains through theme modeling and a denoising autoencoder to enhance the quality of summaries. Notably, TED outperforms all unsupervised abstractive baselines on NYT, CNN/DM and English Gigaword datasets with various document styles. Further analysis shows that the summaries generated by TED are abstractive and containing even higher proportions of novel tokens than those from supervised models.", "pdf": "/pdf/972b259f50fbbfcf3fab290c945bda4be815a6f4.pdf", "code": "https://drive.google.com/file/d/17pp6coa19oOTbW3JEXlS_WMb7vjcCGWJ/view?usp=sharing", "paperhash": "yang|ted_a_pretrained_unsupervised_summarization_model_with_theme_modeling_and_denoising", "original_pdf": "/attachment/4ead5f3043b51de02bc82aae239a1814800e04a8.pdf", "_bibtex": "@misc{\nyang2020ted,\ntitle={{\\{}TED{\\}}: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising},\nauthor={Ziyi Yang and Chenguang Zhu and Michael Zeng and Xuedong Huang and Eric Darve},\nyear={2020},\nurl={https://openreview.net/forum?id=Syxwsp4KDB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "Syxwsp4KDB", "replyto": "Syxwsp4KDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795716663, "tmdate": 1576800266857, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper746/-/Decision"}}}, {"id": "Hke_3SSAYr", "original": null, "number": 2, "cdate": 1571866032307, "ddate": null, "tcdate": 1571866032307, "tmdate": 1574237095069, "tddate": null, "forum": "Syxwsp4KDB", "replyto": "Syxwsp4KDB", "invitation": "ICLR.cc/2020/Conference/Paper746/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "8: Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #3", "review": "Paper's Claims\n\nThe paper introduces a new unsupervised abstractive summarization approach called TED, using a Transformer encoder and decoder. Their main contributions are as follows:\n1) Pretraining the encoder and decoder on news articles using the first beginning as the target summary.\n2) Fine-tune on other datasets using so-called theme modeling, and separately a denoising loss.\n3) TED's performance is claimed to significantly improve over GPT-2 while not being too far from the best unsupervised extractive summarization results.\n\nDecision\n\nEdit: After revisions and discussions, I recommend we accept this paper.\n\nI am leaning towards accepting this paper mostly because of the contribution #1 above. Unsupervised learning using large quantities of text that have the property of being typically written in a style that synthesizes information in the first 1-3 sentences is a powerful idea. That the performance is improved compared to other unsupervised abstractive summarization confirms the importance of this approach.\n\nHowever the importance of and justification for the fine-tuning steps are comparatively much more limited in my opinion. Also, some important details about the preprocessing for pre-training appear to be missing and they could be quite important. \n\nDetailed arguments for decision\n\nI view this effort as aiming to reproduce the BERT approach in the context of abstractive summarization, which is a good idea. The most clever contribution is in leveraging un-labeled text using the first few sentences as the target summary for pretraining. The results of just this part are already beating previous approaches, while not requiring any in-domain data, which is quite powerful. \n\nHowever, some relatively important details regarding the methodology are omitted or only glossed over and it would greatly contribute to making this work more reproducible if the details were included (see my detailed notes below, notably regarding section 2.2). \n\nOn the fine-tuning steps, I have several worries. First, why not fine-tune using supervised learning, as would be the analog to the BERT approach? Instead the authors go out of their way to do in-domain unsupervised learning, which provides a boost, yes, but still doesn't compare positively to extractive and/or supervised methods. Second, why not perform the theme modeling and denoising also -- or rather only -- on the unlabelled pretraining data? Why should it be done on the in-domain fine-tuning data instead (while not using the most valuable piece of in-domain information, namely the example summaries)? After all, it's a fully unsupervised approach and it can actually be performed on any text at all, whether a summary for it exists or not.\n\nAgain regarding the unsupervised approach, and to push the BERT analogy further, I'm wondering why not initialize the pretraining model with a BERT-style trained model? After all we could imagine building a system that adds more and more in-domain characteristics sequentially: first pretrain a BERT model, then fine-tune to summarization using what this paper calls pretraining, and then finally fine-tune again to a specific summarization domain. \n\nSo, to conclude, I find that this paper goes in the right direction and introduces important ideas for pretraining and fine tuning unsupervised abstractive summarization models, but that some decisions about how to use the various ideas (theme and denoising but no supervised learning, in-domain vs during pretraining) have not been explored enough.\n\nExtra notes\n\npage 2, second line: pretrainleverages (typo)\nsection 2.1: fix first sentence to make it an actual sentence.\nsection 2.2: \"we obtain three years of online new articles ... via a search engine\" please be more specific about your methodology.\nsection 2.2: You should double check more throughly that there is no data leakage in test. There could be articles about the same exact events, years apart, for example. I doubt that this would be a big effect, but there are easily ways to find highly similar articles between the pretraining data and test data to make sure.\nsection 2.2: \"Next we conduct following data cleaning\" fix (typo?). Also that sentence probably belongs to the next paragraph.\nsection 2.2: Why did you pick the values that you did for the preprocessing heuristics (such as between 10-150 words, 150-1200 words, 3 sentences and not 2 or 1 or 4, the ratio 0.65, etc.)? Were other values tried?\nsection 2.2: You mention you end up with 21.4M articles. How many were there to start with? What's the filtering ratio?\nsection 2.2: You mention that you pick the model with the best ROUGE-L score on the validation set. How many models were there? What was different between them?\nsection 2.2, OOV Problem: the information in this whole subsection would fit better in 2.1 where 'tokens' are left generic without specifying which type of token you're considering.\nFigure 1: I find the upper part of this figure very confusing. Why are there arrows going from the encoder/decoder to a summary, to theme loss, to article and back to encoder/decoder? It's important that the summary is never seen by the theme loss otherwise it's not unsupervised anymore, and I also don't see why the arrow would go through article *after* theme loss. I assume there must have been a mistake, please fix.\nsection 2.4: \"the sequence is slightly shuffled by applying a permutation /sigma such that ...\" The formula given here tells me that all token indices are shuffled with another token within a window k. That seems like a lot of moving around, and also depending on the implementation a token from the beginning could possibly end up at the very tail of the sentence by being picked iteratively again and again, thus falling outside the permutation distance k. Please provide more details on how this is done and a justification for why it was decided to do it this way.\nSection 3.1: I'd like to know how long (preferably number of words, or at least number of wordpiece tokens) the summaries generated are. What determines how long they are, is it a fixed size, or the model decides to stop on his own (or when hitting some limit), or something else?\nsection 4.2: Do you have any idea why your unsupervised approach yields more novel n-grams than a the supervised model you compare against? This can be good as much as it can be bad, in that it could be going off-track. Yes humans have high novelty, but high novelty in itself isn't necessarily good. I don't find the argument that have more novel ngrams is intrinsically, necessarily good, compelling. If I'm wrong, then it would be nice to have better explanation in the paper.\n\n\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper746/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper746/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "TED: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising", "authors": ["Ziyi Yang", "Chenguang Zhu", "Michael Zeng", "Xuedong Huang", "Eric Darve"], "authorids": ["ziyi.yang@stanford.edu", "chezhu@microsoft.com", "nzeng@microsoft.com", "xdh@microsoft.com", "darve@stanford.edu"], "keywords": ["text summarization", "unsupervised learning", "natural language processing"], "TL;DR": "A new state-of-the-art for unsupervised abstractive text summarization", "abstract": "Text summarization aims to extract essential information from a piece of text and transform it into a concise version. Existing unsupervised abstractive summarization models use recurrent neural networks framework and ignore abundant unlabeled corpora resources. In order to address these issues, we propose TED, a transformer-based unsupervised summarization system with dataset-agnostic pretraining. We first leverage the lead bias in news articles to pretrain the model on large-scale corpora. Then, we finetune TED on target domains through theme modeling and a denoising autoencoder to enhance the quality of summaries. Notably, TED outperforms all unsupervised abstractive baselines on NYT, CNN/DM and English Gigaword datasets with various document styles. Further analysis shows that the summaries generated by TED are abstractive and containing even higher proportions of novel tokens than those from supervised models.", "pdf": "/pdf/972b259f50fbbfcf3fab290c945bda4be815a6f4.pdf", "code": "https://drive.google.com/file/d/17pp6coa19oOTbW3JEXlS_WMb7vjcCGWJ/view?usp=sharing", "paperhash": "yang|ted_a_pretrained_unsupervised_summarization_model_with_theme_modeling_and_denoising", "original_pdf": "/attachment/4ead5f3043b51de02bc82aae239a1814800e04a8.pdf", "_bibtex": "@misc{\nyang2020ted,\ntitle={{\\{}TED{\\}}: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising},\nauthor={Ziyi Yang and Chenguang Zhu and Michael Zeng and Xuedong Huang and Eric Darve},\nyear={2020},\nurl={https://openreview.net/forum?id=Syxwsp4KDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Syxwsp4KDB", "replyto": "Syxwsp4KDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper746/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper746/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575545108396, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper746/Reviewers"], "noninvitees": [], "tcdate": 1570237747693, "tmdate": 1575545108413, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper746/-/Official_Review"}}}, {"id": "B1xJ3ZoaFS", "original": null, "number": 1, "cdate": 1571824038611, "ddate": null, "tcdate": 1571824038611, "tmdate": 1574236870338, "tddate": null, "forum": "Syxwsp4KDB", "replyto": "Syxwsp4KDB", "invitation": "ICLR.cc/2020/Conference/Paper746/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "8: Accept", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #2", "review": "POS-DISCUSSION\nI thank the authors for their answer. I updated my score assuming ryxAY34YwB does not exist, and would encourage authors to discuss in more details the relationship with MeanSum if this gets accepted\n\nPRE-DISCUSSION\n\nThis is an important contribution for the field of unsupervised summarization. \"Unsupervised *\" is trendy in NLP so this is a timely contribution. Furthermore, doing this for summarization is important because of the cost of getting gold summaries and the model used in translation is harder (impossible?) to adapt to this setting where there is information loss in one direction.\n\nHowever, I find major drawbacks in the current state of this paper. They are best related to the three contributions the author claim:\n - Contribution3: the use of BPE. \"BPE for X\", with X being an NLP task can hardly count as a contribution today. If we are counting who did it first, then this is taken at least by Liu & Lapata 2019 through their use of BERT\n - Contribution1: leveraging the lead bias for pre-training. This is a great idea! However, this seems to be covered by an accompanying paper (ICLR submission ryxAY34YwB) which is not referenced. Because of common paragraphs and experimental setting I am assuming there is an overlap of the author sets in two papers. PLEASE CORRECT IF THIS IS NOT THE CASE. As you don't get to claim the same contribution twice, this contribution should go all to the benefit of the other paper.\n - Contribution2: the use of combining reconstruction loss and theme loss for summarization is another great idea. However, the paper that introduced this for summarization (as far as I know) is not cited nor compared too (MeanSum: https://arxiv.org/abs/1810.05739). This seems like a major issue considering the similarity in the approach (including the use of the straight-through Gumbel softmax estimator).\n\nOther comments:\n\n - Being a growing topic of study, I appreciated in particular the care taken to report a number of other approaches. Could you please clarify which version of ROUGE was used in each case? There are significant differences in the different implementations being used.\n - Please also specify the version of ROUGE you used. \n - Your numbers in Table 2 do not coincide with Table 3 of ryxAY34YwB (eg: LEAD-3 for CNN/DM). Can you explain?\n - Your ablation study (Sect 4.1) focuses on CNN/DM (NOTE: the caption of Table 4 says NYT, but the number correspond to CNN/DM. I guess this is an error), where the topic & reconstruction loss indeed helps. However this is not the case for NYT, where LEAD-3 actually beats any of your approach. This is not mention nor discussed.\n - The example of Fig 4 reveals a major problem. The summary states an incorrect fact: the gov accountability had indeed released a report earlier that week; but this was NOT a few hours before the reported incident. What happened a few hours before was a report on Fox News.\n\n\nIn a summary: a good idea combining ideas of ryxAY34YwB and adapting MeanSum. However, this is in my opinion not enough material for a full paper.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"}, "signatures": ["ICLR.cc/2020/Conference/Paper746/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper746/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "TED: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising", "authors": ["Ziyi Yang", "Chenguang Zhu", "Michael Zeng", "Xuedong Huang", "Eric Darve"], "authorids": ["ziyi.yang@stanford.edu", "chezhu@microsoft.com", "nzeng@microsoft.com", "xdh@microsoft.com", "darve@stanford.edu"], "keywords": ["text summarization", "unsupervised learning", "natural language processing"], "TL;DR": "A new state-of-the-art for unsupervised abstractive text summarization", "abstract": "Text summarization aims to extract essential information from a piece of text and transform it into a concise version. Existing unsupervised abstractive summarization models use recurrent neural networks framework and ignore abundant unlabeled corpora resources. In order to address these issues, we propose TED, a transformer-based unsupervised summarization system with dataset-agnostic pretraining. We first leverage the lead bias in news articles to pretrain the model on large-scale corpora. Then, we finetune TED on target domains through theme modeling and a denoising autoencoder to enhance the quality of summaries. Notably, TED outperforms all unsupervised abstractive baselines on NYT, CNN/DM and English Gigaword datasets with various document styles. Further analysis shows that the summaries generated by TED are abstractive and containing even higher proportions of novel tokens than those from supervised models.", "pdf": "/pdf/972b259f50fbbfcf3fab290c945bda4be815a6f4.pdf", "code": "https://drive.google.com/file/d/17pp6coa19oOTbW3JEXlS_WMb7vjcCGWJ/view?usp=sharing", "paperhash": "yang|ted_a_pretrained_unsupervised_summarization_model_with_theme_modeling_and_denoising", "original_pdf": "/attachment/4ead5f3043b51de02bc82aae239a1814800e04a8.pdf", "_bibtex": "@misc{\nyang2020ted,\ntitle={{\\{}TED{\\}}: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising},\nauthor={Ziyi Yang and Chenguang Zhu and Michael Zeng and Xuedong Huang and Eric Darve},\nyear={2020},\nurl={https://openreview.net/forum?id=Syxwsp4KDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Syxwsp4KDB", "replyto": "Syxwsp4KDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper746/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper746/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575545108396, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper746/Reviewers"], "noninvitees": [], "tcdate": 1570237747693, "tmdate": 1575545108413, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper746/-/Official_Review"}}}, {"id": "rkenYRjOsB", "original": null, "number": 2, "cdate": 1573596803807, "ddate": null, "tcdate": 1573596803807, "tmdate": 1573777197975, "tddate": null, "forum": "Syxwsp4KDB", "replyto": "rJxaA5iecS", "invitation": "ICLR.cc/2020/Conference/Paper746/-/Official_Comment", "content": {"title": "To reviewer #1", "comment": "Thanks for your comments. Please find our responses below.\n\n(1) We have corrected the typo.\n(2) Sorry for the confusion. We have removed the term \u201cdataset-agnostic\u201d. We were trying to point out that the pretraining technique generates one single model that achieves consistently good performance across all 3 test datasets.\n(3) Thanks for pointing that out. We have changed it to \u201cTED outperforms previous unsupervised abstractive baselines\u201d.\n\nShould you have any questions, we are very happy to answer them.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper746/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper746/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "TED: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising", "authors": ["Ziyi Yang", "Chenguang Zhu", "Michael Zeng", "Xuedong Huang", "Eric Darve"], "authorids": ["ziyi.yang@stanford.edu", "chezhu@microsoft.com", "nzeng@microsoft.com", "xdh@microsoft.com", "darve@stanford.edu"], "keywords": ["text summarization", "unsupervised learning", "natural language processing"], "TL;DR": "A new state-of-the-art for unsupervised abstractive text summarization", "abstract": "Text summarization aims to extract essential information from a piece of text and transform it into a concise version. Existing unsupervised abstractive summarization models use recurrent neural networks framework and ignore abundant unlabeled corpora resources. In order to address these issues, we propose TED, a transformer-based unsupervised summarization system with dataset-agnostic pretraining. We first leverage the lead bias in news articles to pretrain the model on large-scale corpora. Then, we finetune TED on target domains through theme modeling and a denoising autoencoder to enhance the quality of summaries. Notably, TED outperforms all unsupervised abstractive baselines on NYT, CNN/DM and English Gigaword datasets with various document styles. Further analysis shows that the summaries generated by TED are abstractive and containing even higher proportions of novel tokens than those from supervised models.", "pdf": "/pdf/972b259f50fbbfcf3fab290c945bda4be815a6f4.pdf", "code": "https://drive.google.com/file/d/17pp6coa19oOTbW3JEXlS_WMb7vjcCGWJ/view?usp=sharing", "paperhash": "yang|ted_a_pretrained_unsupervised_summarization_model_with_theme_modeling_and_denoising", "original_pdf": "/attachment/4ead5f3043b51de02bc82aae239a1814800e04a8.pdf", "_bibtex": "@misc{\nyang2020ted,\ntitle={{\\{}TED{\\}}: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising},\nauthor={Ziyi Yang and Chenguang Zhu and Michael Zeng and Xuedong Huang and Eric Darve},\nyear={2020},\nurl={https://openreview.net/forum?id=Syxwsp4KDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Syxwsp4KDB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper746/Authors", "ICLR.cc/2020/Conference/Paper746/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper746/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper746/Reviewers", "ICLR.cc/2020/Conference/Paper746/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper746/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper746/Authors|ICLR.cc/2020/Conference/Paper746/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504166849, "tmdate": 1576860556817, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper746/Authors", "ICLR.cc/2020/Conference/Paper746/Reviewers", "ICLR.cc/2020/Conference/Paper746/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper746/-/Official_Comment"}}}, {"id": "HyxfsJ2diS", "original": null, "number": 4, "cdate": 1573597081547, "ddate": null, "tcdate": 1573597081547, "tmdate": 1573692145427, "tddate": null, "forum": "Syxwsp4KDB", "replyto": "Hke_3SSAYr", "invitation": "ICLR.cc/2020/Conference/Paper746/-/Official_Comment", "content": {"title": "To reviewer #3 (part 2)", "comment": "Regarding the extra notes (with the same order as in \u201cExtra notes\u201d):\n\n(1) (2) Sorry about the typos. We have fixed them.\n(3) The search engine indexes major online news domain, for instance, New York Times and Bloomberg. Then we collect the parsed articles within the 2016-2019 time range as the raw data.\n(4)  We understand your concern about data leakage. We went through the three test sets and did not find significantly overlapped articles as in the pretraining.\n(5) Thanks for pointing it out. We have revised it.\n(6) Some explanations for the heuristic values selections:\n\n150 and 1,200 words: Articles with very long content are filtered them mainly to reduce memory consumption. Short articles are filtered since the information might be too condensed and not suitable for summarization pretraining.\n\n10 and 150 words: Some leading sentences are extremely short, e.g. one or two words phrases.Those are filtered since they have too little information to be reasonable summaries. Longer leading sentences are removed to reduce the pretraining time.\n\n0.65: The overlap ratio is an indicator of the amount of information that the leading sentences maintain. For instance,  in CNN/DM dataset, the median of the overlapping ratio of non-stopping words between golden summary and the article is 0.87, and the ratio between the first 3 sentences and the rest of the article is 0.77 (median). Setting the number at 0.65 makes the final training set size fit with the available computation resources and ensures that the leading sentences contain enough information.\n\nWe mean to have demanding filtering criteria since we want high-quality pretraining data. We didn\u2019t try other settings since pretraining is a time-consuming process.\n\n(7) We start with about 407 million articles. The filtering ratio is about 95%. We\u2019ve also added this information to the paper.\n\n(8) We train one model for 10 epochs. After each epoch, the model is evaluated on validation data. We pick the check points with the highest ROUGE L.\n\n(9) About OOV. It is a good idea. We have edited and moved the paragraph to section 2.1\n\n(10)  About Figure 1. Sorry about the confusion. The \u201csummary\u201d refers to the generated summary from the transformer encoders/decoders, not the groundtruths summaries. The process follows that the article is input to the transformer encoder/decoders and a summary is generated. Then we compute the theme loss using the generated summary and the article. We\u2019ve changed the text label \u201csummary\u201d in figure to \u201cgenerated summary\u201d to avoid the confusion.\n\n(11) About sequence shuffling. Here is how we generate the permutations (the variable perm) of the indices using numpy. Assume the length of the sequence is L, and the window size is k.\nids = np.arange(L)\nnoise =  np.random.uniform(0, k, size = L)\ntmp = ids + noise\nperm = tmp.argsort()\nFor tokens in the beginning, e.g. the first token, since there are at most k -1 elements smaller than tmp[0] in tmp, so the first token is at most shuffled to the kth position.\n\nThe motivation of shuffling is as follows. The information is to extract and summarize is scattered across an article. By applying this shuffling noise, we want our model to learn to recognize and reorganize the information.\n\n(12) The generation has a hard limit, which is decided on the validation dataset. For instance, the maximum generation length for CNN/DM dataset is 175. Also, in beam search, if the generated token is <EOS>, i.e. the end of sentence, then the generation is terminated immediately for the current sequence.\n\n(13) Since TED is an abstractive model, this experiment is to show that TED has the ability to summarize using words/phrases not in the original article, which is typical in human-edited summaries. Explanations why TED has more novel grams could be TED has seen more data during the pretraining phase than PGNet (which is only trained using in-domain data). Also PGNet uses RNN while TED leverages transformer. The more powerful modeling ability of transformer can also help. Also the major evaluation metrics is the ROUGE, on which TED shows competitive performances."}, "signatures": ["ICLR.cc/2020/Conference/Paper746/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper746/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "TED: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising", "authors": ["Ziyi Yang", "Chenguang Zhu", "Michael Zeng", "Xuedong Huang", "Eric Darve"], "authorids": ["ziyi.yang@stanford.edu", "chezhu@microsoft.com", "nzeng@microsoft.com", "xdh@microsoft.com", "darve@stanford.edu"], "keywords": ["text summarization", "unsupervised learning", "natural language processing"], "TL;DR": "A new state-of-the-art for unsupervised abstractive text summarization", "abstract": "Text summarization aims to extract essential information from a piece of text and transform it into a concise version. Existing unsupervised abstractive summarization models use recurrent neural networks framework and ignore abundant unlabeled corpora resources. In order to address these issues, we propose TED, a transformer-based unsupervised summarization system with dataset-agnostic pretraining. We first leverage the lead bias in news articles to pretrain the model on large-scale corpora. Then, we finetune TED on target domains through theme modeling and a denoising autoencoder to enhance the quality of summaries. Notably, TED outperforms all unsupervised abstractive baselines on NYT, CNN/DM and English Gigaword datasets with various document styles. Further analysis shows that the summaries generated by TED are abstractive and containing even higher proportions of novel tokens than those from supervised models.", "pdf": "/pdf/972b259f50fbbfcf3fab290c945bda4be815a6f4.pdf", "code": "https://drive.google.com/file/d/17pp6coa19oOTbW3JEXlS_WMb7vjcCGWJ/view?usp=sharing", "paperhash": "yang|ted_a_pretrained_unsupervised_summarization_model_with_theme_modeling_and_denoising", "original_pdf": "/attachment/4ead5f3043b51de02bc82aae239a1814800e04a8.pdf", "_bibtex": "@misc{\nyang2020ted,\ntitle={{\\{}TED{\\}}: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising},\nauthor={Ziyi Yang and Chenguang Zhu and Michael Zeng and Xuedong Huang and Eric Darve},\nyear={2020},\nurl={https://openreview.net/forum?id=Syxwsp4KDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Syxwsp4KDB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper746/Authors", "ICLR.cc/2020/Conference/Paper746/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper746/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper746/Reviewers", "ICLR.cc/2020/Conference/Paper746/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper746/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper746/Authors|ICLR.cc/2020/Conference/Paper746/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504166849, "tmdate": 1576860556817, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper746/Authors", "ICLR.cc/2020/Conference/Paper746/Reviewers", "ICLR.cc/2020/Conference/Paper746/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper746/-/Official_Comment"}}}, {"id": "Syeo_lh_oS", "original": null, "number": 5, "cdate": 1573597299189, "ddate": null, "tcdate": 1573597299189, "tmdate": 1573601789601, "tddate": null, "forum": "Syxwsp4KDB", "replyto": "B1xJ3ZoaFS", "invitation": "ICLR.cc/2020/Conference/Paper746/-/Official_Comment", "content": {"title": "To reviewer #2", "comment": "We appreciate your comments! Please find our response below.\n\nAbout the concern on our contributions.\n(1) About SentencePiece. We have removed the claim from the major contributions. To the best of our knowledge, TED is one of the initial attempts to use SentencePiece in unsupervised text summarization. \n\n(2) Thanks for pointing that out. We have added the reference to that paper. We believe the usage of denoising and theme modeling in summarization are still innovative as discussed more in the next response.\n\n(3) Thanks for mentioning MeanSum and we have referenced it in the paper. The reasons why we didn\u2019t include MeanSum are:\n\nFirst, MeanSum is for multi-document summarization, while the baseline models we are comparing are for single document. \n\nSecond, the denoising in TED is quite different from the reconstruction idea in MeanSum. In TED\u2019s denoising, the corrupted text are input to the transformer and the model is trained to filter the added noises. Note the original (clean) text is not used as inputs or seen by TED in the forward pass. However, the reconstruction process in MeanSum follows that it inputs multiple documents to RNN, generate the summaries (the encoded reviews), and then reconstruct each document from the summaries.\n\nThird, the same reconstruction idea is also used in a baseline single document summarization model SEQ3 (NAACL 19) that we compared with in the paper, which is published at almost the same time as MeanSum (ICML 19). Similar to MeanSum, SEQ3 tries to reconstruct the the single document from the generated summary. As shown in table 2, TED outperforms SEQ3 by significant margins.\n\nTED is innovative compared with both MeanSum and SEQ3. First MeanSum and SEQ3 both use RNN, while TED builds on transformer. Second, although both MeanSum and SEQ3 have a loss to make make the summary similar to the input article, it is implemented as the classical cosine similarity. In contrast, TED innovatively encodes the similarity by the transformer encoder in a BERT-style.\n\nAbout other comments:\n(1) Most of the performances of baseline models are directly taken from the original paper. After searching their paper, open-sourced code (if available) and by personal communications, we found that PacSum, TextRank (from the PacSum paper), SEQ3, Brief, GPT-2, SUMO, REFRESH, PGNet use ROUGE-1.5.5.  \n\n(2) The ROUGE version we use is ROUGE-1.5.5, same as mentioned above.\n\n(3) We have corrected the numbers in Table 2 in the revised paper. Please refer to the newest table for the performance.\n\n(4) The ablation study in table 4 is on NYT dataset. The full TED model, pretrain w/ theme modeling and pretrain w/ denoise all outperform the lead-3 baseline now.\n\n(5) Fact/common sense checking would be an interesting future direction. Our model manages to recognize that there are time-related information it still needs improvement on delivering factual information. We\u2019ve added the analysis to section 4.2.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper746/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper746/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "TED: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising", "authors": ["Ziyi Yang", "Chenguang Zhu", "Michael Zeng", "Xuedong Huang", "Eric Darve"], "authorids": ["ziyi.yang@stanford.edu", "chezhu@microsoft.com", "nzeng@microsoft.com", "xdh@microsoft.com", "darve@stanford.edu"], "keywords": ["text summarization", "unsupervised learning", "natural language processing"], "TL;DR": "A new state-of-the-art for unsupervised abstractive text summarization", "abstract": "Text summarization aims to extract essential information from a piece of text and transform it into a concise version. Existing unsupervised abstractive summarization models use recurrent neural networks framework and ignore abundant unlabeled corpora resources. In order to address these issues, we propose TED, a transformer-based unsupervised summarization system with dataset-agnostic pretraining. We first leverage the lead bias in news articles to pretrain the model on large-scale corpora. Then, we finetune TED on target domains through theme modeling and a denoising autoencoder to enhance the quality of summaries. Notably, TED outperforms all unsupervised abstractive baselines on NYT, CNN/DM and English Gigaword datasets with various document styles. Further analysis shows that the summaries generated by TED are abstractive and containing even higher proportions of novel tokens than those from supervised models.", "pdf": "/pdf/972b259f50fbbfcf3fab290c945bda4be815a6f4.pdf", "code": "https://drive.google.com/file/d/17pp6coa19oOTbW3JEXlS_WMb7vjcCGWJ/view?usp=sharing", "paperhash": "yang|ted_a_pretrained_unsupervised_summarization_model_with_theme_modeling_and_denoising", "original_pdf": "/attachment/4ead5f3043b51de02bc82aae239a1814800e04a8.pdf", "_bibtex": "@misc{\nyang2020ted,\ntitle={{\\{}TED{\\}}: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising},\nauthor={Ziyi Yang and Chenguang Zhu and Michael Zeng and Xuedong Huang and Eric Darve},\nyear={2020},\nurl={https://openreview.net/forum?id=Syxwsp4KDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Syxwsp4KDB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper746/Authors", "ICLR.cc/2020/Conference/Paper746/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper746/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper746/Reviewers", "ICLR.cc/2020/Conference/Paper746/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper746/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper746/Authors|ICLR.cc/2020/Conference/Paper746/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504166849, "tmdate": 1576860556817, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper746/Authors", "ICLR.cc/2020/Conference/Paper746/Reviewers", "ICLR.cc/2020/Conference/Paper746/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper746/-/Official_Comment"}}}, {"id": "Bkg2Dynusr", "original": null, "number": 3, "cdate": 1573597028271, "ddate": null, "tcdate": 1573597028271, "tmdate": 1573598158512, "tddate": null, "forum": "Syxwsp4KDB", "replyto": "Hke_3SSAYr", "invitation": "ICLR.cc/2020/Conference/Paper746/-/Official_Comment", "content": {"title": "To reviewer #3 (part 1)", "comment": "To reviewer3:\nWe appreciate your detailed and helpful comments. Due to the character limit, we reply with two separated posts (part 1 and 2).\n\nAbout the fine tuning steps.\n\n(1) The reason why we did not finetune with ground-truths is we want to design an unsupervised model. The motivation is in practice one has very limited or even no ground-truths summarizations for a dataset. Also high-quality summarizations are harder to obtain compared with other labelling data, e.g. semantic class. It is ecause summarization requires the advanced ability such as paraphrasing and information extraction, which indeed are not simple for humans. Therefore, we propose an unsupervised approach that does not rely on labelled summaries.\n\n(2) In the theme loss, TED generates summaries recurrently, i.e. using the previously generated tokens to predict the next one. This is because ground-truths summaries are not available and teacher-forcing cannot be used. This process is time-consuming in the pretraining with 21.4M examples, but is feasible for in-domain fine-tuning where data are limited. Also the unsupervised fine tuning techniques (theme modeling and denoising) is to address the scenario that ground-truths are unavailable. However, in the pretraining, the ground-truths are available (lead-3 sentences) so we train the transformer encoder and decoder with classical teacher forcing.\n\n(3) About BERT initializations. We train the transformers from scratch because, first, we have enough amount of training data to do so, i.e. 21.4M article-summary pairs. Second, BERT is not specifically designed for summarization tasks, while our pretraining is. The experiment results (table 2, pretrained) also shows that our pretraining is powerful and competitive.\n\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper746/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper746/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "TED: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising", "authors": ["Ziyi Yang", "Chenguang Zhu", "Michael Zeng", "Xuedong Huang", "Eric Darve"], "authorids": ["ziyi.yang@stanford.edu", "chezhu@microsoft.com", "nzeng@microsoft.com", "xdh@microsoft.com", "darve@stanford.edu"], "keywords": ["text summarization", "unsupervised learning", "natural language processing"], "TL;DR": "A new state-of-the-art for unsupervised abstractive text summarization", "abstract": "Text summarization aims to extract essential information from a piece of text and transform it into a concise version. Existing unsupervised abstractive summarization models use recurrent neural networks framework and ignore abundant unlabeled corpora resources. In order to address these issues, we propose TED, a transformer-based unsupervised summarization system with dataset-agnostic pretraining. We first leverage the lead bias in news articles to pretrain the model on large-scale corpora. Then, we finetune TED on target domains through theme modeling and a denoising autoencoder to enhance the quality of summaries. Notably, TED outperforms all unsupervised abstractive baselines on NYT, CNN/DM and English Gigaword datasets with various document styles. Further analysis shows that the summaries generated by TED are abstractive and containing even higher proportions of novel tokens than those from supervised models.", "pdf": "/pdf/972b259f50fbbfcf3fab290c945bda4be815a6f4.pdf", "code": "https://drive.google.com/file/d/17pp6coa19oOTbW3JEXlS_WMb7vjcCGWJ/view?usp=sharing", "paperhash": "yang|ted_a_pretrained_unsupervised_summarization_model_with_theme_modeling_and_denoising", "original_pdf": "/attachment/4ead5f3043b51de02bc82aae239a1814800e04a8.pdf", "_bibtex": "@misc{\nyang2020ted,\ntitle={{\\{}TED{\\}}: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising},\nauthor={Ziyi Yang and Chenguang Zhu and Michael Zeng and Xuedong Huang and Eric Darve},\nyear={2020},\nurl={https://openreview.net/forum?id=Syxwsp4KDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Syxwsp4KDB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper746/Authors", "ICLR.cc/2020/Conference/Paper746/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper746/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper746/Reviewers", "ICLR.cc/2020/Conference/Paper746/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper746/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper746/Authors|ICLR.cc/2020/Conference/Paper746/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504166849, "tmdate": 1576860556817, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper746/Authors", "ICLR.cc/2020/Conference/Paper746/Reviewers", "ICLR.cc/2020/Conference/Paper746/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper746/-/Official_Comment"}}}, {"id": "rJxaA5iecS", "original": null, "number": 3, "cdate": 1572022997497, "ddate": null, "tcdate": 1572022997497, "tmdate": 1572972557266, "tddate": null, "forum": "Syxwsp4KDB", "replyto": "Syxwsp4KDB", "invitation": "ICLR.cc/2020/Conference/Paper746/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The authors propose to improve abstractive summarization models by using pretrained embeddings, theme modeling and denoising.\n\nThey propose a very interesting idea: to leverage the lead bias in news article to build supervized summarization task from 21.4 M of articles. Details are given how to produce this supervized data using simple heuristics.\n\nThe  model is  train with a denoising loss, by introducing 2 types of noise (tokens from other article and sequence shuffle). Theme modeling is also introduced as a classification problem  (same as BERT) :  the system must learn to classify pairs of sentences from the same article and pairs from different articles. \n\nExperiments are conducted on 3 datasets. The proposed model outperforms the other unsupervized abstractive models and provides results closed to unsupervized extractive models, with a metrics which favors extractive models. Ablation study shows that pretraining yields most of the impact, whereas improvements due to theme modeling and denoising loss are marginal. \n\nIn the Article example : \n\"in the wold\"  ?\n\nConclusion : \n- dataset-agnostic : I don't see why since the approach take advantage of the lead bias.\n- \"outperforms previous systems by significant margins\" : excessive. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper746/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper746/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "TED: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising", "authors": ["Ziyi Yang", "Chenguang Zhu", "Michael Zeng", "Xuedong Huang", "Eric Darve"], "authorids": ["ziyi.yang@stanford.edu", "chezhu@microsoft.com", "nzeng@microsoft.com", "xdh@microsoft.com", "darve@stanford.edu"], "keywords": ["text summarization", "unsupervised learning", "natural language processing"], "TL;DR": "A new state-of-the-art for unsupervised abstractive text summarization", "abstract": "Text summarization aims to extract essential information from a piece of text and transform it into a concise version. Existing unsupervised abstractive summarization models use recurrent neural networks framework and ignore abundant unlabeled corpora resources. In order to address these issues, we propose TED, a transformer-based unsupervised summarization system with dataset-agnostic pretraining. We first leverage the lead bias in news articles to pretrain the model on large-scale corpora. Then, we finetune TED on target domains through theme modeling and a denoising autoencoder to enhance the quality of summaries. Notably, TED outperforms all unsupervised abstractive baselines on NYT, CNN/DM and English Gigaword datasets with various document styles. Further analysis shows that the summaries generated by TED are abstractive and containing even higher proportions of novel tokens than those from supervised models.", "pdf": "/pdf/972b259f50fbbfcf3fab290c945bda4be815a6f4.pdf", "code": "https://drive.google.com/file/d/17pp6coa19oOTbW3JEXlS_WMb7vjcCGWJ/view?usp=sharing", "paperhash": "yang|ted_a_pretrained_unsupervised_summarization_model_with_theme_modeling_and_denoising", "original_pdf": "/attachment/4ead5f3043b51de02bc82aae239a1814800e04a8.pdf", "_bibtex": "@misc{\nyang2020ted,\ntitle={{\\{}TED{\\}}: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising},\nauthor={Ziyi Yang and Chenguang Zhu and Michael Zeng and Xuedong Huang and Eric Darve},\nyear={2020},\nurl={https://openreview.net/forum?id=Syxwsp4KDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Syxwsp4KDB", "replyto": "Syxwsp4KDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper746/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper746/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575545108396, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper746/Reviewers"], "noninvitees": [], "tcdate": 1570237747693, "tmdate": 1575545108413, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper746/-/Official_Review"}}}], "count": 9}