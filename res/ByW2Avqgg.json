{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396588763, "tcdate": 1486396588763, "number": 1, "id": "BJrnhMUdx", "invitation": "ICLR.cc/2017/conference/-/paper444/acceptance", "forum": "ByW2Avqgg", "replyto": "ByW2Avqgg", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "The reviewers pointed out several issues with the paper, and all recommended rejection. The revision seems to not have been enough to change their minds."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Causal Regularization under the Independence of Mechanisms Assumption", "abstract": "Neural networks provide a powerful framework for learning the association between input and response variables and making accurate predictions. However, in many applications such as healthcare, it is important to identify causal relationships between the inputs and the response variables to be able to change the response variables by intervention on the inputs. In pursuit of models whose predictive power comes maximally from causal variables, we propose a novel causal regularizer based on the independence of mechanisms assumption. We utilize the causal regularizer to steer deep neural network architectures towards causally-interpretable solutions. We perform a large-scale analysis of electronic health records. Employing expert's judgment as the causal ground-truth, we show that our causally-regularized algorithm outperforms its L1-regularized equivalence both in predictive performance as well as causal relevance. Finally, we show that the proposed causal regularizer can be used together with representation learning algorithms to yield up to 20% improvement in the causality score of the generated hypotheses.", "pdf": "/pdf/f874a8ac3db85e31cc2fdf628d8563196d36e690.pdf", "TL;DR": "We designed a neural causal regularizer to encourage predictive models to be more causal.", "paperhash": "bahadori|neural_causal_regularization_under_the_independence_of_mechanisms_assumption", "keywords": ["Deep learning", "Applications"], "conflicts": ["gatech.edu", "caltech.edu", "usc.edu", "cmu.edu", "ibm.com", "ed.ac.uk"], "authors": ["Mohammad Taha Bahadori", "Krzysztof Chalupka", "Edward Choi", "Robert Chen", "Walter F. Stewart", "Jimeng Sun"], "authorids": ["bahadori@gatech.edu", "kjchalup@caltech.edu", "mp2893@gatech.edu", "rchen87@gatech.edu", "StewarWF@sutterhealth.org", "jsun@cc.gatech.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396589268, "id": "ICLR.cc/2017/conference/-/paper444/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "ByW2Avqgg", "replyto": "ByW2Avqgg", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396589268}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1486355020043, "tcdate": 1478291113354, "number": 444, "id": "ByW2Avqgg", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "ByW2Avqgg", "signatures": ["~Mohammad_Taha_Bahadori1"], "readers": ["everyone"], "content": {"title": "Neural Causal Regularization under the Independence of Mechanisms Assumption", "abstract": "Neural networks provide a powerful framework for learning the association between input and response variables and making accurate predictions. However, in many applications such as healthcare, it is important to identify causal relationships between the inputs and the response variables to be able to change the response variables by intervention on the inputs. In pursuit of models whose predictive power comes maximally from causal variables, we propose a novel causal regularizer based on the independence of mechanisms assumption. We utilize the causal regularizer to steer deep neural network architectures towards causally-interpretable solutions. We perform a large-scale analysis of electronic health records. Employing expert's judgment as the causal ground-truth, we show that our causally-regularized algorithm outperforms its L1-regularized equivalence both in predictive performance as well as causal relevance. Finally, we show that the proposed causal regularizer can be used together with representation learning algorithms to yield up to 20% improvement in the causality score of the generated hypotheses.", "pdf": "/pdf/f874a8ac3db85e31cc2fdf628d8563196d36e690.pdf", "TL;DR": "We designed a neural causal regularizer to encourage predictive models to be more causal.", "paperhash": "bahadori|neural_causal_regularization_under_the_independence_of_mechanisms_assumption", "keywords": ["Deep learning", "Applications"], "conflicts": ["gatech.edu", "caltech.edu", "usc.edu", "cmu.edu", "ibm.com", "ed.ac.uk"], "authors": ["Mohammad Taha Bahadori", "Krzysztof Chalupka", "Edward Choi", "Robert Chen", "Walter F. Stewart", "Jimeng Sun"], "authorids": ["bahadori@gatech.edu", "kjchalup@caltech.edu", "mp2893@gatech.edu", "rchen87@gatech.edu", "StewarWF@sutterhealth.org", "jsun@cc.gatech.edu"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 19, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1485999455316, "tcdate": 1484288032423, "number": 10, "id": "ByOXlgILx", "invitation": "ICLR.cc/2017/conference/-/paper444/public/comment", "forum": "ByW2Avqgg", "replyto": "ByW2Avqgg", "signatures": ["~Mohammad_Taha_Bahadori1"], "readers": ["everyone"], "writers": ["~Mohammad_Taha_Bahadori1"], "content": {"title": "Major Revision", "comment": "We made a major revision to the paper.  Here is the summary of the main changes:\n\nExperiments:\n-- Providing **ground truth causality** evaluation (by hiring Robert Chen, a clinical expert). (Figure 1, Table 2) The results show a significant gain in causality discovery using the proposed method.\n-- Including a new **publicly available dataset** (MIMIC III) to ensure reproducibility of the results. (Table 1 and Figure 4)\n-- Adding standard deviation to the results.\n\nNovel methodology:\n-- Providing a neural network architecture that allows multivariate causal hypothesis generation, see Section 2.3 and Figure 2.b.\n-- Providing the ground truth causality evaluation for the causal hypotheses generated by our algorithm. (Figure 5b)\n\nWriteup:\n-- Adding more discussion on the related works (Sections 2.1 and 2.2). \n---- In the introduction and Section 2.2 we clearly describe the novelty of this paper with respect to the papers listed by David Lopez-Paz and the reviewers.\n-- Revising the background section 2.1 and making it both more accessible and more mathematically precise.\n-- Adding new visualizations in Figure 2 and removing diagrams that didn\u2019t help delivering the concepts.\n-- Restructuring the methodology section. Now Section 2.2 only discusses the proposed causal regularizer and Section 2.3 describes its combination with neural networks.\n-- Moving the experimental results on the causality detection (and other extra results) to Appendix A.1, to allow space for evaluation of the main results of the paper.\n-- Finally, we revised the introduction accordingly.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Causal Regularization under the Independence of Mechanisms Assumption", "abstract": "Neural networks provide a powerful framework for learning the association between input and response variables and making accurate predictions. However, in many applications such as healthcare, it is important to identify causal relationships between the inputs and the response variables to be able to change the response variables by intervention on the inputs. In pursuit of models whose predictive power comes maximally from causal variables, we propose a novel causal regularizer based on the independence of mechanisms assumption. We utilize the causal regularizer to steer deep neural network architectures towards causally-interpretable solutions. We perform a large-scale analysis of electronic health records. Employing expert's judgment as the causal ground-truth, we show that our causally-regularized algorithm outperforms its L1-regularized equivalence both in predictive performance as well as causal relevance. Finally, we show that the proposed causal regularizer can be used together with representation learning algorithms to yield up to 20% improvement in the causality score of the generated hypotheses.", "pdf": "/pdf/f874a8ac3db85e31cc2fdf628d8563196d36e690.pdf", "TL;DR": "We designed a neural causal regularizer to encourage predictive models to be more causal.", "paperhash": "bahadori|neural_causal_regularization_under_the_independence_of_mechanisms_assumption", "keywords": ["Deep learning", "Applications"], "conflicts": ["gatech.edu", "caltech.edu", "usc.edu", "cmu.edu", "ibm.com", "ed.ac.uk"], "authors": ["Mohammad Taha Bahadori", "Krzysztof Chalupka", "Edward Choi", "Robert Chen", "Walter F. Stewart", "Jimeng Sun"], "authorids": ["bahadori@gatech.edu", "kjchalup@caltech.edu", "mp2893@gatech.edu", "rchen87@gatech.edu", "StewarWF@sutterhealth.org", "jsun@cc.gatech.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287572840, "id": "ICLR.cc/2017/conference/-/paper444/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ByW2Avqgg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper444/reviewers", "ICLR.cc/2017/conference/paper444/areachairs"], "cdate": 1485287572840}}}, {"tddate": null, "tmdate": 1484329317173, "tcdate": 1484320193434, "number": 11, "id": "rkYaaPUUx", "invitation": "ICLR.cc/2017/conference/-/paper444/public/comment", "forum": "ByW2Avqgg", "replyto": "HJAeeLH4x", "signatures": ["~Mohammad_Taha_Bahadori1"], "readers": ["everyone"], "writers": ["~Mohammad_Taha_Bahadori1"], "content": {"title": "Addressed your comments", "comment": "We would like to thank you for your constructive feedback.  Your feedback allowed us to make a major revision to the paper.\n\nAs we listed in the revision notes, in the revised paper we added experiments on a publicly available dataset (MIMIC III) and even preprocessed using a publicly available script. Now, half of the results in Table 1 and Figure 3 are completely reproducible. \n\nFurthermore, we hired a clinical expert to provide us the ground truth causality labels (Table 2). The results strongly confirm the key claims of the paper about the performance of causal regularizer compared to the two step procedure.\n\nFinally, we added another use case for causal regularizer in Section 2.3 and reorganized the section to highlight novel contributions of this paper compared to (Chalupka et al 2016) and (Lopez-Paz et al, 2016)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Causal Regularization under the Independence of Mechanisms Assumption", "abstract": "Neural networks provide a powerful framework for learning the association between input and response variables and making accurate predictions. However, in many applications such as healthcare, it is important to identify causal relationships between the inputs and the response variables to be able to change the response variables by intervention on the inputs. In pursuit of models whose predictive power comes maximally from causal variables, we propose a novel causal regularizer based on the independence of mechanisms assumption. We utilize the causal regularizer to steer deep neural network architectures towards causally-interpretable solutions. We perform a large-scale analysis of electronic health records. Employing expert's judgment as the causal ground-truth, we show that our causally-regularized algorithm outperforms its L1-regularized equivalence both in predictive performance as well as causal relevance. Finally, we show that the proposed causal regularizer can be used together with representation learning algorithms to yield up to 20% improvement in the causality score of the generated hypotheses.", "pdf": "/pdf/f874a8ac3db85e31cc2fdf628d8563196d36e690.pdf", "TL;DR": "We designed a neural causal regularizer to encourage predictive models to be more causal.", "paperhash": "bahadori|neural_causal_regularization_under_the_independence_of_mechanisms_assumption", "keywords": ["Deep learning", "Applications"], "conflicts": ["gatech.edu", "caltech.edu", "usc.edu", "cmu.edu", "ibm.com", "ed.ac.uk"], "authors": ["Mohammad Taha Bahadori", "Krzysztof Chalupka", "Edward Choi", "Robert Chen", "Walter F. Stewart", "Jimeng Sun"], "authorids": ["bahadori@gatech.edu", "kjchalup@caltech.edu", "mp2893@gatech.edu", "rchen87@gatech.edu", "StewarWF@sutterhealth.org", "jsun@cc.gatech.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287572840, "id": "ICLR.cc/2017/conference/-/paper444/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ByW2Avqgg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper444/reviewers", "ICLR.cc/2017/conference/paper444/areachairs"], "cdate": 1485287572840}}}, {"tddate": null, "tmdate": 1484320276681, "tcdate": 1484320276681, "number": 13, "id": "Hk6zADL8l", "invitation": "ICLR.cc/2017/conference/-/paper444/public/comment", "forum": "ByW2Avqgg", "replyto": "ByKDq907e", "signatures": ["~Mohammad_Taha_Bahadori1"], "readers": ["everyone"], "writers": ["~Mohammad_Taha_Bahadori1"], "content": {"title": "Major revision to the paper", "comment": "We would like to thank you for your constructive feedback.  Your feedback allowed us to make a major revision to the paper.\n\nWe rewrote the paper with more detailed discussion of the related works.  We improved the evaluation by including a publicly available dataset and also ground truth causality evaluation. \n\nPlease see the other major improvements to the paper listed in our revision note.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Causal Regularization under the Independence of Mechanisms Assumption", "abstract": "Neural networks provide a powerful framework for learning the association between input and response variables and making accurate predictions. However, in many applications such as healthcare, it is important to identify causal relationships between the inputs and the response variables to be able to change the response variables by intervention on the inputs. In pursuit of models whose predictive power comes maximally from causal variables, we propose a novel causal regularizer based on the independence of mechanisms assumption. We utilize the causal regularizer to steer deep neural network architectures towards causally-interpretable solutions. We perform a large-scale analysis of electronic health records. Employing expert's judgment as the causal ground-truth, we show that our causally-regularized algorithm outperforms its L1-regularized equivalence both in predictive performance as well as causal relevance. Finally, we show that the proposed causal regularizer can be used together with representation learning algorithms to yield up to 20% improvement in the causality score of the generated hypotheses.", "pdf": "/pdf/f874a8ac3db85e31cc2fdf628d8563196d36e690.pdf", "TL;DR": "We designed a neural causal regularizer to encourage predictive models to be more causal.", "paperhash": "bahadori|neural_causal_regularization_under_the_independence_of_mechanisms_assumption", "keywords": ["Deep learning", "Applications"], "conflicts": ["gatech.edu", "caltech.edu", "usc.edu", "cmu.edu", "ibm.com", "ed.ac.uk"], "authors": ["Mohammad Taha Bahadori", "Krzysztof Chalupka", "Edward Choi", "Robert Chen", "Walter F. Stewart", "Jimeng Sun"], "authorids": ["bahadori@gatech.edu", "kjchalup@caltech.edu", "mp2893@gatech.edu", "rchen87@gatech.edu", "StewarWF@sutterhealth.org", "jsun@cc.gatech.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287572840, "id": "ICLR.cc/2017/conference/-/paper444/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ByW2Avqgg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper444/reviewers", "ICLR.cc/2017/conference/paper444/areachairs"], "cdate": 1485287572840}}}, {"tddate": null, "tmdate": 1484320239257, "tcdate": 1484320239257, "number": 12, "id": "rkweCDI8e", "invitation": "ICLR.cc/2017/conference/-/paper444/public/comment", "forum": "ByW2Avqgg", "replyto": "SJBJ5mXNe", "signatures": ["~Mohammad_Taha_Bahadori1"], "readers": ["everyone"], "writers": ["~Mohammad_Taha_Bahadori1"], "content": {"title": "Addressed your comments", "comment": "We would like to thank you for your constructive feedback.  Your feedback allowed us to make a major revision to the paper.\n\nWe made a complete overhaul to the write-up and also additional novel methodology in Section 2.3.  Now you can easily see the novelty of the work in Sections 2.2 and 2.3.\n\nWe deleted the figure that you pointed out and included more insightful figures in Figure 2.\n\nRegarding the ground truth causality, we hired a clinical expert to provide us the ground truth causality labels (Table 2). The results strongly confirm the key claims of the paper about the performance of causal regularizer."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Causal Regularization under the Independence of Mechanisms Assumption", "abstract": "Neural networks provide a powerful framework for learning the association between input and response variables and making accurate predictions. However, in many applications such as healthcare, it is important to identify causal relationships between the inputs and the response variables to be able to change the response variables by intervention on the inputs. In pursuit of models whose predictive power comes maximally from causal variables, we propose a novel causal regularizer based on the independence of mechanisms assumption. We utilize the causal regularizer to steer deep neural network architectures towards causally-interpretable solutions. We perform a large-scale analysis of electronic health records. Employing expert's judgment as the causal ground-truth, we show that our causally-regularized algorithm outperforms its L1-regularized equivalence both in predictive performance as well as causal relevance. Finally, we show that the proposed causal regularizer can be used together with representation learning algorithms to yield up to 20% improvement in the causality score of the generated hypotheses.", "pdf": "/pdf/f874a8ac3db85e31cc2fdf628d8563196d36e690.pdf", "TL;DR": "We designed a neural causal regularizer to encourage predictive models to be more causal.", "paperhash": "bahadori|neural_causal_regularization_under_the_independence_of_mechanisms_assumption", "keywords": ["Deep learning", "Applications"], "conflicts": ["gatech.edu", "caltech.edu", "usc.edu", "cmu.edu", "ibm.com", "ed.ac.uk"], "authors": ["Mohammad Taha Bahadori", "Krzysztof Chalupka", "Edward Choi", "Robert Chen", "Walter F. Stewart", "Jimeng Sun"], "authorids": ["bahadori@gatech.edu", "kjchalup@caltech.edu", "mp2893@gatech.edu", "rchen87@gatech.edu", "StewarWF@sutterhealth.org", "jsun@cc.gatech.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287572840, "id": "ICLR.cc/2017/conference/-/paper444/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ByW2Avqgg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper444/reviewers", "ICLR.cc/2017/conference/paper444/areachairs"], "cdate": 1485287572840}}}, {"tddate": null, "tmdate": 1482149877583, "tcdate": 1482149877583, "number": 3, "id": "HJAeeLH4x", "invitation": "ICLR.cc/2017/conference/-/paper444/official/review", "forum": "ByW2Avqgg", "replyto": "ByW2Avqgg", "signatures": ["ICLR.cc/2017/conference/paper444/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper444/AnonReviewer3"], "content": {"title": "Possibly practical method, but methodology and analysis fall short", "rating": "5: Marginally below acceptance threshold", "review": "This paper proposes to use a causality score to weight a sparsity regularizer.  In that way, selected variables trade off between being causal and discriminative.  The framework is primarily evaluated on a proprietary health dataset.  While the dataset does give a good motivation to the problem setting, the paper falls a bit short for ICLR due to the lack of additional controlled experiments, relatively straightforward methodology (given the approach of Chalupka et al., arXiv Preprint, 2016, which is a more interesting paper from a technical perspective), and paucity of theoretical motivation.\n\nAt the core of this paper, the approach is effectively to weight a sparsity regularizer so that \"causal\" variables (as determined by a separate objective) are more likely to be selected.  This is generally a good idea, but we do not get a proper validation of this from the experiments as ground truth is absent.  A theorem on identifiability of causal+discriminative variables from a data sample combined with adequate synthetic experiments would have probably been sufficient, for example, to push the paper towards accept from a technical perspective, but as it is, it is lacking in insight and reproducibility.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Causal Regularization under the Independence of Mechanisms Assumption", "abstract": "Neural networks provide a powerful framework for learning the association between input and response variables and making accurate predictions. However, in many applications such as healthcare, it is important to identify causal relationships between the inputs and the response variables to be able to change the response variables by intervention on the inputs. In pursuit of models whose predictive power comes maximally from causal variables, we propose a novel causal regularizer based on the independence of mechanisms assumption. We utilize the causal regularizer to steer deep neural network architectures towards causally-interpretable solutions. We perform a large-scale analysis of electronic health records. Employing expert's judgment as the causal ground-truth, we show that our causally-regularized algorithm outperforms its L1-regularized equivalence both in predictive performance as well as causal relevance. Finally, we show that the proposed causal regularizer can be used together with representation learning algorithms to yield up to 20% improvement in the causality score of the generated hypotheses.", "pdf": "/pdf/f874a8ac3db85e31cc2fdf628d8563196d36e690.pdf", "TL;DR": "We designed a neural causal regularizer to encourage predictive models to be more causal.", "paperhash": "bahadori|neural_causal_regularization_under_the_independence_of_mechanisms_assumption", "keywords": ["Deep learning", "Applications"], "conflicts": ["gatech.edu", "caltech.edu", "usc.edu", "cmu.edu", "ibm.com", "ed.ac.uk"], "authors": ["Mohammad Taha Bahadori", "Krzysztof Chalupka", "Edward Choi", "Robert Chen", "Walter F. Stewart", "Jimeng Sun"], "authorids": ["bahadori@gatech.edu", "kjchalup@caltech.edu", "mp2893@gatech.edu", "rchen87@gatech.edu", "StewarWF@sutterhealth.org", "jsun@cc.gatech.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512583624, "id": "ICLR.cc/2017/conference/-/paper444/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper444/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper444/AnonReviewer1", "ICLR.cc/2017/conference/paper444/AnonReviewer2", "ICLR.cc/2017/conference/paper444/AnonReviewer3"], "reply": {"forum": "ByW2Avqgg", "replyto": "ByW2Avqgg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper444/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper444/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512583624}}}, {"tddate": null, "tmdate": 1482009052965, "tcdate": 1482009052965, "number": 2, "id": "SJBJ5mXNe", "invitation": "ICLR.cc/2017/conference/-/paper444/official/review", "forum": "ByW2Avqgg", "replyto": "ByW2Avqgg", "signatures": ["ICLR.cc/2017/conference/paper444/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper444/AnonReviewer2"], "content": {"title": "a good paper but a bit short of the mark in terms of presentation, methodology, and results", "rating": "4: Ok but not good enough - rejection", "review": "The authors extend their method of causal discovery (Chalupka et al 2016) to include assumptions about sparsity via regularization.  They apply this extension to an interesting private dataset from Sutter Health.  While an interesting direction, I found the presentation somewhat confused, the methodological novelty smaller than the bulk of ICLR works, and the central results (or perhaps data; see below) inadequate to address questions of causality.\n\nFirst, I found the presentation somewhat unclear.  The paper at some points seems to be entirely focused on healthcare data, at other points it uses it as a motivating example, and at other points it is neglected.  Also, algorithm 1 seems unreferenced, and I'm not entirely sure why it is needed.  Figure 2 is not needed for this community.  The key methodological advance in this work appears in section 2.1 (Causal regularizer), but it is introduced amidst toy examples and without clear terminology or standard methodological assumptions/build-up.  In Section 3.1 (bottom of first paragraph), key data and results seem to be relegated to the appendices.  Thus overall the paper read rather haphazardly.  Finally, there seems to be an assumption throughout of fairly intimate familiarity with the Cholupka preprint, which i think should be avoided.  This paper should stand alone.\n\nSecond, while the technical contributions/novelty are not a focus of the paper's presentation, I am concerned by the lack of methodological advance.  Essentially a regularization objective is added to the previous method, which of itself is not a bad idea, but I can't point to a technical novelty in the paper that the community can not do without.\n\nThird, fundamentally i don't see how the experiments address the central question of causality; they show regularization behaving as expected (or rather, influencing weights as expected), but I don't think we really have any meaningful quantitative evidence that causality has been learned.  This was briefly discussed (see \"ground truth causality?\" and the response below).  I appreciate the technical challenges/impossibility of having such a dataset, but if that's the case, then I think this work is premature, since there is no way to really validate.\n\nOverall it's clearly a sincere effort, but I found it wanting in terms of a few critical areas.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Causal Regularization under the Independence of Mechanisms Assumption", "abstract": "Neural networks provide a powerful framework for learning the association between input and response variables and making accurate predictions. However, in many applications such as healthcare, it is important to identify causal relationships between the inputs and the response variables to be able to change the response variables by intervention on the inputs. In pursuit of models whose predictive power comes maximally from causal variables, we propose a novel causal regularizer based on the independence of mechanisms assumption. We utilize the causal regularizer to steer deep neural network architectures towards causally-interpretable solutions. We perform a large-scale analysis of electronic health records. Employing expert's judgment as the causal ground-truth, we show that our causally-regularized algorithm outperforms its L1-regularized equivalence both in predictive performance as well as causal relevance. Finally, we show that the proposed causal regularizer can be used together with representation learning algorithms to yield up to 20% improvement in the causality score of the generated hypotheses.", "pdf": "/pdf/f874a8ac3db85e31cc2fdf628d8563196d36e690.pdf", "TL;DR": "We designed a neural causal regularizer to encourage predictive models to be more causal.", "paperhash": "bahadori|neural_causal_regularization_under_the_independence_of_mechanisms_assumption", "keywords": ["Deep learning", "Applications"], "conflicts": ["gatech.edu", "caltech.edu", "usc.edu", "cmu.edu", "ibm.com", "ed.ac.uk"], "authors": ["Mohammad Taha Bahadori", "Krzysztof Chalupka", "Edward Choi", "Robert Chen", "Walter F. Stewart", "Jimeng Sun"], "authorids": ["bahadori@gatech.edu", "kjchalup@caltech.edu", "mp2893@gatech.edu", "rchen87@gatech.edu", "StewarWF@sutterhealth.org", "jsun@cc.gatech.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512583624, "id": "ICLR.cc/2017/conference/-/paper444/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper444/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper444/AnonReviewer1", "ICLR.cc/2017/conference/paper444/AnonReviewer2", "ICLR.cc/2017/conference/paper444/AnonReviewer3"], "reply": {"forum": "ByW2Avqgg", "replyto": "ByW2Avqgg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper444/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper444/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512583624}}}, {"tddate": null, "tmdate": 1481735369044, "tcdate": 1481735369037, "number": 9, "id": "HkZ0hg1Ne", "invitation": "ICLR.cc/2017/conference/-/paper444/public/comment", "forum": "ByW2Avqgg", "replyto": "ByKDq907e", "signatures": ["~Mohammad_Taha_Bahadori1"], "readers": ["everyone"], "writers": ["~Mohammad_Taha_Bahadori1"], "content": {"title": "A Quick Response", "comment": "We would like to sincerely thank you for the detailed and constructive review.  We will make sure to address all of your comments and improve the quality of the paper.\n\nAlso, two days ago we uploaded a revision that addresses some of your comments on related works. In Section 2.1, we included the related works on causal discovery via independence of mechanisms assumption and clarified that other methods (such as Lopez-Paz\u2019s work) could also be used to construction of our regularizer in Section 2.2.  At the end of Section 2.2, we describe the novelty of our proposed regularizer given the existing literature.\n\nWe will write a more elaborate response after addressing your comments and uploading a new revision of the paper. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Causal Regularization under the Independence of Mechanisms Assumption", "abstract": "Neural networks provide a powerful framework for learning the association between input and response variables and making accurate predictions. However, in many applications such as healthcare, it is important to identify causal relationships between the inputs and the response variables to be able to change the response variables by intervention on the inputs. In pursuit of models whose predictive power comes maximally from causal variables, we propose a novel causal regularizer based on the independence of mechanisms assumption. We utilize the causal regularizer to steer deep neural network architectures towards causally-interpretable solutions. We perform a large-scale analysis of electronic health records. Employing expert's judgment as the causal ground-truth, we show that our causally-regularized algorithm outperforms its L1-regularized equivalence both in predictive performance as well as causal relevance. Finally, we show that the proposed causal regularizer can be used together with representation learning algorithms to yield up to 20% improvement in the causality score of the generated hypotheses.", "pdf": "/pdf/f874a8ac3db85e31cc2fdf628d8563196d36e690.pdf", "TL;DR": "We designed a neural causal regularizer to encourage predictive models to be more causal.", "paperhash": "bahadori|neural_causal_regularization_under_the_independence_of_mechanisms_assumption", "keywords": ["Deep learning", "Applications"], "conflicts": ["gatech.edu", "caltech.edu", "usc.edu", "cmu.edu", "ibm.com", "ed.ac.uk"], "authors": ["Mohammad Taha Bahadori", "Krzysztof Chalupka", "Edward Choi", "Robert Chen", "Walter F. Stewart", "Jimeng Sun"], "authorids": ["bahadori@gatech.edu", "kjchalup@caltech.edu", "mp2893@gatech.edu", "rchen87@gatech.edu", "StewarWF@sutterhealth.org", "jsun@cc.gatech.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287572840, "id": "ICLR.cc/2017/conference/-/paper444/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ByW2Avqgg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper444/reviewers", "ICLR.cc/2017/conference/paper444/areachairs"], "cdate": 1485287572840}}}, {"tddate": null, "tmdate": 1481710177022, "tcdate": 1481710177012, "number": 1, "id": "ByKDq907e", "invitation": "ICLR.cc/2017/conference/-/paper444/official/review", "forum": "ByW2Avqgg", "replyto": "ByW2Avqgg", "signatures": ["ICLR.cc/2017/conference/paper444/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper444/AnonReviewer1"], "content": {"title": "", "rating": "6: Marginally above acceptance threshold", "review": "The present submission discusses a \"causal regularizer\", which promotes the use of causal dependencies (X -> Y, where X is a feature of the learning problem, and Y is the target variable) in predictive models. Similarly, such causal regularizer penalizes the use of non-causal dependencies, which can arise due to reverse causation (Y -> X) or confounding (X <- Z -> Y, where Z is a hidden confounder).\n\n+ Overall, this submission tackles one of the most important problems in machine learning, which is to build causal models. The paper discusses and addresses this issue effectively when applied to a dataset in heart disease. In their experiments, the authors correctly identify some of the common causes of heart disease by virtue of their causal regularizer.\n\n- The authors do not discuss the robustness of their approach with respect to choice of hyper-parameters (both describing the neural network architecture and the generative model that synthesizes artificial causal data). This seems like a crucial issue, in particular when dealing with medical data.\n\n- The conclusions of the experimental evaluation should be discussed in greater length. On the one hand, Figure 4.a shows that there are no differences between L1 and causal regularization in terms of predictive performance, but it is difficult to conclude if this result is statistically significant without access to error-bars. On the other hand, Table 3 describes the qualitative differences between L1 and causal regularization. However, this table is hard to read: How were the 30 rows selected? What does the red highlighting mean? Are these red rows some true causal features that were missed? If so, this is related to precision. What about recall? Did the causal regularization pick up many non-causal features as causal?\n\n- Regarding causal classifiers, this paper should do a much better job at reviewing previous work. For instance, the paper \"Towards a Learning Theory of Cause-Effect Inference\" from Lopez-Paz et al. is missing from the references. However, this prior work studies many of the aspects that are hinted as novel in this submission. In particular, the prior work of Lopez-Paz 1) introduces the concept of Mother distribution (referred as Nature hyper-prior in this submission) which explicitly factorizes the distribution over causes and mechanisms, 2) circumvented intractable likelihoods by synthesizing and training on causal data, 3) tackled the confounding case (compare Figure 1 of this submission and Appendix C of Lopez-Paz), and 4) dealt with discrete data seamlessly (such as the ChaLearn data from Section 5.3 in Lopez-Paz).\n\nOn a positive note, this is a well-written paper that addresses the important, under-appreciated problem of incorporating causal reasoning into machine learning. On a negative note, the novelty of the technical contributions is modest and the qualitative evaluation of the results could be greatly extended. In short, I am leaning slightly towards acceptance.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Causal Regularization under the Independence of Mechanisms Assumption", "abstract": "Neural networks provide a powerful framework for learning the association between input and response variables and making accurate predictions. However, in many applications such as healthcare, it is important to identify causal relationships between the inputs and the response variables to be able to change the response variables by intervention on the inputs. In pursuit of models whose predictive power comes maximally from causal variables, we propose a novel causal regularizer based on the independence of mechanisms assumption. We utilize the causal regularizer to steer deep neural network architectures towards causally-interpretable solutions. We perform a large-scale analysis of electronic health records. Employing expert's judgment as the causal ground-truth, we show that our causally-regularized algorithm outperforms its L1-regularized equivalence both in predictive performance as well as causal relevance. Finally, we show that the proposed causal regularizer can be used together with representation learning algorithms to yield up to 20% improvement in the causality score of the generated hypotheses.", "pdf": "/pdf/f874a8ac3db85e31cc2fdf628d8563196d36e690.pdf", "TL;DR": "We designed a neural causal regularizer to encourage predictive models to be more causal.", "paperhash": "bahadori|neural_causal_regularization_under_the_independence_of_mechanisms_assumption", "keywords": ["Deep learning", "Applications"], "conflicts": ["gatech.edu", "caltech.edu", "usc.edu", "cmu.edu", "ibm.com", "ed.ac.uk"], "authors": ["Mohammad Taha Bahadori", "Krzysztof Chalupka", "Edward Choi", "Robert Chen", "Walter F. Stewart", "Jimeng Sun"], "authorids": ["bahadori@gatech.edu", "kjchalup@caltech.edu", "mp2893@gatech.edu", "rchen87@gatech.edu", "StewarWF@sutterhealth.org", "jsun@cc.gatech.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512583624, "id": "ICLR.cc/2017/conference/-/paper444/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper444/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper444/AnonReviewer1", "ICLR.cc/2017/conference/paper444/AnonReviewer2", "ICLR.cc/2017/conference/paper444/AnonReviewer3"], "reply": {"forum": "ByW2Avqgg", "replyto": "ByW2Avqgg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper444/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper444/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512583624}}}, {"tddate": null, "tmdate": 1481554271146, "tcdate": 1481554271107, "number": 8, "id": "SkDwFV37e", "invitation": "ICLR.cc/2017/conference/-/paper444/public/comment", "forum": "ByW2Avqgg", "replyto": "Hkl6fwkmg", "signatures": ["~Mohammad_Taha_Bahadori1"], "readers": ["everyone"], "writers": ["~Mohammad_Taha_Bahadori1"], "content": {"title": "Clarrifications", "comment": "We sincerely thank you for the comments.  We have specified more details about the form of distributions for count data in Appendix A. The joint distributions $p_{X,Y}$ are generated according to Fig 1 using a sampling procedure similar to Algorithm 1. We will make sure to clarify Step 1 as you suggested.\n\nRegarding Step 2: The inputs are not samples, the inputs are distributions. For training, the input is the joint distributions $p_{X,Y}$ sampled using Algorithm 1 and Fig 1. For testing, we use the empirical joint distributions $\\hat{p}_{X,Y}$ estimated using the data. It is also possible to use a sufficient statistic or a discriminative classifier on the actual samples as Lopez-Paz et al, (2016) suggest. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Causal Regularization under the Independence of Mechanisms Assumption", "abstract": "Neural networks provide a powerful framework for learning the association between input and response variables and making accurate predictions. However, in many applications such as healthcare, it is important to identify causal relationships between the inputs and the response variables to be able to change the response variables by intervention on the inputs. In pursuit of models whose predictive power comes maximally from causal variables, we propose a novel causal regularizer based on the independence of mechanisms assumption. We utilize the causal regularizer to steer deep neural network architectures towards causally-interpretable solutions. We perform a large-scale analysis of electronic health records. Employing expert's judgment as the causal ground-truth, we show that our causally-regularized algorithm outperforms its L1-regularized equivalence both in predictive performance as well as causal relevance. Finally, we show that the proposed causal regularizer can be used together with representation learning algorithms to yield up to 20% improvement in the causality score of the generated hypotheses.", "pdf": "/pdf/f874a8ac3db85e31cc2fdf628d8563196d36e690.pdf", "TL;DR": "We designed a neural causal regularizer to encourage predictive models to be more causal.", "paperhash": "bahadori|neural_causal_regularization_under_the_independence_of_mechanisms_assumption", "keywords": ["Deep learning", "Applications"], "conflicts": ["gatech.edu", "caltech.edu", "usc.edu", "cmu.edu", "ibm.com", "ed.ac.uk"], "authors": ["Mohammad Taha Bahadori", "Krzysztof Chalupka", "Edward Choi", "Robert Chen", "Walter F. Stewart", "Jimeng Sun"], "authorids": ["bahadori@gatech.edu", "kjchalup@caltech.edu", "mp2893@gatech.edu", "rchen87@gatech.edu", "StewarWF@sutterhealth.org", "jsun@cc.gatech.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287572840, "id": "ICLR.cc/2017/conference/-/paper444/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ByW2Avqgg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper444/reviewers", "ICLR.cc/2017/conference/paper444/areachairs"], "cdate": 1485287572840}}}, {"tddate": null, "tmdate": 1481553847487, "tcdate": 1481553847482, "number": 7, "id": "SJyaPVnQx", "invitation": "ICLR.cc/2017/conference/-/paper444/public/comment", "forum": "ByW2Avqgg", "replyto": "SyDp_uk7l", "signatures": ["~Mohammad_Taha_Bahadori1"], "readers": ["everyone"], "writers": ["~Mohammad_Taha_Bahadori1"], "content": {"title": "A great real-world dataset", "comment": "The heart failure dataset is the property of Sutter Health and we are not at liberty to release it. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Causal Regularization under the Independence of Mechanisms Assumption", "abstract": "Neural networks provide a powerful framework for learning the association between input and response variables and making accurate predictions. However, in many applications such as healthcare, it is important to identify causal relationships between the inputs and the response variables to be able to change the response variables by intervention on the inputs. In pursuit of models whose predictive power comes maximally from causal variables, we propose a novel causal regularizer based on the independence of mechanisms assumption. We utilize the causal regularizer to steer deep neural network architectures towards causally-interpretable solutions. We perform a large-scale analysis of electronic health records. Employing expert's judgment as the causal ground-truth, we show that our causally-regularized algorithm outperforms its L1-regularized equivalence both in predictive performance as well as causal relevance. Finally, we show that the proposed causal regularizer can be used together with representation learning algorithms to yield up to 20% improvement in the causality score of the generated hypotheses.", "pdf": "/pdf/f874a8ac3db85e31cc2fdf628d8563196d36e690.pdf", "TL;DR": "We designed a neural causal regularizer to encourage predictive models to be more causal.", "paperhash": "bahadori|neural_causal_regularization_under_the_independence_of_mechanisms_assumption", "keywords": ["Deep learning", "Applications"], "conflicts": ["gatech.edu", "caltech.edu", "usc.edu", "cmu.edu", "ibm.com", "ed.ac.uk"], "authors": ["Mohammad Taha Bahadori", "Krzysztof Chalupka", "Edward Choi", "Robert Chen", "Walter F. Stewart", "Jimeng Sun"], "authorids": ["bahadori@gatech.edu", "kjchalup@caltech.edu", "mp2893@gatech.edu", "rchen87@gatech.edu", "StewarWF@sutterhealth.org", "jsun@cc.gatech.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287572840, "id": "ICLR.cc/2017/conference/-/paper444/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ByW2Avqgg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper444/reviewers", "ICLR.cc/2017/conference/paper444/areachairs"], "cdate": 1485287572840}}}, {"tddate": null, "tmdate": 1481553776843, "tcdate": 1481553776836, "number": 6, "id": "rkFdPE27e", "invitation": "ICLR.cc/2017/conference/-/paper444/public/comment", "forum": "ByW2Avqgg", "replyto": "rymYO9JXg", "signatures": ["~Mohammad_Taha_Bahadori1"], "readers": ["everyone"], "writers": ["~Mohammad_Taha_Bahadori1"], "content": {"title": "Labeling the Sutter HF dataset", "comment": "We agree that evaluation on a dataset where the ground truth causality is known is ideal.  Unfortunately, there are not many such datasets available. We are actively working with doctors at Sutter Health to label our dataset and provide more rigorous evaluation. \nAlso, the main contribution of this paper is the causal regularizer, whose advantages are more easily identified in datasets with a large number of variable. However, to our knowledge, such large datasets with true labels are not available yet."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Causal Regularization under the Independence of Mechanisms Assumption", "abstract": "Neural networks provide a powerful framework for learning the association between input and response variables and making accurate predictions. However, in many applications such as healthcare, it is important to identify causal relationships between the inputs and the response variables to be able to change the response variables by intervention on the inputs. In pursuit of models whose predictive power comes maximally from causal variables, we propose a novel causal regularizer based on the independence of mechanisms assumption. We utilize the causal regularizer to steer deep neural network architectures towards causally-interpretable solutions. We perform a large-scale analysis of electronic health records. Employing expert's judgment as the causal ground-truth, we show that our causally-regularized algorithm outperforms its L1-regularized equivalence both in predictive performance as well as causal relevance. Finally, we show that the proposed causal regularizer can be used together with representation learning algorithms to yield up to 20% improvement in the causality score of the generated hypotheses.", "pdf": "/pdf/f874a8ac3db85e31cc2fdf628d8563196d36e690.pdf", "TL;DR": "We designed a neural causal regularizer to encourage predictive models to be more causal.", "paperhash": "bahadori|neural_causal_regularization_under_the_independence_of_mechanisms_assumption", "keywords": ["Deep learning", "Applications"], "conflicts": ["gatech.edu", "caltech.edu", "usc.edu", "cmu.edu", "ibm.com", "ed.ac.uk"], "authors": ["Mohammad Taha Bahadori", "Krzysztof Chalupka", "Edward Choi", "Robert Chen", "Walter F. Stewart", "Jimeng Sun"], "authorids": ["bahadori@gatech.edu", "kjchalup@caltech.edu", "mp2893@gatech.edu", "rchen87@gatech.edu", "StewarWF@sutterhealth.org", "jsun@cc.gatech.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287572840, "id": "ICLR.cc/2017/conference/-/paper444/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ByW2Avqgg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper444/reviewers", "ICLR.cc/2017/conference/paper444/areachairs"], "cdate": 1485287572840}}}, {"tddate": null, "tmdate": 1480726650694, "tcdate": 1480726650689, "number": 2, "id": "rymYO9JXg", "invitation": "ICLR.cc/2017/conference/-/paper444/pre-review/question", "forum": "ByW2Avqgg", "replyto": "ByW2Avqgg", "signatures": ["ICLR.cc/2017/conference/paper444/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper444/AnonReviewer3"], "content": {"title": "ground truth causality?", "question": "The method is to apply a weighted L1 regularizer where the weights are proportional to a causality score determined by some method (in this case the authors' own).  The experiments then show that selected variables on a real world data set (with no ground truth as far as I saw) have a higher causality score as regularization is increased.  This isn't so surprising.  Perhaps a more appropriate evaluation would be for some dataset where causality is known, e.g. from controlled trials."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Causal Regularization under the Independence of Mechanisms Assumption", "abstract": "Neural networks provide a powerful framework for learning the association between input and response variables and making accurate predictions. However, in many applications such as healthcare, it is important to identify causal relationships between the inputs and the response variables to be able to change the response variables by intervention on the inputs. In pursuit of models whose predictive power comes maximally from causal variables, we propose a novel causal regularizer based on the independence of mechanisms assumption. We utilize the causal regularizer to steer deep neural network architectures towards causally-interpretable solutions. We perform a large-scale analysis of electronic health records. Employing expert's judgment as the causal ground-truth, we show that our causally-regularized algorithm outperforms its L1-regularized equivalence both in predictive performance as well as causal relevance. Finally, we show that the proposed causal regularizer can be used together with representation learning algorithms to yield up to 20% improvement in the causality score of the generated hypotheses.", "pdf": "/pdf/f874a8ac3db85e31cc2fdf628d8563196d36e690.pdf", "TL;DR": "We designed a neural causal regularizer to encourage predictive models to be more causal.", "paperhash": "bahadori|neural_causal_regularization_under_the_independence_of_mechanisms_assumption", "keywords": ["Deep learning", "Applications"], "conflicts": ["gatech.edu", "caltech.edu", "usc.edu", "cmu.edu", "ibm.com", "ed.ac.uk"], "authors": ["Mohammad Taha Bahadori", "Krzysztof Chalupka", "Edward Choi", "Robert Chen", "Walter F. Stewart", "Jimeng Sun"], "authorids": ["bahadori@gatech.edu", "kjchalup@caltech.edu", "mp2893@gatech.edu", "rchen87@gatech.edu", "StewarWF@sutterhealth.org", "jsun@cc.gatech.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959276340, "id": "ICLR.cc/2017/conference/-/paper444/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper444/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper444/AnonReviewer2", "ICLR.cc/2017/conference/paper444/AnonReviewer3"], "reply": {"forum": "ByW2Avqgg", "replyto": "ByW2Avqgg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper444/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper444/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959276340}}}, {"tddate": null, "tmdate": 1480718527183, "tcdate": 1480718527180, "number": 1, "id": "SyDp_uk7l", "invitation": "ICLR.cc/2017/conference/-/paper444/official/comment", "forum": "ByW2Avqgg", "replyto": "ByW2Avqgg", "signatures": ["ICLR.cc/2017/conference/paper444/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper444/AnonReviewer1"], "content": {"title": "Reproducibility", "comment": "While the paper provides enough detail to re-implement the proposed methods, there is no discussion as to whether the heart failure dataset will be released. This would be key for reproducibility."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Causal Regularization under the Independence of Mechanisms Assumption", "abstract": "Neural networks provide a powerful framework for learning the association between input and response variables and making accurate predictions. However, in many applications such as healthcare, it is important to identify causal relationships between the inputs and the response variables to be able to change the response variables by intervention on the inputs. In pursuit of models whose predictive power comes maximally from causal variables, we propose a novel causal regularizer based on the independence of mechanisms assumption. We utilize the causal regularizer to steer deep neural network architectures towards causally-interpretable solutions. We perform a large-scale analysis of electronic health records. Employing expert's judgment as the causal ground-truth, we show that our causally-regularized algorithm outperforms its L1-regularized equivalence both in predictive performance as well as causal relevance. Finally, we show that the proposed causal regularizer can be used together with representation learning algorithms to yield up to 20% improvement in the causality score of the generated hypotheses.", "pdf": "/pdf/f874a8ac3db85e31cc2fdf628d8563196d36e690.pdf", "TL;DR": "We designed a neural causal regularizer to encourage predictive models to be more causal.", "paperhash": "bahadori|neural_causal_regularization_under_the_independence_of_mechanisms_assumption", "keywords": ["Deep learning", "Applications"], "conflicts": ["gatech.edu", "caltech.edu", "usc.edu", "cmu.edu", "ibm.com", "ed.ac.uk"], "authors": ["Mohammad Taha Bahadori", "Krzysztof Chalupka", "Edward Choi", "Robert Chen", "Walter F. Stewart", "Jimeng Sun"], "authorids": ["bahadori@gatech.edu", "kjchalup@caltech.edu", "mp2893@gatech.edu", "rchen87@gatech.edu", "StewarWF@sutterhealth.org", "jsun@cc.gatech.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287572706, "id": "ICLR.cc/2017/conference/-/paper444/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "ByW2Avqgg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper444/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper444/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper444/reviewers", "ICLR.cc/2017/conference/paper444/areachairs"], "cdate": 1485287572706}}}, {"tddate": null, "tmdate": 1480712887767, "tcdate": 1480712887762, "number": 1, "id": "Hkl6fwkmg", "invitation": "ICLR.cc/2017/conference/-/paper444/pre-review/question", "forum": "ByW2Avqgg", "replyto": "ByW2Avqgg", "signatures": ["ICLR.cc/2017/conference/paper444/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper444/AnonReviewer2"], "content": {"title": "samples from an observational distribution", "question": "Algorithm 2 has notation that I find somewhat confusing.  Step 1 generates data from $p_{X,Y}$, but in my reading of the paper there is no place that actually indicates what those distributions are: I understand that Fig 1 has the graphical models, but what is the actual form of the distribution?  Does this choice influence the results?  Next, Step 2 says that the classifier is a map from measures $\\mathbbm{P}_{X,Y}$ to $[0,1]$.  But how is that the input?  What form is given for the measure?  Sufficient statistics or some other form?  Alternatively, perhaps you mean that the input are samples.  If so, how many samples, and how does this affect the analysis?  This is one of the two key methodological points in the paper, and I think it warrants more specificity and mathematical detail than is currently present."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Causal Regularization under the Independence of Mechanisms Assumption", "abstract": "Neural networks provide a powerful framework for learning the association between input and response variables and making accurate predictions. However, in many applications such as healthcare, it is important to identify causal relationships between the inputs and the response variables to be able to change the response variables by intervention on the inputs. In pursuit of models whose predictive power comes maximally from causal variables, we propose a novel causal regularizer based on the independence of mechanisms assumption. We utilize the causal regularizer to steer deep neural network architectures towards causally-interpretable solutions. We perform a large-scale analysis of electronic health records. Employing expert's judgment as the causal ground-truth, we show that our causally-regularized algorithm outperforms its L1-regularized equivalence both in predictive performance as well as causal relevance. Finally, we show that the proposed causal regularizer can be used together with representation learning algorithms to yield up to 20% improvement in the causality score of the generated hypotheses.", "pdf": "/pdf/f874a8ac3db85e31cc2fdf628d8563196d36e690.pdf", "TL;DR": "We designed a neural causal regularizer to encourage predictive models to be more causal.", "paperhash": "bahadori|neural_causal_regularization_under_the_independence_of_mechanisms_assumption", "keywords": ["Deep learning", "Applications"], "conflicts": ["gatech.edu", "caltech.edu", "usc.edu", "cmu.edu", "ibm.com", "ed.ac.uk"], "authors": ["Mohammad Taha Bahadori", "Krzysztof Chalupka", "Edward Choi", "Robert Chen", "Walter F. Stewart", "Jimeng Sun"], "authorids": ["bahadori@gatech.edu", "kjchalup@caltech.edu", "mp2893@gatech.edu", "rchen87@gatech.edu", "StewarWF@sutterhealth.org", "jsun@cc.gatech.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959276340, "id": "ICLR.cc/2017/conference/-/paper444/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper444/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper444/AnonReviewer2", "ICLR.cc/2017/conference/paper444/AnonReviewer3"], "reply": {"forum": "ByW2Avqgg", "replyto": "ByW2Avqgg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper444/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper444/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959276340}}}, {"tddate": null, "tmdate": 1478735761863, "tcdate": 1478735760649, "number": 5, "id": "rJ_9PV-Wg", "invitation": "ICLR.cc/2017/conference/-/paper444/public/comment", "forum": "ByW2Avqgg", "replyto": "BJn8UXCll", "signatures": ["~Krzysztof_Chalupka1"], "readers": ["everyone"], "writers": ["~Krzysztof_Chalupka1"], "content": {"title": "Novelty of causality analysis between two discrete variables (Chalupka et al, 2016)", "comment": "We agree with the reviewer that Chalupka et al\u2019s work can be seen as a direct extension of refs [3,4]. I (K. Chalupka) will make sure this, as well as differences with Lopez-Paz\u2019s work, will be extensively discussed in the nearest arXiv update to my paper. \n\nThere are two points that make Chalupka\u2019s work important for this article: 1) It explicitly considers discrete variables. Whereas it is true that extending Lopez-Paz\u2019s work to the discrete case is straightforward, we do not see it explicit in his work, and there is no evaluation of his methods on the discrete case in refs [3,4,5]. 2) More importantly, differentiating between *all* the causal structures shown in Fig.1 in this work is central to Chalupka\u2019s method. Lopez-Paz\u2019s, as well as any previous work, only considers the \u201cX -> Y\u201d, \u201cY -> X\u201d and \u201cX <- H -> Y\u201d cases, and the latter often only in passing.\t"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Causal Regularization under the Independence of Mechanisms Assumption", "abstract": "Neural networks provide a powerful framework for learning the association between input and response variables and making accurate predictions. However, in many applications such as healthcare, it is important to identify causal relationships between the inputs and the response variables to be able to change the response variables by intervention on the inputs. In pursuit of models whose predictive power comes maximally from causal variables, we propose a novel causal regularizer based on the independence of mechanisms assumption. We utilize the causal regularizer to steer deep neural network architectures towards causally-interpretable solutions. We perform a large-scale analysis of electronic health records. Employing expert's judgment as the causal ground-truth, we show that our causally-regularized algorithm outperforms its L1-regularized equivalence both in predictive performance as well as causal relevance. Finally, we show that the proposed causal regularizer can be used together with representation learning algorithms to yield up to 20% improvement in the causality score of the generated hypotheses.", "pdf": "/pdf/f874a8ac3db85e31cc2fdf628d8563196d36e690.pdf", "TL;DR": "We designed a neural causal regularizer to encourage predictive models to be more causal.", "paperhash": "bahadori|neural_causal_regularization_under_the_independence_of_mechanisms_assumption", "keywords": ["Deep learning", "Applications"], "conflicts": ["gatech.edu", "caltech.edu", "usc.edu", "cmu.edu", "ibm.com", "ed.ac.uk"], "authors": ["Mohammad Taha Bahadori", "Krzysztof Chalupka", "Edward Choi", "Robert Chen", "Walter F. Stewart", "Jimeng Sun"], "authorids": ["bahadori@gatech.edu", "kjchalup@caltech.edu", "mp2893@gatech.edu", "rchen87@gatech.edu", "StewarWF@sutterhealth.org", "jsun@cc.gatech.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287572840, "id": "ICLR.cc/2017/conference/-/paper444/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ByW2Avqgg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper444/reviewers", "ICLR.cc/2017/conference/paper444/areachairs"], "cdate": 1485287572840}}}, {"tddate": null, "tmdate": 1478726579539, "tcdate": 1478726579509, "number": 4, "id": "rki2mM-bx", "invitation": "ICLR.cc/2017/conference/-/paper444/public/comment", "forum": "ByW2Avqgg", "replyto": "BJn8UXCll", "signatures": ["~Mohammad_Taha_Bahadori1"], "readers": ["everyone"], "writers": ["~Mohammad_Taha_Bahadori1"], "content": {"title": "On Novelty", "comment": "Dear David,\n\nThank you for the references!  We will add a new related works section shortly and discuss the connections and novelty of this paper. In brief, your comments were about two pieces of work: (1) this paper and (2) (Chalupka et al, 2016).  The main contribution of our paper (as made clear in the title and the abstract) is the introduction of a causal regularizer that can penalize deep neural networks and perform causal variable selection, not Chalupka\u2019s causality classifier."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Causal Regularization under the Independence of Mechanisms Assumption", "abstract": "Neural networks provide a powerful framework for learning the association between input and response variables and making accurate predictions. However, in many applications such as healthcare, it is important to identify causal relationships between the inputs and the response variables to be able to change the response variables by intervention on the inputs. In pursuit of models whose predictive power comes maximally from causal variables, we propose a novel causal regularizer based on the independence of mechanisms assumption. We utilize the causal regularizer to steer deep neural network architectures towards causally-interpretable solutions. We perform a large-scale analysis of electronic health records. Employing expert's judgment as the causal ground-truth, we show that our causally-regularized algorithm outperforms its L1-regularized equivalence both in predictive performance as well as causal relevance. Finally, we show that the proposed causal regularizer can be used together with representation learning algorithms to yield up to 20% improvement in the causality score of the generated hypotheses.", "pdf": "/pdf/f874a8ac3db85e31cc2fdf628d8563196d36e690.pdf", "TL;DR": "We designed a neural causal regularizer to encourage predictive models to be more causal.", "paperhash": "bahadori|neural_causal_regularization_under_the_independence_of_mechanisms_assumption", "keywords": ["Deep learning", "Applications"], "conflicts": ["gatech.edu", "caltech.edu", "usc.edu", "cmu.edu", "ibm.com", "ed.ac.uk"], "authors": ["Mohammad Taha Bahadori", "Krzysztof Chalupka", "Edward Choi", "Robert Chen", "Walter F. Stewart", "Jimeng Sun"], "authorids": ["bahadori@gatech.edu", "kjchalup@caltech.edu", "mp2893@gatech.edu", "rchen87@gatech.edu", "StewarWF@sutterhealth.org", "jsun@cc.gatech.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287572840, "id": "ICLR.cc/2017/conference/-/paper444/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ByW2Avqgg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper444/reviewers", "ICLR.cc/2017/conference/paper444/areachairs"], "cdate": 1485287572840}}}, {"tddate": null, "tmdate": 1478726523897, "tcdate": 1478726522886, "number": 3, "id": "SymFXzWWx", "invitation": "ICLR.cc/2017/conference/-/paper444/public/comment", "forum": "ByW2Avqgg", "replyto": "BJn8UXCll", "signatures": ["~Mohammad_Taha_Bahadori1"], "readers": ["everyone"], "writers": ["~Mohammad_Taha_Bahadori1"], "content": {"title": "Novelty of the proposed neural causal regularizer (this paper)", "comment": "Dear David,\n\nIn [6, Page 181] there is a one-paragraph \u201cFuture Work\u201d section of Lopez-Paz\u2019s PhD thesis. Unfortunately, the idea has not been further developed there and we cannot compare it to our fully-developed and tested methodology. Another work [5, Section 3], mentions the possibility of having a regularizer in one line (to separate only causal and anti-causal cases), but again the idea is left as an untested proposal. \n\nRegarding the sentence in [5], note that the score of a \u201ccausal-anticausal\u201d-only classifier cannot regularize a multivariate model such as logistic regression in a principled way. We have discussed why our proposed regularizer can do this task properly in Section 2.2 in the paragraph after Eq. (1). Moreover, another major novelty of our proposed causal regularizer is to do joint causal variable selection (via L1 regularization) and prediction in high dimensions, contrary to the untested idea in [5]. \n\nRegarding your comment \u201cCausal regularization is also at the heart of invariant prediction [7], and causal transfer [8,9].\u201d: None of the methods in these references propose a causal regularizer. In particular, their method cannot be easily used for our goal of \u201cregularizing neural networks, as in Eq. (3)\u201d (similar to what we proposed in Eq. (1), which can be easily used together with deep neural networks --the main reason we submit this paper to ICLR)."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Causal Regularization under the Independence of Mechanisms Assumption", "abstract": "Neural networks provide a powerful framework for learning the association between input and response variables and making accurate predictions. However, in many applications such as healthcare, it is important to identify causal relationships between the inputs and the response variables to be able to change the response variables by intervention on the inputs. In pursuit of models whose predictive power comes maximally from causal variables, we propose a novel causal regularizer based on the independence of mechanisms assumption. We utilize the causal regularizer to steer deep neural network architectures towards causally-interpretable solutions. We perform a large-scale analysis of electronic health records. Employing expert's judgment as the causal ground-truth, we show that our causally-regularized algorithm outperforms its L1-regularized equivalence both in predictive performance as well as causal relevance. Finally, we show that the proposed causal regularizer can be used together with representation learning algorithms to yield up to 20% improvement in the causality score of the generated hypotheses.", "pdf": "/pdf/f874a8ac3db85e31cc2fdf628d8563196d36e690.pdf", "TL;DR": "We designed a neural causal regularizer to encourage predictive models to be more causal.", "paperhash": "bahadori|neural_causal_regularization_under_the_independence_of_mechanisms_assumption", "keywords": ["Deep learning", "Applications"], "conflicts": ["gatech.edu", "caltech.edu", "usc.edu", "cmu.edu", "ibm.com", "ed.ac.uk"], "authors": ["Mohammad Taha Bahadori", "Krzysztof Chalupka", "Edward Choi", "Robert Chen", "Walter F. Stewart", "Jimeng Sun"], "authorids": ["bahadori@gatech.edu", "kjchalup@caltech.edu", "mp2893@gatech.edu", "rchen87@gatech.edu", "StewarWF@sutterhealth.org", "jsun@cc.gatech.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287572840, "id": "ICLR.cc/2017/conference/-/paper444/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ByW2Avqgg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper444/reviewers", "ICLR.cc/2017/conference/paper444/areachairs"], "cdate": 1485287572840}}}, {"tddate": null, "tmdate": 1478534740139, "tcdate": 1478534740131, "number": 1, "id": "BJn8UXCll", "invitation": "ICLR.cc/2017/conference/-/paper444/public/comment", "forum": "ByW2Avqgg", "replyto": "ByW2Avqgg", "signatures": ["~David_Lopez-Paz2"], "readers": ["everyone"], "writers": ["~David_Lopez-Paz2"], "content": {"title": "Novelty and prior work", "comment": "Learning classifiers to distinguish between causal, anticausal, and confounded dependencies is not a novel idea. It was introduced in the competitions of Guyon [1,2], and later developed in the context of kernel machines [3,4], learning theory [4], and neural networks [5]. These classifiers were applied to discrete data [1,2,3,4,5,6], extend to multiple random variables [4 Appendix C, 6], generalize the additive noise model assumption [5,6], consider hidden confounding [1,2,4 Appendix C, 6], and make use of classifier soft-scores to measure predictive uncertainty [1,2,3,4,5,6].\n\nThe idea of causal regularization is not novel, either. It was proposed at least in [1 Page 181] and [2 Section 3]. Causal regularization is also at the heart of invariant prediction [7], and causal transfer [8,9].\n\nNone of these works are cited by this manuscript or by the companion manuscript (Chalupka et al., 2016). This omission undermines the novelty claims of the manuscript, and prevents the readers from easily seeing what the contribution is. The authors should therefore add a comprehensive discussion of the related works and a realistic discussion of the claimed novelty in this work.\n\n[1] https://www.kaggle.com/c/cause-effect-pairs/\n[2] https://competitions.codalab.org/competitions/1381\n[3] \"The Randomized Causation Coefficient\" https://arxiv.org/abs/1409.4366\n[4] \"Towards a Learning Theory of Cause-Effect Inference\" https://arxiv.org/abs/1502.02398\n[5] \"Discovering Causal Signals in Images\" https://arxiv.org/abs/1605.08179\n[6] \"From Dependence to Causation\" https://arxiv.org/pdf/1607.03300v1.pdf\n[7] \"Causal inference using invariant prediction: identification and confidence intervals\" https://arxiv.org/abs/1501.01332\n[8] \"Causal Transfer in Machine Learning\" https://arxiv.org/abs/1507.05333\n[9] \"A Causal Perspective on Domain Adaptation\" https://arxiv.org/abs/1507.05333v1"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Causal Regularization under the Independence of Mechanisms Assumption", "abstract": "Neural networks provide a powerful framework for learning the association between input and response variables and making accurate predictions. However, in many applications such as healthcare, it is important to identify causal relationships between the inputs and the response variables to be able to change the response variables by intervention on the inputs. In pursuit of models whose predictive power comes maximally from causal variables, we propose a novel causal regularizer based on the independence of mechanisms assumption. We utilize the causal regularizer to steer deep neural network architectures towards causally-interpretable solutions. We perform a large-scale analysis of electronic health records. Employing expert's judgment as the causal ground-truth, we show that our causally-regularized algorithm outperforms its L1-regularized equivalence both in predictive performance as well as causal relevance. Finally, we show that the proposed causal regularizer can be used together with representation learning algorithms to yield up to 20% improvement in the causality score of the generated hypotheses.", "pdf": "/pdf/f874a8ac3db85e31cc2fdf628d8563196d36e690.pdf", "TL;DR": "We designed a neural causal regularizer to encourage predictive models to be more causal.", "paperhash": "bahadori|neural_causal_regularization_under_the_independence_of_mechanisms_assumption", "keywords": ["Deep learning", "Applications"], "conflicts": ["gatech.edu", "caltech.edu", "usc.edu", "cmu.edu", "ibm.com", "ed.ac.uk"], "authors": ["Mohammad Taha Bahadori", "Krzysztof Chalupka", "Edward Choi", "Robert Chen", "Walter F. Stewart", "Jimeng Sun"], "authorids": ["bahadori@gatech.edu", "kjchalup@caltech.edu", "mp2893@gatech.edu", "rchen87@gatech.edu", "StewarWF@sutterhealth.org", "jsun@cc.gatech.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287572840, "id": "ICLR.cc/2017/conference/-/paper444/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ByW2Avqgg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper444/reviewers", "ICLR.cc/2017/conference/paper444/areachairs"], "cdate": 1485287572840}}}], "count": 20}