{"notes": [{"id": "vCEhC7nOb6", "original": "-4VKn28XzSI", "number": 1518, "cdate": 1601308168633, "ddate": null, "tcdate": 1601308168633, "tmdate": 1614985704926, "tddate": null, "forum": "vCEhC7nOb6", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets", "authorids": ["~Depen_Morwani1", "~Harish_Guruprasad_Ramaswamy1"], "authors": ["Depen Morwani", "Harish Guruprasad Ramaswamy"], "keywords": ["Deep Learning Theory", "Weight Normalization", "Inductive Bias", "Gradient Descent"], "abstract": "We analyze the inductive bias of gradient descent for weight normalized smooth homogeneous neural nets, when trained on exponential or cross-entropy loss. Our analysis focuses on exponential weight normalization (EWN), which encourages weight updates along the radial direction. This paper shows that the gradient flow path with EWN is equivalent to gradient flow on standard networks with an adaptive learning rate, and hence causes the weights to be updated in a way that prefers asymptotic relative sparsity. These results can be extended to hold for gradient descent via an appropriate adaptive learning rate. The asymptotic convergence rate of the loss in this setting is given by $\\Theta(\\frac{1}{t(\\log t)^2})$, and is independent of the depth of the network. We contrast these results with the inductive bias of standard weight normalization (SWN) and unnormalized architectures, and demonstrate their implications on synthetic data sets.Experimental results on simple data sets and architectures support our claim on sparse EWN solutions, even with SGD. This demonstrates its potential applications in learning prunable neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "morwani|inductive_bias_of_gradient_descent_for_exponentially_weight_normalized_smooth_homogeneous_neural_nets", "pdf": "/pdf/1aba0dadfc3ada324a5cd12ee1586066d3c98935.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1sKfR9Gf6", "_bibtex": "@misc{\nmorwani2021inductive,\ntitle={Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets},\nauthor={Depen Morwani and Harish Guruprasad Ramaswamy},\nyear={2021},\nurl={https://openreview.net/forum?id=vCEhC7nOb6}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 13, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "ixm7xiyoaH0", "original": null, "number": 1, "cdate": 1610040438918, "ddate": null, "tcdate": 1610040438918, "tmdate": 1610474039762, "tddate": null, "forum": "vCEhC7nOb6", "replyto": "vCEhC7nOb6", "invitation": "ICLR.cc/2021/Conference/Paper1518/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The main concern is that the results in this paper are based on strong asymptotic assumptions. (At least) more empirical results are needed.\n"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets", "authorids": ["~Depen_Morwani1", "~Harish_Guruprasad_Ramaswamy1"], "authors": ["Depen Morwani", "Harish Guruprasad Ramaswamy"], "keywords": ["Deep Learning Theory", "Weight Normalization", "Inductive Bias", "Gradient Descent"], "abstract": "We analyze the inductive bias of gradient descent for weight normalized smooth homogeneous neural nets, when trained on exponential or cross-entropy loss. Our analysis focuses on exponential weight normalization (EWN), which encourages weight updates along the radial direction. This paper shows that the gradient flow path with EWN is equivalent to gradient flow on standard networks with an adaptive learning rate, and hence causes the weights to be updated in a way that prefers asymptotic relative sparsity. These results can be extended to hold for gradient descent via an appropriate adaptive learning rate. The asymptotic convergence rate of the loss in this setting is given by $\\Theta(\\frac{1}{t(\\log t)^2})$, and is independent of the depth of the network. We contrast these results with the inductive bias of standard weight normalization (SWN) and unnormalized architectures, and demonstrate their implications on synthetic data sets.Experimental results on simple data sets and architectures support our claim on sparse EWN solutions, even with SGD. This demonstrates its potential applications in learning prunable neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "morwani|inductive_bias_of_gradient_descent_for_exponentially_weight_normalized_smooth_homogeneous_neural_nets", "pdf": "/pdf/1aba0dadfc3ada324a5cd12ee1586066d3c98935.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1sKfR9Gf6", "_bibtex": "@misc{\nmorwani2021inductive,\ntitle={Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets},\nauthor={Depen Morwani and Harish Guruprasad Ramaswamy},\nyear={2021},\nurl={https://openreview.net/forum?id=vCEhC7nOb6}\n}"}, "tags": [], "invitation": {"reply": {"forum": "vCEhC7nOb6", "replyto": "vCEhC7nOb6", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040438905, "tmdate": 1610474039746, "id": "ICLR.cc/2021/Conference/Paper1518/-/Decision"}}}, {"id": "9mqqM34fbP", "original": null, "number": 3, "cdate": 1603945858705, "ddate": null, "tcdate": 1603945858705, "tmdate": 1607203269890, "tddate": null, "forum": "vCEhC7nOb6", "replyto": "vCEhC7nOb6", "invitation": "ICLR.cc/2021/Conference/Paper1518/-/Official_Review", "content": {"title": "review", "review": "This paper analyzes weight normalization methods, including exponential weight normalization (EWN) and standard weight normalization (SWN), in contrast with unnormalized networks. Under a number of assumptions, the paper characterizes the asymptotic relation between weight norm and gradient norm at the node level (Theorem 2), which shows a distinction between SWN and EWN. Then it's argued that SWN leads to sparser solutions (Proposition 3), which is potentially beneficial for pruning. The paper also shows a convergence rate for SWN which is slightly faster than unnormalized and SWN from previous work, but under stronger assumptions. The paper verifies these results empirically on some toy examples.\n\npros:\n+ The exponential weight normalization method seems new.\n+ The paper has some interesting findings regarding the asymptotic behavior of weight normalization methods (if the results can be justified properly).\n\ncons:\nThe theoretical results are based on very strong asymptotic assumptions, which are not justified properly. The experiments are on very toy settings which are far below the bar. Either the theory or the experiments need to be stronger for this paper to be a solid contribution.\n\n- The assumptions (A1)-(A4) used throughout the paper are much stronger than those in previous work, such as Lyu & Li (2020). In particular, (A3) and (A4) are nonstandard. I'm not sure when these assumptions are expected to hold, and they are only empirically verified on an extremely simple dataset (4 examples).\n\n- In Proposition 3, which is where it is shown that SWN leads to sparsity, there is an extremely strong assumption that the ratio of two gradient norms at two nodes stays constant forever after some point in training. How can this possibly be true?\n\n\n---------- after rebuttal ----------\n\nThanks for the response and the updated manuscript. I'm raising my score from 4 to 5. I'm still leaning towards rejection since I still find the results quite subtle and I hope to see more empirical justifications.\n\nIn the updated Proposition 3, the sparsity-inducing property 3 assumes the existence of a time $t_2>t_1$ when the ratio between the two weight norms deviate from $1/c$. However, it seems entirely possible that this ratio will have already converged $1/c$ after time $t_1$; in this case the two weight norms grow at the same rate. It would be good to investigate this more carefully to see which cases are more likely to happen. I'm also concerned that the advantage of EWN for pruning only shows up in extremely small loss value (Figure 7), and therefore the practical relevance shown in the current paper is not very convincing.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1518/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1518/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets", "authorids": ["~Depen_Morwani1", "~Harish_Guruprasad_Ramaswamy1"], "authors": ["Depen Morwani", "Harish Guruprasad Ramaswamy"], "keywords": ["Deep Learning Theory", "Weight Normalization", "Inductive Bias", "Gradient Descent"], "abstract": "We analyze the inductive bias of gradient descent for weight normalized smooth homogeneous neural nets, when trained on exponential or cross-entropy loss. Our analysis focuses on exponential weight normalization (EWN), which encourages weight updates along the radial direction. This paper shows that the gradient flow path with EWN is equivalent to gradient flow on standard networks with an adaptive learning rate, and hence causes the weights to be updated in a way that prefers asymptotic relative sparsity. These results can be extended to hold for gradient descent via an appropriate adaptive learning rate. The asymptotic convergence rate of the loss in this setting is given by $\\Theta(\\frac{1}{t(\\log t)^2})$, and is independent of the depth of the network. We contrast these results with the inductive bias of standard weight normalization (SWN) and unnormalized architectures, and demonstrate their implications on synthetic data sets.Experimental results on simple data sets and architectures support our claim on sparse EWN solutions, even with SGD. This demonstrates its potential applications in learning prunable neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "morwani|inductive_bias_of_gradient_descent_for_exponentially_weight_normalized_smooth_homogeneous_neural_nets", "pdf": "/pdf/1aba0dadfc3ada324a5cd12ee1586066d3c98935.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1sKfR9Gf6", "_bibtex": "@misc{\nmorwani2021inductive,\ntitle={Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets},\nauthor={Depen Morwani and Harish Guruprasad Ramaswamy},\nyear={2021},\nurl={https://openreview.net/forum?id=vCEhC7nOb6}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "vCEhC7nOb6", "replyto": "vCEhC7nOb6", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1518/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538116779, "tmdate": 1606915783460, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1518/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1518/-/Official_Review"}}}, {"id": "t5qt2aRWIA", "original": null, "number": 12, "cdate": 1606128909227, "ddate": null, "tcdate": 1606128909227, "tmdate": 1606128909227, "tddate": null, "forum": "vCEhC7nOb6", "replyto": "Qkelk-8Ya2", "invitation": "ICLR.cc/2021/Conference/Paper1518/-/Official_Comment", "content": {"title": "Thanks for the comments", "comment": "Thanks very much for your feedback and comments.\n\n3. It is indeed a claim that we have proved in Appendix E. We have also added a revised version, elaborating on the proof of this proposition in Appendix E.\n4. The constant eta(t) is a special case when c is set to 0."}, "signatures": ["ICLR.cc/2021/Conference/Paper1518/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1518/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets", "authorids": ["~Depen_Morwani1", "~Harish_Guruprasad_Ramaswamy1"], "authors": ["Depen Morwani", "Harish Guruprasad Ramaswamy"], "keywords": ["Deep Learning Theory", "Weight Normalization", "Inductive Bias", "Gradient Descent"], "abstract": "We analyze the inductive bias of gradient descent for weight normalized smooth homogeneous neural nets, when trained on exponential or cross-entropy loss. Our analysis focuses on exponential weight normalization (EWN), which encourages weight updates along the radial direction. This paper shows that the gradient flow path with EWN is equivalent to gradient flow on standard networks with an adaptive learning rate, and hence causes the weights to be updated in a way that prefers asymptotic relative sparsity. These results can be extended to hold for gradient descent via an appropriate adaptive learning rate. The asymptotic convergence rate of the loss in this setting is given by $\\Theta(\\frac{1}{t(\\log t)^2})$, and is independent of the depth of the network. We contrast these results with the inductive bias of standard weight normalization (SWN) and unnormalized architectures, and demonstrate their implications on synthetic data sets.Experimental results on simple data sets and architectures support our claim on sparse EWN solutions, even with SGD. This demonstrates its potential applications in learning prunable neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "morwani|inductive_bias_of_gradient_descent_for_exponentially_weight_normalized_smooth_homogeneous_neural_nets", "pdf": "/pdf/1aba0dadfc3ada324a5cd12ee1586066d3c98935.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1sKfR9Gf6", "_bibtex": "@misc{\nmorwani2021inductive,\ntitle={Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets},\nauthor={Depen Morwani and Harish Guruprasad Ramaswamy},\nyear={2021},\nurl={https://openreview.net/forum?id=vCEhC7nOb6}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "vCEhC7nOb6", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1518/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1518/Authors|ICLR.cc/2021/Conference/Paper1518/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858773, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1518/-/Official_Comment"}}}, {"id": "wYpSGpeFRcQ", "original": null, "number": 11, "cdate": 1606128781934, "ddate": null, "tcdate": 1606128781934, "tmdate": 1606128781934, "tddate": null, "forum": "vCEhC7nOb6", "replyto": "vCEhC7nOb6", "invitation": "ICLR.cc/2021/Conference/Paper1518/-/Official_Comment", "content": {"title": "Summary of changes in the rebuttal revision (version dated Nov 23)", "comment": "There is no change in the main paper. The changes in the Appendix are listed below:\n1. We have provided more details on the proof of Proposition 3 in Appendix E."}, "signatures": ["ICLR.cc/2021/Conference/Paper1518/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1518/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets", "authorids": ["~Depen_Morwani1", "~Harish_Guruprasad_Ramaswamy1"], "authors": ["Depen Morwani", "Harish Guruprasad Ramaswamy"], "keywords": ["Deep Learning Theory", "Weight Normalization", "Inductive Bias", "Gradient Descent"], "abstract": "We analyze the inductive bias of gradient descent for weight normalized smooth homogeneous neural nets, when trained on exponential or cross-entropy loss. Our analysis focuses on exponential weight normalization (EWN), which encourages weight updates along the radial direction. This paper shows that the gradient flow path with EWN is equivalent to gradient flow on standard networks with an adaptive learning rate, and hence causes the weights to be updated in a way that prefers asymptotic relative sparsity. These results can be extended to hold for gradient descent via an appropriate adaptive learning rate. The asymptotic convergence rate of the loss in this setting is given by $\\Theta(\\frac{1}{t(\\log t)^2})$, and is independent of the depth of the network. We contrast these results with the inductive bias of standard weight normalization (SWN) and unnormalized architectures, and demonstrate their implications on synthetic data sets.Experimental results on simple data sets and architectures support our claim on sparse EWN solutions, even with SGD. This demonstrates its potential applications in learning prunable neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "morwani|inductive_bias_of_gradient_descent_for_exponentially_weight_normalized_smooth_homogeneous_neural_nets", "pdf": "/pdf/1aba0dadfc3ada324a5cd12ee1586066d3c98935.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1sKfR9Gf6", "_bibtex": "@misc{\nmorwani2021inductive,\ntitle={Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets},\nauthor={Depen Morwani and Harish Guruprasad Ramaswamy},\nyear={2021},\nurl={https://openreview.net/forum?id=vCEhC7nOb6}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "vCEhC7nOb6", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1518/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1518/Authors|ICLR.cc/2021/Conference/Paper1518/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858773, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1518/-/Official_Comment"}}}, {"id": "Qkelk-8Ya2", "original": null, "number": 10, "cdate": 1606036480245, "ddate": null, "tcdate": 1606036480245, "tmdate": 1606036538700, "tddate": null, "forum": "vCEhC7nOb6", "replyto": "S6ySHyaJIYJ", "invitation": "ICLR.cc/2021/Conference/Paper1518/-/Official_Comment", "content": {"title": "Thanks for the clarifications", "comment": "You addressed most of my comments.\n\n3. In the new version of Proposition 3, the first part is an assumption right (\"There exists a time $t_1$...\")? It currently looks like one of the claims.\n\n5. After Proposition 1, it is still written that Proposition 1 holds for a constant eta(t), but the eta(t) in the Proposition statement is not constant. This is not clear.\n\nI read the other reviews and responses and raised the score from 6 to 7."}, "signatures": ["ICLR.cc/2021/Conference/Paper1518/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1518/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets", "authorids": ["~Depen_Morwani1", "~Harish_Guruprasad_Ramaswamy1"], "authors": ["Depen Morwani", "Harish Guruprasad Ramaswamy"], "keywords": ["Deep Learning Theory", "Weight Normalization", "Inductive Bias", "Gradient Descent"], "abstract": "We analyze the inductive bias of gradient descent for weight normalized smooth homogeneous neural nets, when trained on exponential or cross-entropy loss. Our analysis focuses on exponential weight normalization (EWN), which encourages weight updates along the radial direction. This paper shows that the gradient flow path with EWN is equivalent to gradient flow on standard networks with an adaptive learning rate, and hence causes the weights to be updated in a way that prefers asymptotic relative sparsity. These results can be extended to hold for gradient descent via an appropriate adaptive learning rate. The asymptotic convergence rate of the loss in this setting is given by $\\Theta(\\frac{1}{t(\\log t)^2})$, and is independent of the depth of the network. We contrast these results with the inductive bias of standard weight normalization (SWN) and unnormalized architectures, and demonstrate their implications on synthetic data sets.Experimental results on simple data sets and architectures support our claim on sparse EWN solutions, even with SGD. This demonstrates its potential applications in learning prunable neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "morwani|inductive_bias_of_gradient_descent_for_exponentially_weight_normalized_smooth_homogeneous_neural_nets", "pdf": "/pdf/1aba0dadfc3ada324a5cd12ee1586066d3c98935.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1sKfR9Gf6", "_bibtex": "@misc{\nmorwani2021inductive,\ntitle={Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets},\nauthor={Depen Morwani and Harish Guruprasad Ramaswamy},\nyear={2021},\nurl={https://openreview.net/forum?id=vCEhC7nOb6}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "vCEhC7nOb6", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1518/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1518/Authors|ICLR.cc/2021/Conference/Paper1518/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858773, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1518/-/Official_Comment"}}}, {"id": "YNluSAMr75b", "original": null, "number": 2, "cdate": 1603879798910, "ddate": null, "tcdate": 1603879798910, "tmdate": 1606036508639, "tddate": null, "forum": "vCEhC7nOb6", "replyto": "vCEhC7nOb6", "invitation": "ICLR.cc/2021/Conference/Paper1518/-/Official_Review", "content": {"title": "Solid results for analyzing normalization methods, but significance is not exactly clear and several results lack details.", "review": "### Summary \nThis paper studies the inductive bias of gradient methods with normalization on smooth homogeneous models. The focus is on two normalization methods, standard weight normalization (SWN) and exponential weight normalization (EWN). The authors show two main results. The first characterizes the trajectory of normalized gradient methods from which they provide theoretical evidence that EWN is biased towards sparse solutions. The second provides convergence rates for the normalized methods which shows the difference between convergence rates of normalized and unnormalized methods. The theoretical results are corroborated with experiments on several toy datasets.\n\n### Reason for score\nI am currently inclined towards accepting the paper because the results are novel, solid and should be interesting and useful for researchers working on theory of deep learning. However, the score is only marginally above the acceptance threshold, because I have several concerns regarding the clarity and significance of the results. I am willing to raise my score if the authors address my concerns in the rebuttal.\n\n### Pros\n1.\tThe theoretical results are solid, novel and the proof techniques might be useful in other inductive bias analyses.\n2.\tThe sparsity result for EWN is interesting and provides novel insights on pruning neural networks as the MNIST experiments show.\n3.\tMost of the paper is clearly written.\n\n### Cons (roughly ordered from major to minor comments)\n\n1.\tIt is not clear in which cases SWN and EWN are used in practice. The authors do not explicitly cite papers that use them. Therefore, it is not clear how to assess the significance of the results.\n2.\tAfter Theorem 2 it is claimed that ||w_u(t)|| is inversely proportional to ||grad_u L(t)||. I am not sure why this is correct. If ||w_u(t)|| = t and ||grad_u L(t)|| = 1/t^2 for all u, then the theorem result holds, but the claim after the theorem (mentioned above) does not hold. Am I missing something?\n3.\tIn Proposition 3, the assumption that the ratio of gradient norms is exactly c from some t onwards is very strong. The authors should comment on this. Does it hold in practice? Does the Proposition hold under weaker assumptions?\n4.\tMost of the experiments are performed on very simple datasets with few points in the training sets. I think that experiments on other datasets (e.g., with 1000s of points) can strengthen the results.\n5.\tIn Proposition 1, eta(t) is said to be a constant but it seems to depend on the loss which changes with time. What is the L in the denominator of the learning rate equation? Is it the loss?\n6.\tIn Figure 1, the neighborhood of a point for different geometries is not formally defined. The current figures are not clear.\n7.\tIn several experiments, it is claimed that the loss achieved values of order e^(-300). This seems like an unrealistic precision to get empirically. Is there a mistake here?\n8.\tThe presentation of the normalization methods in the equations in page 2 is not very clear. Specifically, why these equations result in a form of normalization. Can the updates be presented in a concise equation where the normalization is showed explicitly?\n9.\tI think that the authors should provide more context to the pruning results in Section 6. Specifically, say why the insights on EWN in previous sections can be useful for pruning applications.\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1518/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1518/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets", "authorids": ["~Depen_Morwani1", "~Harish_Guruprasad_Ramaswamy1"], "authors": ["Depen Morwani", "Harish Guruprasad Ramaswamy"], "keywords": ["Deep Learning Theory", "Weight Normalization", "Inductive Bias", "Gradient Descent"], "abstract": "We analyze the inductive bias of gradient descent for weight normalized smooth homogeneous neural nets, when trained on exponential or cross-entropy loss. Our analysis focuses on exponential weight normalization (EWN), which encourages weight updates along the radial direction. This paper shows that the gradient flow path with EWN is equivalent to gradient flow on standard networks with an adaptive learning rate, and hence causes the weights to be updated in a way that prefers asymptotic relative sparsity. These results can be extended to hold for gradient descent via an appropriate adaptive learning rate. The asymptotic convergence rate of the loss in this setting is given by $\\Theta(\\frac{1}{t(\\log t)^2})$, and is independent of the depth of the network. We contrast these results with the inductive bias of standard weight normalization (SWN) and unnormalized architectures, and demonstrate their implications on synthetic data sets.Experimental results on simple data sets and architectures support our claim on sparse EWN solutions, even with SGD. This demonstrates its potential applications in learning prunable neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "morwani|inductive_bias_of_gradient_descent_for_exponentially_weight_normalized_smooth_homogeneous_neural_nets", "pdf": "/pdf/1aba0dadfc3ada324a5cd12ee1586066d3c98935.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1sKfR9Gf6", "_bibtex": "@misc{\nmorwani2021inductive,\ntitle={Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets},\nauthor={Depen Morwani and Harish Guruprasad Ramaswamy},\nyear={2021},\nurl={https://openreview.net/forum?id=vCEhC7nOb6}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "vCEhC7nOb6", "replyto": "vCEhC7nOb6", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1518/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538116779, "tmdate": 1606915783460, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1518/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1518/-/Official_Review"}}}, {"id": "JzjZhbWIeUl", "original": null, "number": 8, "cdate": 1605189696479, "ddate": null, "tcdate": 1605189696479, "tmdate": 1605189696479, "tddate": null, "forum": "vCEhC7nOb6", "replyto": "2qaMFOrrKuf", "invitation": "ICLR.cc/2021/Conference/Paper1518/-/Official_Comment", "content": {"title": "Response to comments", "comment": "We thank the reviewer for the detailed comments. Responses to individual comments below. The numbering of equations and propositions here correspond to the original submission and not the revised version.\n1. We have added Figure 11 in Appendix N depicting the weight norms attained in case of MNIST experiment in the revised version.\n2. It is possible that EWN on more complicated datasets will also improve sparsity. The sparsity of the asymptotic solution (under assumptions A1-A5) is likely to enable the final learned network to be more robust to pruning. However, with multiple hidden layers the pruning strategy to choose is not particularly clear. That is the reason why in the MNIST experiment here we have used a single hidden layer network.\nIt should be emphasised that we are providing the MNIST experiment as a proof of concept that EWN results in sparsity on real-world datasets and could be beneficial for pruning. However, for deeper nets, even with EWN, we believe better pruning strategies would need to be designed, rather than pruning all the layers on the basis of difference in initial and final norm.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1518/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1518/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets", "authorids": ["~Depen_Morwani1", "~Harish_Guruprasad_Ramaswamy1"], "authors": ["Depen Morwani", "Harish Guruprasad Ramaswamy"], "keywords": ["Deep Learning Theory", "Weight Normalization", "Inductive Bias", "Gradient Descent"], "abstract": "We analyze the inductive bias of gradient descent for weight normalized smooth homogeneous neural nets, when trained on exponential or cross-entropy loss. Our analysis focuses on exponential weight normalization (EWN), which encourages weight updates along the radial direction. This paper shows that the gradient flow path with EWN is equivalent to gradient flow on standard networks with an adaptive learning rate, and hence causes the weights to be updated in a way that prefers asymptotic relative sparsity. These results can be extended to hold for gradient descent via an appropriate adaptive learning rate. The asymptotic convergence rate of the loss in this setting is given by $\\Theta(\\frac{1}{t(\\log t)^2})$, and is independent of the depth of the network. We contrast these results with the inductive bias of standard weight normalization (SWN) and unnormalized architectures, and demonstrate their implications on synthetic data sets.Experimental results on simple data sets and architectures support our claim on sparse EWN solutions, even with SGD. This demonstrates its potential applications in learning prunable neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "morwani|inductive_bias_of_gradient_descent_for_exponentially_weight_normalized_smooth_homogeneous_neural_nets", "pdf": "/pdf/1aba0dadfc3ada324a5cd12ee1586066d3c98935.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1sKfR9Gf6", "_bibtex": "@misc{\nmorwani2021inductive,\ntitle={Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets},\nauthor={Depen Morwani and Harish Guruprasad Ramaswamy},\nyear={2021},\nurl={https://openreview.net/forum?id=vCEhC7nOb6}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "vCEhC7nOb6", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1518/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1518/Authors|ICLR.cc/2021/Conference/Paper1518/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858773, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1518/-/Official_Comment"}}}, {"id": "S6ySHyaJIYJ", "original": null, "number": 7, "cdate": 1605189515614, "ddate": null, "tcdate": 1605189515614, "tmdate": 1605189515614, "tddate": null, "forum": "vCEhC7nOb6", "replyto": "YNluSAMr75b", "invitation": "ICLR.cc/2021/Conference/Paper1518/-/Official_Comment", "content": {"title": "Response to comments", "comment": "We thank the reviewer for the detailed comments. Responses to individual comments below. The numbering of equations and propositions here correspond to the original submission and not the revised version.\n1. SWN was proposed by Salimans and Kingma (2016) as a substitute for Batch Normalization. They showed that under some assumptions SWN can be shown to be equivalent to Batch normalization, while being free of the disadvantages of batch normalization with small batch size. EWN was mentioned in passing in the same paper as another way to reparameterize the weights, and has not been widely used to the best of our knowledge. We have mentioned some of the papers that use SWN in the revised version of the paper.\n2. The confusion here is caused by imprecise wording in the paper. The inverse proportion statement is for an asymptotic t, over different neurons. In Theorem 2 and the statement later, we simply mean that $||\\mathbf{w}_u(t)|| * || \\nabla _{\\mathbf{w}_u} \\mathcal{L}(\\mathbf{w}(t)) ||$ does not depend on $u$. We don\u2019t mean to say anything about a dependence on t. We have slightly reworded the statement in the revised version to remove the confusion.\n3. It is true that in proposition 3, we make an artificial strong assumption for the purpose of showing a sharp instability in the convergent direction. The assumption states \u201cthe ratio of two gradient norms at two nodes stays constant forever after some point in training\u201d. It is possible to omit the strong limit behaviour assumption in Proposition 3, for a slightly less sharp instability result in the convergent direction. This is reflected in the revised version.\n4. The main reason we have very simple datasets is that it is quite difficult to check the validity of assumptions and correctness of the implications on large networks. For the simple 4 point datasets, we can achieve a zero loss using very simple networks (assumption A1) and the small number of nodes enables us to check the assumptions (See Figure 2, where every node gets a curve). It is indeed possible to check the high level implication of sparsity in the learned network, and we do that using the MNIST dataset. We have also added the distribution of the final norm values learnt in case of MNIST in the revised version to demonstrate sparsity in EWN.\n5. eta(t) being set to a constant works for all the asymptotic results. For gradient flow, any non-zero scalar learning rate (which does not fall too fast) will give the same trajectory. For gradient descent, it should be ensured that the discretisation of the trajectory does not adversely affect the dynamics. A constant learning rate is too conservative however, and even learning rates like O(1/L) , where L is the current loss value, can be shown to work (this is because the loss landscape at low loss values is smoother than at higher loss values). This essentially allows the network to take longer steps than usual when the loss value is extremely small.\n6. For EWN, the neighborhood is formally defined as follows:\n$N_\\epsilon =$ { $\\mathbf{w} = e^{\\alpha} \\frac{\\mathbf{v}}{||\\mathbf{v}||} :  [\\alpha, \\mathbf{v}]  \\in B([\\alpha_c, \\mathbf{v}_c], \\epsilon)$ } where B(c,r) is the euclidean ball of radius r centred at $c \\in \\mathbb{R}^{d+1}$. This neighborhood is around the weight vector given by $\\mathbf{w}_c = e^{\\alpha_c}  \\frac{\\mathbf{v}_c}{||\\mathbf{v}_c||}$.\nWe have added this definition to the figure in the revised version of the paper as well.\n7. No, we really mean $e^{-300}$. We need these absurdly low values to exactly verify the asymptotic inductive bias. We achieve this using techniques from Lyu and Li (2020). Informally, the log loss at the current step is measured relative to the log loss at the previous step, this avoids numerical underflow.\n8. We are not sure we fully understand this comment, do inform us if this does not answer your question. The equations in Page 2 before Theorem 1 are a result of chain rule for gradients, and the reparameterization of weight vector, as a product of a scalar and a unit vector, $\\gamma \\frac{\\mathbf{v}}{|| \\mathbf{v} ||}$ in case of SWN and $e^\\alpha \\frac{\\mathbf{v}}{|| \\mathbf{v} ||}$ in case of EWN.\n9. We have added a motivating line at the start of section 6 in the revised version.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1518/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1518/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets", "authorids": ["~Depen_Morwani1", "~Harish_Guruprasad_Ramaswamy1"], "authors": ["Depen Morwani", "Harish Guruprasad Ramaswamy"], "keywords": ["Deep Learning Theory", "Weight Normalization", "Inductive Bias", "Gradient Descent"], "abstract": "We analyze the inductive bias of gradient descent for weight normalized smooth homogeneous neural nets, when trained on exponential or cross-entropy loss. Our analysis focuses on exponential weight normalization (EWN), which encourages weight updates along the radial direction. This paper shows that the gradient flow path with EWN is equivalent to gradient flow on standard networks with an adaptive learning rate, and hence causes the weights to be updated in a way that prefers asymptotic relative sparsity. These results can be extended to hold for gradient descent via an appropriate adaptive learning rate. The asymptotic convergence rate of the loss in this setting is given by $\\Theta(\\frac{1}{t(\\log t)^2})$, and is independent of the depth of the network. We contrast these results with the inductive bias of standard weight normalization (SWN) and unnormalized architectures, and demonstrate their implications on synthetic data sets.Experimental results on simple data sets and architectures support our claim on sparse EWN solutions, even with SGD. This demonstrates its potential applications in learning prunable neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "morwani|inductive_bias_of_gradient_descent_for_exponentially_weight_normalized_smooth_homogeneous_neural_nets", "pdf": "/pdf/1aba0dadfc3ada324a5cd12ee1586066d3c98935.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1sKfR9Gf6", "_bibtex": "@misc{\nmorwani2021inductive,\ntitle={Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets},\nauthor={Depen Morwani and Harish Guruprasad Ramaswamy},\nyear={2021},\nurl={https://openreview.net/forum?id=vCEhC7nOb6}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "vCEhC7nOb6", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1518/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1518/Authors|ICLR.cc/2021/Conference/Paper1518/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858773, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1518/-/Official_Comment"}}}, {"id": "ChhCQB6VsCv", "original": null, "number": 6, "cdate": 1605188605372, "ddate": null, "tcdate": 1605188605372, "tmdate": 1605188712828, "tddate": null, "forum": "vCEhC7nOb6", "replyto": "9mqqM34fbP", "invitation": "ICLR.cc/2021/Conference/Paper1518/-/Official_Comment", "content": {"title": "Strength of assumptions", "comment": "We thank the reviewer for the detailed comments. Responses to individual comments below. The numbering of equations and propositions here correspond to the original submission and not the revised version.\n1. We agree that the assumptions made are much stronger than in Lyu & Li (2020). However, an earlier paper by Nacson et al. (2019a) have assumptions that are close to the assumptions (A3) and (A4).\nMoreover, the assumptions (A3) and (A4) can be replaced by the assumptions that the gradient converges in direction (B3) and there exists at least one node $u$ in the network that satisfies $||\\widetilde{\\mathbf{w}}_u|| > 0$ and $||\\widetilde{\\mathbf{g}}_u|| > 0$ (B4). In fact, in our proofs, A3 and A4 are used to show these two statements, and influence the proof only through these.\nThe new assumption (B3) regarding gradient convergence has been used in previous papers(Gunasekar et al. 2018b) studying inductive bias as well. The new assumption (B4) is very mild as it needs to be satisfied by a single neuron out of the entire network.\n2. It is true that in proposition 3, we make an artificial strong assumption for the purpose of showing a sharp instability in the convergent direction. The assumption states \u201cthe ratio of two gradient norms at two nodes stays constant forever after some point in training\u201d. It is possible to omit the strong limit behaviour assumption in Proposition 3, for a slightly less sharp instability result in the convergent direction. This is reflected in the revised version.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1518/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1518/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets", "authorids": ["~Depen_Morwani1", "~Harish_Guruprasad_Ramaswamy1"], "authors": ["Depen Morwani", "Harish Guruprasad Ramaswamy"], "keywords": ["Deep Learning Theory", "Weight Normalization", "Inductive Bias", "Gradient Descent"], "abstract": "We analyze the inductive bias of gradient descent for weight normalized smooth homogeneous neural nets, when trained on exponential or cross-entropy loss. Our analysis focuses on exponential weight normalization (EWN), which encourages weight updates along the radial direction. This paper shows that the gradient flow path with EWN is equivalent to gradient flow on standard networks with an adaptive learning rate, and hence causes the weights to be updated in a way that prefers asymptotic relative sparsity. These results can be extended to hold for gradient descent via an appropriate adaptive learning rate. The asymptotic convergence rate of the loss in this setting is given by $\\Theta(\\frac{1}{t(\\log t)^2})$, and is independent of the depth of the network. We contrast these results with the inductive bias of standard weight normalization (SWN) and unnormalized architectures, and demonstrate their implications on synthetic data sets.Experimental results on simple data sets and architectures support our claim on sparse EWN solutions, even with SGD. This demonstrates its potential applications in learning prunable neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "morwani|inductive_bias_of_gradient_descent_for_exponentially_weight_normalized_smooth_homogeneous_neural_nets", "pdf": "/pdf/1aba0dadfc3ada324a5cd12ee1586066d3c98935.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1sKfR9Gf6", "_bibtex": "@misc{\nmorwani2021inductive,\ntitle={Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets},\nauthor={Depen Morwani and Harish Guruprasad Ramaswamy},\nyear={2021},\nurl={https://openreview.net/forum?id=vCEhC7nOb6}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "vCEhC7nOb6", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1518/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1518/Authors|ICLR.cc/2021/Conference/Paper1518/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858773, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1518/-/Official_Comment"}}}, {"id": "KdTJ2iuL3Xz", "original": null, "number": 5, "cdate": 1605188141908, "ddate": null, "tcdate": 1605188141908, "tmdate": 1605188141908, "tddate": null, "forum": "vCEhC7nOb6", "replyto": "vCEhC7nOb6", "invitation": "ICLR.cc/2021/Conference/Paper1518/-/Official_Comment", "content": {"title": "Summary of changes in the rebuttal revision (version dated Nov 12)", "comment": "1. We have modified proposition 3, removing the extra assumptions, resulting in a slightly less sharp instability result.\n2. We have added a figure showing the norm of the weights for SWN, EWN and NWN for the MNIST training procedure. It is in Appendix N, Figure 11.\n3. A few more references that use SWN in practice have been added to page 3.\n4. We have changed the caption of Figure 1 giving a more detailed explanation of the figure.\n5. The statement after Theorem 2, has been modified to remove a potential source of confusion. \n6. In Section 6, we add a sentence motivating the usage of EWN, for generating a network that is more robust to pruning.\n7. We have clarified a few definitions in Proposition 2.\n8. We have also fixed a few typos and grammatical errors. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1518/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1518/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets", "authorids": ["~Depen_Morwani1", "~Harish_Guruprasad_Ramaswamy1"], "authors": ["Depen Morwani", "Harish Guruprasad Ramaswamy"], "keywords": ["Deep Learning Theory", "Weight Normalization", "Inductive Bias", "Gradient Descent"], "abstract": "We analyze the inductive bias of gradient descent for weight normalized smooth homogeneous neural nets, when trained on exponential or cross-entropy loss. Our analysis focuses on exponential weight normalization (EWN), which encourages weight updates along the radial direction. This paper shows that the gradient flow path with EWN is equivalent to gradient flow on standard networks with an adaptive learning rate, and hence causes the weights to be updated in a way that prefers asymptotic relative sparsity. These results can be extended to hold for gradient descent via an appropriate adaptive learning rate. The asymptotic convergence rate of the loss in this setting is given by $\\Theta(\\frac{1}{t(\\log t)^2})$, and is independent of the depth of the network. We contrast these results with the inductive bias of standard weight normalization (SWN) and unnormalized architectures, and demonstrate their implications on synthetic data sets.Experimental results on simple data sets and architectures support our claim on sparse EWN solutions, even with SGD. This demonstrates its potential applications in learning prunable neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "morwani|inductive_bias_of_gradient_descent_for_exponentially_weight_normalized_smooth_homogeneous_neural_nets", "pdf": "/pdf/1aba0dadfc3ada324a5cd12ee1586066d3c98935.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1sKfR9Gf6", "_bibtex": "@misc{\nmorwani2021inductive,\ntitle={Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets},\nauthor={Depen Morwani and Harish Guruprasad Ramaswamy},\nyear={2021},\nurl={https://openreview.net/forum?id=vCEhC7nOb6}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "vCEhC7nOb6", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1518/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1518/Authors|ICLR.cc/2021/Conference/Paper1518/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858773, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1518/-/Official_Comment"}}}, {"id": "xshPt-CPbJ", "original": null, "number": 4, "cdate": 1605187671767, "ddate": null, "tcdate": 1605187671767, "tmdate": 1605187671767, "tddate": null, "forum": "vCEhC7nOb6", "replyto": "NPck5HgmCRX", "invitation": "ICLR.cc/2021/Conference/Paper1518/-/Official_Comment", "content": {"title": "Neuron dependent adaptive learning rate and response to other comments", "comment": "We thank the reviewer for the detailed comments. Responses to individual comments below. The numbering of equations and propositions here correspond to the original submission and not the revised version.\n1. In proposition 3, we make an artificial strong assumption for the purpose of showing a sharp instability in the convergent direction. The assumption states \u201cthe weight vector and its gradient align exactly in opposite directions after some t>t2\u201d. Because of this assumption, equation 10 gets simplified to $\\frac{d\\gamma_u(t)}{dt} = \\frac{d ||w_u(t)||}{dt} = \\eta(t) || \\nabla _{\\mathbf{w}_u} \\mathcal{L}(\\mathbf{w}(t))||$. \nIt is possible to omit the strong limit behaviour assumption in Proposition 3, for a slightly less sharp instability result in the convergent direction. This is reflected in the revised version. The modified proof for SWN here directly appeals to Theorem 2.\n2. Consider the unit norm vectors along $\\mathbf w_u(t)$ and $- \\nabla_{\\mathbf w_u} \\mathcal L(\\mathbf w(t))$. Proposition 2 states these two sequences converge to the same value. Hence, for any $\\delta$ there exists a $t_1$ such that for all $t>t_1$ the two unit norm vectors are $\\delta$ close in euclidean norm. As these are unit vectors the cosine between these two vectors is greater than $\\sqrt{1-\\frac{\\delta^2}{2}}$. \n3. For SWN, the norm change can be more easily obtained through equation 10. (As $\\gamma_u(t) = ||\\mathbf{w}_u(t)||$). There is no need to appeal to Theorem 1 directly. \n4. Maybe we didn\u2019t make this absolutely clear in the paper. Even though for a given neuron $u$ the trajectory equation for EWN is simply a scaled version of the Unnormalized network(GF). However, different neurons have different scalings, leading to very different trajectories for the network as a whole. Simulating the EWN trajectory using unnormalized GF would require an adaptive neuron dependent learning rate. For example, the trajectory for EWN and unnormalized GF are completely different in the  simple-traj experiment (Figure 4). This is because the two parameters are associated with different neurons. Hence, it is correct to say EWN and unnormalized GF lead to different solutions asymptotically.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1518/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1518/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets", "authorids": ["~Depen_Morwani1", "~Harish_Guruprasad_Ramaswamy1"], "authors": ["Depen Morwani", "Harish Guruprasad Ramaswamy"], "keywords": ["Deep Learning Theory", "Weight Normalization", "Inductive Bias", "Gradient Descent"], "abstract": "We analyze the inductive bias of gradient descent for weight normalized smooth homogeneous neural nets, when trained on exponential or cross-entropy loss. Our analysis focuses on exponential weight normalization (EWN), which encourages weight updates along the radial direction. This paper shows that the gradient flow path with EWN is equivalent to gradient flow on standard networks with an adaptive learning rate, and hence causes the weights to be updated in a way that prefers asymptotic relative sparsity. These results can be extended to hold for gradient descent via an appropriate adaptive learning rate. The asymptotic convergence rate of the loss in this setting is given by $\\Theta(\\frac{1}{t(\\log t)^2})$, and is independent of the depth of the network. We contrast these results with the inductive bias of standard weight normalization (SWN) and unnormalized architectures, and demonstrate their implications on synthetic data sets.Experimental results on simple data sets and architectures support our claim on sparse EWN solutions, even with SGD. This demonstrates its potential applications in learning prunable neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "morwani|inductive_bias_of_gradient_descent_for_exponentially_weight_normalized_smooth_homogeneous_neural_nets", "pdf": "/pdf/1aba0dadfc3ada324a5cd12ee1586066d3c98935.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1sKfR9Gf6", "_bibtex": "@misc{\nmorwani2021inductive,\ntitle={Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets},\nauthor={Depen Morwani and Harish Guruprasad Ramaswamy},\nyear={2021},\nurl={https://openreview.net/forum?id=vCEhC7nOb6}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "vCEhC7nOb6", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1518/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1518/Authors|ICLR.cc/2021/Conference/Paper1518/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1518/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858773, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1518/-/Official_Comment"}}}, {"id": "2qaMFOrrKuf", "original": null, "number": 1, "cdate": 1603705662974, "ddate": null, "tcdate": 1603705662974, "tmdate": 1605024423633, "tddate": null, "forum": "vCEhC7nOb6", "replyto": "vCEhC7nOb6", "invitation": "ICLR.cc/2021/Conference/Paper1518/-/Official_Review", "content": {"title": "An interesting work on the implicit bias of gradient descent with exponential weight normalization", "review": "This paper analyzes the implicit bias of gradient descent with both the standard weight normalization (SWN), which basically uses the gradients with respect to the radial part and spherical part of the weights, and the exponential weight normalization (EWN), which further parameterizes the radial part using an exponential function. Under a few convergence assumptions, it is shown that for SWN, given a node in the network, the norm of the input weight vector is proportional to the norm of the gradient with respect to this weight vector, while for EWN, the norm of the weight vector is inversely proportional to the norm of gradient. It is further shown that such an implicit bias implies that EWN induces sparse limiting directions, and empirical support is provided. \n\nI think SWN and EWN proposed by this paper are interesting, and it is surprising that they introduce opposite implicit biases. It is also interesting that EWN can find sparse or \"simple\" solutions.\n\nI have the following questions regarding experiments:\n1. Can Proposition 3 be verified on MNIST? For example, can you compare the distribution of norms of weight vectors for EWN, SWN, and unnormalized gradient descent?\n2. Can EWN also improve generalization or sparsity on more complicated datasets, such as CIFAR?", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1518/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1518/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets", "authorids": ["~Depen_Morwani1", "~Harish_Guruprasad_Ramaswamy1"], "authors": ["Depen Morwani", "Harish Guruprasad Ramaswamy"], "keywords": ["Deep Learning Theory", "Weight Normalization", "Inductive Bias", "Gradient Descent"], "abstract": "We analyze the inductive bias of gradient descent for weight normalized smooth homogeneous neural nets, when trained on exponential or cross-entropy loss. Our analysis focuses on exponential weight normalization (EWN), which encourages weight updates along the radial direction. This paper shows that the gradient flow path with EWN is equivalent to gradient flow on standard networks with an adaptive learning rate, and hence causes the weights to be updated in a way that prefers asymptotic relative sparsity. These results can be extended to hold for gradient descent via an appropriate adaptive learning rate. The asymptotic convergence rate of the loss in this setting is given by $\\Theta(\\frac{1}{t(\\log t)^2})$, and is independent of the depth of the network. We contrast these results with the inductive bias of standard weight normalization (SWN) and unnormalized architectures, and demonstrate their implications on synthetic data sets.Experimental results on simple data sets and architectures support our claim on sparse EWN solutions, even with SGD. This demonstrates its potential applications in learning prunable neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "morwani|inductive_bias_of_gradient_descent_for_exponentially_weight_normalized_smooth_homogeneous_neural_nets", "pdf": "/pdf/1aba0dadfc3ada324a5cd12ee1586066d3c98935.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1sKfR9Gf6", "_bibtex": "@misc{\nmorwani2021inductive,\ntitle={Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets},\nauthor={Depen Morwani and Harish Guruprasad Ramaswamy},\nyear={2021},\nurl={https://openreview.net/forum?id=vCEhC7nOb6}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "vCEhC7nOb6", "replyto": "vCEhC7nOb6", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1518/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538116779, "tmdate": 1606915783460, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1518/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1518/-/Official_Review"}}}, {"id": "NPck5HgmCRX", "original": null, "number": 4, "cdate": 1604182647169, "ddate": null, "tcdate": 1604182647169, "tmdate": 1605024423443, "tddate": null, "forum": "vCEhC7nOb6", "replyto": "vCEhC7nOb6", "invitation": "ICLR.cc/2021/Conference/Paper1518/-/Official_Review", "content": {"title": "Technical issues", "review": "The paper studies the gradient flow dynamics over smooth homogeneous models with two types of weight normalized parameterization - standard weight normalization (SWN) and exponentiated weight normalization (EWN). Thm 1 shows the induced dynamics in the unnormalized parameter space resulting from gradient flow on respective weight normalized parameterization. This result is a good starting point that highlights the different dynamics arising from the two parameterizations.\n\nHowever, in the remainder of the paper, there are several technical issues/confusions, outlined below (p.s., please number the equations):\n\n1. In the proof of Proposition 3 and also Thm 2 (see e.g.,  last eq. in page 23 and corresponding equations for GD in Appendix E.1.2, and similarly, last eqn in page 20), the following equality is used which is not true in general. Please clarify if I missed something: ||w(t)||=||w(t_2)||+int_{k=t_2}^t ||dw(t)|| -- triangle inequality would show that the RHS is an upper bound but I do not see how we can get exact equality. \n\n2. In the proof of Thm 3 (page 20), why does Proposition 2 imply that w_u and its negative gradient are aligned in opposite directions? Specifically, why should there be a t_2 such that for all t>t_2, cos(-\\nabla_{w_u} L,w_u)<=\\epsilon?\n\n3. In Appendix D.2 (page 22) while bounding ||w_u(t)|| for SWN, along with the above two concerns, I am also not sure how the two terms in ||dw(t)|| from Thm 1 lead to the simplified bounds on ||w_u(t)|| in the first non-thm equation on page 22. \n\n4. Finally, although not a technical mistake, I believe that the discussion comparing between EWN and unnormalized GF (which I will simply call GF) is conceptually confusing. As the authors themselves note, EWN and GF both follow the *same trajectory*. EWN simply has a scaling factor of ||w(t)||^2 which affects the \u201cspeed\u201d along the trajectory but the path itself if the same -- both have dw(t) = -s(t) nabla_w L(w(t)) for different scalar speeds s(t) and it corresponds to the same path in the space of w but with different time warping. Thus, if one solves the differential equations indefinitely both EWN and GF will trace the exact same path albeit at different times and will eventually lead to the same separator. But the plots and the discussion about Fig 5 for example suggest that EWN and GF leads to different asymptotic solutions, which is not correct.\n\nThus, when comparing EWN and GF, the message could be that EWN when discretized could lead to faster convergence - this is somewhat justified experimentally (from Fig 5) but not theoretically as to truly compare one needs to show analysis for the discretized algorithm. Also experimentally to provide correct comparison of the speed, in Fig 5, the number of iterations of the two methods (EWN and GF) should be matched which is not true in the current plots. On the other hand, it is simply wrong to phrase the message as \u201cEWN and GF lead to different solutions asymptotically\u201d. \n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper1518/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1518/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets", "authorids": ["~Depen_Morwani1", "~Harish_Guruprasad_Ramaswamy1"], "authors": ["Depen Morwani", "Harish Guruprasad Ramaswamy"], "keywords": ["Deep Learning Theory", "Weight Normalization", "Inductive Bias", "Gradient Descent"], "abstract": "We analyze the inductive bias of gradient descent for weight normalized smooth homogeneous neural nets, when trained on exponential or cross-entropy loss. Our analysis focuses on exponential weight normalization (EWN), which encourages weight updates along the radial direction. This paper shows that the gradient flow path with EWN is equivalent to gradient flow on standard networks with an adaptive learning rate, and hence causes the weights to be updated in a way that prefers asymptotic relative sparsity. These results can be extended to hold for gradient descent via an appropriate adaptive learning rate. The asymptotic convergence rate of the loss in this setting is given by $\\Theta(\\frac{1}{t(\\log t)^2})$, and is independent of the depth of the network. We contrast these results with the inductive bias of standard weight normalization (SWN) and unnormalized architectures, and demonstrate their implications on synthetic data sets.Experimental results on simple data sets and architectures support our claim on sparse EWN solutions, even with SGD. This demonstrates its potential applications in learning prunable neural networks.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "morwani|inductive_bias_of_gradient_descent_for_exponentially_weight_normalized_smooth_homogeneous_neural_nets", "pdf": "/pdf/1aba0dadfc3ada324a5cd12ee1586066d3c98935.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=1sKfR9Gf6", "_bibtex": "@misc{\nmorwani2021inductive,\ntitle={Inductive Bias of Gradient Descent for Exponentially Weight Normalized Smooth Homogeneous Neural Nets},\nauthor={Depen Morwani and Harish Guruprasad Ramaswamy},\nyear={2021},\nurl={https://openreview.net/forum?id=vCEhC7nOb6}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "vCEhC7nOb6", "replyto": "vCEhC7nOb6", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1518/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538116779, "tmdate": 1606915783460, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1518/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1518/-/Official_Review"}}}], "count": 14}