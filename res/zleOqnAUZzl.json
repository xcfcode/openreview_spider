{"notes": [{"id": "zleOqnAUZzl", "original": "DOkZylos8d5", "number": 2358, "cdate": 1601308259920, "ddate": null, "tcdate": 1601308259920, "tmdate": 1614985757283, "tddate": null, "forum": "zleOqnAUZzl", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 30, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "9Tpd15lBXLP", "original": null, "number": 1, "cdate": 1610040377419, "ddate": null, "tcdate": 1610040377419, "tmdate": 1610473969891, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "zleOqnAUZzl", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "**Problem Significance**  This paper introduces an interesting taxonomy of OODs and proposed an integrated approach to detect different types of OODs. The AC agrees on the importance of a fine-grained characterization of outliers given the large OOD uncertainty space. \n\n**Technical contribution** The key idea of the paper is to combine the predictions from multiple existing OOD detection methods. While the AC recognizes the effort made by the authors to address the review comments, reviewers have several major standing concerns regarding limited contributions, insufficient analysis, and lack of clarity. The AC agrees with reviewers that the paper is not ready yet for ICLR publication, and can be further strengthened by:\n\n- (R1) reporting the computational cost for the integrated approach. The inference time for approaches such as Mahalanobis is typically a few times more expensive than the MSP baseline. The cumulative time for calculating all four scores may be non-negligible. Authors are encouraged to analyze the performance tradeoff in a future revision. \n- (R2 & R3) discussing the effect of hyper-parameters tuning, which be overly complicated in practice as it involves combinations of multiple methods that each have multiple parameters to tune. \n- (R3) comparing with more recent development on OOD detection and move the new results to the main paper. The AC also thinks it's worth discussing the connection and comparison to methods on quantifying uncertainty via Bayesian probabilistic approaches.\n- (R2 & R4) more rigorous analysis of the benefits of the proposed integrated approach, both empirically and theoretically. Based on Table 7, the performance of using Mahalanobis alone is almost competitive as the proposed approach (except for the CIFAR10-CIFAR100 pair). This may deem further careful examination to understand what value other components are adding, and in what circumstance. \n- (R2, R3 & R4) More discussion on the implication of the taxonomy and algorithm in the high-dimensional space would be valuable. The 2D toy dataset might be too simple to reflect the decision boundary as well as uncertainty space learned by NNs. Moreover, it's important to justify further how aleatoric and epistemic uncertainty manifests in the current experiments using NNs. For example, epistemic uncertainty can arise due to the use of limited samples or due to the model uncertainty associated with the model regularization. \n\nRecent work by Hsu et al. [2] also attempt to define a taxonomy of OOD inputs (based on semantic shift and domain shift), which can be relevant for the authors. \n\n**Recommendation** Three knowledgeable reviewers have indicated rejection. The AC discounted R4's rating due to the less familiarity in this area and lack of participation in the post-rebuttal discussion. \n\n[1] Richard Harang, Ethan M. Rudd. Towards Principled Uncertainty Estimation for Deep Neural Networks\n[2] Hsu et al. Generalized ODIN: Detecting Out-of-distribution Image without Learning from Out-of-distribution Data\n"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"forum": "zleOqnAUZzl", "replyto": "zleOqnAUZzl", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040377403, "tmdate": 1610473969873, "id": "ICLR.cc/2021/Conference/Paper2358/-/Decision"}}}, {"id": "cPhM2rIxXx", "original": null, "number": 1, "cdate": 1603412400202, "ddate": null, "tcdate": 1603412400202, "tmdate": 1606937716502, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "zleOqnAUZzl", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Review", "content": {"title": "Good paper but need improvement", "review": "This paper introduces a taxonomy of OODs and proposed an integrated approach to detect different types of OODs. Their taxonomy classifies OOD on the nature of their uncertainty and they show that no single state-of-the-art approach detects all these OOD types. Motivated by this observation, they combine multiple existing OOD detection methods to detect various types of OODs. \n\nIn general, this paper is easy to understand. But I have the following concerns: \n\n1. Lack of discussions about some important related work. They only compare their method to ODIN and Mahalanobis methods. But there are some other OOD detection methods which also achieve state-of-the-art results, such as [1][2][3]. Could the authors compare their method to these methods? \n\n2. In their taxonomy, they consider examples that are very close to in-distribution as OOD. I am wondering whether we should treat those examples as OOD since they are too close to the in-distribution. I think previous works like ODIN and Mahalanobis all assume that OOD inputs are far away from the in-distribution. In the experimental setup, they consider STL10 as an OOD dataset for CIFAR10. But STL10 contains CIFAR10 alike images. It is unconvincing that we should treat those images as OOD. And I think the classifier trained on CIFAR10 may have correct predictions on some of those images. Could the authors explain why we should treat those images as OOD? \n\n3. I am wondering whether the analysis for the simple two-dimensional dataset could be applied to high-dimensional datasets. In the high-dimensional space, their conclusion about which method detects which type of OOD may not hold. Could the authors explain it? \n\n4. In Appendix A.2.1, they mention that the best results from the twelve combinations of the aforementioned sub-categories (one from each of the four attributions) are reported. Could the authors explain how they select the best results? Do they use the test OOD data to select the best results? \n\n5. Could the author describe how they integrate the existing state-of-the-art detection methods in detail? It is hard for me to understand what they exactly do in their proposed method.  \n\n--------- After Reading the Updated Paper ----------\n\nThanks for the update. After reading the revised paper, I still have some major concerns:\n\n1. The current experiments performed are not enough to demonstrate the effectiveness of the proposed method. The old experiment results (Table 6, 7, 8) are not convincing since the authors train a binary classifier as an OOD detector using a subset of the test OOD data, which is not realizable in practice. We should assume that the test OOD data are unknown during learning the OOD detector. The new experimental results where they train the binary classifier using adversarial examples generated on in-distribution data (follow the Mahalanobis method) in Table 1 are limited. For example, on CIFAR10, they only report results for ResNet50 and WideResNet, but I also want to know the results for DenseNet (Mahalanobis method [4] performs very well on CIFAR10/SVHN using DenseNet under the same setting).\n\n2. Some experimental details about their method are missing. The authors mention that they train 12 binary classifiers and then select the best one on the validation dataset. But they don't provide the details about the validation dataset, which is critical for their results. Based on their previous response, it seems they use a subset of test OOD data to select the best classifier, which is not allowed I think. Based on the current description of experimental settings, it is hard for me to evaluate the reported results.\n\n3. The proposed approach needs a lot of hyper-parameters (4 attributes, 12 combinations, the weights of the binary classifier, etc) and it is unclear how to tune these hyper-parameters and how they would affect the results. The current ablation study is limited I think.\n\n4. This paper doesn't have rigorous analysis for why integrating different attributions would improve OOD detection. I think this is an empirical paper but the experiments provided are not sufficient to demonstrate the effectiveness of the proposed method.\n\nTo clarify, I didn't agree to raise the score previously. What I said was that the previous paper needed significant revision and I could not recommend acceptance. I still have some major concerns after reading the revised paper. Thus, I keep the same rating and think the paper is not ready for publication. I hope the authors could keep improving their paper. \n\n \n[1] Hendrycks, Dan, Mantas Mazeika, and Thomas Dietterich. \"Deep anomaly detection with outlier exposure.\" arXiv preprint arXiv:1812.04606 (2018).\n\n[2] Liu, Weitang, et al. \"Energy-based Out-of-distribution Detection.\" arXiv preprint arXiv:2010.03759 (2020).\n\n[3] Lakshminarayanan, Balaji, Alexander Pritzel, and Charles Blundell. \"Simple and scalable predictive uncertainty estimation using deep ensembles.\" Advances in neural information processing systems. 2017.\n\n[4] Lee, Kimin, et al. \"A simple unified framework for detecting out-of-distribution samples and adversarial attacks.\" Advances in Neural Information Processing Systems. 2018.", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "zleOqnAUZzl", "replyto": "zleOqnAUZzl", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538098243, "tmdate": 1606915766134, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2358/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Review"}}}, {"id": "uS20jXEK3ox", "original": null, "number": 29, "cdate": 1606281125761, "ddate": null, "tcdate": 1606281125761, "tmdate": 1606281125761, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "zleOqnAUZzl", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "AnnonReivwer1", "comment": "We thank you again for the constructive feedback. We believe your comments raised have been addressed in our response and the updated draft. We'd like to kindly follow up and clarify any remainder confusion. Your feedback has been very important and valuable for us to improve the work!"}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "shp5RiKLfWA", "original": null, "number": 28, "cdate": 1606280732345, "ddate": null, "tcdate": 1606280732345, "tmdate": 1606280732345, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "zleOqnAUZzl", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "AnnonReviewer4", "comment": "\nWe thank the reviewer for the input and we have submitted an improved revised version. Our discussions with other reviewers are also encouraging and we have been able to clarify some major concerns. We hope the reviewer will find the new version to be much stronger and an improved submission."}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "IEs6TrqM8HW", "original": null, "number": 27, "cdate": 1606280663052, "ddate": null, "tcdate": 1606280663052, "tmdate": 1606280663052, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "zleOqnAUZzl", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "AnnonReviewer3", "comment": "We thank the reviewer for the encouragement. We have submitted a revised draft that addresses the main concerns from the review.\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "gs0OdJYScQL", "original": null, "number": 26, "cdate": 1606280540886, "ddate": null, "tcdate": 1606280540886, "tmdate": 1606280540886, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "zleOqnAUZzl", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "AnonReviewer2", "comment": "We thank AnonReviewer2 for agreeing to raise the score. We have also submitted a revised draft that addresses the main concerns. We appreciate the reviewer for the suggestions and a very rewarding discussion.\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "19aq6t2odFB", "original": null, "number": 25, "cdate": 1606279858411, "ddate": null, "tcdate": 1606279858411, "tmdate": 1606279946985, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "zleOqnAUZzl", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "Addressing major comments of the reviewers in the rebuttal submission", "comment": "We greatly thank all the reviewers for their feedback and constructive comments on this work. We really appreciate the time and energy spent by the reviewers on providing their invaluable reviews. \n\nWe have tried to address all the major comments by the reviewers in the rebuttal revision -\n\n1) Comparison with the latest (2019, 2020) papers on OOD detection - We have modified our introduction to include the recent papers that were suggested by the reviewers. We have added the \"Discussion and Future Work\" section for discussion on comparison with these papers. The experimental results for comparison with these papers are reported in Appendix section A.2.1.\n\n2) We have elaborated the process of OOD detection by the proposed OOD detector in the experimental section (section 4) of the main paper.\n\n3) Modification of the experiments for training our OOD detector on adversarial in-distribution samples (and not the test OODs) - The results reported in the experimental section are generated by the proposed OOD detector trained on in-distribution samples and adversarial samples generated from the in-distribution samples as OODs. The previously reported results (performed in supervised settings) have been moved to Appendix (A.2.2).\n\n4) The results generated by the Mahalanobis method in the experimental section are generated from their best settings with feature ensemble and input-preprocessing. \n\n5) We have also reported the metric AUPR in the main experimental section of the paper."}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "16uTwLwSJgm", "original": null, "number": 24, "cdate": 1606278476167, "ddate": null, "tcdate": 1606278476167, "tmdate": 1606278476167, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "qurbtGXSRj-", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "Addressing comments of the AnnonReviewer4", "comment": "We thank the reviewer for the invaluable comments and feedback on this paper. We address the reviewer's comments as follows. \n\n1. The demonstration of the limitations of current OOD detection algorithms is solely empirical (based on a toy data set). Theoretic motivations (if possible) would be a great addition. \n\nWe show the limitations of OOD detection algorithms on the toy dataset for illustration purposes. However, these limitations are applicable to real datasets as well. For example, in Fig 5, we show the examples of the OOD sample caused by epistemic and aleatoric uncertainties on the CIFAR dataset. As mentioned in subsection \"Key observations\", these samples are missed by the Mahalanobis approach but detected by our approach. This justifies that the definition of ODDs and limitations of the OOD detection algorithms are not limited to toy datasets only.\n\n2. Similarly, a sound theoretical derivation for the proposed integrated approach is lacking. \n\nThe proposed integrated approach is motivated by two key observations: 1) the OOD samples can be of various types (Fig. 1) and 2) one approach cannot detect all types of OODs. (A.2.3 ABLATION STUDY). Thus, an integrated approach is required to detect all types of OODs. Please note the subsection \"Key observations\" justifies our claims. We agree that a theoretical derivation will further strengthen the claims and we will consider that in the follow-up works. \n\n3. Further toy data sets beyond the two half-moon data set would be helpful to better understand the implications of all algorithms.\n\nWe consider two toy datasets: half moons (Fig 2) and the mixture of Gaussian (Fig 1) to show the variants of OODs. As shown in Fig 2 and 3, after considering a deep neural network to extract features, the non-linear organization of the data points in the original half-moons tends to become linear. This is due to the non-linear projection caused by the neural transformations. We expect to see the same behavior for other 2D or 3D toy datasets as long as a sufficiently deep neural network is considered to extract the features."}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "IPXB1gm5o5Z", "original": null, "number": 22, "cdate": 1606114246753, "ddate": null, "tcdate": 1606114246753, "tmdate": 1606157661322, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "LlbaGqTmlN", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "Looking forward to seeing the revisions ", "comment": "Thank you.  I am looking forward to seeing the revision of this paper. Hopefully, the paper is publication-ready by then. \n\nI am expecting some of the reviewers' suggestions to be applied to increase my score. Please maintain a balance between the space used for tables, figures, and the core of the paper. Don't forget that \"reviewers are not required\" to read appendices, those extra pages are for extra details and lengthy figures/tables. Keep in mind that the research contribution, comparison with similar techniques, and discussions of findings are more valuable than final reported results. "}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "LlbaGqTmlN", "original": null, "number": 21, "cdate": 1606075181623, "ddate": null, "tcdate": 1606075181623, "tmdate": 1606075181623, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "I3YZsU7tnj", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "Addressing comments of AnnoReviewer3", "comment": "We appreciate the invaluable comments provided by the reviewer and provide the following response to address the fundamental issues - \n\n1.      We agree with the reviewer\u2019s observation. We consider the toy dataset to illustrate various types of OODs and motivate the need for a taxonomy to capture these variations. We present results only for the benchmark datasets. Note that in Fig. 5, we show the various types of OODs on the features from DNNs for the CIFAR 10. As the reviewer suggested, the distribution is not perfect and the samples belonging to various types of uncertainties are present in the plot. Thus, our definition of taxonomy is not limited to toy dataset only. We will add more such plots based on the DNN feature on the benchmark datasets in the final version.\n\n2.      Yes, some of these uncertainties can be considered as modeling errors (e.g., generalization error). However, we categorize the uncertainties (and errors) specifically for OODs and not for general prediction errors. For example, type 3, type 4, and type 5 OODs can all be categorized as the generalization error as they can be mispredicted even though they are close to the data distribution. Thus, a fine-grained categorization, specific to OODs, is needed to analyze various types of OODs.\n\n3.      Noise input:  We  (without noise) could outperform (97.07% TNR 99.32 AUROC 96.27 DTACC) the Mahalanobis paper's best-reported result with noise (96.42% TNR 99.14 AUROC 95.75 DTACC) on CIFAR-10 in-distribution data and ResNet34 model.  Our result is reported in table 2 of the paper and Mahalanobis result is reported in Table 1 of the paper.\n\n4.      Implementation details: Good suggestion. We kept them in the appendix due to the space limitations but we will add those details to the main draft.\n\n5.      Discussion on comparison with recent work: We agree with the reviewer that in addition to the experimental comparison, a discussion is also required for comparison with the latest work. We plan to revise the current draft for including this discussion."}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "I3YZsU7tnj", "original": null, "number": 20, "cdate": 1606066593627, "ddate": null, "tcdate": 1606066593627, "tmdate": 1606066593627, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "IDg86c7wWde", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "Additional results provided by authors", "comment": "Thank you for providing additional results in comparison with more recent papers; i. e. geometric self-supervised learning [1], contrastive learning [2], \"energy-based\" [3], and \"outlier exposure\" [4]. The goal is to compare and discuss other techniques in your paper to improve it not just throughing a list of numbers. The current manuscript lacks implementation details and discussion of results. "}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "IDg86c7wWde", "original": null, "number": 19, "cdate": 1606030416740, "ddate": null, "tcdate": 1606030416740, "tmdate": 1606030416740, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "X9Z8Oi8sbeN", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "Quick reply to authors, ", "comment": "Thank you for your attention and well-explained response. \n\n\n----- I still have fundamental issues with the way authors present their OOD types and detection criteria and I encourage authors to stop relying on toy datasets (take the time to read [1] for more on the curse of dimensionality).\n\n- First, you can not separate \"the distribution of all training data\" from \"the combination of class distributions\". Using a secondary kernel or other technique to learn training set distribution is not efficient and accurate. The kernel density estimation techniques that you are referring are not as good as (not even close) DNNs when it comes to complex high-dimensional data like images. So, the appropriate way to calculate or visualize the training set distribution is your trained DNN itself. which will tell \"the distribution of all training data\" is in fact the same as \"the combination of class distributions\". Note that the model does not learn a perfect representation, which is why uncertainty estimation and OOD detection is still an open problem. \n\n- Second, having the above assumption, it seems to me that you are ended up categorizing different uncertainty types and scenarios that cause model mispredictions errors --- which is valuable ---, rather than a taxonomy of OOD types. Some of these types (e.g. Type 3) that you mentioned could be simply inlier samples which the model did not learn in the train time (i.e. generalization error), see [2] for more example benchmarks.  On the other hand, mispredictions due to samples outside (far or near) the training distribution are \"OODs to the trained model\" and is a type of distributional error. I think you are pushing to mix these two different model error types. And the outcomes in the flowchart presented in Figure 6, are not guaranteed to be OODs.\n\n----- I am not convinced about the authors' presentation of results. \nThe Mahanalobis technique presented in [7] involves a step for adding noise to the inputs, we can't subjectively disregard steps when implementing other techniques. As a reviewer, I can only compare your results with the MSP baseline. \n\n--- Other 1: Not enough implementation details are presented in the paper, Appendix is for additional info not the only place you present the prediction score. After all, a big chunk of this paper is about how you use multiple detection signals. \n\n--- Other 2: References are not up to date, no 2020 reference, and only 2 references from 2019.\n\n\n[1] Domingos, Pedro. \"A few useful things to know about machine learning.\" Communications of the ACM 55.10 (2012): 78-87.\n[2] Hendrycks, Dan, et al. \"Natural adversarial examples.\" arXiv preprint arXiv:1907.07174 (2019).\n[3] Lee, K., Lee, K., Lee, H., & Shin, J. (2018). A simple unified framework for detecting out-of-distribution samples and adversarial attacks. In Advances in Neural Information Processing Systems (pp. 7167-7177)."}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "X9Z8Oi8sbeN", "original": null, "number": 18, "cdate": 1605582407843, "ddate": null, "tcdate": 1605582407843, "tmdate": 1605582482547, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "8Xz_3Oeais", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "Comparison with more recent results", "comment": "For the comparison with the recent papers - \"geometric self-supervised learning\" [1], \"contrastive learning\" [2],   \"energy-based\" [3],  \"outlier exposure\" [4], we performed the following four experiments (1 experiment per paper).\n\n1) With  WideResNet trained on CIFAR10 and LSUN as OODs, the results reported in [1] (table 5) are TNR AUROC DTACC - 71.3 93.2 71.0. With WideResNet as the classifier for CIFAR10, we trained our OOD detector with the in-distribution CIFAR10  as in-distribution samples and adversarial samples generated by FGSM attack [5] from the test dataset of CIFAR10 as OODs. The trained OOD detector was then tested on LSUN as OODs and here are the results. TNR AUROC DTACC AUIN AUOUT- 98.84  99.63  97.72  99.25  99.69.\n\n2)  With ResNet-50 trained on CIFAR10 and SVHN as OODs, the results reported in [2] (table 3) are TNR AUROC DTACC AUPR 97.2 99.5  96.7 99.6. With ResNet-50 as the classifier for CIFAR10, we trained our OOD detector with the in-distribution CIFAR10  as in-distribution samples and adversarial samples generated by FGSM from the test dataset of CIFAR10 as OODs. The trained OOD detector was then tested on SVHN as OODs and here are the results. TNR AUROC DTACC AUIN AUOUT- 82.88  96.98  91.74  94.71  98.51\n\n3) With WideResNet trained on CIFAR10 and SVHN as OODs, the results reported in [3] are TNR AUROC AUPR - 64.41 90.96 97.64 (results from Table 1 in the paper). With WideResNet as the classifier for CIFAR10, we trained our OOD detector with the in-distribution CIFAR10 as in-distribution samples and adversarial samples generated by FGSM from the test dataset of CIFAR10 as OODs. The trained OOD detector was then tested on SVHN as OOD and here are the results. TNR AUROC DTACC AUIN AUOUT- 88.95 97.61 92.46 92.84 99.12.\n\n4) For comparison with [4], we again used WideResNet trained on CIFAR10 and SVHN as OODs. The corresponding results reported in [4] are TNR AUROC AUPR - 95.2 98.4 89.4 (results from Table 7 in the paper). These results were generating by treating 80M image as OODs for the training of OOD detector. Since this dataset is no longer available, we generated OODs from the TinyImageNet dataset (since Imagenet is OOD for CIFAR10 as well as SVHN) to train our OOD detector. The trained OOD detector was then tested on SVHN as OOD and here are the results. TNR AUROC DTACC AUIN AUOUT- 92.53 98.56 93.91 96.62 99.41\n\n[1] Hendrycks, D., Mazeika, M., Kadavath, S., & Song, D. (2019). Using self-supervised learning can improve model robustness and uncertainty. In Advances in Neural Information Processing Systems (pp. 15663-15674).\n\n[2] Winkens, J., Bunel, R., Roy, A. G., Stanforth, R., Natarajan, V., Ledsam, J. R., ... & Cemgil, T. (2020). Contrastive training for improved out-of-distribution detection. arXiv preprint arXiv:2007.05566. [8] Liu, Hao, and Pieter Abbeel. \"Hybrid discriminative-generative training via contrastive learning.\" arXiv preprint arXiv:2007.09070 (2020).\n\n[3] Liu, Weitang, et al. \"Energy-based Out-of-distribution Detection.\" Advances in Neural Information Processing Systems 33 (2020).\n\n[4] Hendrycks, Dan, Mantas Mazeika, and Thomas Dietterich. \"Deep anomaly detection with outlier exposure.\" arXiv preprint arXiv:1812.04606 (2018).\n\n[5] Goodfellow, Ian J, Shlens, Jonathon, and Szegedy, Christian. Explaining and harnessing adversarial examples. In ICLR, 2015."}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "zBBb4vQ2gpN", "original": null, "number": 17, "cdate": 1605561077429, "ddate": null, "tcdate": 1605561077429, "tmdate": 1605561077429, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "2ATb383ejfU", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "Need the details of the method and experiments", "comment": "Thanks for the results. I am willing to raise my scores, but I still have some concerns about the experimental details. \n\nI think in the current draft, the authors don't describe their approach in detail. For example, the part about how they train a binary classifier is completely missing. Also, the authors mention that they report the best empirical result on the test OOD data out of the 12 ways of combinations of four attributes. I think **we cannot select the best results using the test OOD data**. I hope the authors could describe their approach and experimental setups in detail. It would be good that they could update the current draft to include these details and also new experimental results. \n\nSince some details of the approach and the experiments are missing, and the paper needs significant revision, I cannot recommend acceptance for now. "}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "2ATb383ejfU", "original": null, "number": 16, "cdate": 1605559196566, "ddate": null, "tcdate": 1605559196566, "tmdate": 1605559196566, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "U2eexTw6S4", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "Comparison with the Mahalanobis and other papers", "comment": "We would like to bring to the notice of the reviewer that all the reported results for OOD detection in the Mahalanobis paper [1] are generated with the FGSM attack [2] (right-hand side of table 2 from the paper and its explanation in \"Comparison of robustness\" on page 7). Our last reported results were with the DeepFool and CW attacks. To make a fair comparison, we ran another experiment with the FGSM attack. Again, the in-distribution data was CIFAR10 trained on the ResNet34 model. The hyperparameters of our OOD detector were tuned only using in-distribution (CIFAR10) and adversarial samples generated by FGSM from the test dataset of CIFAR10. This trained OOD detector was then tested on SVHN as the OOD dataset and here are the results - TNR    AUROC  DTACC  AUIN   AUOUT = 90.18  97.93  92.86  94.11  99.21\n\nThe corresponding results reported in the Mahalanobis paper [1] are TNR    AUROC  DTACC - 75.8     95.5    89.1. So, our results are not worse than those reported in the Mahalanobis paper. \n\nFor the comparison with the other two papers [3] and [4], here are the results. \n\nWith WideResNet trained on CIFAR10 and SVHN as OODs, the results reported in [3] are TNR    AUROC AUPR - 64.41   90.96  97.64 (results from Table 1 in the paper). We used their pre-trained WideResNet (https://github.com/wetliu/energy_ood) on CIFAR10 and trained our OOD detector with the in-distribution CIFAR10 samples and adversarial samples generated by FGSM from the test dataset of CIFAR10.  The OOD detector was then tested on SVHN as OOD and here are the results. TNR    AUROC  DTACC  AUIN   AUOUT- 88.95  97.61  92.46  92.84  99.12.\n\nFor comparison with [4], we again used WideResNet trained on CIFAR10 and SVHN as OODs, the results reported in [4] are TNR    AUROC AUPR - 95.2    98.4       89.4 (results from Table 7 in the paper). These results were generating by treating 80M image as OODs for the training of OOD detector. Since this dataset is no longer available, we generated OODs from the TinyImageNet dataset (since Imagenet is OOD for CIFAR10 as well as SVHN) to train our OOD detector. The trained OOD detector was then tested on SVHN as OOD and here are the results. TNR    AUROC  DTACC  AUIN   AUOUT- 92.53  98.56  93.91  96.62  99.41\n                                                                                                                                                                                                                                                                                                                                             \nThese experiments were done as per the request made by the reviewer to demonstrate the effectiveness of our method trained without the OOD test data as well as comparison with other recent papers.  Since we have addressed this (major) concern and all the other minor concerns of the reviewer, we would like to request him (or her) to revise his (or her) rating.\n\n[1] Lee, Kimin, et al. \"A simple unified framework for detecting out-of-distribution samples and adversarial attacks.\" Advances in Neural Information Processing Systems. 2018. \n\n[2] Goodfellow, Ian J., Jonathon Shlens, and Christian Szegedy. \"Explaining and harnessing adversarial examples.\" arXiv preprint arXiv:1412.6572 (2014).\n\n[3] Liu, Weitang, et al. \"Energy-based Out-of-distribution Detection.\" Advances in Neural Information Processing Systems 33 (2020).\n\n[4] Hendrycks, Dan, Mantas Mazeika, and Thomas Dietterich. \"Deep anomaly detection with outlier exposure.\" arXiv preprint arXiv:1812.04606 (2018)."}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "U2eexTw6S4", "original": null, "number": 15, "cdate": 1605504762012, "ddate": null, "tcdate": 1605504762012, "tmdate": 1605504762012, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "-Na6WT_XFbR", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "Need comparison with current state-of-the-art methods", "comment": "Thanks for the experimental results. It seems the results are worse than those reported in the Mahalanobis paper [1]. Could the authors compare their method with current state-of-the-art OOD detection methods, such as Mahalanobis [1], Outlier Exposure [2], and Energy based method [3]?\n\n[1] Lee, Kimin, et al. \"A simple unified framework for detecting out-of-distribution samples and adversarial attacks.\" Advances in Neural Information Processing Systems. 2018.\n\n[2] Hendrycks, Dan, Mantas Mazeika, and Thomas Dietterich. \"Deep anomaly detection with outlier exposure.\" arXiv preprint arXiv:1812.04606 (2018).\n\n[3] Liu, Weitang, et al. \"Energy-based Out-of-distribution Detection.\" Advances in Neural Information Processing Systems 33 (2020)."}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "-Na6WT_XFbR", "original": null, "number": 14, "cdate": 1605503826659, "ddate": null, "tcdate": 1605503826659, "tmdate": 1605503826659, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "GZSJSM9JcK4", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "Addressing primary concern with experiments", "comment": "As per the reviewer's request to demonstrate that our method still works if we don't tune it on the test OOD data, we performed the following two experiments. With ResNet34 trained on CIFAR10, we generated adversarial data (1000 samples) from the test dataset of CIFAR10 for tuning our OOD detector from \n\nFirst Experiment - DeepFool [1] attack.\nSecond Experiment - CW [2] attack.\n\nThe OOD detector tuned with adversarial examples was then tested with SVHN as OOD at 95% TPR. \n\nThe results obtained from the DeepFool attack are as follows. TNR    AUROC  DTACC  AUIN   AUOUT-  73.27  94.64  87.52  87.98  97.79\n\nThe results obtained from the CW attack are as follows. TNR    AUROC  DTACC  AUIN   AUOUT-  59.29  88.08  80.51  70.62  95.22\n\nPlease note that the OOD detector never saw the tested OODs during its tuning (or training) in the above experiments.\n\n[1] Moosavi-Dezfooli, Seyed-Mohsen, Alhussein Fawzi, and Pascal Frossard. \"Deepfool: a simple and accurate method to fool deep neural networks.\" Proceedings of the IEEE conference on computer vision and pattern recognition, 2016.\n\n[2] Carlini, Nicholas and Wagner, David. Adversarial examples are not easily detected: Bypassing\nten detection methods. In ACM workshop on AISec, 2017.\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "GZSJSM9JcK4", "original": null, "number": 13, "cdate": 1605389952673, "ddate": null, "tcdate": 1605389952673, "tmdate": 1605389952673, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "HEAezjYd_HF", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "Addressing primary concern", "comment": "We can run our method where we tune the detector with adversarial examples. While most well-cited OOD methods have used the approach similar to our paper (as pointed out in our discussions above which includes the references that the reviewer shared with us), we agree there are alternative ways for tuning. We do not think this is significantly different or challenging for our approach. \n\nWould the reviewer be convinced to improve the score to accept if our results on tuning detector with adversarial examples are as strong as they are currently using a limited amount of outlier exposure?"}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "HEAezjYd_HF", "original": null, "number": 12, "cdate": 1605388381266, "ddate": null, "tcdate": 1605388381266, "tmdate": 1605388381266, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "eI3koxqXRe0", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "Primary concern", "comment": "My primary concern is that the proposed method needs to use a subset of test OOD data for tuning the detector. Although there are some existing works that use the same strategy, recently the community starts to realize that we should assume that the test OOD data are unknown and should not tune detector on a subset of them. I don't ask the authors to provide results on detecting adversarial examples but argue that the Mahalanobis method could achieve good OOD detection performance by tuning the detector on adversarial examples generated on in-distribution examples, which means it doesn't require using the test OOD data to tune its parameters. Unless the authors could demonstrate that their method still works well if they don't tune it on the test OOD data, my concern will still remain. "}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "8Xz_3Oeais", "original": null, "number": 5, "cdate": 1605371956298, "ddate": null, "tcdate": 1605371956298, "tmdate": 1605387808499, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "ZoZcbWOigTx", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "Addressing comments of AnonReviewer3 [2/2] ", "comment": "\u201cThe results from the Mahanalobis technique [7] does not match the original paper. If authors did not use a subset of ood samples for tuning, it should be reported in the paper.\u201d\n\nOur OOD detector does not perform input preprocessing (or adding noise to the input) for detection of OODs. So, to compare the results without input-preprocessing, we generated results from the Mahalanobis technique without adding any noise in the inputs.\n\nThe difference results from Table 1 of the Mahalanobis paper [7] without feature ensemble and without input-preprocessing and our reported results (Table 1- CIFAR10 with ResNet34 on SVHN for TNR, AUROC and DTACC and Table 6 - SVHN on the penultimate layer for AUPR (in) and AUPR (out)) are due to the differences in the floating-point precision of the two machines.\n                                                               TNR   AUROC  DTACC AUPR(In)  AUPR(Out)\nResults from Mahalanobis paper - 54.51   93.92    89.13   91.56   95.95\nResults from our paper -                  53.16   93.85    89.17   91.19   96.14\n\nSimilarly, the difference in the results from Table 1 of the Mahalanobis paper [4] with feature ensemble and without input-preprocessing and our reported results (Table 2 - CIFAR10 with ResNet34 on SVHN for TNR, AUROC, and DTACC and Table 6 - SVHN on all layers for AUPR (in) and AUPR (out)) are due to the differences in the floating-point precision of the two machines.\n                                                               TNR   AUROC  DTACC AUPR(In)  AUPR(Out)\nResults from Mahalanobis paper -  91.45   98.37     93.55   96.43   99.35\nResults from our paper -                   91.53   98.4       93.63   96.46   99.37\n\nThe differences in the results from Table 2 of the Mahalanobis paper and our results is because the reported results in Table 2 are obtained after input-preprocessing, whereas we do not consider any input preprocessing for generating results from the Mahalanobis technique.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "eI3koxqXRe0", "original": null, "number": 11, "cdate": 1605386761553, "ddate": null, "tcdate": 1605386761553, "tmdate": 1605386761553, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "534xoS_9qxM", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "Further clarification", "comment": "1. The difference in a DNN's performance trained on CIFAR10 on STL10 demonstrates that they are not from the same distribution but as our experiments show they are close to each other. If we filter dataset on which the model makes the correct prediction, we would expect our OOD detection accuracy to improve. The conceptual similarity (same labels) between datasets does not necessarily mean they represent the same statistical distribution. But we completely agree that OODs currently lack a formal definition despite a number of papers on this topic. Our effort in building this taxonomy is exactly motivated by this gap. We hope our paper will be a step towards a better mathematical characterization (and categorization) of OODs.\n\nAlso, we hope the inclusion of a hard test-case does not penalize our paper because we also included other traditional test-cases.\n\nFurther, we want to draw the reviewer\u2019s attention to https://www.tensorflow.org/datasets/catalog/stl10, https://cs.stanford.edu/~acoates/stl10/  where it is mentioned that \u201cSTL10 dataset is acquired from the labeled examples of Imagenet\u201d. Imagenet is used as OOD set for the CIFAR10 dataset by the state-of-the-art OOD detectors (Mahalanbonis [1], TRAINING CONFIDENCE-CALIBRATED CLASSIFIERS FOR DETECTING OUT-OF-DISTRIBUTION SAMPLES- https://arxiv.org/pdf/1711.09325.pdf,  ENHANCING THE RELIABILITY OF OUT-OF-DISTRIBUTION IMAGE DETECTION IN NEURAL NETWORKS- https://arxiv.org/pdf/1706.02690.pdf etc.).  \n\n2. Nothing in our argument about which \"OODs depend on what kind of uncertainty (epistemic or aleatoric)\" depends on the dimension of data. Our experimental evaluation is over higher-dimensional real datasets. Theoretical study of how high dimensional OODs differ from low dimensional OODs is very interesting, and we agree it would benefit from further investigation. But our identification of taxonomy and experiments with standard benchmarks represent a significant contribution in themselves. \n\n3. We also compared our results with the Mahalanobis technique on adversarial examples. We could beat the Mahalanobis technique on all the tested (FGSM, BIM and DeepFool) attacks for CIFAR10 with ResNet34 model - \n\nFGSM    TNR , AUROC, DTACC, AUPR (in), AUPR (out)\nMahala - 57.78, 92.87, 85.66, 95.87, 87.52\nOurs -    61.22, 93.39, 86.61, 96.12, 88.10\n\nDeepFool TNR , AUROC, DTACC, AUPR (in), AUPR (out)\nMahala -   32.96, 85.80, 78.46, 88.53, 81.68\nOurs -      41.19, 87.16, 79.51, 88.98, 84.07\n\nBIM         TNR , AUROC, DTACC, AUPR (in), AUPR (out)\nMahala -  60.70  93.53  86.55  94.61  92.44\nOurs -      93.23, 98.54, 94.29, 98.39, 98.74\n\nAlso, please see Section 4.2.2 in Reference 2 ( https://arxiv.org/abs/1812.04606 ) about how they use OOD data. They use filtered Tiny images, ImageNet-22K, etc. as  D_out^OE.  We agree that this outlier exposure is more interesting than using a subset of OOD dataset used in other papers but is of the same nature (not adversarial). We emphasize our notion of OOD is widely used including the references in the review, and we are not the first to use a subset of OOD for tuning our detector.\n\nWe hope the reviewer will reconsider the score since we have addressed the primary concerns in the review."}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "534xoS_9qxM", "original": null, "number": 10, "cdate": 1605381128683, "ddate": null, "tcdate": 1605381128683, "tmdate": 1605381192981, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "xn5l_Vk4eo_", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "Concerns still remain", "comment": "1. Yes. STL10 and CIFAR10 don't belong to exactly the same distribution and a model trained on CIFAR10 cannot make an equally accurate prediction on STL10. But we know the distributions of STL10 and CIFAR10 are very close. Since we only have limited training data from CIFAR10 distribution, we cannot model the exact distribution of CIFAR10 distribution. Thus, it is hard to argue that the images from STL10 are not sampled from the CIFAR10 distribution. The model trained on CIFAR10 may be able to give correct predictions on some examples in STL10. Then should we treat these examples as OOD? For example, why should we treat a \"ship\" image that belongs to CIFAR10 classes and the model could give a correct prediction as OOD? I hope the author could give a **formal definition** of OOD.\n\n2. Yes. The sources of uncertainty may remain the same in the high-dimensional space. But **the conclusion about which method detects which type of OOD may not hold**. It is hard to argue that those methods fail due to ignoring certain types of OOD in high dimensional space. \n\n3. Yes. Mahalanobis detector contains a logistic regression detector. But they successfully demonstrate that they can use adversarial examples to train it instead of using test OOD data. My point here is that we cannot use test OOD data to tune the hyper-parameters or train the model since in practice we should **assume that test OOD data are unknown**. I just want to point out that Reference [2] doesn't use test OOD data during training time. "}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "xn5l_Vk4eo_", "original": null, "number": 9, "cdate": 1605378822341, "ddate": null, "tcdate": 1605378822341, "tmdate": 1605378822341, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "eAr_ZRuSiYa", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "Addressing remaining concerns", "comment": "1. We respectfully disagree that STL10 and CIFAR10 belong to the same distribution. Would one expect a deep learning model trained on CIFAR10 to generalize and make equally accurate prediction on STL10? But leaving this test-case aside, our experiments also include the standard test-cases used in literature (we also have OOD test-cases with new classes / open world classification in the paper as the reviewer suggested).  We agree that STL10 is similar to the CIFAR10 dataset which makes it more challenging. The low performance (in terms of TNR) of our OOD detector on STL10 with CIFAR10 as in-distribution indicates this challenge.\n\n2. They appear mixed because of the projection - but our analysis is not after projection - we do projection just to draw a 2D figure for illustration - our analysis is in the high dimensional space. The sources of uncertainty due to the sample being far from in-distribution data, or far from the class-condition in-distribution data, or close to multiple classes, etc. will remain the same in large dimensions too. Aleatoric or epistemic uncertainty are concepts that are not restricted to smaller dimensions. \n\n3.  Reference [1] provided by the reviewer also trains a \"logistic regression detector\" using OODs (and not adversarial examples) similar to our paper. On Page 5 of Reference [1] ( https://papers.nips.cc/paper/2018/file/abdeb6f575ac5c6676b747bca8d09cc2-Paper.pdf ), the end of the paragraph on \"Feature ensemble\" states that \"In our experiments, following similar strategies in [22], we choose the weight of each layer \u03b1` by training a logistic regression detector using validation samples.\" Reference 22 in that paper is the LID paper from ICLR 2018. So, we are just building on a widely-used notion of OODs.  Reference [2] also does not use adversarial attacks but uses a different dataset for outlier exposure. "}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "eAr_ZRuSiYa", "original": null, "number": 8, "cdate": 1605374778008, "ddate": null, "tcdate": 1605374778008, "tmdate": 1605374887860, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "yRdh3x4jNbd", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "Concerns still remain", "comment": "1. I think it is not reasonable to treat STL10 images as OOD just because their resolution is different from CIFAR10. When we feed the images to the model, we need to first resize the images to the same resolution. I think the authors don't answer my question: why we should treat those images that are very similar to CIFAR10 images as OOD? What's their definition of OOD? Usually, people define OOD as inputs with new classes (see open-world classification and previous related work about OOD detection). \n2. I still think that in the high-dimensional space, it is hard to classify OOD inputs into those OOD types that the authors define in the two-dimensional space. In Figure 5, I only see that those projected features are mixed. It is different from what they present in Figure 1. \n3. It seems the approach needs to use the test OOD data to train the binary classifier and select the best result, which is not feasible in practice. Usually, it is hard to know what kinds of OOD data we will face. Thus, we should assume that the test OOD data are unknown. I think [1] also uses adversarial examples, which don't depend on the test OOD data, to train the binary classifier and they also show good results. In fact, several recent works start to have this assumption, see [2]. \n\n[1] Lee, Kimin, et al. \"A simple unified framework for detecting out-of-distribution samples and adversarial attacks.\" Advances in Neural Information Processing Systems. 2018.\n\n[2] Hendrycks, Dan, Mantas Mazeika, and Thomas Dietterich. \"Deep anomaly detection with outlier exposure.\" arXiv preprint arXiv:1812.04606 (2018)."}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "IugKHh4xBB5", "original": null, "number": 7, "cdate": 1605373701898, "ddate": null, "tcdate": 1605373701898, "tmdate": 1605373701898, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "UoSVYi8ptpj", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "Addressing comments of AnonReviewer1", "comment": "\u201cshow that the method also increases the detection rate of outliers inside a given database .. by reporting the classification rate of the DNN in an abstaining scheme\u201d\n\nAs per the reviewer\u2019s suggestion, we conducted new experiments to illustrate the applicability of our approach for the detection of outliers in the same dataset. We considered a ResNet34 model trained on CIFAR10 with an accuracy of 93.67% on the test dataset. We then trained our OOD detector using a set of randomly sampled 300 misclassified images and another set of randomly sampled 300 correctly classified images from the test dataset. This trained OOD detector was then able to correctly identify 326 out of the remaining 333 samples with incorrect predictions as outliers. Thus, using our OOD detector (trained with the True Positive Rate of 95%) with abstaining on outliers improved the classification accuracy to 99.91% from 93.67% on non-abstaining samples. Our results demonstrate that the proposed OOD method can identify and abstain on samples on which the model is likely to produce an incorrect prediction. \n\n\u201cHowever, the method to create the OOD samples is always the same: in-distribution samples come from a database whereas out of distribution samples are drawn from another database.\u201d\n\nAs suggested, we employ a new way to generate out-of-distribution samples by modifying in-distribution samples using adversarial attacks - fast gradient sign method (FGSM) [1], DeepFool [2], basic iterative method (BIM) [3]. We used CIFAR10 as the in-distribution dataset and a ResNet34 model. The attacked images were generated from the test dataset of CIFAR10. We obtained a True Negative Rate (i.e. the rate of detection of attacked images as OODs) of 41.19%, 61.66%,  93.23% for the attacked images generated by Deepfool, FGSM and BIM attacks, respectively at a True Positive Rate of 95%. \n\nThe context of the attacks used to generate OODs - FGSM is a single-step attack that uses the L_\\infty metric for measuring the distance between a legitimate and perturbed example. BIM was introduced to improve the performance of FGSM by running a finer iterative optimizer for multiple iterations. BIM has a much higher attacking rate than FGSM and it still causes noticeable perturbations even though fewer visual flaws occur than those crafted by FGSM. The perturbations introduced by DeepFool are unnoticeable and the attacking rate is much higher than that of FGSM and BIM.\n\n\u201cComputing all the OOD metrics can be computationally expensive, is it necessary to compute them all ? Are this combination of metric the best ? In which conditions?\u201d\n\nAs explained in the Appendix (Section A.2.1) of the paper, the signature of the OOD detector is the weighted sum of the four attributes used to distinguish OODs from the in-distribution samples. These attributes are 1) distance from the in-distribution density estimate, 2) reconstruction error from the principal component analysis, 3) prediction confidence of the classifier, and 4) conformance measure among the nearest neighbors. These attributes can be computed by different metrics. Some of these metrics are mentioned as categories under these attributes in A.2.1. Only one metric per attribute is used in the OOD detector. \n\nAs illustrated in Figure 4 of section 3 in the paper, these attributes tend to capture specific types (shown as different clusters) of OODs but not all. Our ablation studies (Tables 10, 11, and 12 of the Appendix) evaluating each attribute show the above-mentioned limitations. Thus, we proposed an integrated approach combining these attributes to detect a diverse type of OODs.  We evaluated our approach on benchmark datasets considering state-of-the-art neural network models.  The proposed approach achieved a better performance as shown in Tables 1 and 2 in the experiment section justifying the importance of the integrated approach.\n\n[1] Goodfellow, Ian J., Jonathon Shlens, and Christian Szegedy. \"Explaining and harnessing adversarial examples.\" arXiv preprint arXiv:1412.6572 (2014).\n\n[2] Moosavi-Dezfooli, Seyed-Mohsen, Alhussein Fawzi, and Pascal Frossard. \"Deepfool: a simple and accurate method to fool deep neural networks.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2016\n\n[3] Kurakin, Alexey, Goodfellow, Ian, and Bengio, Samy. Adversarial examples in the physical world. arXiv preprint arXiv:1607.02533, 2016."}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "yRdh3x4jNbd", "original": null, "number": 6, "cdate": 1605372282013, "ddate": null, "tcdate": 1605372282013, "tmdate": 1605372282013, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "cPhM2rIxXx", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "Addressing comments of AnonReviewer2", "comment": "\u201cSTL10 contains CIFAR10 alike images\u2026 Could the authors explain why we should treat STL10 as OODs for CIFAR10?\u201d\n\nSTL10 dataset is inspired byCIFAR-10 but two datasets differ in terms of the image resolution (STL10 - 96X96 and CIFAR10 - 32X32). Since STL10 is similar to the CIFAR10 dataset, it makes the OOD detection more challenging while considering STL10 as OODs for the CIFAR10. This is the reason why we selected this pair of datasets to stress test our method. \n\n\u201cI am wondering whether the analysis for the simple two-dimensional dataset could be applied to high-dimensional datasets. In the high-dimensional space, their conclusion about which method detects which type of OOD may not hold. Could the authors explain it?\u201d \n\nWe agree that it is hard to verify whether the observations in the 2D dataset apply directly to the high-dimensional datasets. However, in fig. 5, we show the projection of the high-dimensional features in 2D using t-SNE. Please note the highlighted examples where the OOD samples associated with both epistemic and aleatoric uncertainties are missed by the Mahalanobis [4] but were detected by our approach. Also, our ablation studies (in appendix Table. 10, 11, 12) show that individual approaches (ODIN, PCA, Mahalanobis, etc) are not sufficient to detect all types of OODs and an integrated approach is necessary.\n\n\u201cCould the authors explain how they select the best results? Do they use the test OOD data to select the best results? Could the author describe how they integrate the existing state-of-the-art detection methods in detail?\u201d\n\nA weighted sum of the four attributes (section A.2.1 of the appendix) forms the signature of our OOD detector. The weights of these attributes are generated in the following manner. Following the standard experimental setup [4, 6], we use a small subset of both in-distribution and OOD  data to train a binary classifier using a logistic loss. The trained classifier (or OOD detector) is then evaluated on the remaining OOD samples at the True Positive Rate of 95%. \n\nThe four attributes (forming the signature of the OOD detector) are 1) distance from the in-distribution density estimate, 2) reconstruction error from the principal component analysis (PCA), 3) prediction confidence of the classifier, and 4) conformance measure among the nearest neighbors. These attributes can be computed in different ways. In our experiments, we consider 2 ways of generating distance from the in-distribution density estimate, 1 way of generating reconstruction error from PCA, 3 ways of generating prediction confidence of the classifier, and 2 ways of generating conformance measure among the nearest neighbors, resulting in a total of 12 ways of combining these four attributes (2*1*3*2) (section A.2.1 of the appendix). Out of these 12 combinations, we report the best empirical result on the test OOD data.\n\n\u201cLack of discussion on related work. Could the authors compare their method to these methods...\u201d\n\nWe are looking into the suggested papers to compare our results with these papers. We will provide an update on this once we have the results.  \n\n[4] Lee, Kimin, et al. \"A simple unified framework for detecting out-of-distribution samples and adversarial attacks.\" Advances in Neural Information Processing Systems. 2018.\n\n[6] Lee, Kimin, et al. \"Training confidence-calibrated classifiers for detecting out-of-distribution samples.\" arXiv preprint arXiv:1711.09325 (2017).\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "ZoZcbWOigTx", "original": null, "number": 4, "cdate": 1605371809440, "ddate": null, "tcdate": 1605371809440, "tmdate": 1605371809440, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "kp-9WM2Q2Y1", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment", "content": {"title": "Addressing comments of AnonReviewer3 [1/2]", "comment": "\u201cFigure 1 suggests the tied distribution of all training data is different than the combination of class distributions.\u201d\n\nThe tied distribution shown in figure 1 is obtained using robust covariance estimation (https://scikit-learn.org/stable/modules/generated/sklearn.covariance.EllipticEnvelope.html#sklearn.covariance.EllipticEnvelope), representing the unimodal Gaussian distribution of the complete (irrespective of the class) in-distribution dataset and is only meant for illustrative purposes. This is one of the many ways to model the distribution of the complete dataset. Other potential techniques for modeling the complete dataset are kernel density estimation, multi-modal gaussian distribution, etc. \n\n\u201cI wish authors could explain the difference between Type 4 and 5 in the ood sample taxonomy.\u201d\n \nWhile both Type 4 and Type 5 are OODs due to high class conditional epistemic uncertainty, they vary in their principal component analysis of the class distribution (as explained in the last paragraph of section 2 in the paper). Type 4 are OODs due to high deviation along the principal axis of the in-distribution class 2. Type 5 are OODs due to relatively lower deviation along the non-principal axis (and hence, statistically invariant) of the in-distribution class 1.  The difference in principle axis and non-principal axis will lead to a disparate effect on the reconstruction error. \n\n\u201cThe relation between five types of OOD with three criteria for OOD categorization is not clear.\u201d\n\nCriteria 1 - Is the OOD associated with higher epistemic or aleatoric uncertainty, i.e., is the input away from in-distribution data or can it be confused between multiple classes?  OOD Types - Type 1 and Type 2 are OODs due to epistemic uncertainty as they are far from the in-distribution data. Type 3 are OODs due to aleatoric uncertainty between the in-distribution classes 0 and 1.\n\nCriteria 2 - Is the epistemic uncertainty of an OOD sample unconditional or is it conditioned on the class predicted by the DNN model? OOD Types - Type 1 are OODs due to the epistemic uncertainty of the tied in-distribution. In other words, they are far from the tied in-distribution (represented by the red oval in the figure). Type 2 are OODs due to class conditional epistemic uncertainty. In other words, if we consider class-wise instead of a single tied in-distribution then Type 2 are far from all the class distributions. But if we consider the tied distribution, then Type 2 OODs lie within the in-distribution. So, Type 2 are OODs due to class conditional epistemic uncertainty.\n\nCriteria 3 - Is the OOD an outlier due to unusually high deviation in the principal components of the data or due to small deviation in the non-principal (and hence, statistically invariant) components? OOD Types - Type 4 are OODs due to high deviation along the principal axis of the in-distribution class 2. Type 5 are OODs due to relatively lower deviation along the non-principal axis of the in-distribution class 1. \n\n\u201cWhat was the reason to choose a subset of cifar100 as ood test set but not the whole dataset?\u201d\n \nThe subset of CIFAR100 considered in the experiments consists of the following four classes - sea, road, bee, and butterfly. These classes are visually similar to the ship, automobile, and bird classes in the CIFAR10 dataset respectively (as stated in section 4 under CIFAR10 dataset). Therefore, it would make the task of OOD detection with this subset of CIFAR100 for CIFAR10 as in-distribution more challenging. This is the reason for choosing a subset of CIFAR100 to stress test our method on CIFAR10 as in-distribution.\n\n\"Authors emphasize reporting detection TNR in the manuscript while FNR is missing from the measurements. I suggest authors either report both or use threshold agnostic metrics like area under precision recall curve (AUPR) or area under receiver operating curve (AUROC) for reporting as in the Table.\"\n\nAUROC has been reported in Tables 1 and 2 of the experimental section 4  of the paper (comparison with ODIN and Mahalanobis) and Table 3 in the Appendix (comparison with Baseline). AUPR has been reported for all the experiments in Tables 4, 5, 6, 7, 8, and 9 of the Appendix.\n\n\u201cI can't find an explanation and/or discussion on the final detection score and it's hyperparameters\u201d\n\nSection A.2.1 of the Appendix, \u201cAttributes forming the signature of the OOD detector used in the experiments\u201d, explains how the final detection scores are reported.\n\n\u201cComparison with more recent techniques including Outlier Exposure, \u2026 and contrastive learning are missing in this paper.\u201d\n\nWe are looking into the suggested papers to compare our results with these papers. We will provide an update on this once we have the results.  \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "zleOqnAUZzl", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2358/Authors|ICLR.cc/2021/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923849364, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Comment"}}}, {"id": "qurbtGXSRj-", "original": null, "number": 2, "cdate": 1603863421085, "ddate": null, "tcdate": 1603863421085, "tmdate": 1605110713135, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "zleOqnAUZzl", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Review", "content": {"title": "Interesting Work on the Detection of OODs", "review": "##########################################################################\n\nSummary:\n\nThis paper introduces a novel taxonomy for OOD outliers. The authors analyze current OOD detection approaches and uncover their limitations. They propose to fuse several existing approaches into a combined one and extensively evaluate it on various data sets (CIFAR,10, SVNH, MNIST, STL10, ImageNet, etc.). The proposed integrated OOD detection approach clearly shows superior performance.\n\n##########################################################################\n\nReasons: \n\nOverall, I vote for accepting. The authors make several key contributions: The introduce a novel OOD taxonomy, analyse current OOD detection approaches on a toy data set, propose an integrated OOD detection approach, which shows a superior performance in their extensive evaluation.\n\n##########################################################################\n\nPros:\n\n* Introduction of a sound and helpful OOD taxonomy\n* Limitation analysis of state-of-the-art OOD detection algorithms\n* Proposal of a new integrated approach to detect different kind of OOD inputs that unifies the advanatges of underlying algorithms.\n* Extensive evaluation of new approach shows clearly superior performance. On a variety of data sets (CIFAR,10, SVNH, MNIST, STL10, ImageNet, etc.) the proposed approach outperforms the baselines on all evaluation criteria (TNR, AUROC, DTACC, AUPR IN, AUPR OUT) for various classifier neural network architectures (LeNet, ResNet, DenseNet).\n\n##########################################################################\n\nCons:\n\n* The demonstration of the limitations of current OOD detection algorithms is solely empirical (based on a toy data set). Theoretic motivations (if possible) would be a great addition.\n* Similarly, a sound theoretical derivation for the proposed integrated approach is lacking. \n* Further toy data sets beyond the two half moon data set would be helpful to better understand the implications of all algorithms.\n\n##########################################################################\n\nQuestions during rebuttal period: \n\nPlease address and clarify the cons above ", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "zleOqnAUZzl", "replyto": "zleOqnAUZzl", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538098243, "tmdate": 1606915766134, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2358/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Review"}}}, {"id": "kp-9WM2Q2Y1", "original": null, "number": 3, "cdate": 1604031658611, "ddate": null, "tcdate": 1604031658611, "tmdate": 1605024230253, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "zleOqnAUZzl", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Review", "content": {"title": "Interesting taxonomy of OOD samples but the current paper needs improvement", "review": "-- Paper Summary: \nThe paper presents the idea of fusion of attributes from existing sota ood detection methods to achieve higher detection performance.\n\n-- Review :\n\n- The three criteria presented in section two are questions rather than criteria. It is better to be re-worded into criteria. \n\n- Figure 1 suggests the \"tied distribution of all training data\" is different than the combination of \"class distributions\". I wish authors  could explain the difference between Type 4 and 5 in the ood sample taxonomy.\n\n- The relation between five types of OOD with three criteria for OOD categorization is not clear. \n\n- The visualization in all figures could be improved:\n    - figure 1: too many colors. better to use different shape or numbers directly in the figure.\n    - figure 5: not necessary to include, hard to see and comprehend.\n    - the total number of figures can be reduced by eliminating some and combining others. \n\n- What was the reason to choose a subset of cifar100 as ood test set but not the whole dataset? \n\n- Authors emphasize reporting detection TNR in the manuscript while FNR is missing from the measurements. I suggest authors either report both or use threshold agnostic metrics like area under precision recall curve (AUPR) or area under receiver operating curve (AUROC) for reporting as in the Table. \n\n- I can't find an explanation and/or discussion on the final detection score and it's hyperparametere. \n\n- The results from the Mahanalobis technique [7] does not match the original paper. If authors did not use a subset of ood samples for tuning, it should be reported in the paper.\n\n-- Strengths: \n- interesting taxonomy of ood samples and the following conclusion for integrated detection score. \n\n\n-- Weaknesses: \n- limited on contribution\n- no discussion on final detection score and its hyperparameters.\n- comparison with more recent techniques including Outlier Exposure [1], Self-supervised reject classifier [2], Geometric self-superivised learning [3,4], and contrastive learning [5,6] are missing in this paper. \n\n\n[1] Hendrycks, D., Mazeika, M., & Dietterich, T. (2018, September). Deep Anomaly Detection with Outlier Exposure. ICLR 2019\n\n[2] Mohseni, Sina, et al. \"Self-Supervised Learning for Generalizable Out-of-Distribution Detection.\" AAAI. 2020. \n\n[3] Hendrycks, D., Mazeika, M., Kadavath, S., & Song, D. (2019). Using self-supervised learning can improve model robustness and uncertainty. In Advances in Neural Information Processing Systems (pp. 15663-15674). \n\n[4] Golan, Izhak, and Ran El-Yaniv. \"Deep anomaly detection using geometric transformations.\" Advances in Neural Information Processing Systems. 2018. \n\n[5] Tack, J., Mo, S., Jeong, J., & Shin, J. (2020). Csi: Novelty detection via contrastive learning on distributionally shifted instances. arXiv preprint arXiv:2007.08176. \n\n[6] Winkens, J., Bunel, R., Roy, A. G., Stanforth, R., Natarajan, V., Ledsam, J. R., ... & Cemgil, T. (2020). Contrastive training for improved out-of-distribution detection. arXiv preprint arXiv:2007.05566. [8] Liu, Hao, and Pieter Abbeel. \"Hybrid discriminative-generative training via contrastive learning.\" arXiv preprint arXiv:2007.09070 (2020).\n\n[7] Lee, K., Lee, K., Lee, H., & Shin, J. (2018). A simple unified framework for detecting out-of-distribution samples and adversarial attacks. In Advances in Neural Information Processing Systems (pp. 7167-7177).\n", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "zleOqnAUZzl", "replyto": "zleOqnAUZzl", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538098243, "tmdate": 1606915766134, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2358/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Review"}}}, {"id": "UoSVYi8ptpj", "original": null, "number": 4, "cdate": 1604262790453, "ddate": null, "tcdate": 1604262790453, "tmdate": 1605024230187, "tddate": null, "forum": "zleOqnAUZzl", "replyto": "zleOqnAUZzl", "invitation": "ICLR.cc/2021/Conference/Paper2358/-/Official_Review", "content": {"title": "A combination of methods for OOD detection", "review": "##########################################################################\n\nSummary:\nThe authors explore the different kinds of outliers and show that the methods previously proposed detect different kinds of OOD and not a single one can detect them all. The authors propose an interesting study of the different kind of outlier on synthetic data which  illustrates well the different characteristics of the outlier types. The authors then propose to combine different methods to increase the OOD detection rate. Experiments are conducted on 3 images classification datasets using different deep neural networks. For each dataset, samples from other databases are introduced as outliers and must be detected. The combination method yield better detection rates than baseline methods in almost all configurations. \n\n\n##########################################################################\n\n Reasons for score: \n\nThe main idea of the paper is simple : combine different OOD detection metrics to increase the detection rate on different types of outliers. The proposed method indeed increases the OOD detection rate for almost all the experimental settings tested by the authors. However, the method to create the OOD samples is always the same: in-distribution samples come from a database whereas out of distribution samples are drawn from another database. It would be interesting to show that the method also increases the detection rate of outliers inside a given database. This could be done by reporting the classification rate of the DNN in an abstaining scheme : if the OOD metric is greater than a threshold, the sample is not classified (rejected). If the OOD detection method is useful, the classification rate of the DNN can be freely increased by increasing the threshold and rejecting more and more samples. \n\nThe author do not justify their choice of the combination method. Computing all the OOD metrics can be computationaly expensive, is it necessary to compute them all ? Are this combination of metric the best ? In which conditions ?\n\nThe combination method should be described in the body of the paper, not in appendix.\n\nGuo 2017 appears twice in the bibliography.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2358/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2358/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting OODs", "authorids": ["ramneetk@seas.upenn.edu", "~Susmit_Jha1", "~Anirban_Roy3"], "authors": ["Ramneet Kaur", "Susmit Jha", "Anirban Roy"], "keywords": ["OOD", "out of distribution", "trust", "model confidence", "DNN", "deep learning"], "abstract": "Deep neural networks (DNNs) are known to produce incorrect predictions with very high confidence on out-of-distribution (OOD) inputs. This limitation is one of the key challenges in the adoption of deep learning models in high-assurance systems such as autonomous driving, air traffic management, and medical diagnosis. This challenge has received significant attention recently, and several techniques have been developed to detect inputs where the model's prediction cannot be trusted. These techniques use different statistical, geometric, or topological signatures. This paper presents a taxonomy of OOD outlier inputs based on their source and nature of uncertainty. We demonstrate how different existing detection approaches fail to detect certain types of outliers. We utilize these insights to develop a novel integrated detection approach that uses multiple attributes corresponding to different types of outliers. Our results include experiments on CIFAR10, SVHN and MNIST as in-distribution data and Imagenet, LSUN, SVHN (for CIFAR10), CIFAR10 (for SVHN), KMNIST, and F-MNIST as OOD data across different DNN architectures such as ResNet34, WideResNet, DenseNet, and LeNet5.", "one-sentence_summary": "We study the diversity of out of distribution (OOD) inputs and develop a new OOD detection approach that outperforms existing state-of-the-art methods.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "kaur|are_all_outliers_alike_on_understanding_the_diversity_of_outliers_for_detecting_oods", "pdf": "/pdf/c8ccdbdc0f5815237772396974912d03924165e9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=LEVicIIZVb", "_bibtex": "@misc{\nkaur2021are,\ntitle={Are all outliers alike?  On Understanding the Diversity of Outliers for Detecting {\\{}OOD{\\}}s},\nauthor={Ramneet Kaur and Susmit Jha and Anirban Roy},\nyear={2021},\nurl={https://openreview.net/forum?id=zleOqnAUZzl}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "zleOqnAUZzl", "replyto": "zleOqnAUZzl", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2358/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538098243, "tmdate": 1606915766134, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2358/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2358/-/Official_Review"}}}], "count": 31}