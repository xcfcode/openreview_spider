{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396342551, "tcdate": 1486396342551, "number": 1, "id": "SJkaofUOe", "invitation": "ICLR.cc/2017/conference/-/paper77/acceptance", "forum": "ry54RWtxx", "replyto": "ry54RWtxx", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "There is a general consensus that, though the idea is interesting, the work is not mature enough for a conference publication (e.g., the problem is too toy, not clear that really solves any, even artificial problem, better than existing techniques)."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Learning a Static Analyzer: A Case Study on a Toy Language", "abstract": "Static analyzers are meta-programs that analyze programs to detect\n  potential errors or collect information. For example, they are used\n  as security tools to detect potential buffer overflows. Also, they\n  are used by compilers to verify that a program is well-formed and\n  collect information to generate better code. In this paper, we\n  address the following question: can a static analyzer be learned\n  from data? More specifically, can we use deep learning to learn a\n  static analyzer without the need for complicated feature\n  engineering? We show that long short-term memory networks are able\n  to learn a basic static analyzer for a simple toy language. However,\n  pre-existing approaches based on feature engineering, hidden Markov\n  models, or basic recurrent neural networks fail on such a simple\n  problem. Finally, we show how to make such a tool usable by\n  employing a language model to help the programmer detect where the\n  reported errors are located.", "pdf": "/pdf/fc4810b863abf6bbd0cfb15e0d0e72d7f99505f2.pdf", "paperhash": "zaheer|learning_a_static_analyzer_a_case_study_on_a_toy_language", "keywords": [], "conflicts": ["harvard.edu", "cmu.edu", "oracle.com", "umass.edu"], "authors": ["Manzil Zaheer", "Jean-Baptiste Tristan", "Michael L. Wick", "Guy L. Steele Jr."], "authorids": ["manzil.zaheer@cmu.edu", "jean.baptiste.tristan@oracle.com", "michael.wick@oracle.com", "guy.steele@oracle.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396343062, "id": "ICLR.cc/2017/conference/-/paper77/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "ry54RWtxx", "replyto": "ry54RWtxx", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396343062}}}, {"tddate": null, "tmdate": 1482147629809, "tcdate": 1481907633674, "number": 3, "id": "BJqhp5-Eg", "invitation": "ICLR.cc/2017/conference/-/paper77/official/review", "forum": "ry54RWtxx", "replyto": "ry54RWtxx", "signatures": ["ICLR.cc/2017/conference/paper77/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper77/AnonReviewer1"], "content": {"title": "Interesting start, but I think not quite ready for publication", "rating": "4: Ok but not good enough - rejection", "review": "This paper takes a first step towards learning to statically analyze source code. It develops a simple toy programming language that includes loops and branching. The aim is to determine whether all variables in the program are defined before they are used. The paper tries a variety of off-the-shelf sequence classification models and develops a new model that makes use of a ``differentiable set'' to keep track of which variables have been defined so far. Result show that an LSTM model can achieve 98% accuracy, and the differentiable set model can achieve 99.3% accuracy with sequence-level supervision and 99.7% accuracy with strong token-level supervision. An additional result is used whereby an LSTM language model is trained over correct code, and then low probability (where a threshold to determine low is tuned by hand) tokens are highlighted as sources of possible error.\n\nOne further question is if the authors could clarify what reasoning patterns are needed to solve these problems. Does the model need to, e.g., statically determine whether an `if` condition can ever evaluate to true in order to solve these tasks? Or is it just as simple as checking whether a variable appears on a LHS before it appears on a RHS later in the textual representation of the program?\n\nStrengths:\n- Learning a static analyzer is an interesting concept, and I think there is good potential for this line of work\n- The ability to determine whether variables are defined before they are used is certainly a prerequisite for more complicated static analysis.\n- The experimental setup seems reasonable\n- The differentiable set seems like a useful (albeit simple) modelling tool\n\nWeaknesses:\n- The setup is very toy, and it's not clear to me that this makes much progress towards the challenges that would arise if one were trying to learn a static analyzer \n- The models are mostly very simple. The one novelty on the modelling front (the differentiable set) provides a small win on this task, but it's not clear if it is a useful general construct or not.\n\nOverall:\nI think it's an interesting start, and I'm eager to see how this line of work progresses. In my opinion, it's a bit too early to accept this work to ICLR, but I'd be excited about seeing what happens as the authors try to push the system to learn to analyze more properties of code, and as they push towards scenarios where the learned static analyzer would be useful, perhaps leveraging strengths of machine learning that are not available to standard programming languages analyses.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Learning a Static Analyzer: A Case Study on a Toy Language", "abstract": "Static analyzers are meta-programs that analyze programs to detect\n  potential errors or collect information. For example, they are used\n  as security tools to detect potential buffer overflows. Also, they\n  are used by compilers to verify that a program is well-formed and\n  collect information to generate better code. In this paper, we\n  address the following question: can a static analyzer be learned\n  from data? More specifically, can we use deep learning to learn a\n  static analyzer without the need for complicated feature\n  engineering? We show that long short-term memory networks are able\n  to learn a basic static analyzer for a simple toy language. However,\n  pre-existing approaches based on feature engineering, hidden Markov\n  models, or basic recurrent neural networks fail on such a simple\n  problem. Finally, we show how to make such a tool usable by\n  employing a language model to help the programmer detect where the\n  reported errors are located.", "pdf": "/pdf/fc4810b863abf6bbd0cfb15e0d0e72d7f99505f2.pdf", "paperhash": "zaheer|learning_a_static_analyzer_a_case_study_on_a_toy_language", "keywords": [], "conflicts": ["harvard.edu", "cmu.edu", "oracle.com", "umass.edu"], "authors": ["Manzil Zaheer", "Jean-Baptiste Tristan", "Michael L. Wick", "Guy L. Steele Jr."], "authorids": ["manzil.zaheer@cmu.edu", "jean.baptiste.tristan@oracle.com", "michael.wick@oracle.com", "guy.steele@oracle.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512705396, "id": "ICLR.cc/2017/conference/-/paper77/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper77/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper77/AnonReviewer2", "ICLR.cc/2017/conference/paper77/AnonReviewer3", "ICLR.cc/2017/conference/paper77/AnonReviewer1"], "reply": {"forum": "ry54RWtxx", "replyto": "ry54RWtxx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper77/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper77/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512705396}}}, {"tddate": null, "tmdate": 1481739218754, "tcdate": 1481739218748, "number": 2, "id": "ByjRiby4g", "invitation": "ICLR.cc/2017/conference/-/paper77/official/review", "forum": "ry54RWtxx", "replyto": "ry54RWtxx", "signatures": ["ICLR.cc/2017/conference/paper77/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper77/AnonReviewer3"], "content": {"title": "Too toy: doesn't effectively prove a point", "rating": "3: Clear rejection", "review": "The authors are trying to understand whether static analysis can be learned. As I hinted in my question, I think that all of the interesting complexity of static analysis has been removed in the toy language --- extraordinarily simple logic using a set can solve the problem posed, and an LSTM (unsurprisingly) can learn the extraordinarily simple logic (when given a differentiable set object). This extreme simplicity gives me no confidence that a more realistic static analysis problem can be solved.\n\nLSTMs (and deep learning) have had remarkable successes in solving messy real-world language problems. It's certainly possible that LSTMs could solve static analysis -- but being technically timid is not the right way to go about it.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Learning a Static Analyzer: A Case Study on a Toy Language", "abstract": "Static analyzers are meta-programs that analyze programs to detect\n  potential errors or collect information. For example, they are used\n  as security tools to detect potential buffer overflows. Also, they\n  are used by compilers to verify that a program is well-formed and\n  collect information to generate better code. In this paper, we\n  address the following question: can a static analyzer be learned\n  from data? More specifically, can we use deep learning to learn a\n  static analyzer without the need for complicated feature\n  engineering? We show that long short-term memory networks are able\n  to learn a basic static analyzer for a simple toy language. However,\n  pre-existing approaches based on feature engineering, hidden Markov\n  models, or basic recurrent neural networks fail on such a simple\n  problem. Finally, we show how to make such a tool usable by\n  employing a language model to help the programmer detect where the\n  reported errors are located.", "pdf": "/pdf/fc4810b863abf6bbd0cfb15e0d0e72d7f99505f2.pdf", "paperhash": "zaheer|learning_a_static_analyzer_a_case_study_on_a_toy_language", "keywords": [], "conflicts": ["harvard.edu", "cmu.edu", "oracle.com", "umass.edu"], "authors": ["Manzil Zaheer", "Jean-Baptiste Tristan", "Michael L. Wick", "Guy L. Steele Jr."], "authorids": ["manzil.zaheer@cmu.edu", "jean.baptiste.tristan@oracle.com", "michael.wick@oracle.com", "guy.steele@oracle.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512705396, "id": "ICLR.cc/2017/conference/-/paper77/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper77/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper77/AnonReviewer2", "ICLR.cc/2017/conference/paper77/AnonReviewer3", "ICLR.cc/2017/conference/paper77/AnonReviewer1"], "reply": {"forum": "ry54RWtxx", "replyto": "ry54RWtxx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper77/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper77/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512705396}}}, {"tddate": null, "tmdate": 1481718168271, "tcdate": 1481718168248, "number": 3, "id": "B1xoF30me", "invitation": "ICLR.cc/2017/conference/-/paper77/pre-review/question", "forum": "ry54RWtxx", "replyto": "ry54RWtxx", "signatures": ["ICLR.cc/2017/conference/paper77/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper77/AnonReviewer2"], "content": {"title": "No questions, just making this message go away.", "question": "The paper is very clear, I don't have any questions."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Learning a Static Analyzer: A Case Study on a Toy Language", "abstract": "Static analyzers are meta-programs that analyze programs to detect\n  potential errors or collect information. For example, they are used\n  as security tools to detect potential buffer overflows. Also, they\n  are used by compilers to verify that a program is well-formed and\n  collect information to generate better code. In this paper, we\n  address the following question: can a static analyzer be learned\n  from data? More specifically, can we use deep learning to learn a\n  static analyzer without the need for complicated feature\n  engineering? We show that long short-term memory networks are able\n  to learn a basic static analyzer for a simple toy language. However,\n  pre-existing approaches based on feature engineering, hidden Markov\n  models, or basic recurrent neural networks fail on such a simple\n  problem. Finally, we show how to make such a tool usable by\n  employing a language model to help the programmer detect where the\n  reported errors are located.", "pdf": "/pdf/fc4810b863abf6bbd0cfb15e0d0e72d7f99505f2.pdf", "paperhash": "zaheer|learning_a_static_analyzer_a_case_study_on_a_toy_language", "keywords": [], "conflicts": ["harvard.edu", "cmu.edu", "oracle.com", "umass.edu"], "authors": ["Manzil Zaheer", "Jean-Baptiste Tristan", "Michael L. Wick", "Guy L. Steele Jr."], "authorids": ["manzil.zaheer@cmu.edu", "jean.baptiste.tristan@oracle.com", "michael.wick@oracle.com", "guy.steele@oracle.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481718168787, "id": "ICLR.cc/2017/conference/-/paper77/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper77/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper77/AnonReviewer1", "ICLR.cc/2017/conference/paper77/AnonReviewer3", "ICLR.cc/2017/conference/paper77/AnonReviewer2"], "reply": {"forum": "ry54RWtxx", "replyto": "ry54RWtxx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper77/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper77/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481718168787}}}, {"tddate": null, "tmdate": 1481718060564, "tcdate": 1481718060557, "number": 1, "id": "rkHNthR7x", "invitation": "ICLR.cc/2017/conference/-/paper77/official/review", "forum": "ry54RWtxx", "replyto": "ry54RWtxx", "signatures": ["ICLR.cc/2017/conference/paper77/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper77/AnonReviewer2"], "content": {"title": "Fine idea but small-scale and lacks crucial baselines", "rating": "3: Clear rejection", "review": "The authors explore the idea of deep-learning a static analyzer. They do it with a toy programming language and a very simplified analysis problem -- just checking if all variables are initalized.\n\nWhile the idea is interesting and might be developped into a tool in the future, the toy task presented in this paper is too simple to warrant an ICLR submission. Just detecting whether a variable is initialized in a string is a toy algorihtmic task, similar to the ones solved in a number of paper in recent years by models such as the Neural Turing Machine, Stack RNNs, Neural GPU, or Differentiable Neural Computer. All these architectures perform almost perfectly on a number of algorithmic tasks, so it is highly probable that they would also solve this one. Unluckily, the authors only compare to much more basic models, such as HMMs. Since the code for many of the above-mentioned models is available online, a paper without these baselines is not ready for ICLR. Moreover, there is a risk that existing models already solve this problem very well, making the contribution unclear.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Learning a Static Analyzer: A Case Study on a Toy Language", "abstract": "Static analyzers are meta-programs that analyze programs to detect\n  potential errors or collect information. For example, they are used\n  as security tools to detect potential buffer overflows. Also, they\n  are used by compilers to verify that a program is well-formed and\n  collect information to generate better code. In this paper, we\n  address the following question: can a static analyzer be learned\n  from data? More specifically, can we use deep learning to learn a\n  static analyzer without the need for complicated feature\n  engineering? We show that long short-term memory networks are able\n  to learn a basic static analyzer for a simple toy language. However,\n  pre-existing approaches based on feature engineering, hidden Markov\n  models, or basic recurrent neural networks fail on such a simple\n  problem. Finally, we show how to make such a tool usable by\n  employing a language model to help the programmer detect where the\n  reported errors are located.", "pdf": "/pdf/fc4810b863abf6bbd0cfb15e0d0e72d7f99505f2.pdf", "paperhash": "zaheer|learning_a_static_analyzer_a_case_study_on_a_toy_language", "keywords": [], "conflicts": ["harvard.edu", "cmu.edu", "oracle.com", "umass.edu"], "authors": ["Manzil Zaheer", "Jean-Baptiste Tristan", "Michael L. Wick", "Guy L. Steele Jr."], "authorids": ["manzil.zaheer@cmu.edu", "jean.baptiste.tristan@oracle.com", "michael.wick@oracle.com", "guy.steele@oracle.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512705396, "id": "ICLR.cc/2017/conference/-/paper77/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper77/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper77/AnonReviewer2", "ICLR.cc/2017/conference/paper77/AnonReviewer3", "ICLR.cc/2017/conference/paper77/AnonReviewer1"], "reply": {"forum": "ry54RWtxx", "replyto": "ry54RWtxx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper77/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper77/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512705396}}}, {"tddate": null, "tmdate": 1481139758007, "tcdate": 1481139757969, "number": 5, "id": "rkUVIk8Xe", "invitation": "ICLR.cc/2017/conference/-/paper77/public/comment", "forum": "ry54RWtxx", "replyto": "BJJuuASXx", "signatures": ["~Jean-Baptiste_Tristan1"], "readers": ["everyone"], "writers": ["~Jean-Baptiste_Tristan1"], "content": {"title": "Re: Unclear motivation + Related work", "comment": "-- Motivation.\n\nAside from the comment that the motivation is unclear, I happen to\nagree with every point you make. As you point out, such a black box\nanalyzer would be useful if predictions were challenging. But before\nwe can tackle challenging program analysis problem, we have to tackle\nsimple ones. There have been a few papers recently that address\nproblems such as reversing a sequence or adding two integers. While we\nknow of deterministic and fast algorithms to do so, I find it very\ninteresting to understand how we can learn such algorithms and how far\nwe can go doing this. This is the spirit of the experiment we report\nin the paper. \n\n-- Related work.\n\nThanks for telling us about this work. I didn't yet know about it, but\nnote that it was published on arxiv a few days after we submitted our\npaper, so we can't be expected to have mentioned it. It seems like a\ngreat paper. At first glance it seems like unlike us, they attack a\nreal program analysis problem, and I find it very encouraging that\nthey get such good results. However, their approach is very different,\nas we're more interested in understanding the limits of black-box\nlearning for program analysis."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Learning a Static Analyzer: A Case Study on a Toy Language", "abstract": "Static analyzers are meta-programs that analyze programs to detect\n  potential errors or collect information. For example, they are used\n  as security tools to detect potential buffer overflows. Also, they\n  are used by compilers to verify that a program is well-formed and\n  collect information to generate better code. In this paper, we\n  address the following question: can a static analyzer be learned\n  from data? More specifically, can we use deep learning to learn a\n  static analyzer without the need for complicated feature\n  engineering? We show that long short-term memory networks are able\n  to learn a basic static analyzer for a simple toy language. However,\n  pre-existing approaches based on feature engineering, hidden Markov\n  models, or basic recurrent neural networks fail on such a simple\n  problem. Finally, we show how to make such a tool usable by\n  employing a language model to help the programmer detect where the\n  reported errors are located.", "pdf": "/pdf/fc4810b863abf6bbd0cfb15e0d0e72d7f99505f2.pdf", "paperhash": "zaheer|learning_a_static_analyzer_a_case_study_on_a_toy_language", "keywords": [], "conflicts": ["harvard.edu", "cmu.edu", "oracle.com", "umass.edu"], "authors": ["Manzil Zaheer", "Jean-Baptiste Tristan", "Michael L. Wick", "Guy L. Steele Jr."], "authorids": ["manzil.zaheer@cmu.edu", "jean.baptiste.tristan@oracle.com", "michael.wick@oracle.com", "guy.steele@oracle.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287738537, "id": "ICLR.cc/2017/conference/-/paper77/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ry54RWtxx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper77/reviewers", "ICLR.cc/2017/conference/paper77/areachairs"], "cdate": 1485287738537}}}, {"tddate": null, "tmdate": 1481136231151, "tcdate": 1481136231144, "number": 4, "id": "BJJuuASXx", "invitation": "ICLR.cc/2017/conference/-/paper77/public/comment", "forum": "ry54RWtxx", "replyto": "ry54RWtxx", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Unclear motivation + Related work", "comment": "-- The motivation behind the work is somewhat unclear: by now, it is very well understood how to design analyzers and what sound/optimal means. Creating a ``black box'' analyzer that can make basic predictions (that are sometimes incorrect) without being able to modify it would be useful if the predictions were challenging and need not be sound all the time (like in some of the cited papers). Note that when analyzers are not sound there are typically clear  reasons for why this is so, e.g., dealing with native methods, frameworks, dynamic evaluation, etc. They are not unsound for 'random reasons'. \n\n-- There is also related work, already pointed out: the one of Hindle and others which already addresses what is in section 4.\n\n-- Here is also recent related work on learning (the transformers of the) static analyzers from data, one that is more elaborate as it learns the transformers of real analyzers and even finds real-world issues in Facebook's Flow: https://arxiv.org/abs/1611.01752"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Learning a Static Analyzer: A Case Study on a Toy Language", "abstract": "Static analyzers are meta-programs that analyze programs to detect\n  potential errors or collect information. For example, they are used\n  as security tools to detect potential buffer overflows. Also, they\n  are used by compilers to verify that a program is well-formed and\n  collect information to generate better code. In this paper, we\n  address the following question: can a static analyzer be learned\n  from data? More specifically, can we use deep learning to learn a\n  static analyzer without the need for complicated feature\n  engineering? We show that long short-term memory networks are able\n  to learn a basic static analyzer for a simple toy language. However,\n  pre-existing approaches based on feature engineering, hidden Markov\n  models, or basic recurrent neural networks fail on such a simple\n  problem. Finally, we show how to make such a tool usable by\n  employing a language model to help the programmer detect where the\n  reported errors are located.", "pdf": "/pdf/fc4810b863abf6bbd0cfb15e0d0e72d7f99505f2.pdf", "paperhash": "zaheer|learning_a_static_analyzer_a_case_study_on_a_toy_language", "keywords": [], "conflicts": ["harvard.edu", "cmu.edu", "oracle.com", "umass.edu"], "authors": ["Manzil Zaheer", "Jean-Baptiste Tristan", "Michael L. Wick", "Guy L. Steele Jr."], "authorids": ["manzil.zaheer@cmu.edu", "jean.baptiste.tristan@oracle.com", "michael.wick@oracle.com", "guy.steele@oracle.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287738537, "id": "ICLR.cc/2017/conference/-/paper77/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ry54RWtxx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper77/reviewers", "ICLR.cc/2017/conference/paper77/areachairs"], "cdate": 1485287738537}}}, {"tddate": null, "tmdate": 1481132571477, "tcdate": 1481132571470, "number": 3, "id": "BJQXcpBml", "invitation": "ICLR.cc/2017/conference/-/paper77/public/comment", "forum": "ry54RWtxx", "replyto": "H1MHizoGx", "signatures": ["~Jean-Baptiste_Tristan1"], "readers": ["everyone"], "writers": ["~Jean-Baptiste_Tristan1"], "content": {"title": "Re: Evaluating strong generalization?", "comment": "Here's the result of a new experiment: we train on sentence of length\nup to 205 and then test on sentences of length between 206 and\n410. The results are:\n\nClassification task:\n\nAccuracy: 99.7% \nfalse positive: 0.4% \nfalse negative: 0.2% \n\n\nTransduction task:\n\nAccuracy:  99.9%\nfalse positive:  0.1%\nfalse negative:  0.1%\n\n\nHowever, our method does not generalize to previously unseen\nvariables. A key problem is that the input is token based, therefore a\npreviously unseen variable is just out-of-vocabulary. As a result the\nembedding of an unseen variable is random and interferes with the\nstate of the controller. We're not completely sure yet how to deal\nwith this problem. We might try to use a skip-gram embedding, process\nthe input at the charcater level, or modify the architecture to\ncapture some form of part-of-speech tagging. Another simple solution\nwould be to rename variables to make sure they all belong to the set\nof variables used at train time. Although practical, this solution is\nmuch less interesting from a learning perspective."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Learning a Static Analyzer: A Case Study on a Toy Language", "abstract": "Static analyzers are meta-programs that analyze programs to detect\n  potential errors or collect information. For example, they are used\n  as security tools to detect potential buffer overflows. Also, they\n  are used by compilers to verify that a program is well-formed and\n  collect information to generate better code. In this paper, we\n  address the following question: can a static analyzer be learned\n  from data? More specifically, can we use deep learning to learn a\n  static analyzer without the need for complicated feature\n  engineering? We show that long short-term memory networks are able\n  to learn a basic static analyzer for a simple toy language. However,\n  pre-existing approaches based on feature engineering, hidden Markov\n  models, or basic recurrent neural networks fail on such a simple\n  problem. Finally, we show how to make such a tool usable by\n  employing a language model to help the programmer detect where the\n  reported errors are located.", "pdf": "/pdf/fc4810b863abf6bbd0cfb15e0d0e72d7f99505f2.pdf", "paperhash": "zaheer|learning_a_static_analyzer_a_case_study_on_a_toy_language", "keywords": [], "conflicts": ["harvard.edu", "cmu.edu", "oracle.com", "umass.edu"], "authors": ["Manzil Zaheer", "Jean-Baptiste Tristan", "Michael L. Wick", "Guy L. Steele Jr."], "authorids": ["manzil.zaheer@cmu.edu", "jean.baptiste.tristan@oracle.com", "michael.wick@oracle.com", "guy.steele@oracle.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287738537, "id": "ICLR.cc/2017/conference/-/paper77/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ry54RWtxx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper77/reviewers", "ICLR.cc/2017/conference/paper77/areachairs"], "cdate": 1485287738537}}}, {"tddate": null, "tmdate": 1481050870162, "tcdate": 1481050870154, "number": 2, "id": "BkReiFEQx", "invitation": "ICLR.cc/2017/conference/-/paper77/public/comment", "forum": "ry54RWtxx", "replyto": "S1cMNnJXl", "signatures": ["~Jean-Baptiste_Tristan1"], "readers": ["everyone"], "writers": ["~Jean-Baptiste_Tristan1"], "content": {"title": "Re: Isn't using a differentiable set \"cheating\" in some sense?", "comment": "\"Given a set data structure, isn't the task of finding uninitialized\nvariables fairly easy in the proposed language? You chase through the\ncode paths and put initialized variables in the set, and check the\nused variables against the set.\"\n\nYes, it is indeed a very simple problem. The difficulty here is that\nwe are learning the program analyzer purely from examples and directly\nfrom the tokens without feature engineering. Also, the LSTM needs to\nlearn to use the set data structure. It's a toy example in the same\nvein as adding integers or reversing sequences, but it is useful to\nunderstand what can be learned effectively.\n\n\"Why is doing this with an LSTM interesting? It's just some simple\nlogic... unless the LSTM is doing something with modeling the variable\nvalues (i.e., certain if statements could be mutually exclusive).. Not\nclear why this teaches us anything about LSTMs in more complex\nsituations.\"\n\nI agree that this paper doesn't teach much about LSTMs, but I hope it\ndoes say something about program analysis. Until recently, learning a\nprogram analyzer from examples might have seemed unrealistic: this is\nunderstandable given that other learning methods failed at it and\nrequired intricate feature engineering. Now, it is good to know that\nusing LSTM and differentiable data structure, it is possible to learn\na program analyzer for this task. It doesn't mean that program\nanalysis will be \"solved\" thanks to deep learning, but at least it\nshows that it doesn't obviously fail at it."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Learning a Static Analyzer: A Case Study on a Toy Language", "abstract": "Static analyzers are meta-programs that analyze programs to detect\n  potential errors or collect information. For example, they are used\n  as security tools to detect potential buffer overflows. Also, they\n  are used by compilers to verify that a program is well-formed and\n  collect information to generate better code. In this paper, we\n  address the following question: can a static analyzer be learned\n  from data? More specifically, can we use deep learning to learn a\n  static analyzer without the need for complicated feature\n  engineering? We show that long short-term memory networks are able\n  to learn a basic static analyzer for a simple toy language. However,\n  pre-existing approaches based on feature engineering, hidden Markov\n  models, or basic recurrent neural networks fail on such a simple\n  problem. Finally, we show how to make such a tool usable by\n  employing a language model to help the programmer detect where the\n  reported errors are located.", "pdf": "/pdf/fc4810b863abf6bbd0cfb15e0d0e72d7f99505f2.pdf", "paperhash": "zaheer|learning_a_static_analyzer_a_case_study_on_a_toy_language", "keywords": [], "conflicts": ["harvard.edu", "cmu.edu", "oracle.com", "umass.edu"], "authors": ["Manzil Zaheer", "Jean-Baptiste Tristan", "Michael L. Wick", "Guy L. Steele Jr."], "authorids": ["manzil.zaheer@cmu.edu", "jean.baptiste.tristan@oracle.com", "michael.wick@oracle.com", "guy.steele@oracle.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287738537, "id": "ICLR.cc/2017/conference/-/paper77/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ry54RWtxx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper77/reviewers", "ICLR.cc/2017/conference/paper77/areachairs"], "cdate": 1485287738537}}}, {"tddate": null, "tmdate": 1480733713924, "tcdate": 1480733713911, "number": 2, "id": "S1cMNnJXl", "invitation": "ICLR.cc/2017/conference/-/paper77/pre-review/question", "forum": "ry54RWtxx", "replyto": "ry54RWtxx", "signatures": ["ICLR.cc/2017/conference/paper77/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper77/AnonReviewer3"], "content": {"title": "Isn't using a differentiable set \"cheating\" in some sense?", "question": "Given a set data structure, isn't the task of finding uninitialized variables fairly easy in the proposed language? You chase through the code paths and put initialized variables in the set, and check the used variables against the set.\n\nWhy is doing this with an LSTM interesting? It's just some simple logic... unless the LSTM is doing something with modeling the variable values (i.e., certain if statements could be mutually exclusive).. Not clear why this teaches us anything about LSTMs in more complex situations."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Learning a Static Analyzer: A Case Study on a Toy Language", "abstract": "Static analyzers are meta-programs that analyze programs to detect\n  potential errors or collect information. For example, they are used\n  as security tools to detect potential buffer overflows. Also, they\n  are used by compilers to verify that a program is well-formed and\n  collect information to generate better code. In this paper, we\n  address the following question: can a static analyzer be learned\n  from data? More specifically, can we use deep learning to learn a\n  static analyzer without the need for complicated feature\n  engineering? We show that long short-term memory networks are able\n  to learn a basic static analyzer for a simple toy language. However,\n  pre-existing approaches based on feature engineering, hidden Markov\n  models, or basic recurrent neural networks fail on such a simple\n  problem. Finally, we show how to make such a tool usable by\n  employing a language model to help the programmer detect where the\n  reported errors are located.", "pdf": "/pdf/fc4810b863abf6bbd0cfb15e0d0e72d7f99505f2.pdf", "paperhash": "zaheer|learning_a_static_analyzer_a_case_study_on_a_toy_language", "keywords": [], "conflicts": ["harvard.edu", "cmu.edu", "oracle.com", "umass.edu"], "authors": ["Manzil Zaheer", "Jean-Baptiste Tristan", "Michael L. Wick", "Guy L. Steele Jr."], "authorids": ["manzil.zaheer@cmu.edu", "jean.baptiste.tristan@oracle.com", "michael.wick@oracle.com", "guy.steele@oracle.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481718168787, "id": "ICLR.cc/2017/conference/-/paper77/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper77/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper77/AnonReviewer1", "ICLR.cc/2017/conference/paper77/AnonReviewer3", "ICLR.cc/2017/conference/paper77/AnonReviewer2"], "reply": {"forum": "ry54RWtxx", "replyto": "ry54RWtxx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper77/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper77/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481718168787}}}, {"tddate": null, "tmdate": 1480432442006, "tcdate": 1480432442002, "number": 1, "id": "H1MHizoGx", "invitation": "ICLR.cc/2017/conference/-/paper77/public/comment", "forum": "ry54RWtxx", "replyto": "Ska_o0Fzx", "signatures": ["~Jean-Baptiste_Tristan1"], "readers": ["everyone"], "writers": ["~Jean-Baptiste_Tristan1"], "content": {"title": "Re: Evaluating strong generalization?", "comment": "1. This is a very good suggestion. We will run new experiments to test\ngeneralization for longer programs and an extended set of\nvariables. As a side note, we would like to mention that we just\nupdated our paper with results on an experiment using differentiable\ndata structures. Our hope is that the policy learned by the network\nwill indeed generalize well.\n\n2. The threshold was chosen by looking at a few examples, and it is\nindeed optimizing the presented example. We usually use a scale of\ncolors to indicate whether a variable might have been uninitialized\nbut for clarity we use a two color scheme in the paper. We haven't\nconsidered doing a more quantitative evaluation of that component. We\nthink it would be a good thing to do, but in the context of this paper\nour goal was mainly to address the concern of programmer feedback and\nshow that it is possible to interpret to some extent why a decision\nwas made.\n\nThank you for the reference, it is indeed interesting and we will\nupdate the paper accordingly."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Learning a Static Analyzer: A Case Study on a Toy Language", "abstract": "Static analyzers are meta-programs that analyze programs to detect\n  potential errors or collect information. For example, they are used\n  as security tools to detect potential buffer overflows. Also, they\n  are used by compilers to verify that a program is well-formed and\n  collect information to generate better code. In this paper, we\n  address the following question: can a static analyzer be learned\n  from data? More specifically, can we use deep learning to learn a\n  static analyzer without the need for complicated feature\n  engineering? We show that long short-term memory networks are able\n  to learn a basic static analyzer for a simple toy language. However,\n  pre-existing approaches based on feature engineering, hidden Markov\n  models, or basic recurrent neural networks fail on such a simple\n  problem. Finally, we show how to make such a tool usable by\n  employing a language model to help the programmer detect where the\n  reported errors are located.", "pdf": "/pdf/fc4810b863abf6bbd0cfb15e0d0e72d7f99505f2.pdf", "paperhash": "zaheer|learning_a_static_analyzer_a_case_study_on_a_toy_language", "keywords": [], "conflicts": ["harvard.edu", "cmu.edu", "oracle.com", "umass.edu"], "authors": ["Manzil Zaheer", "Jean-Baptiste Tristan", "Michael L. Wick", "Guy L. Steele Jr."], "authorids": ["manzil.zaheer@cmu.edu", "jean.baptiste.tristan@oracle.com", "michael.wick@oracle.com", "guy.steele@oracle.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287738537, "id": "ICLR.cc/2017/conference/-/paper77/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ry54RWtxx", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper77/reviewers", "ICLR.cc/2017/conference/paper77/areachairs"], "cdate": 1485287738537}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1480366745354, "tcdate": 1478200881637, "number": 77, "id": "ry54RWtxx", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "ry54RWtxx", "signatures": ["~Jean-Baptiste_Tristan1"], "readers": ["everyone"], "content": {"TL;DR": "", "title": "Learning a Static Analyzer: A Case Study on a Toy Language", "abstract": "Static analyzers are meta-programs that analyze programs to detect\n  potential errors or collect information. For example, they are used\n  as security tools to detect potential buffer overflows. Also, they\n  are used by compilers to verify that a program is well-formed and\n  collect information to generate better code. In this paper, we\n  address the following question: can a static analyzer be learned\n  from data? More specifically, can we use deep learning to learn a\n  static analyzer without the need for complicated feature\n  engineering? We show that long short-term memory networks are able\n  to learn a basic static analyzer for a simple toy language. However,\n  pre-existing approaches based on feature engineering, hidden Markov\n  models, or basic recurrent neural networks fail on such a simple\n  problem. Finally, we show how to make such a tool usable by\n  employing a language model to help the programmer detect where the\n  reported errors are located.", "pdf": "/pdf/fc4810b863abf6bbd0cfb15e0d0e72d7f99505f2.pdf", "paperhash": "zaheer|learning_a_static_analyzer_a_case_study_on_a_toy_language", "keywords": [], "conflicts": ["harvard.edu", "cmu.edu", "oracle.com", "umass.edu"], "authors": ["Manzil Zaheer", "Jean-Baptiste Tristan", "Michael L. Wick", "Guy L. Steele Jr."], "authorids": ["manzil.zaheer@cmu.edu", "jean.baptiste.tristan@oracle.com", "michael.wick@oracle.com", "guy.steele@oracle.com"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 12, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1480350581264, "tcdate": 1480350581260, "number": 1, "id": "Ska_o0Fzx", "invitation": "ICLR.cc/2017/conference/-/paper77/pre-review/question", "forum": "ry54RWtxx", "replyto": "ry54RWtxx", "signatures": ["ICLR.cc/2017/conference/paper77/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper77/AnonReviewer1"], "content": {"title": "Evaluating strong generalization?", "question": "Two questions:\n\n1. It seems very hard to generate a dataset of ~200k programs that have all the variability that one would expect to find in real source code. Thus, it would be desirable to use models that exhibit strong generalization (i.e., they generalize well even when test data is systematically different from training data). For example, one might hope that even if the learned static analyzer were run on a program that was much longer and used more identifiers than any program seen during training, the system would still perform well. Have you considered evaluating models in terms of stronger types of generalization?\n\n2. How is the threshold used to color figure 3 chosen? Was it chosen to optimize performance on that example? Have you considered building a quantitative evaluation for that component?\n\n\nAlso, you may be interested in the following citation, which also uses a trained language model to localize errors in code:\nCampbell, Joshua Charles, Abram Hindle, and Jos\u00e9 Nelson Amaral. \"Syntax errors just aren't natural: improving error reporting with language models.\" Proceedings of the 11th Working Conference on Mining Software Repositories. ACM, 2014."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Learning a Static Analyzer: A Case Study on a Toy Language", "abstract": "Static analyzers are meta-programs that analyze programs to detect\n  potential errors or collect information. For example, they are used\n  as security tools to detect potential buffer overflows. Also, they\n  are used by compilers to verify that a program is well-formed and\n  collect information to generate better code. In this paper, we\n  address the following question: can a static analyzer be learned\n  from data? More specifically, can we use deep learning to learn a\n  static analyzer without the need for complicated feature\n  engineering? We show that long short-term memory networks are able\n  to learn a basic static analyzer for a simple toy language. However,\n  pre-existing approaches based on feature engineering, hidden Markov\n  models, or basic recurrent neural networks fail on such a simple\n  problem. Finally, we show how to make such a tool usable by\n  employing a language model to help the programmer detect where the\n  reported errors are located.", "pdf": "/pdf/fc4810b863abf6bbd0cfb15e0d0e72d7f99505f2.pdf", "paperhash": "zaheer|learning_a_static_analyzer_a_case_study_on_a_toy_language", "keywords": [], "conflicts": ["harvard.edu", "cmu.edu", "oracle.com", "umass.edu"], "authors": ["Manzil Zaheer", "Jean-Baptiste Tristan", "Michael L. Wick", "Guy L. Steele Jr."], "authorids": ["manzil.zaheer@cmu.edu", "jean.baptiste.tristan@oracle.com", "michael.wick@oracle.com", "guy.steele@oracle.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481718168787, "id": "ICLR.cc/2017/conference/-/paper77/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper77/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper77/AnonReviewer1", "ICLR.cc/2017/conference/paper77/AnonReviewer3", "ICLR.cc/2017/conference/paper77/AnonReviewer2"], "reply": {"forum": "ry54RWtxx", "replyto": "ry54RWtxx", "writers": {"values-regex": "ICLR.cc/2017/conference/paper77/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper77/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481718168787}}}], "count": 13}