{"notes": [{"id": "BkeJm6VtPH", "original": "r1eyTw68vr", "number": 434, "cdate": 1569438999006, "ddate": null, "tcdate": 1569438999006, "tmdate": 1577168243551, "tddate": null, "forum": "BkeJm6VtPH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Continual Learning via Neural Pruning", "authors": ["Siavash Golkar", "Micheal Kagan", "Kyunghyun Cho"], "authorids": ["siavash.golkar@gmail.com", "makagan@slac.stanford.edu", "kyunghyun.cho@nyu.edu"], "keywords": ["continual learning", "lifelong learning", "catastrophic forgetting", "sparsification"], "TL;DR": "We introduce a continual learning algorithm based on sparsification using activation based neural pruning. We show that we beat or match prior methods of much higher complexity.", "abstract": "We introduce Continual Learning via Neural Pruning~(CLNP), a new method aimed at lifelong learning in fixed capacity models based on neuronal model sparsification. In this method, subsequent tasks are trained using the inactive neurons and filters of the sparsified network and cause zero deterioration to the performance of previous tasks. In order to deal with the possible compromise between model sparsity and performance, we formalize and incorporate the concept of \\emph{graceful forgetting}: the idea that it is preferable to suffer a small amount of forgetting in a controlled manner if it helps regain network capacity and prevents uncontrolled loss of performance during the training of future tasks. CLNP also provides simple continual learning diagnostic tools in terms of the number of free neurons left for the training of future tasks as well as the number of neurons that are being reused. In particular,  we see in experiments that CLNP verifies and automatically takes advantage of the fact that the features of earlier layers are more transferable.   We show empirically that CLNP leads to significantly improved results over current weight elasticity based methods. CLNP can also be applied in single-head architectures providing the first viable such algorithm for continual learning. ", "pdf": "/pdf/9c47e4480b5b2f58c7f2ae6f5c7b2191aeb6568f.pdf", "paperhash": "golkar|continual_learning_via_neural_pruning", "original_pdf": "/attachment/2b3fbaaa99d6e5933946c9d9ccec8ebc379fe931.pdf", "_bibtex": "@misc{\ngolkar2020continual,\ntitle={Continual Learning via Neural Pruning},\nauthor={Siavash Golkar and Micheal Kagan and Kyunghyun Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeJm6VtPH}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "14KLzvQRtm", "original": null, "number": 1, "cdate": 1576798696301, "ddate": null, "tcdate": 1576798696301, "tmdate": 1576800939346, "tddate": null, "forum": "BkeJm6VtPH", "replyto": "BkeJm6VtPH", "invitation": "ICLR.cc/2020/Conference/Paper434/-/Decision", "content": {"decision": "Reject", "comment": "There are several concerns with the brittleness and reproducibility of the proposed approach and experiments.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Continual Learning via Neural Pruning", "authors": ["Siavash Golkar", "Micheal Kagan", "Kyunghyun Cho"], "authorids": ["siavash.golkar@gmail.com", "makagan@slac.stanford.edu", "kyunghyun.cho@nyu.edu"], "keywords": ["continual learning", "lifelong learning", "catastrophic forgetting", "sparsification"], "TL;DR": "We introduce a continual learning algorithm based on sparsification using activation based neural pruning. We show that we beat or match prior methods of much higher complexity.", "abstract": "We introduce Continual Learning via Neural Pruning~(CLNP), a new method aimed at lifelong learning in fixed capacity models based on neuronal model sparsification. In this method, subsequent tasks are trained using the inactive neurons and filters of the sparsified network and cause zero deterioration to the performance of previous tasks. In order to deal with the possible compromise between model sparsity and performance, we formalize and incorporate the concept of \\emph{graceful forgetting}: the idea that it is preferable to suffer a small amount of forgetting in a controlled manner if it helps regain network capacity and prevents uncontrolled loss of performance during the training of future tasks. CLNP also provides simple continual learning diagnostic tools in terms of the number of free neurons left for the training of future tasks as well as the number of neurons that are being reused. In particular,  we see in experiments that CLNP verifies and automatically takes advantage of the fact that the features of earlier layers are more transferable.   We show empirically that CLNP leads to significantly improved results over current weight elasticity based methods. CLNP can also be applied in single-head architectures providing the first viable such algorithm for continual learning. ", "pdf": "/pdf/9c47e4480b5b2f58c7f2ae6f5c7b2191aeb6568f.pdf", "paperhash": "golkar|continual_learning_via_neural_pruning", "original_pdf": "/attachment/2b3fbaaa99d6e5933946c9d9ccec8ebc379fe931.pdf", "_bibtex": "@misc{\ngolkar2020continual,\ntitle={Continual Learning via Neural Pruning},\nauthor={Siavash Golkar and Micheal Kagan and Kyunghyun Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeJm6VtPH}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "BkeJm6VtPH", "replyto": "BkeJm6VtPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795714548, "tmdate": 1576800264277, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper434/-/Decision"}}}, {"id": "Hyx_oR5nKB", "original": null, "number": 1, "cdate": 1571757727735, "ddate": null, "tcdate": 1571757727735, "tmdate": 1572972595742, "tddate": null, "forum": "BkeJm6VtPH", "replyto": "BkeJm6VtPH", "invitation": "ICLR.cc/2020/Conference/Paper434/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a method for mitigating catastrophic forgetting in neural networks, which is an important and unsolved problem in the sequential training of multiple tasks.  The method works by (i) identifying an active subnetwork after training on one task that can perform the task to a sufficient degree of accuracy, (ii) freezing the subnetwork and pruning interfering connections to it from the rest of the network, and (iii) training the rest of the network on the next task and iterating. The contribution is a method that allows for training of sequential tasks in a fixed capacity architecture with zero catastrophic forgetting guaranteed, while still allowing for transfer between tasks via feature sharing. Additionally, it allows for controlled fine-tuning of the trade-off between accuracy and network capacity, which the authors refer to as \u2018graceful forgetting\u2019, by adjusting two hyperparameters that adjust the level of sparsity during the training of a task. The method is shown to outperform several other continual learning methods on permuted MNIST and one other method on split CIFAR-100, both standard evaluations in continual learning.\nWhile the model demonstrates the enviable properties for a continual learning algorithm of zero forgetting and ability to transfer in a fixed network, it suffers from a significant limitation (acknowledged by the authors) that leads me to recommend it for rejection in its current incarnation: \n* Due to the progressive freezing of the parameters, the network eventually reaches full capacity, making it theoretically difficult (in the multi-head setting, depending on the degree of transfer between tasks) or impossible (in the single-head setting) to learn how to perform new tasks.\n* This is particularly problematic because the mechanism for 'graceful forgetting\u2019 can only be applied on the subnetwork for a task that has just been trained on; once N tasks have been learnt, the subnetwork for task k<N cannot be altered without potentially affecting the performance on tasks k to N.\n* In the paper, subnetworks are sparsified to within a fixed margin of the maximum accuracy of each task - with this procedure, you cannot predict how much capacity will be taken up by each task, and so you cannot know in advance how many tasks will fit into the network. If instead you chose to sparsify to a given subnetwork capacity per task in order to guarantee being able to fit a certain number in, then you can not control the accuracy level for each task. \n* Another consequence of the method is that it is not clear how one can easily resume training on a previous task (perhaps to take advantage of transfer from subsequent tasks). You could reinstate connections from the features of subsequent tasks to the earlier task and train, but presumably these would initially interfere with the original subnetwork. Have the authors considered any ways of achieving this?\nIn fairness to the authors, they (a) show that the growth in utilised capacity slows as more tasks are added and (b) propose that the layers of the network could be dynamically extended as a way of overcoming a network at full capacity. For the reasons given above, however, it is not a practical fixed capacity algorithm for a lifelong learning setting, which constitutes an indefinite stream of sequential tasks, since at capacity it can suffer from sudden 'catastrophic remembering\u2019, as opposed to the \u2018graceful forgetting\u2019 advertised in the paper. I do think that the idea has potential and that the algorithm would be *significantly* strengthened if there were a mechanism for graceful forgetting of all or selected previous tasks when the network is at capacity.\n\nFurther Comments / questions:\n* The method is claimed to be the \u201cfirst viable algorithm for single-head continual learning\u201d. This statement is unspecific - what does \u2018viable\u2019 mean in this context? Online EWC [1] is a continual learning algorithm that can theoretically applied in a single-head setting - what makes it non-viable?\nMinor comments not affecting review:\n* Better to label the weight types in the caption of Figure 1 rather than just in the main text\n* In order to see the effect of depletion more clearly, it would also be useful to see the performance of the current task in isolation rather than just the average of all previous tasks.\n* Section 2, line 8: \u201cspeci[c]fic\"\n* The main text reference to Figure 5b compares it to the single-head MNIST usage graph - where is this?\n\n[1] Schwarz, Jonathan, et al. \"Progress & Compress: A scalable framework for continual learning.\" International Conference on Machine Learning. 2018."}, "signatures": ["ICLR.cc/2020/Conference/Paper434/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper434/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Continual Learning via Neural Pruning", "authors": ["Siavash Golkar", "Micheal Kagan", "Kyunghyun Cho"], "authorids": ["siavash.golkar@gmail.com", "makagan@slac.stanford.edu", "kyunghyun.cho@nyu.edu"], "keywords": ["continual learning", "lifelong learning", "catastrophic forgetting", "sparsification"], "TL;DR": "We introduce a continual learning algorithm based on sparsification using activation based neural pruning. We show that we beat or match prior methods of much higher complexity.", "abstract": "We introduce Continual Learning via Neural Pruning~(CLNP), a new method aimed at lifelong learning in fixed capacity models based on neuronal model sparsification. In this method, subsequent tasks are trained using the inactive neurons and filters of the sparsified network and cause zero deterioration to the performance of previous tasks. In order to deal with the possible compromise between model sparsity and performance, we formalize and incorporate the concept of \\emph{graceful forgetting}: the idea that it is preferable to suffer a small amount of forgetting in a controlled manner if it helps regain network capacity and prevents uncontrolled loss of performance during the training of future tasks. CLNP also provides simple continual learning diagnostic tools in terms of the number of free neurons left for the training of future tasks as well as the number of neurons that are being reused. In particular,  we see in experiments that CLNP verifies and automatically takes advantage of the fact that the features of earlier layers are more transferable.   We show empirically that CLNP leads to significantly improved results over current weight elasticity based methods. CLNP can also be applied in single-head architectures providing the first viable such algorithm for continual learning. ", "pdf": "/pdf/9c47e4480b5b2f58c7f2ae6f5c7b2191aeb6568f.pdf", "paperhash": "golkar|continual_learning_via_neural_pruning", "original_pdf": "/attachment/2b3fbaaa99d6e5933946c9d9ccec8ebc379fe931.pdf", "_bibtex": "@misc{\ngolkar2020continual,\ntitle={Continual Learning via Neural Pruning},\nauthor={Siavash Golkar and Micheal Kagan and Kyunghyun Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeJm6VtPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BkeJm6VtPH", "replyto": "BkeJm6VtPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper434/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper434/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575833154750, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper434/Reviewers"], "noninvitees": [], "tcdate": 1570237752191, "tmdate": 1575833154765, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper434/-/Official_Review"}}}, {"id": "BylhcAATtH", "original": null, "number": 2, "cdate": 1571839635733, "ddate": null, "tcdate": 1571839635733, "tmdate": 1572972595698, "tddate": null, "forum": "BkeJm6VtPH", "replyto": "BkeJm6VtPH", "invitation": "ICLR.cc/2020/Conference/Paper434/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "Continual lifelong learning is very interesting and has attracted increasing attention in recent years. Generally, there are two group of methods. And, the proposed method called CLNP leverages the merits from both of them. The experimental results clearly shows the effectiveness of this method.\n\nMy main concern is that this paper actually was accepted by a Neuro AI workshop of NeurIPS and thus this submission does not comply the rules of double-blind review process. Anyway, overall, this paper is well-written and interesting.\n\nI have more following concerns\n1) As the review given by Neuro AI, the submission just compare their results to Zenke et al. 2017 for SPLIT CIFAR-10/CIFAR-100. In this version, authors does not add new experiments to compare some new methods. Actually, most concerns raised by the reviewers in Neuro AI have not been considered.\n2) It is not clear how to set the hyperparameter such as threshold \\theta in different layers. Most settings and criteria are given empirically and this paper seriously lacks theoretical analysis.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper434/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper434/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Continual Learning via Neural Pruning", "authors": ["Siavash Golkar", "Micheal Kagan", "Kyunghyun Cho"], "authorids": ["siavash.golkar@gmail.com", "makagan@slac.stanford.edu", "kyunghyun.cho@nyu.edu"], "keywords": ["continual learning", "lifelong learning", "catastrophic forgetting", "sparsification"], "TL;DR": "We introduce a continual learning algorithm based on sparsification using activation based neural pruning. We show that we beat or match prior methods of much higher complexity.", "abstract": "We introduce Continual Learning via Neural Pruning~(CLNP), a new method aimed at lifelong learning in fixed capacity models based on neuronal model sparsification. In this method, subsequent tasks are trained using the inactive neurons and filters of the sparsified network and cause zero deterioration to the performance of previous tasks. In order to deal with the possible compromise between model sparsity and performance, we formalize and incorporate the concept of \\emph{graceful forgetting}: the idea that it is preferable to suffer a small amount of forgetting in a controlled manner if it helps regain network capacity and prevents uncontrolled loss of performance during the training of future tasks. CLNP also provides simple continual learning diagnostic tools in terms of the number of free neurons left for the training of future tasks as well as the number of neurons that are being reused. In particular,  we see in experiments that CLNP verifies and automatically takes advantage of the fact that the features of earlier layers are more transferable.   We show empirically that CLNP leads to significantly improved results over current weight elasticity based methods. CLNP can also be applied in single-head architectures providing the first viable such algorithm for continual learning. ", "pdf": "/pdf/9c47e4480b5b2f58c7f2ae6f5c7b2191aeb6568f.pdf", "paperhash": "golkar|continual_learning_via_neural_pruning", "original_pdf": "/attachment/2b3fbaaa99d6e5933946c9d9ccec8ebc379fe931.pdf", "_bibtex": "@misc{\ngolkar2020continual,\ntitle={Continual Learning via Neural Pruning},\nauthor={Siavash Golkar and Micheal Kagan and Kyunghyun Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeJm6VtPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BkeJm6VtPH", "replyto": "BkeJm6VtPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper434/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper434/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575833154750, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper434/Reviewers"], "noninvitees": [], "tcdate": 1570237752191, "tmdate": 1575833154765, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper434/-/Official_Review"}}}, {"id": "rJlNAOYzqH", "original": null, "number": 3, "cdate": 1572145355798, "ddate": null, "tcdate": 1572145355798, "tmdate": 1572972595657, "tddate": null, "forum": "BkeJm6VtPH", "replyto": "BkeJm6VtPH", "invitation": "ICLR.cc/2020/Conference/Paper434/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "General:\nThe paper proposed neural pruning method to overcome the catastrophic forgetting. Neural pruning identifies important nodes after learning each task, and sets the values of the incoming weights to 0 to preserve the node activation values. Also, the paper propose a method for gracefully forgetting, which is certainly needed for fixed capacity network. \n\nPros:\n1. When the network capacity does not get depleted, they showed the accuracy does not get dropped. \n2. Good results of outperforming several SOTA algorithms. \n3. Proposed a new method for gracefully forgetting, and achieved a good result. \n\nCon & Questions:\n1. Too many hyperparameters which will only dramatically increase with depths. \n2. The method for gracefully forgetting is not very practical. \n3. Depletion often happens - accuracy not dropping seems to be an overclaim. \n4. I think it is almost impossible to reproduce the results of this paper. \n5. What happens if all the layers have the same hyperparameters?\n6. When a depletion happens for a single-headed network, then how can you learn a new task?"}, "signatures": ["ICLR.cc/2020/Conference/Paper434/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper434/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Continual Learning via Neural Pruning", "authors": ["Siavash Golkar", "Micheal Kagan", "Kyunghyun Cho"], "authorids": ["siavash.golkar@gmail.com", "makagan@slac.stanford.edu", "kyunghyun.cho@nyu.edu"], "keywords": ["continual learning", "lifelong learning", "catastrophic forgetting", "sparsification"], "TL;DR": "We introduce a continual learning algorithm based on sparsification using activation based neural pruning. We show that we beat or match prior methods of much higher complexity.", "abstract": "We introduce Continual Learning via Neural Pruning~(CLNP), a new method aimed at lifelong learning in fixed capacity models based on neuronal model sparsification. In this method, subsequent tasks are trained using the inactive neurons and filters of the sparsified network and cause zero deterioration to the performance of previous tasks. In order to deal with the possible compromise between model sparsity and performance, we formalize and incorporate the concept of \\emph{graceful forgetting}: the idea that it is preferable to suffer a small amount of forgetting in a controlled manner if it helps regain network capacity and prevents uncontrolled loss of performance during the training of future tasks. CLNP also provides simple continual learning diagnostic tools in terms of the number of free neurons left for the training of future tasks as well as the number of neurons that are being reused. In particular,  we see in experiments that CLNP verifies and automatically takes advantage of the fact that the features of earlier layers are more transferable.   We show empirically that CLNP leads to significantly improved results over current weight elasticity based methods. CLNP can also be applied in single-head architectures providing the first viable such algorithm for continual learning. ", "pdf": "/pdf/9c47e4480b5b2f58c7f2ae6f5c7b2191aeb6568f.pdf", "paperhash": "golkar|continual_learning_via_neural_pruning", "original_pdf": "/attachment/2b3fbaaa99d6e5933946c9d9ccec8ebc379fe931.pdf", "_bibtex": "@misc{\ngolkar2020continual,\ntitle={Continual Learning via Neural Pruning},\nauthor={Siavash Golkar and Micheal Kagan and Kyunghyun Cho},\nyear={2020},\nurl={https://openreview.net/forum?id=BkeJm6VtPH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BkeJm6VtPH", "replyto": "BkeJm6VtPH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper434/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper434/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575833154750, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper434/Reviewers"], "noninvitees": [], "tcdate": 1570237752191, "tmdate": 1575833154765, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper434/-/Official_Review"}}}], "count": 5}