{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124430577, "tcdate": 1518473272796, "number": 356, "cdate": 1518473272796, "id": "ry-Se9kvG", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "ry-Se9kvG", "signatures": ["~Jasper_Snoek1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "STOCHASTIC GRADIENT LANGEVIN DYNAMICS THAT EXPLOIT NEURAL NETWORK  STRUCTURE", "abstract": "Tractable approximate Bayesian inference for deep neural networks remains challenging.  Stochastic Gradient Langevin Dynamics (SGLD) offers a tractable approximation to the gold standard of Hamiltonian Monte Carlo.  We improve on existing methods for SGLD by incorporating a recently-developed tractable approximation of the Fisher information, known as K-FAC, as a preconditioner.", "paperhash": "nado|stochastic_gradient_langevin_dynamics_that_exploit_neural_network_structure", "keywords": ["monte carlo", "Bayesian deep networks"], "_bibtex": "@misc{\n  nado2018stochastic,\n  title={STOCHASTIC GRADIENT LANGEVIN DYNAMICS THAT EXPLOIT NEURAL NETWORK  STRUCTURE},\n  author={Zachary Nado and Jasper Snoek and Roger Grosse and David Duvenaud and Bowen Xu and James Martens},\n  year={2018},\n  url={https://openreview.net/forum?id=ry-Se9kvG}\n}", "authorids": ["znado@google.com", "jsnoek@google.com", "rgrosse@cs.toronto.edu", "duvenaud@cs.toronto.edu", "jamesmartens@google.com", "bowenxu@cs.toronto.edu"], "authors": ["Zachary Nado", "Jasper Snoek", "Roger Grosse", "David Duvenaud", "Bowen Xu", "James Martens"], "TL;DR": "We use a recent approximation for the Fisher information to improve approximate Bayesian inference for deep neural networks with Langevin Dynamics.", "pdf": "/pdf/2b3efe24af1a6bc4fd2cf32c850fe34599830aeb.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582855265, "tcdate": 1520569856919, "number": 1, "cdate": 1520569856919, "id": "SJKb0tktf", "invitation": "ICLR.cc/2018/Workshop/-/Paper356/Official_Review", "forum": "ry-Se9kvG", "replyto": "ry-Se9kvG", "signatures": ["ICLR.cc/2018/Workshop/Paper356/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper356/AnonReviewer3"], "content": {"title": "Useful fast sampling method", "rating": "8: Top 50% of accepted papers, clear accept", "review": "This paper provides an effective fisher information approximation method K-FAC to SGLD, the experiments show that the sampler out-performs pre-conditioned version of SGLD.\n\nComments:\nThe author mentioned cited Riemannian based samplers, which can resort to the diagonal approximate version that author claimed to be inaccurate. I would expect to see a comparison between the diagonal approximate Riemannian vs K-FAC based sampler.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "STOCHASTIC GRADIENT LANGEVIN DYNAMICS THAT EXPLOIT NEURAL NETWORK  STRUCTURE", "abstract": "Tractable approximate Bayesian inference for deep neural networks remains challenging.  Stochastic Gradient Langevin Dynamics (SGLD) offers a tractable approximation to the gold standard of Hamiltonian Monte Carlo.  We improve on existing methods for SGLD by incorporating a recently-developed tractable approximation of the Fisher information, known as K-FAC, as a preconditioner.", "paperhash": "nado|stochastic_gradient_langevin_dynamics_that_exploit_neural_network_structure", "keywords": ["monte carlo", "Bayesian deep networks"], "_bibtex": "@misc{\n  nado2018stochastic,\n  title={STOCHASTIC GRADIENT LANGEVIN DYNAMICS THAT EXPLOIT NEURAL NETWORK  STRUCTURE},\n  author={Zachary Nado and Jasper Snoek and Roger Grosse and David Duvenaud and Bowen Xu and James Martens},\n  year={2018},\n  url={https://openreview.net/forum?id=ry-Se9kvG}\n}", "authorids": ["znado@google.com", "jsnoek@google.com", "rgrosse@cs.toronto.edu", "duvenaud@cs.toronto.edu", "jamesmartens@google.com", "bowenxu@cs.toronto.edu"], "authors": ["Zachary Nado", "Jasper Snoek", "Roger Grosse", "David Duvenaud", "Bowen Xu", "James Martens"], "TL;DR": "We use a recent approximation for the Fisher information to improve approximate Bayesian inference for deep neural networks with Langevin Dynamics.", "pdf": "/pdf/2b3efe24af1a6bc4fd2cf32c850fe34599830aeb.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582855067, "id": "ICLR.cc/2018/Workshop/-/Paper356/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper356/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper356/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper356/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper356/AnonReviewer2"], "reply": {"forum": "ry-Se9kvG", "replyto": "ry-Se9kvG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper356/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper356/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582855067}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582746542, "tcdate": 1520658271288, "number": 2, "cdate": 1520658271288, "id": "BkPDD1-KM", "invitation": "ICLR.cc/2018/Workshop/-/Paper356/Official_Review", "forum": "ry-Se9kvG", "replyto": "ry-Se9kvG", "signatures": ["ICLR.cc/2018/Workshop/Paper356/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper356/AnonReviewer1"], "content": {"title": "Promising early result", "rating": "7: Good paper, accept", "review": "The authors propose to use the Kronecker-Factored Approximate Curvature (K-FAC) approximation of the Fisher information as a preconditioner of SGLD. The experiment result shows that it's a promising direction.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "STOCHASTIC GRADIENT LANGEVIN DYNAMICS THAT EXPLOIT NEURAL NETWORK  STRUCTURE", "abstract": "Tractable approximate Bayesian inference for deep neural networks remains challenging.  Stochastic Gradient Langevin Dynamics (SGLD) offers a tractable approximation to the gold standard of Hamiltonian Monte Carlo.  We improve on existing methods for SGLD by incorporating a recently-developed tractable approximation of the Fisher information, known as K-FAC, as a preconditioner.", "paperhash": "nado|stochastic_gradient_langevin_dynamics_that_exploit_neural_network_structure", "keywords": ["monte carlo", "Bayesian deep networks"], "_bibtex": "@misc{\n  nado2018stochastic,\n  title={STOCHASTIC GRADIENT LANGEVIN DYNAMICS THAT EXPLOIT NEURAL NETWORK  STRUCTURE},\n  author={Zachary Nado and Jasper Snoek and Roger Grosse and David Duvenaud and Bowen Xu and James Martens},\n  year={2018},\n  url={https://openreview.net/forum?id=ry-Se9kvG}\n}", "authorids": ["znado@google.com", "jsnoek@google.com", "rgrosse@cs.toronto.edu", "duvenaud@cs.toronto.edu", "jamesmartens@google.com", "bowenxu@cs.toronto.edu"], "authors": ["Zachary Nado", "Jasper Snoek", "Roger Grosse", "David Duvenaud", "Bowen Xu", "James Martens"], "TL;DR": "We use a recent approximation for the Fisher information to improve approximate Bayesian inference for deep neural networks with Langevin Dynamics.", "pdf": "/pdf/2b3efe24af1a6bc4fd2cf32c850fe34599830aeb.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582855067, "id": "ICLR.cc/2018/Workshop/-/Paper356/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper356/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper356/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper356/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper356/AnonReviewer2"], "reply": {"forum": "ry-Se9kvG", "replyto": "ry-Se9kvG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper356/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper356/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582855067}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582695858, "tcdate": 1520712722202, "number": 3, "cdate": 1520712722202, "id": "SycG32-YM", "invitation": "ICLR.cc/2018/Workshop/-/Paper356/Official_Review", "forum": "ry-Se9kvG", "replyto": "ry-Se9kvG", "signatures": ["ICLR.cc/2018/Workshop/Paper356/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper356/AnonReviewer2"], "content": {"title": "Application of K-Fac formulation to Fisher matrix improves conditioned SGLD", "rating": "6: Marginally above acceptance threshold", "review": "The authors provide an application of the Kronecker Factored curvature proposed in Martens et. al. (ICML'15) to preconditioned SGLD, allowing one to efficiently approximate the product of the Fisher metric with the standard stochastic gradient (known as the \"natural gradient\"). The empirical evaluation shows some improvement over pSGLD in terms of test log likelihood.\n\nOverall the paper does not have any theoretical contributions over the ICML'15 work referenced above, and experimental results comparing against the diagonal Riemannian approximations (SGRLD) with a runtime comparison would have been nice.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "STOCHASTIC GRADIENT LANGEVIN DYNAMICS THAT EXPLOIT NEURAL NETWORK  STRUCTURE", "abstract": "Tractable approximate Bayesian inference for deep neural networks remains challenging.  Stochastic Gradient Langevin Dynamics (SGLD) offers a tractable approximation to the gold standard of Hamiltonian Monte Carlo.  We improve on existing methods for SGLD by incorporating a recently-developed tractable approximation of the Fisher information, known as K-FAC, as a preconditioner.", "paperhash": "nado|stochastic_gradient_langevin_dynamics_that_exploit_neural_network_structure", "keywords": ["monte carlo", "Bayesian deep networks"], "_bibtex": "@misc{\n  nado2018stochastic,\n  title={STOCHASTIC GRADIENT LANGEVIN DYNAMICS THAT EXPLOIT NEURAL NETWORK  STRUCTURE},\n  author={Zachary Nado and Jasper Snoek and Roger Grosse and David Duvenaud and Bowen Xu and James Martens},\n  year={2018},\n  url={https://openreview.net/forum?id=ry-Se9kvG}\n}", "authorids": ["znado@google.com", "jsnoek@google.com", "rgrosse@cs.toronto.edu", "duvenaud@cs.toronto.edu", "jamesmartens@google.com", "bowenxu@cs.toronto.edu"], "authors": ["Zachary Nado", "Jasper Snoek", "Roger Grosse", "David Duvenaud", "Bowen Xu", "James Martens"], "TL;DR": "We use a recent approximation for the Fisher information to improve approximate Bayesian inference for deep neural networks with Langevin Dynamics.", "pdf": "/pdf/2b3efe24af1a6bc4fd2cf32c850fe34599830aeb.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582855067, "id": "ICLR.cc/2018/Workshop/-/Paper356/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper356/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper356/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper356/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper356/AnonReviewer2"], "reply": {"forum": "ry-Se9kvG", "replyto": "ry-Se9kvG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper356/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper356/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582855067}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573555186, "tcdate": 1521573555186, "number": 53, "cdate": 1521573554845, "id": "BJin0CAtz", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "ry-Se9kvG", "replyto": "ry-Se9kvG", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "STOCHASTIC GRADIENT LANGEVIN DYNAMICS THAT EXPLOIT NEURAL NETWORK  STRUCTURE", "abstract": "Tractable approximate Bayesian inference for deep neural networks remains challenging.  Stochastic Gradient Langevin Dynamics (SGLD) offers a tractable approximation to the gold standard of Hamiltonian Monte Carlo.  We improve on existing methods for SGLD by incorporating a recently-developed tractable approximation of the Fisher information, known as K-FAC, as a preconditioner.", "paperhash": "nado|stochastic_gradient_langevin_dynamics_that_exploit_neural_network_structure", "keywords": ["monte carlo", "Bayesian deep networks"], "_bibtex": "@misc{\n  nado2018stochastic,\n  title={STOCHASTIC GRADIENT LANGEVIN DYNAMICS THAT EXPLOIT NEURAL NETWORK  STRUCTURE},\n  author={Zachary Nado and Jasper Snoek and Roger Grosse and David Duvenaud and Bowen Xu and James Martens},\n  year={2018},\n  url={https://openreview.net/forum?id=ry-Se9kvG}\n}", "authorids": ["znado@google.com", "jsnoek@google.com", "rgrosse@cs.toronto.edu", "duvenaud@cs.toronto.edu", "jamesmartens@google.com", "bowenxu@cs.toronto.edu"], "authors": ["Zachary Nado", "Jasper Snoek", "Roger Grosse", "David Duvenaud", "Bowen Xu", "James Martens"], "TL;DR": "We use a recent approximation for the Fisher information to improve approximate Bayesian inference for deep neural networks with Langevin Dynamics.", "pdf": "/pdf/2b3efe24af1a6bc4fd2cf32c850fe34599830aeb.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}