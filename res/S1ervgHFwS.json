{"notes": [{"id": "S1ervgHFwS", "original": "r1xGuigFvH", "number": 2358, "cdate": 1569439836529, "ddate": null, "tcdate": 1569439836529, "tmdate": 1577168229750, "tddate": null, "forum": "S1ervgHFwS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["kevin.roth@inf.ethz.ch", "yannic.kilcher@inf.ethz.ch", "thomas.hofmann@inf.ethz.ch"], "title": "Adversarial Training Generalizes Data-dependent Spectral Norm Regularization", "authors": ["Kevin Roth", "Yannic Kilcher", "Thomas Hofmann"], "pdf": "/pdf/478cde394439b29ef1fe946667fd7a1a97d5198c.pdf", "TL;DR": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks.", "abstract": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks. Specifically, we present a data-dependent variant of spectral norm regularization and prove that it is equivalent to adversarial training based on a specific $\\ell_2$-norm constrained projected gradient ascent attack. This fundamental connection confirms the long-standing argument that a network's sensitivity to adversarial examples is tied to its spectral properties and hints at novel ways to robustify and defend against adversarial attacks. We provide extensive empirical evidence to support our theoretical results. ", "keywords": ["Adversarial Robustness", "Adversarial Training", "Spectral Norm Regularization"], "paperhash": "roth|adversarial_training_generalizes_datadependent_spectral_norm_regularization", "original_pdf": "/attachment/7df1de0789db183ad3a5b4cbfcb648952019e520.pdf", "_bibtex": "@misc{\nroth2020adversarial,\ntitle={Adversarial Training Generalizes Data-dependent Spectral Norm Regularization},\nauthor={Kevin Roth and Yannic Kilcher and Thomas Hofmann},\nyear={2020},\nurl={https://openreview.net/forum?id=S1ervgHFwS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 15, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "H8JxNMBdVe", "original": null, "number": 1, "cdate": 1576798747091, "ddate": null, "tcdate": 1576798747091, "tmdate": 1576800888994, "tddate": null, "forum": "S1ervgHFwS", "replyto": "S1ervgHFwS", "invitation": "ICLR.cc/2020/Conference/Paper2358/-/Decision", "content": {"decision": "Reject", "comment": "This paper shows an theoretical equivalence between the L2 PGD adversarial training and operator norm regularization. It gives an interesting observation and support it from both theoretical arguments and practical experiments. There has been a significant discussion between the reviewers and authors. Although the authors made efforts in rebuttal, it still leaves many places to improve and clarify, especially in improving the mathematical rigor of the  proof and experiments using state-of-the-art networks. \n\n", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["kevin.roth@inf.ethz.ch", "yannic.kilcher@inf.ethz.ch", "thomas.hofmann@inf.ethz.ch"], "title": "Adversarial Training Generalizes Data-dependent Spectral Norm Regularization", "authors": ["Kevin Roth", "Yannic Kilcher", "Thomas Hofmann"], "pdf": "/pdf/478cde394439b29ef1fe946667fd7a1a97d5198c.pdf", "TL;DR": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks.", "abstract": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks. Specifically, we present a data-dependent variant of spectral norm regularization and prove that it is equivalent to adversarial training based on a specific $\\ell_2$-norm constrained projected gradient ascent attack. This fundamental connection confirms the long-standing argument that a network's sensitivity to adversarial examples is tied to its spectral properties and hints at novel ways to robustify and defend against adversarial attacks. We provide extensive empirical evidence to support our theoretical results. ", "keywords": ["Adversarial Robustness", "Adversarial Training", "Spectral Norm Regularization"], "paperhash": "roth|adversarial_training_generalizes_datadependent_spectral_norm_regularization", "original_pdf": "/attachment/7df1de0789db183ad3a5b4cbfcb648952019e520.pdf", "_bibtex": "@misc{\nroth2020adversarial,\ntitle={Adversarial Training Generalizes Data-dependent Spectral Norm Regularization},\nauthor={Kevin Roth and Yannic Kilcher and Thomas Hofmann},\nyear={2020},\nurl={https://openreview.net/forum?id=S1ervgHFwS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "S1ervgHFwS", "replyto": "S1ervgHFwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795703087, "tmdate": 1576800250365, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2358/-/Decision"}}}, {"id": "r1eOQ7j2iB", "original": null, "number": 13, "cdate": 1573856032031, "ddate": null, "tcdate": 1573856032031, "tmdate": 1573856058609, "tddate": null, "forum": "S1ervgHFwS", "replyto": "B1laVbdjYH", "invitation": "ICLR.cc/2020/Conference/Paper2358/-/Official_Comment", "content": {"title": "Amended plot for large alpha", "comment": "Dear Reviewer\n\nIn response to your comment wondering what happens in the practical (PGA) algorithm when \\alpha goes to infinity, we empirically tested that the effect of Adversarial Training remains constant when provided with consecutively larger \\alpha-values. Please refer to the last plot in the Appendix in the revised version of our paper.\n\nPlease also have a look at our response to your review below.\nThank you for your time."}, "signatures": ["ICLR.cc/2020/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["kevin.roth@inf.ethz.ch", "yannic.kilcher@inf.ethz.ch", "thomas.hofmann@inf.ethz.ch"], "title": "Adversarial Training Generalizes Data-dependent Spectral Norm Regularization", "authors": ["Kevin Roth", "Yannic Kilcher", "Thomas Hofmann"], "pdf": "/pdf/478cde394439b29ef1fe946667fd7a1a97d5198c.pdf", "TL;DR": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks.", "abstract": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks. Specifically, we present a data-dependent variant of spectral norm regularization and prove that it is equivalent to adversarial training based on a specific $\\ell_2$-norm constrained projected gradient ascent attack. This fundamental connection confirms the long-standing argument that a network's sensitivity to adversarial examples is tied to its spectral properties and hints at novel ways to robustify and defend against adversarial attacks. We provide extensive empirical evidence to support our theoretical results. ", "keywords": ["Adversarial Robustness", "Adversarial Training", "Spectral Norm Regularization"], "paperhash": "roth|adversarial_training_generalizes_datadependent_spectral_norm_regularization", "original_pdf": "/attachment/7df1de0789db183ad3a5b4cbfcb648952019e520.pdf", "_bibtex": "@misc{\nroth2020adversarial,\ntitle={Adversarial Training Generalizes Data-dependent Spectral Norm Regularization},\nauthor={Kevin Roth and Yannic Kilcher and Thomas Hofmann},\nyear={2020},\nurl={https://openreview.net/forum?id=S1ervgHFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1ervgHFwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference/Paper2358/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2358/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2358/Reviewers", "ICLR.cc/2020/Conference/Paper2358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2358/Authors|ICLR.cc/2020/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504142557, "tmdate": 1576860555309, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference/Paper2358/Reviewers", "ICLR.cc/2020/Conference/Paper2358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2358/-/Official_Comment"}}}, {"id": "BylmbysnjS", "original": null, "number": 12, "cdate": 1573854971319, "ddate": null, "tcdate": 1573854971319, "tmdate": 1573854971319, "tddate": null, "forum": "S1ervgHFwS", "replyto": "S1lb22MUjS", "invitation": "ICLR.cc/2020/Conference/Paper2358/-/Official_Comment", "content": {"title": "Additional Results", "comment": "Dear Reviewer\nIn response to your comments - and in parallel to formulating our response - we had started replicating our experiments on a WResNet architecture. In clean training, this reaches 96.3% accuracy on CIFAR10 after 200 epochs of training. We hoped that this platform would satisfy the reviewer's request for evaluation on state-of-the-art models.\nHowever, due to the high computational requirements of this model, our evaluations did not finish in time for this rebuttal period. Specifically, for both AT and ddSNR we only managed to perform 95 epochs, leaving the model training in an unfinished state.\nWe do not want to include half-done results in our paper, but we feel it contributes to the discussion if we state here that as of now, there appears to be no significant difference in adversarial robustness between the adversarially trained variant and a model trained using ddSNR (that has an equivalent drop in clean accuracy as the one trained using AT). This is further evidence in favor of our main claim.\n\nAccuracy on clean samples after 95 epochs:\nNon-regularized model: 0.922\nWith Adversarial Training: 0.865\nWith d.d. Spectral Norm Regularization: 0.868\n\nAccuracy on adversarial samples after 95 epochs:\nNon-regularized model: 0.310\nWith Adversarial Training: 0.625\nWith d.d. Spectral Norm Regularization: 0.633\n\nWe would like to stress again that the purpose of this is to provide evidence for the reasonable assumption that our experimental findings do not change qualitatively when moving to this much more complex architecture, not to attempt to outcompete any other training method. We hope this is satisfactory. We are happy to include the final results in the camera-ready version of the paper.\nPlease also see our response to your response below.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["kevin.roth@inf.ethz.ch", "yannic.kilcher@inf.ethz.ch", "thomas.hofmann@inf.ethz.ch"], "title": "Adversarial Training Generalizes Data-dependent Spectral Norm Regularization", "authors": ["Kevin Roth", "Yannic Kilcher", "Thomas Hofmann"], "pdf": "/pdf/478cde394439b29ef1fe946667fd7a1a97d5198c.pdf", "TL;DR": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks.", "abstract": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks. Specifically, we present a data-dependent variant of spectral norm regularization and prove that it is equivalent to adversarial training based on a specific $\\ell_2$-norm constrained projected gradient ascent attack. This fundamental connection confirms the long-standing argument that a network's sensitivity to adversarial examples is tied to its spectral properties and hints at novel ways to robustify and defend against adversarial attacks. We provide extensive empirical evidence to support our theoretical results. ", "keywords": ["Adversarial Robustness", "Adversarial Training", "Spectral Norm Regularization"], "paperhash": "roth|adversarial_training_generalizes_datadependent_spectral_norm_regularization", "original_pdf": "/attachment/7df1de0789db183ad3a5b4cbfcb648952019e520.pdf", "_bibtex": "@misc{\nroth2020adversarial,\ntitle={Adversarial Training Generalizes Data-dependent Spectral Norm Regularization},\nauthor={Kevin Roth and Yannic Kilcher and Thomas Hofmann},\nyear={2020},\nurl={https://openreview.net/forum?id=S1ervgHFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1ervgHFwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference/Paper2358/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2358/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2358/Reviewers", "ICLR.cc/2020/Conference/Paper2358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2358/Authors|ICLR.cc/2020/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504142557, "tmdate": 1576860555309, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference/Paper2358/Reviewers", "ICLR.cc/2020/Conference/Paper2358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2358/-/Official_Comment"}}}, {"id": "BklZ9jKKsS", "original": null, "number": 11, "cdate": 1573653385047, "ddate": null, "tcdate": 1573653385047, "tmdate": 1573653385047, "tddate": null, "forum": "S1ervgHFwS", "replyto": "S1lb22MUjS", "invitation": "ICLR.cc/2020/Conference/Paper2358/-/Official_Comment", "content": {"title": "Author Response to Comment (Part 1 of 2)", "comment": "*This is part 1 of 2 of our response*\n\nThank you very much for engaging with our comments, we highly appreciate this.\nPlease find our comments below.\n\n\n>> Regarding the theoretical analysis:\nThe claim of theorem 1 is ambiguous, I mean, it\u2019s not precise. Can you give some precise condition for epsilon and alpha, like the upper bound of epsilon and lower bound of alpha for your theorem to hold even under some idealized case like two-layer ReLU network? The current way of presentation is NOT a theorem, but a proposition or intuition.\n\nWe respectfully disagree. The conditions in Theorem 1 *are* precise. Namely, Theorem 1 states that there is an exact correspondence between AT and ddSNR if (i) B\u03b5(x) \u2282 X(\u03c6_x), i.e. if the epsilon-ball is contained in the ReLU cell X(\u03c6_x) around x and (ii) if \\alpha \\to \\infty, i.e. if in the update equation for x_k all the weight is placed on the current gradient direction v_k whereas no weight is put on the previous iterate x_{k\u22121}, as was clearly stated in the paper.\nAlso our Theorem does not hold only in some idealized case, it holds in *any* ReLU network.\nAnd for this statement, we provide a formal proof. How is this not a theorem?\n\nWhat we believe the reviewer might have in mind instead is an \u201cextended proof\u201d for the \u201capproximate correspondence\u201d between AT and ddSNR. \n\nSuch an \u201cextended proof\u201d would ultimately boil down to introducing a tolerance parameter, say \\delta, deriving a radius r such that for all x* with || x* - x || < r, the Jacobian J_f(x*) is \u201c\\delta-close\u201d to J_f(x), and then proving that the correspondence between AT and ddSNR holds \\delta\u2019-approximately (where \\delta\u2019 depends on \\delta). \n\nProving such an extension is highly non-trivial (one would have to take into account how much \u201cnearby\u201d Jacobians can change based on the crossing of ReLU boundaries) and thus out-of-scope of the current paper. We instead opted to verify this \u201capproximate correspondence\u201d experimentally, showing that in practice, the correspondence between AT and d.d. SNR holds approximately in a region much larger than proved in the Theorem, as already discussed in our previous reply.\n\n\n>> Regarding the core contribution and the experiments:\nIn my opinion, I haven\u2019t found the information that this paper can take to the whole community. Like, for example, for practitioner, there is no motivations to use the current methods instead of the adversarial training. For theorists, this paper brought no idea on how to inspire and improve the theory on adversarial training and robust generalization. I expected the authors to achieve either of it, but the theories in this paper DO NOT mean to solve the theoretical problem I mentioned, and I think the proposed methods DO NOT outperform the existing baseline methods on both the efficiency and the accuracy. \n\nHere is what a practitioner could ask themselves: Should I go through the effort to add data-dependent spectral norm regularization in addition to adversarial training on my network to make it more robust? Thanks to us, they now know that this won\u2019t be very fruitful because the two methods do the same thing.\n\nFor theoreticians, the case is even more clear: There have been numerous papers that have shown an empirical correlation between spectral norm regularization and adversarial robustness, yet none of them managed to make a clear formal connection between the two. We establish the first direct proof of this connection.\n\nLastly, again, we never claim that our methods outperform AT, or that they are in any way preferrable. We also do not claim to solve the learning theory problem of deriving adversarially robust generalization bounds, although we do believe that the correspondence we establish opens the door for such bounds via generalizations of existing global spectral norm based ones [e.g. Bartlett et al. \u201cSpectrally-normalized margin bounds for neural networks\u201d or Neyshabur et al. \u201cNorm-based capacity control in neural networks\u201d] to our new notion of data-dependent spectral norm regularization."}, "signatures": ["ICLR.cc/2020/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["kevin.roth@inf.ethz.ch", "yannic.kilcher@inf.ethz.ch", "thomas.hofmann@inf.ethz.ch"], "title": "Adversarial Training Generalizes Data-dependent Spectral Norm Regularization", "authors": ["Kevin Roth", "Yannic Kilcher", "Thomas Hofmann"], "pdf": "/pdf/478cde394439b29ef1fe946667fd7a1a97d5198c.pdf", "TL;DR": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks.", "abstract": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks. Specifically, we present a data-dependent variant of spectral norm regularization and prove that it is equivalent to adversarial training based on a specific $\\ell_2$-norm constrained projected gradient ascent attack. This fundamental connection confirms the long-standing argument that a network's sensitivity to adversarial examples is tied to its spectral properties and hints at novel ways to robustify and defend against adversarial attacks. We provide extensive empirical evidence to support our theoretical results. ", "keywords": ["Adversarial Robustness", "Adversarial Training", "Spectral Norm Regularization"], "paperhash": "roth|adversarial_training_generalizes_datadependent_spectral_norm_regularization", "original_pdf": "/attachment/7df1de0789db183ad3a5b4cbfcb648952019e520.pdf", "_bibtex": "@misc{\nroth2020adversarial,\ntitle={Adversarial Training Generalizes Data-dependent Spectral Norm Regularization},\nauthor={Kevin Roth and Yannic Kilcher and Thomas Hofmann},\nyear={2020},\nurl={https://openreview.net/forum?id=S1ervgHFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1ervgHFwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference/Paper2358/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2358/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2358/Reviewers", "ICLR.cc/2020/Conference/Paper2358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2358/Authors|ICLR.cc/2020/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504142557, "tmdate": 1576860555309, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference/Paper2358/Reviewers", "ICLR.cc/2020/Conference/Paper2358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2358/-/Official_Comment"}}}, {"id": "rJetHsYKoH", "original": null, "number": 10, "cdate": 1573653313391, "ddate": null, "tcdate": 1573653313391, "tmdate": 1573653324037, "tddate": null, "forum": "S1ervgHFwS", "replyto": "S1lb22MUjS", "invitation": "ICLR.cc/2020/Conference/Paper2358/-/Official_Comment", "content": {"title": "Author Response to Comment (Part 2 of 2)", "comment": "*This is part 2 of 2 of our response*\n\n>> For the claim on the experiments, as the concerns I mentioned, if this methods do not consistently show the improvement of the current methods on the existing state-of-the-art methods, I don\u2019t find the meaning of using such of the methods. \nFor state-of-the-art methods, I would like to see some of the top methods in https://paperswithcode.com/sota/image-classification-on-cifar-10. \n93.5% clean accuracy does not mean state-of-the-art performance to me. \nAlso, most of the experiments aims to show that the condition to show the equivalence between the proposed methods and adversarial training can be satisfied in some real world applications and give some interesting empirical observations.\n\nWe would like to stress again that our goal is not to outperform any existing methods. In fact, it would be contrary to our main claim if ddSNR would outperform AT. Instead, our goal is to verify the relevance of our Theorem in a practical setting, by empirically confirming the conditions necessary for the correspondence between AT and ddSNR to hold. By establishing this correspondence in theory and practice, our paper contributes significantly to the understanding of adversarial robustness.\n\nMore experiments can of course always be requested, but we believe that confirming our main claims in practice is more important and valuable than including further architectures.\nIs there a reasonable expectation why there should be a qualitative difference in experimental results between our 93.5%-accurate model and one that is, say, 96% accurate? Our goal is not to improve the state-of-the-art in adversarial robustness, but to compare all methods fairly on a platform that performs competitively, even if it's not at the very top of the leaderboard. \nThe CNN architecture we used is similar to the one used in the prominent works of Carlini & Wagner\u2019s \u201cTowards evaluating the robustness of neural networks\u201d, In Security and Privacy (SP), IEEE, 2017 and Papernot et al.\u2019s \u201cDistillation as a defense to adversarial perturbations against deep neural networks\u201d, In Security and Privacy (SP), IEEE, 2016, both reporting a clean test accuracy of 80.9% for standard training without data-augmentation.\n\nOur accuracies (on clean test) after AT / SNR (~83%) match the ones in related papers that use the architectures requested by the reviewer, e.g. 79% (AlexNet), 83% (ResNet) in Farzan et al. [1] (which the reviewer referred to multiple times), or 79% (ResNet), 87% (WideResNet) in Madry et al. \u201cTowards Deep Learning Models Resistant to Adversarial Attacks\u201d.\n\n\n>> For the detailed feedback on the experiments:\nI miss some of the claims in Section 5.2, so I misunderstood the purpose of Appendix A.5. Sorry for that.\n\nThank you for the feedback. We are glad to hear that we could clarify these misunderstandings.\n\n\n>> For the fairness claim, the authors claimed to tune the hyper-parameters to make sure the regularization methods have the similar test accuracy. Is this shown means the result in Table 1? I tend to have as little hyper-parameters as possible. The current hyper-paremeter setting seems weird to me. Also, if 1 iteration and 10 iterations performs the same, I prefer to use 10 iterations to eliminate the potential question.\n\nThe purpose of Table 1 is to facilitate reproducibility of our results. Table 1 summarizes the hyperparameters we have found following our protocol to choose the regularization constants such that the models achieve roughly the same test set accuracy on clean examples as the adversarially trained model does. \n\nFor each training method we did a sweep over a relatively broad range of hyper-parameters and the numbers we report represent the best configurations for each of the training methods. For your convenience, we have amended the appendix to include a table of searched values for each method.\n\nFor global SNR \u00e0 la Yoshida & Miayto, our aim was to stay as close as possible to the authors' suggestions, as indicated already in our previous reply. For your convenience, we have repeated the main experiments with global SNR using 10 iterations instead of one. Please find the plots in the updated appendix. There is no difference between the 1- and 10-iteration versions.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["kevin.roth@inf.ethz.ch", "yannic.kilcher@inf.ethz.ch", "thomas.hofmann@inf.ethz.ch"], "title": "Adversarial Training Generalizes Data-dependent Spectral Norm Regularization", "authors": ["Kevin Roth", "Yannic Kilcher", "Thomas Hofmann"], "pdf": "/pdf/478cde394439b29ef1fe946667fd7a1a97d5198c.pdf", "TL;DR": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks.", "abstract": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks. Specifically, we present a data-dependent variant of spectral norm regularization and prove that it is equivalent to adversarial training based on a specific $\\ell_2$-norm constrained projected gradient ascent attack. This fundamental connection confirms the long-standing argument that a network's sensitivity to adversarial examples is tied to its spectral properties and hints at novel ways to robustify and defend against adversarial attacks. We provide extensive empirical evidence to support our theoretical results. ", "keywords": ["Adversarial Robustness", "Adversarial Training", "Spectral Norm Regularization"], "paperhash": "roth|adversarial_training_generalizes_datadependent_spectral_norm_regularization", "original_pdf": "/attachment/7df1de0789db183ad3a5b4cbfcb648952019e520.pdf", "_bibtex": "@misc{\nroth2020adversarial,\ntitle={Adversarial Training Generalizes Data-dependent Spectral Norm Regularization},\nauthor={Kevin Roth and Yannic Kilcher and Thomas Hofmann},\nyear={2020},\nurl={https://openreview.net/forum?id=S1ervgHFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1ervgHFwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference/Paper2358/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2358/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2358/Reviewers", "ICLR.cc/2020/Conference/Paper2358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2358/Authors|ICLR.cc/2020/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504142557, "tmdate": 1576860555309, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference/Paper2358/Reviewers", "ICLR.cc/2020/Conference/Paper2358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2358/-/Official_Comment"}}}, {"id": "S1lb22MUjS", "original": null, "number": 9, "cdate": 1573428392548, "ddate": null, "tcdate": 1573428392548, "tmdate": 1573428761470, "tddate": null, "forum": "S1ervgHFwS", "replyto": "HJgdP1MIoS", "invitation": "ICLR.cc/2020/Conference/Paper2358/-/Official_Comment", "content": {"title": "Thanks for your response. Below are my ideas.", "comment": "Regarding the theoretical analysis:\nBy saying that the claim of theorem 1 is ambiguous, I mean, it\u2019s not precise. Can you give some precise condition for epsilon and alpha, like the upper bound of epsilon and lower bound of alpha for your theorem to hold even under some idealized case like two-layer ReLU network? The current way of presentation is NOT a theorem, but a proposition or intuition.\n\nRegarding the core contribution and the experiments:\nIn my opinion, I haven\u2019t found the information that this paper can take to the whole community. Like, for example, for practitioner, there is no motivations to use the current methods instead of the adversarial training, as there are several existing efficient implementations of adversarial training that the authors claimed not worse than the proposed methods. For theorists, this paper brought no idea on how to inspire and improve the theory on adversarial training and robust generalization. I expected the authors to achieve either of it, but the theories in this paper DO NOT mean to solve the theoretical problem I mentioned, and I think the proposed methods DO NOT outperform the existing baseline methods on both the efficiency and the accuracy. So I tend to reject this paper.\n\nFor the claim on the experiments, as the concerns I mentioned, if this methods do not consistently show the improvement of the current methods on the existing state-of-the-art methods, I don\u2019t find the meaning of using such of the methods. For state-of-the-art methods, I would like to see some of the top methods in https://paperswithcode.com/sota/image-classification-on-cifar-10. 93.5% clean accuracy does not mean state-of-the-art performance to me. Also, most of the experiments aims to show that the condition to show the equivalence between the proposed methods and adversarial training can be satisfied in some real world applications and give some interesting empirical observations.\n\nFor the detailed feedback on the experiments:\nI miss some of the claims in Section 5.2, so I misunderstood the purpose of Appendix A.5. Sorry for that.\n\nFor the fairness claim, the authors claimed to tune the hyper-parameters to make sure the regularization methods have the similar test accuracy. Is this shown means the result in Table 1? I tend to have as little hyper-parameters as possible. The current hyper-paremeter setting seems weird to me. Also, if 1 iteration and 10 iterations performs the same, I prefer to use 10 iterations to eliminate the potential question.\n\nIn summary, due to the reason I mentioned, I tend to reject this paper. But if all of the other reviewers think this should be accepted, I will follow their ideas."}, "signatures": ["ICLR.cc/2020/Conference/Paper2358/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2358/AnonReviewer2", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["kevin.roth@inf.ethz.ch", "yannic.kilcher@inf.ethz.ch", "thomas.hofmann@inf.ethz.ch"], "title": "Adversarial Training Generalizes Data-dependent Spectral Norm Regularization", "authors": ["Kevin Roth", "Yannic Kilcher", "Thomas Hofmann"], "pdf": "/pdf/478cde394439b29ef1fe946667fd7a1a97d5198c.pdf", "TL;DR": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks.", "abstract": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks. Specifically, we present a data-dependent variant of spectral norm regularization and prove that it is equivalent to adversarial training based on a specific $\\ell_2$-norm constrained projected gradient ascent attack. This fundamental connection confirms the long-standing argument that a network's sensitivity to adversarial examples is tied to its spectral properties and hints at novel ways to robustify and defend against adversarial attacks. We provide extensive empirical evidence to support our theoretical results. ", "keywords": ["Adversarial Robustness", "Adversarial Training", "Spectral Norm Regularization"], "paperhash": "roth|adversarial_training_generalizes_datadependent_spectral_norm_regularization", "original_pdf": "/attachment/7df1de0789db183ad3a5b4cbfcb648952019e520.pdf", "_bibtex": "@misc{\nroth2020adversarial,\ntitle={Adversarial Training Generalizes Data-dependent Spectral Norm Regularization},\nauthor={Kevin Roth and Yannic Kilcher and Thomas Hofmann},\nyear={2020},\nurl={https://openreview.net/forum?id=S1ervgHFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1ervgHFwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference/Paper2358/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2358/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2358/Reviewers", "ICLR.cc/2020/Conference/Paper2358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2358/Authors|ICLR.cc/2020/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504142557, "tmdate": 1576860555309, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference/Paper2358/Reviewers", "ICLR.cc/2020/Conference/Paper2358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2358/-/Official_Comment"}}}, {"id": "HJgdP1MIoS", "original": null, "number": 7, "cdate": 1573424991929, "ddate": null, "tcdate": 1573424991929, "tmdate": 1573424991929, "tddate": null, "forum": "S1ervgHFwS", "replyto": "B1xIuisysH", "invitation": "ICLR.cc/2020/Conference/Paper2358/-/Official_Comment", "content": {"title": "Author Response to Review (Part 1 of 3)", "comment": "*This is part 1 of 3 of our response*\n\nBefore we begin to address the individual comments, we would like to emphasize that the majority of them are already addressed in our paper, including a citation to Farzan et al. [1], which the reviewer refers to multiple times. Most importantly, Farzan et al. [1] (among many others) study \u201cspectral normalization of the DNN\u2019s weight matrices\u201d, i.e. data-INdependent SNR (similar to Yoshida & Miyato - which they also cite and which we have implemented in our paper). \n\nWe would like to stress that this is fundamentally different from what we do, which is data-dependent SNR. Notably, data-INdependent SNR can only establish and minimize a loose upper bound on the data-dependent spectral norm. In particular, it cannot account for / does not explain adversarial robustness (see Section 5.4, Figures 3 (left) and 5 (left)). \n\nOur data-dependent variant, on the other hand, is a much stronger regularizer. In fact, we show equivalence with adversarial training, which none of the other previous works can establish. Hence, the data-dependent SNR introduced in our paper is not simply a competing method, but a significant generalization.\n\nFrom reading the reviewer's comments, we believe that we may not have put enough emphasis in our paper to make this distinction clear. We hope that through this discussion, we can resolve these concerns. We will improve the writing in our paper accordingly.\n\n>> The authors only give a data-dependent version of SNR based on the Jacobian of the neural network, which I think is somewhat weak. \n\nNote that our presented d.d. SNR is a stronger notion of SNR than any of the previous works, including [1], which the reviewer refers to. \nWe show this in theory, as our method can be proven to be equivalent to AT under certain conditions, while previous work cannot do that. And we explicitly show in practice that spectral normalization of the DNN\u2019s weight matrices, as studied by [1], cannot account for adversarial robustness (see Figures 3 (left) and 5 (left)), whereas our data-dependent SNR variant does.\n\n>> The fast computational of maximum singular value with power methods have been proposed in [1]. \n\nThe power-method based computation of dominant singular values has been known for almost a century now (von Mises 1929). And even in the context of adversarial robustness, it has been studied before [1], see e.g. Yoshida & Miato (which is also cited by [1]).\n\nAs such, we do not claim power method based regularization of singular values to be a novel contribution. However, we are the first to provide a power method based formulation of AT and establish a theoretical equivalence between AT and d.d. SNR.\n\n>> The experiments are limited with specific settings that are not generally used in practice. Also, the experiment section contain several not so important information.\n\nOur model architecture and hyperparameter settings come from publically available and widely used settings and reach comparable performance to state-of-the-art models, while still being feasible to do research on without huge resource requirements.\n\nNote that our goal is not to outperform adversarial training, but to show its equivalence to d.d. SNR. We believe our experimental section does show this very thoroughly. Further, what the reviewer calls \"not so important information\" is actually extremely vital, since it shows that the conditions of our Theorem are well fulfilled in practice. If we wanted to suggest a new method for robustifying networks and improve over adversarial training, the reviewer would be entirely correct and the experimental section should look very different, but that would be contrary to our main Theorem. Our experimental section is aimed at showing that d.d. SNR corresponds to AT in a practical setting and that it does so in accordance with our theory, as we empirically confirm the conditions necessary for our theory to hold.\n\nWe have received and continue to receive praise for the thorough experimental evaluation in this paper from other researchers, precisely because it achieves what it is supposed to achieve. Hopefully, given this new perspective, the choice of our experiments makes more sense."}, "signatures": ["ICLR.cc/2020/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["kevin.roth@inf.ethz.ch", "yannic.kilcher@inf.ethz.ch", "thomas.hofmann@inf.ethz.ch"], "title": "Adversarial Training Generalizes Data-dependent Spectral Norm Regularization", "authors": ["Kevin Roth", "Yannic Kilcher", "Thomas Hofmann"], "pdf": "/pdf/478cde394439b29ef1fe946667fd7a1a97d5198c.pdf", "TL;DR": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks.", "abstract": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks. Specifically, we present a data-dependent variant of spectral norm regularization and prove that it is equivalent to adversarial training based on a specific $\\ell_2$-norm constrained projected gradient ascent attack. This fundamental connection confirms the long-standing argument that a network's sensitivity to adversarial examples is tied to its spectral properties and hints at novel ways to robustify and defend against adversarial attacks. We provide extensive empirical evidence to support our theoretical results. ", "keywords": ["Adversarial Robustness", "Adversarial Training", "Spectral Norm Regularization"], "paperhash": "roth|adversarial_training_generalizes_datadependent_spectral_norm_regularization", "original_pdf": "/attachment/7df1de0789db183ad3a5b4cbfcb648952019e520.pdf", "_bibtex": "@misc{\nroth2020adversarial,\ntitle={Adversarial Training Generalizes Data-dependent Spectral Norm Regularization},\nauthor={Kevin Roth and Yannic Kilcher and Thomas Hofmann},\nyear={2020},\nurl={https://openreview.net/forum?id=S1ervgHFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1ervgHFwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference/Paper2358/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2358/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2358/Reviewers", "ICLR.cc/2020/Conference/Paper2358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2358/Authors|ICLR.cc/2020/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504142557, "tmdate": 1576860555309, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference/Paper2358/Reviewers", "ICLR.cc/2020/Conference/Paper2358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2358/-/Official_Comment"}}}, {"id": "H1lL7yzIir", "original": null, "number": 6, "cdate": 1573424925691, "ddate": null, "tcdate": 1573424925691, "tmdate": 1573424925691, "tddate": null, "forum": "S1ervgHFwS", "replyto": "B1xIuisysH", "invitation": "ICLR.cc/2020/Conference/Paper2358/-/Official_Comment", "content": {"title": "Author Response to Review (Part 2 of 3)", "comment": "*This is part 2 of 3 of our response*\n\n>> Detailed comments:\n\n>> 1. I think the claim of theorem 1 is somewhat ambiguous. How to guarantee there exists such epsilon satisfies this condition? What will happen if \\alpha is not sufficiently large? If we don\u2019t use logits pairing and \\ell_2 norm constraint, will the claim hold? I think the correlation behinds the spectral norm and adversarial training is well investigated and use this correlation as the intuition behinds work is enough. \n\nFirst, we disagree strongly that this is well investigated and that using the correlation as an intuition is enough. Just because previous work has measured a correlation between two things does not mean further research is unnecessary. Establishing the reason behind such a correlation in a formal manner is a definite step forward in our understanding of this phenomenon. None of the previous work has been able to make this theoretical link - or even the necessary insistence that data-dependence is needed to establish this connection.\n\nTo address the specific questions. \nSince every datapoint exhibits some configuration of activations of the nonlinearities in the network, the existence of the required epsilon-ball is guaranteed by definition. \nThe requirement of alpha to be large is a weak assumption and one that is well-defined because of the projection operator. We took account of this in the paragraph following the theorem. That being said, for finite alpha, the theorem will not hold exactly, but approximately. This is why our experimental section is geared towards showing empirically (with alpha < infinity) what the theorem claims theoretically (for alpha -> infinity).\nExtending this work to other settings, such as other \\ell_p norms is a non-trivial extension to this work, which we are currently investigating. \n\n>> 2. The global SNR only needs to calculate the spectral norm of each layer\u2019s weight matrix, whose computational cost is acceptable. However, to calculate the Jacobian and use the power methods, we will additionally do several forward pass and backward pass just as AT. As a regularization technique, is this calculation tolerable? If this is some variant of AT, I don\u2019t find the experiment results support the claim that it will outperform AT consistantly.\n\nWe stress again that we never aimed at, nor claimed that, our method outperforms AT. In fact, our experiments show that they are on par, supporting our Theorem that there is a correspondence between the two.\n\nThe reviewer is correct that data-dependent SNR is computationally more costly than global SNR, which we state in our paper. In detail, one power-method iteration of d.d. SNR is as costly as one power-method iteration of global SNR, as they involve the same number of matrix-vector products. The reason why d.d. SNR is ultimately a constant factor more costly compared to global SNR is because in global SNR the computation of the regularizer is data-independent (it decouples from the empirical loss), hence the power-method iterations can be amortized across data-points. \nThat said, data-dependent SNR is equally costly as PGD-based AT. This again supports our claim that the two correspond to each other and as such, yes, the calculation is tolerable."}, "signatures": ["ICLR.cc/2020/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["kevin.roth@inf.ethz.ch", "yannic.kilcher@inf.ethz.ch", "thomas.hofmann@inf.ethz.ch"], "title": "Adversarial Training Generalizes Data-dependent Spectral Norm Regularization", "authors": ["Kevin Roth", "Yannic Kilcher", "Thomas Hofmann"], "pdf": "/pdf/478cde394439b29ef1fe946667fd7a1a97d5198c.pdf", "TL;DR": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks.", "abstract": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks. Specifically, we present a data-dependent variant of spectral norm regularization and prove that it is equivalent to adversarial training based on a specific $\\ell_2$-norm constrained projected gradient ascent attack. This fundamental connection confirms the long-standing argument that a network's sensitivity to adversarial examples is tied to its spectral properties and hints at novel ways to robustify and defend against adversarial attacks. We provide extensive empirical evidence to support our theoretical results. ", "keywords": ["Adversarial Robustness", "Adversarial Training", "Spectral Norm Regularization"], "paperhash": "roth|adversarial_training_generalizes_datadependent_spectral_norm_regularization", "original_pdf": "/attachment/7df1de0789db183ad3a5b4cbfcb648952019e520.pdf", "_bibtex": "@misc{\nroth2020adversarial,\ntitle={Adversarial Training Generalizes Data-dependent Spectral Norm Regularization},\nauthor={Kevin Roth and Yannic Kilcher and Thomas Hofmann},\nyear={2020},\nurl={https://openreview.net/forum?id=S1ervgHFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1ervgHFwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference/Paper2358/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2358/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2358/Reviewers", "ICLR.cc/2020/Conference/Paper2358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2358/Authors|ICLR.cc/2020/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504142557, "tmdate": 1576860555309, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference/Paper2358/Reviewers", "ICLR.cc/2020/Conference/Paper2358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2358/-/Official_Comment"}}}, {"id": "H1g6ACW8jS", "original": null, "number": 5, "cdate": 1573424852544, "ddate": null, "tcdate": 1573424852544, "tmdate": 1573424852544, "tddate": null, "forum": "S1ervgHFwS", "replyto": "B1xIuisysH", "invitation": "ICLR.cc/2020/Conference/Paper2358/-/Official_Comment", "content": {"title": "Author Response to Review (Part 3 of 3)", "comment": "*This is part 3 of 3 of our response*\n\n>> 3. Why don\u2019t use some standard neural network architecture like ResNet? Also, are the comparisons fair? For example, the regularization coefficient of global SNR and d.d. SNR are different. And the authors use only 1 iteration to calculate the singular value in global spectral norm regularization, why to do that? \n\n\u201cThe regularization constants were chosen such that the models achieve roughly the same test set accuracy on clean examples as the adversarially trained model does.\u201d as was clearly stated in our paper. Hence, yes, the comparisons are fair.\n\nFor global SNR, we try to stay as close as possible to the original authors' suggestions. Yoshida & Miato write \u201cOne [power method] iteration [per parameter update] was adequate in our experiments\u201d and \u201cwe performed only one [power method] iteration [per parameter update] because it was adequate for obtaining a sufficiently good approximation\u201d. Note, the computation of the data-independent regularizer decouples from the empirical loss, hence the power-method iterations can be amortized across data-points.\n\nAs stated above, our network architecture is standard, is publically available and is used throughout research.\n\n\n>> 4. The evaluation of some assumption on the network is better moved to appendix, as this is only some sanity check, not the core contribution. More experiments with ResNet, WideResNet, MobileNet etc. on CIFAR100 and ImageNet are more convincing.\n\nFirstly, it is unclear what evaluation of assumptions the reviewer is referring to. Secondly, we sincerely do not expect to see any difference regarding the correspondence \u201cAT <-> d.d. SNR\u201d on other architectures / data sets. Our theorem proves that \\ell_2-norm constrained PGA-based AT and d.d. SNR are equivalent for small enough epsilon, while our extensive experiments show that in practice, the correspondence between AT and d.d. SNR holds approximately in a region much larger than proved in the Theorem, the region being roughly the size of the epsilon*-ball used during adversarial training (epsilon* = 1.75 >> epsilon in Theorem), see Figure 2 (left) and discussion in Section 5.3 \u201cValidity of linear approximation\u201d. \n\nSure, more experiments can always be requested, but we believe that confirming our main claims in practice is more important and valuable than including one further architecture or dataset. Please also consider our comments from the \"general comments\" section at the beginning of this review on this topic.\n\n\n>> 5. What\u2019s the attack method in the main context?\n\nWe evaluated against \\ell_2-norm constrained PGA in the main text, as stated in Section 5.1 and Table 1. Additional results for \\ell_\\infty PGA attack are provided in the Appendix.\n\n\n>> 6. The discussion in Appendix A.5 is somewhat confusing. If the authors want to argue that the network is locally linear so that we can approximate with linear regression, why should we use the power methods?\n\nWe use the power method during training, since we only need access to the dominant singular vector. In the experiment section, we more generally study the spectral properties of the Jacobian, requiring us to compute the full spectrum and not just the dominant singular value / vector pair. The full spectral decomposition requires much more computation and is only viable when evaluating / investigating certain properties, not during training. We very clearly stated this in the first paragraph of Section 5.1.\n\n\n>> \"Still, I feel the contribution of this paper is somewhat weak. I don\u2019t see any improvements of the proposed algorithms compared with the standard adversarial training, as well as the theoretical contribution like adversarial generalization. The experiments are not convincing, as the setting is different from the general setting the community used in adversarial training. I\u2019m not familiar with the results in global spectral normalization and it\u2019s possible that the global spectral normalization may have little gain in adversarial robustness, but in my opinion, the main contribution [1] is the generalization analysis of spectral normalized adversarial trained neural networks, which this paper lacks. On the empirical side, the computation efficiency and performance of the proposed algorithms don\u2019t outperform adversarial training much. So I tend to reject this paper.\"\n\nAgain, we 1. do not claim to outperform AT, we claim to show its correspondence to d.d. SNR and 2. we show this correspondence in a theoretical way that no previous work has managed to establish. Our experimental section reflects and supports these points very well. Also, we are not in a competition with [1].\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["kevin.roth@inf.ethz.ch", "yannic.kilcher@inf.ethz.ch", "thomas.hofmann@inf.ethz.ch"], "title": "Adversarial Training Generalizes Data-dependent Spectral Norm Regularization", "authors": ["Kevin Roth", "Yannic Kilcher", "Thomas Hofmann"], "pdf": "/pdf/478cde394439b29ef1fe946667fd7a1a97d5198c.pdf", "TL;DR": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks.", "abstract": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks. Specifically, we present a data-dependent variant of spectral norm regularization and prove that it is equivalent to adversarial training based on a specific $\\ell_2$-norm constrained projected gradient ascent attack. This fundamental connection confirms the long-standing argument that a network's sensitivity to adversarial examples is tied to its spectral properties and hints at novel ways to robustify and defend against adversarial attacks. We provide extensive empirical evidence to support our theoretical results. ", "keywords": ["Adversarial Robustness", "Adversarial Training", "Spectral Norm Regularization"], "paperhash": "roth|adversarial_training_generalizes_datadependent_spectral_norm_regularization", "original_pdf": "/attachment/7df1de0789db183ad3a5b4cbfcb648952019e520.pdf", "_bibtex": "@misc{\nroth2020adversarial,\ntitle={Adversarial Training Generalizes Data-dependent Spectral Norm Regularization},\nauthor={Kevin Roth and Yannic Kilcher and Thomas Hofmann},\nyear={2020},\nurl={https://openreview.net/forum?id=S1ervgHFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1ervgHFwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference/Paper2358/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2358/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2358/Reviewers", "ICLR.cc/2020/Conference/Paper2358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2358/Authors|ICLR.cc/2020/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504142557, "tmdate": 1576860555309, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference/Paper2358/Reviewers", "ICLR.cc/2020/Conference/Paper2358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2358/-/Official_Comment"}}}, {"id": "HJxvL6Z8iB", "original": null, "number": 4, "cdate": 1573424462676, "ddate": null, "tcdate": 1573424462676, "tmdate": 1573424462676, "tddate": null, "forum": "S1ervgHFwS", "replyto": "B1laVbdjYH", "invitation": "ICLR.cc/2020/Conference/Paper2358/-/Official_Comment", "content": {"title": "Author Response to Review (Part 1 of 2)", "comment": "*This is part 1 of 2 of our response*\n\nWe would like to thank the reviewer for these comments. We hope that with our detailed answers below we can initiate a fruitful discussion that resolves all concerns.\n\nGeneral Concerns: \n\n(i) limited theoretical results \n\nNote that while our Theorem establishes an exact equivalence for sufficiently small epsilon, as noted by the reviewer, we verified in extensive experiments that in practice the correspondence between AT and d.d. SNR holds up very well in a region much larger than proven in our Theorem, specifically large enough to cover common use cases. Therefore, the conclusions of our theory are directly relevant to practitioners.\n\n(ii) No significant improvement for practical algorithm\n\nWe would like to stress that we never claimed that d.d. SNR outperforms AT. The main point of our Theorem (indeed our paper) is that there is a correspondence between the two. In fact, it would be contrary to our main claim if one would outperform the other, be that in terms of final adversarial robustness or computational complexity. We believe that our paper shows this equivalence in theory and practice and thereby increases the understanding of adversarial robustness.\n\n\nSpecific Concerns:\n\n>> Main theorem is only valid for small perturbations, unclear how this assumption relates to practice.\n\nThe condition on epsilon in the Theorem guarantees that the Jacobian is fixed for all x* with ||x* - x|| <= epsilon, in which case the correspondence between \\ell_2 norm constrained PGA-based AT and data-dependent SNR was proven to be an exact equivalence. \n\nIn practice, however, the correspondence between AT and d.d. SNR holds approximately in a region much larger than proved in the Theorem: As shown in Figure 2 (left) and discussed in Section 5.3 \u201cValidity of linear approximation\u201d, we verified that the Jacobian is almost constant in a region that is roughly the size of the epsilon*-ball used during adversarial training (epsilon* = 1.75 >> epsilon in Theorem).\n\nThe correspondence is in fact consistently supported by all our experiments. In Section 5.4 Adversarial Robustness, for instance, we show that a network trained with d.d. SNR is equally robust to adversarial perturbations with varying magnitude as the PGA trained network is.\n\nIn other words, the Theorem is applicable in practice as long as the Jacobian of the network remains approximately constant in the epsilon-ball under consideration. We will add a paragraph below the Theorem to make this clear.\n\n\n>> It is unclear how the assumption \\alpha \\to \\infty influences the practical algorithm.\n\nWe elaborate on the condition on \\alpha in the paragraph below Theorem 1: \u201cin the update equation for x_k all the weight [if \\alpha -> \\infty] is placed on the current gradient direction v_k whereas no weight is put on the previous iterate x_{k\u22121}\u201d. Note that because of the projection operator, the limit case is well defined.\n\nMathematically, lim_{\\alpha \\to \\infty} \\Proj ( x_{k-1} + \\alpha*v_k ) is equivalent to lim_{\\alpha \\to \\infty} \\Proj ( 1/alpha*x_{k-1} + v_k ).\nTherefore, in the practical algorithm, instead of letting the prefactor \\alpha in front of v_k go to \\infty, we can equivalently let the prefactor 1/alpha in front of x_{k-1} go to zero, see Equations (18)-(24) in Appendix 7.2 \u201cProof of Main Theorem\u201d.\n\nThe key insight of our experiments Section is that there is no significant difference between adversarial training with small \\alpha and data-dependent spectral norm regularization (corresponding to AT with \\alpha -> \\inty). Both have a similar regularizing effect on the spectrum, similar local linearity, similar adversarial robustness. This supports our claim that the effect of AT is captured by d.d. SNR.\n\n\n>> Generalize theorem to other \\ell_p norms.\n\nThis is a non-trivial generalization that we are currently investigating for a future publication."}, "signatures": ["ICLR.cc/2020/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["kevin.roth@inf.ethz.ch", "yannic.kilcher@inf.ethz.ch", "thomas.hofmann@inf.ethz.ch"], "title": "Adversarial Training Generalizes Data-dependent Spectral Norm Regularization", "authors": ["Kevin Roth", "Yannic Kilcher", "Thomas Hofmann"], "pdf": "/pdf/478cde394439b29ef1fe946667fd7a1a97d5198c.pdf", "TL;DR": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks.", "abstract": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks. Specifically, we present a data-dependent variant of spectral norm regularization and prove that it is equivalent to adversarial training based on a specific $\\ell_2$-norm constrained projected gradient ascent attack. This fundamental connection confirms the long-standing argument that a network's sensitivity to adversarial examples is tied to its spectral properties and hints at novel ways to robustify and defend against adversarial attacks. We provide extensive empirical evidence to support our theoretical results. ", "keywords": ["Adversarial Robustness", "Adversarial Training", "Spectral Norm Regularization"], "paperhash": "roth|adversarial_training_generalizes_datadependent_spectral_norm_regularization", "original_pdf": "/attachment/7df1de0789db183ad3a5b4cbfcb648952019e520.pdf", "_bibtex": "@misc{\nroth2020adversarial,\ntitle={Adversarial Training Generalizes Data-dependent Spectral Norm Regularization},\nauthor={Kevin Roth and Yannic Kilcher and Thomas Hofmann},\nyear={2020},\nurl={https://openreview.net/forum?id=S1ervgHFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1ervgHFwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference/Paper2358/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2358/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2358/Reviewers", "ICLR.cc/2020/Conference/Paper2358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2358/Authors|ICLR.cc/2020/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504142557, "tmdate": 1576860555309, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference/Paper2358/Reviewers", "ICLR.cc/2020/Conference/Paper2358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2358/-/Official_Comment"}}}, {"id": "r1lbZ6bUir", "original": null, "number": 3, "cdate": 1573424377255, "ddate": null, "tcdate": 1573424377255, "tmdate": 1573424377255, "tddate": null, "forum": "S1ervgHFwS", "replyto": "B1laVbdjYH", "invitation": "ICLR.cc/2020/Conference/Paper2358/-/Official_Comment", "content": {"title": "Author Response to Review (Part 2 of 2)", "comment": "*This is part 2 of 2 of our response*\n\n>> Discussion of computational complexity of the proposed regularization method compared to PGD.\n\nIn the last sentence of Section 4.1 we compare the computational complexity of d.d. SNR with that of global (data-independent) SNR. \n\nCompared to PGD, d.d. SNR is equally computationally expensive. As stated in Table 1, both PGD and d.d. SNR were implemented with 10 iterations. Since our main claim is to show equivalence of the two methods, this is a valuable piece of information. We will add a sentence to the paper to emphasize this point.\n\n\n>> Many other types of regularization decreases the (local) Lipschitz constant. Could you further give result that distinguishes the proposed norm?\n\nIndeed there are many works that aim at regularizing the Lipschitz constant. However, these works mostly focus on decreasing the global Lipschitz constant, which corresponds to data-independent SNR and gives only a loose bound on adversarial robustness. We would like to stress that this is different from (and weaker than) our presented data-dependent SNR.\n\nOne of the main points in our paper, especially our experiments, is that the Lipschitz regularization of previous work cannot account for / does not explain adversarial robustness (see Section 5.4, Figures 3 (left) and 5 (left)). The data-dependent SNR variant introduced in our paper is a novel and significant generalization and the first type of SNR that is equivalent to AT.\n\n\n>> It would be better to give improved algorithm for adversarial training based on the current result. The current contribution for further theoretical is too weak and I don\u2019t see significant contribution to empirical algorithm.\n\nAs we stated above, it is not our goal to improve the practical algorithm of adversarial training, but to show its correspondence to data-dependent SNR. In fact, it would be contrary to our main result to try to improve the practical algorithm.\n\nOther than that, we do not understand what the reviewer means by his or her request. Please elaborate.\n\n\n>> Equ (10) seems not the typical one used and seems not the one studied later.\n\nWe do study this equation for p=2. See also Equations (33) and (34) in the Appendix, where we show that Equation (10) reduces to Equation (7) under the conditions of our Theorem.\n\nPerhaps the reviewer refers to the setting in which the network is trained to only minimize the adversarially perturbed empirical loss. It is however customary to train the network to minimize a convex combination of a clean empirical loss and an adversarially perturbed empirical loss, see the equation on page 5 in Goodfellow et al. \u201cExplaining and harnessing adversarial examples\u201d.\n\n\nIn conclusion, we agree that our Theorem makes strong assumptions, but we believe that 1. it is valuable to be on record and theoretically confirm this long-standing hypothesis and 2. we show extensively that the claim of the Theorem holds well beyond its assumptions in practice. As for improving over AT in the practical sense, we never claim to do so, and it would actually run contrary to our claim.\n\nWe hope that these comments provide clarification and we look forward to continuing the discussion.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["kevin.roth@inf.ethz.ch", "yannic.kilcher@inf.ethz.ch", "thomas.hofmann@inf.ethz.ch"], "title": "Adversarial Training Generalizes Data-dependent Spectral Norm Regularization", "authors": ["Kevin Roth", "Yannic Kilcher", "Thomas Hofmann"], "pdf": "/pdf/478cde394439b29ef1fe946667fd7a1a97d5198c.pdf", "TL;DR": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks.", "abstract": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks. Specifically, we present a data-dependent variant of spectral norm regularization and prove that it is equivalent to adversarial training based on a specific $\\ell_2$-norm constrained projected gradient ascent attack. This fundamental connection confirms the long-standing argument that a network's sensitivity to adversarial examples is tied to its spectral properties and hints at novel ways to robustify and defend against adversarial attacks. We provide extensive empirical evidence to support our theoretical results. ", "keywords": ["Adversarial Robustness", "Adversarial Training", "Spectral Norm Regularization"], "paperhash": "roth|adversarial_training_generalizes_datadependent_spectral_norm_regularization", "original_pdf": "/attachment/7df1de0789db183ad3a5b4cbfcb648952019e520.pdf", "_bibtex": "@misc{\nroth2020adversarial,\ntitle={Adversarial Training Generalizes Data-dependent Spectral Norm Regularization},\nauthor={Kevin Roth and Yannic Kilcher and Thomas Hofmann},\nyear={2020},\nurl={https://openreview.net/forum?id=S1ervgHFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1ervgHFwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference/Paper2358/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2358/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2358/Reviewers", "ICLR.cc/2020/Conference/Paper2358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2358/Authors|ICLR.cc/2020/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504142557, "tmdate": 1576860555309, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference/Paper2358/Reviewers", "ICLR.cc/2020/Conference/Paper2358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2358/-/Official_Comment"}}}, {"id": "B1eJ6jbIjS", "original": null, "number": 2, "cdate": 1573424055010, "ddate": null, "tcdate": 1573424055010, "tmdate": 1573424055010, "tddate": null, "forum": "S1ervgHFwS", "replyto": "SyeD7eqHcH", "invitation": "ICLR.cc/2020/Conference/Paper2358/-/Official_Comment", "content": {"title": "Author Response to Review", "comment": "Dear Reviewer\nWe would like to thank you for your comments.\nYour feedback is highly appreciated."}, "signatures": ["ICLR.cc/2020/Conference/Paper2358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["kevin.roth@inf.ethz.ch", "yannic.kilcher@inf.ethz.ch", "thomas.hofmann@inf.ethz.ch"], "title": "Adversarial Training Generalizes Data-dependent Spectral Norm Regularization", "authors": ["Kevin Roth", "Yannic Kilcher", "Thomas Hofmann"], "pdf": "/pdf/478cde394439b29ef1fe946667fd7a1a97d5198c.pdf", "TL;DR": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks.", "abstract": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks. Specifically, we present a data-dependent variant of spectral norm regularization and prove that it is equivalent to adversarial training based on a specific $\\ell_2$-norm constrained projected gradient ascent attack. This fundamental connection confirms the long-standing argument that a network's sensitivity to adversarial examples is tied to its spectral properties and hints at novel ways to robustify and defend against adversarial attacks. We provide extensive empirical evidence to support our theoretical results. ", "keywords": ["Adversarial Robustness", "Adversarial Training", "Spectral Norm Regularization"], "paperhash": "roth|adversarial_training_generalizes_datadependent_spectral_norm_regularization", "original_pdf": "/attachment/7df1de0789db183ad3a5b4cbfcb648952019e520.pdf", "_bibtex": "@misc{\nroth2020adversarial,\ntitle={Adversarial Training Generalizes Data-dependent Spectral Norm Regularization},\nauthor={Kevin Roth and Yannic Kilcher and Thomas Hofmann},\nyear={2020},\nurl={https://openreview.net/forum?id=S1ervgHFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1ervgHFwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference/Paper2358/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2358/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2358/Reviewers", "ICLR.cc/2020/Conference/Paper2358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2358/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2358/Authors|ICLR.cc/2020/Conference/Paper2358/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504142557, "tmdate": 1576860555309, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2358/Authors", "ICLR.cc/2020/Conference/Paper2358/Reviewers", "ICLR.cc/2020/Conference/Paper2358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2358/-/Official_Comment"}}}, {"id": "B1xIuisysH", "original": null, "number": 3, "cdate": 1573006189878, "ddate": null, "tcdate": 1573006189878, "tmdate": 1573006189878, "tddate": null, "forum": "S1ervgHFwS", "replyto": "S1ervgHFwS", "invitation": "ICLR.cc/2020/Conference/Paper2358/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #2", "review": "Adversarial training generalizes data-dependent spectral norm regularization\n\nThis paper shows that, projected gradient descent based adversarial training is similar to the data-dependent spectral norm regularization, and under very restrictive condition, the authors show that this two methods are the same. Some experiments are conducted to support the theory.\n\nOverall, I think this paper is marginal, while the experiments are not convincing. First, the relation between spectral normalization and adversarial training have been investigated by [1], while the fast computational of maximum singular value with power methods have also been proposed in [1]. The authors only give a data-dependent version of the spectral normalization based on the Jacobian of the neural networks, which I think is somewhat weak. The experiments are limited with specific settings that are not generally used in practice, which alleviate my confidence on this paper\u2019s results. Also, the experiment section contain several not so important information. I think the authors should do far more experiments to support the main claim, while move these additional justification to the appendix.\n\nDetailed comments:\n1. I think the claim of theorem 1 is somewhat ambiguous. How to guarantee there exists such epsilon satisfies this condition? Is this the case we face in the real world? What will happen if \\alpha is not sufficiently large? If we don\u2019t use logits pairing and \\ell_2 norm constraint, will the claim hold? I think the correlation behinds the spectral norm and adversarial training is well investigated and use this correlation as the intuition behinds work is enough. This theorem cannot convince me that the proposed methods have a strong theoretical basis.\n2. Generally, the neural networks have a large number of parameters (~ millions) for image classification task. The global spectral norm regularization only needs to calculate the spectral norm of each layer\u2019s weight matrix, whose computational cost is acceptable. However, to calculate the Jacobian and use the power methods, we will additionally do several forward pass and backward pass just as adversarial training. As a regularization technique, is this calculation tolerable? If this is some variant of the adversarial training, I don\u2019t find the experiment results support the claim that it will outperform the adversarial training consistantly.\n3. Why don\u2019t use some standard neural network architecture like ResNet? As this results is not comparable to other existing work, I\u2019m not sure if this result is meaningful. Also, are the comparisons fair? For example, the regularization coefficient of global spectral norm regularization and data-dependent spectral norm regularization are far more different. And the authors use only 1 iteration to calculate the singular value in global spectral norm regularization, why to do that? Also, what\u2019s the result compared with \\ell_p norm constraint adversarial training?\n4. The evaluation of some assumption on the network is better moved to appendix, as this is only some sanity check, not the core contribution. More experiments with ResNet, WideResNet, MobileNet etc. on CIFAR100 and ImageNet are more convincing.\n5. What\u2019s the attack method in the main context?\n6. I think the discussion in Appendix A.5 is somewhat confusing. If the authors want to argue that the network is locally linear so that we can approximate with linear regression, why should we use the power methods?\n\nStill, I feel the contribution of this paper is somewhat weak. I don\u2019t see any improvements of the proposed algorithms compared with the standard adversarial training, as well as the theoretical contribution like adversarial generalization. The experiments are not convincing, as the setting is different from the general setting the community used in adversarial training. I\u2019m not familiar with the results in global spectral normalization and it\u2019s possible that the global spectral normalization may have little gain in adversarial robustness, but in my opinion, the main contribution [1] is the generalization analysis of spectral normalized adversarial trained neural networks, which this paper lacks. On the empirical side, the computation efficiency and performance of the proposed algorithms don\u2019t outperform adversarial training much. So I tend to reject this paper.\n\n\n[1] Farnia, Farzan, Jesse Zhang, and David Tse. \"Generalizable Adversarial Training via Spectral Normalization.\" International Conference on Learning Representations, 2019.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper2358/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2358/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["kevin.roth@inf.ethz.ch", "yannic.kilcher@inf.ethz.ch", "thomas.hofmann@inf.ethz.ch"], "title": "Adversarial Training Generalizes Data-dependent Spectral Norm Regularization", "authors": ["Kevin Roth", "Yannic Kilcher", "Thomas Hofmann"], "pdf": "/pdf/478cde394439b29ef1fe946667fd7a1a97d5198c.pdf", "TL;DR": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks.", "abstract": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks. Specifically, we present a data-dependent variant of spectral norm regularization and prove that it is equivalent to adversarial training based on a specific $\\ell_2$-norm constrained projected gradient ascent attack. This fundamental connection confirms the long-standing argument that a network's sensitivity to adversarial examples is tied to its spectral properties and hints at novel ways to robustify and defend against adversarial attacks. We provide extensive empirical evidence to support our theoretical results. ", "keywords": ["Adversarial Robustness", "Adversarial Training", "Spectral Norm Regularization"], "paperhash": "roth|adversarial_training_generalizes_datadependent_spectral_norm_regularization", "original_pdf": "/attachment/7df1de0789db183ad3a5b4cbfcb648952019e520.pdf", "_bibtex": "@misc{\nroth2020adversarial,\ntitle={Adversarial Training Generalizes Data-dependent Spectral Norm Regularization},\nauthor={Kevin Roth and Yannic Kilcher and Thomas Hofmann},\nyear={2020},\nurl={https://openreview.net/forum?id=S1ervgHFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "S1ervgHFwS", "replyto": "S1ervgHFwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2358/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2358/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575693389966, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2358/Reviewers"], "noninvitees": [], "tcdate": 1570237723965, "tmdate": 1575693389979, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2358/-/Official_Review"}}}, {"id": "B1laVbdjYH", "original": null, "number": 1, "cdate": 1571680564688, "ddate": null, "tcdate": 1571680564688, "tmdate": 1572972348826, "tddate": null, "forum": "S1ervgHFwS", "replyto": "S1ervgHFwS", "invitation": "ICLR.cc/2020/Conference/Paper2358/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper studies the link between adversarial training and the proposed data-dependent operator norm regularization for ReLU network. Under specific conditions, in theory, the authors show the equivalence between the l2 PGD training and the regularization method. Empirical experiments are conducted to support the theory.\n\nWhile this paper gives interesting observation on both theory and empirical study, I think this paper is not qualified for publishing in ICLR due to the following reasons: (1) limited theoretical results; (2) No significant improvement for practical algorithm;\n\nMain argument:\n\nThe main theorem 1 seems to be weak as it is only valid for small perturbation region \\epsilon and it is unclear how this assumption is consistent to the practice. It is also unclear how the assumption that \\alpha \\to \\infty influences the practical algorithm.\n\nIt would be better to generalize the theorem to other \\ell_p attack, instead of just \\ell_2. \n\nDiscussion of computational complexity of the proposed regularization method compared with PGD is missed.\n\nThe adversarial robustness is related to the (local) Lipschitz continuity and many other types of regularization decreases the (local) Lipschitz constant. Could you further give result that distinguishes the proposed norm?\n\nIt would be better to give improved algorithm for adversarial training based on the current result. The current contribution for further theoretical is too weak as the main theorem requires strong assumption. And I don\u2019t see significant contribution to empirical algorithm.\n\n\nMinor\nEqu (10) seems not the typical one used and seems not the one studied later.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2358/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2358/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["kevin.roth@inf.ethz.ch", "yannic.kilcher@inf.ethz.ch", "thomas.hofmann@inf.ethz.ch"], "title": "Adversarial Training Generalizes Data-dependent Spectral Norm Regularization", "authors": ["Kevin Roth", "Yannic Kilcher", "Thomas Hofmann"], "pdf": "/pdf/478cde394439b29ef1fe946667fd7a1a97d5198c.pdf", "TL;DR": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks.", "abstract": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks. Specifically, we present a data-dependent variant of spectral norm regularization and prove that it is equivalent to adversarial training based on a specific $\\ell_2$-norm constrained projected gradient ascent attack. This fundamental connection confirms the long-standing argument that a network's sensitivity to adversarial examples is tied to its spectral properties and hints at novel ways to robustify and defend against adversarial attacks. We provide extensive empirical evidence to support our theoretical results. ", "keywords": ["Adversarial Robustness", "Adversarial Training", "Spectral Norm Regularization"], "paperhash": "roth|adversarial_training_generalizes_datadependent_spectral_norm_regularization", "original_pdf": "/attachment/7df1de0789db183ad3a5b4cbfcb648952019e520.pdf", "_bibtex": "@misc{\nroth2020adversarial,\ntitle={Adversarial Training Generalizes Data-dependent Spectral Norm Regularization},\nauthor={Kevin Roth and Yannic Kilcher and Thomas Hofmann},\nyear={2020},\nurl={https://openreview.net/forum?id=S1ervgHFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "S1ervgHFwS", "replyto": "S1ervgHFwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2358/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2358/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575693389966, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2358/Reviewers"], "noninvitees": [], "tcdate": 1570237723965, "tmdate": 1575693389979, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2358/-/Official_Review"}}}, {"id": "SyeD7eqHcH", "original": null, "number": 2, "cdate": 1572343838566, "ddate": null, "tcdate": 1572343838566, "tmdate": 1572972348790, "tddate": null, "forum": "S1ervgHFwS", "replyto": "S1ervgHFwS", "invitation": "ICLR.cc/2020/Conference/Paper2358/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This largely theretical paper establishes a theoretical link between adversarial training and operator norm regularization\nfor DNNs. It is well written and structured, and it falls squarely within the the remit of the conference. The experimental apparatus is thorough and the derivations, proofs and the maths at large seem sound to me, even if I have not checked them in full detail. The study delivers a data-dependent variant of spectral norm regularization affecting large singular values of the DNN. It is proved to be equivalent to adversarial training based on a type of norm-constrained projected gradient ascent attack.\nResults are novel and relevant and, in my opinion, they merit acceptance."}, "signatures": ["ICLR.cc/2020/Conference/Paper2358/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2358/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["kevin.roth@inf.ethz.ch", "yannic.kilcher@inf.ethz.ch", "thomas.hofmann@inf.ethz.ch"], "title": "Adversarial Training Generalizes Data-dependent Spectral Norm Regularization", "authors": ["Kevin Roth", "Yannic Kilcher", "Thomas Hofmann"], "pdf": "/pdf/478cde394439b29ef1fe946667fd7a1a97d5198c.pdf", "TL;DR": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks.", "abstract": "We establish a theoretical link between adversarial training and operator norm regularization for deep neural networks. Specifically, we present a data-dependent variant of spectral norm regularization and prove that it is equivalent to adversarial training based on a specific $\\ell_2$-norm constrained projected gradient ascent attack. This fundamental connection confirms the long-standing argument that a network's sensitivity to adversarial examples is tied to its spectral properties and hints at novel ways to robustify and defend against adversarial attacks. We provide extensive empirical evidence to support our theoretical results. ", "keywords": ["Adversarial Robustness", "Adversarial Training", "Spectral Norm Regularization"], "paperhash": "roth|adversarial_training_generalizes_datadependent_spectral_norm_regularization", "original_pdf": "/attachment/7df1de0789db183ad3a5b4cbfcb648952019e520.pdf", "_bibtex": "@misc{\nroth2020adversarial,\ntitle={Adversarial Training Generalizes Data-dependent Spectral Norm Regularization},\nauthor={Kevin Roth and Yannic Kilcher and Thomas Hofmann},\nyear={2020},\nurl={https://openreview.net/forum?id=S1ervgHFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "S1ervgHFwS", "replyto": "S1ervgHFwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2358/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2358/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575693389966, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2358/Reviewers"], "noninvitees": [], "tcdate": 1570237723965, "tmdate": 1575693389979, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2358/-/Official_Review"}}}], "count": 16}