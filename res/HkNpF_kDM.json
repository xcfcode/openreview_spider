{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124456276, "tcdate": 1518467516343, "number": 252, "cdate": 1518467516343, "id": "HkNpF_kDM", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "HkNpF_kDM", "signatures": ["~Damien_Scieur1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Nonlinear Acceleration of CNNs", "abstract": "Regularized Nonlinear Acceleration (RNA) can improve the rate of convergence of many optimization schemes such as gradient descent, SAGA or SVRG, estimating the optimum using a nonlinear average of past iterates. Until now, its analysis was limited to convex problems, but empirical observations show that RNA may be extended to a broader setting. Here, we investigate the benefits of nonlinear acceleration when applied to the training of neural networks, in particular for the task of image recognition on the CIFAR10 and ImageNet data sets. In our experiments, with minimal modifications to existing frameworks, RNA speeds up convergence and improves testing error on standard CNNs.", "paperhash": "scieur|nonlinear_acceleration_of_cnns", "_bibtex": "@misc{\n  scieur2018nonlinear,\n  title={Nonlinear Acceleration of CNNs},\n  author={Damien Scieur and Edouard Oyallon and Alexandre d\u2019Aspremont and Francis Bach},\n  year={2018},\n  url={https://openreview.net/forum?id=HkNpF_kDM}\n}", "authorids": ["damien.scieur@inria.fr", "edouard.oyallon@centralesupelec.fr", "aspremon@ens.fr", "francis.bach@inria.fr"], "authors": ["Damien Scieur", "Edouard Oyallon", "Alexandre d\u2019Aspremont", "Francis Bach"], "keywords": [], "pdf": "/pdf/42b31e10e754ef17eb0b7026f76e0e2e3d4fd9f5.pdf"}, "nonreaders": [], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "tmdate": 1521753035414, "tcdate": 1521753035414, "number": 4, "cdate": 1521753035414, "id": "Sk70o5ZcM", "invitation": "ICLR.cc/2018/Workshop/-/Paper252/Public_Comment", "forum": "HkNpF_kDM", "replyto": "HkNpF_kDM", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Public Code", "comment": "The code can be downloaded here: \nhttps://github.com/windows7lover/RegularizedNonlinearAcceleration\n\nThis includes:\n- The implementation of the RNA algorithm\n- A tutorial code which shows how to use the algorithm (on mnist)\n- The experimental code which reproduces the experiments on CIFAR10"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Nonlinear Acceleration of CNNs", "abstract": "Regularized Nonlinear Acceleration (RNA) can improve the rate of convergence of many optimization schemes such as gradient descent, SAGA or SVRG, estimating the optimum using a nonlinear average of past iterates. Until now, its analysis was limited to convex problems, but empirical observations show that RNA may be extended to a broader setting. Here, we investigate the benefits of nonlinear acceleration when applied to the training of neural networks, in particular for the task of image recognition on the CIFAR10 and ImageNet data sets. In our experiments, with minimal modifications to existing frameworks, RNA speeds up convergence and improves testing error on standard CNNs.", "paperhash": "scieur|nonlinear_acceleration_of_cnns", "_bibtex": "@misc{\n  scieur2018nonlinear,\n  title={Nonlinear Acceleration of CNNs},\n  author={Damien Scieur and Edouard Oyallon and Alexandre d\u2019Aspremont and Francis Bach},\n  year={2018},\n  url={https://openreview.net/forum?id=HkNpF_kDM}\n}", "authorids": ["damien.scieur@inria.fr", "edouard.oyallon@centralesupelec.fr", "aspremon@ens.fr", "francis.bach@inria.fr"], "authors": ["Damien Scieur", "Edouard Oyallon", "Alexandre d\u2019Aspremont", "Francis Bach"], "keywords": [], "pdf": "/pdf/42b31e10e754ef17eb0b7026f76e0e2e3d4fd9f5.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712624212, "id": "ICLR.cc/2018/Workshop/-/Paper252/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper252/Reviewers"], "reply": {"replyto": null, "forum": "HkNpF_kDM", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712624212}}}, {"tddate": null, "ddate": null, "tmdate": 1521752921582, "tcdate": 1521752921582, "number": 3, "cdate": 1521752921582, "id": "ByzPocZqz", "invitation": "ICLR.cc/2018/Workshop/-/Paper252/Public_Comment", "forum": "HkNpF_kDM", "replyto": "HyaPFQ8Kf", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Thank you for your review", "comment": "Dear Reviewer,\n\nthank you for your positive feedback. We are still working on this project, and we also hope that other researchers will use this technique in the future."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Nonlinear Acceleration of CNNs", "abstract": "Regularized Nonlinear Acceleration (RNA) can improve the rate of convergence of many optimization schemes such as gradient descent, SAGA or SVRG, estimating the optimum using a nonlinear average of past iterates. Until now, its analysis was limited to convex problems, but empirical observations show that RNA may be extended to a broader setting. Here, we investigate the benefits of nonlinear acceleration when applied to the training of neural networks, in particular for the task of image recognition on the CIFAR10 and ImageNet data sets. In our experiments, with minimal modifications to existing frameworks, RNA speeds up convergence and improves testing error on standard CNNs.", "paperhash": "scieur|nonlinear_acceleration_of_cnns", "_bibtex": "@misc{\n  scieur2018nonlinear,\n  title={Nonlinear Acceleration of CNNs},\n  author={Damien Scieur and Edouard Oyallon and Alexandre d\u2019Aspremont and Francis Bach},\n  year={2018},\n  url={https://openreview.net/forum?id=HkNpF_kDM}\n}", "authorids": ["damien.scieur@inria.fr", "edouard.oyallon@centralesupelec.fr", "aspremon@ens.fr", "francis.bach@inria.fr"], "authors": ["Damien Scieur", "Edouard Oyallon", "Alexandre d\u2019Aspremont", "Francis Bach"], "keywords": [], "pdf": "/pdf/42b31e10e754ef17eb0b7026f76e0e2e3d4fd9f5.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712624212, "id": "ICLR.cc/2018/Workshop/-/Paper252/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper252/Reviewers"], "reply": {"replyto": null, "forum": "HkNpF_kDM", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712624212}}}, {"tddate": null, "ddate": null, "tmdate": 1521752620851, "tcdate": 1521752620851, "number": 2, "cdate": 1521752620851, "id": "H1BN99Z5f", "invitation": "ICLR.cc/2018/Workshop/-/Paper252/Public_Comment", "forum": "HkNpF_kDM", "replyto": "BymWnYpOM", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Thank you for your review", "comment": "Dear Reviewer,\n\nthank you for your feedback. In fact, solving (R^T R+lambda I)z = 1 is extremely quick and easy. The size of the system is independent of the number of parameters. In fact, it grows in K^2 where K is the epoch counter, bounded by 10 in our experiments. The \"difficult part\" is the matrix multiplication R^T * R, which takes O(K^2 d) operations\u00a8, where d is the number of parameters. In practice, this adds a negligible computation time, so we can easily compute the extrapolated model in parrallel on a CPU, without slowing down the learning algorithm."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Nonlinear Acceleration of CNNs", "abstract": "Regularized Nonlinear Acceleration (RNA) can improve the rate of convergence of many optimization schemes such as gradient descent, SAGA or SVRG, estimating the optimum using a nonlinear average of past iterates. Until now, its analysis was limited to convex problems, but empirical observations show that RNA may be extended to a broader setting. Here, we investigate the benefits of nonlinear acceleration when applied to the training of neural networks, in particular for the task of image recognition on the CIFAR10 and ImageNet data sets. In our experiments, with minimal modifications to existing frameworks, RNA speeds up convergence and improves testing error on standard CNNs.", "paperhash": "scieur|nonlinear_acceleration_of_cnns", "_bibtex": "@misc{\n  scieur2018nonlinear,\n  title={Nonlinear Acceleration of CNNs},\n  author={Damien Scieur and Edouard Oyallon and Alexandre d\u2019Aspremont and Francis Bach},\n  year={2018},\n  url={https://openreview.net/forum?id=HkNpF_kDM}\n}", "authorids": ["damien.scieur@inria.fr", "edouard.oyallon@centralesupelec.fr", "aspremon@ens.fr", "francis.bach@inria.fr"], "authors": ["Damien Scieur", "Edouard Oyallon", "Alexandre d\u2019Aspremont", "Francis Bach"], "keywords": [], "pdf": "/pdf/42b31e10e754ef17eb0b7026f76e0e2e3d4fd9f5.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712624212, "id": "ICLR.cc/2018/Workshop/-/Paper252/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper252/Reviewers"], "reply": {"replyto": null, "forum": "HkNpF_kDM", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712624212}}}, {"tddate": null, "ddate": null, "tmdate": 1521752470102, "tcdate": 1521752470102, "number": 1, "cdate": 1521752470102, "id": "rJAcF9ZcM", "invitation": "ICLR.cc/2018/Workshop/-/Paper252/Public_Comment", "forum": "HkNpF_kDM", "replyto": "BybQE_kKz", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Thank you for your review", "comment": "Dear Reviewer,\n\nthank you for your remark. The big jump in the figure 2 is due to our choice to use generic parameters to make the comparison as fair as possible. The spike is due to a low value of $\\lambda$, and disapears if we use an adaptive strategy."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Nonlinear Acceleration of CNNs", "abstract": "Regularized Nonlinear Acceleration (RNA) can improve the rate of convergence of many optimization schemes such as gradient descent, SAGA or SVRG, estimating the optimum using a nonlinear average of past iterates. Until now, its analysis was limited to convex problems, but empirical observations show that RNA may be extended to a broader setting. Here, we investigate the benefits of nonlinear acceleration when applied to the training of neural networks, in particular for the task of image recognition on the CIFAR10 and ImageNet data sets. In our experiments, with minimal modifications to existing frameworks, RNA speeds up convergence and improves testing error on standard CNNs.", "paperhash": "scieur|nonlinear_acceleration_of_cnns", "_bibtex": "@misc{\n  scieur2018nonlinear,\n  title={Nonlinear Acceleration of CNNs},\n  author={Damien Scieur and Edouard Oyallon and Alexandre d\u2019Aspremont and Francis Bach},\n  year={2018},\n  url={https://openreview.net/forum?id=HkNpF_kDM}\n}", "authorids": ["damien.scieur@inria.fr", "edouard.oyallon@centralesupelec.fr", "aspremon@ens.fr", "francis.bach@inria.fr"], "authors": ["Damien Scieur", "Edouard Oyallon", "Alexandre d\u2019Aspremont", "Francis Bach"], "keywords": [], "pdf": "/pdf/42b31e10e754ef17eb0b7026f76e0e2e3d4fd9f5.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712624212, "id": "ICLR.cc/2018/Workshop/-/Paper252/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper252/Reviewers"], "reply": {"replyto": null, "forum": "HkNpF_kDM", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712624212}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582911863, "tcdate": 1520438266575, "number": 1, "cdate": 1520438266575, "id": "BymWnYpOM", "invitation": "ICLR.cc/2018/Workshop/-/Paper252/Official_Review", "forum": "HkNpF_kDM", "replyto": "HkNpF_kDM", "signatures": ["ICLR.cc/2018/Workshop/Paper252/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper252/AnonReviewer2"], "content": {"title": "The paper proposes to use the idea of regularized nonlinear acceleration to tune the performance of NN in an ad-hoc and offline manner. ", "rating": "7: Good paper, accept", "review": "Quality: \n\nThe paper brings forth an idea that can potentially improve accuracy using already fitted parameters. There is a slight concern regarding practicality of solving $(R^T R + \\lambda I) z = 1$ when the number of parameters is extremely large (in millions) as is the case for most applications of CNN. However, since RNA procedure is applied off-line and in an ad hoc manner, there really is no reason to not try it. Informally speaking, if it works and leads to improved accuracy, then that's great. If it doesn't work, then since the fraction of time and effort needed by the user to configure RNA is relatively small compared to the time to train CNNs, it would not have been much of a trouble for the user.\n\nClarity:\n\nThe paper is clearly written.\n\nOriginality:\n\nIt is an application of the authors' previous work to image classification problems involving CNN.\n\nSignificance:\n\nThe experimental results are not ground breaking but it shows that it can be a useful method for fine tuning the performance of NN.\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Nonlinear Acceleration of CNNs", "abstract": "Regularized Nonlinear Acceleration (RNA) can improve the rate of convergence of many optimization schemes such as gradient descent, SAGA or SVRG, estimating the optimum using a nonlinear average of past iterates. Until now, its analysis was limited to convex problems, but empirical observations show that RNA may be extended to a broader setting. Here, we investigate the benefits of nonlinear acceleration when applied to the training of neural networks, in particular for the task of image recognition on the CIFAR10 and ImageNet data sets. In our experiments, with minimal modifications to existing frameworks, RNA speeds up convergence and improves testing error on standard CNNs.", "paperhash": "scieur|nonlinear_acceleration_of_cnns", "_bibtex": "@misc{\n  scieur2018nonlinear,\n  title={Nonlinear Acceleration of CNNs},\n  author={Damien Scieur and Edouard Oyallon and Alexandre d\u2019Aspremont and Francis Bach},\n  year={2018},\n  url={https://openreview.net/forum?id=HkNpF_kDM}\n}", "authorids": ["damien.scieur@inria.fr", "edouard.oyallon@centralesupelec.fr", "aspremon@ens.fr", "francis.bach@inria.fr"], "authors": ["Damien Scieur", "Edouard Oyallon", "Alexandre d\u2019Aspremont", "Francis Bach"], "keywords": [], "pdf": "/pdf/42b31e10e754ef17eb0b7026f76e0e2e3d4fd9f5.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582911675, "id": "ICLR.cc/2018/Workshop/-/Paper252/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper252/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper252/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper252/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper252/AnonReviewer1"], "reply": {"forum": "HkNpF_kDM", "replyto": "HkNpF_kDM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper252/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper252/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582911675}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582861099, "tcdate": 1520563225216, "number": 2, "cdate": 1520563225216, "id": "BybQE_kKz", "invitation": "ICLR.cc/2018/Workshop/-/Paper252/Official_Review", "forum": "HkNpF_kDM", "replyto": "HkNpF_kDM", "signatures": ["ICLR.cc/2018/Workshop/Paper252/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper252/AnonReviewer3"], "content": {"title": "This paper is well written and the idea is interesting.", "rating": "9: Top 15% of accepted papers, strong accept", "review": "This paper presents an interesting extension of Regularized Nonlinear Acceleration (RNA)  for training deep CNNs. The paper is well written and easy to follow. The results are promising with clear explanations. The authors also publish their source code.\n\nOne minor question: There is a big jump of the proposed method in the right figure of Figure 2. Any reasons?\n\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Nonlinear Acceleration of CNNs", "abstract": "Regularized Nonlinear Acceleration (RNA) can improve the rate of convergence of many optimization schemes such as gradient descent, SAGA or SVRG, estimating the optimum using a nonlinear average of past iterates. Until now, its analysis was limited to convex problems, but empirical observations show that RNA may be extended to a broader setting. Here, we investigate the benefits of nonlinear acceleration when applied to the training of neural networks, in particular for the task of image recognition on the CIFAR10 and ImageNet data sets. In our experiments, with minimal modifications to existing frameworks, RNA speeds up convergence and improves testing error on standard CNNs.", "paperhash": "scieur|nonlinear_acceleration_of_cnns", "_bibtex": "@misc{\n  scieur2018nonlinear,\n  title={Nonlinear Acceleration of CNNs},\n  author={Damien Scieur and Edouard Oyallon and Alexandre d\u2019Aspremont and Francis Bach},\n  year={2018},\n  url={https://openreview.net/forum?id=HkNpF_kDM}\n}", "authorids": ["damien.scieur@inria.fr", "edouard.oyallon@centralesupelec.fr", "aspremon@ens.fr", "francis.bach@inria.fr"], "authors": ["Damien Scieur", "Edouard Oyallon", "Alexandre d\u2019Aspremont", "Francis Bach"], "keywords": [], "pdf": "/pdf/42b31e10e754ef17eb0b7026f76e0e2e3d4fd9f5.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582911675, "id": "ICLR.cc/2018/Workshop/-/Paper252/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper252/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper252/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper252/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper252/AnonReviewer1"], "reply": {"forum": "HkNpF_kDM", "replyto": "HkNpF_kDM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper252/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper252/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582911675}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582597648, "tcdate": 1521002852933, "number": 3, "cdate": 1521002852933, "id": "HyaPFQ8Kf", "invitation": "ICLR.cc/2018/Workshop/-/Paper252/Official_Review", "forum": "HkNpF_kDM", "replyto": "HkNpF_kDM", "signatures": ["ICLR.cc/2018/Workshop/Paper252/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper252/AnonReviewer1"], "content": {"title": "Review", "rating": "9: Top 15% of accepted papers, strong accept", "review": "This paper applies regularized nonlinear acceleration (RNA) to accelerate the training of of CNN. I find the empirical performance impressive, and believe this method can be adopted in practice. The authors also provide high-quality codes for the work.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Nonlinear Acceleration of CNNs", "abstract": "Regularized Nonlinear Acceleration (RNA) can improve the rate of convergence of many optimization schemes such as gradient descent, SAGA or SVRG, estimating the optimum using a nonlinear average of past iterates. Until now, its analysis was limited to convex problems, but empirical observations show that RNA may be extended to a broader setting. Here, we investigate the benefits of nonlinear acceleration when applied to the training of neural networks, in particular for the task of image recognition on the CIFAR10 and ImageNet data sets. In our experiments, with minimal modifications to existing frameworks, RNA speeds up convergence and improves testing error on standard CNNs.", "paperhash": "scieur|nonlinear_acceleration_of_cnns", "_bibtex": "@misc{\n  scieur2018nonlinear,\n  title={Nonlinear Acceleration of CNNs},\n  author={Damien Scieur and Edouard Oyallon and Alexandre d\u2019Aspremont and Francis Bach},\n  year={2018},\n  url={https://openreview.net/forum?id=HkNpF_kDM}\n}", "authorids": ["damien.scieur@inria.fr", "edouard.oyallon@centralesupelec.fr", "aspremon@ens.fr", "francis.bach@inria.fr"], "authors": ["Damien Scieur", "Edouard Oyallon", "Alexandre d\u2019Aspremont", "Francis Bach"], "keywords": [], "pdf": "/pdf/42b31e10e754ef17eb0b7026f76e0e2e3d4fd9f5.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582911675, "id": "ICLR.cc/2018/Workshop/-/Paper252/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper252/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper252/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper252/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper252/AnonReviewer1"], "reply": {"forum": "HkNpF_kDM", "replyto": "HkNpF_kDM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper252/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper252/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582911675}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573546713, "tcdate": 1521573546713, "number": 16, "cdate": 1521573546365, "id": "BJ7nCA0KM", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "HkNpF_kDM", "replyto": "HkNpF_kDM", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Nonlinear Acceleration of CNNs", "abstract": "Regularized Nonlinear Acceleration (RNA) can improve the rate of convergence of many optimization schemes such as gradient descent, SAGA or SVRG, estimating the optimum using a nonlinear average of past iterates. Until now, its analysis was limited to convex problems, but empirical observations show that RNA may be extended to a broader setting. Here, we investigate the benefits of nonlinear acceleration when applied to the training of neural networks, in particular for the task of image recognition on the CIFAR10 and ImageNet data sets. In our experiments, with minimal modifications to existing frameworks, RNA speeds up convergence and improves testing error on standard CNNs.", "paperhash": "scieur|nonlinear_acceleration_of_cnns", "_bibtex": "@misc{\n  scieur2018nonlinear,\n  title={Nonlinear Acceleration of CNNs},\n  author={Damien Scieur and Edouard Oyallon and Alexandre d\u2019Aspremont and Francis Bach},\n  year={2018},\n  url={https://openreview.net/forum?id=HkNpF_kDM}\n}", "authorids": ["damien.scieur@inria.fr", "edouard.oyallon@centralesupelec.fr", "aspremon@ens.fr", "francis.bach@inria.fr"], "authors": ["Damien Scieur", "Edouard Oyallon", "Alexandre d\u2019Aspremont", "Francis Bach"], "keywords": [], "pdf": "/pdf/42b31e10e754ef17eb0b7026f76e0e2e3d4fd9f5.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 9}