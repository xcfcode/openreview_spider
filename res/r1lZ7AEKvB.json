{"notes": [{"id": "r1lZ7AEKvB", "original": "HylegISOvB", "number": 1028, "cdate": 1569439257485, "ddate": null, "tcdate": 1569439257485, "tmdate": 1583912052433, "tddate": null, "forum": "r1lZ7AEKvB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["pbarcelo@gmail.com", "egor.kostylev@cs.ox.ac.uk", "mikael.monet@imfd.cl", "jorge.perez.rojas@gmail.com", "juan.reutter@gmail.com", "jpsilvapena@gmail.com"], "title": "The Logical Expressiveness of Graph Neural Networks", "authors": ["Pablo Barcel\u00f3", "Egor V. Kostylev", "Mikael Monet", "Jorge P\u00e9rez", "Juan Reutter", "Juan Pablo Silva"], "pdf": "/pdf/60fc684014522b4eec2e087e6006320b2fe35ec3.pdf", "TL;DR": "We characterize the expressive power of GNNs in terms of classical logical languages, separating different GNNs and showing connections with standard notions in Knowledge Representation.", "abstract": "The ability of graph neural networks (GNNs) for distinguishing nodes in graphs has been recently characterized in terms of the Weisfeiler-Lehman (WL) test for checking graph isomorphism. This characterization, however, does not settle the issue of which Boolean node classifiers (i.e., functions classifying nodes in graphs as true or  false) can be expressed by GNNs.  We tackle this problem by focusing on Boolean classifiers expressible as formulas in the logic FOC2, a well-studied fragment of first order logic. FOC2 is tightly related to the WL test, and hence to GNNs. We start by studying a popular class of GNNs, which we call AC-GNNs, in which the features of each node in the graph are updated, in successive layers, only in terms of the features of its neighbors.  We show that this class of GNNs is too weak to capture all FOC2 classifiers, and provide a syntactic characterization of  the largest subclass of FOC2 classifiers that can be captured by AC-GNNs. This subclass coincides with a logic heavily used by the knowledge representation community. We then look at what needs to be added to AC-GNNs for capturing all FOC2 classifiers. We show that it suffices to add readout functions, which allow to update the features of a node not only in terms of its neighbors, but also in terms of a global attribute vector. We call GNNs of this kind ACR-GNNs. We experimentally validate our findings showing that, on synthetic data conforming to FOC2 formulas, AC-GNNs struggle to fit the training data while ACR-GNNs can generalize even to graphs of sizes not seen during training.", "code": "https://anonymous.4open.science/r/787222e2-ad5e-4810-a788-e80f0fe7eff0/", "keywords": ["Graph Neural Networks", "First Order Logic", "Expressiveness"], "paperhash": "barcel\u00f3|the_logical_expressiveness_of_graph_neural_networks", "_bibtex": "@inproceedings{\nBarcel\u00f32020The,\ntitle={The Logical Expressiveness of Graph Neural Networks},\nauthor={Pablo Barcel\u00f3 and Egor V. Kostylev and Mikael Monet and Jorge P\u00e9rez and Juan Reutter and Juan Pablo Silva},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lZ7AEKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/0103dcb9cbd36f9f074be3036fdef740e15a484b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "Ehwwk01bkD", "original": null, "number": 1, "cdate": 1576798712636, "ddate": null, "tcdate": 1576798712636, "tmdate": 1576800923803, "tddate": null, "forum": "r1lZ7AEKvB", "replyto": "r1lZ7AEKvB", "invitation": "ICLR.cc/2020/Conference/Paper1028/-/Decision", "content": {"decision": "Accept (Spotlight)", "comment": "The paper focuses on characterizing the expressiveness of graph neural networks. The reviewers were satisfied that the authors answered their questions suffciiently and uniformly agree that this is a strong paper that should be accepted.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pbarcelo@gmail.com", "egor.kostylev@cs.ox.ac.uk", "mikael.monet@imfd.cl", "jorge.perez.rojas@gmail.com", "juan.reutter@gmail.com", "jpsilvapena@gmail.com"], "title": "The Logical Expressiveness of Graph Neural Networks", "authors": ["Pablo Barcel\u00f3", "Egor V. Kostylev", "Mikael Monet", "Jorge P\u00e9rez", "Juan Reutter", "Juan Pablo Silva"], "pdf": "/pdf/60fc684014522b4eec2e087e6006320b2fe35ec3.pdf", "TL;DR": "We characterize the expressive power of GNNs in terms of classical logical languages, separating different GNNs and showing connections with standard notions in Knowledge Representation.", "abstract": "The ability of graph neural networks (GNNs) for distinguishing nodes in graphs has been recently characterized in terms of the Weisfeiler-Lehman (WL) test for checking graph isomorphism. This characterization, however, does not settle the issue of which Boolean node classifiers (i.e., functions classifying nodes in graphs as true or  false) can be expressed by GNNs.  We tackle this problem by focusing on Boolean classifiers expressible as formulas in the logic FOC2, a well-studied fragment of first order logic. FOC2 is tightly related to the WL test, and hence to GNNs. We start by studying a popular class of GNNs, which we call AC-GNNs, in which the features of each node in the graph are updated, in successive layers, only in terms of the features of its neighbors.  We show that this class of GNNs is too weak to capture all FOC2 classifiers, and provide a syntactic characterization of  the largest subclass of FOC2 classifiers that can be captured by AC-GNNs. This subclass coincides with a logic heavily used by the knowledge representation community. We then look at what needs to be added to AC-GNNs for capturing all FOC2 classifiers. We show that it suffices to add readout functions, which allow to update the features of a node not only in terms of its neighbors, but also in terms of a global attribute vector. We call GNNs of this kind ACR-GNNs. We experimentally validate our findings showing that, on synthetic data conforming to FOC2 formulas, AC-GNNs struggle to fit the training data while ACR-GNNs can generalize even to graphs of sizes not seen during training.", "code": "https://anonymous.4open.science/r/787222e2-ad5e-4810-a788-e80f0fe7eff0/", "keywords": ["Graph Neural Networks", "First Order Logic", "Expressiveness"], "paperhash": "barcel\u00f3|the_logical_expressiveness_of_graph_neural_networks", "_bibtex": "@inproceedings{\nBarcel\u00f32020The,\ntitle={The Logical Expressiveness of Graph Neural Networks},\nauthor={Pablo Barcel\u00f3 and Egor V. Kostylev and Mikael Monet and Jorge P\u00e9rez and Juan Reutter and Juan Pablo Silva},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lZ7AEKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/0103dcb9cbd36f9f074be3036fdef740e15a484b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "r1lZ7AEKvB", "replyto": "r1lZ7AEKvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795708203, "tmdate": 1576800256562, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1028/-/Decision"}}}, {"id": "r1x495CRqH", "original": null, "number": 3, "cdate": 1572952715705, "ddate": null, "tcdate": 1572952715705, "tmdate": 1574460975594, "tddate": null, "forum": "r1lZ7AEKvB", "replyto": "r1lZ7AEKvB", "invitation": "ICLR.cc/2020/Conference/Paper1028/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "8: Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "title": "Official Blind Review #3", "review": "This paper establishes novel theoretical connections between Boolean node classifiers on aggregate-combine Graph Neural Networks (AC-GNNs) and first-order predicate logic (FOC2). It shows that current boolean node classifiers on AC-GNNs can only represent a subset of FOC2 but that a simple extension taking into global information can generalise AC-GNNs to the full FOC2.\n\nThe style of the manuscript is mixed: the abstract and introduction are quite dense for non-experts; a motivating real-world example could help here. The other sections, on the other hand, are quite good to follow and most concepts have a good high-level introduction as well as a little example to follow the arguments.\n\nThe theoretical connections connection between GNNs and first-order logic strike me as interesting. I did not, however, understand the results reported in table 2: ACR reaches optimal performance only on alpha_1 but not on alpha_2 and alpha_3. Does this happen because the latter two expressions are not part of FOC2?\n\n---\nI increased my rating due to the author rebuttal.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1028/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1028/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pbarcelo@gmail.com", "egor.kostylev@cs.ox.ac.uk", "mikael.monet@imfd.cl", "jorge.perez.rojas@gmail.com", "juan.reutter@gmail.com", "jpsilvapena@gmail.com"], "title": "The Logical Expressiveness of Graph Neural Networks", "authors": ["Pablo Barcel\u00f3", "Egor V. Kostylev", "Mikael Monet", "Jorge P\u00e9rez", "Juan Reutter", "Juan Pablo Silva"], "pdf": "/pdf/60fc684014522b4eec2e087e6006320b2fe35ec3.pdf", "TL;DR": "We characterize the expressive power of GNNs in terms of classical logical languages, separating different GNNs and showing connections with standard notions in Knowledge Representation.", "abstract": "The ability of graph neural networks (GNNs) for distinguishing nodes in graphs has been recently characterized in terms of the Weisfeiler-Lehman (WL) test for checking graph isomorphism. This characterization, however, does not settle the issue of which Boolean node classifiers (i.e., functions classifying nodes in graphs as true or  false) can be expressed by GNNs.  We tackle this problem by focusing on Boolean classifiers expressible as formulas in the logic FOC2, a well-studied fragment of first order logic. FOC2 is tightly related to the WL test, and hence to GNNs. We start by studying a popular class of GNNs, which we call AC-GNNs, in which the features of each node in the graph are updated, in successive layers, only in terms of the features of its neighbors.  We show that this class of GNNs is too weak to capture all FOC2 classifiers, and provide a syntactic characterization of  the largest subclass of FOC2 classifiers that can be captured by AC-GNNs. This subclass coincides with a logic heavily used by the knowledge representation community. We then look at what needs to be added to AC-GNNs for capturing all FOC2 classifiers. We show that it suffices to add readout functions, which allow to update the features of a node not only in terms of its neighbors, but also in terms of a global attribute vector. We call GNNs of this kind ACR-GNNs. We experimentally validate our findings showing that, on synthetic data conforming to FOC2 formulas, AC-GNNs struggle to fit the training data while ACR-GNNs can generalize even to graphs of sizes not seen during training.", "code": "https://anonymous.4open.science/r/787222e2-ad5e-4810-a788-e80f0fe7eff0/", "keywords": ["Graph Neural Networks", "First Order Logic", "Expressiveness"], "paperhash": "barcel\u00f3|the_logical_expressiveness_of_graph_neural_networks", "_bibtex": "@inproceedings{\nBarcel\u00f32020The,\ntitle={The Logical Expressiveness of Graph Neural Networks},\nauthor={Pablo Barcel\u00f3 and Egor V. Kostylev and Mikael Monet and Jorge P\u00e9rez and Juan Reutter and Juan Pablo Silva},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lZ7AEKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/0103dcb9cbd36f9f074be3036fdef740e15a484b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "r1lZ7AEKvB", "replyto": "r1lZ7AEKvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1028/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1028/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576273390369, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1028/Reviewers"], "noninvitees": [], "tcdate": 1570237743451, "tmdate": 1576273390381, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1028/-/Official_Review"}}}, {"id": "HJgRoh5dsS", "original": null, "number": 4, "cdate": 1573592229991, "ddate": null, "tcdate": 1573592229991, "tmdate": 1573592229991, "tddate": null, "forum": "r1lZ7AEKvB", "replyto": "r1gFmXtGsS", "invitation": "ICLR.cc/2020/Conference/Paper1028/-/Official_Comment", "content": {"title": "Answer to related work", "comment": "Thank you for these relevant pointers. Indeed, it seems likely that a result similar to our Proposition 4.1 (saying that each graded modal logic formula can be captured by an AC-GNN) could be derived by the combination of these two papers: by Theorem 2, item (f) of [Hella et al., 2012], the GML formula \\phi would be captured by an \u201cMB\u201d distributed algorithm A_\\phi, which in turn, by the MB version of  Lemma 13 of [Sato et al., 2019], would be captured by an AC-GNNt. However, an important part of our Proposition 4.1 is that we use AC-GNNs that are \u201csimple\u201d, in the sense defined in our paper (aggregation is a matrix multiplication of the sum of the feature vectors of the neighbors, and we use a (truncated) ReLU); this in contrast does not seem to be what we would obtain by combining the results of [Sato et al., 2019] and [Hella et al., 2012]. In addition, we observe the following differences:\n- [Sato et al., 2019] considers graphs of bounded degree, while our graphs can have unbounded degree;\n- the forward direction of our Theorem 4.2 (i.e., if an FO formula is not equivalent to a GML formula then no AC-GNN can capture it) does not follow from these two papers, since it goes outside of modal logics;\n- more generally, [Sato et al., 2019] and [Hella et al., 2012] consider only \u201clocal\u201d variants of GNNs and of distributed algorithms, i.e., (1) no internal global readouts in the GNNs; (2) in the distributed algorithms the messages are always transmitted only to the neighbors; and (3) the logics considered are all modal i.e., local; therefore, all our results on ACR-GNNs and FO and FO_2 do not seem to follow from these papers.\n\nWe will point to these works in the final version.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1028/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1028/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pbarcelo@gmail.com", "egor.kostylev@cs.ox.ac.uk", "mikael.monet@imfd.cl", "jorge.perez.rojas@gmail.com", "juan.reutter@gmail.com", "jpsilvapena@gmail.com"], "title": "The Logical Expressiveness of Graph Neural Networks", "authors": ["Pablo Barcel\u00f3", "Egor V. Kostylev", "Mikael Monet", "Jorge P\u00e9rez", "Juan Reutter", "Juan Pablo Silva"], "pdf": "/pdf/60fc684014522b4eec2e087e6006320b2fe35ec3.pdf", "TL;DR": "We characterize the expressive power of GNNs in terms of classical logical languages, separating different GNNs and showing connections with standard notions in Knowledge Representation.", "abstract": "The ability of graph neural networks (GNNs) for distinguishing nodes in graphs has been recently characterized in terms of the Weisfeiler-Lehman (WL) test for checking graph isomorphism. This characterization, however, does not settle the issue of which Boolean node classifiers (i.e., functions classifying nodes in graphs as true or  false) can be expressed by GNNs.  We tackle this problem by focusing on Boolean classifiers expressible as formulas in the logic FOC2, a well-studied fragment of first order logic. FOC2 is tightly related to the WL test, and hence to GNNs. We start by studying a popular class of GNNs, which we call AC-GNNs, in which the features of each node in the graph are updated, in successive layers, only in terms of the features of its neighbors.  We show that this class of GNNs is too weak to capture all FOC2 classifiers, and provide a syntactic characterization of  the largest subclass of FOC2 classifiers that can be captured by AC-GNNs. This subclass coincides with a logic heavily used by the knowledge representation community. We then look at what needs to be added to AC-GNNs for capturing all FOC2 classifiers. We show that it suffices to add readout functions, which allow to update the features of a node not only in terms of its neighbors, but also in terms of a global attribute vector. We call GNNs of this kind ACR-GNNs. We experimentally validate our findings showing that, on synthetic data conforming to FOC2 formulas, AC-GNNs struggle to fit the training data while ACR-GNNs can generalize even to graphs of sizes not seen during training.", "code": "https://anonymous.4open.science/r/787222e2-ad5e-4810-a788-e80f0fe7eff0/", "keywords": ["Graph Neural Networks", "First Order Logic", "Expressiveness"], "paperhash": "barcel\u00f3|the_logical_expressiveness_of_graph_neural_networks", "_bibtex": "@inproceedings{\nBarcel\u00f32020The,\ntitle={The Logical Expressiveness of Graph Neural Networks},\nauthor={Pablo Barcel\u00f3 and Egor V. Kostylev and Mikael Monet and Jorge P\u00e9rez and Juan Reutter and Juan Pablo Silva},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lZ7AEKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/0103dcb9cbd36f9f074be3036fdef740e15a484b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1lZ7AEKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1028/Authors", "ICLR.cc/2020/Conference/Paper1028/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1028/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1028/Reviewers", "ICLR.cc/2020/Conference/Paper1028/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1028/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1028/Authors|ICLR.cc/2020/Conference/Paper1028/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504162376, "tmdate": 1576860549875, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1028/Authors", "ICLR.cc/2020/Conference/Paper1028/Reviewers", "ICLR.cc/2020/Conference/Paper1028/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1028/-/Official_Comment"}}}, {"id": "r1eHD2cOiH", "original": null, "number": 3, "cdate": 1573592157355, "ddate": null, "tcdate": 1573592157355, "tmdate": 1573592157355, "tddate": null, "forum": "r1lZ7AEKvB", "replyto": "r1x495CRqH", "invitation": "ICLR.cc/2020/Conference/Paper1028/-/Official_Comment", "content": {"title": "Answer to reviewer #3", "comment": "Thanks a lot for your positive comments. We will do our best to improve the readability of the introduction, and to try to fit an example. In any case we will delay this change for an eventual final version of the paper as it might require some more general changes to the flow of the intro. But thank you very much for pointing this out.\n\nRegarding your question, all \\alpha_i do belong to FOC2. In fact, it is not difficult to show that there exists an ACR-i GNN that captures alpha_i for each i, but none of ACR-j GNNs with j < i can do this. Nonetheless, the existence of such a GNN does not imply the ability to learn this GNN from examples. So, besides other things, our experiments demonstrate that, for i = 2 and i = 3, it is possible to learn an ACR-i GNN very close (~80-90%) to alpha_i, in contrast to AC-GNNs that achieve a lower performance (60%) even if 10 layers are allowed; The question whether and how it is possible to learn an ACR-i GNN exactly equivalent to alpha_i is still open. We will add a discussion about this into the final version of the paper.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1028/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1028/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pbarcelo@gmail.com", "egor.kostylev@cs.ox.ac.uk", "mikael.monet@imfd.cl", "jorge.perez.rojas@gmail.com", "juan.reutter@gmail.com", "jpsilvapena@gmail.com"], "title": "The Logical Expressiveness of Graph Neural Networks", "authors": ["Pablo Barcel\u00f3", "Egor V. Kostylev", "Mikael Monet", "Jorge P\u00e9rez", "Juan Reutter", "Juan Pablo Silva"], "pdf": "/pdf/60fc684014522b4eec2e087e6006320b2fe35ec3.pdf", "TL;DR": "We characterize the expressive power of GNNs in terms of classical logical languages, separating different GNNs and showing connections with standard notions in Knowledge Representation.", "abstract": "The ability of graph neural networks (GNNs) for distinguishing nodes in graphs has been recently characterized in terms of the Weisfeiler-Lehman (WL) test for checking graph isomorphism. This characterization, however, does not settle the issue of which Boolean node classifiers (i.e., functions classifying nodes in graphs as true or  false) can be expressed by GNNs.  We tackle this problem by focusing on Boolean classifiers expressible as formulas in the logic FOC2, a well-studied fragment of first order logic. FOC2 is tightly related to the WL test, and hence to GNNs. We start by studying a popular class of GNNs, which we call AC-GNNs, in which the features of each node in the graph are updated, in successive layers, only in terms of the features of its neighbors.  We show that this class of GNNs is too weak to capture all FOC2 classifiers, and provide a syntactic characterization of  the largest subclass of FOC2 classifiers that can be captured by AC-GNNs. This subclass coincides with a logic heavily used by the knowledge representation community. We then look at what needs to be added to AC-GNNs for capturing all FOC2 classifiers. We show that it suffices to add readout functions, which allow to update the features of a node not only in terms of its neighbors, but also in terms of a global attribute vector. We call GNNs of this kind ACR-GNNs. We experimentally validate our findings showing that, on synthetic data conforming to FOC2 formulas, AC-GNNs struggle to fit the training data while ACR-GNNs can generalize even to graphs of sizes not seen during training.", "code": "https://anonymous.4open.science/r/787222e2-ad5e-4810-a788-e80f0fe7eff0/", "keywords": ["Graph Neural Networks", "First Order Logic", "Expressiveness"], "paperhash": "barcel\u00f3|the_logical_expressiveness_of_graph_neural_networks", "_bibtex": "@inproceedings{\nBarcel\u00f32020The,\ntitle={The Logical Expressiveness of Graph Neural Networks},\nauthor={Pablo Barcel\u00f3 and Egor V. Kostylev and Mikael Monet and Jorge P\u00e9rez and Juan Reutter and Juan Pablo Silva},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lZ7AEKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/0103dcb9cbd36f9f074be3036fdef740e15a484b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1lZ7AEKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1028/Authors", "ICLR.cc/2020/Conference/Paper1028/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1028/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1028/Reviewers", "ICLR.cc/2020/Conference/Paper1028/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1028/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1028/Authors|ICLR.cc/2020/Conference/Paper1028/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504162376, "tmdate": 1576860549875, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1028/Authors", "ICLR.cc/2020/Conference/Paper1028/Reviewers", "ICLR.cc/2020/Conference/Paper1028/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1028/-/Official_Comment"}}}, {"id": "HygY42cOoB", "original": null, "number": 2, "cdate": 1573592113353, "ddate": null, "tcdate": 1573592113353, "tmdate": 1573592113353, "tddate": null, "forum": "r1lZ7AEKvB", "replyto": "H1ezHHmAtB", "invitation": "ICLR.cc/2020/Conference/Paper1028/-/Official_Comment", "content": {"title": "Answer to reviewer #2", "comment": "Thank you very much for your comments. In the final version of the paper, we plan to add in the body of the paper more discussion on the aggregate and combine operation used in the proofs and how they affect the expressiveness of GNNs."}, "signatures": ["ICLR.cc/2020/Conference/Paper1028/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1028/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pbarcelo@gmail.com", "egor.kostylev@cs.ox.ac.uk", "mikael.monet@imfd.cl", "jorge.perez.rojas@gmail.com", "juan.reutter@gmail.com", "jpsilvapena@gmail.com"], "title": "The Logical Expressiveness of Graph Neural Networks", "authors": ["Pablo Barcel\u00f3", "Egor V. Kostylev", "Mikael Monet", "Jorge P\u00e9rez", "Juan Reutter", "Juan Pablo Silva"], "pdf": "/pdf/60fc684014522b4eec2e087e6006320b2fe35ec3.pdf", "TL;DR": "We characterize the expressive power of GNNs in terms of classical logical languages, separating different GNNs and showing connections with standard notions in Knowledge Representation.", "abstract": "The ability of graph neural networks (GNNs) for distinguishing nodes in graphs has been recently characterized in terms of the Weisfeiler-Lehman (WL) test for checking graph isomorphism. This characterization, however, does not settle the issue of which Boolean node classifiers (i.e., functions classifying nodes in graphs as true or  false) can be expressed by GNNs.  We tackle this problem by focusing on Boolean classifiers expressible as formulas in the logic FOC2, a well-studied fragment of first order logic. FOC2 is tightly related to the WL test, and hence to GNNs. We start by studying a popular class of GNNs, which we call AC-GNNs, in which the features of each node in the graph are updated, in successive layers, only in terms of the features of its neighbors.  We show that this class of GNNs is too weak to capture all FOC2 classifiers, and provide a syntactic characterization of  the largest subclass of FOC2 classifiers that can be captured by AC-GNNs. This subclass coincides with a logic heavily used by the knowledge representation community. We then look at what needs to be added to AC-GNNs for capturing all FOC2 classifiers. We show that it suffices to add readout functions, which allow to update the features of a node not only in terms of its neighbors, but also in terms of a global attribute vector. We call GNNs of this kind ACR-GNNs. We experimentally validate our findings showing that, on synthetic data conforming to FOC2 formulas, AC-GNNs struggle to fit the training data while ACR-GNNs can generalize even to graphs of sizes not seen during training.", "code": "https://anonymous.4open.science/r/787222e2-ad5e-4810-a788-e80f0fe7eff0/", "keywords": ["Graph Neural Networks", "First Order Logic", "Expressiveness"], "paperhash": "barcel\u00f3|the_logical_expressiveness_of_graph_neural_networks", "_bibtex": "@inproceedings{\nBarcel\u00f32020The,\ntitle={The Logical Expressiveness of Graph Neural Networks},\nauthor={Pablo Barcel\u00f3 and Egor V. Kostylev and Mikael Monet and Jorge P\u00e9rez and Juan Reutter and Juan Pablo Silva},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lZ7AEKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/0103dcb9cbd36f9f074be3036fdef740e15a484b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1lZ7AEKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1028/Authors", "ICLR.cc/2020/Conference/Paper1028/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1028/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1028/Reviewers", "ICLR.cc/2020/Conference/Paper1028/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1028/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1028/Authors|ICLR.cc/2020/Conference/Paper1028/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504162376, "tmdate": 1576860549875, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1028/Authors", "ICLR.cc/2020/Conference/Paper1028/Reviewers", "ICLR.cc/2020/Conference/Paper1028/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1028/-/Official_Comment"}}}, {"id": "HJlFy2cdir", "original": null, "number": 1, "cdate": 1573592032610, "ddate": null, "tcdate": 1573592032610, "tmdate": 1573592032610, "tddate": null, "forum": "r1lZ7AEKvB", "replyto": "r1egYwC6tr", "invitation": "ICLR.cc/2020/Conference/Paper1028/-/Official_Comment", "content": {"title": "Answer to reviewer #1", "comment": "Thank you for your review. You correctly point out that more empirical results on real life data are needed and this is part of our current and future work. We just add that there is some work showing that current benchmarks might not be very helpful when differentiating specific changes for GNNs [1]. It is even common practice to only keep and train over the biggest connected component of the graph, and discard the rest, so our ACR-GNN might not benefit from those situations. Recent work has also started studying that current real life datasets might not be adequate for some tasks [2]. Moreover, most common benchmarks do not encode global constraints in the graph features nor labels, and thus it might not be easy to find a good benchmark to show for our global approach. We comment on this only to emphasize that finding a good benchmark for our approach has not been an easy task and that is why we focused more on synthetic data in this submission.\n\n[1] Chen, Ting, Song Bian, Yizhou Sun. \"Are Powerful Graph Neural Nets Necessary? A Dissection on Graph Classification.\" https://arxiv.org/abs/1905.04579\n[2] Ivanov, Sergei, Sergei Sviridov, and Evgeny Burnaev. \"Understanding Isomorphism Bias in Graph Data Sets.\" https://arxiv.org/abs/1910.12091\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1028/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1028/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pbarcelo@gmail.com", "egor.kostylev@cs.ox.ac.uk", "mikael.monet@imfd.cl", "jorge.perez.rojas@gmail.com", "juan.reutter@gmail.com", "jpsilvapena@gmail.com"], "title": "The Logical Expressiveness of Graph Neural Networks", "authors": ["Pablo Barcel\u00f3", "Egor V. Kostylev", "Mikael Monet", "Jorge P\u00e9rez", "Juan Reutter", "Juan Pablo Silva"], "pdf": "/pdf/60fc684014522b4eec2e087e6006320b2fe35ec3.pdf", "TL;DR": "We characterize the expressive power of GNNs in terms of classical logical languages, separating different GNNs and showing connections with standard notions in Knowledge Representation.", "abstract": "The ability of graph neural networks (GNNs) for distinguishing nodes in graphs has been recently characterized in terms of the Weisfeiler-Lehman (WL) test for checking graph isomorphism. This characterization, however, does not settle the issue of which Boolean node classifiers (i.e., functions classifying nodes in graphs as true or  false) can be expressed by GNNs.  We tackle this problem by focusing on Boolean classifiers expressible as formulas in the logic FOC2, a well-studied fragment of first order logic. FOC2 is tightly related to the WL test, and hence to GNNs. We start by studying a popular class of GNNs, which we call AC-GNNs, in which the features of each node in the graph are updated, in successive layers, only in terms of the features of its neighbors.  We show that this class of GNNs is too weak to capture all FOC2 classifiers, and provide a syntactic characterization of  the largest subclass of FOC2 classifiers that can be captured by AC-GNNs. This subclass coincides with a logic heavily used by the knowledge representation community. We then look at what needs to be added to AC-GNNs for capturing all FOC2 classifiers. We show that it suffices to add readout functions, which allow to update the features of a node not only in terms of its neighbors, but also in terms of a global attribute vector. We call GNNs of this kind ACR-GNNs. We experimentally validate our findings showing that, on synthetic data conforming to FOC2 formulas, AC-GNNs struggle to fit the training data while ACR-GNNs can generalize even to graphs of sizes not seen during training.", "code": "https://anonymous.4open.science/r/787222e2-ad5e-4810-a788-e80f0fe7eff0/", "keywords": ["Graph Neural Networks", "First Order Logic", "Expressiveness"], "paperhash": "barcel\u00f3|the_logical_expressiveness_of_graph_neural_networks", "_bibtex": "@inproceedings{\nBarcel\u00f32020The,\ntitle={The Logical Expressiveness of Graph Neural Networks},\nauthor={Pablo Barcel\u00f3 and Egor V. Kostylev and Mikael Monet and Jorge P\u00e9rez and Juan Reutter and Juan Pablo Silva},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lZ7AEKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/0103dcb9cbd36f9f074be3036fdef740e15a484b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1lZ7AEKvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1028/Authors", "ICLR.cc/2020/Conference/Paper1028/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1028/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1028/Reviewers", "ICLR.cc/2020/Conference/Paper1028/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1028/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1028/Authors|ICLR.cc/2020/Conference/Paper1028/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504162376, "tmdate": 1576860549875, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1028/Authors", "ICLR.cc/2020/Conference/Paper1028/Reviewers", "ICLR.cc/2020/Conference/Paper1028/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1028/-/Official_Comment"}}}, {"id": "r1gFmXtGsS", "original": null, "number": 1, "cdate": 1573192480692, "ddate": null, "tcdate": 1573192480692, "tmdate": 1573192480692, "tddate": null, "forum": "r1lZ7AEKvB", "replyto": "r1lZ7AEKvB", "invitation": "ICLR.cc/2020/Conference/Paper1028/-/Public_Comment", "content": {"title": "A related work on the connection between GNNs and modal logic", "comment": "Hi, the analysis of the connection between FOC2 and GNNs is interesting, and I really enjoyed reading it. [Sato+ 2019] pointed out that the GNN classes are equivalent to computational models of local algorithms. Especially, it gave a theoretical consideration about the limit of the ability of GNNs in terms of approximation ratios by pointing out the connections between GNNs and local algorithms. Since each computational model of local algorithms is equivalent to a modal logic class such as graded modal logic [Hella+ 2012], the contribution of this paper is closely related to [Sato+ 2019], and it is good for this paper to refer to them.\n\n[1] Ryoma Sato, Makoto Yamada, Hisashi Kashima. Approximation Ratios of Graph Neural Networks for Combinatorial Problems. NeurIPS 2019. https://arxiv.org/abs/1905.10261\n\n[2] Lauri Hella, Matti J\u00e4rvisalo, Antti Kuusisto, Juhana Laurinharju, Tuomo Lempi\u00e4inen, Kerkko Luosto, Jukka Suomela, Jonni Virtema. Weak Models of Distributed Computing, with Connections to Modal Logic. PODC 2012. https://arxiv.org/abs/1205.2051\n\nThank you for your attention."}, "signatures": ["~Ryoma_Sato1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Ryoma_Sato1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pbarcelo@gmail.com", "egor.kostylev@cs.ox.ac.uk", "mikael.monet@imfd.cl", "jorge.perez.rojas@gmail.com", "juan.reutter@gmail.com", "jpsilvapena@gmail.com"], "title": "The Logical Expressiveness of Graph Neural Networks", "authors": ["Pablo Barcel\u00f3", "Egor V. Kostylev", "Mikael Monet", "Jorge P\u00e9rez", "Juan Reutter", "Juan Pablo Silva"], "pdf": "/pdf/60fc684014522b4eec2e087e6006320b2fe35ec3.pdf", "TL;DR": "We characterize the expressive power of GNNs in terms of classical logical languages, separating different GNNs and showing connections with standard notions in Knowledge Representation.", "abstract": "The ability of graph neural networks (GNNs) for distinguishing nodes in graphs has been recently characterized in terms of the Weisfeiler-Lehman (WL) test for checking graph isomorphism. This characterization, however, does not settle the issue of which Boolean node classifiers (i.e., functions classifying nodes in graphs as true or  false) can be expressed by GNNs.  We tackle this problem by focusing on Boolean classifiers expressible as formulas in the logic FOC2, a well-studied fragment of first order logic. FOC2 is tightly related to the WL test, and hence to GNNs. We start by studying a popular class of GNNs, which we call AC-GNNs, in which the features of each node in the graph are updated, in successive layers, only in terms of the features of its neighbors.  We show that this class of GNNs is too weak to capture all FOC2 classifiers, and provide a syntactic characterization of  the largest subclass of FOC2 classifiers that can be captured by AC-GNNs. This subclass coincides with a logic heavily used by the knowledge representation community. We then look at what needs to be added to AC-GNNs for capturing all FOC2 classifiers. We show that it suffices to add readout functions, which allow to update the features of a node not only in terms of its neighbors, but also in terms of a global attribute vector. We call GNNs of this kind ACR-GNNs. We experimentally validate our findings showing that, on synthetic data conforming to FOC2 formulas, AC-GNNs struggle to fit the training data while ACR-GNNs can generalize even to graphs of sizes not seen during training.", "code": "https://anonymous.4open.science/r/787222e2-ad5e-4810-a788-e80f0fe7eff0/", "keywords": ["Graph Neural Networks", "First Order Logic", "Expressiveness"], "paperhash": "barcel\u00f3|the_logical_expressiveness_of_graph_neural_networks", "_bibtex": "@inproceedings{\nBarcel\u00f32020The,\ntitle={The Logical Expressiveness of Graph Neural Networks},\nauthor={Pablo Barcel\u00f3 and Egor V. Kostylev and Mikael Monet and Jorge P\u00e9rez and Juan Reutter and Juan Pablo Silva},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lZ7AEKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/0103dcb9cbd36f9f074be3036fdef740e15a484b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "r1lZ7AEKvB", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504200676, "tmdate": 1576860583148, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper1028/Authors", "ICLR.cc/2020/Conference/Paper1028/Reviewers", "ICLR.cc/2020/Conference/Paper1028/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1028/-/Public_Comment"}}}, {"id": "r1egYwC6tr", "original": null, "number": 1, "cdate": 1571837816408, "ddate": null, "tcdate": 1571837816408, "tmdate": 1572972521679, "tddate": null, "forum": "r1lZ7AEKvB", "replyto": "r1lZ7AEKvB", "invitation": "ICLR.cc/2020/Conference/Paper1028/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "The paper utilizes recent insights into the relationship between the Weisfeiler-Lehman (WL) test for checking graph isomorphism and Graph Neural Networks (GNNs) in order to characterize the class of node classifiers that can be captured by a specific GNN architecture, called aggregate-combine GNN (AC-GNN). \n\nThe primary contribution of this work is the identification of the logical classifiers that can be represented within an AC-GNN, a fragment of first order logic called graded modal logic, as well as an extention of AC-GNNs with the ability to capture a strictly more expressive fragment of first order logic, called ACR-GNN. Both of these results are supported by formal proofs and derivations, adding not only theoretical value to the presented work, but also intuitive insights behind the reasons of the AC-GNN limitations. In addition, the presented experiments demonstrate the practical implications of the results, with the exception of some datasets where no significance difference in performance between AC-GNNs and ACR-GNNs was found.\nI believe that the contributions of this paper are significant. On the one hand, studying theoretical properties of GNNs facilitates their transparency and highlights the range of applications they can be used in. On the other hand, although the GNN variant introduced by the author is a special case of an existing class of GNNs, the motivation behind its introduction is different and follows naturally from the discussion within the paper.\n\nThe fact that no actual difference in performance between AC-GNNs and ACR-GNNs was noticed in the only non-synthetic dataset used in the experiment should prompt the author to run experiments with more real life datasets, in order to empirically verify the results, but this is a minor point."}, "signatures": ["ICLR.cc/2020/Conference/Paper1028/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1028/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pbarcelo@gmail.com", "egor.kostylev@cs.ox.ac.uk", "mikael.monet@imfd.cl", "jorge.perez.rojas@gmail.com", "juan.reutter@gmail.com", "jpsilvapena@gmail.com"], "title": "The Logical Expressiveness of Graph Neural Networks", "authors": ["Pablo Barcel\u00f3", "Egor V. Kostylev", "Mikael Monet", "Jorge P\u00e9rez", "Juan Reutter", "Juan Pablo Silva"], "pdf": "/pdf/60fc684014522b4eec2e087e6006320b2fe35ec3.pdf", "TL;DR": "We characterize the expressive power of GNNs in terms of classical logical languages, separating different GNNs and showing connections with standard notions in Knowledge Representation.", "abstract": "The ability of graph neural networks (GNNs) for distinguishing nodes in graphs has been recently characterized in terms of the Weisfeiler-Lehman (WL) test for checking graph isomorphism. This characterization, however, does not settle the issue of which Boolean node classifiers (i.e., functions classifying nodes in graphs as true or  false) can be expressed by GNNs.  We tackle this problem by focusing on Boolean classifiers expressible as formulas in the logic FOC2, a well-studied fragment of first order logic. FOC2 is tightly related to the WL test, and hence to GNNs. We start by studying a popular class of GNNs, which we call AC-GNNs, in which the features of each node in the graph are updated, in successive layers, only in terms of the features of its neighbors.  We show that this class of GNNs is too weak to capture all FOC2 classifiers, and provide a syntactic characterization of  the largest subclass of FOC2 classifiers that can be captured by AC-GNNs. This subclass coincides with a logic heavily used by the knowledge representation community. We then look at what needs to be added to AC-GNNs for capturing all FOC2 classifiers. We show that it suffices to add readout functions, which allow to update the features of a node not only in terms of its neighbors, but also in terms of a global attribute vector. We call GNNs of this kind ACR-GNNs. We experimentally validate our findings showing that, on synthetic data conforming to FOC2 formulas, AC-GNNs struggle to fit the training data while ACR-GNNs can generalize even to graphs of sizes not seen during training.", "code": "https://anonymous.4open.science/r/787222e2-ad5e-4810-a788-e80f0fe7eff0/", "keywords": ["Graph Neural Networks", "First Order Logic", "Expressiveness"], "paperhash": "barcel\u00f3|the_logical_expressiveness_of_graph_neural_networks", "_bibtex": "@inproceedings{\nBarcel\u00f32020The,\ntitle={The Logical Expressiveness of Graph Neural Networks},\nauthor={Pablo Barcel\u00f3 and Egor V. Kostylev and Mikael Monet and Jorge P\u00e9rez and Juan Reutter and Juan Pablo Silva},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lZ7AEKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/0103dcb9cbd36f9f074be3036fdef740e15a484b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "r1lZ7AEKvB", "replyto": "r1lZ7AEKvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1028/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1028/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576273390369, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1028/Reviewers"], "noninvitees": [], "tcdate": 1570237743451, "tmdate": 1576273390381, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1028/-/Official_Review"}}}, {"id": "H1ezHHmAtB", "original": null, "number": 2, "cdate": 1571857722484, "ddate": null, "tcdate": 1571857722484, "tmdate": 1572972521635, "tddate": null, "forum": "r1lZ7AEKvB", "replyto": "r1lZ7AEKvB", "invitation": "ICLR.cc/2020/Conference/Paper1028/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper elaborates on the expressivity of graph neural networks (GNNs). More precisely, the authors show that expressivity of AC-GNNs (aggregate and combine) can only express logical classifiers that can be expressed in graded modal logic. By adding readouts, ACR-GNNs (aggregate, combine and readout) can capture FOC2 which is logical classifiers expressed with 2 variables and counting quantifiers. The second theorem leaves open the question of whether ACR-GNNs can capture logical classifiers beyond FOC2.\n\nThe paper is written nicely, its easy on the eyes, and delegates the proofs to the appendix. I was a bit surprised by the lack of a discussion connecting the choice of the aggregate and combine operations to the representation power of GNNs. One has to delve deep into the proofs to find out if the choice of these operations affects expressivity."}, "signatures": ["ICLR.cc/2020/Conference/Paper1028/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1028/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["pbarcelo@gmail.com", "egor.kostylev@cs.ox.ac.uk", "mikael.monet@imfd.cl", "jorge.perez.rojas@gmail.com", "juan.reutter@gmail.com", "jpsilvapena@gmail.com"], "title": "The Logical Expressiveness of Graph Neural Networks", "authors": ["Pablo Barcel\u00f3", "Egor V. Kostylev", "Mikael Monet", "Jorge P\u00e9rez", "Juan Reutter", "Juan Pablo Silva"], "pdf": "/pdf/60fc684014522b4eec2e087e6006320b2fe35ec3.pdf", "TL;DR": "We characterize the expressive power of GNNs in terms of classical logical languages, separating different GNNs and showing connections with standard notions in Knowledge Representation.", "abstract": "The ability of graph neural networks (GNNs) for distinguishing nodes in graphs has been recently characterized in terms of the Weisfeiler-Lehman (WL) test for checking graph isomorphism. This characterization, however, does not settle the issue of which Boolean node classifiers (i.e., functions classifying nodes in graphs as true or  false) can be expressed by GNNs.  We tackle this problem by focusing on Boolean classifiers expressible as formulas in the logic FOC2, a well-studied fragment of first order logic. FOC2 is tightly related to the WL test, and hence to GNNs. We start by studying a popular class of GNNs, which we call AC-GNNs, in which the features of each node in the graph are updated, in successive layers, only in terms of the features of its neighbors.  We show that this class of GNNs is too weak to capture all FOC2 classifiers, and provide a syntactic characterization of  the largest subclass of FOC2 classifiers that can be captured by AC-GNNs. This subclass coincides with a logic heavily used by the knowledge representation community. We then look at what needs to be added to AC-GNNs for capturing all FOC2 classifiers. We show that it suffices to add readout functions, which allow to update the features of a node not only in terms of its neighbors, but also in terms of a global attribute vector. We call GNNs of this kind ACR-GNNs. We experimentally validate our findings showing that, on synthetic data conforming to FOC2 formulas, AC-GNNs struggle to fit the training data while ACR-GNNs can generalize even to graphs of sizes not seen during training.", "code": "https://anonymous.4open.science/r/787222e2-ad5e-4810-a788-e80f0fe7eff0/", "keywords": ["Graph Neural Networks", "First Order Logic", "Expressiveness"], "paperhash": "barcel\u00f3|the_logical_expressiveness_of_graph_neural_networks", "_bibtex": "@inproceedings{\nBarcel\u00f32020The,\ntitle={The Logical Expressiveness of Graph Neural Networks},\nauthor={Pablo Barcel\u00f3 and Egor V. Kostylev and Mikael Monet and Jorge P\u00e9rez and Juan Reutter and Juan Pablo Silva},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lZ7AEKvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/0103dcb9cbd36f9f074be3036fdef740e15a484b.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "r1lZ7AEKvB", "replyto": "r1lZ7AEKvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1028/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1028/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576273390369, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1028/Reviewers"], "noninvitees": [], "tcdate": 1570237743451, "tmdate": 1576273390381, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1028/-/Official_Review"}}}], "count": 10}