{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124436799, "tcdate": 1518472847715, "number": 351, "cdate": 1518472847715, "id": "rkdq0F1Pf", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "rkdq0F1Pf", "signatures": ["~Praveen_V_Sai_Ch1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Domain Adversarial Representation Learning for Data Independent Defenses against Poisoning Attacks", "abstract": "Understanding the worst case loss of a defense against a determined attack is important to evaluate the robustness of a particular classification algorithm to data poisoning attacks. Even though there are many methods for defending against attacks, they are dependent on the separability of the dataset representation. We pose this as a domain adaptation problem and learn a function in an adversarial setting to transform a dataset from a source domain to a target domain which has an established separability of clusters. The defenses thus obtained in the target domain show tighter upper bounds as compared to those in the source domain.", "paperhash": "praven|domain_adversarial_representation_learning_for_data_independent_defenses_against_poisoning_attacks", "keywords": [], "_bibtex": "@misc{\n  praven2018domain,\n  title={Domain Adversarial Representation Learning for Data Independent Defenses against Poisoning Attacks},\n  author={Ch V Sai Praven and Cheruvu Siva Kumar},\n  year={2018},\n  url={https://openreview.net/forum?id=rkdq0F1Pf}\n}", "authorids": ["chvsp972911@gmail.com"], "authors": ["Ch V Sai Praven", "Cheruvu Siva Kumar"], "TL;DR": "Domain adaptation for data defenses", "pdf": "/pdf/6dfeb1acac26ae6aabd4cb2653e8b02d35609c69.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582827919, "tcdate": 1520608289772, "number": 1, "cdate": 1520608289772, "id": "B19mV7xtG", "invitation": "ICLR.cc/2018/Workshop/-/Paper351/Official_Review", "forum": "rkdq0F1Pf", "replyto": "rkdq0F1Pf", "signatures": ["ICLR.cc/2018/Workshop/Paper351/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper351/AnonReviewer3"], "content": {"title": "Smart idea, but not developed enough", "rating": "4: Ok but not good enough - rejection", "review": "The paper build on recent work of Steinhardt et al. (2007) that proposed a method to make a learner more robust to \"data poisoning attacks\" by removing outliers. This method works under the assumption that classes are well-separated into clusters. The empirical study of Steinhardt et al. confirms this by showing great robustness on MNIST-17 dataset (where classes are well-separated) and poor robustness on IMDB dataset (where classes are not well separated).\n\nIn the current workshop papers, the authors start from the above empirical observation and undertake to transform the representation of IMDB samples to be alike the MNIST-17 ones. This is done by learning a mapping with the help of domain adversarial learning; they enforce the IMDB samples to be indistinguishable from the MNIST ones. Doing this, the experiments show this new representation makes the IMDB dataset more robust to attack under the Steinhardt et al. framework. I think this is interesting as MNIST and IMDB are in appearance unrelated tasks. (A similar result is obtained by transforming the SVHN dataset into the MNIST dataset, which are more related tasks).\n\nThe work focuses on a few experimental tasks. It shows that the idea is promising, but does not provide evidence that the method will work on other problems. Thus, the authors point out a nice observation, but the overall contribution is rather small. \n\nMoreover, the paper lacks rigor: Few is said on how the method is trained, the objective function on page 2 contains undefined symbols (tilde{P}_{target}, D_\\pi), and there is no reference to other works explaining the domain adversarial strategy.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Domain Adversarial Representation Learning for Data Independent Defenses against Poisoning Attacks", "abstract": "Understanding the worst case loss of a defense against a determined attack is important to evaluate the robustness of a particular classification algorithm to data poisoning attacks. Even though there are many methods for defending against attacks, they are dependent on the separability of the dataset representation. We pose this as a domain adaptation problem and learn a function in an adversarial setting to transform a dataset from a source domain to a target domain which has an established separability of clusters. The defenses thus obtained in the target domain show tighter upper bounds as compared to those in the source domain.", "paperhash": "praven|domain_adversarial_representation_learning_for_data_independent_defenses_against_poisoning_attacks", "keywords": [], "_bibtex": "@misc{\n  praven2018domain,\n  title={Domain Adversarial Representation Learning for Data Independent Defenses against Poisoning Attacks},\n  author={Ch V Sai Praven and Cheruvu Siva Kumar},\n  year={2018},\n  url={https://openreview.net/forum?id=rkdq0F1Pf}\n}", "authorids": ["chvsp972911@gmail.com"], "authors": ["Ch V Sai Praven", "Cheruvu Siva Kumar"], "TL;DR": "Domain adaptation for data defenses", "pdf": "/pdf/6dfeb1acac26ae6aabd4cb2653e8b02d35609c69.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582827725, "id": "ICLR.cc/2018/Workshop/-/Paper351/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper351/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper351/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper351/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper351/AnonReviewer2"], "reply": {"forum": "rkdq0F1Pf", "replyto": "rkdq0F1Pf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper351/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper351/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582827725}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582745314, "tcdate": 1520658784934, "number": 2, "cdate": 1520658784934, "id": "rktwtkZYz", "invitation": "ICLR.cc/2018/Workshop/-/Paper351/Official_Review", "forum": "rkdq0F1Pf", "replyto": "rkdq0F1Pf", "signatures": ["ICLR.cc/2018/Workshop/Paper351/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper351/AnonReviewer1"], "content": {"title": "Overall, I could not get the motivation of the study.", "rating": "3: Clear rejection", "review": "The last sentence in Motivation is terminated in the middle. \n\nWhat does R^{source}, R^{target} mean? Does the symbol \"source\" denote the number of the space dimension?\n\nThe construction of G in section 2.3 seems to follow the GAN. References to the original papers should be added. Also, no explanation on discriminator D is given. Is C is used as D in the formulation? In the formulation, pi is not defined.  \n\nOverall, I could not get the motivation of the study. There is no explanation how domain adaptation is used for what purposes. The description is so incomplete to understand the idea.\n\n\n\n\n ", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Domain Adversarial Representation Learning for Data Independent Defenses against Poisoning Attacks", "abstract": "Understanding the worst case loss of a defense against a determined attack is important to evaluate the robustness of a particular classification algorithm to data poisoning attacks. Even though there are many methods for defending against attacks, they are dependent on the separability of the dataset representation. We pose this as a domain adaptation problem and learn a function in an adversarial setting to transform a dataset from a source domain to a target domain which has an established separability of clusters. The defenses thus obtained in the target domain show tighter upper bounds as compared to those in the source domain.", "paperhash": "praven|domain_adversarial_representation_learning_for_data_independent_defenses_against_poisoning_attacks", "keywords": [], "_bibtex": "@misc{\n  praven2018domain,\n  title={Domain Adversarial Representation Learning for Data Independent Defenses against Poisoning Attacks},\n  author={Ch V Sai Praven and Cheruvu Siva Kumar},\n  year={2018},\n  url={https://openreview.net/forum?id=rkdq0F1Pf}\n}", "authorids": ["chvsp972911@gmail.com"], "authors": ["Ch V Sai Praven", "Cheruvu Siva Kumar"], "TL;DR": "Domain adaptation for data defenses", "pdf": "/pdf/6dfeb1acac26ae6aabd4cb2653e8b02d35609c69.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582827725, "id": "ICLR.cc/2018/Workshop/-/Paper351/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper351/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper351/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper351/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper351/AnonReviewer2"], "reply": {"forum": "rkdq0F1Pf", "replyto": "rkdq0F1Pf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper351/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper351/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582827725}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582686828, "tcdate": 1520718271909, "number": 3, "cdate": 1520718271909, "id": "ryuT-RWYf", "invitation": "ICLR.cc/2018/Workshop/-/Paper351/Official_Review", "forum": "rkdq0F1Pf", "replyto": "rkdq0F1Pf", "signatures": ["ICLR.cc/2018/Workshop/Paper351/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper351/AnonReviewer2"], "content": {"title": "Interesting but missed many details", "rating": "5: Marginally below acceptance threshold", "review": "[Overview]\n\nThis paper proposed a domain adaptation method based on adversarial learning, to alleviate the risk of poisoning attacks. Briefly, the authors proposed a learning method to transform the source domain to a target domain which has a more cleaner boundary among different classes. The learning method borrowed the idea from adversarial domain adaptation. It is shown that with the adversarial domain adaptation, the upper bound on test loss decrease significantly on IMDB and SVHN with MNIST as the target domain.\n\n[Comments]\n\nI think the only difference between the proposed objective function and the one of original GAN is that the input z to G_{\\theta} is from a specific source domain, instead of a random noise, e.g., gaussian. \n\nThe paper missed many details. For example, what kind of representation was used to represent the source and target domain data. The architecture for generator and critic are also not explained. Also, the authors missed a number of references which should be relevant to this work.  In the experiment, the authors did not explain how to compute the upper bound on test loss. \n\nI am also curious that what if the source domain data are replaced with two gaussian components, and how the upper bound on test loss change with the change of the multi-gaussian distributions. \n\nI think this paper is not ready to be accepted but it would be a very interesting paper if the authors spend more effort to make the paper more reading-proof, explain the details in the experiments, and perform more ablated study in the experiments.\n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Domain Adversarial Representation Learning for Data Independent Defenses against Poisoning Attacks", "abstract": "Understanding the worst case loss of a defense against a determined attack is important to evaluate the robustness of a particular classification algorithm to data poisoning attacks. Even though there are many methods for defending against attacks, they are dependent on the separability of the dataset representation. We pose this as a domain adaptation problem and learn a function in an adversarial setting to transform a dataset from a source domain to a target domain which has an established separability of clusters. The defenses thus obtained in the target domain show tighter upper bounds as compared to those in the source domain.", "paperhash": "praven|domain_adversarial_representation_learning_for_data_independent_defenses_against_poisoning_attacks", "keywords": [], "_bibtex": "@misc{\n  praven2018domain,\n  title={Domain Adversarial Representation Learning for Data Independent Defenses against Poisoning Attacks},\n  author={Ch V Sai Praven and Cheruvu Siva Kumar},\n  year={2018},\n  url={https://openreview.net/forum?id=rkdq0F1Pf}\n}", "authorids": ["chvsp972911@gmail.com"], "authors": ["Ch V Sai Praven", "Cheruvu Siva Kumar"], "TL;DR": "Domain adaptation for data defenses", "pdf": "/pdf/6dfeb1acac26ae6aabd4cb2653e8b02d35609c69.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582827725, "id": "ICLR.cc/2018/Workshop/-/Paper351/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper351/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper351/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper351/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper351/AnonReviewer2"], "reply": {"forum": "rkdq0F1Pf", "replyto": "rkdq0F1Pf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper351/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper351/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582827725}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573603600, "tcdate": 1521573603600, "number": 254, "cdate": 1521573603257, "id": "BJhJkyy9z", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "rkdq0F1Pf", "replyto": "rkdq0F1Pf", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Domain Adversarial Representation Learning for Data Independent Defenses against Poisoning Attacks", "abstract": "Understanding the worst case loss of a defense against a determined attack is important to evaluate the robustness of a particular classification algorithm to data poisoning attacks. Even though there are many methods for defending against attacks, they are dependent on the separability of the dataset representation. We pose this as a domain adaptation problem and learn a function in an adversarial setting to transform a dataset from a source domain to a target domain which has an established separability of clusters. The defenses thus obtained in the target domain show tighter upper bounds as compared to those in the source domain.", "paperhash": "praven|domain_adversarial_representation_learning_for_data_independent_defenses_against_poisoning_attacks", "keywords": [], "_bibtex": "@misc{\n  praven2018domain,\n  title={Domain Adversarial Representation Learning for Data Independent Defenses against Poisoning Attacks},\n  author={Ch V Sai Praven and Cheruvu Siva Kumar},\n  year={2018},\n  url={https://openreview.net/forum?id=rkdq0F1Pf}\n}", "authorids": ["chvsp972911@gmail.com"], "authors": ["Ch V Sai Praven", "Cheruvu Siva Kumar"], "TL;DR": "Domain adaptation for data defenses", "pdf": "/pdf/6dfeb1acac26ae6aabd4cb2653e8b02d35609c69.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}