{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396678849, "tcdate": 1486396678849, "number": 1, "id": "SkyfTfUux", "invitation": "ICLR.cc/2017/conference/-/paper563/acceptance", "forum": "H1Go7Koex", "replyto": "H1Go7Koex", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "The paper introduces some interesting architectural ideas for character-aware sequence modelling. However, as pointed out by reviewers and from my own reading of the paper, this paper fails badly on the evaluation front. First, some of the evaluation tasks are poorly defined (e.g. question task). Second, the tasks look fairly simple, whereas there are \"standard\" tasks such as language modelling datasets (one of the reviewers suggests TREC, but other datasets such as NANT, PTB, or even the Billion Word Corpus) which could be used here. Finally, the benchmarks presented against are weak. There are several character-aware language models which obtain robust results on LM data which could readily be adapted to sentence representation learning, eg. Ling et al. 2016, or Chung et al. 2016, which should have been compared against. The authors should look at the evaluations in these papers and consider them for a future version of this paper. As it stands, I cannot recommend acceptance in its current form."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Character-aware Attention Residual Network for Sentence Representation", "abstract": "Text classification in general is a well studied area. However, classifying short and noisy text remains challenging. Feature sparsity is a major issue. The quality of document representation here has a great impact on the classification accuracy. Existing methods represent text using bag-of-word model, with TFIDF or other weighting schemes. Recently word embedding and even document embedding are proposed to represent text. The purpose is to capture features at both word level and sentence level. However, the character level information are usually ignored. In this paper, we take word morphology and word semantic meaning into consideration, which are represented by character-aware embedding and word distributed embedding. By concatenating both character-level and word distributed embedding together and arranging words in order, a sentence representation matrix could be obtained. To overcome data sparsity problem of short text, sentence representation vector is then derived based on different views from sentence representation matrix. The various views contributes to the construction of an enriched sentence embedding. We employ a residual network on the sentence embedding to get a consistent and refined sentence representation. Evaluated on a few short text datasets, our model outperforms state-of-the-art models.", "pdf": "/pdf/dd6c821a700f996289e5d2f1f82c0f60e98df04b.pdf", "TL;DR": "We propose a character-aware attention residual network for short text representation.", "paperhash": "zheng|characteraware_attention_residual_network_for_sentence_representation", "keywords": ["Deep learning"], "conflicts": ["cs.nyu.edu"], "authors": ["Xin Zheng", "Zhenzhou Wu"], "authorids": ["xzheng008@e.ntu.edu.sg", "zhenzhou.wu@sap.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396679343, "id": "ICLR.cc/2017/conference/-/paper563/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "H1Go7Koex", "replyto": "H1Go7Koex", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396679343}}}, {"tddate": null, "tmdate": 1483509690194, "tcdate": 1483509690194, "number": 6, "id": "SJGTyfqHg", "invitation": "ICLR.cc/2017/conference/-/paper563/public/comment", "forum": "H1Go7Koex", "replyto": "SkwzKOb4l", "signatures": ["~Xin_Zheng1"], "readers": ["everyone"], "writers": ["~Xin_Zheng1"], "content": {"title": "To AnonReviewer1", "comment": "Thanks for your comments!\n1.\tCharacter-level embedding has been utilized by many works before as we mentioned in related work. However we find that by combining character-level embedding and word-level embedding could capture more information for short noisy text and would improve the classification performance. The contribution in this paper is more on the two types of features and the first application of residual network on text representation refinement. There are less information in short noisy text than the other long text and not many works focus on short noisy text classification. The two types of features proposed in our paper could capture different aspect of information in the text and leads to good performance. Residual network could further help refine the short text representation and give better result.\n2.\tIn fact, TFIDF-SVM (linear kernel) performs quite well on text classification and it is hard to beat it. The last dataset (AG_news) is typical well-formatted relatively long documents and TFIDF-SVM has great advantage to achieve good performance. Experiment results from (Zhang et al. 2015) also suggest that the TFIDF weighting perform best on three of their testing datasets. Compared with results on ag_news, our model achieves better performance on short and noisy tweets and question datasets than all the other baselines.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Character-aware Attention Residual Network for Sentence Representation", "abstract": "Text classification in general is a well studied area. However, classifying short and noisy text remains challenging. Feature sparsity is a major issue. The quality of document representation here has a great impact on the classification accuracy. Existing methods represent text using bag-of-word model, with TFIDF or other weighting schemes. Recently word embedding and even document embedding are proposed to represent text. The purpose is to capture features at both word level and sentence level. However, the character level information are usually ignored. In this paper, we take word morphology and word semantic meaning into consideration, which are represented by character-aware embedding and word distributed embedding. By concatenating both character-level and word distributed embedding together and arranging words in order, a sentence representation matrix could be obtained. To overcome data sparsity problem of short text, sentence representation vector is then derived based on different views from sentence representation matrix. The various views contributes to the construction of an enriched sentence embedding. We employ a residual network on the sentence embedding to get a consistent and refined sentence representation. Evaluated on a few short text datasets, our model outperforms state-of-the-art models.", "pdf": "/pdf/dd6c821a700f996289e5d2f1f82c0f60e98df04b.pdf", "TL;DR": "We propose a character-aware attention residual network for short text representation.", "paperhash": "zheng|characteraware_attention_residual_network_for_sentence_representation", "keywords": ["Deep learning"], "conflicts": ["cs.nyu.edu"], "authors": ["Xin Zheng", "Zhenzhou Wu"], "authorids": ["xzheng008@e.ntu.edu.sg", "zhenzhou.wu@sap.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287519835, "id": "ICLR.cc/2017/conference/-/paper563/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "H1Go7Koex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper563/reviewers", "ICLR.cc/2017/conference/paper563/areachairs"], "cdate": 1485287519835}}}, {"tddate": null, "tmdate": 1483509280549, "tcdate": 1483509280549, "number": 5, "id": "SJ_mAb9Sg", "invitation": "ICLR.cc/2017/conference/-/paper563/public/comment", "forum": "H1Go7Koex", "replyto": "BJY73xrNx", "signatures": ["~Xin_Zheng1"], "readers": ["everyone"], "writers": ["~Xin_Zheng1"], "content": {"title": "To AnonReviewer2", "comment": "Thanks for your comments!\n1.\tCharacter-aware word embedding has been utilized by many works before as we mentioned in related work. However we find that by combining character-level embedding and word-level embedding could capture more information for short noisy text and would improve the classification performance. The contribution in this paper is more on the two types of features, and the first application of residual network on text representation refinement. There are less information in short noisy text than the other long text and not many works focus on short noisy text classification. The two types of features proposed in our paper could capture different aspects of information in the text and lead to good performance. Residual network could further help refine the short text representation and give better result.\n2.\tAs stated in paper, the short text final representation is the concatenation of two types of features which capture different aspects of information and of different scale. To make the representation more consistent, we apply residual network to refine short text final representation. \n3.\tWe add the evaluation for the character-level word embedding and the attention weight for Type 1 feature. Experiment results suggest either part could contribute to better performance.\n4.\tSorry for the typo. It should be $G$.\n5.\tThanks for the kind reminding on the citation format. We make it the appropriate way.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Character-aware Attention Residual Network for Sentence Representation", "abstract": "Text classification in general is a well studied area. However, classifying short and noisy text remains challenging. Feature sparsity is a major issue. The quality of document representation here has a great impact on the classification accuracy. Existing methods represent text using bag-of-word model, with TFIDF or other weighting schemes. Recently word embedding and even document embedding are proposed to represent text. The purpose is to capture features at both word level and sentence level. However, the character level information are usually ignored. In this paper, we take word morphology and word semantic meaning into consideration, which are represented by character-aware embedding and word distributed embedding. By concatenating both character-level and word distributed embedding together and arranging words in order, a sentence representation matrix could be obtained. To overcome data sparsity problem of short text, sentence representation vector is then derived based on different views from sentence representation matrix. The various views contributes to the construction of an enriched sentence embedding. We employ a residual network on the sentence embedding to get a consistent and refined sentence representation. Evaluated on a few short text datasets, our model outperforms state-of-the-art models.", "pdf": "/pdf/dd6c821a700f996289e5d2f1f82c0f60e98df04b.pdf", "TL;DR": "We propose a character-aware attention residual network for short text representation.", "paperhash": "zheng|characteraware_attention_residual_network_for_sentence_representation", "keywords": ["Deep learning"], "conflicts": ["cs.nyu.edu"], "authors": ["Xin Zheng", "Zhenzhou Wu"], "authorids": ["xzheng008@e.ntu.edu.sg", "zhenzhou.wu@sap.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287519835, "id": "ICLR.cc/2017/conference/-/paper563/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "H1Go7Koex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper563/reviewers", "ICLR.cc/2017/conference/paper563/areachairs"], "cdate": 1485287519835}}}, {"tddate": null, "tmdate": 1483508952932, "tcdate": 1483508952932, "number": 4, "id": "Sk-J6-qBx", "invitation": "ICLR.cc/2017/conference/-/paper563/public/comment", "forum": "H1Go7Koex", "replyto": "H1LI5KB4x", "signatures": ["~Xin_Zheng1"], "readers": ["everyone"], "writers": ["~Xin_Zheng1"], "content": {"title": "To AnonReviewer3", "comment": "Thanks for your comments! \n1.\tWe add the evaluation of weight assigned by attention model for type 1 feature and the character embedding part. Thus, each part of the architecture has an evaluation. Experiment results suggest that removing each part will lead to worse performance, especially for type 1 and type 2 feature. Thus, each part of the architecture do contribute to the final performance, and type 1 and type 2 feature are more important.\n2.\tTwitter data is typical short noisy text and we crawl tweets by ourselves as evaluation data. For text classification, TFIDF weighted feature with SVM (linear kernel) performs quite well and it is hard to beat it. Experiment results from (Zhang et al. 2015) also suggest that the TFIDF weighting perform best on three of their testing datasets. Besides, we also compare with the work from (Zhang et al. 2015) which is one of the state-of-the-art.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Character-aware Attention Residual Network for Sentence Representation", "abstract": "Text classification in general is a well studied area. However, classifying short and noisy text remains challenging. Feature sparsity is a major issue. The quality of document representation here has a great impact on the classification accuracy. Existing methods represent text using bag-of-word model, with TFIDF or other weighting schemes. Recently word embedding and even document embedding are proposed to represent text. The purpose is to capture features at both word level and sentence level. However, the character level information are usually ignored. In this paper, we take word morphology and word semantic meaning into consideration, which are represented by character-aware embedding and word distributed embedding. By concatenating both character-level and word distributed embedding together and arranging words in order, a sentence representation matrix could be obtained. To overcome data sparsity problem of short text, sentence representation vector is then derived based on different views from sentence representation matrix. The various views contributes to the construction of an enriched sentence embedding. We employ a residual network on the sentence embedding to get a consistent and refined sentence representation. Evaluated on a few short text datasets, our model outperforms state-of-the-art models.", "pdf": "/pdf/dd6c821a700f996289e5d2f1f82c0f60e98df04b.pdf", "TL;DR": "We propose a character-aware attention residual network for short text representation.", "paperhash": "zheng|characteraware_attention_residual_network_for_sentence_representation", "keywords": ["Deep learning"], "conflicts": ["cs.nyu.edu"], "authors": ["Xin Zheng", "Zhenzhou Wu"], "authorids": ["xzheng008@e.ntu.edu.sg", "zhenzhou.wu@sap.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287519835, "id": "ICLR.cc/2017/conference/-/paper563/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "H1Go7Koex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper563/reviewers", "ICLR.cc/2017/conference/paper563/areachairs"], "cdate": 1485287519835}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1483508509526, "tcdate": 1478362009911, "number": 563, "id": "H1Go7Koex", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "H1Go7Koex", "signatures": ["~Xin_Zheng1"], "readers": ["everyone"], "content": {"title": "Character-aware Attention Residual Network for Sentence Representation", "abstract": "Text classification in general is a well studied area. However, classifying short and noisy text remains challenging. Feature sparsity is a major issue. The quality of document representation here has a great impact on the classification accuracy. Existing methods represent text using bag-of-word model, with TFIDF or other weighting schemes. Recently word embedding and even document embedding are proposed to represent text. The purpose is to capture features at both word level and sentence level. However, the character level information are usually ignored. In this paper, we take word morphology and word semantic meaning into consideration, which are represented by character-aware embedding and word distributed embedding. By concatenating both character-level and word distributed embedding together and arranging words in order, a sentence representation matrix could be obtained. To overcome data sparsity problem of short text, sentence representation vector is then derived based on different views from sentence representation matrix. The various views contributes to the construction of an enriched sentence embedding. We employ a residual network on the sentence embedding to get a consistent and refined sentence representation. Evaluated on a few short text datasets, our model outperforms state-of-the-art models.", "pdf": "/pdf/dd6c821a700f996289e5d2f1f82c0f60e98df04b.pdf", "TL;DR": "We propose a character-aware attention residual network for short text representation.", "paperhash": "zheng|characteraware_attention_residual_network_for_sentence_representation", "keywords": ["Deep learning"], "conflicts": ["cs.nyu.edu"], "authors": ["Xin Zheng", "Zhenzhou Wu"], "authorids": ["xzheng008@e.ntu.edu.sg", "zhenzhou.wu@sap.com"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 11, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1482164813755, "tcdate": 1482164813755, "number": 3, "id": "H1LI5KB4x", "invitation": "ICLR.cc/2017/conference/-/paper563/official/review", "forum": "H1Go7Koex", "replyto": "H1Go7Koex", "signatures": ["ICLR.cc/2017/conference/paper563/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper563/AnonReviewer3"], "content": {"title": "Review", "rating": "4: Ok but not good enough - rejection", "review": "This paper proposes a new model for sentence classification. \n\nPros:\n- Some interesting architecture choices in the network.\n\nCons:\n- No evaluation of the architecture choices. An ablation study is critical here to understand what is important and what is not.\n- No evaluation on standard datasets. On the only pre-existing dataset evaluated on a simple TFIDF-SVM method is state-of-the-art, so results are unconvincing.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Character-aware Attention Residual Network for Sentence Representation", "abstract": "Text classification in general is a well studied area. However, classifying short and noisy text remains challenging. Feature sparsity is a major issue. The quality of document representation here has a great impact on the classification accuracy. Existing methods represent text using bag-of-word model, with TFIDF or other weighting schemes. Recently word embedding and even document embedding are proposed to represent text. The purpose is to capture features at both word level and sentence level. However, the character level information are usually ignored. In this paper, we take word morphology and word semantic meaning into consideration, which are represented by character-aware embedding and word distributed embedding. By concatenating both character-level and word distributed embedding together and arranging words in order, a sentence representation matrix could be obtained. To overcome data sparsity problem of short text, sentence representation vector is then derived based on different views from sentence representation matrix. The various views contributes to the construction of an enriched sentence embedding. We employ a residual network on the sentence embedding to get a consistent and refined sentence representation. Evaluated on a few short text datasets, our model outperforms state-of-the-art models.", "pdf": "/pdf/dd6c821a700f996289e5d2f1f82c0f60e98df04b.pdf", "TL;DR": "We propose a character-aware attention residual network for short text representation.", "paperhash": "zheng|characteraware_attention_residual_network_for_sentence_representation", "keywords": ["Deep learning"], "conflicts": ["cs.nyu.edu"], "authors": ["Xin Zheng", "Zhenzhou Wu"], "authorids": ["xzheng008@e.ntu.edu.sg", "zhenzhou.wu@sap.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512541105, "id": "ICLR.cc/2017/conference/-/paper563/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper563/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper563/AnonReviewer1", "ICLR.cc/2017/conference/paper563/AnonReviewer2", "ICLR.cc/2017/conference/paper563/AnonReviewer3"], "reply": {"forum": "H1Go7Koex", "replyto": "H1Go7Koex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper563/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper563/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512541105}}}, {"tddate": null, "tmdate": 1482128416683, "tcdate": 1482128416683, "number": 2, "id": "BJY73xrNx", "invitation": "ICLR.cc/2017/conference/-/paper563/official/review", "forum": "H1Go7Koex", "replyto": "H1Go7Koex", "signatures": ["ICLR.cc/2017/conference/paper563/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper563/AnonReviewer2"], "content": {"title": "Need more explanation about network architecture", "rating": "4: Ok but not good enough - rejection", "review": "This paper proposes a new neural network model for sentence representation. This new model is inspired by the success of residual network in Computer Vision and some observation of word morphology in Natural Language Processing. Although this paper shows that this new model could give the best results on several datasets, it lacks a strong evidence/intuition/motivation to support the network architecture.\n\nTo be specific:\n\n- I was confused by the contribution of this paper: character-aware word embedding or residual network or both?\n- The claim of using residual network in section 3.3 seems pretty thin, since it ignores some fundamental difference between image representation and sentence representation. Even though the results show that adding residual network could help, I was still not be convinced. Is there any explanation about what is captured in the residual component from the perspective of sentence modeling?\n- This paper combines several components in the classification framework, including character-aware model for word embedding, residual network and attention weight in Type 1 feature. I would like to see the contribution from each of them to the final performance, while in Table 3 I only saw one of them. Is it possible to add more results on the ablation test?\n- In equation (5), what is the meaning of $i$ in $G_i$?\n- The citation format is impropriate\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Character-aware Attention Residual Network for Sentence Representation", "abstract": "Text classification in general is a well studied area. However, classifying short and noisy text remains challenging. Feature sparsity is a major issue. The quality of document representation here has a great impact on the classification accuracy. Existing methods represent text using bag-of-word model, with TFIDF or other weighting schemes. Recently word embedding and even document embedding are proposed to represent text. The purpose is to capture features at both word level and sentence level. However, the character level information are usually ignored. In this paper, we take word morphology and word semantic meaning into consideration, which are represented by character-aware embedding and word distributed embedding. By concatenating both character-level and word distributed embedding together and arranging words in order, a sentence representation matrix could be obtained. To overcome data sparsity problem of short text, sentence representation vector is then derived based on different views from sentence representation matrix. The various views contributes to the construction of an enriched sentence embedding. We employ a residual network on the sentence embedding to get a consistent and refined sentence representation. Evaluated on a few short text datasets, our model outperforms state-of-the-art models.", "pdf": "/pdf/dd6c821a700f996289e5d2f1f82c0f60e98df04b.pdf", "TL;DR": "We propose a character-aware attention residual network for short text representation.", "paperhash": "zheng|characteraware_attention_residual_network_for_sentence_representation", "keywords": ["Deep learning"], "conflicts": ["cs.nyu.edu"], "authors": ["Xin Zheng", "Zhenzhou Wu"], "authorids": ["xzheng008@e.ntu.edu.sg", "zhenzhou.wu@sap.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512541105, "id": "ICLR.cc/2017/conference/-/paper563/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper563/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper563/AnonReviewer1", "ICLR.cc/2017/conference/paper563/AnonReviewer2", "ICLR.cc/2017/conference/paper563/AnonReviewer3"], "reply": {"forum": "H1Go7Koex", "replyto": "H1Go7Koex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper563/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper563/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512541105}}}, {"tddate": null, "tmdate": 1481898254852, "tcdate": 1481898254852, "number": 1, "id": "SkwzKOb4l", "invitation": "ICLR.cc/2017/conference/-/paper563/official/review", "forum": "H1Go7Koex", "replyto": "H1Go7Koex", "signatures": ["ICLR.cc/2017/conference/paper563/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper563/AnonReviewer1"], "content": {"title": "A paper that needs more work", "rating": "4: Ok but not good enough - rejection", "review": "This paper proposes a character-aware attention residual network for sentence embedding. Several text classification tasks are used to evaluate the effectiveness of the proposed model. On two of the three tasks, the residual network outforms a few baselines, but couldn't beat the simple TFIDF-SVM on the last one.\n\nThis work is not novel enough. Character information has been applied in many previously published work, as cited by the authors. Residual network is also not new.\n\nWhy not testing the model on a few more widely used datasets for short text classification, such as TREC? More competitive baselines can be compared to. Also, it's not clear how the \"Question\" dataset was created and which domain it is.\n\nLast, it is surprising that the format of citations throughout the paper is all wrong. \n\nFor example:\nlike Word2Vec Mikolov et al. (2013)\n->\nlike Word2Vec (Mikolov et al., 2013)\n\nThe citations can't just mix with the normal text. Please refer to other published papers.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Character-aware Attention Residual Network for Sentence Representation", "abstract": "Text classification in general is a well studied area. However, classifying short and noisy text remains challenging. Feature sparsity is a major issue. The quality of document representation here has a great impact on the classification accuracy. Existing methods represent text using bag-of-word model, with TFIDF or other weighting schemes. Recently word embedding and even document embedding are proposed to represent text. The purpose is to capture features at both word level and sentence level. However, the character level information are usually ignored. In this paper, we take word morphology and word semantic meaning into consideration, which are represented by character-aware embedding and word distributed embedding. By concatenating both character-level and word distributed embedding together and arranging words in order, a sentence representation matrix could be obtained. To overcome data sparsity problem of short text, sentence representation vector is then derived based on different views from sentence representation matrix. The various views contributes to the construction of an enriched sentence embedding. We employ a residual network on the sentence embedding to get a consistent and refined sentence representation. Evaluated on a few short text datasets, our model outperforms state-of-the-art models.", "pdf": "/pdf/dd6c821a700f996289e5d2f1f82c0f60e98df04b.pdf", "TL;DR": "We propose a character-aware attention residual network for short text representation.", "paperhash": "zheng|characteraware_attention_residual_network_for_sentence_representation", "keywords": ["Deep learning"], "conflicts": ["cs.nyu.edu"], "authors": ["Xin Zheng", "Zhenzhou Wu"], "authorids": ["xzheng008@e.ntu.edu.sg", "zhenzhou.wu@sap.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512541105, "id": "ICLR.cc/2017/conference/-/paper563/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper563/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper563/AnonReviewer1", "ICLR.cc/2017/conference/paper563/AnonReviewer2", "ICLR.cc/2017/conference/paper563/AnonReviewer3"], "reply": {"forum": "H1Go7Koex", "replyto": "H1Go7Koex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper563/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper563/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512541105}}}, {"tddate": null, "tmdate": 1480991777393, "tcdate": 1480991736980, "number": 3, "id": "Bk--EiQXg", "invitation": "ICLR.cc/2017/conference/-/paper563/public/comment", "forum": "H1Go7Koex", "replyto": "ryUuzuCGe", "signatures": ["~Zhenzhou_Wu1"], "readers": ["everyone"], "writers": ["~Zhenzhou_Wu1"], "content": {"title": "answers", "comment": "Thanks for the feedback. We have tried on a tweeter dataset that is almost sentence level and similar to stanford sentiment treebank. It's definitely interesting to test on treebank as well, we will improve on that. In the meantime, for short text, you can refer to other dataset's results. Thanks."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Character-aware Attention Residual Network for Sentence Representation", "abstract": "Text classification in general is a well studied area. However, classifying short and noisy text remains challenging. Feature sparsity is a major issue. The quality of document representation here has a great impact on the classification accuracy. Existing methods represent text using bag-of-word model, with TFIDF or other weighting schemes. Recently word embedding and even document embedding are proposed to represent text. The purpose is to capture features at both word level and sentence level. However, the character level information are usually ignored. In this paper, we take word morphology and word semantic meaning into consideration, which are represented by character-aware embedding and word distributed embedding. By concatenating both character-level and word distributed embedding together and arranging words in order, a sentence representation matrix could be obtained. To overcome data sparsity problem of short text, sentence representation vector is then derived based on different views from sentence representation matrix. The various views contributes to the construction of an enriched sentence embedding. We employ a residual network on the sentence embedding to get a consistent and refined sentence representation. Evaluated on a few short text datasets, our model outperforms state-of-the-art models.", "pdf": "/pdf/dd6c821a700f996289e5d2f1f82c0f60e98df04b.pdf", "TL;DR": "We propose a character-aware attention residual network for short text representation.", "paperhash": "zheng|characteraware_attention_residual_network_for_sentence_representation", "keywords": ["Deep learning"], "conflicts": ["cs.nyu.edu"], "authors": ["Xin Zheng", "Zhenzhou Wu"], "authorids": ["xzheng008@e.ntu.edu.sg", "zhenzhou.wu@sap.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287519835, "id": "ICLR.cc/2017/conference/-/paper563/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "H1Go7Koex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper563/reviewers", "ICLR.cc/2017/conference/paper563/areachairs"], "cdate": 1485287519835}}}, {"tddate": null, "tmdate": 1480651373740, "tcdate": 1480651373736, "number": 1, "id": "ryUuzuCGe", "invitation": "ICLR.cc/2017/conference/-/paper563/pre-review/question", "forum": "H1Go7Koex", "replyto": "H1Go7Koex", "signatures": ["ICLR.cc/2017/conference/paper563/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper563/AnonReviewer2"], "content": {"title": "Evaluation on sentiment analysis", "question": "Sentiment analysis is one of most popular tasks on text classification. It would be interesting to see the evaluation of the proposed model on some sentence-level datasets, for example, the Stanford Sentiment Treebank. Is there any reason that kind of experiment was not included?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Character-aware Attention Residual Network for Sentence Representation", "abstract": "Text classification in general is a well studied area. However, classifying short and noisy text remains challenging. Feature sparsity is a major issue. The quality of document representation here has a great impact on the classification accuracy. Existing methods represent text using bag-of-word model, with TFIDF or other weighting schemes. Recently word embedding and even document embedding are proposed to represent text. The purpose is to capture features at both word level and sentence level. However, the character level information are usually ignored. In this paper, we take word morphology and word semantic meaning into consideration, which are represented by character-aware embedding and word distributed embedding. By concatenating both character-level and word distributed embedding together and arranging words in order, a sentence representation matrix could be obtained. To overcome data sparsity problem of short text, sentence representation vector is then derived based on different views from sentence representation matrix. The various views contributes to the construction of an enriched sentence embedding. We employ a residual network on the sentence embedding to get a consistent and refined sentence representation. Evaluated on a few short text datasets, our model outperforms state-of-the-art models.", "pdf": "/pdf/dd6c821a700f996289e5d2f1f82c0f60e98df04b.pdf", "TL;DR": "We propose a character-aware attention residual network for short text representation.", "paperhash": "zheng|characteraware_attention_residual_network_for_sentence_representation", "keywords": ["Deep learning"], "conflicts": ["cs.nyu.edu"], "authors": ["Xin Zheng", "Zhenzhou Wu"], "authorids": ["xzheng008@e.ntu.edu.sg", "zhenzhou.wu@sap.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959213134, "id": "ICLR.cc/2017/conference/-/paper563/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper563/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper563/AnonReviewer2"], "reply": {"forum": "H1Go7Koex", "replyto": "H1Go7Koex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper563/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper563/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959213134}}}, {"tddate": null, "tmdate": 1479273436457, "tcdate": 1479273436451, "number": 2, "id": "r141nwt-l", "invitation": "ICLR.cc/2017/conference/-/paper563/public/comment", "forum": "H1Go7Koex", "replyto": "rysAmxK-g", "signatures": ["~Xin_Zheng1"], "readers": ["everyone"], "writers": ["~Xin_Zheng1"], "content": {"title": "Character-aware Attention Residual Network for Sentence Representation is the latest version. Thanks!", "comment": "Character-aware Attention Residual Network for Sentence Representation\nXin Zheng, Zhenzhou Wu\n5 Nov 2016\n\nThis is the latest version. Thanks for your comments!"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Character-aware Attention Residual Network for Sentence Representation", "abstract": "Text classification in general is a well studied area. However, classifying short and noisy text remains challenging. Feature sparsity is a major issue. The quality of document representation here has a great impact on the classification accuracy. Existing methods represent text using bag-of-word model, with TFIDF or other weighting schemes. Recently word embedding and even document embedding are proposed to represent text. The purpose is to capture features at both word level and sentence level. However, the character level information are usually ignored. In this paper, we take word morphology and word semantic meaning into consideration, which are represented by character-aware embedding and word distributed embedding. By concatenating both character-level and word distributed embedding together and arranging words in order, a sentence representation matrix could be obtained. To overcome data sparsity problem of short text, sentence representation vector is then derived based on different views from sentence representation matrix. The various views contributes to the construction of an enriched sentence embedding. We employ a residual network on the sentence embedding to get a consistent and refined sentence representation. Evaluated on a few short text datasets, our model outperforms state-of-the-art models.", "pdf": "/pdf/dd6c821a700f996289e5d2f1f82c0f60e98df04b.pdf", "TL;DR": "We propose a character-aware attention residual network for short text representation.", "paperhash": "zheng|characteraware_attention_residual_network_for_sentence_representation", "keywords": ["Deep learning"], "conflicts": ["cs.nyu.edu"], "authors": ["Xin Zheng", "Zhenzhou Wu"], "authorids": ["xzheng008@e.ntu.edu.sg", "zhenzhou.wu@sap.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287519835, "id": "ICLR.cc/2017/conference/-/paper563/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "H1Go7Koex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper563/reviewers", "ICLR.cc/2017/conference/paper563/areachairs"], "cdate": 1485287519835}}}, {"tddate": null, "tmdate": 1479242706969, "tcdate": 1479242706963, "number": 1, "id": "rysAmxK-g", "invitation": "ICLR.cc/2017/conference/-/paper563/public/comment", "forum": "H1Go7Koex", "replyto": "H1Go7Koex", "signatures": ["~Tara_N_Sainath1"], "readers": ["everyone"], "writers": ["~Tara_N_Sainath1"], "content": {"title": "duplicate paper", "comment": "Hi Authors,\n\nYou seem to have submitted two of the same paper? Pls advise which is the correct one\n\nCharacter-aware Attention Residual Network for Sentence Representation\nXin Zheng, Zhenzhou Wu\n5 Nov 2016\n\nCHARACTER-AWARE RESIDUAL NETWORK FOR SENTENCE REPRESENTATION\nXin Zheng, Zhenzhou Wu\n4 Nov 2016\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Character-aware Attention Residual Network for Sentence Representation", "abstract": "Text classification in general is a well studied area. However, classifying short and noisy text remains challenging. Feature sparsity is a major issue. The quality of document representation here has a great impact on the classification accuracy. Existing methods represent text using bag-of-word model, with TFIDF or other weighting schemes. Recently word embedding and even document embedding are proposed to represent text. The purpose is to capture features at both word level and sentence level. However, the character level information are usually ignored. In this paper, we take word morphology and word semantic meaning into consideration, which are represented by character-aware embedding and word distributed embedding. By concatenating both character-level and word distributed embedding together and arranging words in order, a sentence representation matrix could be obtained. To overcome data sparsity problem of short text, sentence representation vector is then derived based on different views from sentence representation matrix. The various views contributes to the construction of an enriched sentence embedding. We employ a residual network on the sentence embedding to get a consistent and refined sentence representation. Evaluated on a few short text datasets, our model outperforms state-of-the-art models.", "pdf": "/pdf/dd6c821a700f996289e5d2f1f82c0f60e98df04b.pdf", "TL;DR": "We propose a character-aware attention residual network for short text representation.", "paperhash": "zheng|characteraware_attention_residual_network_for_sentence_representation", "keywords": ["Deep learning"], "conflicts": ["cs.nyu.edu"], "authors": ["Xin Zheng", "Zhenzhou Wu"], "authorids": ["xzheng008@e.ntu.edu.sg", "zhenzhou.wu@sap.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287519835, "id": "ICLR.cc/2017/conference/-/paper563/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "H1Go7Koex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper563/reviewers", "ICLR.cc/2017/conference/paper563/areachairs"], "cdate": 1485287519835}}}], "count": 12}