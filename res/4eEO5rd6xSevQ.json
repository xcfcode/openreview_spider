{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1363851960000, "tcdate": 1363851960000, "number": 8, "id": "KktHprTPH5p6q", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "4eEO5rd6xSevQ", "replyto": "4eEO5rd6xSevQ", "signatures": ["anonymous reviewer 8b9c"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "One additional comment is that the work bears some similarities to Hinton's recent work on 'capsules' and it may be worth citing that paper:\r\n\r\nHinton, G. E., Krizhevsky, A. and Wang, S. (2011)\r\nTransforming Auto-encoders.\r\nICANN-11: International Conference on Artificial Neural Networks, Helsinki. \r\nhttp://www.cs.toronto.edu/~hinton/absps/transauto6.pdf"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Jitter-Adaptive Dictionary Learning - Application to Multi-Trial Neuroelectric Signals", "decision": "conferencePoster-iclr2013-conference", "abstract": "Dictionary Learning has proven to be a powerful tool for many image processing tasks, where atoms are typically defined on small image patches. As a drawback, the dictionary only encodes basic structures. In addition, this approach treats patches of different locations in one single set, which means a loss of information when features are well-aligned across signals. This is the case, for instance, in multi-trial magneto- or electroencephalography (M/EEG). Learning the dictionary on the entire signals could make use of the alignement and reveal higher-level features. In this case, however, small missalignements or phase variations of features would not be compensated for. In this paper, we propose an extension to the common dictionary learning framework to overcome these limitations by allowing atoms to adapt their position across signals. The method is validated on simulated and real neuroelectric data.", "pdf": "https://arxiv.org/abs/1301.3611", "paperhash": "hitziger|jitteradaptive_dictionary_learning_application_to_multitrial_neuroelectric_signals", "keywords": [], "conflicts": [], "authors": ["Sebastian Hitziger", "Maureen Clerc", "Alexandre Gramfort", "Sandrine Saillet", "Christian B\u00e9nar", "Th\u00e9odore Papadopoulo"], "authorids": ["sebastian.hitziger@gmx.de", "maureen.clerc@inria.fr", "alexandre.gramfort@telecom-paristech.fr", "ssaillet53@gmail.com", "christian.benar@univmed.fr", "theodore.papadopoulo@inria.fr"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1363646700000, "tcdate": 1363646700000, "number": 1, "id": "Gp6ETkwghDG9l", "invitation": "ICLR.cc/2013/-/submission/reply", "forum": "4eEO5rd6xSevQ", "replyto": "DdhjdI7FMGDFT", "signatures": ["anonymous reviewer 8ed7"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "The authors have improved the paper, addressing many of the issues I brought up. I would modify my review to be Neutral; if that is not an acceptable evaluation, then I modify my review to a Weak Accept. I am only posting this response to the poster asking for an updated evaluation, because I am not sure if I am supposed to make this modification public.\r\n\r\nI still have a couple of comments:\r\n\r\n1. The authors include a description of the convolution sparse coding techniques, such as SISC, which better compares their contribution to related work. SISC is not a real competitor to JADL, because it is too computationally intensive; however, in the synthetic experiments, it would be useful to include it in the comparison. If SISC outperformed JADL, it would not invalidate the usefulness of JADL (which is the only one that can be applied to large datasets), but would give a much better understanding of the properties of JADL versus these previous convolution approaches.\r\n\r\n2. The paper is over length, but I assume that will be fixed."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Jitter-Adaptive Dictionary Learning - Application to Multi-Trial Neuroelectric Signals", "decision": "conferencePoster-iclr2013-conference", "abstract": "Dictionary Learning has proven to be a powerful tool for many image processing tasks, where atoms are typically defined on small image patches. As a drawback, the dictionary only encodes basic structures. In addition, this approach treats patches of different locations in one single set, which means a loss of information when features are well-aligned across signals. This is the case, for instance, in multi-trial magneto- or electroencephalography (M/EEG). Learning the dictionary on the entire signals could make use of the alignement and reveal higher-level features. In this case, however, small missalignements or phase variations of features would not be compensated for. In this paper, we propose an extension to the common dictionary learning framework to overcome these limitations by allowing atoms to adapt their position across signals. The method is validated on simulated and real neuroelectric data.", "pdf": "https://arxiv.org/abs/1301.3611", "paperhash": "hitziger|jitteradaptive_dictionary_learning_application_to_multitrial_neuroelectric_signals", "keywords": [], "conflicts": [], "authors": ["Sebastian Hitziger", "Maureen Clerc", "Alexandre Gramfort", "Sandrine Saillet", "Christian B\u00e9nar", "Th\u00e9odore Papadopoulo"], "authorids": ["sebastian.hitziger@gmx.de", "maureen.clerc@inria.fr", "alexandre.gramfort@telecom-paristech.fr", "ssaillet53@gmail.com", "christian.benar@univmed.fr", "theodore.papadopoulo@inria.fr"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1363533540000, "tcdate": 1363533540000, "number": 4, "id": "9CrL9uhDy_qlF", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "4eEO5rd6xSevQ", "replyto": "4eEO5rd6xSevQ", "signatures": ["Aaron Courville"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "Please read the author's responses  to your review and the updated version of the paper. Do they change your evaluation of the paper?"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Jitter-Adaptive Dictionary Learning - Application to Multi-Trial Neuroelectric Signals", "decision": "conferencePoster-iclr2013-conference", "abstract": "Dictionary Learning has proven to be a powerful tool for many image processing tasks, where atoms are typically defined on small image patches. As a drawback, the dictionary only encodes basic structures. In addition, this approach treats patches of different locations in one single set, which means a loss of information when features are well-aligned across signals. This is the case, for instance, in multi-trial magneto- or electroencephalography (M/EEG). Learning the dictionary on the entire signals could make use of the alignement and reveal higher-level features. In this case, however, small missalignements or phase variations of features would not be compensated for. In this paper, we propose an extension to the common dictionary learning framework to overcome these limitations by allowing atoms to adapt their position across signals. The method is validated on simulated and real neuroelectric data.", "pdf": "https://arxiv.org/abs/1301.3611", "paperhash": "hitziger|jitteradaptive_dictionary_learning_application_to_multitrial_neuroelectric_signals", "keywords": [], "conflicts": [], "authors": ["Sebastian Hitziger", "Maureen Clerc", "Alexandre Gramfort", "Sandrine Saillet", "Christian B\u00e9nar", "Th\u00e9odore Papadopoulo"], "authorids": ["sebastian.hitziger@gmx.de", "maureen.clerc@inria.fr", "alexandre.gramfort@telecom-paristech.fr", "ssaillet53@gmail.com", "christian.benar@univmed.fr", "theodore.papadopoulo@inria.fr"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1363533480000, "tcdate": 1363533480000, "number": 1, "id": "DdhjdI7FMGDFT", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "4eEO5rd6xSevQ", "replyto": "4eEO5rd6xSevQ", "signatures": ["Aaron Courville"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "Please read the author's responses  to your review and the updated version of the paper. Do they change your evaluation of the paper?"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Jitter-Adaptive Dictionary Learning - Application to Multi-Trial Neuroelectric Signals", "decision": "conferencePoster-iclr2013-conference", "abstract": "Dictionary Learning has proven to be a powerful tool for many image processing tasks, where atoms are typically defined on small image patches. As a drawback, the dictionary only encodes basic structures. In addition, this approach treats patches of different locations in one single set, which means a loss of information when features are well-aligned across signals. This is the case, for instance, in multi-trial magneto- or electroencephalography (M/EEG). Learning the dictionary on the entire signals could make use of the alignement and reveal higher-level features. In this case, however, small missalignements or phase variations of features would not be compensated for. In this paper, we propose an extension to the common dictionary learning framework to overcome these limitations by allowing atoms to adapt their position across signals. The method is validated on simulated and real neuroelectric data.", "pdf": "https://arxiv.org/abs/1301.3611", "paperhash": "hitziger|jitteradaptive_dictionary_learning_application_to_multitrial_neuroelectric_signals", "keywords": [], "conflicts": [], "authors": ["Sebastian Hitziger", "Maureen Clerc", "Alexandre Gramfort", "Sandrine Saillet", "Christian B\u00e9nar", "Th\u00e9odore Papadopoulo"], "authorids": ["sebastian.hitziger@gmx.de", "maureen.clerc@inria.fr", "alexandre.gramfort@telecom-paristech.fr", "ssaillet53@gmail.com", "christian.benar@univmed.fr", "theodore.papadopoulo@inria.fr"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1363533480000, "tcdate": 1363533480000, "number": 6, "id": "HrUgwafkmVrpB", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "4eEO5rd6xSevQ", "replyto": "4eEO5rd6xSevQ", "signatures": ["Aaron Courville"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "Please read the author's responses  to your review and the updated version of the paper. Do they change your evaluation of the paper?"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Jitter-Adaptive Dictionary Learning - Application to Multi-Trial Neuroelectric Signals", "decision": "conferencePoster-iclr2013-conference", "abstract": "Dictionary Learning has proven to be a powerful tool for many image processing tasks, where atoms are typically defined on small image patches. As a drawback, the dictionary only encodes basic structures. In addition, this approach treats patches of different locations in one single set, which means a loss of information when features are well-aligned across signals. This is the case, for instance, in multi-trial magneto- or electroencephalography (M/EEG). Learning the dictionary on the entire signals could make use of the alignement and reveal higher-level features. In this case, however, small missalignements or phase variations of features would not be compensated for. In this paper, we propose an extension to the common dictionary learning framework to overcome these limitations by allowing atoms to adapt their position across signals. The method is validated on simulated and real neuroelectric data.", "pdf": "https://arxiv.org/abs/1301.3611", "paperhash": "hitziger|jitteradaptive_dictionary_learning_application_to_multitrial_neuroelectric_signals", "keywords": [], "conflicts": [], "authors": ["Sebastian Hitziger", "Maureen Clerc", "Alexandre Gramfort", "Sandrine Saillet", "Christian B\u00e9nar", "Th\u00e9odore Papadopoulo"], "authorids": ["sebastian.hitziger@gmx.de", "maureen.clerc@inria.fr", "alexandre.gramfort@telecom-paristech.fr", "ssaillet53@gmail.com", "christian.benar@univmed.fr", "theodore.papadopoulo@inria.fr"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1363126320000, "tcdate": 1363126320000, "number": 3, "id": "3yWm3DNg8o3fu", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "4eEO5rd6xSevQ", "replyto": "4eEO5rd6xSevQ", "signatures": ["Sebastian Hitziger, Maureen Clerc, Alexandre Gramfort, Sandrine Saillet, Christian B\u00e9nar, Th\u00e9odore Papadopoulo"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "We thank the reviewers for their constructive comments. We submitted a new version of the paper to arXiv, which should be made available on Wednesday, March 13. As one major change we now point out the similarity to convolutional/shift-invariant sparse coding (SISC)*, but also mention the differences mainly introduced by the l_0 sparsity constraint. A new contribution is an analysis of the algorithm's complexity as well as possibilities for speed ups \u2013 although the computation time was already low for the conducted experiments, this could become an issue for real-time analysis. The changes in detail:\r\n\r\n                  \r\n[1] Smith, Evan, and Michael S. Lewicki. 'Efficient coding of time-relative structure using spikes.' Neural Computation 17.1 (2005): 19-45.\r\n[2] Blumensath, Thomas, and Davies, Mike. 'Sparse and shift-invariant representations of music.' Audio, Speech, and Language Processing, IEEE Transactions on 14.1 (2006): 50-57.\r\n[3] R. Grosse, R. Raina, H. Kwong, and AY Ng, 'Shift-invariant sparse coding for audio classification,' in Proceedings of the Twenty-third Conference on Uncertainty in Artificial Intelligence (UAI'07), 2007\r\n[4] Ekanadham, Chaitanya, Daniel Tranchina, and Eero P. Simoncelli. 'Sparse decomposition of transformation-invariant signals with continuous basis pursuit.' Acoustics, Speech and Signal Processing (ICASSP), 2011 IEEE International Conference on. IEEE, 2011.\r\n\r\nIntroduction\r\nThe second part of the introduction has been rewritten. Shift-invariant sparse coding (SISC) is introduced and its differences to JADL are pointed out. Most significant is the constraint in JADL, that only one shifted version of each atom shall be active per signal. As a consequence, JADL leads to a less complex algorithm (in both, sparse coding and dictionary update step), which in contrast to SISC does not need heuristic preselection of active atoms. In addition, we remarked that JADL is designed to learn only few atoms, in contrast to most dictionary learning applications. Hence, the term \u201csparsity\u201d only makes sense with respect to the \u201cunrolled\u201d dictionary. However, for the most part this sparsity is achieved by the explicit constraint, not by sparse regularization.\r\n\r\nSection 3, JADL\r\nIn the sparse coding section, the computational advantages of the modified LARS have been pointed out and contrasted with SISC.\r\n\r\nIn the dictionary update section, we noted that the JADL formulation leads to an update of same complexity as regular DL; this does not apply to SISC. This fact could be used by changing the ratio of sparse coding and dictionary update steps in favor to the latter, i.e. by employing mini-batch or online techniques.\r\n\r\nSection 4, Experiments\r\nFor the real data, the computation time has been investigated for different K (number of atoms) and S (number of allowed shifts). The curve shows linear correlation with S; when increasing K, however, the computation time increases more than linear. This is due to the following: While both S and K affect the size of the unrolled dictionary, an increase in S is handled efficiently in the JADL formulation, as mentioned in the sections sparse coding and dictionary update above. We also mentioned that the computation time for the conducted experiments was very small (4.3 seconds for the real data), hence computational complexity should not become an issue for offline analysis. Employing the proposed speed ups and a further optimization of the code, on the other hand, could even allow for real time analysis (this could be desirable especially for M/EEG-based brain computer interfaces (BCI)) .\r\n\r\nDetailed responses to the reviewers' comments\r\n-------------------------------------------------------------\r\n\r\nAnonymous 8ed7\r\n-------------------------\r\n\r\nCons\r\n1. [Computational requirements] As mentioned above, we investigated computation time empirically for different values of S and K. Even for K=15 and S=200 (i.e. 3000 elements in the unrolled dictionary ) the computation time remained less than 1 minute for 200 iterations. Therefore, the increased complexity should only matter for real-time applications, for which we proposed several speed-ups in the formulation of the algorithm.\r\n\r\n2. (a) [Examples for shifts] We added a comment (footnote) on possible definitions of the shifts in the problem statement, there are different ways how to define the shifts at the borders. As the JADL framework is general enough to allow even arbitrary linear transforms, we do not specify a certain definition at this point. A detailed discussion of the right way to handle boundary effects would be out of the scope of the paper; however, we found that in our experiments the choice of the shifts did not affect the outcome significantly.  \r\n\r\n(b) [Examples for types of data that can be analyzed with JADL] In the introduction, we now mention similar properties to those of neuroelectric data in different bioelectric or biomagnetic signals, such as ECG, EMG. [explain \u201cfeatures well-aligned across signals\u201d] We changed this formulation to \u201ceach waveform of interest occurs approximately at the same time in every trial\u201d. Is this sufficiently clear?\r\n(c) [Improve explanation how to enforce constraint (7)] changed as suggested\r\n\r\n3. [On the importance of lambda] We agree that if the number of atoms is large, the parameter lambda has an important role to ensure sparsity. However, JADL is designed to learn only a small number K of atoms. This is due to several reasons: (i) the jitter-adaptivity ensures a compact representation, as a waveform that is shifted throughout signals can be encoded in a single atom; (ii) for the applications JADL is aimed at, it is either not desired or not feasible to learn many atoms, since (a) the dictionary should be easily interpretable and reveal the main activity across signals (b) the number of training examples M is limited and K<<M must hold to prevent from overfitting, which is a particularily critical aspect due to often high noise level. A similar comment on the different use of \u201csparsity\u201d in JADL has been added to the introduction to get this point clear.\r\n\r\n4. [Comparison to common DL with large K and large lambda] We agree that a comparison to DL with a similar K used as in JADL would not be fair. For the simulated data, different values of K have therefore been used, and lambda has been optimized individually for each K to yield the smallest error/highest similarity w.r.t. the ground truth. The table stops at K=12; for larger K performance becomes worse for all three methods. This is now pointed out in the new version.\r\n\r\nMinor Comments\r\n\r\n2. We changed the claim from \u201cthe biggest challenge\u201d to \u201can important challenge\u201d and provided references.\r\n3. changed as suggested\r\n4. changed as suggested\r\n\r\n\r\nAnonymous 5e7a\r\n-------------------------\r\n\r\nWe agree that a comparison to previous work on convolutional/shift-invariant sparse coding is necessary and hope that the changes made as described above make the similarities and differences to between SISC and JADL sufficiently clear. We found that most papers on SISC do not address the problem of the dictionary update but only focus on sparse coding. An exception was [3], from which it becomes clear that for SISC the dictionary update is a non-trivial problem with increased computational complexity.\r\n\r\nAnonymous 8b9c\r\n-------------------------\r\n\r\nSee comment above for comparison to SISC.\r\n\r\nIn fact, the LFP data does not contain much more structure than the spikes. Hence, the learned dictionaries look quite redundant and its analysis provides only limited insight in the data. However, we think that the visualization of the code reveals that although the dictionary looks redundant, important differences have been picked up, leading to contiguous sets of epochs dominated by the same atom."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Jitter-Adaptive Dictionary Learning - Application to Multi-Trial Neuroelectric Signals", "decision": "conferencePoster-iclr2013-conference", "abstract": "Dictionary Learning has proven to be a powerful tool for many image processing tasks, where atoms are typically defined on small image patches. As a drawback, the dictionary only encodes basic structures. In addition, this approach treats patches of different locations in one single set, which means a loss of information when features are well-aligned across signals. This is the case, for instance, in multi-trial magneto- or electroencephalography (M/EEG). Learning the dictionary on the entire signals could make use of the alignement and reveal higher-level features. In this case, however, small missalignements or phase variations of features would not be compensated for. In this paper, we propose an extension to the common dictionary learning framework to overcome these limitations by allowing atoms to adapt their position across signals. The method is validated on simulated and real neuroelectric data.", "pdf": "https://arxiv.org/abs/1301.3611", "paperhash": "hitziger|jitteradaptive_dictionary_learning_application_to_multitrial_neuroelectric_signals", "keywords": [], "conflicts": [], "authors": ["Sebastian Hitziger", "Maureen Clerc", "Alexandre Gramfort", "Sandrine Saillet", "Christian B\u00e9nar", "Th\u00e9odore Papadopoulo"], "authorids": ["sebastian.hitziger@gmx.de", "maureen.clerc@inria.fr", "alexandre.gramfort@telecom-paristech.fr", "ssaillet53@gmail.com", "christian.benar@univmed.fr", "theodore.papadopoulo@inria.fr"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362402300000, "tcdate": 1362402300000, "number": 7, "id": "zo2FGvCYFkoR4", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "4eEO5rd6xSevQ", "replyto": "4eEO5rd6xSevQ", "signatures": ["anonymous reviewer 8b9c"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Jitter-Adaptive Dictionary Learning - Application to Multi-Trial Neuroelectric Signals", "review": "The paper proposes a method for learning shiftable dictionary elements - i.e., each dictionary is allowed to shift to its optimal position to model structure in a signal.  Results on test data show a significant improvement over regular sparse coding dictionary learning for recovering structure in data, and results on LFP data provide a more interpretable result.\r\n\r\nThis seems like a sensible approach and the results are pretty convincing.  The choice of data seems a bit odd - all the LFP waveforms look the same, perhaps it would be worthwhile to expand the waveform so we can see more structure than just a spike.  \r\n\r\nThis approach could be easily confused for a convolution model.  The difference here is that the coefficients are mutually exclusive over shift.  the authors may want to point out the similarities and differences to a convolution sparse coding model for the reader."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Jitter-Adaptive Dictionary Learning - Application to Multi-Trial Neuroelectric Signals", "decision": "conferencePoster-iclr2013-conference", "abstract": "Dictionary Learning has proven to be a powerful tool for many image processing tasks, where atoms are typically defined on small image patches. As a drawback, the dictionary only encodes basic structures. In addition, this approach treats patches of different locations in one single set, which means a loss of information when features are well-aligned across signals. This is the case, for instance, in multi-trial magneto- or electroencephalography (M/EEG). Learning the dictionary on the entire signals could make use of the alignement and reveal higher-level features. In this case, however, small missalignements or phase variations of features would not be compensated for. In this paper, we propose an extension to the common dictionary learning framework to overcome these limitations by allowing atoms to adapt their position across signals. The method is validated on simulated and real neuroelectric data.", "pdf": "https://arxiv.org/abs/1301.3611", "paperhash": "hitziger|jitteradaptive_dictionary_learning_application_to_multitrial_neuroelectric_signals", "keywords": [], "conflicts": [], "authors": ["Sebastian Hitziger", "Maureen Clerc", "Alexandre Gramfort", "Sandrine Saillet", "Christian B\u00e9nar", "Th\u00e9odore Papadopoulo"], "authorids": ["sebastian.hitziger@gmx.de", "maureen.clerc@inria.fr", "alexandre.gramfort@telecom-paristech.fr", "ssaillet53@gmail.com", "christian.benar@univmed.fr", "theodore.papadopoulo@inria.fr"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362376680000, "tcdate": 1362376680000, "number": 2, "id": "NjApJLTlfWxlo", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "4eEO5rd6xSevQ", "replyto": "4eEO5rd6xSevQ", "signatures": ["anonymous reviewer 5e7a"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Jitter-Adaptive Dictionary Learning - Application to Multi-Trial Neuroelectric Signals", "review": "This paper introduces a sparse coding variant called 'jitter-adaptive' sparse coding, aimed at improving the efficiency of sparse coding by augmenting a dictionary with temporally shifted elements. The motivating use case is EEG data, where neural activity can arise at any time, in atoms that span multiple recording channels. Ideally these motifs would be recognized as the dictionary components by a dictionary-learning algorithm.\r\n\r\nEEG data has been analyzed with sparse coding before, as noted by the authors, and the focus of this paper is the use of jitter-adaptive dictionary learning to achieve a more useful signal decomposition.  The use of jitter adaptive dictionary learning is indeed an intuitive and effective strategy for recovering the atoms of synthetic and actual data.\r\n\r\nOne weakness of this paper is that the technique of augmenting a dictionary by a time-shifting operator is not entirely novel, and the authors should compare and contrast their approach with e.g.:\r\n\r\n- Continuous Basis Pursuit\r\n- Deconvolutional Networks- Charles Cadieu's PhD work\r\n- The Statistical Inefficiency of Sparse Coding for Images (http://arxiv.org/abs/1109.6638)\r\n  \r\n\r\nPro(s)\r\n- jitter-adaptive learning is an effective strategy for applying sparse coding \r\n  to temporal data, particularly EEG\r\n \r\nCon(s)\r\n- paper would benefit from clarification of contribution relative to previous   work"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Jitter-Adaptive Dictionary Learning - Application to Multi-Trial Neuroelectric Signals", "decision": "conferencePoster-iclr2013-conference", "abstract": "Dictionary Learning has proven to be a powerful tool for many image processing tasks, where atoms are typically defined on small image patches. As a drawback, the dictionary only encodes basic structures. In addition, this approach treats patches of different locations in one single set, which means a loss of information when features are well-aligned across signals. This is the case, for instance, in multi-trial magneto- or electroencephalography (M/EEG). Learning the dictionary on the entire signals could make use of the alignement and reveal higher-level features. In this case, however, small missalignements or phase variations of features would not be compensated for. In this paper, we propose an extension to the common dictionary learning framework to overcome these limitations by allowing atoms to adapt their position across signals. The method is validated on simulated and real neuroelectric data.", "pdf": "https://arxiv.org/abs/1301.3611", "paperhash": "hitziger|jitteradaptive_dictionary_learning_application_to_multitrial_neuroelectric_signals", "keywords": [], "conflicts": [], "authors": ["Sebastian Hitziger", "Maureen Clerc", "Alexandre Gramfort", "Sandrine Saillet", "Christian B\u00e9nar", "Th\u00e9odore Papadopoulo"], "authorids": ["sebastian.hitziger@gmx.de", "maureen.clerc@inria.fr", "alexandre.gramfort@telecom-paristech.fr", "ssaillet53@gmail.com", "christian.benar@univmed.fr", "theodore.papadopoulo@inria.fr"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362362340000, "tcdate": 1362362340000, "number": 5, "id": "DJA5lKoL8-lLY", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "4eEO5rd6xSevQ", "replyto": "4eEO5rd6xSevQ", "signatures": ["anonymous reviewer 8ed7"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Jitter-Adaptive Dictionary Learning - Application to Multi-Trial Neuroelectric Signals", "review": "This paper introduces a dictionary learning technique that incorporates time delays or shifts on the learned dictionary, called JADL, to better account for this structure in multi-trial neuroelectric signals. The algorithm uses the previous dictionary learning framework and non-convex optimization, but adds a selection step over possible shifts for each atom (for each point), framed as an l-0 optimization. This objective is the main contribution of the paper, which enables better performance for time-delayed data as well as potentially useful temporal structure to be extracted from the data.\r\n\r\nThe paper introduces a novel objective for addressing the time shift problem (e.g in M/EEG data), but frames a typical coordinate descent approach for solving the resulting non-convex problem.  The main difference in the optimization is (1) ensuring that the coefficients, a, for the dictionary, D, block-wise satisfy the l-0 constraint by disabling updates to all but one coefficient within a block and (2) modifying the gradient update in block coordinate descent on the dictionary, D, which now has a shift operator around D. Taking this obvious solution route leads to a non-convex optimization and potentially lengthy computation (as the delta set size increases). The quality of writing and experiments is high.\r\n\r\nPros\r\n1. The proposed JADL algorithm facilitates application of dictionary learning techniques to M/EEG data, which is an important application. Moreover, as a secondary benefit, it allows time-delay structure to be learned.\r\n\r\n2. The writing is mostly clear and the paper is well organized.\r\n\r\n3. Experimental results are comprehensive and include important details of their experimental procedure.\r\n\r\nCons\r\n1. The computational requirements of this algorithm are not explored, though the larger dictionary in JADL (due to the addition of delta shifts) could significantly slow learning.\r\n\r\n2. For clarity: (a) Include examples of shifts, Delta, in the problem statement (such as the ones used in the experiments). (b) Include examples of the types of data that could benefit from this framework, to better justify the importance of framing the problem with time-shifts and better explain what is meant by 'features [being] well-aligned across signals'.  (c ) The explanation of how to enforce constraint (7) should be improved, e.g. 'block all other coefficients a_j^{S,i}' should probably be 'block all other coefficients in segment a_j^{S,i}', but the meaning is actually significantly different and this was quite confusing.\r\n\r\n3. The comment that the parameter, lambda, is no longer important because sparsity is induced by the constraint in (7) suggests that as the size of the set of delta increases, this problem formulation no longer learns a sparse solution over the chosen dictionary. I would suggest that this is not the case, but rather that the datasets used in this paper had a small dictionary and did not require the coefficients to be sparse. The constraint in (7) simply ensures that only one delta is chosen per atom, but does not guarantee that the final solution over the delta-shifted dictionary will be sparse. Therefore, if the number of atoms is large, the regularizer || a_j ||_1 should still be important. It is true that constraint (7) ensures the solution is sparse over all possible delta-shifted dictionaries; this is however an unfair comparison to other dictionary learning techniques which have a much smaller dictionary space to weight over.\r\n\r\n4. Con (3) suggests that learning with a very large dictionary (the size of the delta-shifted dictionary set) and setting the lambda parameter large might have more comparable performance to the algorithm suggested in this paper and should be included. Of course, this highly regularized approach on a large dictionary would not explicitly provide the time shift structure in the data as does JADL, but would be an interesting and more fair comparison. However, if the time-shift structure is not actually useful (and is simply used to improve learning), then DL with a large dictionary and large regularization parameter, lambda, could be all that is needed to deal with this problem for EEG data. The authors should clarify this difference and contribution more clearly.\r\n\r\n\r\nMinor Comments:\r\n1. For a reference on convex solution to the dictionary learning problem, see 'Convex sparse matrix factorizations', F. Bach, J. Mairal and J. Ponce. 2008; and 'Convex Sparse Coding, Subspace Learning and Semi-Supervised Extensions', X. Zhang, Y. Yu, M. White, R. Huang and D. Schuurmans. 2011.\r\n2. There should be citations for the claim: 'This issue is currently the biggest challenge\r\nin M/EEG multi-trial analysis.'\r\n3. Bottom of page 3: 'which allows to solve it' -> 'which allows us to solve it'\r\n4. Page 5: 'property allows to' -> 'property allows us to'"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Jitter-Adaptive Dictionary Learning - Application to Multi-Trial Neuroelectric Signals", "decision": "conferencePoster-iclr2013-conference", "abstract": "Dictionary Learning has proven to be a powerful tool for many image processing tasks, where atoms are typically defined on small image patches. As a drawback, the dictionary only encodes basic structures. In addition, this approach treats patches of different locations in one single set, which means a loss of information when features are well-aligned across signals. This is the case, for instance, in multi-trial magneto- or electroencephalography (M/EEG). Learning the dictionary on the entire signals could make use of the alignement and reveal higher-level features. In this case, however, small missalignements or phase variations of features would not be compensated for. In this paper, we propose an extension to the common dictionary learning framework to overcome these limitations by allowing atoms to adapt their position across signals. The method is validated on simulated and real neuroelectric data.", "pdf": "https://arxiv.org/abs/1301.3611", "paperhash": "hitziger|jitteradaptive_dictionary_learning_application_to_multitrial_neuroelectric_signals", "keywords": [], "conflicts": [], "authors": ["Sebastian Hitziger", "Maureen Clerc", "Alexandre Gramfort", "Sandrine Saillet", "Christian B\u00e9nar", "Th\u00e9odore Papadopoulo"], "authorids": ["sebastian.hitziger@gmx.de", "maureen.clerc@inria.fr", "alexandre.gramfort@telecom-paristech.fr", "ssaillet53@gmail.com", "christian.benar@univmed.fr", "theodore.papadopoulo@inria.fr"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1358427600000, "tcdate": 1358427600000, "number": 33, "id": "4eEO5rd6xSevQ", "invitation": "ICLR.cc/2013/conference/-/submission", "forum": "4eEO5rd6xSevQ", "signatures": ["sebastian.hitziger@gmx.de"], "readers": ["everyone"], "content": {"title": "Jitter-Adaptive Dictionary Learning - Application to Multi-Trial Neuroelectric Signals", "decision": "conferencePoster-iclr2013-conference", "abstract": "Dictionary Learning has proven to be a powerful tool for many image processing tasks, where atoms are typically defined on small image patches. As a drawback, the dictionary only encodes basic structures. In addition, this approach treats patches of different locations in one single set, which means a loss of information when features are well-aligned across signals. This is the case, for instance, in multi-trial magneto- or electroencephalography (M/EEG). Learning the dictionary on the entire signals could make use of the alignement and reveal higher-level features. In this case, however, small missalignements or phase variations of features would not be compensated for. In this paper, we propose an extension to the common dictionary learning framework to overcome these limitations by allowing atoms to adapt their position across signals. The method is validated on simulated and real neuroelectric data.", "pdf": "https://arxiv.org/abs/1301.3611", "paperhash": "hitziger|jitteradaptive_dictionary_learning_application_to_multitrial_neuroelectric_signals", "keywords": [], "conflicts": [], "authors": ["Sebastian Hitziger", "Maureen Clerc", "Alexandre Gramfort", "Sandrine Saillet", "Christian B\u00e9nar", "Th\u00e9odore Papadopoulo"], "authorids": ["sebastian.hitziger@gmx.de", "maureen.clerc@inria.fr", "alexandre.gramfort@telecom-paristech.fr", "ssaillet53@gmail.com", "christian.benar@univmed.fr", "theodore.papadopoulo@inria.fr"]}, "writers": [], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496673673639, "cdate": 1496673673639, "tcdate": 1496673673639, "id": "ICLR.cc/2013/conference/-/submission", "writers": ["ICLR.cc/2013"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717}}}], "count": 10}