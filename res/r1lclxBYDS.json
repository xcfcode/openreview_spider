{"notes": [{"id": "r1lclxBYDS", "original": "ryls26kFDB", "number": 2109, "cdate": 1569439730096, "ddate": null, "tcdate": 1569439730096, "tmdate": 1577168244686, "tddate": null, "forum": "r1lclxBYDS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "On the implicit minimization of alternative loss functions when training deep networks", "authors": ["Alexandre Lemire Paquin", "Brahim Chaib-draa", "Philippe Gigu\u00e8re"], "authorids": ["alexandre.lemire-paquin.1@ulaval.ca", "brahim.chaib-draa@ift.ulaval.ca", "philippe.giguere@ift.ulaval.ca"], "keywords": ["implicit minimization", "optimization bias", "margin based loss functions", "flat minima"], "TL;DR": "We study how the batch size and the learning affect the implicit minimization of different loss functions.", "abstract": "Understanding the implicit bias of optimization algorithms is important in order to improve generalization of neural networks. One approach to try to exploit such understanding would be to then make the bias explicit in the loss function.  Conversely, an interesting approach to gain more insights into the implicit bias could be to study how different loss functions  are being implicitly minimized when training the network. In this work, we concentrate our study on the inductive bias occurring when minimizing the cross-entropy loss with different batch sizes and learning rates.  We investigate how three loss functions are being implicitly minimized during training. These three loss functions are the Hinge loss with different margins, the cross-entropy loss with different temperatures and a newly introduced Gcdf loss with different standard deviations. This  Gcdf loss establishes a connection between a sharpness measure for the 0\u22121 loss and margin based loss functions. We find that a common behavior is emerging for all the loss functions considered.", "pdf": "/pdf/a3c36c4f3b86a0ccd2afa515b2f44eb9a406b6b7.pdf", "paperhash": "paquin|on_the_implicit_minimization_of_alternative_loss_functions_when_training_deep_networks", "original_pdf": "/attachment/a3c36c4f3b86a0ccd2afa515b2f44eb9a406b6b7.pdf", "_bibtex": "@misc{\npaquin2020on,\ntitle={On the implicit minimization of alternative loss functions when training deep networks},\nauthor={Alexandre Lemire Paquin and Brahim Chaib-draa and Philippe Gigu{\\`e}re},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lclxBYDS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "yK4J9sWXy6", "original": null, "number": 1, "cdate": 1576798740744, "ddate": null, "tcdate": 1576798740744, "tmdate": 1576800895507, "tddate": null, "forum": "r1lclxBYDS", "replyto": "r1lclxBYDS", "invitation": "ICLR.cc/2020/Conference/Paper2109/-/Decision", "content": {"decision": "Reject", "comment": "The paper proposes an interesting setting in which the effect of different optimization parameters on the loss function is analyzed.  The analysis is based on considering cross-entropy loss with different softmax parameters, or hinge loss with different margin parameters.  The observations are interesting but ultimately the reviewers felt that the experimental results were not sufficient to warrant publication at ICLR.  The reviews unanimously recommended rejection, and no rebuttal was provided.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the implicit minimization of alternative loss functions when training deep networks", "authors": ["Alexandre Lemire Paquin", "Brahim Chaib-draa", "Philippe Gigu\u00e8re"], "authorids": ["alexandre.lemire-paquin.1@ulaval.ca", "brahim.chaib-draa@ift.ulaval.ca", "philippe.giguere@ift.ulaval.ca"], "keywords": ["implicit minimization", "optimization bias", "margin based loss functions", "flat minima"], "TL;DR": "We study how the batch size and the learning affect the implicit minimization of different loss functions.", "abstract": "Understanding the implicit bias of optimization algorithms is important in order to improve generalization of neural networks. One approach to try to exploit such understanding would be to then make the bias explicit in the loss function.  Conversely, an interesting approach to gain more insights into the implicit bias could be to study how different loss functions  are being implicitly minimized when training the network. In this work, we concentrate our study on the inductive bias occurring when minimizing the cross-entropy loss with different batch sizes and learning rates.  We investigate how three loss functions are being implicitly minimized during training. These three loss functions are the Hinge loss with different margins, the cross-entropy loss with different temperatures and a newly introduced Gcdf loss with different standard deviations. This  Gcdf loss establishes a connection between a sharpness measure for the 0\u22121 loss and margin based loss functions. We find that a common behavior is emerging for all the loss functions considered.", "pdf": "/pdf/a3c36c4f3b86a0ccd2afa515b2f44eb9a406b6b7.pdf", "paperhash": "paquin|on_the_implicit_minimization_of_alternative_loss_functions_when_training_deep_networks", "original_pdf": "/attachment/a3c36c4f3b86a0ccd2afa515b2f44eb9a406b6b7.pdf", "_bibtex": "@misc{\npaquin2020on,\ntitle={On the implicit minimization of alternative loss functions when training deep networks},\nauthor={Alexandre Lemire Paquin and Brahim Chaib-draa and Philippe Gigu{\\`e}re},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lclxBYDS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "r1lclxBYDS", "replyto": "r1lclxBYDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795725551, "tmdate": 1576800277465, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2109/-/Decision"}}}, {"id": "ryx18TZ6dr", "original": null, "number": 1, "cdate": 1570737479286, "ddate": null, "tcdate": 1570737479286, "tmdate": 1572972381971, "tddate": null, "forum": "r1lclxBYDS", "replyto": "r1lclxBYDS", "invitation": "ICLR.cc/2020/Conference/Paper2109/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper want to show that minimizing cross-entropy loss will simultaneously minimize Hinge loss with different margins, cross-entropy loss with different temperatures and a newly introduced Gcdf loss with different standard deviations. The main contribution is a new gcdf loss based on Gaussian-perturbed parameters. However, this loss can only be used with linear models. For deep models, the authors suggest that only measure this loss on the top layer of model.\n\nThe motivation is week. Seems most of these loss functions only depend on s_i - s_j, the difference between logits. And the optimization with cross-entropy loss wants to maximize this difference between logits corresponding to true labels and false labels, which is obviously minimize difference loss functions. So I do not feel surprise that optimizing the neural network with cross-entropy loss will minimize other kinds of losses.\n\nThe format is poor. The figures occupy most of the places and thus let me feel the contents of this paper is somewhat weak.\n\nDetailed Comments:\n1. In Sec 3.1, it will be better to mention that y belongs to +1 and -1. Also, in the last sentence in Sec 3.1, the meaning of x is normalized is ambiguous. I guess the authors want to say if x is unit norm?\n2. Will adding the regularization of the feature map norm violate the performance?\n3. What do the authors want to say in Sec 4.3? Does the relation of learning rate and convergence rate of gcdf loss indicate some non-trivial results?\n4. I cannot understand the meaning of Figure 7. Obviously different learning rate may lead to different training process and thus the different solution and different s_i - s_j. But I think this is not related to the different losses. With simple calculation I think we can find all of these losses have some relation with s_i - s_j and thus we can directly say different learning rate lead to different s_i - s_j and there is no need to relate s_i - s_j to these losses.\n\nOverall I find the claims of this paper is somewhat weak. Gcdf loss seems related to some kinds of adversarial robustness that can be individual interest, but the current paper is still far from the standard of publication. Some more interesting and valuable directions can be the theoretically analysis of the equivalence between the objective optimization, e.g. minimizing cross-entropy loss is equivalent to minimizing gcdf loss for example, as well as the empirical comparison between the different losses, like selecting some losses as objective can boost the performance on some aspects."}, "signatures": ["ICLR.cc/2020/Conference/Paper2109/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2109/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the implicit minimization of alternative loss functions when training deep networks", "authors": ["Alexandre Lemire Paquin", "Brahim Chaib-draa", "Philippe Gigu\u00e8re"], "authorids": ["alexandre.lemire-paquin.1@ulaval.ca", "brahim.chaib-draa@ift.ulaval.ca", "philippe.giguere@ift.ulaval.ca"], "keywords": ["implicit minimization", "optimization bias", "margin based loss functions", "flat minima"], "TL;DR": "We study how the batch size and the learning affect the implicit minimization of different loss functions.", "abstract": "Understanding the implicit bias of optimization algorithms is important in order to improve generalization of neural networks. One approach to try to exploit such understanding would be to then make the bias explicit in the loss function.  Conversely, an interesting approach to gain more insights into the implicit bias could be to study how different loss functions  are being implicitly minimized when training the network. In this work, we concentrate our study on the inductive bias occurring when minimizing the cross-entropy loss with different batch sizes and learning rates.  We investigate how three loss functions are being implicitly minimized during training. These three loss functions are the Hinge loss with different margins, the cross-entropy loss with different temperatures and a newly introduced Gcdf loss with different standard deviations. This  Gcdf loss establishes a connection between a sharpness measure for the 0\u22121 loss and margin based loss functions. We find that a common behavior is emerging for all the loss functions considered.", "pdf": "/pdf/a3c36c4f3b86a0ccd2afa515b2f44eb9a406b6b7.pdf", "paperhash": "paquin|on_the_implicit_minimization_of_alternative_loss_functions_when_training_deep_networks", "original_pdf": "/attachment/a3c36c4f3b86a0ccd2afa515b2f44eb9a406b6b7.pdf", "_bibtex": "@misc{\npaquin2020on,\ntitle={On the implicit minimization of alternative loss functions when training deep networks},\nauthor={Alexandre Lemire Paquin and Brahim Chaib-draa and Philippe Gigu{\\`e}re},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lclxBYDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "r1lclxBYDS", "replyto": "r1lclxBYDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2109/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2109/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575835294477, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2109/Reviewers"], "noninvitees": [], "tcdate": 1570237727589, "tmdate": 1575835294489, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2109/-/Official_Review"}}}, {"id": "ryeeKOZatS", "original": null, "number": 2, "cdate": 1571784823781, "ddate": null, "tcdate": 1571784823781, "tmdate": 1572972381935, "tddate": null, "forum": "r1lclxBYDS", "replyto": "r1lclxBYDS", "invitation": "ICLR.cc/2020/Conference/Paper2109/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper adds to a large body of research on implicit regularization:\nin the context of deep networks, that, when SGD with a certain step\nsize or batch size is used, from among parameter vectors that fit\nthe data equally well, some are much more likely to be chosen than\nothers.  This paper attacks this question through the lens of\nloss functions: when SGD is applied to the usual softmax loss\nwith a given learning rate, how does the choice of learning\nrate effect how rapidly other loss functions are reduced?  They\npay special attention to a loss function that they call Gcdf,\nwhich is motivated by \"wide minima\" considerations.  In particular,\nfor the Gcdf to be small, not only must training examples be\nclassified correctly, but randomly perturbing the weights in\nthe last layer should not change this correct prediction.\n\nI am convinced that Figures 6 and 12 of this paper show\nthat optimization of the softmax with a larger step size\nimplicitly optimizes a loss function that rewards robustness\nto a greater extent than when a small step size is used.\nI find this interesting.\n\nThe authors do a nice job of summarizing a lot of related work.\n\nThe Gcdf loss is similar to the ramp loss used in [1]\n(see Section 3.1) and elsewhere, including to analyze\ngeneralization in deep learning.  It is also like the\npotential function optimized by RobustBoost\n(see (4) of [2]) -- the RobustBoost loss function does\nnot scale by the norm of x, but since it is an ensemble\nmethod, the role of x is played by the predictions of\nmembers of the ensemble, which have a fixed scale.\n\nI assume that, when they evaluate the Gcdf loss for a deep\nnetwork, they normalize by the norm of the last hidden\nlayer.  If this is true, it only captures \"wide minima\"\nin the sense of being robust with respect to perturbations\nof the output layer.  (They seem to acknowledge this point\nin their paper.)\n\nThe results in the paper are not described in enough\ndetail to be reproduced.  For example, I don't see\nwhere they specify the architecture of the network\nthat they used in Section 4.\n\nThe experiments are limited and narrow in scope.\n\nIn Figures 2 and 3 I don't see that they have adequately controlled\nfor the effect of the learning rate on how fast the explicitly\nminimized loss is reduced.  Part of the effect observed is simply\nthat, when a small learning rate is used, after a given number of\nepochs, the weights are just not changed much, so that no loss is\nreduced much.  In Figure 2, I find it strange that they did not plot\nthe values for T=1.\n\nFigure 6 is the most interesting to me.  It seems to show that\ntraining the same loss function with a larger learning rate\neffectively optimizes the gcdf loss that rewards sacrificing\ntraining error to achieve stronger robustness.  \n\nSmall point: the first time I read Appendix A, I thought that the\nresults were not there.  It was only later that I saw the figures with\nthe MNIST results.  It would be helpful if the authors wrote\n\"The results are in Figures 8-12\".\n\nWhile, as I wrote above, I did find Figure 6 interesting, I feel that\nthe increment of this research over the large body of previous work\non this topic is not enough to justify publication in ICLR.\n\n\n\n\n[1] Bartlett, Peter L., Dylan J. Foster, and Matus\nJ. Telgarsky. \"Spectrally-normalized margin bounds for neural\nnetworks.\" Advances in Neural Information Processing Systems. 2017.\n\n[2] https://arxiv.org/pdf/0905.2138.pdf\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2109/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2109/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the implicit minimization of alternative loss functions when training deep networks", "authors": ["Alexandre Lemire Paquin", "Brahim Chaib-draa", "Philippe Gigu\u00e8re"], "authorids": ["alexandre.lemire-paquin.1@ulaval.ca", "brahim.chaib-draa@ift.ulaval.ca", "philippe.giguere@ift.ulaval.ca"], "keywords": ["implicit minimization", "optimization bias", "margin based loss functions", "flat minima"], "TL;DR": "We study how the batch size and the learning affect the implicit minimization of different loss functions.", "abstract": "Understanding the implicit bias of optimization algorithms is important in order to improve generalization of neural networks. One approach to try to exploit such understanding would be to then make the bias explicit in the loss function.  Conversely, an interesting approach to gain more insights into the implicit bias could be to study how different loss functions  are being implicitly minimized when training the network. In this work, we concentrate our study on the inductive bias occurring when minimizing the cross-entropy loss with different batch sizes and learning rates.  We investigate how three loss functions are being implicitly minimized during training. These three loss functions are the Hinge loss with different margins, the cross-entropy loss with different temperatures and a newly introduced Gcdf loss with different standard deviations. This  Gcdf loss establishes a connection between a sharpness measure for the 0\u22121 loss and margin based loss functions. We find that a common behavior is emerging for all the loss functions considered.", "pdf": "/pdf/a3c36c4f3b86a0ccd2afa515b2f44eb9a406b6b7.pdf", "paperhash": "paquin|on_the_implicit_minimization_of_alternative_loss_functions_when_training_deep_networks", "original_pdf": "/attachment/a3c36c4f3b86a0ccd2afa515b2f44eb9a406b6b7.pdf", "_bibtex": "@misc{\npaquin2020on,\ntitle={On the implicit minimization of alternative loss functions when training deep networks},\nauthor={Alexandre Lemire Paquin and Brahim Chaib-draa and Philippe Gigu{\\`e}re},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lclxBYDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "r1lclxBYDS", "replyto": "r1lclxBYDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2109/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2109/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575835294477, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2109/Reviewers"], "noninvitees": [], "tcdate": 1570237727589, "tmdate": 1575835294489, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2109/-/Official_Review"}}}, {"id": "B1lQ53WCKH", "original": null, "number": 3, "cdate": 1571851403252, "ddate": null, "tcdate": 1571851403252, "tmdate": 1572972381889, "tddate": null, "forum": "r1lclxBYDS", "replyto": "r1lclxBYDS", "invitation": "ICLR.cc/2020/Conference/Paper2109/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper makes a step towards understanding of the implicit bias of optimization algorithms in deep learning. The authors consider alternative loss functions for deep networks: (1) the temperature-scaled cross-entropy loss with different values of the temperature; (2) the hinge-loss with different values of the margin parameter; (3) the Gcdf loss with different values of the variance parameter. The paper introduces the Gcdf loss which is derived as a modification of the 0-1 loss under the noise in the parameters of the linear output layer. The authors propose to use the alternative losses as measures of margin and sharpness associated with a solution found by an optimization algorithm. The experiments show how SGD in different learning scenarios (low/high learning rate and small/large batch) performs implicit minimization of the alternative loss functions with different parameters. Specifically, using larger learning rates/smaller batch sizes is shown to implicitly minimize the losses corresponding to higher values of the temperature/margin/variance. The results provide insights about margins and sharpness of solutions found by different modes of SGD.\n\nThe direction explored in the paper is important for the understanding of the connections between optimization, properties of the loss landscapes (such as sharpness), and generalization. The results reported in the paper are interesting. However, currently I am not convinced that the contributions are sufficient for publication at ICLR as the scope of the performed analysis is limited. In my view, the study is not comprehensive enough and the paper would benefit from incorporating additional results. \n\nDetailed comments:\n\n\n1) My main concern is that currently there is very little explanation provided for the observed experimental findings. The paper would strongly benefit from additional results focused on identification and verification of the mechanisms behind the observed behavior of the optimizer. \n\n2) Many connections mentioned in the paper are left unexplored. It would help to investigate the mentioned connections between the implicit minimization of the considered losses and sharpness, curvature, and generalization. A similar design of the experiment can be used in which the alternative loss values can be tracked alongside with the validation loss (or multiple losses) as well as the measures of sharpness and the characteristics of the Hessian.\n\n3) Another direction for improvement is the extension of the set of analyzed settings (as it was mentioned in the discussion section). This includes performing the analysis for a broader set of architectures (potentially with different normalization schemes), optimizers, and choices of the hyperparameters (momentum, weight decay). These experiments would help to better understand the observed phenomenon and analyze the effect of different settings.\n \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2109/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2109/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "On the implicit minimization of alternative loss functions when training deep networks", "authors": ["Alexandre Lemire Paquin", "Brahim Chaib-draa", "Philippe Gigu\u00e8re"], "authorids": ["alexandre.lemire-paquin.1@ulaval.ca", "brahim.chaib-draa@ift.ulaval.ca", "philippe.giguere@ift.ulaval.ca"], "keywords": ["implicit minimization", "optimization bias", "margin based loss functions", "flat minima"], "TL;DR": "We study how the batch size and the learning affect the implicit minimization of different loss functions.", "abstract": "Understanding the implicit bias of optimization algorithms is important in order to improve generalization of neural networks. One approach to try to exploit such understanding would be to then make the bias explicit in the loss function.  Conversely, an interesting approach to gain more insights into the implicit bias could be to study how different loss functions  are being implicitly minimized when training the network. In this work, we concentrate our study on the inductive bias occurring when minimizing the cross-entropy loss with different batch sizes and learning rates.  We investigate how three loss functions are being implicitly minimized during training. These three loss functions are the Hinge loss with different margins, the cross-entropy loss with different temperatures and a newly introduced Gcdf loss with different standard deviations. This  Gcdf loss establishes a connection between a sharpness measure for the 0\u22121 loss and margin based loss functions. We find that a common behavior is emerging for all the loss functions considered.", "pdf": "/pdf/a3c36c4f3b86a0ccd2afa515b2f44eb9a406b6b7.pdf", "paperhash": "paquin|on_the_implicit_minimization_of_alternative_loss_functions_when_training_deep_networks", "original_pdf": "/attachment/a3c36c4f3b86a0ccd2afa515b2f44eb9a406b6b7.pdf", "_bibtex": "@misc{\npaquin2020on,\ntitle={On the implicit minimization of alternative loss functions when training deep networks},\nauthor={Alexandre Lemire Paquin and Brahim Chaib-draa and Philippe Gigu{\\`e}re},\nyear={2020},\nurl={https://openreview.net/forum?id=r1lclxBYDS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "r1lclxBYDS", "replyto": "r1lclxBYDS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2109/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2109/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575835294477, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2109/Reviewers"], "noninvitees": [], "tcdate": 1570237727589, "tmdate": 1575835294489, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2109/-/Official_Review"}}}], "count": 5}