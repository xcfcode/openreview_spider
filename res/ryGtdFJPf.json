{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124428354, "tcdate": 1518471289644, "number": 296, "cdate": 1518471289644, "id": "ryGtdFJPf", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "ryGtdFJPf", "signatures": ["~Anna_Thomas1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Learning Invariance with Compact Transforms", "abstract": "The problem of building machine learning models that admit efficient representations and also capture an appropriate inductive bias for the domain has recently attracted significant interest. Existing work for compressing deep learning pipelines has explored classes of structured matrices that exhibit forms of shift-invariance akin to convolutions. We leverage the displacement rank framework to automatically learn the structured class, allowing for adaptation to the invariances required for a given dataset while preserving asymptotically efficient multiplication and storage. In a setting with a small fixed parameter budget, our broad classes of structured matrices improve final accuracy by 5-7% on standard image classification datasets compared to conventional parameter constraining methods.", "paperhash": "thomas|learning_invariance_with_compact_transforms", "keywords": ["structured matrices", "low displacement rank", "learning invariance", "model compression"], "_bibtex": "@misc{\n  thomas2018learning,\n  title={Learning Invariance with Compact Transforms},\n  author={Anna T. Thomas and Albert Gu and Tri Dao and Atri Rudra and Christopher R\u00e9},\n  year={2018},\n  url={https://openreview.net/forum?id=ryGtdFJPf}\n}", "authorids": ["thomasat@stanford.edu", "albertgu@stanford.edu", "trid@stanford.edu", "atri@buffalo.edu", "chrismre@cs.stanford.edu"], "authors": ["Anna T. Thomas", "Albert Gu", "Tri Dao", "Atri Rudra", "Christopher R\u00e9"], "TL;DR": "We leverage the displacement rank framework to automatically learn compact models, adapting to invariances in a given dataset while preserving efficient operations.", "pdf": "/pdf/583cdb2d1bfb45aa4e34f486df3c75702b9bd2ff.pdf"}, "nonreaders": [], "details": {"replyCount": 6, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582802753, "tcdate": 1520622391374, "number": 1, "cdate": 1520622391374, "id": "r1kHjUxFz", "invitation": "ICLR.cc/2018/Workshop/-/Paper296/Official_Review", "forum": "ryGtdFJPf", "replyto": "ryGtdFJPf", "signatures": ["ICLR.cc/2018/Workshop/Paper296/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper296/AnonReviewer1"], "content": {"title": "generalized low rank structure for compression and guiding inductive bias in neural nets", "rating": "8: Top 50% of accepted papers, clear accept", "review": "The authors significantly generalize previous work in compressing weight matrices in neural nets by introducing the use of low displacement rank matrices. Prior works considered low-rank matrices and certain classes of structured matrices, including toeplitz, circulant, vandermonde, which are instances of LDR matrices.\n\nThe novel contribution of this work is to realize that this more general class of matrices can be used to decrease the model size, and to demonstrate that the inductive biases gained thereby can be useful. I recommend it be accepted, as I think this is an interesting and useful formalization for practitioners, both from the point of view of (potential) efficiency, and from its ability to learn and expose inductive biases --- e.g. in the best case one could imagine that learning the correct LDR structures might lead to improved performance on certain classes of non-image data in the same way that the form of the matrices in CNNs (in combination with structure of the connections) has proven to be quite useful for image data.\n\nPros:\n- The authors unify and generalize a large number of weight matrix structures previously used to compress and guide inductive bias in neural networks, and demonstrate that learning the correct LDR structure is feasible and can lead to improved performance over previous such fixed structures.\n\nCons:\n- The authors do not provide timing information to show that learning with LDR matrices can be accomplished efficiently as they claim\n- The description of Figure 1 in Section 3 and the figure itself does not seem to match: shouldn't h in the figure be 623290?- - What does the Krylov(...) notation in Theorem 1 mean: how can one use this to compute a matrix-vector multiply? \n- I would like to have seen a discussion of the implications of the Zhao et al. 2017 ICML paper on theoretical guarantees for using LDR matrices as weights to the approach suggested by the authors.\n\n\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Invariance with Compact Transforms", "abstract": "The problem of building machine learning models that admit efficient representations and also capture an appropriate inductive bias for the domain has recently attracted significant interest. Existing work for compressing deep learning pipelines has explored classes of structured matrices that exhibit forms of shift-invariance akin to convolutions. We leverage the displacement rank framework to automatically learn the structured class, allowing for adaptation to the invariances required for a given dataset while preserving asymptotically efficient multiplication and storage. In a setting with a small fixed parameter budget, our broad classes of structured matrices improve final accuracy by 5-7% on standard image classification datasets compared to conventional parameter constraining methods.", "paperhash": "thomas|learning_invariance_with_compact_transforms", "keywords": ["structured matrices", "low displacement rank", "learning invariance", "model compression"], "_bibtex": "@misc{\n  thomas2018learning,\n  title={Learning Invariance with Compact Transforms},\n  author={Anna T. Thomas and Albert Gu and Tri Dao and Atri Rudra and Christopher R\u00e9},\n  year={2018},\n  url={https://openreview.net/forum?id=ryGtdFJPf}\n}", "authorids": ["thomasat@stanford.edu", "albertgu@stanford.edu", "trid@stanford.edu", "atri@buffalo.edu", "chrismre@cs.stanford.edu"], "authors": ["Anna T. Thomas", "Albert Gu", "Tri Dao", "Atri Rudra", "Christopher R\u00e9"], "TL;DR": "We leverage the displacement rank framework to automatically learn compact models, adapting to invariances in a given dataset while preserving efficient operations.", "pdf": "/pdf/583cdb2d1bfb45aa4e34f486df3c75702b9bd2ff.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582802527, "id": "ICLR.cc/2018/Workshop/-/Paper296/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper296/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper296/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper296/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper296/AnonReviewer2"], "reply": {"forum": "ryGtdFJPf", "replyto": "ryGtdFJPf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper296/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper296/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582802527}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582764213, "tcdate": 1520641261921, "number": 2, "cdate": 1520641261921, "id": "HkUlBixKf", "invitation": "ICLR.cc/2018/Workshop/-/Paper296/Official_Review", "forum": "ryGtdFJPf", "replyto": "ryGtdFJPf", "signatures": ["ICLR.cc/2018/Workshop/Paper296/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper296/AnonReviewer3"], "content": {"title": "Seems to have good results", "rating": "8: Top 50% of accepted papers, clear accept", "review": "The paper discusses a new framework for encoding structure in neural net layers (extending basic ideas like sparsity, convolutional structure, and others discussed in Sindhwani et al.). Their \"LDR\" structure captures enough information, while still reducing the number of parameters to show a benefit. The actual details of how to do this, and the training, is not explained, but the results on some standard test problems show promise.\n\nThis seems a very topical paper, with interesting results, and fits well in the workshop track. It could lead to a quite interesting full paper.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Invariance with Compact Transforms", "abstract": "The problem of building machine learning models that admit efficient representations and also capture an appropriate inductive bias for the domain has recently attracted significant interest. Existing work for compressing deep learning pipelines has explored classes of structured matrices that exhibit forms of shift-invariance akin to convolutions. We leverage the displacement rank framework to automatically learn the structured class, allowing for adaptation to the invariances required for a given dataset while preserving asymptotically efficient multiplication and storage. In a setting with a small fixed parameter budget, our broad classes of structured matrices improve final accuracy by 5-7% on standard image classification datasets compared to conventional parameter constraining methods.", "paperhash": "thomas|learning_invariance_with_compact_transforms", "keywords": ["structured matrices", "low displacement rank", "learning invariance", "model compression"], "_bibtex": "@misc{\n  thomas2018learning,\n  title={Learning Invariance with Compact Transforms},\n  author={Anna T. Thomas and Albert Gu and Tri Dao and Atri Rudra and Christopher R\u00e9},\n  year={2018},\n  url={https://openreview.net/forum?id=ryGtdFJPf}\n}", "authorids": ["thomasat@stanford.edu", "albertgu@stanford.edu", "trid@stanford.edu", "atri@buffalo.edu", "chrismre@cs.stanford.edu"], "authors": ["Anna T. Thomas", "Albert Gu", "Tri Dao", "Atri Rudra", "Christopher R\u00e9"], "TL;DR": "We leverage the displacement rank framework to automatically learn compact models, adapting to invariances in a given dataset while preserving efficient operations.", "pdf": "/pdf/583cdb2d1bfb45aa4e34f486df3c75702b9bd2ff.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582802527, "id": "ICLR.cc/2018/Workshop/-/Paper296/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper296/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper296/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper296/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper296/AnonReviewer2"], "reply": {"forum": "ryGtdFJPf", "replyto": "ryGtdFJPf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper296/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper296/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582802527}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582724731, "tcdate": 1520678121266, "number": 3, "cdate": 1520678121266, "id": "BkZgSNbtM", "invitation": "ICLR.cc/2018/Workshop/-/Paper296/Official_Review", "forum": "ryGtdFJPf", "replyto": "ryGtdFJPf", "signatures": ["ICLR.cc/2018/Workshop/Paper296/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper296/AnonReviewer2"], "content": {"title": "An interesting paper about constructing compressed neural nets with low displacement rank layers where the displacement operators are learned from the data.", "rating": "8: Top 50% of accepted papers, clear accept", "review": "The paper belongs to the body of work investigating structured matrices for constructing compressed neural nets. The main idea here is to rely on low displacement rank structured matrices that can be represented by a displacement operator and a low-rank residual. The authors show that by learning the displacement operator which models the invariances in the data, they outperform state of the art approaches based on structured matrices by improving the final accuracy by 5\u20137% on standard image classification datasets.\n\nThe idea is very seductive, and it seems to rely on a well-founded theoretical development. That said, I must confess that I've been a little bit frustrated to not know more on how learning the displacement operator is concretely performed. The paper mentions that this is done by considering it as a parameter, but how the gradient is computed is not clear. It is probably not a hard task, but I recommend the authors to provide more details in the appendix.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Invariance with Compact Transforms", "abstract": "The problem of building machine learning models that admit efficient representations and also capture an appropriate inductive bias for the domain has recently attracted significant interest. Existing work for compressing deep learning pipelines has explored classes of structured matrices that exhibit forms of shift-invariance akin to convolutions. We leverage the displacement rank framework to automatically learn the structured class, allowing for adaptation to the invariances required for a given dataset while preserving asymptotically efficient multiplication and storage. In a setting with a small fixed parameter budget, our broad classes of structured matrices improve final accuracy by 5-7% on standard image classification datasets compared to conventional parameter constraining methods.", "paperhash": "thomas|learning_invariance_with_compact_transforms", "keywords": ["structured matrices", "low displacement rank", "learning invariance", "model compression"], "_bibtex": "@misc{\n  thomas2018learning,\n  title={Learning Invariance with Compact Transforms},\n  author={Anna T. Thomas and Albert Gu and Tri Dao and Atri Rudra and Christopher R\u00e9},\n  year={2018},\n  url={https://openreview.net/forum?id=ryGtdFJPf}\n}", "authorids": ["thomasat@stanford.edu", "albertgu@stanford.edu", "trid@stanford.edu", "atri@buffalo.edu", "chrismre@cs.stanford.edu"], "authors": ["Anna T. Thomas", "Albert Gu", "Tri Dao", "Atri Rudra", "Christopher R\u00e9"], "TL;DR": "We leverage the displacement rank framework to automatically learn compact models, adapting to invariances in a given dataset while preserving efficient operations.", "pdf": "/pdf/583cdb2d1bfb45aa4e34f486df3c75702b9bd2ff.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582802527, "id": "ICLR.cc/2018/Workshop/-/Paper296/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper296/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper296/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper296/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper296/AnonReviewer2"], "reply": {"forum": "ryGtdFJPf", "replyto": "ryGtdFJPf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper296/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper296/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582802527}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573547654, "tcdate": 1521573547654, "number": 20, "cdate": 1521573547307, "id": "r1NhAARFf", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "ryGtdFJPf", "replyto": "ryGtdFJPf", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Invariance with Compact Transforms", "abstract": "The problem of building machine learning models that admit efficient representations and also capture an appropriate inductive bias for the domain has recently attracted significant interest. Existing work for compressing deep learning pipelines has explored classes of structured matrices that exhibit forms of shift-invariance akin to convolutions. We leverage the displacement rank framework to automatically learn the structured class, allowing for adaptation to the invariances required for a given dataset while preserving asymptotically efficient multiplication and storage. In a setting with a small fixed parameter budget, our broad classes of structured matrices improve final accuracy by 5-7% on standard image classification datasets compared to conventional parameter constraining methods.", "paperhash": "thomas|learning_invariance_with_compact_transforms", "keywords": ["structured matrices", "low displacement rank", "learning invariance", "model compression"], "_bibtex": "@misc{\n  thomas2018learning,\n  title={Learning Invariance with Compact Transforms},\n  author={Anna T. Thomas and Albert Gu and Tri Dao and Atri Rudra and Christopher R\u00e9},\n  year={2018},\n  url={https://openreview.net/forum?id=ryGtdFJPf}\n}", "authorids": ["thomasat@stanford.edu", "albertgu@stanford.edu", "trid@stanford.edu", "atri@buffalo.edu", "chrismre@cs.stanford.edu"], "authors": ["Anna T. Thomas", "Albert Gu", "Tri Dao", "Atri Rudra", "Christopher R\u00e9"], "TL;DR": "We leverage the displacement rank framework to automatically learn compact models, adapting to invariances in a given dataset while preserving efficient operations.", "pdf": "/pdf/583cdb2d1bfb45aa4e34f486df3c75702b9bd2ff.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}, {"tddate": null, "ddate": null, "tmdate": 1518984316165, "tcdate": 1518984316165, "number": 2, "cdate": 1518984316165, "id": "ByEYnLDPz", "invitation": "ICLR.cc/2018/Workshop/-/Paper296/Public_Comment", "forum": "ryGtdFJPf", "replyto": "HyzjBjHPf", "signatures": ["~Anna_Thomas1"], "readers": ["everyone"], "writers": ["~Anna_Thomas1"], "content": {"title": "Fixed length", "comment": "Thank you for letting us know. We have sent in an updated version. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Invariance with Compact Transforms", "abstract": "The problem of building machine learning models that admit efficient representations and also capture an appropriate inductive bias for the domain has recently attracted significant interest. Existing work for compressing deep learning pipelines has explored classes of structured matrices that exhibit forms of shift-invariance akin to convolutions. We leverage the displacement rank framework to automatically learn the structured class, allowing for adaptation to the invariances required for a given dataset while preserving asymptotically efficient multiplication and storage. In a setting with a small fixed parameter budget, our broad classes of structured matrices improve final accuracy by 5-7% on standard image classification datasets compared to conventional parameter constraining methods.", "paperhash": "thomas|learning_invariance_with_compact_transforms", "keywords": ["structured matrices", "low displacement rank", "learning invariance", "model compression"], "_bibtex": "@misc{\n  thomas2018learning,\n  title={Learning Invariance with Compact Transforms},\n  author={Anna T. Thomas and Albert Gu and Tri Dao and Atri Rudra and Christopher R\u00e9},\n  year={2018},\n  url={https://openreview.net/forum?id=ryGtdFJPf}\n}", "authorids": ["thomasat@stanford.edu", "albertgu@stanford.edu", "trid@stanford.edu", "atri@buffalo.edu", "chrismre@cs.stanford.edu"], "authors": ["Anna T. Thomas", "Albert Gu", "Tri Dao", "Atri Rudra", "Christopher R\u00e9"], "TL;DR": "We leverage the displacement rank framework to automatically learn compact models, adapting to invariances in a given dataset while preserving efficient operations.", "pdf": "/pdf/583cdb2d1bfb45aa4e34f486df3c75702b9bd2ff.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712623406, "id": "ICLR.cc/2018/Workshop/-/Paper296/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper296/Reviewers"], "reply": {"replyto": null, "forum": "ryGtdFJPf", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712623406}}}, {"tddate": null, "ddate": null, "tmdate": 1518871962212, "tcdate": 1518871962212, "number": 1, "cdate": 1518871962212, "id": "HyzjBjHPf", "invitation": "ICLR.cc/2018/Workshop/-/Paper296/Public_Comment", "forum": "ryGtdFJPf", "replyto": "ryGtdFJPf", "signatures": ["~Oriol_Vinyals1"], "readers": ["everyone"], "writers": ["~Oriol_Vinyals1"], "content": {"title": "Please Fix Length", "comment": "Your paper violates by a few lines the 3 page limit (see https://iclr.cc/Conferences/2018/CallForWorkshops). Please send us a fixed version of your PDF at iclr2018.programchairs@gmail.com by the end of Monday, February 19th, or else we will reject your paper.\n\nThanks,\nICLR2018 Program Chairs"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Invariance with Compact Transforms", "abstract": "The problem of building machine learning models that admit efficient representations and also capture an appropriate inductive bias for the domain has recently attracted significant interest. Existing work for compressing deep learning pipelines has explored classes of structured matrices that exhibit forms of shift-invariance akin to convolutions. We leverage the displacement rank framework to automatically learn the structured class, allowing for adaptation to the invariances required for a given dataset while preserving asymptotically efficient multiplication and storage. In a setting with a small fixed parameter budget, our broad classes of structured matrices improve final accuracy by 5-7% on standard image classification datasets compared to conventional parameter constraining methods.", "paperhash": "thomas|learning_invariance_with_compact_transforms", "keywords": ["structured matrices", "low displacement rank", "learning invariance", "model compression"], "_bibtex": "@misc{\n  thomas2018learning,\n  title={Learning Invariance with Compact Transforms},\n  author={Anna T. Thomas and Albert Gu and Tri Dao and Atri Rudra and Christopher R\u00e9},\n  year={2018},\n  url={https://openreview.net/forum?id=ryGtdFJPf}\n}", "authorids": ["thomasat@stanford.edu", "albertgu@stanford.edu", "trid@stanford.edu", "atri@buffalo.edu", "chrismre@cs.stanford.edu"], "authors": ["Anna T. Thomas", "Albert Gu", "Tri Dao", "Atri Rudra", "Christopher R\u00e9"], "TL;DR": "We leverage the displacement rank framework to automatically learn compact models, adapting to invariances in a given dataset while preserving efficient operations.", "pdf": "/pdf/583cdb2d1bfb45aa4e34f486df3c75702b9bd2ff.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518712623406, "id": "ICLR.cc/2018/Workshop/-/Paper296/Public_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper296/Reviewers"], "reply": {"replyto": null, "forum": "ryGtdFJPf", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1518712623406}}}], "count": 7}