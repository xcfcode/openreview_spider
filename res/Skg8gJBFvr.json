{"notes": [{"id": "Skg8gJBFvr", "original": "ryg_cEjdDr", "number": 1506, "cdate": 1569439469678, "ddate": null, "tcdate": 1569439469678, "tmdate": 1577168224570, "tddate": null, "forum": "Skg8gJBFvr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["zhangdinghuai@pku.edu.cn", "lushleaf21@gmail.com", "cygong@cs.utexas.edu", "zhanxing.zhu@pku.edu.cn", "lqiang@cs.utexas.edu"], "title": "Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing", "authors": ["Dinghuai Zhang*", "Mao Ye*", "Chengyue Gong*", "Zhanxing Zhu", "Qiang Liu"], "pdf": "/pdf/5430ccda33560b7029405730fa6562adde7517ec.pdf", "TL;DR": "We improve existing certification results with a new certification framework by reformulating the original problem to a functional optimization one, and design a new distribution family which suits this task better through this framework.", "abstract": "Randomized classifiers have been shown to provide a promising approach for achieving certified robustness against adversarial attacks in deep learning. However, most existing methods only leverage Gaussian smoothing noise and only work for $\\ell_2$ perturbation. We propose a general framework of adversarial certification with non-Gaussian noise and for more general types of attacks, from a unified functional optimization perspective. Our new framework allows us to identify a key trade-off between accuracy and robustness via designing smoothing distributions, helping to design two new families of non-Gaussian smoothing distributions that work more efficiently for $\\ell_2$ and $\\ell_\\infty$ attacks, respectively. Our proposed methods achieve better results than previous works and provide a new perspective on randomized smoothing certification.", "keywords": ["Adversarial Certification", "Randomized Smoothing", "Functional Optimization"], "paperhash": "zhang|filling_the_soap_bubbles_efficient_blackbox_adversarial_certification_with_nongaussian_smoothing", "original_pdf": "/attachment/a0d9b6e729690f3d5caaa80fbaff632a81858fa9.pdf", "_bibtex": "@misc{\nzhang*2020filling,\ntitle={Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing},\nauthor={Dinghuai Zhang* and Mao Ye* and Chengyue Gong* and Zhanxing Zhu and Qiang Liu},\nyear={2020},\nurl={https://openreview.net/forum?id=Skg8gJBFvr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 13, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "Vgu2JZ1WMj", "original": null, "number": 1, "cdate": 1576798725075, "ddate": null, "tcdate": 1576798725075, "tmdate": 1576800911433, "tddate": null, "forum": "Skg8gJBFvr", "replyto": "Skg8gJBFvr", "invitation": "ICLR.cc/2020/Conference/Paper1506/-/Decision", "content": {"decision": "Reject", "comment": "The authors extend the framework of randomized smoothing to handle non-Gaussian smoothing distribution and use this to show that they can construct smoothed models that perform well against l2 and linf adversarial attacks. They show that the resulting framework can obtain state-of-the-art certified robustness results improving upon prior work.\n\nWhile the paper contains several interesting ideas, the reviewers were concerned about several technical flaws and omissions from the paper:\n\n1) A theorem on strong duality was incorrect in the initial version of the paper, though this was fixed in the rebuttal. However, the reasoning of the authors on the \"fundamental trade-off\" is specific to the particular framework they consider, and is not really a fundamental trade-off.\n\n2) The justification for the new family of distributions constructed by the author is not very clear and the experiments only show marginal improvements over prior work. Thus, the significance of this contribution is not clear.\n\nSome of the issues were clarified during the rebuttal, but the reviewers remained unconvinced about the above points.\n\nThus, the paper cannot be accepted in its current form.\n", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zhangdinghuai@pku.edu.cn", "lushleaf21@gmail.com", "cygong@cs.utexas.edu", "zhanxing.zhu@pku.edu.cn", "lqiang@cs.utexas.edu"], "title": "Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing", "authors": ["Dinghuai Zhang*", "Mao Ye*", "Chengyue Gong*", "Zhanxing Zhu", "Qiang Liu"], "pdf": "/pdf/5430ccda33560b7029405730fa6562adde7517ec.pdf", "TL;DR": "We improve existing certification results with a new certification framework by reformulating the original problem to a functional optimization one, and design a new distribution family which suits this task better through this framework.", "abstract": "Randomized classifiers have been shown to provide a promising approach for achieving certified robustness against adversarial attacks in deep learning. However, most existing methods only leverage Gaussian smoothing noise and only work for $\\ell_2$ perturbation. We propose a general framework of adversarial certification with non-Gaussian noise and for more general types of attacks, from a unified functional optimization perspective. Our new framework allows us to identify a key trade-off between accuracy and robustness via designing smoothing distributions, helping to design two new families of non-Gaussian smoothing distributions that work more efficiently for $\\ell_2$ and $\\ell_\\infty$ attacks, respectively. Our proposed methods achieve better results than previous works and provide a new perspective on randomized smoothing certification.", "keywords": ["Adversarial Certification", "Randomized Smoothing", "Functional Optimization"], "paperhash": "zhang|filling_the_soap_bubbles_efficient_blackbox_adversarial_certification_with_nongaussian_smoothing", "original_pdf": "/attachment/a0d9b6e729690f3d5caaa80fbaff632a81858fa9.pdf", "_bibtex": "@misc{\nzhang*2020filling,\ntitle={Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing},\nauthor={Dinghuai Zhang* and Mao Ye* and Chengyue Gong* and Zhanxing Zhu and Qiang Liu},\nyear={2020},\nurl={https://openreview.net/forum?id=Skg8gJBFvr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "Skg8gJBFvr", "replyto": "Skg8gJBFvr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795703710, "tmdate": 1576800251139, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1506/-/Decision"}}}, {"id": "r1x8lRc2jB", "original": null, "number": 8, "cdate": 1573854702118, "ddate": null, "tcdate": 1573854702118, "tmdate": 1573854702118, "tddate": null, "forum": "Skg8gJBFvr", "replyto": "Skg8gJBFvr", "invitation": "ICLR.cc/2020/Conference/Paper1506/-/Official_Comment", "content": {"title": "Summary of paper revision", "comment": "We fix the issue of Theorem 1 pointed out by Reviewer #3. Our lower bound is still tight (strong duality holds) for all the cases we studied."}, "signatures": ["ICLR.cc/2020/Conference/Paper1506/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1506/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zhangdinghuai@pku.edu.cn", "lushleaf21@gmail.com", "cygong@cs.utexas.edu", "zhanxing.zhu@pku.edu.cn", "lqiang@cs.utexas.edu"], "title": "Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing", "authors": ["Dinghuai Zhang*", "Mao Ye*", "Chengyue Gong*", "Zhanxing Zhu", "Qiang Liu"], "pdf": "/pdf/5430ccda33560b7029405730fa6562adde7517ec.pdf", "TL;DR": "We improve existing certification results with a new certification framework by reformulating the original problem to a functional optimization one, and design a new distribution family which suits this task better through this framework.", "abstract": "Randomized classifiers have been shown to provide a promising approach for achieving certified robustness against adversarial attacks in deep learning. However, most existing methods only leverage Gaussian smoothing noise and only work for $\\ell_2$ perturbation. We propose a general framework of adversarial certification with non-Gaussian noise and for more general types of attacks, from a unified functional optimization perspective. Our new framework allows us to identify a key trade-off between accuracy and robustness via designing smoothing distributions, helping to design two new families of non-Gaussian smoothing distributions that work more efficiently for $\\ell_2$ and $\\ell_\\infty$ attacks, respectively. Our proposed methods achieve better results than previous works and provide a new perspective on randomized smoothing certification.", "keywords": ["Adversarial Certification", "Randomized Smoothing", "Functional Optimization"], "paperhash": "zhang|filling_the_soap_bubbles_efficient_blackbox_adversarial_certification_with_nongaussian_smoothing", "original_pdf": "/attachment/a0d9b6e729690f3d5caaa80fbaff632a81858fa9.pdf", "_bibtex": "@misc{\nzhang*2020filling,\ntitle={Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing},\nauthor={Dinghuai Zhang* and Mao Ye* and Chengyue Gong* and Zhanxing Zhu and Qiang Liu},\nyear={2020},\nurl={https://openreview.net/forum?id=Skg8gJBFvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Skg8gJBFvr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1506/Authors", "ICLR.cc/2020/Conference/Paper1506/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1506/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1506/Reviewers", "ICLR.cc/2020/Conference/Paper1506/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1506/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1506/Authors|ICLR.cc/2020/Conference/Paper1506/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504155005, "tmdate": 1576860557408, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1506/Authors", "ICLR.cc/2020/Conference/Paper1506/Reviewers", "ICLR.cc/2020/Conference/Paper1506/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1506/-/Official_Comment"}}}, {"id": "BJxlo2c2jB", "original": null, "number": 6, "cdate": 1573854359985, "ddate": null, "tcdate": 1573854359985, "tmdate": 1573854359985, "tddate": null, "forum": "Skg8gJBFvr", "replyto": "ByllmnE6tH", "invitation": "ICLR.cc/2020/Conference/Paper1506/-/Official_Comment", "content": {"title": "Thanks for your review. 2/2", "comment": "3. (sketchy justification): 'The paper justifies a smoothing distribution that concentrates more mass around the center as follows: 'This phenomenon makes it problematic to use standard Gaussian distribution for adversarial certification, because one would expect that the smoothing distribution should concentrate around the center (the original image) in order to make the smoothed classifier close to the original classifier (and hence accurate).' I don't see why we should want more mass near the center---in the limit as we move all the mass towards the center and get the original classifier, our certified bound will be terrible, so it's not clear why moving in that direction should be expected to help. Indeed, the experimental gains are minimal (1 to 3 percentage points) and on methods that were not carefully tuned, so one could imagine that the baseline method could be improved by that much just with careful tuning.'\n\nReply: As we have shown in Eq (7), the certified lower bound can be interpreted as two terms: the \"accuracy\" and the \"robustness\". And a good certified lower bound is based on a good trade-off between these two terms: Too much perturbation on the original image will cause the classifier gives prediction with low accuracy while having good robustness (low lambda-total variation). On the other hand, as you said, in the extreme case, if we move all the mass to center, the certified bound would be terrible. This is because in this case, the lambda-total variation would be very large but meanwhile, we have high prediction accuracy. The reason we have better accuracy is obvious: the perturbed image is more close to the original image. \n\nAgain, the key argument of our paper is on: using the proposed distribution to achieve a better trade-off between accuracy and robustness. It is not that meaningful to have an argument that considering the 'limit' case because the art in this area is playing with the trade-off.\n\nRegarding your question on the experiment, we want to point out that in all the experiments, we simply use the pre-trained models provided by the paper we compare. We believe that those pre-trained models are well tuned to have good performance for the baseline method. We expect to get similar (or better) results with further tuning.\n\nWe also want to highlight that the improvement we made is not marginal at all, comparing with several recent works in this area, including the concurrent submission we mentioned (https://openreview.net/forum?id=SJlKrkSFPH). \n\n4. I similarly didn't understand the justification for the mixed L-inf / L-2 distribution for L-infinity verification. The main justification was \"The motivation is that this allows us to allocate more probability mass along the 'pointy' directions with larger norm, and hence decrease the maximum distance term max \u03b4\u2208B`\u221e,rDF(\u03bb\u03c00\u2016\u03c0\u03b4)\" This is at the very least too brief for justifying the main experimental innovation in the paper (here at least the empirical improvements are bigger, although still not huge).\n\nThe proposed mixed L-inf/L-2 distribution has two terms: ||z||_\\infty^-k and \\exp(-||z||^2_2/\\sigma^2). The second term controls the tail behavior of the proposed distribution. We justify why we use \\ell_2 norm for this term by Theorem 4. The first controls how the distribution shrink towards the center. As illustrated in Figure3, as the \\ell_infty is a hypercube and using \\ell_norm will have less total variation and thus gives better performance. \n\nBesides, to the best of our knowledge, we have achieved the best certified accuracy on l_infty certification on Imagenet at the time of submission.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1506/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1506/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zhangdinghuai@pku.edu.cn", "lushleaf21@gmail.com", "cygong@cs.utexas.edu", "zhanxing.zhu@pku.edu.cn", "lqiang@cs.utexas.edu"], "title": "Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing", "authors": ["Dinghuai Zhang*", "Mao Ye*", "Chengyue Gong*", "Zhanxing Zhu", "Qiang Liu"], "pdf": "/pdf/5430ccda33560b7029405730fa6562adde7517ec.pdf", "TL;DR": "We improve existing certification results with a new certification framework by reformulating the original problem to a functional optimization one, and design a new distribution family which suits this task better through this framework.", "abstract": "Randomized classifiers have been shown to provide a promising approach for achieving certified robustness against adversarial attacks in deep learning. However, most existing methods only leverage Gaussian smoothing noise and only work for $\\ell_2$ perturbation. We propose a general framework of adversarial certification with non-Gaussian noise and for more general types of attacks, from a unified functional optimization perspective. Our new framework allows us to identify a key trade-off between accuracy and robustness via designing smoothing distributions, helping to design two new families of non-Gaussian smoothing distributions that work more efficiently for $\\ell_2$ and $\\ell_\\infty$ attacks, respectively. Our proposed methods achieve better results than previous works and provide a new perspective on randomized smoothing certification.", "keywords": ["Adversarial Certification", "Randomized Smoothing", "Functional Optimization"], "paperhash": "zhang|filling_the_soap_bubbles_efficient_blackbox_adversarial_certification_with_nongaussian_smoothing", "original_pdf": "/attachment/a0d9b6e729690f3d5caaa80fbaff632a81858fa9.pdf", "_bibtex": "@misc{\nzhang*2020filling,\ntitle={Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing},\nauthor={Dinghuai Zhang* and Mao Ye* and Chengyue Gong* and Zhanxing Zhu and Qiang Liu},\nyear={2020},\nurl={https://openreview.net/forum?id=Skg8gJBFvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Skg8gJBFvr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1506/Authors", "ICLR.cc/2020/Conference/Paper1506/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1506/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1506/Reviewers", "ICLR.cc/2020/Conference/Paper1506/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1506/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1506/Authors|ICLR.cc/2020/Conference/Paper1506/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504155005, "tmdate": 1576860557408, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1506/Authors", "ICLR.cc/2020/Conference/Paper1506/Reviewers", "ICLR.cc/2020/Conference/Paper1506/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1506/-/Official_Comment"}}}, {"id": "B1eytnq3jr", "original": null, "number": 5, "cdate": 1573854326962, "ddate": null, "tcdate": 1573854326962, "tmdate": 1573854326962, "tddate": null, "forum": "Skg8gJBFvr", "replyto": "ByllmnE6tH", "invitation": "ICLR.cc/2020/Conference/Paper1506/-/Official_Comment", "content": {"title": "Thanks for your review. 1/2", "comment": "Response to Reviewer #3\n\nThank you very for your time and comments. Here we provide our response. We hope you could consider raising your score if they addresses your concerns. Otherwise, please let us know and we will try our best to improve and clarify. We hope the reviewer could take the overall benefit and potentials of our new framework into account when it comes to the decision. \n\nAs we also point to the other reviewers and AC,  there is an independent and concurrent submission to ICLR that overlaps with our work in both our basic framework and many detailed algorithmic choices. \"A FRAMEWORK FOR ROBUSTNESS CERTIFICATION OF SMOOTHED CLASSIFIERS USING F-DIVERGENCES (https://openreview.net/forum?id=SJlKrkSFPH)\".  Because of the high overlap with our work, we hope you could also check this paper and their reviews and calibrate your score accordingly, since if our work is rejected while their accepted only due to uncalibrated reviews, it would block the opportunity for publishing our work in the future.  \n\n1. (main theorem is incorrect): 'Claim 3 in the appendix is wrong. The fact that (delta', f') outperforms (delta-bar, f-bar) with respect to lambda* does not imply that (delta', f', lambda*) is a better solution to the primal problem, because we must take max over lambda and the maximizing lambda need not be lambda*. In particular if f' doesn't satisfy the constraint we would instead take lambda to infinity.'\n\nReply: Thanks very much for pointing out this!  We have *fixed the issue*. The strong duality is the previous submission is wrong. In the newly updated version, we show that strong duality holds for the case of our experiment, that is, the proposed method is tight for the certification problem we studied. Please check the updated draft for details.\n\n2. 'The paper makes several references (in italics) to a \"fundamental trade-off between accuracy and robustness\". But a fundamental trade-off means that *any* method that attains good accuracy must sacrifice robustness and vice versa; this requires a \"for all\" statement, i.e. a lower bound. All the paper shows is that the *particular upper bound* exhibits a trade-off (and even then, the notions of \"accuracy\" and \"robustness\" are merely interpretations of quantities in the bound; it's not clear why the robustness term in particular is tied to more standard notions of robustness).'\n\nTheoretically, as shown by our theory, if we view the adversarial certification problem as a constraint optimization problem and set the space of classifier space as F_[0,1], the solution of the lower bound can be decomposed into the two terms in Equ(7). Under the assumption in our paper, this is a 'for all' statement and this statement holds. \n\nSecondly, the adversarial defense is on the trade-off between accuracy and robustness. We believe this point of view should have been widely accepted by the community, e.g. [1, 2, 3]. There are many ways to mathematically characterize this trade-off and this is exactly one of our contributions. \n\n[1] Zhang, Hongyang, et al. \"Theoretically principled trade-off between robustness and accuracy.\" International conference on machine learning. 2019.\n\n[2] Raghunathan, Aditi, et al. \"Adversarial Training Can Hurt Generalization.\" arXiv preprint arXiv:1906.06032 (2019).\n\n[3] Shi, Yujun, et al. \"Understanding Adversarial Behavior of DNNs by Disentangling Non-Robust and Robust Components in Performance Metric.\" arXiv preprint arXiv:1906.02494 (2019).\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1506/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1506/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zhangdinghuai@pku.edu.cn", "lushleaf21@gmail.com", "cygong@cs.utexas.edu", "zhanxing.zhu@pku.edu.cn", "lqiang@cs.utexas.edu"], "title": "Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing", "authors": ["Dinghuai Zhang*", "Mao Ye*", "Chengyue Gong*", "Zhanxing Zhu", "Qiang Liu"], "pdf": "/pdf/5430ccda33560b7029405730fa6562adde7517ec.pdf", "TL;DR": "We improve existing certification results with a new certification framework by reformulating the original problem to a functional optimization one, and design a new distribution family which suits this task better through this framework.", "abstract": "Randomized classifiers have been shown to provide a promising approach for achieving certified robustness against adversarial attacks in deep learning. However, most existing methods only leverage Gaussian smoothing noise and only work for $\\ell_2$ perturbation. We propose a general framework of adversarial certification with non-Gaussian noise and for more general types of attacks, from a unified functional optimization perspective. Our new framework allows us to identify a key trade-off between accuracy and robustness via designing smoothing distributions, helping to design two new families of non-Gaussian smoothing distributions that work more efficiently for $\\ell_2$ and $\\ell_\\infty$ attacks, respectively. Our proposed methods achieve better results than previous works and provide a new perspective on randomized smoothing certification.", "keywords": ["Adversarial Certification", "Randomized Smoothing", "Functional Optimization"], "paperhash": "zhang|filling_the_soap_bubbles_efficient_blackbox_adversarial_certification_with_nongaussian_smoothing", "original_pdf": "/attachment/a0d9b6e729690f3d5caaa80fbaff632a81858fa9.pdf", "_bibtex": "@misc{\nzhang*2020filling,\ntitle={Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing},\nauthor={Dinghuai Zhang* and Mao Ye* and Chengyue Gong* and Zhanxing Zhu and Qiang Liu},\nyear={2020},\nurl={https://openreview.net/forum?id=Skg8gJBFvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Skg8gJBFvr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1506/Authors", "ICLR.cc/2020/Conference/Paper1506/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1506/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1506/Reviewers", "ICLR.cc/2020/Conference/Paper1506/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1506/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1506/Authors|ICLR.cc/2020/Conference/Paper1506/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504155005, "tmdate": 1576860557408, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1506/Authors", "ICLR.cc/2020/Conference/Paper1506/Reviewers", "ICLR.cc/2020/Conference/Paper1506/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1506/-/Official_Comment"}}}, {"id": "BygQJM9noS", "original": null, "number": 3, "cdate": 1573851610753, "ddate": null, "tcdate": 1573851610753, "tmdate": 1573852364589, "tddate": null, "forum": "Skg8gJBFvr", "replyto": "rJejRI6aKS", "invitation": "ICLR.cc/2020/Conference/Paper1506/-/Official_Comment", "content": {"title": "Thanks for your review. However we respectfully disagree with many of your comments.", "comment": "Thank R#1 for your time and comments. We do respectfully disagree with many of your comments, and think they are based on misunderstanding. We hope our response can help clarify the issue.\n\nWe also note an independent and concurrent submission to ICLR that overlaps with our work in many ways. \n\"A FRAMEWORK FOR ROBUSTNESS CERTIFICATION OF SMOOTHED CLASSIFIERS USING F-DIVERGENCES (https://openreview.net/forum?id=SJlKrkSFPH)\".  Because of the high overlap with our work, we strongly encourage these two works can be jointly considered and receives calibrated scores. \n\nQuestion: \"For \\ell_2 perturbations, there is no major difference between this new family of distributions (d-k \\chi^2) and a Gaussian with different variance.''\n\nReply: Your understanding is *wrong*.  The family of distribution indexed by (k, sigma) is not mathematically equivalent to Gaussian. It strictly generalizes Gaussian. Our Figure 1 and discussion on page 6 is to illustrate this very point. \n\nAlso as we show in the paper, the impact of k on the shape of the distribution is also very practically significant. Note that the radius distribution of our generalized family is a scaled Chi distribution, in which k is the *shape parameter*, which controls the shape. \n\nIn addition, we also found Theorem 9 and Theorem 10 in the appendix of the concurrent submission (https://openreview.net/forum?id=SJlKrkSFPH) which illustrate the very same point.  \n\nQuestion: Concerns on experiments; ''I don't see why the value of (k,\\sigma) was not provided in Table 1 and only \\sigma was provided. Also, the table of Cohen et al. was only calculated for specific values of \\sigma for Gaussian distributions (0.12, 0.25, 0.5, 1.00). For a fair comparison, comparable values of \\sigma 's must be calculated, and then the best choice should be selected.''\n\nReply: It looks the reviewer has missed some of our experiments. See please the \"Settings and Hyper-parameters\" subsection for  how k is chosen. We also do an ablation study for k in appendix, in which we empirically show that k and \\sigma can lead to different results. For comparable values of \\sigma, we also did so. See **Settings and Hyper-parameters**. \n\n\nQuestion:  ''In the light of previous arguments, I don't think the choice of Eq. (9) or Eq. (10) is well motivated. Why not smooth it with a cube of appropriate radius''\n\nReply:  In Theorem 4, We have already proven that Eq.(9) is not doable because of the curse of dimensionality! No matter how you choose the radius, you cannot get **any** practical result for high-dimension cases.\n\nAnd we don\u2019t quite get what you mean by \u2018cube of appropriate radius\u2019. If you mean an uniform distribution on the hyper-cude with certain radius, this smoothing distribution also suffers from the curse of dimensionality.\n\n4. Question: \"inconsistent Salmen's experiment results\"\n\nReply: Our setting in Table 3 is **l_inf** while Salmen's whole paper is about **l_2** certification. These are totally different settings, thus we may be not aware of where does your concern come from. We 'transfer' their result on \\ell_2 certification to L_infty setting using theorem 3.\n\n5. Question: ''On p.5, why was the toy classifier sphere-based? The toughest classifier for Gaussian smoothing (the one achieving the lower bound for Gaussian smoothing) is actually a linear classifier.''\n\nReply: This is just a motivating example for illustration. Cohen's work derives a bound with worst case achieved by linear classifier and the space of classifier we and they concern is very general (that includes almost all nonlinear real-word case and of course the sphere-based classifier)\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1506/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1506/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zhangdinghuai@pku.edu.cn", "lushleaf21@gmail.com", "cygong@cs.utexas.edu", "zhanxing.zhu@pku.edu.cn", "lqiang@cs.utexas.edu"], "title": "Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing", "authors": ["Dinghuai Zhang*", "Mao Ye*", "Chengyue Gong*", "Zhanxing Zhu", "Qiang Liu"], "pdf": "/pdf/5430ccda33560b7029405730fa6562adde7517ec.pdf", "TL;DR": "We improve existing certification results with a new certification framework by reformulating the original problem to a functional optimization one, and design a new distribution family which suits this task better through this framework.", "abstract": "Randomized classifiers have been shown to provide a promising approach for achieving certified robustness against adversarial attacks in deep learning. However, most existing methods only leverage Gaussian smoothing noise and only work for $\\ell_2$ perturbation. We propose a general framework of adversarial certification with non-Gaussian noise and for more general types of attacks, from a unified functional optimization perspective. Our new framework allows us to identify a key trade-off between accuracy and robustness via designing smoothing distributions, helping to design two new families of non-Gaussian smoothing distributions that work more efficiently for $\\ell_2$ and $\\ell_\\infty$ attacks, respectively. Our proposed methods achieve better results than previous works and provide a new perspective on randomized smoothing certification.", "keywords": ["Adversarial Certification", "Randomized Smoothing", "Functional Optimization"], "paperhash": "zhang|filling_the_soap_bubbles_efficient_blackbox_adversarial_certification_with_nongaussian_smoothing", "original_pdf": "/attachment/a0d9b6e729690f3d5caaa80fbaff632a81858fa9.pdf", "_bibtex": "@misc{\nzhang*2020filling,\ntitle={Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing},\nauthor={Dinghuai Zhang* and Mao Ye* and Chengyue Gong* and Zhanxing Zhu and Qiang Liu},\nyear={2020},\nurl={https://openreview.net/forum?id=Skg8gJBFvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Skg8gJBFvr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1506/Authors", "ICLR.cc/2020/Conference/Paper1506/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1506/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1506/Reviewers", "ICLR.cc/2020/Conference/Paper1506/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1506/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1506/Authors|ICLR.cc/2020/Conference/Paper1506/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504155005, "tmdate": 1576860557408, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1506/Authors", "ICLR.cc/2020/Conference/Paper1506/Reviewers", "ICLR.cc/2020/Conference/Paper1506/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1506/-/Official_Comment"}}}, {"id": "rylAi45hor", "original": null, "number": 4, "cdate": 1573852325970, "ddate": null, "tcdate": 1573852325970, "tmdate": 1573852325970, "tddate": null, "forum": "Skg8gJBFvr", "replyto": "B1lWEtgb9B", "invitation": "ICLR.cc/2020/Conference/Paper1506/-/Official_Comment", "content": {"title": "Thanks for your review! Below please find our response.", "comment": "Response to Reviewer #2\n\nThank you very for your time and comments.  We hope you can re-consider your evaluation based on the new framework that we develop, which significantly generalizes and simplify the derivations in existing results. We believe our empirical results are sufficient to support and demonstrate the potential benefit of this framework (see response below). \n\nWe also want to point out an independent and concurrent submission to ICLR that overlaps with our work in both our basic framework and many detailed algorithmic choices. \"A FRAMEWORK FOR ROBUSTNESS CERTIFICATION OF SMOOTHED CLASSIFIERS USING F-DIVERGENCES (https://openreview.net/forum?id=SJlKrkSFPH)\".  Because of the high overlap with our work, we hope you could also check this paper and their reviews and calibrate your score accordingly, since having our work rejected while their work accepted due to uncalibrated review would block the opportunity for publishing our work in the future.   \n\nWe response to the main arguments here:\n\n1. You are correct that models trained with our proposed noise should be used ideally. But it is very computationally expensive to conduct (especially when training on ImageNet).  So we used Cohen's as a standard setting, which I think it forms a fair comparison. \n\nWe used Salman et al's model for Linfty certification because we found Salman's model performs better for L_infty certification. This is likely because Cohen's model is trained with Gaussian noise data augmentation, which does not match our smoothing distribution of L_infty certification, while Salman's model is trained in a more adversarial fashion, and turns out to be more robust for L_infty distribution  (even though it was still designed for the standard Gaussian distribution).\n\n2. For results of Cohen's method, Salman et al.'s paper (https://github.com/Hadisalman/smoothing-adversarial), Salman's blog (https://decentdescent.org/smoothadv.html) and Cohen's paper (https://arxiv.org/pdf/1902.02918.pdf) have inconsistent results. This may be due to randomness of the algorithm. For our paper, we reported numbers that came from our experiment with Cohen's github code.\n\n3. We are not sure what do you mean by 68.2. We work on L_infty certification and there is no result for L_inf certification in Salman et al.'s paper (they work on an extension of Cohen's, which it's about L_2 setting). We 'transfer' their result on \\ell_2 certification to L_infty setting using theorem 3.\n\nThanks for your other comments, which point out many improper descriptions and are helpful for us to revise our work. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1506/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1506/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zhangdinghuai@pku.edu.cn", "lushleaf21@gmail.com", "cygong@cs.utexas.edu", "zhanxing.zhu@pku.edu.cn", "lqiang@cs.utexas.edu"], "title": "Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing", "authors": ["Dinghuai Zhang*", "Mao Ye*", "Chengyue Gong*", "Zhanxing Zhu", "Qiang Liu"], "pdf": "/pdf/5430ccda33560b7029405730fa6562adde7517ec.pdf", "TL;DR": "We improve existing certification results with a new certification framework by reformulating the original problem to a functional optimization one, and design a new distribution family which suits this task better through this framework.", "abstract": "Randomized classifiers have been shown to provide a promising approach for achieving certified robustness against adversarial attacks in deep learning. However, most existing methods only leverage Gaussian smoothing noise and only work for $\\ell_2$ perturbation. We propose a general framework of adversarial certification with non-Gaussian noise and for more general types of attacks, from a unified functional optimization perspective. Our new framework allows us to identify a key trade-off between accuracy and robustness via designing smoothing distributions, helping to design two new families of non-Gaussian smoothing distributions that work more efficiently for $\\ell_2$ and $\\ell_\\infty$ attacks, respectively. Our proposed methods achieve better results than previous works and provide a new perspective on randomized smoothing certification.", "keywords": ["Adversarial Certification", "Randomized Smoothing", "Functional Optimization"], "paperhash": "zhang|filling_the_soap_bubbles_efficient_blackbox_adversarial_certification_with_nongaussian_smoothing", "original_pdf": "/attachment/a0d9b6e729690f3d5caaa80fbaff632a81858fa9.pdf", "_bibtex": "@misc{\nzhang*2020filling,\ntitle={Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing},\nauthor={Dinghuai Zhang* and Mao Ye* and Chengyue Gong* and Zhanxing Zhu and Qiang Liu},\nyear={2020},\nurl={https://openreview.net/forum?id=Skg8gJBFvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Skg8gJBFvr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1506/Authors", "ICLR.cc/2020/Conference/Paper1506/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1506/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1506/Reviewers", "ICLR.cc/2020/Conference/Paper1506/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1506/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1506/Authors|ICLR.cc/2020/Conference/Paper1506/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504155005, "tmdate": 1576860557408, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1506/Authors", "ICLR.cc/2020/Conference/Paper1506/Reviewers", "ICLR.cc/2020/Conference/Paper1506/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1506/-/Official_Comment"}}}, {"id": "ByllmnE6tH", "original": null, "number": 1, "cdate": 1571798040084, "ddate": null, "tcdate": 1571798040084, "tmdate": 1572972459761, "tddate": null, "forum": "Skg8gJBFvr", "replyto": "Skg8gJBFvr", "invitation": "ICLR.cc/2020/Conference/Paper1506/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper introduces an improvement to the randomized smoothing analysis in Cohen et al. (2019), using Lagrangian relaxation to achieve a more general lower bound. Using this, it considers different adversarial smoothing distributions that yield some increase in certified adversarial accuracy.\n\nOverall assessment: While the Lagrangian relaxation idea is interesting and could yield interesting follow-up work, the paper is sloppy in several respects and needs to be tightened before it can be considered for publication.\n\nKey issues:\n1. Proof of main theorem (strong duality) is incorrect. Likely the statement itself is also incorrect. Fortunately the most important direction (lower bound) is still true, so this isn't a fatal flaw to the approach.\n2. The paper makes several references (in italics) to a \"fundamental trade-off between accuracy and robustness\". But a fundamental trade-off means that *any* method that attains good accuracy must sacrifice robustness and vice versa; this requires a \"for all\" statement, i.e. a lower bound. All the paper shows is that the *particular upper bound* exhibits a trade-off (and even then, the notions of \"accuracy\" and \"robustness\" are merely interpretations of quantities in the bound; it's not clear why the robustness term in particular is tied to more standard notions of robustness).\n3. The justification for why the particular smoothing distributions are good ideas is sketchy.\n\nI elaborate on 1 and 3 below. Addressing 1-3 effectively will improve my score.\n\n#1 (main theorem is incorrect): Claim 3 in the appendix is wrong. The fact that (delta', f') outperforms (delta-bar, f-bar) with respect to lambda* does not imply that (delta', f', lambda*) is a better solution to the primal problem, because we must take max over lambda and the maximizing lambda need not be lambda*. In particular if f' doesn't satisfy the constraint we would instead take lambda to infinity.\n\n#3 (sketchy justification): The paper justifies a smoothing distribution that concentrates more mass around the center as follows: \"This phenomenon makes it problematic to use standard Gaussian distribution for adversarial certification, because one would expect that the smoothing distribution should concentrate around the center (the original image) in order to make the smoothed classifier close to the original classifier (and hence accurate).\" I don't see why we should want more mass near the center---in the limit as we move all the mass towards the center and get the original classifier, our certified bound will be terrible, so it's not clear why moving in that direction should be expected to help. Indeed, the experimental gains are minimal (1 to 3 percentage points) and on methods that were not carefully tuned, so one could imagine that the baseline method could be improved by that much just with careful tuning.\n\nI similarly didn't understand the justification for the mixed L-inf / L-2 distribution for L-infinity verification. The main justification was \"The motivation is that this allows us to allocate more probability mass along the \u201cpointy\u201d directions with larger`\u221enorm, and hence decrease the maximum distance term max \u03b4\u2208B`\u221e,rDF(\u03bb\u03c00\u2016\u03c0\u03b4).\" This is at the very least too brief for justifying the main experimental innovation in the paper (here at least the empirical improvements are bigger, although still not huge).\n\nMinor but related: Why is the x-axis in Figure 4 so compressed? This is also in a regime where all 3 methods fail to certify so not clear it's meaningful.\n\nWriting comment: Change some of the Theorems to Propositions. Theorems should be for key claims in paper (there shouldn't be 4 of them in one 8-page paper)."}, "signatures": ["ICLR.cc/2020/Conference/Paper1506/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1506/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zhangdinghuai@pku.edu.cn", "lushleaf21@gmail.com", "cygong@cs.utexas.edu", "zhanxing.zhu@pku.edu.cn", "lqiang@cs.utexas.edu"], "title": "Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing", "authors": ["Dinghuai Zhang*", "Mao Ye*", "Chengyue Gong*", "Zhanxing Zhu", "Qiang Liu"], "pdf": "/pdf/5430ccda33560b7029405730fa6562adde7517ec.pdf", "TL;DR": "We improve existing certification results with a new certification framework by reformulating the original problem to a functional optimization one, and design a new distribution family which suits this task better through this framework.", "abstract": "Randomized classifiers have been shown to provide a promising approach for achieving certified robustness against adversarial attacks in deep learning. However, most existing methods only leverage Gaussian smoothing noise and only work for $\\ell_2$ perturbation. We propose a general framework of adversarial certification with non-Gaussian noise and for more general types of attacks, from a unified functional optimization perspective. Our new framework allows us to identify a key trade-off between accuracy and robustness via designing smoothing distributions, helping to design two new families of non-Gaussian smoothing distributions that work more efficiently for $\\ell_2$ and $\\ell_\\infty$ attacks, respectively. Our proposed methods achieve better results than previous works and provide a new perspective on randomized smoothing certification.", "keywords": ["Adversarial Certification", "Randomized Smoothing", "Functional Optimization"], "paperhash": "zhang|filling_the_soap_bubbles_efficient_blackbox_adversarial_certification_with_nongaussian_smoothing", "original_pdf": "/attachment/a0d9b6e729690f3d5caaa80fbaff632a81858fa9.pdf", "_bibtex": "@misc{\nzhang*2020filling,\ntitle={Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing},\nauthor={Dinghuai Zhang* and Mao Ye* and Chengyue Gong* and Zhanxing Zhu and Qiang Liu},\nyear={2020},\nurl={https://openreview.net/forum?id=Skg8gJBFvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Skg8gJBFvr", "replyto": "Skg8gJBFvr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1506/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1506/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575663566868, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1506/Reviewers"], "noninvitees": [], "tcdate": 1570237736390, "tmdate": 1575663566880, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1506/-/Official_Review"}}}, {"id": "rJejRI6aKS", "original": null, "number": 2, "cdate": 1571833555234, "ddate": null, "tcdate": 1571833555234, "tmdate": 1572972459717, "tddate": null, "forum": "Skg8gJBFvr", "replyto": "Skg8gJBFvr", "invitation": "ICLR.cc/2020/Conference/Paper1506/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary:\n\nThis paper investigates the choice of noise distributions for smoothing an arbitrary classifier for defending against adversarial attacks.  The paper focuses on the two major adversaries: \\ell_2 adversaries and \\ell_\\infty adversaries. Theorem 1 quantifies the tradeoff between the choice of smoothing distribution which (1) has clean accuracy close to the original classifier and (2) promotes the smoothness of smoothed classifier (and hence adversarial accuracy).  For the \\ell_2 adversary, the paper argues that Gaussian distribution is not the right choice, because the distribution is concentrated on the spherical shell around the x. Instead, the authors propose using a new family of distributions, with the norm square  (p_{|z|_2^2}) following the scaled \\chi^2 distribution with degree d-k (Eq. 8). This allows an extra degree of freedom, and setting k=0 recovers the Gaussian distribution. For \\ell_\\infty perturbations, the paper suggests another family of distributions combining the \\ell_2 and \\ell_\\infty norm (Eq. 9), and argues that it outperforms the natural choice of \\ell_\\infty norm-based distributions (Eq. 10).\n\nI think the paper should be rejected because (1) For \\ell_2 perturbations, there is no major difference between this new family of distributions (d-k \\chi^2) and a Gaussian with different variance. (2) For \\ell_\\infty distributions, the motivation of mixed norm distributions (Eq. 9) over \\ell_\\infty based distributions (Eq. 10) is not very clear. (3) The experimental evidence is also weak (see below).\n\nMain arguments:\n\n1. The distribution of the norm \\|z\\|_2 in Eq. (8) would be concentrated on a thin spherical shell of radius about \\sqrt{d-k}\\sigma. As the Gaussian distribution with standard deviation \\sigma' is supported on a shell of radius about \\sqrt{d} \\sigma', for each (k,\\sigma) in the family of Eq. 8, there is an equivalent Gaussian with appropriate \\sigma' (Theorem 3 now just compares the radius of the spherical shell). Therefore, I don't see the benefit of this extra degree of freedom of k: the noise distribution is again a \"soap bubble\" of a different radius. Thus, a grid search over \\sigma' for a Gaussian should be the same as a grid search over (k,\\sigma) in Eq. 8.\n\nEven the experimental experiments are a marginal improvement over Cohen et al.  I don't see why the value of (k,\\sigma) was not provided in Table 1 and only \\sigma was provided. Also, the table of Cohen et al. was only calculated for specific values of \\sigma for Gaussian distributions (0.12, 0.25, 0.5, 1.00). For a fair comparison, comparable values of \\sigma's must be calculated, and then the best choice should be selected. \n\n2. In the light of previous arguments, I don't think the choice of Eq. (9) or Eq. (10) is well motivated. \nWhy not smooth it with a cube of appropriate radius? Also, not enough experimental details are provided for Table 3.  Salman et al. (2019) reports the accuracy of 68.2% for \\ell_infty perturbations (Table 3, Salman et al. (2019)), whereas the value reported in your Table 3 for at the same radius is 58%. Is it a typo? In any case, the values reported for the proposed model in Table 3 are only a marginal improvement over Figure 1 (left) in Salman et al. (2019), just going by the trivial \\ell_2 to \\ell_\\infty certificate.\n\nOther areas for improvement:\n\n1. The paper contains numerous grammatical errors, confusing statements, and nonstandard phrases.  For example: (i) more less robust, (ii) black start, (iii) pointy points, etc.  I suggest that the authors spend more time clarifying their manuscript.\n\n2. The paragraph starting with \"Trade-off between Accuracy and Robustness\": I think this paragraph should be reworded for clarification.  It is not robustness but rather the lack thereof -- say, sensitivity.\n\n3. On p.5, why was the toy classifier sphere-based? The toughest classifier for Gaussian smoothing (the one achieving the lower bound for Gaussian smoothing) is actually a linear classifier.\n\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1506/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1506/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zhangdinghuai@pku.edu.cn", "lushleaf21@gmail.com", "cygong@cs.utexas.edu", "zhanxing.zhu@pku.edu.cn", "lqiang@cs.utexas.edu"], "title": "Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing", "authors": ["Dinghuai Zhang*", "Mao Ye*", "Chengyue Gong*", "Zhanxing Zhu", "Qiang Liu"], "pdf": "/pdf/5430ccda33560b7029405730fa6562adde7517ec.pdf", "TL;DR": "We improve existing certification results with a new certification framework by reformulating the original problem to a functional optimization one, and design a new distribution family which suits this task better through this framework.", "abstract": "Randomized classifiers have been shown to provide a promising approach for achieving certified robustness against adversarial attacks in deep learning. However, most existing methods only leverage Gaussian smoothing noise and only work for $\\ell_2$ perturbation. We propose a general framework of adversarial certification with non-Gaussian noise and for more general types of attacks, from a unified functional optimization perspective. Our new framework allows us to identify a key trade-off between accuracy and robustness via designing smoothing distributions, helping to design two new families of non-Gaussian smoothing distributions that work more efficiently for $\\ell_2$ and $\\ell_\\infty$ attacks, respectively. Our proposed methods achieve better results than previous works and provide a new perspective on randomized smoothing certification.", "keywords": ["Adversarial Certification", "Randomized Smoothing", "Functional Optimization"], "paperhash": "zhang|filling_the_soap_bubbles_efficient_blackbox_adversarial_certification_with_nongaussian_smoothing", "original_pdf": "/attachment/a0d9b6e729690f3d5caaa80fbaff632a81858fa9.pdf", "_bibtex": "@misc{\nzhang*2020filling,\ntitle={Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing},\nauthor={Dinghuai Zhang* and Mao Ye* and Chengyue Gong* and Zhanxing Zhu and Qiang Liu},\nyear={2020},\nurl={https://openreview.net/forum?id=Skg8gJBFvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Skg8gJBFvr", "replyto": "Skg8gJBFvr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1506/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1506/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575663566868, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1506/Reviewers"], "noninvitees": [], "tcdate": 1570237736390, "tmdate": 1575663566880, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1506/-/Official_Review"}}}, {"id": "B1lWEtgb9B", "original": null, "number": 3, "cdate": 1572043049028, "ddate": null, "tcdate": 1572043049028, "tmdate": 1572972459673, "tddate": null, "forum": "Skg8gJBFvr", "replyto": "Skg8gJBFvr", "invitation": "ICLR.cc/2020/Conference/Paper1506/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents a new method for adversarial certification using non-Gaussian noise. A new framework for certification is proposed, which allows to use different distributions compared to previous work based on Gaussian noise. From this framework, a trade-off between accuracy and robustness is identified and new distributions are proposed to obtain a better trade-off than with Gaussian noise. Using these new distributions, they re-certify models obtained in previous work.\n\nI am hesitating between a weak reject and a weak accept. The theoretical results are interesting, showing a clear trade-off between robustness and accuracy with a new lower bound and deriving better smoothing distributions. However, the experimental results are lacking, and do not support much the proposed method. Training with this new distribution would have been a natural experiment given the argument. Moreover, the results for L_inf are partial and it would be expected to have some results for ImageNet as claimed in the introduction. I would have given an accept if the previous points had been addressed and I feel that with some more work on it, it would become an excellent paper.\n\nMain arguments:\nMy main concern is about the experiments: Why were Cohen et al.\u2019s models used instead of Salman et al.\u2019s? Salman et al.\u2019s have achieved better certified accuracy under the L_2 norm so it would only seem natural to use their model.\nAbout the main results: there seems to be a discrepancy between the results reported for Cohen et al. and the original paper for both CIFAR-10 and ImageNet L2 certification. Also, the reported certified accuracy for Salman et al.\u2019s model for L_inf on CIFAR-10 reported in the original paper is 68.2 at 2/255, which is very far from the 58 in Table 3. What is the reason for these differences?\n\nMinor comments:\nIn the third paragraph, it is claimed that L_inf attacks are a stronger and more relevant type of attacks than L_2 attacks. These two different objectives cannot be compared in those terms.\nDefenses such as adversarial training have not been \u201cbroken\u201d as claimed in section 2 in the sense that the claims made in the original paper still hold true. The term broken is used for defenses in which the claimed accuracy against stronger attacks were found to be much lower than what was claimed in the original paper.\nIt is claimed that \u201cif ||z||_inf is too large to exceed the region of natural images, the accuracy will be obviously rather poor\u201d; however, the common practice is to clip to the input space bounds. How would that affect the method?\n\nThings to improve the paper that did not impact the score:\nIn the first paragraph, Goodfellow et al., 2015 is cited, however, papers on adversarial attacks were published earlier than that such as Szegedy et al., 2014 or Biggio et al., 2013.\nVershynin, 2018 is cited about the distribution of a gaussian in high-dimensional spaces. However, this is a very well known result and does not need any citation (or if any, Bellman, 1961).\nTypo after equation 4: ||f||_{L_p}\nTypo in \u201cBlack-box Certification with Randomness\u201d paragraph: \u201cby convovling\u201d\nTypos in Table 2.: the columns 2.0 to 3.5 are mislabeled\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1506/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1506/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zhangdinghuai@pku.edu.cn", "lushleaf21@gmail.com", "cygong@cs.utexas.edu", "zhanxing.zhu@pku.edu.cn", "lqiang@cs.utexas.edu"], "title": "Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing", "authors": ["Dinghuai Zhang*", "Mao Ye*", "Chengyue Gong*", "Zhanxing Zhu", "Qiang Liu"], "pdf": "/pdf/5430ccda33560b7029405730fa6562adde7517ec.pdf", "TL;DR": "We improve existing certification results with a new certification framework by reformulating the original problem to a functional optimization one, and design a new distribution family which suits this task better through this framework.", "abstract": "Randomized classifiers have been shown to provide a promising approach for achieving certified robustness against adversarial attacks in deep learning. However, most existing methods only leverage Gaussian smoothing noise and only work for $\\ell_2$ perturbation. We propose a general framework of adversarial certification with non-Gaussian noise and for more general types of attacks, from a unified functional optimization perspective. Our new framework allows us to identify a key trade-off between accuracy and robustness via designing smoothing distributions, helping to design two new families of non-Gaussian smoothing distributions that work more efficiently for $\\ell_2$ and $\\ell_\\infty$ attacks, respectively. Our proposed methods achieve better results than previous works and provide a new perspective on randomized smoothing certification.", "keywords": ["Adversarial Certification", "Randomized Smoothing", "Functional Optimization"], "paperhash": "zhang|filling_the_soap_bubbles_efficient_blackbox_adversarial_certification_with_nongaussian_smoothing", "original_pdf": "/attachment/a0d9b6e729690f3d5caaa80fbaff632a81858fa9.pdf", "_bibtex": "@misc{\nzhang*2020filling,\ntitle={Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing},\nauthor={Dinghuai Zhang* and Mao Ye* and Chengyue Gong* and Zhanxing Zhu and Qiang Liu},\nyear={2020},\nurl={https://openreview.net/forum?id=Skg8gJBFvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Skg8gJBFvr", "replyto": "Skg8gJBFvr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1506/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1506/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575663566868, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1506/Reviewers"], "noninvitees": [], "tcdate": 1570237736390, "tmdate": 1575663566880, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1506/-/Official_Review"}}}, {"id": "Hkgqg8GpFH", "original": null, "number": 2, "cdate": 1571788273960, "ddate": null, "tcdate": 1571788273960, "tmdate": 1571788273960, "tddate": null, "forum": "Skg8gJBFvr", "replyto": "rkeRwZqa_S", "invitation": "ICLR.cc/2020/Conference/Paper1506/-/Official_Comment", "content": {"comment": "Thanks a lot for your questions.\n\nFirst question: We use Salman et al\u2019s model for Linfty certification because we found Salman's model performs better for L_infty certification.\nThis is likely because Cohen\u2019s model is trained with Gaussian noise data augmentation, which does not match our smoothing distribution of L_infty certification, while Salman\u2019s model is trained in a more adversarial fashion, and tends out to be more robust for L_infty distribution  (even it was still designed for the standard Gaussian distribution).\n\nSecond question:\nWe agree that we may get better performance by directly training on our proposed distribution. It is an interesting direction that we plan to explore in future work.", "title": "Thanks for your questions"}, "signatures": ["ICLR.cc/2020/Conference/Paper1506/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1506/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zhangdinghuai@pku.edu.cn", "lushleaf21@gmail.com", "cygong@cs.utexas.edu", "zhanxing.zhu@pku.edu.cn", "lqiang@cs.utexas.edu"], "title": "Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing", "authors": ["Dinghuai Zhang*", "Mao Ye*", "Chengyue Gong*", "Zhanxing Zhu", "Qiang Liu"], "pdf": "/pdf/5430ccda33560b7029405730fa6562adde7517ec.pdf", "TL;DR": "We improve existing certification results with a new certification framework by reformulating the original problem to a functional optimization one, and design a new distribution family which suits this task better through this framework.", "abstract": "Randomized classifiers have been shown to provide a promising approach for achieving certified robustness against adversarial attacks in deep learning. However, most existing methods only leverage Gaussian smoothing noise and only work for $\\ell_2$ perturbation. We propose a general framework of adversarial certification with non-Gaussian noise and for more general types of attacks, from a unified functional optimization perspective. Our new framework allows us to identify a key trade-off between accuracy and robustness via designing smoothing distributions, helping to design two new families of non-Gaussian smoothing distributions that work more efficiently for $\\ell_2$ and $\\ell_\\infty$ attacks, respectively. Our proposed methods achieve better results than previous works and provide a new perspective on randomized smoothing certification.", "keywords": ["Adversarial Certification", "Randomized Smoothing", "Functional Optimization"], "paperhash": "zhang|filling_the_soap_bubbles_efficient_blackbox_adversarial_certification_with_nongaussian_smoothing", "original_pdf": "/attachment/a0d9b6e729690f3d5caaa80fbaff632a81858fa9.pdf", "_bibtex": "@misc{\nzhang*2020filling,\ntitle={Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing},\nauthor={Dinghuai Zhang* and Mao Ye* and Chengyue Gong* and Zhanxing Zhu and Qiang Liu},\nyear={2020},\nurl={https://openreview.net/forum?id=Skg8gJBFvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Skg8gJBFvr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1506/Authors", "ICLR.cc/2020/Conference/Paper1506/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1506/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1506/Reviewers", "ICLR.cc/2020/Conference/Paper1506/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1506/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1506/Authors|ICLR.cc/2020/Conference/Paper1506/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504155005, "tmdate": 1576860557408, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1506/Authors", "ICLR.cc/2020/Conference/Paper1506/Reviewers", "ICLR.cc/2020/Conference/Paper1506/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1506/-/Official_Comment"}}}, {"id": "rkeRwZqa_S", "original": null, "number": 2, "cdate": 1570771301751, "ddate": null, "tcdate": 1570771301751, "tmdate": 1570771301751, "tddate": null, "forum": "Skg8gJBFvr", "replyto": "SJlZpBx1OB", "invitation": "ICLR.cc/2020/Conference/Paper1506/-/Public_Comment", "content": {"comment": "Thanks for the clarification! This makes sense.\n\nSome other questions:\n1) Why did you use Cohen et al.'s models for l2 certification, but Salman et al.'s models for linfty certification? What if you use Salman et al.'s models for l2, and Cohen et al.'s for linfty?\n\n2) It would seem natural to train on your proposed distribution as well, and one would perhaps expect better performance after doing so, compared to using pre-trained models trained on Gaussian noise or SmoothAdv. Do you have those results?\n\nThanks! Hope to hear back from you soon :)", "title": "Thanks for the clarification; other questions"}, "signatures": ["~Greg_Yang1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Greg_Yang1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zhangdinghuai@pku.edu.cn", "lushleaf21@gmail.com", "cygong@cs.utexas.edu", "zhanxing.zhu@pku.edu.cn", "lqiang@cs.utexas.edu"], "title": "Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing", "authors": ["Dinghuai Zhang*", "Mao Ye*", "Chengyue Gong*", "Zhanxing Zhu", "Qiang Liu"], "pdf": "/pdf/5430ccda33560b7029405730fa6562adde7517ec.pdf", "TL;DR": "We improve existing certification results with a new certification framework by reformulating the original problem to a functional optimization one, and design a new distribution family which suits this task better through this framework.", "abstract": "Randomized classifiers have been shown to provide a promising approach for achieving certified robustness against adversarial attacks in deep learning. However, most existing methods only leverage Gaussian smoothing noise and only work for $\\ell_2$ perturbation. We propose a general framework of adversarial certification with non-Gaussian noise and for more general types of attacks, from a unified functional optimization perspective. Our new framework allows us to identify a key trade-off between accuracy and robustness via designing smoothing distributions, helping to design two new families of non-Gaussian smoothing distributions that work more efficiently for $\\ell_2$ and $\\ell_\\infty$ attacks, respectively. Our proposed methods achieve better results than previous works and provide a new perspective on randomized smoothing certification.", "keywords": ["Adversarial Certification", "Randomized Smoothing", "Functional Optimization"], "paperhash": "zhang|filling_the_soap_bubbles_efficient_blackbox_adversarial_certification_with_nongaussian_smoothing", "original_pdf": "/attachment/a0d9b6e729690f3d5caaa80fbaff632a81858fa9.pdf", "_bibtex": "@misc{\nzhang*2020filling,\ntitle={Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing},\nauthor={Dinghuai Zhang* and Mao Ye* and Chengyue Gong* and Zhanxing Zhu and Qiang Liu},\nyear={2020},\nurl={https://openreview.net/forum?id=Skg8gJBFvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Skg8gJBFvr", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504193773, "tmdate": 1576860590527, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper1506/Authors", "ICLR.cc/2020/Conference/Paper1506/Reviewers", "ICLR.cc/2020/Conference/Paper1506/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1506/-/Public_Comment"}}}, {"id": "SJlZpBx1OB", "original": null, "number": 1, "cdate": 1569813944601, "ddate": null, "tcdate": 1569813944601, "tmdate": 1569816717977, "tddate": null, "forum": "Skg8gJBFvr", "replyto": "BJxwqasovr", "invitation": "ICLR.cc/2020/Conference/Paper1506/-/Official_Comment", "content": {"comment": "Thanks for your concern! We want to clarify that actually we don't need to get the exact optimal lambda because *any* lambda could give a valid confidence lower bound. Besides, the optimization is smooth since the derivative of lower bound $D$ w.r.t. lambda is actually bounded by 2 with some algebra. It's our negligence of omitting these details :(  The search space is chosen heuristically, which is good enough (the optimization of lambda can be shown to convex with only one minimal point), so we just don't explore more on this. We will update relevant details as soon as the update of pdf file is allowed :)", "title": "Some clarification"}, "signatures": ["ICLR.cc/2020/Conference/Paper1506/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1506/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zhangdinghuai@pku.edu.cn", "lushleaf21@gmail.com", "cygong@cs.utexas.edu", "zhanxing.zhu@pku.edu.cn", "lqiang@cs.utexas.edu"], "title": "Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing", "authors": ["Dinghuai Zhang*", "Mao Ye*", "Chengyue Gong*", "Zhanxing Zhu", "Qiang Liu"], "pdf": "/pdf/5430ccda33560b7029405730fa6562adde7517ec.pdf", "TL;DR": "We improve existing certification results with a new certification framework by reformulating the original problem to a functional optimization one, and design a new distribution family which suits this task better through this framework.", "abstract": "Randomized classifiers have been shown to provide a promising approach for achieving certified robustness against adversarial attacks in deep learning. However, most existing methods only leverage Gaussian smoothing noise and only work for $\\ell_2$ perturbation. We propose a general framework of adversarial certification with non-Gaussian noise and for more general types of attacks, from a unified functional optimization perspective. Our new framework allows us to identify a key trade-off between accuracy and robustness via designing smoothing distributions, helping to design two new families of non-Gaussian smoothing distributions that work more efficiently for $\\ell_2$ and $\\ell_\\infty$ attacks, respectively. Our proposed methods achieve better results than previous works and provide a new perspective on randomized smoothing certification.", "keywords": ["Adversarial Certification", "Randomized Smoothing", "Functional Optimization"], "paperhash": "zhang|filling_the_soap_bubbles_efficient_blackbox_adversarial_certification_with_nongaussian_smoothing", "original_pdf": "/attachment/a0d9b6e729690f3d5caaa80fbaff632a81858fa9.pdf", "_bibtex": "@misc{\nzhang*2020filling,\ntitle={Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing},\nauthor={Dinghuai Zhang* and Mao Ye* and Chengyue Gong* and Zhanxing Zhu and Qiang Liu},\nyear={2020},\nurl={https://openreview.net/forum?id=Skg8gJBFvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Skg8gJBFvr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1506/Authors", "ICLR.cc/2020/Conference/Paper1506/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1506/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1506/Reviewers", "ICLR.cc/2020/Conference/Paper1506/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1506/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1506/Authors|ICLR.cc/2020/Conference/Paper1506/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504155005, "tmdate": 1576860557408, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1506/Authors", "ICLR.cc/2020/Conference/Paper1506/Reviewers", "ICLR.cc/2020/Conference/Paper1506/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1506/-/Official_Comment"}}}, {"id": "BJxwqasovr", "original": null, "number": 1, "cdate": 1569598862879, "ddate": null, "tcdate": 1569598862879, "tmdate": 1569598862879, "tddate": null, "forum": "Skg8gJBFvr", "replyto": "Skg8gJBFvr", "invitation": "ICLR.cc/2020/Conference/Paper1506/-/Public_Comment", "content": {"comment": "Dear authors,\n\nThanks for a very interesting paper. I might have missed this in the paper, but how did you choose \\lambda_start, \\lambda_end, and h for your algorithm 1 and 2? Additionally, what is the guarantee you provide for those choices? For example, how do you prevent the possibility that the best \\lambda is outside your interval, or the possibility that the function in lambda is very nonsmooth and h is too big in comparison?\n\nThanks again, and looking for your reply :)", "title": "How to choose \\lambda_start, \\lambda_end, as well as the increment h?"}, "signatures": ["~Greg_Yang1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Greg_Yang1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["zhangdinghuai@pku.edu.cn", "lushleaf21@gmail.com", "cygong@cs.utexas.edu", "zhanxing.zhu@pku.edu.cn", "lqiang@cs.utexas.edu"], "title": "Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing", "authors": ["Dinghuai Zhang*", "Mao Ye*", "Chengyue Gong*", "Zhanxing Zhu", "Qiang Liu"], "pdf": "/pdf/5430ccda33560b7029405730fa6562adde7517ec.pdf", "TL;DR": "We improve existing certification results with a new certification framework by reformulating the original problem to a functional optimization one, and design a new distribution family which suits this task better through this framework.", "abstract": "Randomized classifiers have been shown to provide a promising approach for achieving certified robustness against adversarial attacks in deep learning. However, most existing methods only leverage Gaussian smoothing noise and only work for $\\ell_2$ perturbation. We propose a general framework of adversarial certification with non-Gaussian noise and for more general types of attacks, from a unified functional optimization perspective. Our new framework allows us to identify a key trade-off between accuracy and robustness via designing smoothing distributions, helping to design two new families of non-Gaussian smoothing distributions that work more efficiently for $\\ell_2$ and $\\ell_\\infty$ attacks, respectively. Our proposed methods achieve better results than previous works and provide a new perspective on randomized smoothing certification.", "keywords": ["Adversarial Certification", "Randomized Smoothing", "Functional Optimization"], "paperhash": "zhang|filling_the_soap_bubbles_efficient_blackbox_adversarial_certification_with_nongaussian_smoothing", "original_pdf": "/attachment/a0d9b6e729690f3d5caaa80fbaff632a81858fa9.pdf", "_bibtex": "@misc{\nzhang*2020filling,\ntitle={Filling the Soap Bubbles: Efficient Black-Box Adversarial Certification with Non-Gaussian Smoothing},\nauthor={Dinghuai Zhang* and Mao Ye* and Chengyue Gong* and Zhanxing Zhu and Qiang Liu},\nyear={2020},\nurl={https://openreview.net/forum?id=Skg8gJBFvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Skg8gJBFvr", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504193773, "tmdate": 1576860590527, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper1506/Authors", "ICLR.cc/2020/Conference/Paper1506/Reviewers", "ICLR.cc/2020/Conference/Paper1506/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1506/-/Public_Comment"}}}], "count": 14}