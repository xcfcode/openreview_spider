{"notes": [{"tddate": null, "ddate": null, "tmdate": 1528124432765, "tcdate": 1518418960959, "number": 94, "cdate": 1518418960959, "id": "ByuM23RUG", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "ByuM23RUG", "original": "BJ0U7Pl0b", "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Expert-based reward function training: the novel method to train sequence generators", "abstract": "The training methods of sequence generator with a combination of GAN and policy gradient has shown good performance.\nIn this paper, we propose expert-based reward function training: the novel method to train sequence generator.\nDifferent from previous studies of sequence generation, expert-based reward function training does not utilize GAN's framework.\nStill, our model outperforms SeqGAN and a strong baseline, RankGAN.", "pdf": "/pdf/933c4ef21322bcb1628e4730f8b1c053b653074e.pdf", "TL;DR": "This paper aims to learn a better metric for unsupervised learning, such as text generation, and shows a significant improvement over SeqGAN.", "paperhash": "toyama|expertbased_reward_function_training_the_novel_method_to_train_sequence_generators", "keywords": ["sequence generation", "reinforcement learning", "unsupervised learning", "RNN"], "authors": ["Joji Toyama", "Yusuke Iwasawa", "Kotaro Nakayama", "Yutaka Matsuo"], "authorids": ["toyama@weblab.t.u-tokyo.ac.jp", "iwasawa@weblab.t.u-tokyo.ac.jp", "nakayama@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "_bibtex": "@misc{\n  toyama2018expert-based,\n  title={Expert-based reward function training: the novel method to train sequence generators},\n  author={Joji Toyama and Yusuke Iwasawa and Kotaro Nakayama and Yutaka Matsuo},\n  year={2018},\n  url={https://openreview.net/forum?id=ByuM23RUG}\n}"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}, "tauthor": "toyama.jouji@gmail.com"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582903651, "tcdate": 1520459214012, "number": 1, "cdate": 1520459214012, "id": "ry8AaRTuM", "invitation": "ICLR.cc/2018/Workshop/-/Paper94/Official_Review", "forum": "ByuM23RUG", "replyto": "ByuM23RUG", "signatures": ["ICLR.cc/2018/Workshop/Paper94/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper94/AnonReviewer2"], "content": {"title": "Training sequence generators using rewards from a (relative) density estimator", "rating": "5: Marginally below acceptance threshold", "review": "This paper proposes training a discrete sequence generator, using whatever RL techniques one is comfortable with, to maximize a reward function provided by an \"expert\" that is separately trained to model the general \"shape\" of the target distribution. The two obvious difficulties one faces in this direction are (i) how to make the RL-based training work reasonably well (given a fixed reward to optimize), and (ii) how to define an expert that provides useful rewards and is easy to train.\n\nThe authors focus on problem (ii). The proposed method is to train a classifier to discriminate between the target distribution and a constructed \"contrastive\" distribution. The trained classifier can be used as a (relative) density estimate for the target distribution, which can be used as the reward to maximize. I would recommend the authors review the literature on \"Noise Contrastive Estimation\" and other approaches to unnormalized density estimation.\n\nIt's not clear that the proposed method would work better than some obvious baselines, e.g. training an LSTM on the target distribution and then training the generator, via RL, to generate samples that have high log likelihood according to the trained LSTM. This seems kind of like \"cheating\", since it kind of directly optimizes the reported performance metric, but I'm generally skeptical about metrics that only work when people don't (directly) optimize them.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Expert-based reward function training: the novel method to train sequence generators", "abstract": "The training methods of sequence generator with a combination of GAN and policy gradient has shown good performance.\nIn this paper, we propose expert-based reward function training: the novel method to train sequence generator.\nDifferent from previous studies of sequence generation, expert-based reward function training does not utilize GAN's framework.\nStill, our model outperforms SeqGAN and a strong baseline, RankGAN.", "pdf": "/pdf/933c4ef21322bcb1628e4730f8b1c053b653074e.pdf", "TL;DR": "This paper aims to learn a better metric for unsupervised learning, such as text generation, and shows a significant improvement over SeqGAN.", "paperhash": "toyama|expertbased_reward_function_training_the_novel_method_to_train_sequence_generators", "keywords": ["sequence generation", "reinforcement learning", "unsupervised learning", "RNN"], "authors": ["Joji Toyama", "Yusuke Iwasawa", "Kotaro Nakayama", "Yutaka Matsuo"], "authorids": ["toyama@weblab.t.u-tokyo.ac.jp", "iwasawa@weblab.t.u-tokyo.ac.jp", "nakayama@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "_bibtex": "@misc{\n  toyama2018expert-based,\n  title={Expert-based reward function training: the novel method to train sequence generators},\n  author={Joji Toyama and Yusuke Iwasawa and Kotaro Nakayama and Yutaka Matsuo},\n  year={2018},\n  url={https://openreview.net/forum?id=ByuM23RUG}\n}"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582903458, "id": "ICLR.cc/2018/Workshop/-/Paper94/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper94/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper94/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper94/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper94/AnonReviewer1"], "reply": {"forum": "ByuM23RUG", "replyto": "ByuM23RUG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper94/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper94/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582903458}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582668386, "tcdate": 1520747810946, "number": 2, "cdate": 1520747810946, "id": "rJsQBrfYf", "invitation": "ICLR.cc/2018/Workshop/-/Paper94/Official_Review", "forum": "ByuM23RUG", "replyto": "ByuM23RUG", "signatures": ["ICLR.cc/2018/Workshop/Paper94/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper94/AnonReviewer3"], "content": {"title": "Review", "rating": "6: Marginally above acceptance threshold", "review": "The paper proposed a novel method for training discrete sequences. It is related to GAN training. The proposed method first trains the discriminator to discriminator real samples and negative samples from data, it then trains the generator to maximize the reward of the discriminator while keeping the discriminator fixed.  The proposed method outperforms SeqGAN and RankGAN for the Oracel test.\n\nThis is an interesting idea. It seems that this method alleviates the stability issue of training GANs. For the experiments, was the generator pretrained on the MLE objective.  I would be curious to see the performance on real text data (compared to synthetic data), I am also curious if the generator has issues with mode dropping. ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Expert-based reward function training: the novel method to train sequence generators", "abstract": "The training methods of sequence generator with a combination of GAN and policy gradient has shown good performance.\nIn this paper, we propose expert-based reward function training: the novel method to train sequence generator.\nDifferent from previous studies of sequence generation, expert-based reward function training does not utilize GAN's framework.\nStill, our model outperforms SeqGAN and a strong baseline, RankGAN.", "pdf": "/pdf/933c4ef21322bcb1628e4730f8b1c053b653074e.pdf", "TL;DR": "This paper aims to learn a better metric for unsupervised learning, such as text generation, and shows a significant improvement over SeqGAN.", "paperhash": "toyama|expertbased_reward_function_training_the_novel_method_to_train_sequence_generators", "keywords": ["sequence generation", "reinforcement learning", "unsupervised learning", "RNN"], "authors": ["Joji Toyama", "Yusuke Iwasawa", "Kotaro Nakayama", "Yutaka Matsuo"], "authorids": ["toyama@weblab.t.u-tokyo.ac.jp", "iwasawa@weblab.t.u-tokyo.ac.jp", "nakayama@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "_bibtex": "@misc{\n  toyama2018expert-based,\n  title={Expert-based reward function training: the novel method to train sequence generators},\n  author={Joji Toyama and Yusuke Iwasawa and Kotaro Nakayama and Yutaka Matsuo},\n  year={2018},\n  url={https://openreview.net/forum?id=ByuM23RUG}\n}"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582903458, "id": "ICLR.cc/2018/Workshop/-/Paper94/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper94/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper94/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper94/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper94/AnonReviewer1"], "reply": {"forum": "ByuM23RUG", "replyto": "ByuM23RUG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper94/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper94/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582903458}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582621194, "tcdate": 1520863665276, "number": 3, "cdate": 1520863665276, "id": "rkF2Y-VtM", "invitation": "ICLR.cc/2018/Workshop/-/Paper94/Official_Review", "forum": "ByuM23RUG", "replyto": "ByuM23RUG", "signatures": ["ICLR.cc/2018/Workshop/Paper94/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper94/AnonReviewer1"], "content": {"title": "Expert-based reward sequence training review", "rating": "7: Good paper, accept", "review": "A good set of promising results on a model that essentially uses an intermediate density model to train sequences. This I think is a good way to ensure that the discriminator is measuring something sensible (as the generated distribution is usually likely very disjoint from the true distribution). Is there some sense in doing some curriculum learning here, mixing in the generated samples as it improves?", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Expert-based reward function training: the novel method to train sequence generators", "abstract": "The training methods of sequence generator with a combination of GAN and policy gradient has shown good performance.\nIn this paper, we propose expert-based reward function training: the novel method to train sequence generator.\nDifferent from previous studies of sequence generation, expert-based reward function training does not utilize GAN's framework.\nStill, our model outperforms SeqGAN and a strong baseline, RankGAN.", "pdf": "/pdf/933c4ef21322bcb1628e4730f8b1c053b653074e.pdf", "TL;DR": "This paper aims to learn a better metric for unsupervised learning, such as text generation, and shows a significant improvement over SeqGAN.", "paperhash": "toyama|expertbased_reward_function_training_the_novel_method_to_train_sequence_generators", "keywords": ["sequence generation", "reinforcement learning", "unsupervised learning", "RNN"], "authors": ["Joji Toyama", "Yusuke Iwasawa", "Kotaro Nakayama", "Yutaka Matsuo"], "authorids": ["toyama@weblab.t.u-tokyo.ac.jp", "iwasawa@weblab.t.u-tokyo.ac.jp", "nakayama@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "_bibtex": "@misc{\n  toyama2018expert-based,\n  title={Expert-based reward function training: the novel method to train sequence generators},\n  author={Joji Toyama and Yusuke Iwasawa and Kotaro Nakayama and Yutaka Matsuo},\n  year={2018},\n  url={https://openreview.net/forum?id=ByuM23RUG}\n}"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582903458, "id": "ICLR.cc/2018/Workshop/-/Paper94/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper94/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper94/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper94/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper94/AnonReviewer1"], "reply": {"forum": "ByuM23RUG", "replyto": "ByuM23RUG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper94/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper94/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582903458}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573568063, "tcdate": 1521573568063, "number": 110, "cdate": 1521573567720, "id": "HyOpCRAYM", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "ByuM23RUG", "replyto": "ByuM23RUG", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Expert-based reward function training: the novel method to train sequence generators", "abstract": "The training methods of sequence generator with a combination of GAN and policy gradient has shown good performance.\nIn this paper, we propose expert-based reward function training: the novel method to train sequence generator.\nDifferent from previous studies of sequence generation, expert-based reward function training does not utilize GAN's framework.\nStill, our model outperforms SeqGAN and a strong baseline, RankGAN.", "pdf": "/pdf/933c4ef21322bcb1628e4730f8b1c053b653074e.pdf", "TL;DR": "This paper aims to learn a better metric for unsupervised learning, such as text generation, and shows a significant improvement over SeqGAN.", "paperhash": "toyama|expertbased_reward_function_training_the_novel_method_to_train_sequence_generators", "keywords": ["sequence generation", "reinforcement learning", "unsupervised learning", "RNN"], "authors": ["Joji Toyama", "Yusuke Iwasawa", "Kotaro Nakayama", "Yutaka Matsuo"], "authorids": ["toyama@weblab.t.u-tokyo.ac.jp", "iwasawa@weblab.t.u-tokyo.ac.jp", "nakayama@weblab.t.u-tokyo.ac.jp", "matsuo@weblab.t.u-tokyo.ac.jp"], "_bibtex": "@misc{\n  toyama2018expert-based,\n  title={Expert-based reward function training: the novel method to train sequence generators},\n  author={Joji Toyama and Yusuke Iwasawa and Kotaro Nakayama and Yutaka Matsuo},\n  year={2018},\n  url={https://openreview.net/forum?id=ByuM23RUG}\n}"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}