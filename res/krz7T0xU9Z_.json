{"notes": [{"id": "krz7T0xU9Z_", "original": "yi8KH1VrtoZ", "number": 3072, "cdate": 1601308340788, "ddate": null, "tcdate": 1601308340788, "tmdate": 1614778092806, "tddate": null, "forum": "krz7T0xU9Z_", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "The inductive bias of ReLU networks on orthogonally separable data", "authorids": ["~Mary_Phuong1", "~Christoph_H_Lampert1"], "authors": ["Mary Phuong", "Christoph H Lampert"], "keywords": ["inductive bias", "implicit bias", "gradient descent", "ReLU networks", "max-margin", "extremal sector"], "abstract": "We study the inductive bias of two-layer ReLU networks trained by gradient flow. We identify a class of easy-to-learn (`orthogonally separable') datasets, and characterise the solution that ReLU networks trained on such datasets converge to. Irrespective of network width, the solution turns out to be a combination of two max-margin classifiers: one corresponding to the positive data subset and one corresponding to the negative data subset.\nThe proof is based on the recently introduced concept of extremal sectors, for which we prove a number of properties in the context of orthogonal separability. In particular, we prove stationarity of activation patterns from some time $T$ onwards, which enables a reduction of the ReLU network to an ensemble of linear subnetworks.\n", "one-sentence_summary": "We characterise the function learnt by two-layer ReLU nets trained on orthogonally separable data.", "pdf": "/pdf/a68e4ef7c465175fddb6ba540763c62f8708c9e3.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "phuong|the_inductive_bias_of_relu_networks_on_orthogonally_separable_data", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nphuong2021the,\ntitle={The inductive bias of Re{\\{}LU{\\}} networks on orthogonally separable data},\nauthor={Mary Phuong and Christoph H Lampert},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=krz7T0xU9Z_}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "3170cGfMqSN", "original": null, "number": 1, "cdate": 1610040455993, "ddate": null, "tcdate": 1610040455993, "tmdate": 1610474058656, "tddate": null, "forum": "krz7T0xU9Z_", "replyto": "krz7T0xU9Z_", "invitation": "ICLR.cc/2021/Conference/Paper3072/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Poster)", "comment": "The paper shows that under a very restrictive assumption on the data, ReLU networks with one hidden layer and zero bias trained by gradient flow converge two a meaningful predictor provided that the network weights are randomly initialized with sufficiently small variances. While there is some overlap with a paper by Lyu & Li (2020), the paper under review establishes its results for networks with arbitrary widths whereas using the results of Lyu & Li (2020) works, at least so far, only for sufficiently wide networks. The assumption on the data is anything than realistic and actually any \"simple, conventional\" learning algorithm can easily learn in this regime. Nonetheless, getting meaningful results for neural networks is still a notoriously difficult task and for this reason, the paper deserves publication.   "}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The inductive bias of ReLU networks on orthogonally separable data", "authorids": ["~Mary_Phuong1", "~Christoph_H_Lampert1"], "authors": ["Mary Phuong", "Christoph H Lampert"], "keywords": ["inductive bias", "implicit bias", "gradient descent", "ReLU networks", "max-margin", "extremal sector"], "abstract": "We study the inductive bias of two-layer ReLU networks trained by gradient flow. We identify a class of easy-to-learn (`orthogonally separable') datasets, and characterise the solution that ReLU networks trained on such datasets converge to. Irrespective of network width, the solution turns out to be a combination of two max-margin classifiers: one corresponding to the positive data subset and one corresponding to the negative data subset.\nThe proof is based on the recently introduced concept of extremal sectors, for which we prove a number of properties in the context of orthogonal separability. In particular, we prove stationarity of activation patterns from some time $T$ onwards, which enables a reduction of the ReLU network to an ensemble of linear subnetworks.\n", "one-sentence_summary": "We characterise the function learnt by two-layer ReLU nets trained on orthogonally separable data.", "pdf": "/pdf/a68e4ef7c465175fddb6ba540763c62f8708c9e3.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "phuong|the_inductive_bias_of_relu_networks_on_orthogonally_separable_data", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nphuong2021the,\ntitle={The inductive bias of Re{\\{}LU{\\}} networks on orthogonally separable data},\nauthor={Mary Phuong and Christoph H Lampert},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=krz7T0xU9Z_}\n}"}, "tags": [], "invitation": {"reply": {"forum": "krz7T0xU9Z_", "replyto": "krz7T0xU9Z_", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040455980, "tmdate": 1610474058637, "id": "ICLR.cc/2021/Conference/Paper3072/-/Decision"}}}, {"id": "OuQZ5vfkPgt", "original": null, "number": 6, "cdate": 1606271078592, "ddate": null, "tcdate": 1606271078592, "tmdate": 1606271078592, "tddate": null, "forum": "krz7T0xU9Z_", "replyto": "m4q7wUmD5dc", "invitation": "ICLR.cc/2021/Conference/Paper3072/-/Official_Comment", "content": {"title": "Re: possibly stronger results", "comment": "I greatly appreciate your detailed response. I would like to clarify my comment on the \u2018possibly stronger results\u2019.\n\nAs you mentioned in your response, Lyu & Li assumes that at some time T, the network converges to a zero-training-error solution. Based on this assumption, Lyu & Li shows the implicit bias of homogeneous models. \n\nOn the other hand, by Li & Liang, Ji & Telgarsky or other recent results on training neural networks with logistic loss, as long as the network is wide enough, the network should be able to achieve zero training error at some point during the training. Since we only apply these results to show the guarantee for a zero-training-error solution, it is not necessary to require an infinitely wide network. (Under the assumption in the submission, the data are linearly separable, and therefore the width requirement can be polylog by Ji & Telgarsky.) \n\nCombining these results, for example, Ji & Telgarsky and Lyu & Li, we can see that as long as the data are non-parallel to each other, wide enough networks can reach a KKT point of the nonlinear maximum margin problem. In contrast, the submission shows the convergence to a linear maximum margin solution under a much stronger assumption. \n\nI hope the above clarifies (i) why I think the previous results may still be comparable to this paper, (ii) why it is not necessary to apply Li & Liang (or other similar results mentioned in the review with milder data assumptions) for an arbitrarily long training time or increasingly wide networks, and (iii) why I feel the combination of the various existing results may be stronger than the results in this paper (weaker assumptions, deeper networks, more general implicit bias).\n\nThat being said, I agree that the results in this submission provide a more refined characterization of the implicit bias under the stronger assumption of orthogonal separability, and this setting has not been studied in the literature.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3072/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3072/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The inductive bias of ReLU networks on orthogonally separable data", "authorids": ["~Mary_Phuong1", "~Christoph_H_Lampert1"], "authors": ["Mary Phuong", "Christoph H Lampert"], "keywords": ["inductive bias", "implicit bias", "gradient descent", "ReLU networks", "max-margin", "extremal sector"], "abstract": "We study the inductive bias of two-layer ReLU networks trained by gradient flow. We identify a class of easy-to-learn (`orthogonally separable') datasets, and characterise the solution that ReLU networks trained on such datasets converge to. Irrespective of network width, the solution turns out to be a combination of two max-margin classifiers: one corresponding to the positive data subset and one corresponding to the negative data subset.\nThe proof is based on the recently introduced concept of extremal sectors, for which we prove a number of properties in the context of orthogonal separability. In particular, we prove stationarity of activation patterns from some time $T$ onwards, which enables a reduction of the ReLU network to an ensemble of linear subnetworks.\n", "one-sentence_summary": "We characterise the function learnt by two-layer ReLU nets trained on orthogonally separable data.", "pdf": "/pdf/a68e4ef7c465175fddb6ba540763c62f8708c9e3.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "phuong|the_inductive_bias_of_relu_networks_on_orthogonally_separable_data", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nphuong2021the,\ntitle={The inductive bias of Re{\\{}LU{\\}} networks on orthogonally separable data},\nauthor={Mary Phuong and Christoph H Lampert},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=krz7T0xU9Z_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "krz7T0xU9Z_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3072/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3072/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3072/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3072/Authors|ICLR.cc/2021/Conference/Paper3072/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3072/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923841413, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3072/-/Official_Comment"}}}, {"id": "-OSILLHajAZ", "original": null, "number": 5, "cdate": 1605962863540, "ddate": null, "tcdate": 1605962863540, "tmdate": 1605962863540, "tddate": null, "forum": "krz7T0xU9Z_", "replyto": "Cqf3_ffvFnS", "invitation": "ICLR.cc/2021/Conference/Paper3072/-/Official_Comment", "content": {"title": "Thank you! Assumptions on the data explained in more detail and made formal", "comment": "Thank you for your encouraging feedback!\nBelow we hope to answer your questions, but please do comment if anything remains unclear.\n\n(General position) You are completely right. We mean 'general position' from geometry: no d-dimensional hyperplane contains more than d+1 points. We have now clarified this in the paper. \n\n(Almost all datasets) To motivate the framing, there are a number of 'bad configurations' that we would like to avoid. For example, Lemma 1 requires that for each sector, g(w) as defined in eq. (31) lies in the relative interior of the sector or in the interior of the complement of the sector (i.e. it does not lie exactly on the relative boundary of the sector). Another example is Lemma A.3 which, as you rightly point out, requires that the data lie in general position. \n\nOne way to deal with all of these is to require that the data is sampled from a distribution with a density. More precisely, by 'almost all datasets' we mean that if x_i are sampled from any distribution with a density wrt the Lebesgue measure, then the theorem (treated as an implication) holds with probability one wrt the data. This is an easy-to-state and sufficient condition for our results to hold (we have now clarified this in the paper).\n\n(lambda) An explicit bound on lambda does seem attainable (see e.g. the last equation on p.26 of [Maennel et al, 2018]), but this goes deeper into prior work and we did not try to do it.\n\n(Experiments) Yes, the networks in 5.1 and 5.2 are trained on identical data. \n\n(Typos, notation) Thanks!\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3072/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3072/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The inductive bias of ReLU networks on orthogonally separable data", "authorids": ["~Mary_Phuong1", "~Christoph_H_Lampert1"], "authors": ["Mary Phuong", "Christoph H Lampert"], "keywords": ["inductive bias", "implicit bias", "gradient descent", "ReLU networks", "max-margin", "extremal sector"], "abstract": "We study the inductive bias of two-layer ReLU networks trained by gradient flow. We identify a class of easy-to-learn (`orthogonally separable') datasets, and characterise the solution that ReLU networks trained on such datasets converge to. Irrespective of network width, the solution turns out to be a combination of two max-margin classifiers: one corresponding to the positive data subset and one corresponding to the negative data subset.\nThe proof is based on the recently introduced concept of extremal sectors, for which we prove a number of properties in the context of orthogonal separability. In particular, we prove stationarity of activation patterns from some time $T$ onwards, which enables a reduction of the ReLU network to an ensemble of linear subnetworks.\n", "one-sentence_summary": "We characterise the function learnt by two-layer ReLU nets trained on orthogonally separable data.", "pdf": "/pdf/a68e4ef7c465175fddb6ba540763c62f8708c9e3.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "phuong|the_inductive_bias_of_relu_networks_on_orthogonally_separable_data", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nphuong2021the,\ntitle={The inductive bias of Re{\\{}LU{\\}} networks on orthogonally separable data},\nauthor={Mary Phuong and Christoph H Lampert},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=krz7T0xU9Z_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "krz7T0xU9Z_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3072/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3072/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3072/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3072/Authors|ICLR.cc/2021/Conference/Paper3072/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3072/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923841413, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3072/-/Official_Comment"}}}, {"id": "NwYCcV5JJOG", "original": null, "number": 4, "cdate": 1605962673087, "ddate": null, "tcdate": 1605962673087, "tmdate": 1605962673087, "tddate": null, "forum": "krz7T0xU9Z_", "replyto": "BKzK5qYrGPz", "invitation": "ICLR.cc/2021/Conference/Paper3072/-/Official_Comment", "content": {"title": "Thank you!", "comment": "Thank you for your encouraging feedback!\nBelow we hope to answer your questions, but please do comment if anything remains unclear.\n\n1, We have expanded Theorem 1 to include the characterisation of the outer weights as well. (The magnitude of a_j equals the norm of the respective w_j, and the sign of a_j is 1 if w_j converges to w+ and -1 if w_j converges to w-.)\n\n2, First-layer biases: Yes, via the data transformation x' = [x, c] for a constant c. The constant would have to be small enough such that the transformed data is still orthogonally separable. The first-layer neurons would then converge to the bias-regularised max-margin directions. If the bias is also initialised differently, then this would affect the (1-1/2^p) factor, but the crux of the result should go through.\n\nSecond-layer bias: Likely yes, but we are less sure. In this case, the (scalar) bias roughly tries to adjust so that the margin of the positive class equals the margin of the negative class. In the second phase of learning (after neurons have separated), this seems to matter little, but the first phase of training could be affected if the classes are very imbalanced.\n\n3, The easiest (though not the most realistic) case is if the classes have disjoint sparsity patterns in feature space. Creating such class-specific features was popular e.g. for structured multiclass SVMs. In general, we are not aware of any simple preprocessing procedure that would guarantee orthogonal separability. However, in future work we'd be very interested in studying whether deep nets learn orthogonally separable representations by themselves (we have added some preliminary experiments in support of this in Appendix D).\n\n4, There are no assumptions on lambda_j's except that they are small, lambda_j \\in (0, lambda]. We have changed the text to make this a bit clearer.\n\n5, Thank you, we have done so.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3072/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3072/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The inductive bias of ReLU networks on orthogonally separable data", "authorids": ["~Mary_Phuong1", "~Christoph_H_Lampert1"], "authors": ["Mary Phuong", "Christoph H Lampert"], "keywords": ["inductive bias", "implicit bias", "gradient descent", "ReLU networks", "max-margin", "extremal sector"], "abstract": "We study the inductive bias of two-layer ReLU networks trained by gradient flow. We identify a class of easy-to-learn (`orthogonally separable') datasets, and characterise the solution that ReLU networks trained on such datasets converge to. Irrespective of network width, the solution turns out to be a combination of two max-margin classifiers: one corresponding to the positive data subset and one corresponding to the negative data subset.\nThe proof is based on the recently introduced concept of extremal sectors, for which we prove a number of properties in the context of orthogonal separability. In particular, we prove stationarity of activation patterns from some time $T$ onwards, which enables a reduction of the ReLU network to an ensemble of linear subnetworks.\n", "one-sentence_summary": "We characterise the function learnt by two-layer ReLU nets trained on orthogonally separable data.", "pdf": "/pdf/a68e4ef7c465175fddb6ba540763c62f8708c9e3.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "phuong|the_inductive_bias_of_relu_networks_on_orthogonally_separable_data", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nphuong2021the,\ntitle={The inductive bias of Re{\\{}LU{\\}} networks on orthogonally separable data},\nauthor={Mary Phuong and Christoph H Lampert},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=krz7T0xU9Z_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "krz7T0xU9Z_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3072/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3072/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3072/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3072/Authors|ICLR.cc/2021/Conference/Paper3072/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3072/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923841413, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3072/-/Official_Comment"}}}, {"id": "m4q7wUmD5dc", "original": null, "number": 3, "cdate": 1605962490771, "ddate": null, "tcdate": 1605962490771, "tmdate": 1605962490771, "tddate": null, "forum": "krz7T0xU9Z_", "replyto": "tzzK496sMzr", "invitation": "ICLR.cc/2021/Conference/Paper3072/-/Official_Comment", "content": {"title": "The setting is simple, but has not been addressed in the literature", "comment": "Thank you for your feedback!\nBelow we hope to address your concerns, but please do comment if anything remains unclear or disputable.\n\n(Orthogonal separability) We agree that the assumption is strong and that it makes the classification problem trivial. However, the network doesn't know it's trivial and doesn't use the trivial algorithm.\nIt is a priori unclear what a network would do even in this setting, and we believe it was valuable to work it out.\n\n(a. Comparison to Lyu & Li) We think the mentioned paper and ours are not directly comparable.\nFirst, that paper assumes that at some time T, the network converges to a zero-training-error solution, and focusses on how training unfolds from there. It does not discuss how one arrives at such a zero-training-error solution in the first place, or indeed which of the many attainable zero-training-error solutions are preferred by (S)GD.\nIn contrast, we analyse the entire training process, from initialisation until convergence. The starting point for our analysis is random initialisation, as opposed to an assumed zero-error solution, and we characterise the solution preferred by GD.\n\nSecond, our result is actually stronger, in the sense that we give an exact formula for the learned network, whereas they give a necessary first-order condition with potentially many solutions (in fact, which of the first-order points (S)GD picks likely depends on which zero-error basin is assumed as the starting point of the analysis).\n\nOf course, our (stronger) conclusions make use of stronger assumptions, and the work of Lyu & Li applies more generally.\n\n(a. Nonlinear max-margin) Yes, the solution described in Theorem 1 (with appropriately normalised u and z) is indeed a KKT point of the nonlinear max-margin problem (P) [Theorem 4.4, Lyu & Li]. We have included a proof of this claim in Appendix C.\n\n(b) Compared to the first two mentioned papers, the answer is the difference between ReLU neurons and linear neurons. ReLU updates are more local: when learning, linear neurons take into account all examples, whereas ReLU neurons take into account examples in their positive half-plane only. How a ReLU neuron updates and what trajectory it takes is therefore determined by its initial orientation. \n\nCompared to the last paper, the answer is related to point (a) above: we are interested in the early phase of training and bias towards specific minima, which the other paper simply assumes away.\n\n(c. Comparison to Li & Liang) It seems to us that training longer (i.e. letting weights go to infinity, and the training error to approach zero) in the setting of [Li & Liang, 2018] would require the network to keep increasing its width [Li & Liang, p.5, last line]: m \\geq poly(1/epsilon), which however is the basis for setting the initialisation scale [p.3, assumption (A3)]: sigma = m^{-1/2}. So, to be able to train longer, one needs to start with a smaller init, which has the effect of limiting how far one can go.\n\nIn contrast, our work allows the training time to go to infinity and the width of the network to be fixed.\n\nHowever, if we have somehow misunderunderstood your argument, please do correct us and we are happy to discuss.\n\n(c. Possibly stronger result) We do not (yet) see how the papers [Lyu & Li 2020, Ji & Telgarsky 2020, Moroshko et al 2020] imply a stronger result than ours. We are happy to discuss if you provide more details, e.g. which theorems/lemmas you have in mind.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3072/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3072/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The inductive bias of ReLU networks on orthogonally separable data", "authorids": ["~Mary_Phuong1", "~Christoph_H_Lampert1"], "authors": ["Mary Phuong", "Christoph H Lampert"], "keywords": ["inductive bias", "implicit bias", "gradient descent", "ReLU networks", "max-margin", "extremal sector"], "abstract": "We study the inductive bias of two-layer ReLU networks trained by gradient flow. We identify a class of easy-to-learn (`orthogonally separable') datasets, and characterise the solution that ReLU networks trained on such datasets converge to. Irrespective of network width, the solution turns out to be a combination of two max-margin classifiers: one corresponding to the positive data subset and one corresponding to the negative data subset.\nThe proof is based on the recently introduced concept of extremal sectors, for which we prove a number of properties in the context of orthogonal separability. In particular, we prove stationarity of activation patterns from some time $T$ onwards, which enables a reduction of the ReLU network to an ensemble of linear subnetworks.\n", "one-sentence_summary": "We characterise the function learnt by two-layer ReLU nets trained on orthogonally separable data.", "pdf": "/pdf/a68e4ef7c465175fddb6ba540763c62f8708c9e3.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "phuong|the_inductive_bias_of_relu_networks_on_orthogonally_separable_data", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nphuong2021the,\ntitle={The inductive bias of Re{\\{}LU{\\}} networks on orthogonally separable data},\nauthor={Mary Phuong and Christoph H Lampert},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=krz7T0xU9Z_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "krz7T0xU9Z_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3072/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3072/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3072/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3072/Authors|ICLR.cc/2021/Conference/Paper3072/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3072/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923841413, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3072/-/Official_Comment"}}}, {"id": "c4CC5-QCp0z", "original": null, "number": 2, "cdate": 1605962226598, "ddate": null, "tcdate": 1605962226598, "tmdate": 1605962226598, "tddate": null, "forum": "krz7T0xU9Z_", "replyto": "Zgc4Qsv7xng", "invitation": "ICLR.cc/2021/Conference/Paper3072/-/Official_Comment", "content": {"title": "Thank you!", "comment": "Thank you for your encouraging feedback!\nBelow we hope to answer your questions, but please do comment if anything remains unclear.\n\n(1) Our notion of max-margin is the single-class one originally employed e.g. by one-class support vector machines. It corresponds to the max-margin separator between the data and the origin, and it coincides with the minimum-norm vector subject to inner-product constraints.\n\n(2) The mentioned paper assumes that at some time T, the network converges to a zero-training-error solution, and focusses on how training unfolds from there. It does not discuss how one arrives at such a zero-training-error solution in the first place, or indeed which of the many attainable zero-training-error solutions are preferred by (S)GD. Also, the term 'max-margin' is used differently than in our work: they mean 'min_x f(x)', which depends on the network parameters and is a moving target.\n\nIn contrast, we analyse the entire training process, from initialisation until convergence. The starting point for our analysis is random initialisation, as opposed to an assumed zero-error solution, and we characterise the solution preferred by GD. The characterisation of the solution is complete in the sense that it is an exact formula depending on the dataset only (as opposed to a stationarity-type necessary condition with potentially many solutions).\n\n(3) Thank you for the suggestion, we have added an MNIST experiment to Appendix D (p.18).\n\n(4) The easiest (though not the most realistic) case is if the classes have disjoint sparsity patterns in feature space. Creating such class-specific features was popular e.g. for structured multiclass SVMs. In general, we are not aware of any simple preprocessing procedure that would guarantee orthogonal separability. However, in future work we'd be very interested in studying whether deep nets learn orthogonally separable representations by themselves (see also Appendix D, Figure 3).\n\n(5) The first singular value corresponds to the horizontal direction in Figure 1b (the 'shared' direction of w+ and w-), and the second singular value corresponds to the vertical direction in Figure 1b (the direction in which w+, w- deviate from the shared direction). \n\n(6,7) Thanks for the feedback! We have added an intuitive explanation of how Definitions 1 and 2 relate to each other, and what the role of G is.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3072/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3072/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The inductive bias of ReLU networks on orthogonally separable data", "authorids": ["~Mary_Phuong1", "~Christoph_H_Lampert1"], "authors": ["Mary Phuong", "Christoph H Lampert"], "keywords": ["inductive bias", "implicit bias", "gradient descent", "ReLU networks", "max-margin", "extremal sector"], "abstract": "We study the inductive bias of two-layer ReLU networks trained by gradient flow. We identify a class of easy-to-learn (`orthogonally separable') datasets, and characterise the solution that ReLU networks trained on such datasets converge to. Irrespective of network width, the solution turns out to be a combination of two max-margin classifiers: one corresponding to the positive data subset and one corresponding to the negative data subset.\nThe proof is based on the recently introduced concept of extremal sectors, for which we prove a number of properties in the context of orthogonal separability. In particular, we prove stationarity of activation patterns from some time $T$ onwards, which enables a reduction of the ReLU network to an ensemble of linear subnetworks.\n", "one-sentence_summary": "We characterise the function learnt by two-layer ReLU nets trained on orthogonally separable data.", "pdf": "/pdf/a68e4ef7c465175fddb6ba540763c62f8708c9e3.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "phuong|the_inductive_bias_of_relu_networks_on_orthogonally_separable_data", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nphuong2021the,\ntitle={The inductive bias of Re{\\{}LU{\\}} networks on orthogonally separable data},\nauthor={Mary Phuong and Christoph H Lampert},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=krz7T0xU9Z_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "krz7T0xU9Z_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3072/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3072/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3072/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3072/Authors|ICLR.cc/2021/Conference/Paper3072/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3072/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923841413, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3072/-/Official_Comment"}}}, {"id": "Cqf3_ffvFnS", "original": null, "number": 1, "cdate": 1603826909979, "ddate": null, "tcdate": 1603826909979, "tmdate": 1605024073798, "tddate": null, "forum": "krz7T0xU9Z_", "replyto": "krz7T0xU9Z_", "invitation": "ICLR.cc/2021/Conference/Paper3072/-/Official_Review", "content": {"title": "I find that the paper is well written, modulo some assumptions on the data that would be better to be made more rigorous. ", "review": "This paper studies the inductive bias of two-layer ReLU networks trained by gradient flow. The main challenge is to analyze the global convergence of the flow dynamics. Under a special assumption that the data are orthogonally separable, the paper shows that the dynamics converges to a unique max-margin solution. I find that the paper is well written, modulo some assumptions on the data that would be better to be made more rigorous. The overall quality is good. The novelty compared to the literature is that this paper provides a global analysis of the non-linear non-smooth dynamics without going into the over-parameterized regime.\u00a0\n\nIn Theorem 1 of the paper, what does it mean \u00ab\u00a0For almost all such datasets?\u00a0\u00bb What is the probability distribution of (X,y)? Is there any more precision condition on \\lambda, which controls the norm of the initial weights?\u00a0\n\nIn Lemma A.3, what does it mean \u00ab\u00a0genetic position\u00a0\u00bb? I think what is needed is to assume that the probability that all the x_i lie on some hyperplane is close to zero. This assumption is crucial for (43) to hold,\u00a0therefore I think it should be made more precise.\u00a0Or to put in a less probabilistic, one may assume that the maximal number of samples {x_i} that lie on some hyperplane is smaller than the dimension of x_i.\n\nFor clarity, is the experiment in 5.2 uses the same data (X,y) as in 5.1?\u00a0\n\nSome typos or confusions of notations are listed below:\n- \\ell^+(t) right before (18), is confusing, as \\ell^+ is a function of \\theta, I would suggest to use L^+(t)\u00a0 = \\ell^+(\\theta(t))\u00a0\n- Change W+(t) -> W_(t) to (24)\n- \\ell\u2019_i(t) in (40) and (41) are also confusing, write L_i\u2019(t) = \\ell_i\u2019(\\theta(t)) ?\u00a0\n- Change \\Sigma[i,j] -> \\Sigma[j,i] in (42), (43), etc.\u00a0\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3072/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3072/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The inductive bias of ReLU networks on orthogonally separable data", "authorids": ["~Mary_Phuong1", "~Christoph_H_Lampert1"], "authors": ["Mary Phuong", "Christoph H Lampert"], "keywords": ["inductive bias", "implicit bias", "gradient descent", "ReLU networks", "max-margin", "extremal sector"], "abstract": "We study the inductive bias of two-layer ReLU networks trained by gradient flow. We identify a class of easy-to-learn (`orthogonally separable') datasets, and characterise the solution that ReLU networks trained on such datasets converge to. Irrespective of network width, the solution turns out to be a combination of two max-margin classifiers: one corresponding to the positive data subset and one corresponding to the negative data subset.\nThe proof is based on the recently introduced concept of extremal sectors, for which we prove a number of properties in the context of orthogonal separability. In particular, we prove stationarity of activation patterns from some time $T$ onwards, which enables a reduction of the ReLU network to an ensemble of linear subnetworks.\n", "one-sentence_summary": "We characterise the function learnt by two-layer ReLU nets trained on orthogonally separable data.", "pdf": "/pdf/a68e4ef7c465175fddb6ba540763c62f8708c9e3.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "phuong|the_inductive_bias_of_relu_networks_on_orthogonally_separable_data", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nphuong2021the,\ntitle={The inductive bias of Re{\\{}LU{\\}} networks on orthogonally separable data},\nauthor={Mary Phuong and Christoph H Lampert},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=krz7T0xU9Z_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "krz7T0xU9Z_", "replyto": "krz7T0xU9Z_", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3072/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538082848, "tmdate": 1606915788353, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3072/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3072/-/Official_Review"}}}, {"id": "BKzK5qYrGPz", "original": null, "number": 2, "cdate": 1603930346720, "ddate": null, "tcdate": 1603930346720, "tmdate": 1605024073735, "tddate": null, "forum": "krz7T0xU9Z_", "replyto": "krz7T0xU9Z_", "invitation": "ICLR.cc/2021/Conference/Paper3072/-/Official_Review", "content": {"title": "Good paper that studies an important and interesting problem. Provides a clean solution.", "review": "This paper characterizes the implicit bias of gradient flow of two-layer ReLU networks on orthogonally separable data trained on the logistic loss. The problem of characterizing the implicit bias of gradient descent on neural networks is an important one, and while the authors do make fairly strong assumptions on the data (data corresponding to the different labels lie in separate orthants), the proof is novel, interesting and non-trivial. The proofs are carefully carried out and seemed as far as I could verify.\n\n\nA few questions:\n1. Is it possible to characterize what the outer weights (a's) converge to? If yes, I would suggest that the authors include this either in the main theorem, or as a comment after the theorem.\n2. Does a similar result hold if the network also has bias variables? \n3. Can linearly separable data be made into orthogonally separable data (by appropriate pre-processing) and by also training a bias term?\n4. How are the lambda_j's chosen in the near zero initialization? The current description of choosing lambda_j on page 2 is quite vague.\n5. I would also urge the authors to add the additional assumption about the positive and negative examples spanning the entire space in Section 2 along with the other assumptions. ", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3072/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3072/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The inductive bias of ReLU networks on orthogonally separable data", "authorids": ["~Mary_Phuong1", "~Christoph_H_Lampert1"], "authors": ["Mary Phuong", "Christoph H Lampert"], "keywords": ["inductive bias", "implicit bias", "gradient descent", "ReLU networks", "max-margin", "extremal sector"], "abstract": "We study the inductive bias of two-layer ReLU networks trained by gradient flow. We identify a class of easy-to-learn (`orthogonally separable') datasets, and characterise the solution that ReLU networks trained on such datasets converge to. Irrespective of network width, the solution turns out to be a combination of two max-margin classifiers: one corresponding to the positive data subset and one corresponding to the negative data subset.\nThe proof is based on the recently introduced concept of extremal sectors, for which we prove a number of properties in the context of orthogonal separability. In particular, we prove stationarity of activation patterns from some time $T$ onwards, which enables a reduction of the ReLU network to an ensemble of linear subnetworks.\n", "one-sentence_summary": "We characterise the function learnt by two-layer ReLU nets trained on orthogonally separable data.", "pdf": "/pdf/a68e4ef7c465175fddb6ba540763c62f8708c9e3.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "phuong|the_inductive_bias_of_relu_networks_on_orthogonally_separable_data", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nphuong2021the,\ntitle={The inductive bias of Re{\\{}LU{\\}} networks on orthogonally separable data},\nauthor={Mary Phuong and Christoph H Lampert},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=krz7T0xU9Z_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "krz7T0xU9Z_", "replyto": "krz7T0xU9Z_", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3072/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538082848, "tmdate": 1606915788353, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3072/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3072/-/Official_Review"}}}, {"id": "tzzK496sMzr", "original": null, "number": 3, "cdate": 1603970606261, "ddate": null, "tcdate": 1603970606261, "tmdate": 1605024073676, "tddate": null, "forum": "krz7T0xU9Z_", "replyto": "krz7T0xU9Z_", "invitation": "ICLR.cc/2021/Conference/Paper3072/-/Official_Review", "content": {"title": "The assumptions may be too strong", "review": "This paper studies the inductive bias of gradient flow for two-layer ReLU networks for classification problems. Under an orthogonally separable data assumption, it is shown that each node of the ReLU network will converge to one of two directions that linearly separate the data. I think the inductive bias of neural network training is a very important research problem and the result of this paper looks interesting. However, I also have the following concerns about this paper. \n\nPerhaps the most obvious limitation of this paper is that the orthogonally separable data assumption is too strong. Under this assumption, the classification problem can be solved trivially: one can simply randomly pick a training example and use it as the parameters in a linear predictor. It seems to be highly unlikely that this assumption can be satisfied by any challenging real-world problems.\n\nMoreover, the current submission lacks discussion and explanation of their results:\n\n(a) The result of this paper seems to be weaker than the result in Lyu & Li (2020), while also requiring much stronger assumptions than Lyu & Li (2020).  Note that the inductive bias given in Lyu & Li (2020) is in the form of a maximum margin KKT point of the ReLU network (as a *nonlinear* classifier), however, the result in this paper is more related to the maximum margin solution of linear models, which in general may be much worse than the margin achievable by wide neural networks. Therefore I guess the most straightforward question the authors should clarify is whether under their setting w^+ and w^- indeed gives a KKT point of the *nonlinear* maximum margin problem given by Lyu & Li (2020).\n\n(b) To my knowledge most of the inductive bias results for classification problems (cross-entropy/exponential loss) do not rely on specific initialization methods (except certain assumptions to guarantee achieving zero training error) (Soudry et al. (2018), Ji & Telgarsky (2019b), Lyu & Li (2020)). Therefore the authors may consider providing more explanation on why they require the specific initialization.\n\n(c) In Section 6 it is mentioned that Li & Liang (2018) contain the training in the neighborhood of the (relatively large) initialization. While this is to some extent true, I find this comment not very convincing. When studying inductive bias, it is natural to restrict the training to a fixed training dataset, i.e. to treat the online SGD in Li & Liang (2018) as finite sum SGD by considering a uniform data distribution over training samples. In this case, since Li & Liang (2018) considers classification with cross-entropy loss, the weights will eventually go to infinity and therefore will not stay in the neighborhood of initialization forever, as is shown in Lyu & Li (2020). This is also true for other classification results in the lazy training setting including [1,2,3,4]. It seems that a combination of these results mentioned above and the result by Lyu & Li (2020), which has been discussed in Ji & Telgarsky, 2020 and [5], can already imply a much stronger result compared to this paper. \n\n\n\n\n[1] Zou, Difan, Yuan Cao, Dongruo Zhou, and Quanquan Gu. \"Stochastic Gradient Descent Optimizes Over-parameterized Deep ReLU Networks.\" arXiv preprint arXiv:1811.08888 (2018).\n\n[2] Nitanda, Atsushi, Geoffrey Chinot, and Taiji Suzuki. \"Gradient Descent can Learn Less Over-parameterized Two-layer Neural Networks on Classification Problems.\" arXiv preprint arXiv:1905.09870 (2019).\n\n[3] Cao, Yuan, and Quanquan Gu. \"Generalization bounds of stochastic gradient descent for wide and deep neural networks.\" NeurIPS 2019.\n\n[4] Ji, Ziwei, and Matus Telgarsky. \"Polylogarithmic width suffices for gradient descent to achieve arbitrarily small test error with shallow relu networks.\" ICLR 2020.\n\n[5] Moroshko, Edward, Suriya Gunasekar, Blake Woodworth, Jason D. Lee, Nathan Srebro, and Daniel Soudry. \"Implicit bias in deep linear classification: Initialization scale vs training accuracy.\" arXiv preprint arXiv:2007.06738 (2020).\n\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3072/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3072/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The inductive bias of ReLU networks on orthogonally separable data", "authorids": ["~Mary_Phuong1", "~Christoph_H_Lampert1"], "authors": ["Mary Phuong", "Christoph H Lampert"], "keywords": ["inductive bias", "implicit bias", "gradient descent", "ReLU networks", "max-margin", "extremal sector"], "abstract": "We study the inductive bias of two-layer ReLU networks trained by gradient flow. We identify a class of easy-to-learn (`orthogonally separable') datasets, and characterise the solution that ReLU networks trained on such datasets converge to. Irrespective of network width, the solution turns out to be a combination of two max-margin classifiers: one corresponding to the positive data subset and one corresponding to the negative data subset.\nThe proof is based on the recently introduced concept of extremal sectors, for which we prove a number of properties in the context of orthogonal separability. In particular, we prove stationarity of activation patterns from some time $T$ onwards, which enables a reduction of the ReLU network to an ensemble of linear subnetworks.\n", "one-sentence_summary": "We characterise the function learnt by two-layer ReLU nets trained on orthogonally separable data.", "pdf": "/pdf/a68e4ef7c465175fddb6ba540763c62f8708c9e3.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "phuong|the_inductive_bias_of_relu_networks_on_orthogonally_separable_data", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nphuong2021the,\ntitle={The inductive bias of Re{\\{}LU{\\}} networks on orthogonally separable data},\nauthor={Mary Phuong and Christoph H Lampert},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=krz7T0xU9Z_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "krz7T0xU9Z_", "replyto": "krz7T0xU9Z_", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3072/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538082848, "tmdate": 1606915788353, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3072/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3072/-/Official_Review"}}}, {"id": "Zgc4Qsv7xng", "original": null, "number": 4, "cdate": 1604026011025, "ddate": null, "tcdate": 1604026011025, "tmdate": 1605024073616, "tddate": null, "forum": "krz7T0xU9Z_", "replyto": "krz7T0xU9Z_", "invitation": "ICLR.cc/2021/Conference/Paper3072/-/Official_Review", "content": {"title": "Very special case of inductive bias, very well presented.", "review": "(a) This belongs to the literature of implicit bias/inductive bias, which has\ngained a great deal of attention among theoretical enthusiasts with an\noptimization leaning.\n\n(b) The paper is carefully laid out and argued, and is at a nice level\nof clarity and precision.\n\n(c) The mathematical argumentation seems to me correct; \nhowever I haven't checked line-by-line.\n\n(d) The situation being studied is very very special\nand doesn't much correspond to the big kahuna\ndeep learning. Nevertheless the intellectual clarity\nof this special case is quite appealing.\n\n(e) The implied conclusion seems rather special\nas well. From one viewpoint it says that if you start \nfrom the get-go with perfect \nseparation of a particular strong form,\nthen the future evolution of the training \ncan never spoil things. This is a very weak statement,\nbut I suppose if we can't get results here in a very special case\nthat we can understand well, then the \ngeneral situation is truly hopeless.\n\nSpecific Comments.\n\n(1) Why is this max-margin if your constraints only consider one class. It seems to be more of a finding a minimum-norm vector aligned with all training data of that class. Its unclear why the concept of separating margins comes in.\n\n(2) \u201cTheory III: Dynamics and Generalization in Deep Networks\u201d by Banburski et al. also considers general deep relu networks and shows that the resulting margins are max-margin\u2014requiring only separability, not orthogonal separability. In addition, that paper uses traditional DE methods rather than relying on lesser-known extremal sector techniques. Can you discuss or highlight why the simpler example in this paper might lead to insights not found in the other paper.\n\n(3) While the paper says that it is not directly applicable to deep nets, it draws motivation from the popularity of that literature. In that spirit, to justify such an evocation, can you show at least one experiment on a non-synthetic dataset such as MNIST/CIFAR/etc (perhaps even simplified with hand-engineered preprocessed features and subsetted to two-classes) that would support the potential connection to deep learning?\n\n(4) Can you provide any evidence why datasets would become orthogonally separated? Is there some feature\nengineering procedure that tends to produce orthogonal separation?\n\n(5) In Figure 1, variance is strange: shows one big outlier, but the plotted projection shows two roughly-equal-magitude directions of variation.\n\n(6) It is unclear how Definition 2 relates to strict extremal directions as defined by the sign patterns.\n\n(7) G should be clarified: What G is and what it represents should be explained to make the results more insightful\n\n\n\n 16m 50s\n\nType a message\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3072/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3072/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "The inductive bias of ReLU networks on orthogonally separable data", "authorids": ["~Mary_Phuong1", "~Christoph_H_Lampert1"], "authors": ["Mary Phuong", "Christoph H Lampert"], "keywords": ["inductive bias", "implicit bias", "gradient descent", "ReLU networks", "max-margin", "extremal sector"], "abstract": "We study the inductive bias of two-layer ReLU networks trained by gradient flow. We identify a class of easy-to-learn (`orthogonally separable') datasets, and characterise the solution that ReLU networks trained on such datasets converge to. Irrespective of network width, the solution turns out to be a combination of two max-margin classifiers: one corresponding to the positive data subset and one corresponding to the negative data subset.\nThe proof is based on the recently introduced concept of extremal sectors, for which we prove a number of properties in the context of orthogonal separability. In particular, we prove stationarity of activation patterns from some time $T$ onwards, which enables a reduction of the ReLU network to an ensemble of linear subnetworks.\n", "one-sentence_summary": "We characterise the function learnt by two-layer ReLU nets trained on orthogonally separable data.", "pdf": "/pdf/a68e4ef7c465175fddb6ba540763c62f8708c9e3.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "phuong|the_inductive_bias_of_relu_networks_on_orthogonally_separable_data", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nphuong2021the,\ntitle={The inductive bias of Re{\\{}LU{\\}} networks on orthogonally separable data},\nauthor={Mary Phuong and Christoph H Lampert},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=krz7T0xU9Z_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "krz7T0xU9Z_", "replyto": "krz7T0xU9Z_", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3072/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538082848, "tmdate": 1606915788353, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3072/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3072/-/Official_Review"}}}], "count": 11}