{"notes": [{"id": "HJgeEh09KQ", "original": "rkeLZbCcYX", "number": 1421, "cdate": 1538087976394, "ddate": null, "tcdate": 1538087976394, "tmdate": 1554499718496, "tddate": null, "forum": "HJgeEh09KQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Boosting Robustness Certification of Neural Networks", "abstract": "We present a novel approach for the certification of neural networks against adversarial perturbations which combines scalable overapproximation methods with precise (mixed integer) linear programming. This results in significantly better precision than state-of-the-art verifiers on challenging feedforward and convolutional neural networks with piecewise linear activation functions.", "keywords": ["Robustness certification", "Adversarial Attacks", "Abstract Interpretation", "MILP Solvers", "Verification of Neural Networks"], "authorids": ["gsingh@inf.ethz.ch", "timon.gehr@inf.ethz.ch", "pueschel@inf.ethz.ch", "martin.vechev@inf.ethz.ch"], "authors": ["Gagandeep Singh", "Timon Gehr", "Markus P\u00fcschel", "Martin Vechev"], "TL;DR": "We refine the over-approximation results from incomplete verifiers using MILP solvers to prove more robustness properties than state-of-the-art. ", "pdf": "/pdf/5d0d223bd447482b1dfe80a9cb59319ba679acf6.pdf", "paperhash": "singh|boosting_robustness_certification_of_neural_networks", "_bibtex": "@inproceedings{\nsingh2018robustness,\ntitle={Robustness Certification with Refinement},\nauthor={Gagandeep Singh and Timon Gehr and Markus P\u00fcschel and Martin Vechev},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJgeEh09KQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "SJlJ3qJOlN", "original": null, "number": 1, "cdate": 1545235110654, "ddate": null, "tcdate": 1545235110654, "tmdate": 1545354475444, "tddate": null, "forum": "HJgeEh09KQ", "replyto": "HJgeEh09KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1421/Meta_Review", "content": {"metareview": "The paper addresess an important problem of neural net robustness verification, and presents a novel approach outperforming state of art; author provided details rebuttals which clarified their contributions over the state of art and highlighted scalability; this work appears to be a solid and useful contribution to the field.\n ", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Accept (Poster)", "title": "A novel and scalable approach to robustness analysis of neural nets"}, "signatures": ["ICLR.cc/2019/Conference/Paper1421/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1421/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Boosting Robustness Certification of Neural Networks", "abstract": "We present a novel approach for the certification of neural networks against adversarial perturbations which combines scalable overapproximation methods with precise (mixed integer) linear programming. This results in significantly better precision than state-of-the-art verifiers on challenging feedforward and convolutional neural networks with piecewise linear activation functions.", "keywords": ["Robustness certification", "Adversarial Attacks", "Abstract Interpretation", "MILP Solvers", "Verification of Neural Networks"], "authorids": ["gsingh@inf.ethz.ch", "timon.gehr@inf.ethz.ch", "pueschel@inf.ethz.ch", "martin.vechev@inf.ethz.ch"], "authors": ["Gagandeep Singh", "Timon Gehr", "Markus P\u00fcschel", "Martin Vechev"], "TL;DR": "We refine the over-approximation results from incomplete verifiers using MILP solvers to prove more robustness properties than state-of-the-art. ", "pdf": "/pdf/5d0d223bd447482b1dfe80a9cb59319ba679acf6.pdf", "paperhash": "singh|boosting_robustness_certification_of_neural_networks", "_bibtex": "@inproceedings{\nsingh2018robustness,\ntitle={Robustness Certification with Refinement},\nauthor={Gagandeep Singh and Timon Gehr and Markus P\u00fcschel and Martin Vechev},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJgeEh09KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1421/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352843640, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJgeEh09KQ", "replyto": "HJgeEh09KQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1421/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1421/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1421/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352843640}}}, {"id": "SJxdpsmL0m", "original": null, "number": 5, "cdate": 1543023551827, "ddate": null, "tcdate": 1543023551827, "tmdate": 1543023551827, "tddate": null, "forum": "HJgeEh09KQ", "replyto": "S1xULFL9n7", "invitation": "ICLR.cc/2019/Conference/-/Paper1421/Official_Comment", "content": {"title": "Response to main question", "comment": "\nQ1. My background is more theoretical, but I'm looking for theorems here, considering the complicatedness of the neural network. All I am looking for is probably some high-level explanation. \n\nR1. RefineAI is a new approach for proving the robustness of neural networks: it is more precise than current incomplete methods and more scalable than current complete methods. We believe this is a difficult problem and RefineAI is a promising step forward.\n\nSome key insights in the paper:\n\nInsight I: expensive but precise techniques like MILP solvers can be used for refinement earlier in the analysis but do not scale for refinement of neurons in later layers. However, they do substantially improve on incomplete verifiers.\n\nInsight II: not all neurons in the network contribute equally to the output and thus we do not need to refine all neurons in a layer. For this, we present a novel heuristic which improves the scalability of our approach while maintaining sufficient precision.   \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1421/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1421/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1421/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Boosting Robustness Certification of Neural Networks", "abstract": "We present a novel approach for the certification of neural networks against adversarial perturbations which combines scalable overapproximation methods with precise (mixed integer) linear programming. This results in significantly better precision than state-of-the-art verifiers on challenging feedforward and convolutional neural networks with piecewise linear activation functions.", "keywords": ["Robustness certification", "Adversarial Attacks", "Abstract Interpretation", "MILP Solvers", "Verification of Neural Networks"], "authorids": ["gsingh@inf.ethz.ch", "timon.gehr@inf.ethz.ch", "pueschel@inf.ethz.ch", "martin.vechev@inf.ethz.ch"], "authors": ["Gagandeep Singh", "Timon Gehr", "Markus P\u00fcschel", "Martin Vechev"], "TL;DR": "We refine the over-approximation results from incomplete verifiers using MILP solvers to prove more robustness properties than state-of-the-art. ", "pdf": "/pdf/5d0d223bd447482b1dfe80a9cb59319ba679acf6.pdf", "paperhash": "singh|boosting_robustness_certification_of_neural_networks", "_bibtex": "@inproceedings{\nsingh2018robustness,\ntitle={Robustness Certification with Refinement},\nauthor={Gagandeep Singh and Timon Gehr and Markus P\u00fcschel and Martin Vechev},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJgeEh09KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1421/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626375, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJgeEh09KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1421/Authors", "ICLR.cc/2019/Conference/Paper1421/Reviewers", "ICLR.cc/2019/Conference/Paper1421/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1421/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1421/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1421/Authors|ICLR.cc/2019/Conference/Paper1421/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1421/Reviewers", "ICLR.cc/2019/Conference/Paper1421/Authors", "ICLR.cc/2019/Conference/Paper1421/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626375}}}, {"id": "B1xk_jXURm", "original": null, "number": 4, "cdate": 1543023463279, "ddate": null, "tcdate": 1543023463279, "tmdate": 1543023463279, "tddate": null, "forum": "HJgeEh09KQ", "replyto": "BJeGXqR9h7", "invitation": "ICLR.cc/2019/Conference/-/Paper1421/Official_Comment", "content": {"title": "Response to main questions", "comment": "\nQ1. Is MILP-based refinement applicable only for the first few layers of the network?\n\nR1. Generally, such refinement is most effective in the initial layers: as the analysis proceeds deeper into the network, it becomes harder for the MILP solver to refine the bounds within the specified time limit of 1 second. This is due to the increase in the number of integer variables caused by the increase in the number of unstable units (as explained in the general section on unstable ReLU). \n\nQ2. Why is l6 = 0? I think that it is easy to figure out that max(0,x4) is at least 0.\n\nR2. We assume you mean l6=-0.5. The negative lower bound for x6 = ReLU(x4) is due to the Zonotope ReLU transformer shown in Figure 2 which permits negative values for the output. \n\nQ3. I couldn't understand your sentence \"Note that the encoding ...\". Explaining a bit more about how bounds computed in previous layers are used will be helpful.\n\nR3. We mean that both the set of constraints added by the LP encoding (Ehlers (2017)) and the Zonotope transformer (Figure 2) for approximating ReLU behaviour depends on the neuron bounds from the previous layers. The degree of imprecision introduced by these approximations can be reduced by propagating tighter bounds through the network.  We will clarify this.\n\nQ4. Do you mean that your algorithm looks into the future layers of each neuron xi and adds the weights of edges in all the reachable paths from xi?\n\nR4. Yes. We consider all outgoing edges from xi and add the absolute values of the corresponding weights.\n\nQ5. Why did you reduce epsilon from 0.07 to 0.02, 0.015 and 0.015?\n\nR5. The 5x100 network is trained using adversarial training and is thus more robust than the other networks which were not obtained through adversarial training. Thus, we chose a higher epsilon for it compared to the other networks (please see the comment in the general section on unstable ReLU)."}, "signatures": ["ICLR.cc/2019/Conference/Paper1421/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1421/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1421/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Boosting Robustness Certification of Neural Networks", "abstract": "We present a novel approach for the certification of neural networks against adversarial perturbations which combines scalable overapproximation methods with precise (mixed integer) linear programming. This results in significantly better precision than state-of-the-art verifiers on challenging feedforward and convolutional neural networks with piecewise linear activation functions.", "keywords": ["Robustness certification", "Adversarial Attacks", "Abstract Interpretation", "MILP Solvers", "Verification of Neural Networks"], "authorids": ["gsingh@inf.ethz.ch", "timon.gehr@inf.ethz.ch", "pueschel@inf.ethz.ch", "martin.vechev@inf.ethz.ch"], "authors": ["Gagandeep Singh", "Timon Gehr", "Markus P\u00fcschel", "Martin Vechev"], "TL;DR": "We refine the over-approximation results from incomplete verifiers using MILP solvers to prove more robustness properties than state-of-the-art. ", "pdf": "/pdf/5d0d223bd447482b1dfe80a9cb59319ba679acf6.pdf", "paperhash": "singh|boosting_robustness_certification_of_neural_networks", "_bibtex": "@inproceedings{\nsingh2018robustness,\ntitle={Robustness Certification with Refinement},\nauthor={Gagandeep Singh and Timon Gehr and Markus P\u00fcschel and Martin Vechev},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJgeEh09KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1421/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626375, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJgeEh09KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1421/Authors", "ICLR.cc/2019/Conference/Paper1421/Reviewers", "ICLR.cc/2019/Conference/Paper1421/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1421/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1421/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1421/Authors|ICLR.cc/2019/Conference/Paper1421/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1421/Reviewers", "ICLR.cc/2019/Conference/Paper1421/Authors", "ICLR.cc/2019/Conference/Paper1421/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626375}}}, {"id": "B1eV9q7URm", "original": null, "number": 3, "cdate": 1543023244494, "ddate": null, "tcdate": 1543023244494, "tmdate": 1543023244494, "tddate": null, "forum": "HJgeEh09KQ", "replyto": "H1ep3mjh2Q", "invitation": "ICLR.cc/2019/Conference/-/Paper1421/Official_Comment", "content": {"title": "Response to main questions", "comment": "\nQ1. The verified robustness percentage of Tjeng & Tedrake is reported but the robustness bound is not.\n\nR1. The epsilon considered for this experiment is reported (page 7) and it is 0.03. \n  \nQ2. Can RefineAI handle only piecewise linear activation functions? How about other activations such as sigmoid? If so, what modifications are needed?\n\nR2. RefineAI provides better approximations for ReLU because it uses tighter bounds returned by MILP/LP solvers. Similarly, we can refine DeepZ approximations for sigmoid (which already exist) by using better bounds from a tighter approximation, e.g., quadratic approximation.\n\nQ3. How is the verification problem affected by considering the untargeted attack as in this paper vs. the targeted attack in Weng et al (2018) and Tjeng & Tedrake (2017)?\n\nR3. Since the targeted attack is weaker, the complete verifier from Tjeng and Tedrake runs faster and the incomplete verifier from Weng et al. proves more properties in their respective evaluation than it would if they considered untargeted attacks as considered in this paper.\n\nQ4. How tight are the output bounds improved by the neuron selection heuristics? \n\nR4. We observed that the width of the interval for the correctly classified label is up to 37% smaller with our neuron selection heuristic.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1421/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1421/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1421/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Boosting Robustness Certification of Neural Networks", "abstract": "We present a novel approach for the certification of neural networks against adversarial perturbations which combines scalable overapproximation methods with precise (mixed integer) linear programming. This results in significantly better precision than state-of-the-art verifiers on challenging feedforward and convolutional neural networks with piecewise linear activation functions.", "keywords": ["Robustness certification", "Adversarial Attacks", "Abstract Interpretation", "MILP Solvers", "Verification of Neural Networks"], "authorids": ["gsingh@inf.ethz.ch", "timon.gehr@inf.ethz.ch", "pueschel@inf.ethz.ch", "martin.vechev@inf.ethz.ch"], "authors": ["Gagandeep Singh", "Timon Gehr", "Markus P\u00fcschel", "Martin Vechev"], "TL;DR": "We refine the over-approximation results from incomplete verifiers using MILP solvers to prove more robustness properties than state-of-the-art. ", "pdf": "/pdf/5d0d223bd447482b1dfe80a9cb59319ba679acf6.pdf", "paperhash": "singh|boosting_robustness_certification_of_neural_networks", "_bibtex": "@inproceedings{\nsingh2018robustness,\ntitle={Robustness Certification with Refinement},\nauthor={Gagandeep Singh and Timon Gehr and Markus P\u00fcschel and Martin Vechev},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJgeEh09KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1421/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626375, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJgeEh09KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1421/Authors", "ICLR.cc/2019/Conference/Paper1421/Reviewers", "ICLR.cc/2019/Conference/Paper1421/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1421/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1421/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1421/Authors|ICLR.cc/2019/Conference/Paper1421/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1421/Reviewers", "ICLR.cc/2019/Conference/Paper1421/Authors", "ICLR.cc/2019/Conference/Paper1421/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626375}}}, {"id": "HyxBSKmURQ", "original": null, "number": 2, "cdate": 1543022908940, "ddate": null, "tcdate": 1543022908940, "tmdate": 1543023042370, "tddate": null, "forum": "HJgeEh09KQ", "replyto": "HJgeEh09KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1421/Official_Comment", "content": {"title": "Answers to key questions", "comment": "\nWe thank the reviewers for their feedback.\n\nBelow is a summary of key points, followed by further elaboration on each point. We also provide individual replies to each reviewer.\n\nSummary points [short]\n\n1. RefineAI is more precise than state-of-the-art incomplete verifiers.\n2. RefineAI is more scalable than existing state-of-the-art complete verifiers, including the latest: https://openreview.net/forum?id=HyGIdiRqtm based on Tjeng & Tedrake.\n3. RefineAI is applicable to much larger networks than shown in the paper.\n4. Effectiveness of verification methods for neural networks is primarily affected by the number of unstable ReLU units, *not* by the number of neurons.\n5. DeepZ [1], the domain used in our paper, is publicly available [3].\n\nWe are happy to provide further results or explanations if requested.\n\nSummary points [longer]\n\n\u2192 RefineAI is more precise than all state-of-the-art incomplete verifiers.\n\nThis is because DeepZ has the same precision as Weng et. al (2018) and Kolter and Wong (2018) while being faster (unlike RefineAI, Weng et al. cannot handle convolutional nets). Then, based on DeepZ results, Refine AI computes more precise results.\n\n\u2192 RefineAI is more scalable than all state-of-the-art complete verifiers, including the latest: https://openreview.net/forum?id=HyGIdiRqtm, based on Tjeng & Tedrake.\n\nThis is because the above method uses Box to compute initial bounds and uses more expensive methods if required. Unfortunately, in deeper layers, Box analysis becomes too imprecise and does not help. As a result, the above approach primarily relies on LP to obtain tight bounds for formulating a MILP instance for the whole network. Determining bounds with LP for all neurons in the larger networks is prohibitive. For example, on the 9x200 network from our paper, determining bounds with LP for all neurons already takes > 20 minutes (without calling the MILP solver which is more expensive than LP) whereas DeepZ computes significantly more precise bounds than Box for deeper layers in few seconds. \n\nThis gives us considerably fewer candidates to refine using LP/MILP than the Box analysis provides. Note that Tjeng & Tedrake (2017) is in turn significantly faster than Reluplex.\n\n\u2192 RefineAI is applicable to much larger networks than shown in the paper.\n\nWe evaluated RefineAI on larger publicly available networks from [3]: three MNIST convolutional networks containing 3,604 (Conv1), 4,804 (Conv2), 34,688 (Conv3) neurons and one skip net containing 71,650 neurons. We also tried a CIFAR10 convolutional network with 4,852 neurons. As in the paper, we considered epsilon values for which the precision of DeepZ drops significantly. The performance numbers below show RefineAI scales to larger networks (DiffAI is a particular defense [2]):\n\n          Dataset            Network       Epsilon     Adversarial training            Avg. runtime(s)\n                                                                                                                       DeepZ       RefineAI\n          MNIST\t            Conv1              0.1            None                                  1.1            357 \n                                    Conv2              0.2            DiffAI                                  6.8           602\n                                    Conv3              0.2            DiffAI                                     7          1011               \n                                    Skipnet          0.13            DiffAI                                 163           682\n          CIFAR10           Conv            0.012            DiffAI                                  3.9           262\n\n\u2192 The effectiveness of a verification method for neural networks is primarily affected by the number of unstable ReLU units, *not* by the number of neurons.\n\nThis is because the speed of a complete verifier and the precision of an incomplete verifier are affected mainly by unstable ReLU units: those which can take both + and - values. Indeed, the speed of the MILP solver used in both RefineAI and the method based on Tjeng & Tedrake (2017) is adversely affected by the presolve approximations for such unstable units. \n\nThis explains why defending a network (e.g., via DiffAI) will make any verifier scale better (including RefineAI): because defended networks have much fewer unstable units than undefended networks.\n\n[1] Fast and Effective Robustness Certification, NIPS\u201918\n[2] Differentiable Abstract Interpretation for Provably Robust Neural Networks, ICML\u201918.\n[3] DeepZ analysis: https://github.com/eth-sri/eran. "}, "signatures": ["ICLR.cc/2019/Conference/Paper1421/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1421/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1421/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Boosting Robustness Certification of Neural Networks", "abstract": "We present a novel approach for the certification of neural networks against adversarial perturbations which combines scalable overapproximation methods with precise (mixed integer) linear programming. This results in significantly better precision than state-of-the-art verifiers on challenging feedforward and convolutional neural networks with piecewise linear activation functions.", "keywords": ["Robustness certification", "Adversarial Attacks", "Abstract Interpretation", "MILP Solvers", "Verification of Neural Networks"], "authorids": ["gsingh@inf.ethz.ch", "timon.gehr@inf.ethz.ch", "pueschel@inf.ethz.ch", "martin.vechev@inf.ethz.ch"], "authors": ["Gagandeep Singh", "Timon Gehr", "Markus P\u00fcschel", "Martin Vechev"], "TL;DR": "We refine the over-approximation results from incomplete verifiers using MILP solvers to prove more robustness properties than state-of-the-art. ", "pdf": "/pdf/5d0d223bd447482b1dfe80a9cb59319ba679acf6.pdf", "paperhash": "singh|boosting_robustness_certification_of_neural_networks", "_bibtex": "@inproceedings{\nsingh2018robustness,\ntitle={Robustness Certification with Refinement},\nauthor={Gagandeep Singh and Timon Gehr and Markus P\u00fcschel and Martin Vechev},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJgeEh09KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1421/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621626375, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJgeEh09KQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1421/Authors", "ICLR.cc/2019/Conference/Paper1421/Reviewers", "ICLR.cc/2019/Conference/Paper1421/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1421/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1421/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1421/Authors|ICLR.cc/2019/Conference/Paper1421/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1421/Reviewers", "ICLR.cc/2019/Conference/Paper1421/Authors", "ICLR.cc/2019/Conference/Paper1421/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621626375}}}, {"id": "S1xULFL9n7", "original": null, "number": 1, "cdate": 1541200206384, "ddate": null, "tcdate": 1541200206384, "tmdate": 1542478671312, "tddate": null, "forum": "HJgeEh09KQ", "replyto": "HJgeEh09KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1421/Official_Review", "content": {"title": "a refined approach for robust verification, but experimental part could be stronger", "review": "This paper introduces a verifier that obtains improvement on both the precision of the incomplete verifiers and the scalability of the complete verifiers. The proposed approaches combines over-parameterization, mixed integer linear programming, and linear programming relaxation. \n\nThis paper is well written and well organized. I like the simple example exposed in section 2, which is a friendly start. However, I begun to lose track after that. As far as I can understand, the next section listed several techniques to be deployed. But I failed to see enough justification or reasoning why these techniques are important. My background is more theoretical, but I'm looking for theorems here, considering the complicatedness of neural network. All I am looking for is probably some high level explanation.\n\nEmpirically, the proposed approach is more robust while time consuming that the AI2 algorithm. However, the contribution and the importance of this paper still seems incremental to me.  I probably have grumbled too much about the lack of reasonings. As this paper is purely empirical, which is totally fine and could be valuable and influential as well.  In that case, I found the current experiment unsatisfying and would love to see more extensive experimental results. \n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1421/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Boosting Robustness Certification of Neural Networks", "abstract": "We present a novel approach for the certification of neural networks against adversarial perturbations which combines scalable overapproximation methods with precise (mixed integer) linear programming. This results in significantly better precision than state-of-the-art verifiers on challenging feedforward and convolutional neural networks with piecewise linear activation functions.", "keywords": ["Robustness certification", "Adversarial Attacks", "Abstract Interpretation", "MILP Solvers", "Verification of Neural Networks"], "authorids": ["gsingh@inf.ethz.ch", "timon.gehr@inf.ethz.ch", "pueschel@inf.ethz.ch", "martin.vechev@inf.ethz.ch"], "authors": ["Gagandeep Singh", "Timon Gehr", "Markus P\u00fcschel", "Martin Vechev"], "TL;DR": "We refine the over-approximation results from incomplete verifiers using MILP solvers to prove more robustness properties than state-of-the-art. ", "pdf": "/pdf/5d0d223bd447482b1dfe80a9cb59319ba679acf6.pdf", "paperhash": "singh|boosting_robustness_certification_of_neural_networks", "_bibtex": "@inproceedings{\nsingh2018robustness,\ntitle={Robustness Certification with Refinement},\nauthor={Gagandeep Singh and Timon Gehr and Markus P\u00fcschel and Martin Vechev},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJgeEh09KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1421/Official_Review", "cdate": 1542234233327, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJgeEh09KQ", "replyto": "HJgeEh09KQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1421/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335943353, "tmdate": 1552335943353, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1421/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "H1ep3mjh2Q", "original": null, "number": 3, "cdate": 1541350325512, "ddate": null, "tcdate": 1541350325512, "tmdate": 1541533147143, "tddate": null, "forum": "HJgeEh09KQ", "replyto": "HJgeEh09KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1421/Official_Review", "content": {"title": "Interesting ideas but not persuasive enough", "review": "This paper proposed a mixed strategy to obtain better precision on robustness verifications of feed-forward neural networks with piecewise linear activation functions.\n\nThe topic of robustness verification is important. The paper is well-written and the overview example is nice and helpful. \n\nThe central idea of this paper is simple and the results can be expected: the authors combine several verification methods (the complete verifier MILP, the incomplete verifier LP and AI2) and thus achieve better precision compared with imcomplete verifiers while being more scalable than the complete verifiers. However, the verified networks are fairly small (1800 neurons) and it is not clear how good the performance is compared to other state-of-the-art complete/incomplete verifiers. \n\nAbout experiments questions:\n1. The experiments compare verified robustness with AI2 and show that RefineAI can verify more than AI2 at the expense of much more computation time (Figure 3). However, the problem here is how is RefineAI or AI2 compare with other complete and incomplete verifiers as described in  the second paragraph of introduction? The AI2 does not seem to have public available codes that readers can try out but for some complete and incomplete verifiers papers mentioned in the introductions,  I do find some public codes available:\n* complete verifiers\n1. Tjeng & Tedrake (2017): github.com/vtjeng/MIPVerify.jl\n2. SMT Katz etal (2017): https://github.com/guykatzz/ReluplexCav2017\n\n* incomplete verifiers\n3. Weng etal (2018) : https://github.com/huanzhang12/CertifiedReLURobustness\n4. Wong & Kolter (2018): http://github.com/locuslab/convex_adversarial\n\nHow does Refine AI proposed in this paper compare with the above four papers in terms of the verified robustness percentage on test set, the robustness bound (the epsilon in the paragraph Abstract Interpretation p.4) and the run time? The verified robustness percentage of Tjeng & Tedrake is reported but the robustness bound is not reported.  Also, can Refine AI scale to other datasets?\n\nAbout other questions:\n1. Can RefineAI handle only piece-wise linear activation functions? How about other activation functions, such as sigmoid? If so, what are the modifications to be made to handle other non-piece-wise linear activation functions? \n\n2. In Sec 4, the Robustness properties paragraph. \"The adversarial attack considered here is untargeted and therefore stronger than ...\". The approaches in Weng etal (2018) and Tjeng & Tedrake (2017) seem to be able to handle the untargeted robustness as well? \n\n3. In Sec 4, the Effect of neural selection heuristic paragraph. \"Although the number of images verified change by only 3 %... produces tighter output bounds...\". How tight the output bounds improved by the neuron selection heuristics? \n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1421/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Boosting Robustness Certification of Neural Networks", "abstract": "We present a novel approach for the certification of neural networks against adversarial perturbations which combines scalable overapproximation methods with precise (mixed integer) linear programming. This results in significantly better precision than state-of-the-art verifiers on challenging feedforward and convolutional neural networks with piecewise linear activation functions.", "keywords": ["Robustness certification", "Adversarial Attacks", "Abstract Interpretation", "MILP Solvers", "Verification of Neural Networks"], "authorids": ["gsingh@inf.ethz.ch", "timon.gehr@inf.ethz.ch", "pueschel@inf.ethz.ch", "martin.vechev@inf.ethz.ch"], "authors": ["Gagandeep Singh", "Timon Gehr", "Markus P\u00fcschel", "Martin Vechev"], "TL;DR": "We refine the over-approximation results from incomplete verifiers using MILP solvers to prove more robustness properties than state-of-the-art. ", "pdf": "/pdf/5d0d223bd447482b1dfe80a9cb59319ba679acf6.pdf", "paperhash": "singh|boosting_robustness_certification_of_neural_networks", "_bibtex": "@inproceedings{\nsingh2018robustness,\ntitle={Robustness Certification with Refinement},\nauthor={Gagandeep Singh and Timon Gehr and Markus P\u00fcschel and Martin Vechev},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJgeEh09KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1421/Official_Review", "cdate": 1542234233327, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJgeEh09KQ", "replyto": "HJgeEh09KQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1421/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335943353, "tmdate": 1552335943353, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1421/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "BJeGXqR9h7", "original": null, "number": 2, "cdate": 1541233178325, "ddate": null, "tcdate": 1541233178325, "tmdate": 1541533146935, "tddate": null, "forum": "HJgeEh09KQ", "replyto": "HJgeEh09KQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1421/Official_Review", "content": {"title": "Interesting idea but not fully evaluated", "review": "In the paper, the authors provide a new approach for verifying the robustness of deep neural networks that combines complete yet expensive methods based on mixed integer-linear programming (MILP) and incomplete yet cheap methods based on abstract interpretation or linear-programming relaxation. Roughly speaking, the approach is to run an abstract interpreter but to refine its results at early layers of a neural network using mixed integer-linear programming and some of later layers using linear programming. The unrefined results of the abstract interpreter help these refinement steps. They help prioritize or prune the refinement of the abstract-interpretation results at neurons at a layer. Using neural networks with 3, 5, 6, 9 layers and the MNIST dataset, the authors compared their approach with AI^2, which uses only abstract interpretation. This experimental comparison shows that the approach can prove the robustness of more examples for all of these networks.\n\nI found the authors' way of combining complete techniques and incomplete techniques novel and interesting. They apply complete techniques in a prioritized manner, so that those techniques do not incur big performance penalties. However, I feel that more experimental justifications are needed. The approach in the paper applies MILP to the first few layers of a given network, without any further simplification or abstraction of the network. One possible implication of this is that this MILP-based refinement is applicable only for the first few layers of the network. Of course, prioritization and timeout of the authors help, but I am not sure that this is enough. Also, I think that more datasets and networks should be tried. The experiments in the paper with different networks for MNIST show the promise, but I feel that they are not enough.\n\n* p3: Why is l6 = 0? I think that it is easy to figure out that max(0,x4) is at least 0.\n\n* p4: [li,yi] for ===> [li,ui] \n\n* p4: gamma_n(T^#_(x|->Ax+b)) ===> gamma_n(T^#_(x|->Ax+b)(a))\n\n* p4: subseteq T^#...  ===> subseteq gamma_n(T^#...)\n\n* p5: phi^(k)(x^(0)_1,...,x^(k-1)_p) ===> phi^(k)(x^(0)_1,...,x^k_p) \n\n* p6: I couldn't understand your sentence \"Note that the encoding ...\". Explaining a bit more about how bounds computed in previous layers are used will be helpful.\n\n* p6: I find your explanation on the way to compute the second ranking with weights confusing. Do you mean that your algorithm looks into the future layers of each neuron xi and adds the weights of edges in all the reachable paths from xi?\n\n* p7: Why did you reduce epsilon from 0.07 to 0.02, 0.15 and 0.017?\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1421/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Boosting Robustness Certification of Neural Networks", "abstract": "We present a novel approach for the certification of neural networks against adversarial perturbations which combines scalable overapproximation methods with precise (mixed integer) linear programming. This results in significantly better precision than state-of-the-art verifiers on challenging feedforward and convolutional neural networks with piecewise linear activation functions.", "keywords": ["Robustness certification", "Adversarial Attacks", "Abstract Interpretation", "MILP Solvers", "Verification of Neural Networks"], "authorids": ["gsingh@inf.ethz.ch", "timon.gehr@inf.ethz.ch", "pueschel@inf.ethz.ch", "martin.vechev@inf.ethz.ch"], "authors": ["Gagandeep Singh", "Timon Gehr", "Markus P\u00fcschel", "Martin Vechev"], "TL;DR": "We refine the over-approximation results from incomplete verifiers using MILP solvers to prove more robustness properties than state-of-the-art. ", "pdf": "/pdf/5d0d223bd447482b1dfe80a9cb59319ba679acf6.pdf", "paperhash": "singh|boosting_robustness_certification_of_neural_networks", "_bibtex": "@inproceedings{\nsingh2018robustness,\ntitle={Robustness Certification with Refinement},\nauthor={Gagandeep Singh and Timon Gehr and Markus P\u00fcschel and Martin Vechev},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJgeEh09KQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1421/Official_Review", "cdate": 1542234233327, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJgeEh09KQ", "replyto": "HJgeEh09KQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1421/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335943353, "tmdate": 1552335943353, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1421/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 9}