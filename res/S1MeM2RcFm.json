{"notes": [{"id": "S1MeM2RcFm", "original": "rJxHiidqF7", "number": 1234, "cdate": 1538087944181, "ddate": null, "tcdate": 1538087944181, "tmdate": 1545355436154, "tddate": null, "forum": "S1MeM2RcFm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "BlackMarks: Black-box Multi-bit Watermarking for Deep Neural Networks", "abstract": "Deep Neural Networks (DNNs) are increasingly deployed in cloud servers and autonomous agents due to their superior performance. The deployed DNN is either leveraged in a white-box setting (model internals are publicly known) or a black-box setting (only model outputs are known) depending on the application. A practical concern in the rush to adopt DNNs is protecting the models against Intellectual Property (IP) infringement. We propose BlackMarks, the first end-to-end multi-bit watermarking framework that is applicable in the black-box scenario. BlackMarks takes the pre-trained unmarked model and the owner\u2019s binary signature as inputs. The output is the corresponding marked model with specific keys that can be later used to trigger the embedded watermark. To do so, BlackMarks first designs a model-dependent encoding scheme that maps all possible classes in the task to bit \u20180\u2019 and bit \u20181\u2019. Given the owner\u2019s watermark signature (a binary string), a set of key image and label pairs is designed using targeted adversarial attacks. The watermark (WM) is then encoded in the distribution of output activations of the DNN by fine-tuning the model with a WM-specific regularized loss. To extract the WM, BlackMarks queries the model with the WM key images and decodes the owner\u2019s signature from the corresponding predictions using the designed encoding scheme. We perform a comprehensive evaluation of BlackMarks\u2019 performance on MNIST, CIFAR-10, ImageNet datasets and corroborate its effectiveness and robustness. BlackMarks preserves the functionality of the original DNN and incurs negligible WM embedding overhead as low as 2.054%.", "keywords": ["Digital Watermarking", "IP Protection", "Deep Neural Networks"], "authorids": ["huc044@ucsd.edu", "bita@ucsd.edu", "farinaz@ucsd.edu"], "authors": ["Huili Chen", "Bita Darvish Rouhani", "Farinaz Koushanfar"], "TL;DR": "Proposing the first watermarking framework for multi-bit signature embedding and extraction using the outputs of the DNN. ", "pdf": "/pdf/c4b4f13d0cba7ac0db7e3239ce7f1b794a1131a6.pdf", "paperhash": "chen|blackmarks_blackbox_multibit_watermarking_for_deep_neural_networks", "_bibtex": "@misc{\nchen2019blackmarks,\ntitle={BlackMarks: Black-box Multi-bit Watermarking for Deep Neural Networks},\nauthor={Huili Chen and Bita Darvish Rouhani and Farinaz Koushanfar},\nyear={2019},\nurl={https://openreview.net/forum?id=S1MeM2RcFm},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "rJxGDucSlV", "original": null, "number": 1, "cdate": 1545082970232, "ddate": null, "tcdate": 1545082970232, "tmdate": 1545354480788, "tddate": null, "forum": "S1MeM2RcFm", "replyto": "S1MeM2RcFm", "invitation": "ICLR.cc/2019/Conference/-/Paper1234/Meta_Review", "content": {"metareview": "The reviews agree the paper is not ready for publication at ICLR. ", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Reject", "title": "reject"}, "signatures": ["ICLR.cc/2019/Conference/Paper1234/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1234/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BlackMarks: Black-box Multi-bit Watermarking for Deep Neural Networks", "abstract": "Deep Neural Networks (DNNs) are increasingly deployed in cloud servers and autonomous agents due to their superior performance. The deployed DNN is either leveraged in a white-box setting (model internals are publicly known) or a black-box setting (only model outputs are known) depending on the application. A practical concern in the rush to adopt DNNs is protecting the models against Intellectual Property (IP) infringement. We propose BlackMarks, the first end-to-end multi-bit watermarking framework that is applicable in the black-box scenario. BlackMarks takes the pre-trained unmarked model and the owner\u2019s binary signature as inputs. The output is the corresponding marked model with specific keys that can be later used to trigger the embedded watermark. To do so, BlackMarks first designs a model-dependent encoding scheme that maps all possible classes in the task to bit \u20180\u2019 and bit \u20181\u2019. Given the owner\u2019s watermark signature (a binary string), a set of key image and label pairs is designed using targeted adversarial attacks. The watermark (WM) is then encoded in the distribution of output activations of the DNN by fine-tuning the model with a WM-specific regularized loss. To extract the WM, BlackMarks queries the model with the WM key images and decodes the owner\u2019s signature from the corresponding predictions using the designed encoding scheme. We perform a comprehensive evaluation of BlackMarks\u2019 performance on MNIST, CIFAR-10, ImageNet datasets and corroborate its effectiveness and robustness. BlackMarks preserves the functionality of the original DNN and incurs negligible WM embedding overhead as low as 2.054%.", "keywords": ["Digital Watermarking", "IP Protection", "Deep Neural Networks"], "authorids": ["huc044@ucsd.edu", "bita@ucsd.edu", "farinaz@ucsd.edu"], "authors": ["Huili Chen", "Bita Darvish Rouhani", "Farinaz Koushanfar"], "TL;DR": "Proposing the first watermarking framework for multi-bit signature embedding and extraction using the outputs of the DNN. ", "pdf": "/pdf/c4b4f13d0cba7ac0db7e3239ce7f1b794a1131a6.pdf", "paperhash": "chen|blackmarks_blackbox_multibit_watermarking_for_deep_neural_networks", "_bibtex": "@misc{\nchen2019blackmarks,\ntitle={BlackMarks: Black-box Multi-bit Watermarking for Deep Neural Networks},\nauthor={Huili Chen and Bita Darvish Rouhani and Farinaz Koushanfar},\nyear={2019},\nurl={https://openreview.net/forum?id=S1MeM2RcFm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1234/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352913942, "tddate": null, "super": null, "final": null, "reply": {"forum": "S1MeM2RcFm", "replyto": "S1MeM2RcFm", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1234/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1234/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1234/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352913942}}}, {"id": "BJg3dt1yTX", "original": null, "number": 3, "cdate": 1541499251594, "ddate": null, "tcdate": 1541499251594, "tmdate": 1541533307649, "tddate": null, "forum": "S1MeM2RcFm", "replyto": "S1MeM2RcFm", "invitation": "ICLR.cc/2019/Conference/-/Paper1234/Official_Review", "content": {"title": "Review", "review": "A method for multi-bit watermarking of neural networks in a black-box setting is proposed. In particular, the authors demonstrate that the predictions of existing models can carry a multi-bit string that can later be used to verify ownership.\nExperiments on MNIST, CIFAR-10 and ImageNet are presented in addition to a robustness assessment w.r.t. different WM removal attacks.\n\nQuestions/Comments:\n\nRegarding the encoding scheme, a question that came up is whether one needs to perform clustering on the last layer before the softmax? In principle, this could be done at any point, right?\n\nAnother question is how the method scales with the key length. Did you experiment with large/small values of K (e.g., 100,200,...)? It would be interesting, e.g., to see a plot that shows key length vs. accuracy of the marked model, or, key\nlength vs. detection success (or BER).\n\nApart from these comments, how does the proposed model compare to zero-bit WM schemes? I am missing a clear comparison to other, related work, as part of the experiments. While there might not exist other \"black-box multi-bit\"\nschemes in the literature, one could still compare against non-multi-bit schemes. \n\nIn light of a missing comparison, my assessment is \"Marginally below acceptance threshold\", but I am willing to vote\nthis up, given an appropriate response.\n\n\n\n\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1234/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BlackMarks: Black-box Multi-bit Watermarking for Deep Neural Networks", "abstract": "Deep Neural Networks (DNNs) are increasingly deployed in cloud servers and autonomous agents due to their superior performance. The deployed DNN is either leveraged in a white-box setting (model internals are publicly known) or a black-box setting (only model outputs are known) depending on the application. A practical concern in the rush to adopt DNNs is protecting the models against Intellectual Property (IP) infringement. We propose BlackMarks, the first end-to-end multi-bit watermarking framework that is applicable in the black-box scenario. BlackMarks takes the pre-trained unmarked model and the owner\u2019s binary signature as inputs. The output is the corresponding marked model with specific keys that can be later used to trigger the embedded watermark. To do so, BlackMarks first designs a model-dependent encoding scheme that maps all possible classes in the task to bit \u20180\u2019 and bit \u20181\u2019. Given the owner\u2019s watermark signature (a binary string), a set of key image and label pairs is designed using targeted adversarial attacks. The watermark (WM) is then encoded in the distribution of output activations of the DNN by fine-tuning the model with a WM-specific regularized loss. To extract the WM, BlackMarks queries the model with the WM key images and decodes the owner\u2019s signature from the corresponding predictions using the designed encoding scheme. We perform a comprehensive evaluation of BlackMarks\u2019 performance on MNIST, CIFAR-10, ImageNet datasets and corroborate its effectiveness and robustness. BlackMarks preserves the functionality of the original DNN and incurs negligible WM embedding overhead as low as 2.054%.", "keywords": ["Digital Watermarking", "IP Protection", "Deep Neural Networks"], "authorids": ["huc044@ucsd.edu", "bita@ucsd.edu", "farinaz@ucsd.edu"], "authors": ["Huili Chen", "Bita Darvish Rouhani", "Farinaz Koushanfar"], "TL;DR": "Proposing the first watermarking framework for multi-bit signature embedding and extraction using the outputs of the DNN. ", "pdf": "/pdf/c4b4f13d0cba7ac0db7e3239ce7f1b794a1131a6.pdf", "paperhash": "chen|blackmarks_blackbox_multibit_watermarking_for_deep_neural_networks", "_bibtex": "@misc{\nchen2019blackmarks,\ntitle={BlackMarks: Black-box Multi-bit Watermarking for Deep Neural Networks},\nauthor={Huili Chen and Bita Darvish Rouhani and Farinaz Koushanfar},\nyear={2019},\nurl={https://openreview.net/forum?id=S1MeM2RcFm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1234/Official_Review", "cdate": 1542234274670, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1MeM2RcFm", "replyto": "S1MeM2RcFm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1234/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335902317, "tmdate": 1552335902317, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1234/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "ryxrFSh62m", "original": null, "number": 2, "cdate": 1541420413428, "ddate": null, "tcdate": 1541420413428, "tmdate": 1541533307442, "tddate": null, "forum": "S1MeM2RcFm", "replyto": "S1MeM2RcFm", "invitation": "ICLR.cc/2019/Conference/-/Paper1234/Official_Review", "content": {"title": "Some interesting ideas, but a better evaluation is needed to show the effectiveness of the method", "review": "summary:\n\nThe paper proposes an approach for model watermarking (i.e., watermarking a trained neural neteowrk). The watermark is a bit string, which is embedded in the model as part of a fine-tuning procedure, and can be decoded from the network from the model's specific predictions for a specific set of inputs (called keys) chosen during the fine-tuning step. The process generates a watermark when we can be confident that a model that didn't go through the exact same fine-tuning procedure gives significantly different predictions on the set of keys. The application scenario is when a company A wants to deploy a model for which A has IP ownership, and A wants to assess whether a competitor is (illegaly) re-using A's model. The approach presented in the paper works in the black-box setting, meaning that whether a model posesses the watermark can be assessed only by querying the model (i.e., without access to the internals of the model).\n\nThe overall approach closely follows Merrer et al. (2017), but extends this previous work to multi-bit watermarking. The similarity with Merrer et al. is that keys are generated with a procesdure to generate adversarial examples, watermarking is performed by specifically training the network to give the source label (i.e., the label of the image from which the adversarial example has been generated). The differences with Merrer et al. lie in the fact that each key encoded a specific bit (0 or 1), and the multi-bit watermark is encoded in the predictions for all keys (in case of a multi-class classifier, the labels are first partitionned into two clusters to map each class to either 0 or 1). In contrast, Merrer et al. focused on \"zero-bit\" watermarking, meaning that all keys together are only used to perform a test of whether the model has been watermarked (not encode the watermark). Another noticeable difference with Merrer et al. is in step 4 of the algorithm, in which several unmarked models are generated to select better key images.\n\ncomments:\n\nWhile overall the approach makes sense and most of the design decisions seem appropriate, many questions are only partly addressed. My main concerns are:\n1- the watermarks are encoded in adversarial examples for which the trained model gives the \"true\" label (i.e., the watermark is embedded in adversarial examples on which the model is robust). The evaluation does not address the concerns of false alarms on models trained to be robust to adversarial examples. Previous work (e.g., Merrer et al.) study at least the effect of fine-tuning with adversarial examples..\n\n2- A watermark of length K is encoded in K images, and the test for watermarking is \"The owner can prove the authorship of the model if the BER is zero.\". This leaves little room to model manipulation. For instance, the competitor could randomize its predictions once in a while (typically output a random label for one out of K inputs), with very small decrease in accuracy and yet would have a non-negligible probability of having a non-zero BER.\n\nother comments:\n1- overhead section: in step 4 of the algorithm, there is a mention of \"construct T unmarked models\": why aren't they considered in the overhead? This seems to be an extremely significant part of the cost (the overall cost seems to be more T times the cost of building a single unmarked model rather than a few percent)\n\n2- step 2 page 4: \"The intuition here is that we want to filter out the highly transferable WM keys\": I must have misunderstood something here. Why are highly transferable adversarial examples a problem? That would be the opposite: if we want the key to generate few false alarms (i.e., we do not want to claim ownership of a non-watermarked model), then we need the adversarial examples to \"transfer\" (i.e., be adversarial for non-watermarked models), since the watermarked model predicts the source class for the key. Merrer et al. (2017) on the contrary claim \" As such adversaries seem to generalize across models [...] , this frontier tweaking should resist model manipulation and yield only few false positives (wrong identification of non marked model).\", which means that transferability of adversarial examples is a fundamental assumption underlying the approach.\n\n3- under Eq. 1: \"Note that without the additional regularization loss (LWM), this retraining procedure resembles \u2018adversarial training\u2019 (Kurakin et al., 2016).\": I do not understand that sentence. Without L_{WM}, the loss is the usual classification loss (L_0), and has nothing to do with adversarial training.\n\n4- more generally, the contribution of the paper is on multi-bit watermarking, but there is no clear application scenario/experiment  where the multi-bit is more useful than the zero-bit watermarking.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1234/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BlackMarks: Black-box Multi-bit Watermarking for Deep Neural Networks", "abstract": "Deep Neural Networks (DNNs) are increasingly deployed in cloud servers and autonomous agents due to their superior performance. The deployed DNN is either leveraged in a white-box setting (model internals are publicly known) or a black-box setting (only model outputs are known) depending on the application. A practical concern in the rush to adopt DNNs is protecting the models against Intellectual Property (IP) infringement. We propose BlackMarks, the first end-to-end multi-bit watermarking framework that is applicable in the black-box scenario. BlackMarks takes the pre-trained unmarked model and the owner\u2019s binary signature as inputs. The output is the corresponding marked model with specific keys that can be later used to trigger the embedded watermark. To do so, BlackMarks first designs a model-dependent encoding scheme that maps all possible classes in the task to bit \u20180\u2019 and bit \u20181\u2019. Given the owner\u2019s watermark signature (a binary string), a set of key image and label pairs is designed using targeted adversarial attacks. The watermark (WM) is then encoded in the distribution of output activations of the DNN by fine-tuning the model with a WM-specific regularized loss. To extract the WM, BlackMarks queries the model with the WM key images and decodes the owner\u2019s signature from the corresponding predictions using the designed encoding scheme. We perform a comprehensive evaluation of BlackMarks\u2019 performance on MNIST, CIFAR-10, ImageNet datasets and corroborate its effectiveness and robustness. BlackMarks preserves the functionality of the original DNN and incurs negligible WM embedding overhead as low as 2.054%.", "keywords": ["Digital Watermarking", "IP Protection", "Deep Neural Networks"], "authorids": ["huc044@ucsd.edu", "bita@ucsd.edu", "farinaz@ucsd.edu"], "authors": ["Huili Chen", "Bita Darvish Rouhani", "Farinaz Koushanfar"], "TL;DR": "Proposing the first watermarking framework for multi-bit signature embedding and extraction using the outputs of the DNN. ", "pdf": "/pdf/c4b4f13d0cba7ac0db7e3239ce7f1b794a1131a6.pdf", "paperhash": "chen|blackmarks_blackbox_multibit_watermarking_for_deep_neural_networks", "_bibtex": "@misc{\nchen2019blackmarks,\ntitle={BlackMarks: Black-box Multi-bit Watermarking for Deep Neural Networks},\nauthor={Huili Chen and Bita Darvish Rouhani and Farinaz Koushanfar},\nyear={2019},\nurl={https://openreview.net/forum?id=S1MeM2RcFm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1234/Official_Review", "cdate": 1542234274670, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1MeM2RcFm", "replyto": "S1MeM2RcFm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1234/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335902317, "tmdate": 1552335902317, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1234/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "r1gtuXeYh7", "original": null, "number": 1, "cdate": 1541108592855, "ddate": null, "tcdate": 1541108592855, "tmdate": 1541533307193, "tddate": null, "forum": "S1MeM2RcFm", "replyto": "S1MeM2RcFm", "invitation": "ICLR.cc/2019/Conference/-/Paper1234/Official_Review", "content": {"title": "review", "review": "Strengths:\n\nWell written paper, covers most of the relevant related work\nTechnique is conceptually easy to understand (~ adversarial training)\n\nWeaknesses:\n\nUnclear set of desiderata properties for a watermarking technique\nNo formal guarantees are verified, the mechanism is only tested\nAttacks tested are not tailored to the technique proposed\n\nFeedback and rebuttal questions:\n\nThis submission is easy to read and follow, and motivates the problem of watermarking well in light of intellectual property concerns. The technique proposed exploits unused capacity in the model to train it to associate specific inputs (computed adversarially) to specific outputs (the keys). Watermarking succeeds when the bit error rate between the predicted signature and the expected one is zero. This approach is conceptually easy to understand. \n\nThe experimental setup used to evaluate the approach is however limited. First, it is unclear why desiderata stated in Section 3.1 and summarized in Table 1 are necessary and sufficient. Would you be able to justify their choice in your rebuttal? For instance, the \u201csecurity\u201d requirement in Table 1 overlaps with \u201cfidelity\u201d. Similarly, the property named \u201cintegrity\u201d really refers to only a subset of what one would typically describe as integrity. It basically calls for a low false positive or high precision. \n\nThe attack model described in Section 3.2 only considers three existing attacks: model fine-tuning, parameter pruning and watermark overwriting. These attacks do not consider how the adversary could adapt and they are not optimal strategies for attacking the specific defensive mechanism put in place here. For instance, could you explain in your rebuttal why pruning the smallest weights in the architecture in the final architecture would help with removing adversarial examples injected to watermark the model? Similarly, given that adversarial subspaces have large volumes, it makes sense that multiple watermarks could be inserted simultaneously and thus watermark overwriting attacks would fail.\n\nIf the approach is based on exploring unused capacity in the model, the adversary could in fact attempt to use a compression technique to preserve the model\u2019s behavior on the task and remove the watermarking logic. For instance, the adversary could use an unlabeled set of inputs and have them labeled by the watermarked model. Because these inputs will not be \u201cadversarial\u201d, the watermarked model\u2019s decision surface used to encode the signatures will remain unexplored during knowledge transfer and the resulted compressed or distilled model would solve the original task without being watermarked. Is this an attack you have considered in your experiments and if not could you elaborate why one may exclude it in your rebuttal?\n\nMinor comments: \n\nP3: Typo \u201cVerifiabiity\u201d\nP5: Could you add a reference or additional experimental results that justify why transferable keys would be located near the decision boundaries? \n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1234/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BlackMarks: Black-box Multi-bit Watermarking for Deep Neural Networks", "abstract": "Deep Neural Networks (DNNs) are increasingly deployed in cloud servers and autonomous agents due to their superior performance. The deployed DNN is either leveraged in a white-box setting (model internals are publicly known) or a black-box setting (only model outputs are known) depending on the application. A practical concern in the rush to adopt DNNs is protecting the models against Intellectual Property (IP) infringement. We propose BlackMarks, the first end-to-end multi-bit watermarking framework that is applicable in the black-box scenario. BlackMarks takes the pre-trained unmarked model and the owner\u2019s binary signature as inputs. The output is the corresponding marked model with specific keys that can be later used to trigger the embedded watermark. To do so, BlackMarks first designs a model-dependent encoding scheme that maps all possible classes in the task to bit \u20180\u2019 and bit \u20181\u2019. Given the owner\u2019s watermark signature (a binary string), a set of key image and label pairs is designed using targeted adversarial attacks. The watermark (WM) is then encoded in the distribution of output activations of the DNN by fine-tuning the model with a WM-specific regularized loss. To extract the WM, BlackMarks queries the model with the WM key images and decodes the owner\u2019s signature from the corresponding predictions using the designed encoding scheme. We perform a comprehensive evaluation of BlackMarks\u2019 performance on MNIST, CIFAR-10, ImageNet datasets and corroborate its effectiveness and robustness. BlackMarks preserves the functionality of the original DNN and incurs negligible WM embedding overhead as low as 2.054%.", "keywords": ["Digital Watermarking", "IP Protection", "Deep Neural Networks"], "authorids": ["huc044@ucsd.edu", "bita@ucsd.edu", "farinaz@ucsd.edu"], "authors": ["Huili Chen", "Bita Darvish Rouhani", "Farinaz Koushanfar"], "TL;DR": "Proposing the first watermarking framework for multi-bit signature embedding and extraction using the outputs of the DNN. ", "pdf": "/pdf/c4b4f13d0cba7ac0db7e3239ce7f1b794a1131a6.pdf", "paperhash": "chen|blackmarks_blackbox_multibit_watermarking_for_deep_neural_networks", "_bibtex": "@misc{\nchen2019blackmarks,\ntitle={BlackMarks: Black-box Multi-bit Watermarking for Deep Neural Networks},\nauthor={Huili Chen and Bita Darvish Rouhani and Farinaz Koushanfar},\nyear={2019},\nurl={https://openreview.net/forum?id=S1MeM2RcFm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1234/Official_Review", "cdate": 1542234274670, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "S1MeM2RcFm", "replyto": "S1MeM2RcFm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1234/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335902317, "tmdate": 1552335902317, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1234/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 5}