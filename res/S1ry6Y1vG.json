{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124441031, "tcdate": 1518472412658, "number": 323, "cdate": 1518472412658, "id": "S1ry6Y1vG", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "S1ry6Y1vG", "signatures": ["~Rosanne_Liu1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Faster Neural Networks Straight from JPEG", "abstract": "Training convolutional neural networks (CNNs) directly from RGB pixels hasenjoyed overwhelming empirical success. But can more performance be squeezedout of networks by using different input representations? In this paper we proposeand explore a simple idea: train CNNs directly on the blockwise discrete cosinetransform (DCT) coefficients computed and available in the middle of the JPEG codec. We modify libjpeg to produce DCT coefficients directly, modify a ResNet-50 network to accommodate the differently sized and strided input, andevaluate performance on ImageNet. We find networks that are both faster and moreaccurate, as well as networks with about the same accuracy but 1.77x faster thanResNet-50.", "paperhash": "gueguen|faster_neural_networks_straight_from_jpeg", "keywords": ["ImageNet", "JPEG", "Compression"], "_bibtex": "@misc{\n  gueguen2018faster,\n  title={Faster Neural Networks Straight from JPEG},\n  author={Lionel Gueguen and Alex Sergeev and Rosanne Liu and Jason Yosinski},\n  year={2018},\n  url={https://openreview.net/forum?id=S1ry6Y1vG}\n}", "authorids": ["lgueguen@uber.com", "asergeev@uber.com", "mimosavvy@gmail.com", "jason@yosinski.com"], "authors": ["Lionel Gueguen", "Alex Sergeev", "Rosanne Liu", "Jason Yosinski"], "TL;DR": "Faster and more accurate network that takes JPEG features as input", "pdf": "/pdf/03fd0f14cb296161eabef66fb7ad0f856ee9faea.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582982386, "tcdate": 1519753621065, "number": 1, "cdate": 1519753621065, "id": "Sk69tGQuG", "invitation": "ICLR.cc/2018/Workshop/-/Paper323/Official_Review", "forum": "S1ry6Y1vG", "replyto": "S1ry6Y1vG", "signatures": ["ICLR.cc/2018/Workshop/Paper323/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper323/AnonReviewer2"], "content": {"title": "An exhaustive study with an unexpected conclusion", "rating": "7: Good paper, accept", "review": "This work explores the behavior of ResNet-50 for ImageNet classification when applied directly over the DCT coefficients of JPEG images. The authors present seven different variations that obtain both gains in accuracy and speed. The experiments also include a configuration in which the first layer mimics the actual DCT filters, obtaining the same gain in accuracy as the best learned architecture.\n\nThe presented work is exhaustive and original in terms of how to explore the potential of working over DCT coefficients. the authors consider both the accuracy and speed dimensions on the results, and actually obtain interesting conclusions that may impact real-world products that may value the trade off between them. The text is clear, well-written, and guides the reader into the understanding of the figures and results.\n\nPROS\n- The different considered configurations are deeply discussed and argued.\n- The gains obtained in the DCT-Frozen configuration might have an impact in other tasks. These results open the door to further exciting research.\n- Text is clear and figures informative.\n\nCONS\n- Given some surprising results, it would be advisable to run the experiments more than 3 runs and study the variance of the results.\n- The results on Top-1 error rate are not included, and it is not discussed either if they match the conclusions obtained over Top5 error rate.\n\n- The paper fails into citing the related work in the field of image understanding from the compressed domain, which obviously limits the novelty of the work. For example:\n\nFu, D., & Guimaraes, G. (2016). Using Compression to Speed Up Image Classification in Artificial Neural Networks.\n\nJaved, M., Nagabhushan, P., & Chaudhuri, B. B. (2017). A review on document image analysis techniques directly in the compressed domain. Artificial Intelligence Review, 1-30.\n\nRobert Torfason, Fabian Mentzer, Eirikur Agustsson, Michael Tschannen, Radu Timofte, Luc Van Gool\nTowards Image Understanding from Deep Compression Without Decoding (ICLR 2018)\nhttps://openreview.net/forum?id=HkXWCMbRW", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Faster Neural Networks Straight from JPEG", "abstract": "Training convolutional neural networks (CNNs) directly from RGB pixels hasenjoyed overwhelming empirical success. But can more performance be squeezedout of networks by using different input representations? In this paper we proposeand explore a simple idea: train CNNs directly on the blockwise discrete cosinetransform (DCT) coefficients computed and available in the middle of the JPEG codec. We modify libjpeg to produce DCT coefficients directly, modify a ResNet-50 network to accommodate the differently sized and strided input, andevaluate performance on ImageNet. We find networks that are both faster and moreaccurate, as well as networks with about the same accuracy but 1.77x faster thanResNet-50.", "paperhash": "gueguen|faster_neural_networks_straight_from_jpeg", "keywords": ["ImageNet", "JPEG", "Compression"], "_bibtex": "@misc{\n  gueguen2018faster,\n  title={Faster Neural Networks Straight from JPEG},\n  author={Lionel Gueguen and Alex Sergeev and Rosanne Liu and Jason Yosinski},\n  year={2018},\n  url={https://openreview.net/forum?id=S1ry6Y1vG}\n}", "authorids": ["lgueguen@uber.com", "asergeev@uber.com", "mimosavvy@gmail.com", "jason@yosinski.com"], "authors": ["Lionel Gueguen", "Alex Sergeev", "Rosanne Liu", "Jason Yosinski"], "TL;DR": "Faster and more accurate network that takes JPEG features as input", "pdf": "/pdf/03fd0f14cb296161eabef66fb7ad0f856ee9faea.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582982158, "id": "ICLR.cc/2018/Workshop/-/Paper323/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper323/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper323/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper323/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper323/AnonReviewer3"], "reply": {"forum": "S1ry6Y1vG", "replyto": "S1ry6Y1vG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper323/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper323/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582982158}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582867683, "tcdate": 1520555188373, "number": 2, "cdate": 1520555188373, "id": "H12nVUyYz", "invitation": "ICLR.cc/2018/Workshop/-/Paper323/Official_Review", "forum": "S1ry6Y1vG", "replyto": "S1ry6Y1vG", "signatures": ["ICLR.cc/2018/Workshop/Paper323/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper323/AnonReviewer1"], "content": {"title": "nice demonstration of effective input representation", "rating": "7: Good paper, accept", "review": "This paper demonstrates the use of DCT coefficients available in the JPEG image format as an effective input representation to a convolutional network.  Instead of inputting RGB pixels, a JPEG-compressed image is half-decompressed to its 8x8 block DCT coefficients, which are used as input to the network.  8x8 strides are similar to existing ResNet-50 layer 2 spatial resolution, and several approaches are evaluated for how to sample and place the DCT input into the network.  Evaluations are performed on ImageNet classification; the method can achieve good performance while offering significant speedups, mostly by being able to replace the first two blocks with already-computed JPEG DCT.\n\nThis is an interesting and effective technique, and I found the paper good overall.  I think it can be improved in much of its description of the different architecture variants --- these were hard to follow from the descriptions alone, and I think could much benefit from a picture of these.\n\nAlso I think additional discussion on related and prior work might be good.  One recent paper I was able to find pretty quickly is Ulicny and Dahyot IMVIP 2017 \"On using CNN with DCT based Image Data\".\n\nAnother experiment I would be interested in is how does JPEG quality affect the results?  Can the network be trained with DCT inputs from different quality/compression settings (or a range of quality)?  But I don't think that is necessary for the workshops.\n\nOverall, this is a nice demonstration, and while I think it could be a little clearer in the exact model modifications, the idea is quite nice to see and effective.\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Faster Neural Networks Straight from JPEG", "abstract": "Training convolutional neural networks (CNNs) directly from RGB pixels hasenjoyed overwhelming empirical success. But can more performance be squeezedout of networks by using different input representations? In this paper we proposeand explore a simple idea: train CNNs directly on the blockwise discrete cosinetransform (DCT) coefficients computed and available in the middle of the JPEG codec. We modify libjpeg to produce DCT coefficients directly, modify a ResNet-50 network to accommodate the differently sized and strided input, andevaluate performance on ImageNet. We find networks that are both faster and moreaccurate, as well as networks with about the same accuracy but 1.77x faster thanResNet-50.", "paperhash": "gueguen|faster_neural_networks_straight_from_jpeg", "keywords": ["ImageNet", "JPEG", "Compression"], "_bibtex": "@misc{\n  gueguen2018faster,\n  title={Faster Neural Networks Straight from JPEG},\n  author={Lionel Gueguen and Alex Sergeev and Rosanne Liu and Jason Yosinski},\n  year={2018},\n  url={https://openreview.net/forum?id=S1ry6Y1vG}\n}", "authorids": ["lgueguen@uber.com", "asergeev@uber.com", "mimosavvy@gmail.com", "jason@yosinski.com"], "authors": ["Lionel Gueguen", "Alex Sergeev", "Rosanne Liu", "Jason Yosinski"], "TL;DR": "Faster and more accurate network that takes JPEG features as input", "pdf": "/pdf/03fd0f14cb296161eabef66fb7ad0f856ee9faea.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582982158, "id": "ICLR.cc/2018/Workshop/-/Paper323/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper323/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper323/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper323/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper323/AnonReviewer3"], "reply": {"forum": "S1ry6Y1vG", "replyto": "S1ry6Y1vG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper323/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper323/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582982158}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582788086, "tcdate": 1520630282906, "number": 3, "cdate": 1520630282906, "id": "Bk7zqdltG", "invitation": "ICLR.cc/2018/Workshop/-/Paper323/Official_Review", "forum": "S1ry6Y1vG", "replyto": "S1ry6Y1vG", "signatures": ["ICLR.cc/2018/Workshop/Paper323/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper323/AnonReviewer3"], "content": {"title": "A good idea, and correct benchmark to demonstrate efficient results, but short discussion", "rating": "7: Good paper, accept", "review": "This paper deals with image representation, and use of the compressed representation of JPEG to accelerate recognition.\nPerformance on ImageNet are interesting.\n\nThe discussion is, due to the format, quite short. \nShall be extended, reducing even more other parts.\n\nFor example we would like to have idea of the impact of the JPEG quality Q\nused during encoding. \nHere it is 100%, but what is the compromise Q, speed and accuracy ?\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Faster Neural Networks Straight from JPEG", "abstract": "Training convolutional neural networks (CNNs) directly from RGB pixels hasenjoyed overwhelming empirical success. But can more performance be squeezedout of networks by using different input representations? In this paper we proposeand explore a simple idea: train CNNs directly on the blockwise discrete cosinetransform (DCT) coefficients computed and available in the middle of the JPEG codec. We modify libjpeg to produce DCT coefficients directly, modify a ResNet-50 network to accommodate the differently sized and strided input, andevaluate performance on ImageNet. We find networks that are both faster and moreaccurate, as well as networks with about the same accuracy but 1.77x faster thanResNet-50.", "paperhash": "gueguen|faster_neural_networks_straight_from_jpeg", "keywords": ["ImageNet", "JPEG", "Compression"], "_bibtex": "@misc{\n  gueguen2018faster,\n  title={Faster Neural Networks Straight from JPEG},\n  author={Lionel Gueguen and Alex Sergeev and Rosanne Liu and Jason Yosinski},\n  year={2018},\n  url={https://openreview.net/forum?id=S1ry6Y1vG}\n}", "authorids": ["lgueguen@uber.com", "asergeev@uber.com", "mimosavvy@gmail.com", "jason@yosinski.com"], "authors": ["Lionel Gueguen", "Alex Sergeev", "Rosanne Liu", "Jason Yosinski"], "TL;DR": "Faster and more accurate network that takes JPEG features as input", "pdf": "/pdf/03fd0f14cb296161eabef66fb7ad0f856ee9faea.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582982158, "id": "ICLR.cc/2018/Workshop/-/Paper323/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper323/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper323/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper323/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper323/AnonReviewer3"], "reply": {"forum": "S1ry6Y1vG", "replyto": "S1ry6Y1vG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper323/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper323/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582982158}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573554748, "tcdate": 1521573554748, "number": 51, "cdate": 1521573554408, "id": "r1ohC0RYM", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "S1ry6Y1vG", "replyto": "S1ry6Y1vG", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Faster Neural Networks Straight from JPEG", "abstract": "Training convolutional neural networks (CNNs) directly from RGB pixels hasenjoyed overwhelming empirical success. But can more performance be squeezedout of networks by using different input representations? In this paper we proposeand explore a simple idea: train CNNs directly on the blockwise discrete cosinetransform (DCT) coefficients computed and available in the middle of the JPEG codec. We modify libjpeg to produce DCT coefficients directly, modify a ResNet-50 network to accommodate the differently sized and strided input, andevaluate performance on ImageNet. We find networks that are both faster and moreaccurate, as well as networks with about the same accuracy but 1.77x faster thanResNet-50.", "paperhash": "gueguen|faster_neural_networks_straight_from_jpeg", "keywords": ["ImageNet", "JPEG", "Compression"], "_bibtex": "@misc{\n  gueguen2018faster,\n  title={Faster Neural Networks Straight from JPEG},\n  author={Lionel Gueguen and Alex Sergeev and Rosanne Liu and Jason Yosinski},\n  year={2018},\n  url={https://openreview.net/forum?id=S1ry6Y1vG}\n}", "authorids": ["lgueguen@uber.com", "asergeev@uber.com", "mimosavvy@gmail.com", "jason@yosinski.com"], "authors": ["Lionel Gueguen", "Alex Sergeev", "Rosanne Liu", "Jason Yosinski"], "TL;DR": "Faster and more accurate network that takes JPEG features as input", "pdf": "/pdf/03fd0f14cb296161eabef66fb7ad0f856ee9faea.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}