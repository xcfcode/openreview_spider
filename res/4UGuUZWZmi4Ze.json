{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1363179420000, "tcdate": 1363179420000, "number": 4, "id": "D3uj2h4TUE2ce", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "4UGuUZWZmi4Ze", "replyto": "4UGuUZWZmi4Ze", "signatures": ["Felix Bauer"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "Points raised by reviewers:\r\nreviewer 43a2:\r\n(1) Good classification of rotations and scale are reported in Table 1, unfortunately these appear to be on toy, not natural, images. Impressive grouping of complex transformations such as translations and rotations are shown in Figure 3.\r\n(2) While the gabors learned on natural image patches are interesting it is hard to judge them without knowing how large they are. These details seem to be omitted from the paper.\r\n(3) It is not immediately obvious what applications would benefit from this type of model. It also seems like it could be relatively expensive computationally, and there was no mention of timing versus the standard gated Boltzmann machine model.\r\n\r\nreviewer ea89:\r\n(4) Please write the formulas for the full model that you train, not just the encoding. Even though they exist in other papers, they are not so complicated to write them down here.\r\n(5) You say that the pinwheel patterns don't appear in rodents because they don't have a binocular vision. However you haven't actually obtained the pinwheels from binocularity but from video.\r\n(6) The formula (9) is unclear and should be fixed. For example, how come the f index appears only once?\r\n(6a) Figure 3: What is index of parameter set? In text you talk about different datasizes - where are the results for these?\r\n\r\nreviewer cce5:\r\n(7a) * Targets somewhat of a 'niche audience'; may be less accessible to the general representation learning community\r\n(7b) * Presents a lot of qualitative but not quantitative results\r\n(8) Fig 2: It's difficult to read/understand the frequency scale (left, bottom); it seems that frequency has been discretized; what do these bins represent, and how are they constructed?\r\n(9) In section 2.1, could you be more explicit about what you mean by 'matching' the input filters (and the output filters). I assume the matching is referring to the connectivity by connecting filters to mapping units? Matching comes up again in Section 3, so it would help to clarify this early on.\r\n(10) Check equation 8: what happened to C - should it not show up there?\r\n\r\nOur response:\r\nWe thank the reviewers for their comments and suggestions. We submitted an updated version of the paper in which we address these points:\r\n\r\n(1, 7b) We agree. While the toy results do suggest that the reduction in the number of parameters caused by grouping helps generalize, real world applications like activity recognition work much better with local receptive fields and pooling, which we feel is much too complicated for a first paper in this direction.\r\n(2) We updated the paper to include a more detailed description of the datasets and experiments.\r\nX (3) We included a discussion of computational complexity. The complexity scales with the square of the group size (which is typically small, like 5). This is not a huge increase in complexity because without grouping the model has to account for the equivalent number of products by replicating filters.\r\n(4) We included the equations as suggested.\r\n(5) This is a good point, and we now clarify this in the updated version of the paper. Binocular stimuli, like video, are dominated by local translation, and the exact same biological mechanisms have traditionally been assumed to model both (multiview complex cells). A simple GBM has in fact been applied to binocular 3D inference tasks in the past (eg. 'Stereopsis via Deep Learning', Memisevic, Conrad, 2011).\r\n(6) We fixed this in the updated version.\r\n(6a): We now describe the figure in more detail in the updated version. (Along the x-axis we show models with varying numbers of factors and mapping units)\r\n(6a): We now describe the figure in more detail in the updated version. (Along the x-axis we show models with varying numbers of factors and mapping units)\r\n(7a): While the model and experiments we discuss in the paper are very specific and technical, we see the main contribution of the paper in explaining concisely why square-pooling, group sparse coding and topographic feature models learn to group frequency, orientation and position and not phase. While it is well-known that they show this behaviour we show that thinking of squares as representing transformations can explain why. We rewrote the text to make this point clearer.\r\n(8) They are DFT bins: We generate the plots by performing a 2d FFT on the learned Fourier filters (note that, since we train on translations in this experiment, we get Fourier components rather than Gabor features). We clarified this in the updated version.\r\n(9) We use 'matching' synonymous with 'multiplying'. Indeed, this means that 'matched' filters are those whose product gets fed into a mapping unit (along with other products). We clarified this in the updated version.\r\n(10) Yes. We fixed this in the updated version."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature grouping from spatially constrained multiplicative interaction", "decision": "conferenceOral-iclr2013-conference", "abstract": "We present a feature learning model that learns to encode relationships between images. The model is defined as a Gated Boltzmann Machine, which is constrained such that hidden units that are nearby in space can gate each other's connections. We show how frequency/orientation 'columns' as well as topographic filter maps follow naturally from training the model on image pairs. The model also helps explain why square-pooling models yield feature groups with similar grouping properties. Experimental results on synthetic image transformations show that spatially constrained gating is an effective way to reduce the number of parameters and thereby to regularize a transformation-learning model.", "pdf": "https://arxiv.org/abs/1301.3391", "paperhash": "bauer|feature_grouping_from_spatially_constrained_multiplicative_interaction", "keywords": [], "conflicts": [], "authors": ["Felix Bauer", "Roland Memisevic"], "authorids": ["felix.bauer.bfx@gmail.com", "roland.memisevic@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362214680000, "tcdate": 1362214680000, "number": 3, "id": "ah5kV2s_ULa20", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "4UGuUZWZmi4Ze", "replyto": "4UGuUZWZmi4Ze", "signatures": ["anonymous reviewer cce5"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Feature grouping from spatially constrained multiplicative interaction", "review": "This paper proposes a novel generalization of the Gated Boltzmann Machine. Unlike a traditional GBM, this model is constrained in a way that hidden units that are grouped together (groupings defined a priori) can gate each other's connections. The model is shown to produce group structure in the learned representations (topographic feature maps) as well as frequency and orientation consistency of the filters within each group.\r\n\r\nThis paper is well written, presents a novel learning paradigm and is of interest to the representation learning community, especially those researchers interested in higher-order RBMs and transformation learning.  \r\n\r\nPositive points of the paper:\r\n  * Novelty\r\n  * Readability\r\n  * Treatment of an area (transformation learning) that is, in my opinion, worthy of more attention in the representation learning community\r\n  * Makes connections to the 'group sparse coding' literature (where other papers have proposed encouraging the squared responses of grouped filters to be similar)\r\n  * Makes a good effort to explain the observed phenomena (e.g. in discussing the filter responses)\r\n\r\nNegative points of the paper:\r\n  * Targets somewhat of a 'niche audience'; may be less accessible to the general representation learning community\r\n  * Presents a lot of qualitative but not quantitative results\r\n\r\nOverall, it's a nice paper.\r\n\r\nSome specific comments:\r\n\r\nFig 2: It's difficult to read/understand the frequency scale (left, bottom); it seems that frequency has been discretized; what do these bins represent, and how are they constructed?\r\n\r\nIn section 2.1, could you be more explicit about what you mean by 'matching' the input filters (and the output filters). I assume the matching is referring to the connectivity by connecting filters to mapping units? Matching comes up again in Section 3, so it would help to clarify this early on.\r\n\r\nCheck equation 8: what happened to C - should it not show up there?"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature grouping from spatially constrained multiplicative interaction", "decision": "conferenceOral-iclr2013-conference", "abstract": "We present a feature learning model that learns to encode relationships between images. The model is defined as a Gated Boltzmann Machine, which is constrained such that hidden units that are nearby in space can gate each other's connections. We show how frequency/orientation 'columns' as well as topographic filter maps follow naturally from training the model on image pairs. The model also helps explain why square-pooling models yield feature groups with similar grouping properties. Experimental results on synthetic image transformations show that spatially constrained gating is an effective way to reduce the number of parameters and thereby to regularize a transformation-learning model.", "pdf": "https://arxiv.org/abs/1301.3391", "paperhash": "bauer|feature_grouping_from_spatially_constrained_multiplicative_interaction", "keywords": [], "conflicts": [], "authors": ["Felix Bauer", "Roland Memisevic"], "authorids": ["felix.bauer.bfx@gmail.com", "roland.memisevic@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362171300000, "tcdate": 1362171300000, "number": 2, "id": "VlvAlDIDt_Sa0", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "4UGuUZWZmi4Ze", "replyto": "4UGuUZWZmi4Ze", "signatures": ["anonymous reviewer ea89"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Feature grouping from spatially constrained multiplicative interaction", "review": "The model presented in this paper is an extension of a previous model that extracts features from images, and these featuers are multiplied together to extract motion information (or other relation between two images). The novelty is to connect each feature of one image to several features of other image. This reuses the features. Futher, these connections are made in groups, and the features in the group will learn to have related properties. With overlaping groups one obtains pinwheel patterns observed in visual cortex. This is a different mechanism then previous ones. \r\n\r\n- Please write the formulas for the full model that you train, not just the encoding. Even though they exist in other papers, they are not so complicated to write them down here.\r\n\r\n- You say that the pinwheel patterns don't appear in rodents because they don't have a binocular vision. However you haven't actually obtained the pinwheels from binocularity but from video.\r\n\r\n- The formula (9) is unclear and should be fixed. For example, how come the f index appears only once?\r\n\r\n- Figure 3: What is index of parameter set? In text you talk about different datasizes - where are the results for these?"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature grouping from spatially constrained multiplicative interaction", "decision": "conferenceOral-iclr2013-conference", "abstract": "We present a feature learning model that learns to encode relationships between images. The model is defined as a Gated Boltzmann Machine, which is constrained such that hidden units that are nearby in space can gate each other's connections. We show how frequency/orientation 'columns' as well as topographic filter maps follow naturally from training the model on image pairs. The model also helps explain why square-pooling models yield feature groups with similar grouping properties. Experimental results on synthetic image transformations show that spatially constrained gating is an effective way to reduce the number of parameters and thereby to regularize a transformation-learning model.", "pdf": "https://arxiv.org/abs/1301.3391", "paperhash": "bauer|feature_grouping_from_spatially_constrained_multiplicative_interaction", "keywords": [], "conflicts": [], "authors": ["Felix Bauer", "Roland Memisevic"], "authorids": ["felix.bauer.bfx@gmail.com", "roland.memisevic@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1361968140000, "tcdate": 1361968140000, "number": 1, "id": "yTWI4b3EnB4CU", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "4UGuUZWZmi4Ze", "replyto": "4UGuUZWZmi4Ze", "signatures": ["anonymous reviewer 43a2"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Feature grouping from spatially constrained multiplicative interaction", "review": "This paper introduces a group-gated Boltzmann machine for learning the transformations between a pair of images more efficiently than with a standard gated Boltzmann machine. Experiments show the model learns phase invariant complex cells-like units grouped by frequency and orientation. These groups can also be manipulated to include overlapping neighbors in which case the model learns topographic pinwheel layouts of orientation, frequency and phase. The paper also mentions how the model is related to squared-pooling used in other learning methods.\r\n\r\nPros\r\nInteresting idea to add an additional connectivity matrix to the factors to enforce grouping behavior in a gated RBM. This is shown to be beneficial for learning translation invariant groups which are stable for frequency and orientation.\r\n\r\nGood classification of rotations and scale are reported in Table 1, unfortunately these appear to be on toy, not natural, images. Impressive grouping of complex transformations such as translations and rotations are shown in Figure 3.\r\n\r\nFigure 2 is a great figure. Clearly shows how a GRBM can represent all forms of frequency and orientation and combine these to represent translations. In general the paper was well written and has good explanatory figures.\r\n\r\nCons\r\nWhile the gabors learned on natural image patches are interesting it is hard to judge them without knowing how large they are. These details seem to be omitted from the paper.\r\n\r\nIt is not immediately obvious what applications would benefit from this type of model. It also seems like it could be relatively expensive computationally, and there was no mention of timing versus the standard gated Boltzmann machine model.\r\n\r\nNovelty and Quality:\r\nThis extension to gated Boltzmann machines is novel in that it allows grouping of features and increases the modelling power because the model no longer needs multiple feature to do simple translations. The paper was well written overall."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature grouping from spatially constrained multiplicative interaction", "decision": "conferenceOral-iclr2013-conference", "abstract": "We present a feature learning model that learns to encode relationships between images. The model is defined as a Gated Boltzmann Machine, which is constrained such that hidden units that are nearby in space can gate each other's connections. We show how frequency/orientation 'columns' as well as topographic filter maps follow naturally from training the model on image pairs. The model also helps explain why square-pooling models yield feature groups with similar grouping properties. Experimental results on synthetic image transformations show that spatially constrained gating is an effective way to reduce the number of parameters and thereby to regularize a transformation-learning model.", "pdf": "https://arxiv.org/abs/1301.3391", "paperhash": "bauer|feature_grouping_from_spatially_constrained_multiplicative_interaction", "keywords": [], "conflicts": [], "authors": ["Felix Bauer", "Roland Memisevic"], "authorids": ["felix.bauer.bfx@gmail.com", "roland.memisevic@gmail.com"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1358433000000, "tcdate": 1358433000000, "number": 4, "id": "4UGuUZWZmi4Ze", "invitation": "ICLR.cc/2013/conference/-/submission", "forum": "4UGuUZWZmi4Ze", "signatures": ["felix.bauer.bfx@gmail.com"], "readers": ["everyone"], "content": {"title": "Feature grouping from spatially constrained multiplicative interaction", "decision": "conferenceOral-iclr2013-conference", "abstract": "We present a feature learning model that learns to encode relationships between images. The model is defined as a Gated Boltzmann Machine, which is constrained such that hidden units that are nearby in space can gate each other's connections. We show how frequency/orientation 'columns' as well as topographic filter maps follow naturally from training the model on image pairs. The model also helps explain why square-pooling models yield feature groups with similar grouping properties. Experimental results on synthetic image transformations show that spatially constrained gating is an effective way to reduce the number of parameters and thereby to regularize a transformation-learning model.", "pdf": "https://arxiv.org/abs/1301.3391", "paperhash": "bauer|feature_grouping_from_spatially_constrained_multiplicative_interaction", "keywords": [], "conflicts": [], "authors": ["Felix Bauer", "Roland Memisevic"], "authorids": ["felix.bauer.bfx@gmail.com", "roland.memisevic@gmail.com"]}, "writers": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496673673639, "cdate": 1496673673639, "tcdate": 1496673673639, "id": "ICLR.cc/2013/conference/-/submission", "writers": ["ICLR.cc/2013"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717}}}], "count": 5}