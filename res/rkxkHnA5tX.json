{"notes": [{"id": "rkxkHnA5tX", "original": "rJlQM31UKQ", "number": 1506, "cdate": 1538087991361, "ddate": null, "tcdate": 1538087991361, "tmdate": 1545355443709, "tddate": null, "forum": "rkxkHnA5tX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning from Noisy Demonstration Sets via Meta-Learned Suitability Assessor", "abstract": "A noisy and diverse demonstration set may hinder the performances of an agent aiming to acquire certain skills via imitation learning. However, state-of-the-art imitation learning algorithms often assume the optimality of the given demonstration set.\nIn this paper, we address such optimal assumption by learning only from the most suitable demonstrations in a given set. Suitability of a demonstration is estimated by whether imitating it produce desirable outcomes for achieving the goals of the tasks. For more efficient demonstration suitability assessments, the learning agent should be capable of imitating a demonstration as quick as possible, which shares similar spirit with fast adaptation in the meta-learning regime. Our framework, thus built on top of Model-Agnostic Meta-Learning, evaluates how desirable the imitated outcomes are, after adaptation to each demonstration in the set. The resulting assessments hence enable us to select suitable demonstration subsets for acquiring better imitated skills. The videos related to our experiments are available at: https://sites.google.com/view/deepdj", "keywords": ["Imitation Learning", "Noisy Demonstration Set", "Meta-Learning"], "authorids": ["telinwu@usc.edu", "jd730@snu.ac.kr", "jingyuny@usc.edu", "shaofanl@usc.edu", "vondrick@cs.columbia.edu", "limjj@usc.edu"], "authors": ["Te-Lin Wu", "Jaedong Hwang", "Jingyun Yang", "Shaofan Lai", "Carl Vondrick", "Joseph J. Lim"], "TL;DR": "We propose a framework to learn a good policy through imitation learning from a noisy demonstration set via meta-training a demonstration suitability assessor.", "pdf": "/pdf/8bffe3ba3be64af2446c6311b3bb7d228cf27bb6.pdf", "paperhash": "wu|learning_from_noisy_demonstration_sets_via_metalearned_suitability_assessor", "_bibtex": "@misc{\nwu2019learning,\ntitle={Learning from Noisy Demonstration Sets via Meta-Learned Suitability Assessor},\nauthor={Te-Lin Wu and Jaedong Hwang and Jingyun Yang and Shaofan Lai and Carl Vondrick and Joseph J. Lim},\nyear={2019},\nurl={https://openreview.net/forum?id=rkxkHnA5tX},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "BJg4rnmtxV", "original": null, "number": 1, "cdate": 1545317435550, "ddate": null, "tcdate": 1545317435550, "tmdate": 1545354473762, "tddate": null, "forum": "rkxkHnA5tX", "replyto": "rkxkHnA5tX", "invitation": "ICLR.cc/2019/Conference/-/Paper1506/Meta_Review", "content": {"metareview": "The reviewers raised a number of major concerns including the incremental novelty of the proposed (if any), insufficient explanation, and, most importantly, insufficient and inadequate experimental evaluation presented. The authors did not provide any rebuttal. Hence, I cannot suggest this paper for presentation at ICLR.", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "metareview"}, "signatures": ["ICLR.cc/2019/Conference/Paper1506/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1506/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning from Noisy Demonstration Sets via Meta-Learned Suitability Assessor", "abstract": "A noisy and diverse demonstration set may hinder the performances of an agent aiming to acquire certain skills via imitation learning. However, state-of-the-art imitation learning algorithms often assume the optimality of the given demonstration set.\nIn this paper, we address such optimal assumption by learning only from the most suitable demonstrations in a given set. Suitability of a demonstration is estimated by whether imitating it produce desirable outcomes for achieving the goals of the tasks. For more efficient demonstration suitability assessments, the learning agent should be capable of imitating a demonstration as quick as possible, which shares similar spirit with fast adaptation in the meta-learning regime. Our framework, thus built on top of Model-Agnostic Meta-Learning, evaluates how desirable the imitated outcomes are, after adaptation to each demonstration in the set. The resulting assessments hence enable us to select suitable demonstration subsets for acquiring better imitated skills. The videos related to our experiments are available at: https://sites.google.com/view/deepdj", "keywords": ["Imitation Learning", "Noisy Demonstration Set", "Meta-Learning"], "authorids": ["telinwu@usc.edu", "jd730@snu.ac.kr", "jingyuny@usc.edu", "shaofanl@usc.edu", "vondrick@cs.columbia.edu", "limjj@usc.edu"], "authors": ["Te-Lin Wu", "Jaedong Hwang", "Jingyun Yang", "Shaofan Lai", "Carl Vondrick", "Joseph J. Lim"], "TL;DR": "We propose a framework to learn a good policy through imitation learning from a noisy demonstration set via meta-training a demonstration suitability assessor.", "pdf": "/pdf/8bffe3ba3be64af2446c6311b3bb7d228cf27bb6.pdf", "paperhash": "wu|learning_from_noisy_demonstration_sets_via_metalearned_suitability_assessor", "_bibtex": "@misc{\nwu2019learning,\ntitle={Learning from Noisy Demonstration Sets via Meta-Learned Suitability Assessor},\nauthor={Te-Lin Wu and Jaedong Hwang and Jingyun Yang and Shaofan Lai and Carl Vondrick and Joseph J. Lim},\nyear={2019},\nurl={https://openreview.net/forum?id=rkxkHnA5tX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1506/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352812710, "tddate": null, "super": null, "final": null, "reply": {"forum": "rkxkHnA5tX", "replyto": "rkxkHnA5tX", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1506/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1506/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1506/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352812710}}}, {"id": "HJxSenCj6Q", "original": null, "number": 3, "cdate": 1542347757506, "ddate": null, "tcdate": 1542347757506, "tmdate": 1542347757506, "tddate": null, "forum": "rkxkHnA5tX", "replyto": "rkxkHnA5tX", "invitation": "ICLR.cc/2019/Conference/-/Paper1506/Official_Review", "content": {"title": "Problem of limited scope, with interesting domains but uncompelling final performance", "review": "Summary/Contributions:\nThis paper focuses on an imitation learning setup where there some of the provided demonstrations which are irrelevant to the task being considered. The stated contribution of the paper is a MAML based algorithm to imitation learning which automatically determines if the demonstrations are \"suitable\".  The authors also employ a mutual information based maximization term between the demonstrations and the pre-update and post update trajectories.  \n\nPros:\n- The tasks proposed in the problem seem interesting.\n\nCons:\n- The problem statement seems to be of limited scope.\n- The use of the task heuristics seems a bit ad-hoc. \n- The final policies are unimpressive\n\nJustification for rating:\nThe major weakness of this paper in my view are that the setup is of somewhat limited scope since receiving irrelevant demonstrations in the form used by the paper would be unnecessarily costly. The domains considered by the paper seem interesting, but the learned policies are not very compelling. I also feel that the MAML baselines + avg finetuning baselines are somewhat limited giving the new domains. I would appreciate for instance a comparison to off-policy learning methods with demonstrations which the authors discuss in the related work (Hester et al. 2017, Nair et al. 2017, Yang et al. 2018). The justification between using mutual information regularization term also does not seem well-motivated and orthogonal to the problem statement. For instance, a diversity of demonstrations should in principle allow for more information between the demonstrations and the induced change.\n\nOther:\nThe writing and grammar of the paper needs serious revision. There are error throughout the paper starting from the abstract. ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1506/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning from Noisy Demonstration Sets via Meta-Learned Suitability Assessor", "abstract": "A noisy and diverse demonstration set may hinder the performances of an agent aiming to acquire certain skills via imitation learning. However, state-of-the-art imitation learning algorithms often assume the optimality of the given demonstration set.\nIn this paper, we address such optimal assumption by learning only from the most suitable demonstrations in a given set. Suitability of a demonstration is estimated by whether imitating it produce desirable outcomes for achieving the goals of the tasks. For more efficient demonstration suitability assessments, the learning agent should be capable of imitating a demonstration as quick as possible, which shares similar spirit with fast adaptation in the meta-learning regime. Our framework, thus built on top of Model-Agnostic Meta-Learning, evaluates how desirable the imitated outcomes are, after adaptation to each demonstration in the set. The resulting assessments hence enable us to select suitable demonstration subsets for acquiring better imitated skills. The videos related to our experiments are available at: https://sites.google.com/view/deepdj", "keywords": ["Imitation Learning", "Noisy Demonstration Set", "Meta-Learning"], "authorids": ["telinwu@usc.edu", "jd730@snu.ac.kr", "jingyuny@usc.edu", "shaofanl@usc.edu", "vondrick@cs.columbia.edu", "limjj@usc.edu"], "authors": ["Te-Lin Wu", "Jaedong Hwang", "Jingyun Yang", "Shaofan Lai", "Carl Vondrick", "Joseph J. Lim"], "TL;DR": "We propose a framework to learn a good policy through imitation learning from a noisy demonstration set via meta-training a demonstration suitability assessor.", "pdf": "/pdf/8bffe3ba3be64af2446c6311b3bb7d228cf27bb6.pdf", "paperhash": "wu|learning_from_noisy_demonstration_sets_via_metalearned_suitability_assessor", "_bibtex": "@misc{\nwu2019learning,\ntitle={Learning from Noisy Demonstration Sets via Meta-Learned Suitability Assessor},\nauthor={Te-Lin Wu and Jaedong Hwang and Jingyun Yang and Shaofan Lai and Carl Vondrick and Joseph J. Lim},\nyear={2019},\nurl={https://openreview.net/forum?id=rkxkHnA5tX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1506/Official_Review", "cdate": 1542234215365, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rkxkHnA5tX", "replyto": "rkxkHnA5tX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1506/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335960881, "tmdate": 1552335960881, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1506/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SylhzCuiaX", "original": null, "number": 2, "cdate": 1542323732488, "ddate": null, "tcdate": 1542323732488, "tmdate": 1542323732488, "tddate": null, "forum": "rkxkHnA5tX", "replyto": "rkxkHnA5tX", "invitation": "ICLR.cc/2019/Conference/-/Paper1506/Official_Review", "content": {"title": "Artificial problem class which doesn't justify the complexity of the method that doesn't deliver good performance.", "review": "The problem is described as doing imitation learning from a set of demonstrations that includes useless behavior. Authors propose a method that is an extension of MAML which selects the useful demonstrations by their provided performance gains at the meta-training time.\n\nPaper clearly demonstrates significant amount of work. Pieces from different modern method implementations (like MAML, TRPO, GAIL, multiple custom loss functions) are combined to work together. Also four custom task domains are implemented with MuJoCo. Finally decent amount of experiments are run.\n\nUnfortunately, all that hard work can't be justified by the motivations that are very artificial in details and by the final task performance.\n\nFirst of all, the setup includes small number of demonstrations where almost none of them are seemingly successful (judging by the videos). This is a very artificial setting that does not reflect the actual imitation learning problems like demonstrations provided by humans. There, normally the problem is either dealing with small number of demonstrations that are all typically successful but similarly suboptimal or dealing with small number of distinct demonstrators which are again successful but have significantly different styles. In the summary video, authors motivate the case by learning from sources like internet videos, but that setting is also very far away from the case here, because such video collections are much larger but more importantly the main problem is dealing with the third person perspective. All the experiments here is done from first person demonstrations (in one case with a slightly different body).\n\nBiggest caveat of the paper is that it is promoted as a purely imitation learning method. Yet everything hinges on the existence of a \"task heuristic\" which is nothing but a reward function. If such function exists, all these first person demonstrations can be judged and selected based on that function. There would be no need for a complicated meta-learning scheme. Also the task could be trained directly on that reward by reinforcement learning. Also computation of this heuristic function is not specified. As far as I understand, it is a different quantity than the sparse \"Task Success Reward\".\n\nFinally, the final performance of the imitating agents are far from accomplishing the task, though they show some resemblance to the imitation behavior. This is not all that surprising, given small number of demonstrations and high dimensional control problems.\n\nOverall, the details of the setup makes the problem very artificial, the final performance is not impressive. Method is an amalgamation of bunch other recent work, which gives the impression of creating complexity for its own sake. I do not think that this method will be useful for moving the field forward and produce any impact. ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1506/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning from Noisy Demonstration Sets via Meta-Learned Suitability Assessor", "abstract": "A noisy and diverse demonstration set may hinder the performances of an agent aiming to acquire certain skills via imitation learning. However, state-of-the-art imitation learning algorithms often assume the optimality of the given demonstration set.\nIn this paper, we address such optimal assumption by learning only from the most suitable demonstrations in a given set. Suitability of a demonstration is estimated by whether imitating it produce desirable outcomes for achieving the goals of the tasks. For more efficient demonstration suitability assessments, the learning agent should be capable of imitating a demonstration as quick as possible, which shares similar spirit with fast adaptation in the meta-learning regime. Our framework, thus built on top of Model-Agnostic Meta-Learning, evaluates how desirable the imitated outcomes are, after adaptation to each demonstration in the set. The resulting assessments hence enable us to select suitable demonstration subsets for acquiring better imitated skills. The videos related to our experiments are available at: https://sites.google.com/view/deepdj", "keywords": ["Imitation Learning", "Noisy Demonstration Set", "Meta-Learning"], "authorids": ["telinwu@usc.edu", "jd730@snu.ac.kr", "jingyuny@usc.edu", "shaofanl@usc.edu", "vondrick@cs.columbia.edu", "limjj@usc.edu"], "authors": ["Te-Lin Wu", "Jaedong Hwang", "Jingyun Yang", "Shaofan Lai", "Carl Vondrick", "Joseph J. Lim"], "TL;DR": "We propose a framework to learn a good policy through imitation learning from a noisy demonstration set via meta-training a demonstration suitability assessor.", "pdf": "/pdf/8bffe3ba3be64af2446c6311b3bb7d228cf27bb6.pdf", "paperhash": "wu|learning_from_noisy_demonstration_sets_via_metalearned_suitability_assessor", "_bibtex": "@misc{\nwu2019learning,\ntitle={Learning from Noisy Demonstration Sets via Meta-Learned Suitability Assessor},\nauthor={Te-Lin Wu and Jaedong Hwang and Jingyun Yang and Shaofan Lai and Carl Vondrick and Joseph J. Lim},\nyear={2019},\nurl={https://openreview.net/forum?id=rkxkHnA5tX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1506/Official_Review", "cdate": 1542234215365, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rkxkHnA5tX", "replyto": "rkxkHnA5tX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1506/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335960881, "tmdate": 1552335960881, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1506/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SkxapRNs3X", "original": null, "number": 1, "cdate": 1541258949465, "ddate": null, "tcdate": 1541258949465, "tmdate": 1541677879250, "tddate": null, "forum": "rkxkHnA5tX", "replyto": "rkxkHnA5tX", "invitation": "ICLR.cc/2019/Conference/-/Paper1506/Official_Review", "content": {"title": "many things unclear, experiments not convincing enough, writing needs improvement.", "review": "The paper makes its intent plainly clear, it wants to remove the assumption that demonstrations are optimal.  Thus it should show that in a case that some demonstrations are bad, it outperforms other methods which assume they are all good. The method proposed, while interesting, well-conceived and potentially novel, is not convincingly tested to this end. \n\nThe paper should also show that the method can detect the bad demonstrations, and select the good demonstrations. \n\nThe experiments are on toy tasks and not existing tasks in the literature. Why not use an existing dataset/domain and simply noise up the demonstrations?\n\nFurthermore, many crucial details are omitted, such as the nature of the heuristic function K, and how precisely the weighting $c_i$ is adapted (section 4.4). Is it done by gradient descent? We would have to know what K is, and if it is differentiable to know this.\n\nAlso the writing itself needs a thorough revision.\n\nI think there may well be promise in the method, but it does not appear ready for publication.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1506/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Learning from Noisy Demonstration Sets via Meta-Learned Suitability Assessor", "abstract": "A noisy and diverse demonstration set may hinder the performances of an agent aiming to acquire certain skills via imitation learning. However, state-of-the-art imitation learning algorithms often assume the optimality of the given demonstration set.\nIn this paper, we address such optimal assumption by learning only from the most suitable demonstrations in a given set. Suitability of a demonstration is estimated by whether imitating it produce desirable outcomes for achieving the goals of the tasks. For more efficient demonstration suitability assessments, the learning agent should be capable of imitating a demonstration as quick as possible, which shares similar spirit with fast adaptation in the meta-learning regime. Our framework, thus built on top of Model-Agnostic Meta-Learning, evaluates how desirable the imitated outcomes are, after adaptation to each demonstration in the set. The resulting assessments hence enable us to select suitable demonstration subsets for acquiring better imitated skills. The videos related to our experiments are available at: https://sites.google.com/view/deepdj", "keywords": ["Imitation Learning", "Noisy Demonstration Set", "Meta-Learning"], "authorids": ["telinwu@usc.edu", "jd730@snu.ac.kr", "jingyuny@usc.edu", "shaofanl@usc.edu", "vondrick@cs.columbia.edu", "limjj@usc.edu"], "authors": ["Te-Lin Wu", "Jaedong Hwang", "Jingyun Yang", "Shaofan Lai", "Carl Vondrick", "Joseph J. Lim"], "TL;DR": "We propose a framework to learn a good policy through imitation learning from a noisy demonstration set via meta-training a demonstration suitability assessor.", "pdf": "/pdf/8bffe3ba3be64af2446c6311b3bb7d228cf27bb6.pdf", "paperhash": "wu|learning_from_noisy_demonstration_sets_via_metalearned_suitability_assessor", "_bibtex": "@misc{\nwu2019learning,\ntitle={Learning from Noisy Demonstration Sets via Meta-Learned Suitability Assessor},\nauthor={Te-Lin Wu and Jaedong Hwang and Jingyun Yang and Shaofan Lai and Carl Vondrick and Joseph J. Lim},\nyear={2019},\nurl={https://openreview.net/forum?id=rkxkHnA5tX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1506/Official_Review", "cdate": 1542234215365, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rkxkHnA5tX", "replyto": "rkxkHnA5tX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1506/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335960881, "tmdate": 1552335960881, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1506/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 5}