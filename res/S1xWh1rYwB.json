{"notes": [{"id": "mKhBtMIUv0x", "original": null, "number": 12, "cdate": 1588881849673, "ddate": null, "tcdate": 1588881849673, "tmdate": 1588881849673, "tddate": null, "forum": "S1xWh1rYwB", "replyto": "0PGiUwlVkQa", "invitation": "ICLR.cc/2020/Conference/Paper1940/-/Official_Comment", "content": {"title": "Infomask paper ", "comment": "Dear Saeid,\n\nthanks for pointing us to your paper. We now reference your work. The main difference is that in your work the information bottleneck is already added during the training of the network. In contrast, our methods works aims at already trained network (post-hoc explanations). This is also reflected how we restrict the amount of information. \n\nBest,\nLeon"}, "signatures": ["ICLR.cc/2020/Conference/Paper1940/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1940/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["karl.schulz@tum.de", "leon.sixt@fu-berlin.de", "tombari@in.tum.de", "tim.landgraf@fu-berlin.de"], "title": "Restricting the Flow: Information Bottlenecks for Attribution", "authors": ["Karl Schulz", "Leon Sixt", "Federico Tombari", "Tim Landgraf"], "pdf": "/pdf/fa83870e660a55419088e307e2571dfea2df9116.pdf", "TL;DR": "We apply the informational bottleneck concept to attribution.", "abstract": "Attribution methods provide insights into the decision-making of machine learning models like artificial neural networks. For a given input sample, they assign a relevance score to each individual input variable, such as the pixels of an image. In this work, we adopt the information bottleneck concept for attribution. By adding noise to intermediate feature maps, we restrict the flow of information and can quantify (in bits) how much information image regions provide. We compare our method against ten baselines using three different metrics on VGG-16 and ResNet-50, and find that our methods outperform all baselines in five out of six settings. The method\u2019s information-theoretic foundation provides an absolute frame of reference for attribution values (bits) and a guarantee that regions scored close to zero are not necessary for the network's decision. ", "code": "https://github.com/BioroboticsLab/IBA-paper-code", "keywords": ["Attribution", "Informational Bottleneck", "Interpretable Machine Learning", "Explainable AI"], "paperhash": "schulz|restricting_the_flow_information_bottlenecks_for_attribution", "_bibtex": "@inproceedings{\nSchulz2020Restricting,\ntitle={Restricting the Flow: Information Bottlenecks for Attribution},\nauthor={Karl Schulz and Leon Sixt and Federico Tombari and Tim Landgraf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1xWh1rYwB}\n}", "original_pdf": "/attachment/bfcda49c9992f8979d9cc88da9dbc91396bff625.pdf"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1xWh1rYwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1940/Authors", "ICLR.cc/2020/Conference/Paper1940/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1940/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1940/Reviewers", "ICLR.cc/2020/Conference/Paper1940/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1940/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1940/Authors|ICLR.cc/2020/Conference/Paper1940/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504148658, "tmdate": 1576860528572, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1940/Authors", "ICLR.cc/2020/Conference/Paper1940/Reviewers", "ICLR.cc/2020/Conference/Paper1940/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1940/-/Official_Comment"}}}, {"id": "S1xWh1rYwB", "original": "S1efdeyYvS", "number": 1940, "cdate": 1569439656527, "ddate": null, "tcdate": 1569439656527, "tmdate": 1588881569213, "tddate": null, "forum": "S1xWh1rYwB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["karl.schulz@tum.de", "leon.sixt@fu-berlin.de", "tombari@in.tum.de", "tim.landgraf@fu-berlin.de"], "title": "Restricting the Flow: Information Bottlenecks for Attribution", "authors": ["Karl Schulz", "Leon Sixt", "Federico Tombari", "Tim Landgraf"], "pdf": "/pdf/fa83870e660a55419088e307e2571dfea2df9116.pdf", "TL;DR": "We apply the informational bottleneck concept to attribution.", "abstract": "Attribution methods provide insights into the decision-making of machine learning models like artificial neural networks. For a given input sample, they assign a relevance score to each individual input variable, such as the pixels of an image. In this work, we adopt the information bottleneck concept for attribution. By adding noise to intermediate feature maps, we restrict the flow of information and can quantify (in bits) how much information image regions provide. We compare our method against ten baselines using three different metrics on VGG-16 and ResNet-50, and find that our methods outperform all baselines in five out of six settings. The method\u2019s information-theoretic foundation provides an absolute frame of reference for attribution values (bits) and a guarantee that regions scored close to zero are not necessary for the network's decision. ", "code": "https://github.com/BioroboticsLab/IBA-paper-code", "keywords": ["Attribution", "Informational Bottleneck", "Interpretable Machine Learning", "Explainable AI"], "paperhash": "schulz|restricting_the_flow_information_bottlenecks_for_attribution", "_bibtex": "@inproceedings{\nSchulz2020Restricting,\ntitle={Restricting the Flow: Information Bottlenecks for Attribution},\nauthor={Karl Schulz and Leon Sixt and Federico Tombari and Tim Landgraf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1xWh1rYwB}\n}", "original_pdf": "/attachment/bfcda49c9992f8979d9cc88da9dbc91396bff625.pdf"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 13, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "0PGiUwlVkQa", "original": null, "number": 2, "cdate": 1585606948789, "ddate": null, "tcdate": 1585606948789, "tmdate": 1585607033278, "tddate": null, "forum": "S1xWh1rYwB", "replyto": "S1xWh1rYwB", "invitation": "ICLR.cc/2020/Conference/Paper1940/-/Public_Comment", "content": {"title": "Overlaps with the Infomask paper", "comment": "Dear authors, we found overlaps in the methodology of your paper with our published Infomask paper: https://arxiv.org/abs/1903.11741 \n\nIt is highly appreciated if you could please highlight the differences.\n\nThanks \n\n"}, "signatures": ["~Saeid_Asgari_Taghanaki1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Saeid_Asgari_Taghanaki1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["karl.schulz@tum.de", "leon.sixt@fu-berlin.de", "tombari@in.tum.de", "tim.landgraf@fu-berlin.de"], "title": "Restricting the Flow: Information Bottlenecks for Attribution", "authors": ["Karl Schulz", "Leon Sixt", "Federico Tombari", "Tim Landgraf"], "pdf": "/pdf/fa83870e660a55419088e307e2571dfea2df9116.pdf", "TL;DR": "We apply the informational bottleneck concept to attribution.", "abstract": "Attribution methods provide insights into the decision-making of machine learning models like artificial neural networks. For a given input sample, they assign a relevance score to each individual input variable, such as the pixels of an image. In this work, we adopt the information bottleneck concept for attribution. By adding noise to intermediate feature maps, we restrict the flow of information and can quantify (in bits) how much information image regions provide. We compare our method against ten baselines using three different metrics on VGG-16 and ResNet-50, and find that our methods outperform all baselines in five out of six settings. The method\u2019s information-theoretic foundation provides an absolute frame of reference for attribution values (bits) and a guarantee that regions scored close to zero are not necessary for the network's decision. ", "code": "https://github.com/BioroboticsLab/IBA-paper-code", "keywords": ["Attribution", "Informational Bottleneck", "Interpretable Machine Learning", "Explainable AI"], "paperhash": "schulz|restricting_the_flow_information_bottlenecks_for_attribution", "_bibtex": "@inproceedings{\nSchulz2020Restricting,\ntitle={Restricting the Flow: Information Bottlenecks for Attribution},\nauthor={Karl Schulz and Leon Sixt and Federico Tombari and Tim Landgraf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1xWh1rYwB}\n}", "original_pdf": "/attachment/bfcda49c9992f8979d9cc88da9dbc91396bff625.pdf"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1xWh1rYwB", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504187395, "tmdate": 1576860562428, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper1940/Authors", "ICLR.cc/2020/Conference/Paper1940/Reviewers", "ICLR.cc/2020/Conference/Paper1940/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1940/-/Public_Comment"}}}, {"id": "BxGBa1vmPl", "original": null, "number": 11, "cdate": 1581789001018, "ddate": null, "tcdate": 1581789001018, "tmdate": 1581789001018, "tddate": null, "forum": "S1xWh1rYwB", "replyto": "S1xWh1rYwB", "invitation": "ICLR.cc/2020/Conference/Paper1940/-/Official_Comment", "content": {"title": "Summary of Changes", "comment": "We want to summarize our changes since the original submission:\n- Include Sanity Checks (Adebayo et al., 2018)\n- Add Figure 4: Different depth and beta values\n- Include LRP with parameters \u03b1=1, \u03b2=0\n- Include some additional references\n\nImproved presentation:\n- switch to seismic color map.\n- migrate the overloading of X by introducing a new variable for the intermediate representation R.\n- include heatmaps in the appendix without overlay on not-cherry-picked samples.\n- redo diagrams of Per-Sample and Readout with tikz (increase beauty).\n- fixed several minor issues (grammar, wording, clarity).\n\nMany of these changes were encouraged by the feedback of our reviewers.\nThank you for accepting us for a talk!"}, "signatures": ["ICLR.cc/2020/Conference/Paper1940/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1940/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["karl.schulz@tum.de", "leon.sixt@fu-berlin.de", "tombari@in.tum.de", "tim.landgraf@fu-berlin.de"], "title": "Restricting the Flow: Information Bottlenecks for Attribution", "authors": ["Karl Schulz", "Leon Sixt", "Federico Tombari", "Tim Landgraf"], "pdf": "/pdf/fa83870e660a55419088e307e2571dfea2df9116.pdf", "TL;DR": "We apply the informational bottleneck concept to attribution.", "abstract": "Attribution methods provide insights into the decision-making of machine learning models like artificial neural networks. For a given input sample, they assign a relevance score to each individual input variable, such as the pixels of an image. In this work, we adopt the information bottleneck concept for attribution. By adding noise to intermediate feature maps, we restrict the flow of information and can quantify (in bits) how much information image regions provide. We compare our method against ten baselines using three different metrics on VGG-16 and ResNet-50, and find that our methods outperform all baselines in five out of six settings. The method\u2019s information-theoretic foundation provides an absolute frame of reference for attribution values (bits) and a guarantee that regions scored close to zero are not necessary for the network's decision. ", "code": "https://github.com/BioroboticsLab/IBA-paper-code", "keywords": ["Attribution", "Informational Bottleneck", "Interpretable Machine Learning", "Explainable AI"], "paperhash": "schulz|restricting_the_flow_information_bottlenecks_for_attribution", "_bibtex": "@inproceedings{\nSchulz2020Restricting,\ntitle={Restricting the Flow: Information Bottlenecks for Attribution},\nauthor={Karl Schulz and Leon Sixt and Federico Tombari and Tim Landgraf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1xWh1rYwB}\n}", "original_pdf": "/attachment/bfcda49c9992f8979d9cc88da9dbc91396bff625.pdf"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1xWh1rYwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1940/Authors", "ICLR.cc/2020/Conference/Paper1940/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1940/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1940/Reviewers", "ICLR.cc/2020/Conference/Paper1940/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1940/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1940/Authors|ICLR.cc/2020/Conference/Paper1940/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504148658, "tmdate": 1576860528572, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1940/Authors", "ICLR.cc/2020/Conference/Paper1940/Reviewers", "ICLR.cc/2020/Conference/Paper1940/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1940/-/Official_Comment"}}}, {"id": "K3CKL6W4A", "original": null, "number": 1, "cdate": 1578467731143, "ddate": null, "tcdate": 1578467731143, "tmdate": 1578467731143, "tddate": null, "forum": "S1xWh1rYwB", "replyto": "S1xWh1rYwB", "invitation": "ICLR.cc/2020/Conference/Paper1940/-/Public_Comment", "content": {"title": "Some related work...", "comment": "Nice paper!\n\nAlso See: Information-Bottleneck Approach to Salient Region Discovery by Zhmoginov et all, \nhttps://arxiv.org/abs/1907.09578 also explores information bottleneck for similar tasks on simple datasets.\n\nTheir (our) model is somewhat different, but relies on similar concept of finding the regions that preserve most of the mutual information between masked image and the labels. It would be interesting if the differences were articulated in this paper."}, "signatures": ["~Mark_Sandler1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Mark_Sandler1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["karl.schulz@tum.de", "leon.sixt@fu-berlin.de", "tombari@in.tum.de", "tim.landgraf@fu-berlin.de"], "title": "Restricting the Flow: Information Bottlenecks for Attribution", "authors": ["Karl Schulz", "Leon Sixt", "Federico Tombari", "Tim Landgraf"], "pdf": "/pdf/fa83870e660a55419088e307e2571dfea2df9116.pdf", "TL;DR": "We apply the informational bottleneck concept to attribution.", "abstract": "Attribution methods provide insights into the decision-making of machine learning models like artificial neural networks. For a given input sample, they assign a relevance score to each individual input variable, such as the pixels of an image. In this work, we adopt the information bottleneck concept for attribution. By adding noise to intermediate feature maps, we restrict the flow of information and can quantify (in bits) how much information image regions provide. We compare our method against ten baselines using three different metrics on VGG-16 and ResNet-50, and find that our methods outperform all baselines in five out of six settings. The method\u2019s information-theoretic foundation provides an absolute frame of reference for attribution values (bits) and a guarantee that regions scored close to zero are not necessary for the network's decision. ", "code": "https://github.com/BioroboticsLab/IBA-paper-code", "keywords": ["Attribution", "Informational Bottleneck", "Interpretable Machine Learning", "Explainable AI"], "paperhash": "schulz|restricting_the_flow_information_bottlenecks_for_attribution", "_bibtex": "@inproceedings{\nSchulz2020Restricting,\ntitle={Restricting the Flow: Information Bottlenecks for Attribution},\nauthor={Karl Schulz and Leon Sixt and Federico Tombari and Tim Landgraf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1xWh1rYwB}\n}", "original_pdf": "/attachment/bfcda49c9992f8979d9cc88da9dbc91396bff625.pdf"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1xWh1rYwB", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504187395, "tmdate": 1576860562428, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper1940/Authors", "ICLR.cc/2020/Conference/Paper1940/Reviewers", "ICLR.cc/2020/Conference/Paper1940/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1940/-/Public_Comment"}}}, {"id": "dsIQuI8DCU", "original": null, "number": 1, "cdate": 1576798736463, "ddate": null, "tcdate": 1576798736463, "tmdate": 1576800899907, "tddate": null, "forum": "S1xWh1rYwB", "replyto": "S1xWh1rYwB", "invitation": "ICLR.cc/2020/Conference/Paper1940/-/Decision", "content": {"decision": "Accept (Talk)", "comment": "All three reviewers strongly recommend accepting this paper. It is clear, novel, and a significant contribution to the field. Please take their suggestions into account in a camera ready version. Thanks!", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["karl.schulz@tum.de", "leon.sixt@fu-berlin.de", "tombari@in.tum.de", "tim.landgraf@fu-berlin.de"], "title": "Restricting the Flow: Information Bottlenecks for Attribution", "authors": ["Karl Schulz", "Leon Sixt", "Federico Tombari", "Tim Landgraf"], "pdf": "/pdf/fa83870e660a55419088e307e2571dfea2df9116.pdf", "TL;DR": "We apply the informational bottleneck concept to attribution.", "abstract": "Attribution methods provide insights into the decision-making of machine learning models like artificial neural networks. For a given input sample, they assign a relevance score to each individual input variable, such as the pixels of an image. In this work, we adopt the information bottleneck concept for attribution. By adding noise to intermediate feature maps, we restrict the flow of information and can quantify (in bits) how much information image regions provide. We compare our method against ten baselines using three different metrics on VGG-16 and ResNet-50, and find that our methods outperform all baselines in five out of six settings. The method\u2019s information-theoretic foundation provides an absolute frame of reference for attribution values (bits) and a guarantee that regions scored close to zero are not necessary for the network's decision. ", "code": "https://github.com/BioroboticsLab/IBA-paper-code", "keywords": ["Attribution", "Informational Bottleneck", "Interpretable Machine Learning", "Explainable AI"], "paperhash": "schulz|restricting_the_flow_information_bottlenecks_for_attribution", "_bibtex": "@inproceedings{\nSchulz2020Restricting,\ntitle={Restricting the Flow: Information Bottlenecks for Attribution},\nauthor={Karl Schulz and Leon Sixt and Federico Tombari and Tim Landgraf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1xWh1rYwB}\n}", "original_pdf": "/attachment/bfcda49c9992f8979d9cc88da9dbc91396bff625.pdf"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "S1xWh1rYwB", "replyto": "S1xWh1rYwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795706334, "tmdate": 1576800254359, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1940/-/Decision"}}}, {"id": "S1xbOKTJ9S", "original": null, "number": 3, "cdate": 1571965288851, "ddate": null, "tcdate": 1571965288851, "tmdate": 1575302442198, "tddate": null, "forum": "S1xWh1rYwB", "replyto": "S1xWh1rYwB", "invitation": "ICLR.cc/2020/Conference/Paper1940/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "8: Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #1", "review": "\nSummary\n---\n\n(motivation)\nLots of methods produce attribution maps (heat maps, saliency maps, visual explantions) that aim to highlight input regions with respect to a given CNN.\nThese methods produce scores that highlight regions that are in a vague sense \"important.\"\nWhile that's useful (relative importance is interesting), the scores don't mean anything by themselves.\nThis paper introduces another new attribution method that measures the amount of information (in bits!) each input region contains, calibrating this score by providing a reference point at 0 bits.\nNon-highlighted regions contribute 0 bits of information to the task, so they are clearly irrelevant in the common sense that they have 0 mutual information with the correct output.\n\n(approach - attribution methods)\nAn information bottleneck is introduced by replacing a layer's (e.g., conv2) output X with a noisy version Z of that output.\nIn particular, Z is a convex combination of the feature map (e.g., conv2) with Gaussian noise with the same mean and variance as that feature map.\nThe weights of the combination are found so they minimize the information shared between the input and Z and maxmimize information shared between Z and the task output Y.\nThese weights are either optimized on\n1) a per-image basis (Per-Sample) or\n2) predicted by a model trained on the entire dataset (Readout).\n\n(approach - evaluation)\nThe paper uses 3 metrics with differing degrees of novelty:\n1) The bbox metric rewards attribution methods that put a lot of mass in ground truth bounding boxes.\n2) The original Sensitivity-n metric from (Ancona et al. 2017) is reported with a version that uses 8x8 occlusions.\n3) Least relevant image degredation is compared to most relevant image degredation (e.g., from (Ancona et al. 2017)) to form a new occlusion style metric.\n\n(experiments)\nExperiments consider many of the most popular baselines, including Occlusion, Gradients, SmoothGrad, Integrated Gradients, GuidedBP, LRP, Grad-CAM, and Pattern Attribution. They show:\n1) Qualitatively, the visualizations highlight only regions that seem relevant.\n2) Both Per-Sample and Readout approaches put higher confidence into ground truth bounding boxes than all other baselines.\n3) Both Per-Sample and Readout approaches outperform all baselines almost all the time according to the new image degredation metric.\n\n\nStrengths\n---\n\nThe idea makes a lot of sense. I think heat maps are often thought of in terms of the colloquial sense of information, so it makes sense to formalize that intuition.\n\nThe related work section is very well done. The first paragraph is particularly good because it gives not just a fairly comprehensive view of attribution methods, but also because it efficiently describes how they all work.\n\nThe results show that proposed approaches clearly outperform many strong baselines across different metrics most of the time.\n\n\nWeaknesses\n---\n\n\n* I'm not sure why the new degredation metric is a useful addition. What does it add that MoRF and LeRF don't capture on their own independently?\n\n* I think [1] would be a nice addition to the evaluation section as it tests for something qualitatively different than the various metrics from section 4. It would also be a good addition to the related work.\n\n\nMissing Details / Points of Confusion\n---\n\n* I think there's an extra p(x) in eq. 11 in appendix D.\n\n* I think the variable X is overloaded. In eq. 1 it refers to the input (e.g., the pixels of an image) while in eq. 2 it refers to an intermediate feature map (e.g., conv2) even though it later seems to refer to the input again (e.g., eq. 3). Different notation should be used for intermediate feature maps and inputs.\n\n\nPresentation Weaknesses\n---\n\n* In section 3.1 is lambda meant to be constrained in the range [0, 1]? This is only mentioned later (section 3.2) and should probably be mentioned when lambda is introduced.\n\n* \"indicating that all negative evidence was removed.\" I think this should read \"indicating that only negative evidence was removed.\"\n\n\nSuggestions\n---\n\n\"The bottleneck is inserted into an early layer to ensure that the information in the network is still local\"\nI'd like this to be explored a bit more. Though deeper feature maps are certainly more spatially coarse they still might be somewhat \"local\". To what degree to they loose localization information? My equally vague alternative intuition goes a bit differently: The amount of relevant information flowing through any spatial location seems like it shouldn't change that much, only the way its represented should change. If the proposed visualizations were the same for every choice of layer then it would confirm this intuition. That would also be an interesting result because most if not all of the cited baseline approaches (where applicable) produce qualitatively different attributions at different layers (e.g., see Grad-CAM).\n\n\n[1]: Adebayo, Julius et al. \u201cSanity Checks for Saliency Maps.\u201d NeurIPS (2018).\n\n\nPreliminary Evaluation\n---\n\nClarity: The paper is clearly written.\nOriginality: The idea of using the formal notion of information in attribution maps is novel, as is the bbox metric.\nSignificance: This method could be quite significant. I can see it becoming an important method to compare to.\nQuality: The idea is sound and the evaluation is strong.\n\nThis is a very nice paper in all the ways listed above and it should be accepted!\n\nPost-rebuttal comments\n---\n\nThe author responses and other reviews have only increased my confidence that this paper should be accepted.\n\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"}, "signatures": ["ICLR.cc/2020/Conference/Paper1940/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1940/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["karl.schulz@tum.de", "leon.sixt@fu-berlin.de", "tombari@in.tum.de", "tim.landgraf@fu-berlin.de"], "title": "Restricting the Flow: Information Bottlenecks for Attribution", "authors": ["Karl Schulz", "Leon Sixt", "Federico Tombari", "Tim Landgraf"], "pdf": "/pdf/fa83870e660a55419088e307e2571dfea2df9116.pdf", "TL;DR": "We apply the informational bottleneck concept to attribution.", "abstract": "Attribution methods provide insights into the decision-making of machine learning models like artificial neural networks. For a given input sample, they assign a relevance score to each individual input variable, such as the pixels of an image. In this work, we adopt the information bottleneck concept for attribution. By adding noise to intermediate feature maps, we restrict the flow of information and can quantify (in bits) how much information image regions provide. We compare our method against ten baselines using three different metrics on VGG-16 and ResNet-50, and find that our methods outperform all baselines in five out of six settings. The method\u2019s information-theoretic foundation provides an absolute frame of reference for attribution values (bits) and a guarantee that regions scored close to zero are not necessary for the network's decision. ", "code": "https://github.com/BioroboticsLab/IBA-paper-code", "keywords": ["Attribution", "Informational Bottleneck", "Interpretable Machine Learning", "Explainable AI"], "paperhash": "schulz|restricting_the_flow_information_bottlenecks_for_attribution", "_bibtex": "@inproceedings{\nSchulz2020Restricting,\ntitle={Restricting the Flow: Information Bottlenecks for Attribution},\nauthor={Karl Schulz and Leon Sixt and Federico Tombari and Tim Landgraf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1xWh1rYwB}\n}", "original_pdf": "/attachment/bfcda49c9992f8979d9cc88da9dbc91396bff625.pdf"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "S1xWh1rYwB", "replyto": "S1xWh1rYwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1940/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1940/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575865952333, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1940/Reviewers"], "noninvitees": [], "tcdate": 1570237730086, "tmdate": 1575865952353, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1940/-/Official_Review"}}}, {"id": "BJeXnpJAKB", "original": null, "number": 2, "cdate": 1571843499421, "ddate": null, "tcdate": 1571843499421, "tmdate": 1574479839598, "tddate": null, "forum": "S1xWh1rYwB", "replyto": "S1xWh1rYwB", "invitation": "ICLR.cc/2020/Conference/Paper1940/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #3", "review": "This paper presents an information-bottleneck-based approach to infer the regions/pixels that are most relevant to the output. For all the metrics listed in the paper, the proposed approaches all achieve very good performance. It turns out, the proposed two architectures are better (at least alternative) choices to the other existing attribution methods.\n\nI do agree that the proposed two models (Per-Sample and Readout) can be used to roughly infer regions of interest, which has been strongly supported by the comprehensive experiments. To minimize equation (6), we need to make beta*L_I small. Minimizing L_{CE} in (6) tries to maximize the mutual information between Z and output (labels); while minimizing L_I with respect to weight beta would try to inject noise to each dimension of Z. However, L_{CE} needs to ensure it can get enough information for prediction, and thus would prevent the noise injection process for \u201cthe key regions\u201d. By choosing reasonable beta (similar to variational information bottleneck), the proposed approaches are capable to highlight key regions used for prediction.\n\nOverall, I think the method is elegant for approximately estimating the relevance score map.\nBelow are some of my (minor) questions/concerns:\n\n1. What we learned = What we want?\nThe proposed approach seeks a sort of \u201csparse heatmap\u201d. \nThe larger the beta, the more regions/pixels would be suppressed while smaller beta might fail to suppress non-important regions in the image.\nIn the paper, the beta used for calculating the per-sample bottleneck is among [100/k , 10/k, 1/k].\nThe beta for ReadOut bottleneck is 10/k.\nHowever, according to Table 1, only when beta is smaller than 1/k, the accuracy of the model does not degrade too much. \nWhen using beta=10/k to get the \"heat map\" (where 10/k is the best choice of per-smaple bottleneck for degradation task), how close is the \"heat map in beta=10/k\" to the \"ground-truth heatmap\"?\nTo better understand the proposed methods, I have a small suggestion:\n------ Try betas in a broader range including very small betas, e.g. [0.0001/k, 0.001/k,....,1/k,10/k], for both Table one and visualization. \nFix a few images and visualize the heatmap given different betas.\nWe might better see how the growth of beta changes the heatmap.\n\n2. About zero-valued attributions.\nI agree with you that equation (5) is an upper bound of MI (eq (4)).\nHowever, I am not sure if I totally agree with the claim \"If L_1 is zero for an area, we can guarantee that no information from this area is used for prediction.\"\n----- Given L_1=0 really implies that no information of the corresponding region is used for the certain beta, but is this true for the original model (beta=0)? Table one shows that different beta would lead to very different downstream task accuracy.\n\n3. Specific to the two approaches you proposed, can you explain/motivate in what situations per-sample bottle would be better and in what cases we should prefer ReadOut bottleneck?\n\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"}, "signatures": ["ICLR.cc/2020/Conference/Paper1940/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1940/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["karl.schulz@tum.de", "leon.sixt@fu-berlin.de", "tombari@in.tum.de", "tim.landgraf@fu-berlin.de"], "title": "Restricting the Flow: Information Bottlenecks for Attribution", "authors": ["Karl Schulz", "Leon Sixt", "Federico Tombari", "Tim Landgraf"], "pdf": "/pdf/fa83870e660a55419088e307e2571dfea2df9116.pdf", "TL;DR": "We apply the informational bottleneck concept to attribution.", "abstract": "Attribution methods provide insights into the decision-making of machine learning models like artificial neural networks. For a given input sample, they assign a relevance score to each individual input variable, such as the pixels of an image. In this work, we adopt the information bottleneck concept for attribution. By adding noise to intermediate feature maps, we restrict the flow of information and can quantify (in bits) how much information image regions provide. We compare our method against ten baselines using three different metrics on VGG-16 and ResNet-50, and find that our methods outperform all baselines in five out of six settings. The method\u2019s information-theoretic foundation provides an absolute frame of reference for attribution values (bits) and a guarantee that regions scored close to zero are not necessary for the network's decision. ", "code": "https://github.com/BioroboticsLab/IBA-paper-code", "keywords": ["Attribution", "Informational Bottleneck", "Interpretable Machine Learning", "Explainable AI"], "paperhash": "schulz|restricting_the_flow_information_bottlenecks_for_attribution", "_bibtex": "@inproceedings{\nSchulz2020Restricting,\ntitle={Restricting the Flow: Information Bottlenecks for Attribution},\nauthor={Karl Schulz and Leon Sixt and Federico Tombari and Tim Landgraf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1xWh1rYwB}\n}", "original_pdf": "/attachment/bfcda49c9992f8979d9cc88da9dbc91396bff625.pdf"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "S1xWh1rYwB", "replyto": "S1xWh1rYwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1940/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1940/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575865952333, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1940/Reviewers"], "noninvitees": [], "tcdate": 1570237730086, "tmdate": 1575865952353, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1940/-/Official_Review"}}}, {"id": "r1xdC7Dnjr", "original": null, "number": 6, "cdate": 1573839824441, "ddate": null, "tcdate": 1573839824441, "tmdate": 1573839837220, "tddate": null, "forum": "S1xWh1rYwB", "replyto": "BJxHG52nFB", "invitation": "ICLR.cc/2020/Conference/Paper1940/-/Official_Comment", "content": {"title": "Response to Review 2", "comment": "Thank you very much for your extensive and helpful comments. We addressed changes in the paper in a general comment. Concerning your specific comments:\n\n> [...]Some of the design- and implementation-choices needed to render the intractable info bottleneck objective tractable could perhaps be discussed and potentially even improved in light of recent results in other fields (Bayesian DL, deep latent-variable generative models, and variational methods for deep neural network compression),[...]\n\nYes, a more complex variational approximation of Q(Z) could make our approximation of the mutual information even more accurate. As a simple normal distribution already yielded good results, we did not further explore this direction. However, it would be an interesting subject for future work.\n\n> A short section of current shortcomings/limitations could be added to the discussion.\n\nWe agree! We added the following paragraph to the conclusion stating the following limitations:\n\nGenerally, we would advise to use the Per-Sample Bottleneck over the Readout Bottleneck. It performs better and is more flexible as it only requires to estimate the mean and variance of the feature map. The Readout Bottleneck has the advantage of producing attribution maps with a single forward pass once trained. Images with multiple object instances provide the network with redundant class information. The Per-Sample Bottleneck may therefore discard some of the class evidence. Even for single object instances, the heatmaps of the Per-Sample Bottleneck may vary slightly due to the randomness of the optimization process.\n\n\n> II) Perturbation-based approaches that inject noise (into the input image directly) have been proposed previously. Most notably: Visualizing and Understanding Atari Agents, Greydanus et al. 2018 and potentially follow-up citations. It would be interesting to compare both works empirically, but perhaps also theoretically/conceptually. Could the Greydanus work be related to applying the noise directly to the input image along with some additional constraints?\n\nThank you for the suggestion! Greydanus et al. blurs parts of the input images and then measures the drop in the output of the policy network and the value function. We think this method could be seen as an extension of Occlusion. Instead of setting image patches to zero, they are blurred, effectively removing high-frequency image information. Greydanus et. al do not apply noise to the input image and they also do not optimize the amount of blur. We cited the work as an Occlusion type method. We have searched the follow-up citations, but were not able to find any methods that apply noise for attribution purposes. \n\n> Is there a particular reason for this choice of colormap? While it seems to be roughly perceptually uniform (which is of course good), why not choose a simple sequential colormap (instead of a rainbow-like one)? At least the use of red and green at the same time should rather be avoided to maximize colormap readability under the most common forms of color vision deficiencies.\n\nWe share your concerns and updated the colormap to red for positive attribution and blue for negative attribution.\n\n> Just a pointer - no need to act on this for the current paper. Large parts of the field of neural network compression are concerned with a similar kind of attribution - the question is which weights/neurons/filters are relevant and which ones are not and can thus be removed from the network without loss in accuracy. Information-bottleneck style objectives (or the closely related ELBO / variational free energy) in conjunction with sparsity inducing priors have been proven to be quite fruitful. See e.g. Variational Dropout Sparsifies Deep Neural Networks, Molchanov et al. 2017 for interesting work, that aims at learning the variance of Gaussian noise that is injected into neural network weights using a similar construction and variational objective as shown in this paper. Perhaps some ideas can be borrowed/translated for future, improved versions of the method from that body of literature (Molchanov 2017, but also more sophisticated follow-up work).\n\nIndeed, there exist interesting parallels to neural network compression. We agree that both areas could enrich each other. Thanks for pointing this out!\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1940/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1940/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["karl.schulz@tum.de", "leon.sixt@fu-berlin.de", "tombari@in.tum.de", "tim.landgraf@fu-berlin.de"], "title": "Restricting the Flow: Information Bottlenecks for Attribution", "authors": ["Karl Schulz", "Leon Sixt", "Federico Tombari", "Tim Landgraf"], "pdf": "/pdf/fa83870e660a55419088e307e2571dfea2df9116.pdf", "TL;DR": "We apply the informational bottleneck concept to attribution.", "abstract": "Attribution methods provide insights into the decision-making of machine learning models like artificial neural networks. For a given input sample, they assign a relevance score to each individual input variable, such as the pixels of an image. In this work, we adopt the information bottleneck concept for attribution. By adding noise to intermediate feature maps, we restrict the flow of information and can quantify (in bits) how much information image regions provide. We compare our method against ten baselines using three different metrics on VGG-16 and ResNet-50, and find that our methods outperform all baselines in five out of six settings. The method\u2019s information-theoretic foundation provides an absolute frame of reference for attribution values (bits) and a guarantee that regions scored close to zero are not necessary for the network's decision. ", "code": "https://github.com/BioroboticsLab/IBA-paper-code", "keywords": ["Attribution", "Informational Bottleneck", "Interpretable Machine Learning", "Explainable AI"], "paperhash": "schulz|restricting_the_flow_information_bottlenecks_for_attribution", "_bibtex": "@inproceedings{\nSchulz2020Restricting,\ntitle={Restricting the Flow: Information Bottlenecks for Attribution},\nauthor={Karl Schulz and Leon Sixt and Federico Tombari and Tim Landgraf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1xWh1rYwB}\n}", "original_pdf": "/attachment/bfcda49c9992f8979d9cc88da9dbc91396bff625.pdf"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1xWh1rYwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1940/Authors", "ICLR.cc/2020/Conference/Paper1940/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1940/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1940/Reviewers", "ICLR.cc/2020/Conference/Paper1940/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1940/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1940/Authors|ICLR.cc/2020/Conference/Paper1940/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504148658, "tmdate": 1576860528572, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1940/Authors", "ICLR.cc/2020/Conference/Paper1940/Reviewers", "ICLR.cc/2020/Conference/Paper1940/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1940/-/Official_Comment"}}}, {"id": "H1eii7P2jr", "original": null, "number": 5, "cdate": 1573839779331, "ddate": null, "tcdate": 1573839779331, "tmdate": 1573839779331, "tddate": null, "forum": "S1xWh1rYwB", "replyto": "BJeXnpJAKB", "invitation": "ICLR.cc/2020/Conference/Paper1940/-/Official_Comment", "content": {"title": "Response to Review 3", "comment": "Thank you very much for your comments. We addressed the majority of changes to the paper in a general response. Concerning your specific comments:\n\n> \u201cHow close is the \"heat map in beta=10/k\" to the \"ground-truth heatmap\"?\u201d\n\nIt is not clear to us what you mean by \u201cground-truth heatmap\u201d. There is no human-labeled set of heatmaps available to evaluate attribution methods. To evaluate how well the attribution mass is localized, we used the \u201ebbox\u201c metric which calculates the proportion of most relevant scores falling within the object\u2018s bounding box. Thus, we use the bounding box labels as ground-truth proxy for localization performance, and we find that beta=10/k performs best: For the ResNet-50, on average 62 % of the highest attribution values are contained in the respective bounding box which is 15.2% higher than the best baseline.\n\n\n> However, according to Table 1, only when beta is smaller than 1/k, the accuracy of the model does not degrade too much. \n> Try betas in a broader range including very small betas, e.g. [0.0001/k, 0.001/k,....,1/k,10/k], for both Table one and visualization.\n \nWe agree with your suggestion and added a comparison of heatmaps for beta values from 0.1/k to 1000/k in a new figure (fig. 4). We found that beta = 0.1/k resulted in more information flowing through the network and producing more vague heatmaps. For beta = 1000/k, heatmaps are uniform with very low values (< 0.1 bits / pixel) meaning almost all information is discarded. \nWe updated table 1 to also include the Per-Sample Bottleneck. \n\n> However, I am not sure if I totally agree with the claim \"If L_1 is zero for an area, we can guarantee that no information from this area is used for prediction.\"\n----- Given L_1=0 really implies that no information of the corresponding region is used for the certain beta, but is this true for the original model (beta=0)? Table one shows that different beta would lead to very different downstream task accuracy.\n\nWe agree that that sentence could be clearer. In the introduction, we already described it clearer: \u201c[..] areas scored irrelevant are indeed not necessary for the network's prediction.\u201d We incorporated your feedback and changed the sentence to:  \u201cIf L_I is zero for an area, we can guarantee that information from this area is not necessary for the network's prediction. Information from this area might still be used when no noise is added.\u201d \n\n> Specific to the two approaches you proposed, can you explain/motivate in what situations per-sample bottle would be better and in what cases we should prefer ReadOut bottleneck?\n\nWe addressed the issues you raised, added additional content (stimulated by the other two reviewers) and hope you agree we have significantly improved the manuscript. We would appreciate if our efforts would be rewarded with an updated rating of \u201cAccept\u201d. Thank you!\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1940/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1940/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["karl.schulz@tum.de", "leon.sixt@fu-berlin.de", "tombari@in.tum.de", "tim.landgraf@fu-berlin.de"], "title": "Restricting the Flow: Information Bottlenecks for Attribution", "authors": ["Karl Schulz", "Leon Sixt", "Federico Tombari", "Tim Landgraf"], "pdf": "/pdf/fa83870e660a55419088e307e2571dfea2df9116.pdf", "TL;DR": "We apply the informational bottleneck concept to attribution.", "abstract": "Attribution methods provide insights into the decision-making of machine learning models like artificial neural networks. For a given input sample, they assign a relevance score to each individual input variable, such as the pixels of an image. In this work, we adopt the information bottleneck concept for attribution. By adding noise to intermediate feature maps, we restrict the flow of information and can quantify (in bits) how much information image regions provide. We compare our method against ten baselines using three different metrics on VGG-16 and ResNet-50, and find that our methods outperform all baselines in five out of six settings. The method\u2019s information-theoretic foundation provides an absolute frame of reference for attribution values (bits) and a guarantee that regions scored close to zero are not necessary for the network's decision. ", "code": "https://github.com/BioroboticsLab/IBA-paper-code", "keywords": ["Attribution", "Informational Bottleneck", "Interpretable Machine Learning", "Explainable AI"], "paperhash": "schulz|restricting_the_flow_information_bottlenecks_for_attribution", "_bibtex": "@inproceedings{\nSchulz2020Restricting,\ntitle={Restricting the Flow: Information Bottlenecks for Attribution},\nauthor={Karl Schulz and Leon Sixt and Federico Tombari and Tim Landgraf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1xWh1rYwB}\n}", "original_pdf": "/attachment/bfcda49c9992f8979d9cc88da9dbc91396bff625.pdf"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1xWh1rYwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1940/Authors", "ICLR.cc/2020/Conference/Paper1940/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1940/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1940/Reviewers", "ICLR.cc/2020/Conference/Paper1940/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1940/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1940/Authors|ICLR.cc/2020/Conference/Paper1940/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504148658, "tmdate": 1576860528572, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1940/Authors", "ICLR.cc/2020/Conference/Paper1940/Reviewers", "ICLR.cc/2020/Conference/Paper1940/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1940/-/Official_Comment"}}}, {"id": "ryx1P7wnsB", "original": null, "number": 4, "cdate": 1573839702650, "ddate": null, "tcdate": 1573839702650, "tmdate": 1573839702650, "tddate": null, "forum": "S1xWh1rYwB", "replyto": "S1xbOKTJ9S", "invitation": "ICLR.cc/2020/Conference/Paper1940/-/Official_Comment", "content": {"title": "Response to Review 1", "comment": "Thank you for your extensive and helpful comments and thorough review of the paper. We summarized our modifications in a general comment. We respond inline to your specific comments:\n\n> I'm not sure why the new degradation metric is a useful addition. What does it add that MoRF and LeRF don't capture on their own independently?\n\nWe agree that the integral between MoRF and LeRF does not capture anything not already implicitly contained in the MoRF and LeRF curves. However, when comparing different MoRF or LeRF curves visually, it is not always obvious which method performs better overall, as the paths may intersect (see Appendix G). Calculating the integral between the MoRF and LeRF paths yields a single scalar, which is directly comparable and while capturing the objective to perform well in both the MoRF and LeRF task. \n\n> I think [1] would be a nice addition to the evaluation section as it tests for something qualitatively different than the various metrics from section 4. It would also be a good addition to the related work.\n\nThanks for pointing it out to us. We added the weight randomization sanity check [1] to the evaluation section and compare our method to the others. \n\nRegarding your minor comments / presentation issues:\n* we removed the p(x) in eq. 11. \n* we now mention the range of lambda when it is introduced \n* we introduced a new variable R to denote intermediate feature maps\n\n> \"indicating that all negative evidence was removed.\" I think this should read \"indicating that only negative evidence was removed.\"\n\nThank you, we updated the paper accordingly.\n\n> \"The bottleneck is inserted into an early layer to ensure that the information in the network is still local\". I'd like this to be explored a bit more. Though deeper feature maps are certainly more spatially coarse they still might be somewhat \"local\". To what degree to they loose localization information? My equally vague alternative intuition goes a bit differently: The amount of relevant information flowing through any spatial location seems like it shouldn't change that much, only the way its represented should change. If the proposed visualizations were the same for every choice of layer then it would confirm this intuition. That would also be an interesting result because most if not all of the cited baseline approaches (where applicable) produce qualitatively different attributions at different layers (e.g., see Grad-CAM).\n\nThis is indeed an interesting question and we included a new figure which compares different layer depths. The figure backs your intuition that the spatial locations of important features should remain approximately the same. However, deeper layers have larger FOVs, so that the representations are not guaranteed to stay in the exact spatial location. Deeper layers also have drastically smaller spatial resolution, limiting the resolution of the heatmap. For very early layers, the heatmaps are sparser. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1940/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1940/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["karl.schulz@tum.de", "leon.sixt@fu-berlin.de", "tombari@in.tum.de", "tim.landgraf@fu-berlin.de"], "title": "Restricting the Flow: Information Bottlenecks for Attribution", "authors": ["Karl Schulz", "Leon Sixt", "Federico Tombari", "Tim Landgraf"], "pdf": "/pdf/fa83870e660a55419088e307e2571dfea2df9116.pdf", "TL;DR": "We apply the informational bottleneck concept to attribution.", "abstract": "Attribution methods provide insights into the decision-making of machine learning models like artificial neural networks. For a given input sample, they assign a relevance score to each individual input variable, such as the pixels of an image. In this work, we adopt the information bottleneck concept for attribution. By adding noise to intermediate feature maps, we restrict the flow of information and can quantify (in bits) how much information image regions provide. We compare our method against ten baselines using three different metrics on VGG-16 and ResNet-50, and find that our methods outperform all baselines in five out of six settings. The method\u2019s information-theoretic foundation provides an absolute frame of reference for attribution values (bits) and a guarantee that regions scored close to zero are not necessary for the network's decision. ", "code": "https://github.com/BioroboticsLab/IBA-paper-code", "keywords": ["Attribution", "Informational Bottleneck", "Interpretable Machine Learning", "Explainable AI"], "paperhash": "schulz|restricting_the_flow_information_bottlenecks_for_attribution", "_bibtex": "@inproceedings{\nSchulz2020Restricting,\ntitle={Restricting the Flow: Information Bottlenecks for Attribution},\nauthor={Karl Schulz and Leon Sixt and Federico Tombari and Tim Landgraf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1xWh1rYwB}\n}", "original_pdf": "/attachment/bfcda49c9992f8979d9cc88da9dbc91396bff625.pdf"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1xWh1rYwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1940/Authors", "ICLR.cc/2020/Conference/Paper1940/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1940/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1940/Reviewers", "ICLR.cc/2020/Conference/Paper1940/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1940/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1940/Authors|ICLR.cc/2020/Conference/Paper1940/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504148658, "tmdate": 1576860528572, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1940/Authors", "ICLR.cc/2020/Conference/Paper1940/Reviewers", "ICLR.cc/2020/Conference/Paper1940/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1940/-/Official_Comment"}}}, {"id": "SyxnBRLhoB", "original": null, "number": 3, "cdate": 1573838404483, "ddate": null, "tcdate": 1573838404483, "tmdate": 1573838404483, "tddate": null, "forum": "S1xWh1rYwB", "replyto": "S1xWh1rYwB", "invitation": "ICLR.cc/2020/Conference/Paper1940/-/Official_Comment", "content": {"title": "General Response to the Reviews", "comment": "We want to thank the reviewers for the extensive feedback, their helpful comments, and suggestions. We appreciate the effort and time you invested very much! We respond to each review below individually. Here is a short summary of our improvements:\n\n* A new figure shows the effect of varying layer depth and varying values for beta\n* included Per-Sample Bottleneck to Table 1\n* we added \"sanity checks\" (Adebayo et. al, 2018) to our evaluation section \n* we fixed typos, integrated minor comments, and improved the presentation\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1940/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1940/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["karl.schulz@tum.de", "leon.sixt@fu-berlin.de", "tombari@in.tum.de", "tim.landgraf@fu-berlin.de"], "title": "Restricting the Flow: Information Bottlenecks for Attribution", "authors": ["Karl Schulz", "Leon Sixt", "Federico Tombari", "Tim Landgraf"], "pdf": "/pdf/fa83870e660a55419088e307e2571dfea2df9116.pdf", "TL;DR": "We apply the informational bottleneck concept to attribution.", "abstract": "Attribution methods provide insights into the decision-making of machine learning models like artificial neural networks. For a given input sample, they assign a relevance score to each individual input variable, such as the pixels of an image. In this work, we adopt the information bottleneck concept for attribution. By adding noise to intermediate feature maps, we restrict the flow of information and can quantify (in bits) how much information image regions provide. We compare our method against ten baselines using three different metrics on VGG-16 and ResNet-50, and find that our methods outperform all baselines in five out of six settings. The method\u2019s information-theoretic foundation provides an absolute frame of reference for attribution values (bits) and a guarantee that regions scored close to zero are not necessary for the network's decision. ", "code": "https://github.com/BioroboticsLab/IBA-paper-code", "keywords": ["Attribution", "Informational Bottleneck", "Interpretable Machine Learning", "Explainable AI"], "paperhash": "schulz|restricting_the_flow_information_bottlenecks_for_attribution", "_bibtex": "@inproceedings{\nSchulz2020Restricting,\ntitle={Restricting the Flow: Information Bottlenecks for Attribution},\nauthor={Karl Schulz and Leon Sixt and Federico Tombari and Tim Landgraf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1xWh1rYwB}\n}", "original_pdf": "/attachment/bfcda49c9992f8979d9cc88da9dbc91396bff625.pdf"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1xWh1rYwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1940/Authors", "ICLR.cc/2020/Conference/Paper1940/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1940/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1940/Reviewers", "ICLR.cc/2020/Conference/Paper1940/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1940/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1940/Authors|ICLR.cc/2020/Conference/Paper1940/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504148658, "tmdate": 1576860528572, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1940/Authors", "ICLR.cc/2020/Conference/Paper1940/Reviewers", "ICLR.cc/2020/Conference/Paper1940/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1940/-/Official_Comment"}}}, {"id": "BJxHG52nFB", "original": null, "number": 1, "cdate": 1571764749274, "ddate": null, "tcdate": 1571764749274, "tmdate": 1572972403926, "tddate": null, "forum": "S1xWh1rYwB", "replyto": "S1xWh1rYwB", "invitation": "ICLR.cc/2020/Conference/Paper1940/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary\nThe paper proposes a novel perturbation-based method for computing attribution/saliency maps for deep neural network based image classifiers. In contrast to most previous work on perturbation-based attribution, the paper proposes to inject carefully crafted noise into an early layer of the network. Importantly, the noise is chosen such that it optimizes an information-theoretically motivated objective (rate-distortion/info bottleneck) that ensures that decision-relevant signal is flowing while constraining the overall channel-capacity, such that decision-irrelevant signal is blocked from flowing. The flow of signal is controlled by the amount of noise injected, which translates into a certain amount of mutual information between input image regions and noisy activations/features. This mutual information can be visualized in the input image, but it also has a clear, quantitative meaning that is readily interpretable. The paper introduces two ways to construct the injected noise, based on the information bottleneck. Resulting attribution maps are computed and evaluated on VGG-16 and ResNet-50 (on ImageNet), and are compared against an impressive number of previously proposed attribution methods. Importantly, the paper uses three different quantitative measures to compare the quality of attribution maps. The proposed method performs well on all three measures.\n\nContributions\ni) Derivation of a novel method for constructing attribution maps. Importantly, the method is grounded on solid theoretical footing for extracting minimal relevant information (rate-distortion theory / information bottleneck method).\n\nii) Proposal of a novel quantitative measure to compare quality of pixel-level attribution maps in image classification, and extension of a previously reported method.\n\niii) Evaluation and comparison against a large body of state-of-the-art attribution methods.\n\nQuality, Clarity, Novelty, Impact\nThe paper is clear and well written, with a nice introduction to the information bottleneck method. Experiments are well described and hyper-parameter settings are given in the appendix. To the best of my knowledge, the proposed method is sufficiently novel and the application of the information bottleneck framework to pixel-level attribution has not been reported before. Some of the design- and implementation-choices needed to render the intractable info bottleneck objective tractable could perhaps be discussed and potentially even improved in light of recent results in other fields (Bayesian DL, deep latent-variable generative models, and variational methods for deep neural network compression), but I currently don\u2019t consider this a major issue. To me personally the work in convincing and mature enough to vote for acceptance - perhaps most importantly it lays important groundwork for important connections to the theory of relevant information and puts a lot of much needed emphasis on objective evaluation of attribution methods (i.e. without subjective visual judgement of saliency maps). My suggestions below are aimed at helping improve the paper even further.\n\n\nImprovements\nI) A short section of current shortcomings/limitations could be added to the discussion.\n\nII) Perturbation-based approaches that inject noise (into the input image directly) have been proposed previously. Most notably: Visualizing and Understanding Atari Agents, Greydanus et al. 2018 and potentially follow-up citations. It would be interesting to compare both works empirically, but perhaps also theoretically/conceptually. Could the Greydanus work be related to applying the noise directly to the input image along with some additional constraints?\n\n\nMinor Comments\na) Is there a particular reason for this choice of colormap? While it seems to be roughly perceptually uniform (which is of course good), why not choose a simple sequential colormap (instead of a rainbow-like one)? At least the use of red and green at the same time should rather be avoided to maximize colormap readability under the most common forms of color vision deficiencies.\n\nb) Just a pointer - no need to act on this for the current paper. Large parts of the field of neural network compression are concerned with a similar kind of attribution - the question is which weights/neurons/filters are relevant and which ones are not and can thus be removed from the network without loss in accuracy. Information-bottleneck style objectives (or the closely related ELBO / variational free energy) in conjunction with sparsity inducing priors have been proven to be quite fruitful. See e.g. Variational Dropout Sparsifies Deep Neural Networks, Molchanov et al. 2017 for interesting work, that aims at learning the variance of Gaussian noise that is injected into neural network weights using a similar construction and variational objective as shown in this paper. Perhaps some ideas can be borrowed/translated for future, improved versions of the method from that body of literature (Molchanov 2017, but also more sophisticated follow-up work)."}, "signatures": ["ICLR.cc/2020/Conference/Paper1940/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1940/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["karl.schulz@tum.de", "leon.sixt@fu-berlin.de", "tombari@in.tum.de", "tim.landgraf@fu-berlin.de"], "title": "Restricting the Flow: Information Bottlenecks for Attribution", "authors": ["Karl Schulz", "Leon Sixt", "Federico Tombari", "Tim Landgraf"], "pdf": "/pdf/fa83870e660a55419088e307e2571dfea2df9116.pdf", "TL;DR": "We apply the informational bottleneck concept to attribution.", "abstract": "Attribution methods provide insights into the decision-making of machine learning models like artificial neural networks. For a given input sample, they assign a relevance score to each individual input variable, such as the pixels of an image. In this work, we adopt the information bottleneck concept for attribution. By adding noise to intermediate feature maps, we restrict the flow of information and can quantify (in bits) how much information image regions provide. We compare our method against ten baselines using three different metrics on VGG-16 and ResNet-50, and find that our methods outperform all baselines in five out of six settings. The method\u2019s information-theoretic foundation provides an absolute frame of reference for attribution values (bits) and a guarantee that regions scored close to zero are not necessary for the network's decision. ", "code": "https://github.com/BioroboticsLab/IBA-paper-code", "keywords": ["Attribution", "Informational Bottleneck", "Interpretable Machine Learning", "Explainable AI"], "paperhash": "schulz|restricting_the_flow_information_bottlenecks_for_attribution", "_bibtex": "@inproceedings{\nSchulz2020Restricting,\ntitle={Restricting the Flow: Information Bottlenecks for Attribution},\nauthor={Karl Schulz and Leon Sixt and Federico Tombari and Tim Landgraf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1xWh1rYwB}\n}", "original_pdf": "/attachment/bfcda49c9992f8979d9cc88da9dbc91396bff625.pdf"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "S1xWh1rYwB", "replyto": "S1xWh1rYwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1940/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1940/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575865952333, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1940/Reviewers"], "noninvitees": [], "tcdate": 1570237730086, "tmdate": 1575865952353, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1940/-/Official_Review"}}}, {"id": "BJgJBmM7YH", "original": null, "number": 1, "cdate": 1571132214902, "ddate": null, "tcdate": 1571132214902, "tmdate": 1571132214902, "tddate": null, "forum": "S1xWh1rYwB", "replyto": "S1xWh1rYwB", "invitation": "ICLR.cc/2020/Conference/Paper1940/-/Official_Comment", "content": {"comment": "Hello,\n\nwe found a bug in our code that had minor effects on our results.  When calculating the KL-divergence, we used \"log(s)\" instead of \"log(s**2)\" where \"s\" is the standard deviation. We re-run the evaluation and provide an screenshot of the updated results: https://gist.github.com/attribution-bottleneck/07ee0959bbd8b8ac36f9dba476301dd8 .\nThe degradation task for VGG is now also performed on the full ImageNet validation set and on 8x8 and 14x14 tiles. Using the correct log variance, we found that the Per-Sample bottleneck even improved a bit on the degradation task. We will update the paper once the rebuttal period starts.\n", "title": "bug with minor effects on the results"}, "signatures": ["ICLR.cc/2020/Conference/Paper1940/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1940/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["karl.schulz@tum.de", "leon.sixt@fu-berlin.de", "tombari@in.tum.de", "tim.landgraf@fu-berlin.de"], "title": "Restricting the Flow: Information Bottlenecks for Attribution", "authors": ["Karl Schulz", "Leon Sixt", "Federico Tombari", "Tim Landgraf"], "pdf": "/pdf/fa83870e660a55419088e307e2571dfea2df9116.pdf", "TL;DR": "We apply the informational bottleneck concept to attribution.", "abstract": "Attribution methods provide insights into the decision-making of machine learning models like artificial neural networks. For a given input sample, they assign a relevance score to each individual input variable, such as the pixels of an image. In this work, we adopt the information bottleneck concept for attribution. By adding noise to intermediate feature maps, we restrict the flow of information and can quantify (in bits) how much information image regions provide. We compare our method against ten baselines using three different metrics on VGG-16 and ResNet-50, and find that our methods outperform all baselines in five out of six settings. The method\u2019s information-theoretic foundation provides an absolute frame of reference for attribution values (bits) and a guarantee that regions scored close to zero are not necessary for the network's decision. ", "code": "https://github.com/BioroboticsLab/IBA-paper-code", "keywords": ["Attribution", "Informational Bottleneck", "Interpretable Machine Learning", "Explainable AI"], "paperhash": "schulz|restricting_the_flow_information_bottlenecks_for_attribution", "_bibtex": "@inproceedings{\nSchulz2020Restricting,\ntitle={Restricting the Flow: Information Bottlenecks for Attribution},\nauthor={Karl Schulz and Leon Sixt and Federico Tombari and Tim Landgraf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=S1xWh1rYwB}\n}", "original_pdf": "/attachment/bfcda49c9992f8979d9cc88da9dbc91396bff625.pdf"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1xWh1rYwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1940/Authors", "ICLR.cc/2020/Conference/Paper1940/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1940/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1940/Reviewers", "ICLR.cc/2020/Conference/Paper1940/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1940/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1940/Authors|ICLR.cc/2020/Conference/Paper1940/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504148658, "tmdate": 1576860528572, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1940/Authors", "ICLR.cc/2020/Conference/Paper1940/Reviewers", "ICLR.cc/2020/Conference/Paper1940/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1940/-/Official_Comment"}}}], "count": 14}