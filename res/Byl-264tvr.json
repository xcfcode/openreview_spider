{"notes": [{"id": "Xz5S9dWLUco", "original": null, "number": 7, "cdate": 1589397261863, "ddate": null, "tcdate": 1589397261863, "tmdate": 1589397261863, "tddate": null, "forum": "Byl-264tvr", "replyto": "Byl-264tvr", "invitation": "ICLR.cc/2020/Conference/Paper771/-/Official_Comment", "content": {"title": "Updated Paper", "comment": "We thank the area chair and the reviewers for their time, effort, and their constructive feedback. We used the feedback to update our paper in the following way: We specified our contributions and specifically pointed out the advantages of end-to-end tracking with an internal motion model and relational reasoning over classical methods. We also added references to Frossard & Urtasun as well as the most recent state-of-the-art visual object trackers.\n\nMost importantly, we added a quantitative comparison to state-of-the-art visual object trackers.\n\nThe new version can be found on arxive:\n\nhttps://arxiv.org/pdf/1907.12887.pdf"}, "signatures": ["ICLR.cc/2020/Conference/Paper771/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper771/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["fabian@robots.ox.ac.uk", "adamk@robots.ox.ac.uk", "kevin@robots.ox.ac.uk", "oiwi.parkerjones@jesus.ox.ac.uk", "ingmar@robots.ox.ac.uk"], "title": "Improving End-to-End Object Tracking Using Relational Reasoning", "authors": ["Fabian B. Fuchs", "Adam R. Kosiorek", "Li Sun", "Oiwi Parker Jones", "Ingmar Posner"], "pdf": "/pdf/5cc2ef797810bf0bf85f8f8f49bcf10f2defccb1.pdf", "TL;DR": "MOHART uses a self-attention mechanism to perform relational reasoning in multi-object tracking.", "abstract": "Relational reasoning, the ability to model interactions and relations between objects, is valuable for robust multi-object tracking and pivotal for trajectory prediction. In this paper, we propose MOHART, a class-agnostic, end-to-end multi-object tracking and trajectory prediction algorithm, which explicitly accounts for permutation invariance in its relational reasoning. We explore a number of permutation invariant architectures and show that multi-headed self-attention outperforms the provided baselines and better accounts for complex physical interactions in a challenging toy experiment. We show on three real-world tracking datasets that adding relational reasoning capabilities in this way increases the tracking and trajectory prediction performance, particularly in the presence of ego-motion, occlusions, crowded scenes, and faulty sensor inputs. To the best of our knowledge, MOHART is the first fully end-to-end multi-object tracking from vision approach applied to real-world data reported in the literature. ", "keywords": ["Relational Reasoning", "Tracking", "Intuitive Physics", "Real-World Application", "Permutation Invariance"], "paperhash": "fuchs|improving_endtoend_object_tracking_using_relational_reasoning", "original_pdf": "/attachment/5cc2ef797810bf0bf85f8f8f49bcf10f2defccb1.pdf", "_bibtex": "@misc{\nfuchs2020improving,\ntitle={Improving End-to-End Object Tracking Using Relational Reasoning},\nauthor={Fabian B. Fuchs and Adam R. Kosiorek and Li Sun and Oiwi Parker Jones and Ingmar Posner},\nyear={2020},\nurl={https://openreview.net/forum?id=Byl-264tvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Byl-264tvr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper771/Authors", "ICLR.cc/2020/Conference/Paper771/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper771/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper771/Reviewers", "ICLR.cc/2020/Conference/Paper771/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper771/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper771/Authors|ICLR.cc/2020/Conference/Paper771/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504166472, "tmdate": 1576860532823, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper771/Authors", "ICLR.cc/2020/Conference/Paper771/Reviewers", "ICLR.cc/2020/Conference/Paper771/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper771/-/Official_Comment"}}}, {"id": "Byl-264tvr", "original": "B1gY-aJODH", "number": 771, "cdate": 1569439145131, "ddate": null, "tcdate": 1569439145131, "tmdate": 1577168286445, "tddate": null, "forum": "Byl-264tvr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["fabian@robots.ox.ac.uk", "adamk@robots.ox.ac.uk", "kevin@robots.ox.ac.uk", "oiwi.parkerjones@jesus.ox.ac.uk", "ingmar@robots.ox.ac.uk"], "title": "Improving End-to-End Object Tracking Using Relational Reasoning", "authors": ["Fabian B. Fuchs", "Adam R. Kosiorek", "Li Sun", "Oiwi Parker Jones", "Ingmar Posner"], "pdf": "/pdf/5cc2ef797810bf0bf85f8f8f49bcf10f2defccb1.pdf", "TL;DR": "MOHART uses a self-attention mechanism to perform relational reasoning in multi-object tracking.", "abstract": "Relational reasoning, the ability to model interactions and relations between objects, is valuable for robust multi-object tracking and pivotal for trajectory prediction. In this paper, we propose MOHART, a class-agnostic, end-to-end multi-object tracking and trajectory prediction algorithm, which explicitly accounts for permutation invariance in its relational reasoning. We explore a number of permutation invariant architectures and show that multi-headed self-attention outperforms the provided baselines and better accounts for complex physical interactions in a challenging toy experiment. We show on three real-world tracking datasets that adding relational reasoning capabilities in this way increases the tracking and trajectory prediction performance, particularly in the presence of ego-motion, occlusions, crowded scenes, and faulty sensor inputs. To the best of our knowledge, MOHART is the first fully end-to-end multi-object tracking from vision approach applied to real-world data reported in the literature. ", "keywords": ["Relational Reasoning", "Tracking", "Intuitive Physics", "Real-World Application", "Permutation Invariance"], "paperhash": "fuchs|improving_endtoend_object_tracking_using_relational_reasoning", "original_pdf": "/attachment/5cc2ef797810bf0bf85f8f8f49bcf10f2defccb1.pdf", "_bibtex": "@misc{\nfuchs2020improving,\ntitle={Improving End-to-End Object Tracking Using Relational Reasoning},\nauthor={Fabian B. Fuchs and Adam R. Kosiorek and Li Sun and Oiwi Parker Jones and Ingmar Posner},\nyear={2020},\nurl={https://openreview.net/forum?id=Byl-264tvr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "l5L_FQdEwO", "original": null, "number": 1, "cdate": 1576798705608, "ddate": null, "tcdate": 1576798705608, "tmdate": 1576800930524, "tddate": null, "forum": "Byl-264tvr", "replyto": "Byl-264tvr", "invitation": "ICLR.cc/2020/Conference/Paper771/-/Decision", "content": {"decision": "Reject", "comment": "The authors propose an end-to-end object tracker by exploiting the attention mechanism. Two reviewers recommend rejection, while the last reviewer is more positive. The concerns brought up are novelty (last reviewer), and experiments (second reviewer). Furthermore, the authors seem to overclaim their contribution. There indeed are end-to-end multi-object trackers, see Frossard & Urtasun's work for example. This work needs to be cited, and possibly a comparison is needed. Since the paper did not receive favourable reviews and there are additional citations missing, this paper cannot be accepted in current form. The authors are encouraged to strengthen their work and resubmit to a future venue.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["fabian@robots.ox.ac.uk", "adamk@robots.ox.ac.uk", "kevin@robots.ox.ac.uk", "oiwi.parkerjones@jesus.ox.ac.uk", "ingmar@robots.ox.ac.uk"], "title": "Improving End-to-End Object Tracking Using Relational Reasoning", "authors": ["Fabian B. Fuchs", "Adam R. Kosiorek", "Li Sun", "Oiwi Parker Jones", "Ingmar Posner"], "pdf": "/pdf/5cc2ef797810bf0bf85f8f8f49bcf10f2defccb1.pdf", "TL;DR": "MOHART uses a self-attention mechanism to perform relational reasoning in multi-object tracking.", "abstract": "Relational reasoning, the ability to model interactions and relations between objects, is valuable for robust multi-object tracking and pivotal for trajectory prediction. In this paper, we propose MOHART, a class-agnostic, end-to-end multi-object tracking and trajectory prediction algorithm, which explicitly accounts for permutation invariance in its relational reasoning. We explore a number of permutation invariant architectures and show that multi-headed self-attention outperforms the provided baselines and better accounts for complex physical interactions in a challenging toy experiment. We show on three real-world tracking datasets that adding relational reasoning capabilities in this way increases the tracking and trajectory prediction performance, particularly in the presence of ego-motion, occlusions, crowded scenes, and faulty sensor inputs. To the best of our knowledge, MOHART is the first fully end-to-end multi-object tracking from vision approach applied to real-world data reported in the literature. ", "keywords": ["Relational Reasoning", "Tracking", "Intuitive Physics", "Real-World Application", "Permutation Invariance"], "paperhash": "fuchs|improving_endtoend_object_tracking_using_relational_reasoning", "original_pdf": "/attachment/5cc2ef797810bf0bf85f8f8f49bcf10f2defccb1.pdf", "_bibtex": "@misc{\nfuchs2020improving,\ntitle={Improving End-to-End Object Tracking Using Relational Reasoning},\nauthor={Fabian B. Fuchs and Adam R. Kosiorek and Li Sun and Oiwi Parker Jones and Ingmar Posner},\nyear={2020},\nurl={https://openreview.net/forum?id=Byl-264tvr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "Byl-264tvr", "replyto": "Byl-264tvr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795728564, "tmdate": 1576800280997, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper771/-/Decision"}}}, {"id": "rJl6YjZhjB", "original": null, "number": 5, "cdate": 1573817221514, "ddate": null, "tcdate": 1573817221514, "tmdate": 1573817221514, "tddate": null, "forum": "Byl-264tvr", "replyto": "rJlOWZYujS", "invitation": "ICLR.cc/2020/Conference/Paper771/-/Official_Comment", "content": {"title": "Response to R1", "comment": "Couldn't agree more! :)"}, "signatures": ["ICLR.cc/2020/Conference/Paper771/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper771/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["fabian@robots.ox.ac.uk", "adamk@robots.ox.ac.uk", "kevin@robots.ox.ac.uk", "oiwi.parkerjones@jesus.ox.ac.uk", "ingmar@robots.ox.ac.uk"], "title": "Improving End-to-End Object Tracking Using Relational Reasoning", "authors": ["Fabian B. Fuchs", "Adam R. Kosiorek", "Li Sun", "Oiwi Parker Jones", "Ingmar Posner"], "pdf": "/pdf/5cc2ef797810bf0bf85f8f8f49bcf10f2defccb1.pdf", "TL;DR": "MOHART uses a self-attention mechanism to perform relational reasoning in multi-object tracking.", "abstract": "Relational reasoning, the ability to model interactions and relations between objects, is valuable for robust multi-object tracking and pivotal for trajectory prediction. In this paper, we propose MOHART, a class-agnostic, end-to-end multi-object tracking and trajectory prediction algorithm, which explicitly accounts for permutation invariance in its relational reasoning. We explore a number of permutation invariant architectures and show that multi-headed self-attention outperforms the provided baselines and better accounts for complex physical interactions in a challenging toy experiment. We show on three real-world tracking datasets that adding relational reasoning capabilities in this way increases the tracking and trajectory prediction performance, particularly in the presence of ego-motion, occlusions, crowded scenes, and faulty sensor inputs. To the best of our knowledge, MOHART is the first fully end-to-end multi-object tracking from vision approach applied to real-world data reported in the literature. ", "keywords": ["Relational Reasoning", "Tracking", "Intuitive Physics", "Real-World Application", "Permutation Invariance"], "paperhash": "fuchs|improving_endtoend_object_tracking_using_relational_reasoning", "original_pdf": "/attachment/5cc2ef797810bf0bf85f8f8f49bcf10f2defccb1.pdf", "_bibtex": "@misc{\nfuchs2020improving,\ntitle={Improving End-to-End Object Tracking Using Relational Reasoning},\nauthor={Fabian B. Fuchs and Adam R. Kosiorek and Li Sun and Oiwi Parker Jones and Ingmar Posner},\nyear={2020},\nurl={https://openreview.net/forum?id=Byl-264tvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Byl-264tvr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper771/Authors", "ICLR.cc/2020/Conference/Paper771/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper771/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper771/Reviewers", "ICLR.cc/2020/Conference/Paper771/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper771/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper771/Authors|ICLR.cc/2020/Conference/Paper771/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504166472, "tmdate": 1576860532823, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper771/Authors", "ICLR.cc/2020/Conference/Paper771/Reviewers", "ICLR.cc/2020/Conference/Paper771/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper771/-/Official_Comment"}}}, {"id": "rJlOWZYujS", "original": null, "number": 4, "cdate": 1573585152214, "ddate": null, "tcdate": 1573585152214, "tmdate": 1573585152214, "tddate": null, "forum": "Byl-264tvr", "replyto": "rkeGsCPuiB", "invitation": "ICLR.cc/2020/Conference/Paper771/-/Official_Comment", "content": {"title": "Response to authors", "comment": "Agreed re structural novelty. Also I actually meant to write \"The [architectural] novelty is\"... to be clear, I don't think we as a community should be optimizing for architectural novelty, which is part of the reason I voted to accept this paper. Good empirical evaluations of novel combinations of existing ideas are useful."}, "signatures": ["ICLR.cc/2020/Conference/Paper771/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper771/AnonReviewer1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["fabian@robots.ox.ac.uk", "adamk@robots.ox.ac.uk", "kevin@robots.ox.ac.uk", "oiwi.parkerjones@jesus.ox.ac.uk", "ingmar@robots.ox.ac.uk"], "title": "Improving End-to-End Object Tracking Using Relational Reasoning", "authors": ["Fabian B. Fuchs", "Adam R. Kosiorek", "Li Sun", "Oiwi Parker Jones", "Ingmar Posner"], "pdf": "/pdf/5cc2ef797810bf0bf85f8f8f49bcf10f2defccb1.pdf", "TL;DR": "MOHART uses a self-attention mechanism to perform relational reasoning in multi-object tracking.", "abstract": "Relational reasoning, the ability to model interactions and relations between objects, is valuable for robust multi-object tracking and pivotal for trajectory prediction. In this paper, we propose MOHART, a class-agnostic, end-to-end multi-object tracking and trajectory prediction algorithm, which explicitly accounts for permutation invariance in its relational reasoning. We explore a number of permutation invariant architectures and show that multi-headed self-attention outperforms the provided baselines and better accounts for complex physical interactions in a challenging toy experiment. We show on three real-world tracking datasets that adding relational reasoning capabilities in this way increases the tracking and trajectory prediction performance, particularly in the presence of ego-motion, occlusions, crowded scenes, and faulty sensor inputs. To the best of our knowledge, MOHART is the first fully end-to-end multi-object tracking from vision approach applied to real-world data reported in the literature. ", "keywords": ["Relational Reasoning", "Tracking", "Intuitive Physics", "Real-World Application", "Permutation Invariance"], "paperhash": "fuchs|improving_endtoend_object_tracking_using_relational_reasoning", "original_pdf": "/attachment/5cc2ef797810bf0bf85f8f8f49bcf10f2defccb1.pdf", "_bibtex": "@misc{\nfuchs2020improving,\ntitle={Improving End-to-End Object Tracking Using Relational Reasoning},\nauthor={Fabian B. Fuchs and Adam R. Kosiorek and Li Sun and Oiwi Parker Jones and Ingmar Posner},\nyear={2020},\nurl={https://openreview.net/forum?id=Byl-264tvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Byl-264tvr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper771/Authors", "ICLR.cc/2020/Conference/Paper771/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper771/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper771/Reviewers", "ICLR.cc/2020/Conference/Paper771/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper771/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper771/Authors|ICLR.cc/2020/Conference/Paper771/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504166472, "tmdate": 1576860532823, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper771/Authors", "ICLR.cc/2020/Conference/Paper771/Reviewers", "ICLR.cc/2020/Conference/Paper771/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper771/-/Official_Comment"}}}, {"id": "S1guPxOuor", "original": null, "number": 3, "cdate": 1573580896163, "ddate": null, "tcdate": 1573580896163, "tmdate": 1573580896163, "tddate": null, "forum": "Byl-264tvr", "replyto": "S1lqFdj0tS", "invitation": "ICLR.cc/2020/Conference/Paper771/-/Official_Comment", "content": {"title": "Response to R2", "comment": "1. \"It is not clear when the new architecture would be helpful. [\u2026] I think a more detailed study can be conducted, especially in the toy example case.  Maybe it is possible to design different levels of randomness in the trajectory and further figure out when is the reasoning block helpful.\"\n\nCould you please elaborate on what you mean by different levels of randomness? What you are describing sounds to us very similar to figure 4b: we vary the level of randomness (i.e. how often the electron/proton identity is randomly re-assigned). The experiments show that the higher the stochasticity, the more important the relational reasoning. In a fully deterministic version of this environment, where the forcefield can be inferred from the trajectory of one particle, relational reasoning is not necessary. We believe that this insight matches well with the results from the real-world experiments: e.g., camera ego-motion could be seen as a stochastic external factor, leading to bigger performance gains from relational reasoning.\n\nIf you had a different experiment in mind, we would be very curious to hear about your idea!\n\n2. \"Even the real data experiments do not have very impressive results, from my biased observation. (I am not in the field, so maybe I am wrong here.)\"\n\nWe personally do find of the real-world results \u2018impressive\u2019 (being fully aware of the subjectiveness of this statement), especially figures 5 and 9 where sensor input is only partially available. While no new sensor output is available (feeding just black frames to the model), the algorithm learns to fall back onto its internal motion model, predicting how the pedestrians walk. Once new sensor data is available, the model \u2018snaps back\u2019 onto the objects. This is learned fully end-to-end while not applying any algorithmic changes to MOHART compared to the vanilla tracking setup.\n\n3. \"The end-to-end approach is also another perspective where the authors try to differentiate their methods from others. I think it is potentially an interesting problem that why end-to-end is something you would prefer (which is definitely a harder problem), and when.\"\n\nThe strength of tracking-by-detection approaches lies in their rigidity because they can be carefully designed to fit the particular challenges of the problem. Particularly with known object classes and a plethora of training data the external object detector can provide a very strong starting point. End-to-end tracking, on the other hand, has the benefit of being very flexible: It can be applied to track any object class, even one that was never seen during training time. The algorithm also has the power of learning about a wide range of phenomena such as ego-motion and faulty sensor inputs (both of which particularly benefit from relational reasoning, as our experiments show).\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper771/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper771/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["fabian@robots.ox.ac.uk", "adamk@robots.ox.ac.uk", "kevin@robots.ox.ac.uk", "oiwi.parkerjones@jesus.ox.ac.uk", "ingmar@robots.ox.ac.uk"], "title": "Improving End-to-End Object Tracking Using Relational Reasoning", "authors": ["Fabian B. Fuchs", "Adam R. Kosiorek", "Li Sun", "Oiwi Parker Jones", "Ingmar Posner"], "pdf": "/pdf/5cc2ef797810bf0bf85f8f8f49bcf10f2defccb1.pdf", "TL;DR": "MOHART uses a self-attention mechanism to perform relational reasoning in multi-object tracking.", "abstract": "Relational reasoning, the ability to model interactions and relations between objects, is valuable for robust multi-object tracking and pivotal for trajectory prediction. In this paper, we propose MOHART, a class-agnostic, end-to-end multi-object tracking and trajectory prediction algorithm, which explicitly accounts for permutation invariance in its relational reasoning. We explore a number of permutation invariant architectures and show that multi-headed self-attention outperforms the provided baselines and better accounts for complex physical interactions in a challenging toy experiment. We show on three real-world tracking datasets that adding relational reasoning capabilities in this way increases the tracking and trajectory prediction performance, particularly in the presence of ego-motion, occlusions, crowded scenes, and faulty sensor inputs. To the best of our knowledge, MOHART is the first fully end-to-end multi-object tracking from vision approach applied to real-world data reported in the literature. ", "keywords": ["Relational Reasoning", "Tracking", "Intuitive Physics", "Real-World Application", "Permutation Invariance"], "paperhash": "fuchs|improving_endtoend_object_tracking_using_relational_reasoning", "original_pdf": "/attachment/5cc2ef797810bf0bf85f8f8f49bcf10f2defccb1.pdf", "_bibtex": "@misc{\nfuchs2020improving,\ntitle={Improving End-to-End Object Tracking Using Relational Reasoning},\nauthor={Fabian B. Fuchs and Adam R. Kosiorek and Li Sun and Oiwi Parker Jones and Ingmar Posner},\nyear={2020},\nurl={https://openreview.net/forum?id=Byl-264tvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Byl-264tvr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper771/Authors", "ICLR.cc/2020/Conference/Paper771/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper771/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper771/Reviewers", "ICLR.cc/2020/Conference/Paper771/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper771/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper771/Authors|ICLR.cc/2020/Conference/Paper771/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504166472, "tmdate": 1576860532823, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper771/Authors", "ICLR.cc/2020/Conference/Paper771/Reviewers", "ICLR.cc/2020/Conference/Paper771/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper771/-/Official_Comment"}}}, {"id": "BkltsJddiH", "original": null, "number": 2, "cdate": 1573580705214, "ddate": null, "tcdate": 1573580705214, "tmdate": 1573580705214, "tddate": null, "forum": "Byl-264tvr", "replyto": "S1xCmqbaFr", "invitation": "ICLR.cc/2020/Conference/Paper771/-/Official_Comment", "content": {"title": "Response to R3", "comment": "We are pleased that the author finds the idea neat and the findings of the paper enlightening.\n\nAs regards the comparison of MOHART to other SOTA approaches: while it is true that the field has evolved since the publication of HART, we are not aware of recent end-to-end tracking approaches for real-world data, and especially we were unable to find ones that track multiple objects at a time.\n\nWe note that it is not straight-forward to quantitatively compare the performance of (MO)HART and non-end2end methods such as tracking-by-detection algorithms. MOHART is evaluated with ground truth bounding boxes provided in the first video frame with all objects present. This evaluation paradigm is used, e.g., in the Visual Object Tracking Challenge (Kristan et al. 2016) where performance is reported as intersection over union. This dataset, however, contains only one annotated object per sequence and is unsuitable for multi-object tracking evaluation. We are not aware of any dataset or benchmark for multi-object tracking that would use a similar evaluation protocol. The MOTChallenge dataset, on the other hand, which contains many annotated objects per frame, is set up as a data association problem. Instead of ground truth bounding boxes in the first frame, the dataset provides (imperfect) detections for each individual frame. The goal of tracking-by-detection algorithms is to match the detections of the same object across frames. Algorithms typically applied to this dataset would have an unfair advantage over MOHART due to the access to external detections, and the results of such a comparison could be misleading for a potential reader.\n\nHaving said that, we do agree that having a broader comparison with other approaches would be helpful for the readers to better position MOHART within the existing literature. We are currently looking into possible datasets and baselines to provide further comparison.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper771/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper771/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["fabian@robots.ox.ac.uk", "adamk@robots.ox.ac.uk", "kevin@robots.ox.ac.uk", "oiwi.parkerjones@jesus.ox.ac.uk", "ingmar@robots.ox.ac.uk"], "title": "Improving End-to-End Object Tracking Using Relational Reasoning", "authors": ["Fabian B. Fuchs", "Adam R. Kosiorek", "Li Sun", "Oiwi Parker Jones", "Ingmar Posner"], "pdf": "/pdf/5cc2ef797810bf0bf85f8f8f49bcf10f2defccb1.pdf", "TL;DR": "MOHART uses a self-attention mechanism to perform relational reasoning in multi-object tracking.", "abstract": "Relational reasoning, the ability to model interactions and relations between objects, is valuable for robust multi-object tracking and pivotal for trajectory prediction. In this paper, we propose MOHART, a class-agnostic, end-to-end multi-object tracking and trajectory prediction algorithm, which explicitly accounts for permutation invariance in its relational reasoning. We explore a number of permutation invariant architectures and show that multi-headed self-attention outperforms the provided baselines and better accounts for complex physical interactions in a challenging toy experiment. We show on three real-world tracking datasets that adding relational reasoning capabilities in this way increases the tracking and trajectory prediction performance, particularly in the presence of ego-motion, occlusions, crowded scenes, and faulty sensor inputs. To the best of our knowledge, MOHART is the first fully end-to-end multi-object tracking from vision approach applied to real-world data reported in the literature. ", "keywords": ["Relational Reasoning", "Tracking", "Intuitive Physics", "Real-World Application", "Permutation Invariance"], "paperhash": "fuchs|improving_endtoend_object_tracking_using_relational_reasoning", "original_pdf": "/attachment/5cc2ef797810bf0bf85f8f8f49bcf10f2defccb1.pdf", "_bibtex": "@misc{\nfuchs2020improving,\ntitle={Improving End-to-End Object Tracking Using Relational Reasoning},\nauthor={Fabian B. Fuchs and Adam R. Kosiorek and Li Sun and Oiwi Parker Jones and Ingmar Posner},\nyear={2020},\nurl={https://openreview.net/forum?id=Byl-264tvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Byl-264tvr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper771/Authors", "ICLR.cc/2020/Conference/Paper771/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper771/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper771/Reviewers", "ICLR.cc/2020/Conference/Paper771/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper771/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper771/Authors|ICLR.cc/2020/Conference/Paper771/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504166472, "tmdate": 1576860532823, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper771/Authors", "ICLR.cc/2020/Conference/Paper771/Reviewers", "ICLR.cc/2020/Conference/Paper771/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper771/-/Official_Comment"}}}, {"id": "rkeGsCPuiB", "original": null, "number": 1, "cdate": 1573580441646, "ddate": null, "tcdate": 1573580441646, "tmdate": 1573580441646, "tddate": null, "forum": "Byl-264tvr", "replyto": "BkgBQO1aFH", "invitation": "ICLR.cc/2020/Conference/Paper771/-/Official_Comment", "content": {"title": "Response to R1", "comment": "We are delighted that the reviewer finds that the experiments and results are a worthwhile contribution to the ICLR community.\n\nAs regards the structural novelty, beyond the addition of the relational reasoning module, another structural contribution is the ability to track multiple objects in parallel. This is thanks to a new presence variable, which indicates whether an object is (still) in the scene. Beyond being useful as an output of the model, the ground-truth presence is also used for masking the training loss. We believe that the simplicity of using two well-understood components (HART end-to-end tracking and Transformer-based attention) with a clear objective (tracking with relational reasoning) is an advantage. The modularity of the relational reasoning component has the further benefit of being easily applicable to future generations of end-to-end tracking.\n\nThe reason that fixed repulsive forces are well-modeled by HART is its LSTM-based state estimation: since the forces change deterministically, a single LSTM cell can predict their evolution. We believe that performance gains from relational reasoning would be higher if HART used a weaker state-estimation mechanism. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper771/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper771/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["fabian@robots.ox.ac.uk", "adamk@robots.ox.ac.uk", "kevin@robots.ox.ac.uk", "oiwi.parkerjones@jesus.ox.ac.uk", "ingmar@robots.ox.ac.uk"], "title": "Improving End-to-End Object Tracking Using Relational Reasoning", "authors": ["Fabian B. Fuchs", "Adam R. Kosiorek", "Li Sun", "Oiwi Parker Jones", "Ingmar Posner"], "pdf": "/pdf/5cc2ef797810bf0bf85f8f8f49bcf10f2defccb1.pdf", "TL;DR": "MOHART uses a self-attention mechanism to perform relational reasoning in multi-object tracking.", "abstract": "Relational reasoning, the ability to model interactions and relations between objects, is valuable for robust multi-object tracking and pivotal for trajectory prediction. In this paper, we propose MOHART, a class-agnostic, end-to-end multi-object tracking and trajectory prediction algorithm, which explicitly accounts for permutation invariance in its relational reasoning. We explore a number of permutation invariant architectures and show that multi-headed self-attention outperforms the provided baselines and better accounts for complex physical interactions in a challenging toy experiment. We show on three real-world tracking datasets that adding relational reasoning capabilities in this way increases the tracking and trajectory prediction performance, particularly in the presence of ego-motion, occlusions, crowded scenes, and faulty sensor inputs. To the best of our knowledge, MOHART is the first fully end-to-end multi-object tracking from vision approach applied to real-world data reported in the literature. ", "keywords": ["Relational Reasoning", "Tracking", "Intuitive Physics", "Real-World Application", "Permutation Invariance"], "paperhash": "fuchs|improving_endtoend_object_tracking_using_relational_reasoning", "original_pdf": "/attachment/5cc2ef797810bf0bf85f8f8f49bcf10f2defccb1.pdf", "_bibtex": "@misc{\nfuchs2020improving,\ntitle={Improving End-to-End Object Tracking Using Relational Reasoning},\nauthor={Fabian B. Fuchs and Adam R. Kosiorek and Li Sun and Oiwi Parker Jones and Ingmar Posner},\nyear={2020},\nurl={https://openreview.net/forum?id=Byl-264tvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Byl-264tvr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper771/Authors", "ICLR.cc/2020/Conference/Paper771/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper771/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper771/Reviewers", "ICLR.cc/2020/Conference/Paper771/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper771/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper771/Authors|ICLR.cc/2020/Conference/Paper771/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504166472, "tmdate": 1576860532823, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper771/Authors", "ICLR.cc/2020/Conference/Paper771/Reviewers", "ICLR.cc/2020/Conference/Paper771/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper771/-/Official_Comment"}}}, {"id": "BkgBQO1aFH", "original": null, "number": 1, "cdate": 1571776540900, "ddate": null, "tcdate": 1571776540900, "tmdate": 1572972554332, "tddate": null, "forum": "Byl-264tvr", "replyto": "Byl-264tvr", "invitation": "ICLR.cc/2020/Conference/Paper771/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "I'm somewhat out of area for this review: I study relational models, but have little experience with computer vision in general and object tracking in particular. \n\n--------------------\n\nThis paper presents an extension to HART [Kosiorek 2017] to track multiple objects. It builds on a simple baseline: run multiple HART models in parallel, each tracking one of the objects. They extend this by adding a relational reasoning module to allow interaction between the parallel models. The relational reasoning module uses Lee et al. (2019)'s self-attention block (similar to Vaswani et al. 2017). They find that the simple baseline is surprisingly effective, but that MOHART (their model) improves performance in environments with stochastic interactions and crowded settings which tend to be more noisy.\n\nThe novelty is somewhat limited: they're plugging together two existing approaches (HART and SAB) to allow for interaction, but I am recommending acceptance because I found the experiments surprising (as a negative result) - they show that independent HART models are a strong baseline for tracking in settings that involve interactions, but that are nevertheless solvable without knowledge about the state of other objects. For the synthetic experiments, I would have expected the fact there are repulsive forces between the objects would have been sufficient for the relational module to be helpful. The paper also provides further evidence of the usefulness of non-local networks for these sorts of problems."}, "signatures": ["ICLR.cc/2020/Conference/Paper771/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper771/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["fabian@robots.ox.ac.uk", "adamk@robots.ox.ac.uk", "kevin@robots.ox.ac.uk", "oiwi.parkerjones@jesus.ox.ac.uk", "ingmar@robots.ox.ac.uk"], "title": "Improving End-to-End Object Tracking Using Relational Reasoning", "authors": ["Fabian B. Fuchs", "Adam R. Kosiorek", "Li Sun", "Oiwi Parker Jones", "Ingmar Posner"], "pdf": "/pdf/5cc2ef797810bf0bf85f8f8f49bcf10f2defccb1.pdf", "TL;DR": "MOHART uses a self-attention mechanism to perform relational reasoning in multi-object tracking.", "abstract": "Relational reasoning, the ability to model interactions and relations between objects, is valuable for robust multi-object tracking and pivotal for trajectory prediction. In this paper, we propose MOHART, a class-agnostic, end-to-end multi-object tracking and trajectory prediction algorithm, which explicitly accounts for permutation invariance in its relational reasoning. We explore a number of permutation invariant architectures and show that multi-headed self-attention outperforms the provided baselines and better accounts for complex physical interactions in a challenging toy experiment. We show on three real-world tracking datasets that adding relational reasoning capabilities in this way increases the tracking and trajectory prediction performance, particularly in the presence of ego-motion, occlusions, crowded scenes, and faulty sensor inputs. To the best of our knowledge, MOHART is the first fully end-to-end multi-object tracking from vision approach applied to real-world data reported in the literature. ", "keywords": ["Relational Reasoning", "Tracking", "Intuitive Physics", "Real-World Application", "Permutation Invariance"], "paperhash": "fuchs|improving_endtoend_object_tracking_using_relational_reasoning", "original_pdf": "/attachment/5cc2ef797810bf0bf85f8f8f49bcf10f2defccb1.pdf", "_bibtex": "@misc{\nfuchs2020improving,\ntitle={Improving End-to-End Object Tracking Using Relational Reasoning},\nauthor={Fabian B. Fuchs and Adam R. Kosiorek and Li Sun and Oiwi Parker Jones and Ingmar Posner},\nyear={2020},\nurl={https://openreview.net/forum?id=Byl-264tvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Byl-264tvr", "replyto": "Byl-264tvr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper771/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper771/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576105524842, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper771/Reviewers"], "noninvitees": [], "tcdate": 1570237747328, "tmdate": 1576105524857, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper771/-/Official_Review"}}}, {"id": "S1xCmqbaFr", "original": null, "number": 2, "cdate": 1571785254428, "ddate": null, "tcdate": 1571785254428, "tmdate": 1572972554289, "tddate": null, "forum": "Byl-264tvr", "replyto": "Byl-264tvr", "invitation": "ICLR.cc/2020/Conference/Paper771/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The paper presents a class-agnostic method for tracking multiple moving objects (MOHART) that extends an existing single-object tracking method (Hierarchical Attentive Recurrent Tracking, HART). Similarly to HART, MOHART utilizes an attention mechanism and LSTM units. The extension form HART to MOHART is done in two main steps: HART is applied to multiple objects in parallel, with a presence variable attached to each, and a permutation-invariant network that learns the interactions between the objects.\n\nThe method is tested in two groups of experiments: synthetic data of moving circles, and on several real datasets. The results on the moving circles are enlightening. The paper shows that although MOHART outperforms HART in all circumstances, if the forces between the circles change randomly every number of steps, MOHART outperforms HART by a very large margin. This is because the forces between the circles are determined by their color, which is observable by the network, and MOHART, which capable of learning their interaction, learns the pattern of changing forces. HART, being an independent-particle model, cannot learn the interactions.\n\nThe results on the real datasets demonstrate superiority over HART, and in a series of ablation experiments, the Authors are able to show that MOHART's ability to utilize interactions between objects is responsible for the improvement. For example, the improvement over HART is greater when egomotion is significant, because egomotion creates correlations between the movement of objects in the camera frame, which MOHART can utilize.\n\nI found the paper enlightening, based on a neat idea. The experimental results are extensively analyzed and the Author's insights about their algorithm are substantiated by the experiments. \n\nHowever the difficulty I had with the paper is that the results are only compared to HART. HART was published in 2017, and the field of scene understanding and tracking had been addressed in multiple papers since then. It is one of the more competitive and application-driven fields in computer vision. Comparing MOHART only to its sister-method from over two years ago significantly limits the usefulness of paper IMHO. The expectation IMHO is not that MOHART outperform each and every method out there, but that the reader know where MOHART stands compared to other methods (e. g. tracking by detection).\n\nI will refrain from pointing to specific papers to compare to, because I believe the Authors should chose the settings, datasets, criteria, and metrics that are the most convenient for them for comparison. The papers surveyed in Section 2, especially under \"Tracking-by-Detection\", have many followups. Recent papers from those that claim state of the art could good candidates for comparison.\n\nIn view of the above, I am inclined at this stage to reject the paper."}, "signatures": ["ICLR.cc/2020/Conference/Paper771/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper771/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["fabian@robots.ox.ac.uk", "adamk@robots.ox.ac.uk", "kevin@robots.ox.ac.uk", "oiwi.parkerjones@jesus.ox.ac.uk", "ingmar@robots.ox.ac.uk"], "title": "Improving End-to-End Object Tracking Using Relational Reasoning", "authors": ["Fabian B. Fuchs", "Adam R. Kosiorek", "Li Sun", "Oiwi Parker Jones", "Ingmar Posner"], "pdf": "/pdf/5cc2ef797810bf0bf85f8f8f49bcf10f2defccb1.pdf", "TL;DR": "MOHART uses a self-attention mechanism to perform relational reasoning in multi-object tracking.", "abstract": "Relational reasoning, the ability to model interactions and relations between objects, is valuable for robust multi-object tracking and pivotal for trajectory prediction. In this paper, we propose MOHART, a class-agnostic, end-to-end multi-object tracking and trajectory prediction algorithm, which explicitly accounts for permutation invariance in its relational reasoning. We explore a number of permutation invariant architectures and show that multi-headed self-attention outperforms the provided baselines and better accounts for complex physical interactions in a challenging toy experiment. We show on three real-world tracking datasets that adding relational reasoning capabilities in this way increases the tracking and trajectory prediction performance, particularly in the presence of ego-motion, occlusions, crowded scenes, and faulty sensor inputs. To the best of our knowledge, MOHART is the first fully end-to-end multi-object tracking from vision approach applied to real-world data reported in the literature. ", "keywords": ["Relational Reasoning", "Tracking", "Intuitive Physics", "Real-World Application", "Permutation Invariance"], "paperhash": "fuchs|improving_endtoend_object_tracking_using_relational_reasoning", "original_pdf": "/attachment/5cc2ef797810bf0bf85f8f8f49bcf10f2defccb1.pdf", "_bibtex": "@misc{\nfuchs2020improving,\ntitle={Improving End-to-End Object Tracking Using Relational Reasoning},\nauthor={Fabian B. Fuchs and Adam R. Kosiorek and Li Sun and Oiwi Parker Jones and Ingmar Posner},\nyear={2020},\nurl={https://openreview.net/forum?id=Byl-264tvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Byl-264tvr", "replyto": "Byl-264tvr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper771/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper771/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576105524842, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper771/Reviewers"], "noninvitees": [], "tcdate": 1570237747328, "tmdate": 1576105524857, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper771/-/Official_Review"}}}, {"id": "S1lqFdj0tS", "original": null, "number": 3, "cdate": 1571891330515, "ddate": null, "tcdate": 1571891330515, "tmdate": 1572972554249, "tddate": null, "forum": "Byl-264tvr", "replyto": "Byl-264tvr", "invitation": "ICLR.cc/2020/Conference/Paper771/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper deals with the problem of multiple object tracking and trajectory prediction in multiple frames of videos. The main focus is adding a relation-reasoning building block to the original HART framework. With multiple objects, the key is to be able to learn the permutation invariant representation during potential changing and dynamic object trajectories. The paper also uses toy examples to show that the proposed block of relation reasoning is not necessarily beneficial when the object trajectory is less random and more static. Finally, experiments on real data demonstrate that the proposed method that accounts for relation reasoning is helpful by a limited magnitude.\n \nThe main contribution of this paper is the novel relation reasoning block. However, there are three key concerns of mine:\n \n1. It is not clear when the new architecture would be helpful. I am really happy to see a more careful study of the success and failure cases of the method. I also appreciate the honesty that the current model is not competitive with the ones that have an accurate bounding box as input. But I think a more detailed study can be conducted, especially in the toy example case.  Maybe it is possible to design different levels of randomness in the trajectory and further figure out when is the reasoning block helpful.\n\n2. Even the real data experiments do not have very impressive results, from my biased observation. (I am not in the field, so maybe I am wrong here.) \n\n3. The end-to-end approach is also another perspective where the authors try to differentiate their methods from others. I think it is potentially an interesting problem that why end-to-end is something you would prefer (which is definitely a harder problem), and when. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper771/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper771/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["fabian@robots.ox.ac.uk", "adamk@robots.ox.ac.uk", "kevin@robots.ox.ac.uk", "oiwi.parkerjones@jesus.ox.ac.uk", "ingmar@robots.ox.ac.uk"], "title": "Improving End-to-End Object Tracking Using Relational Reasoning", "authors": ["Fabian B. Fuchs", "Adam R. Kosiorek", "Li Sun", "Oiwi Parker Jones", "Ingmar Posner"], "pdf": "/pdf/5cc2ef797810bf0bf85f8f8f49bcf10f2defccb1.pdf", "TL;DR": "MOHART uses a self-attention mechanism to perform relational reasoning in multi-object tracking.", "abstract": "Relational reasoning, the ability to model interactions and relations between objects, is valuable for robust multi-object tracking and pivotal for trajectory prediction. In this paper, we propose MOHART, a class-agnostic, end-to-end multi-object tracking and trajectory prediction algorithm, which explicitly accounts for permutation invariance in its relational reasoning. We explore a number of permutation invariant architectures and show that multi-headed self-attention outperforms the provided baselines and better accounts for complex physical interactions in a challenging toy experiment. We show on three real-world tracking datasets that adding relational reasoning capabilities in this way increases the tracking and trajectory prediction performance, particularly in the presence of ego-motion, occlusions, crowded scenes, and faulty sensor inputs. To the best of our knowledge, MOHART is the first fully end-to-end multi-object tracking from vision approach applied to real-world data reported in the literature. ", "keywords": ["Relational Reasoning", "Tracking", "Intuitive Physics", "Real-World Application", "Permutation Invariance"], "paperhash": "fuchs|improving_endtoend_object_tracking_using_relational_reasoning", "original_pdf": "/attachment/5cc2ef797810bf0bf85f8f8f49bcf10f2defccb1.pdf", "_bibtex": "@misc{\nfuchs2020improving,\ntitle={Improving End-to-End Object Tracking Using Relational Reasoning},\nauthor={Fabian B. Fuchs and Adam R. Kosiorek and Li Sun and Oiwi Parker Jones and Ingmar Posner},\nyear={2020},\nurl={https://openreview.net/forum?id=Byl-264tvr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Byl-264tvr", "replyto": "Byl-264tvr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper771/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper771/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576105524842, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper771/Reviewers"], "noninvitees": [], "tcdate": 1570237747328, "tmdate": 1576105524857, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper771/-/Official_Review"}}}], "count": 11}