{"notes": [{"id": "B1xbTlBKwB", "original": "rye0ReZYDH", "number": 2563, "cdate": 1569439928933, "ddate": null, "tcdate": 1569439928933, "tmdate": 1577168212783, "tddate": null, "forum": "B1xbTlBKwB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["hiroaki.yamane@riken.jp", "cyl@microsoft.com", "harada@mi.t.u-tokyo.ac.jp"], "title": "Measuring Numerical Common Sense: Is A Word Embedding Approach Effective?", "authors": ["Hiroaki Yamane", "Chin-Yew Lin", "Tatsuya Harada"], "pdf": "/pdf/08d261937c2acd3156dfb5bdfefe30ac2bfb07e1.pdf", "abstract": "Numerical common sense (e.g., ``a person with a height of 2m is very tall'') is essential when deploying artificial intelligence (AI) systems in society. To predict ranges of small and large values for a given target noun and unit, \nprevious studies have implemented a rule-based method that processed numeric values appearing in a natural language by using template matching. To obtain numerical knowledge, crawled textual data from web pages are frequently used as the input in the above method. Although this is an important task, few studies have addressed the availability of numerical common sense extracted from corresponding textual information. To this end, we first used a crowdsourcing service to obtain sufficient data for a subjective agreement on numerical common sense. Second, to examine whether common sense is attributed to current word embedding, we examined the performance of a regressor trained on the obtained data. In comparison with humans, the performance of an automatic relevance determination regression model was good, particularly when the unit was yen (a maximum correlation coefficient of 0.57). Although all the regression approach with word embedding does not predict values with high correlation coefficients, this word-embedding method could potentially contribute to construct numerical common sense for AI deployment.", "keywords": ["numerical common sense", "word embedding", "semantic representation"], "paperhash": "yamane|measuring_numerical_common_sense_is_a_word_embedding_approach_effective", "original_pdf": "/attachment/25ce288328b46bbb45af58213b8765ab5e79a2a1.pdf", "_bibtex": "@misc{\nyamane2020measuring,\ntitle={Measuring Numerical Common Sense: Is A Word Embedding Approach Effective?},\nauthor={Hiroaki Yamane and Chin-Yew Lin and Tatsuya Harada},\nyear={2020},\nurl={https://openreview.net/forum?id=B1xbTlBKwB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "Ni5eKNNvjY", "original": null, "number": 1, "cdate": 1576798752235, "ddate": null, "tcdate": 1576798752235, "tmdate": 1576800883401, "tddate": null, "forum": "B1xbTlBKwB", "replyto": "B1xbTlBKwB", "invitation": "ICLR.cc/2020/Conference/Paper2563/-/Decision", "content": {"decision": "Reject", "comment": "The authors tackle an interesting and important problem, developing numerical common-sense. They use a crowdsourcing service to collect a dataset and use regression from word embeddings to numerical common sense.\n\nReviewers were concerned with the size and quality of the dataset, the quality of the prediction methods used, and the analysis of the experimental results.\n\nGiven the many concerns, I recommend rejecting the paper, but I encourage the authors to revise the paper to address the concerns and resubmit to another venue.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["hiroaki.yamane@riken.jp", "cyl@microsoft.com", "harada@mi.t.u-tokyo.ac.jp"], "title": "Measuring Numerical Common Sense: Is A Word Embedding Approach Effective?", "authors": ["Hiroaki Yamane", "Chin-Yew Lin", "Tatsuya Harada"], "pdf": "/pdf/08d261937c2acd3156dfb5bdfefe30ac2bfb07e1.pdf", "abstract": "Numerical common sense (e.g., ``a person with a height of 2m is very tall'') is essential when deploying artificial intelligence (AI) systems in society. To predict ranges of small and large values for a given target noun and unit, \nprevious studies have implemented a rule-based method that processed numeric values appearing in a natural language by using template matching. To obtain numerical knowledge, crawled textual data from web pages are frequently used as the input in the above method. Although this is an important task, few studies have addressed the availability of numerical common sense extracted from corresponding textual information. To this end, we first used a crowdsourcing service to obtain sufficient data for a subjective agreement on numerical common sense. Second, to examine whether common sense is attributed to current word embedding, we examined the performance of a regressor trained on the obtained data. In comparison with humans, the performance of an automatic relevance determination regression model was good, particularly when the unit was yen (a maximum correlation coefficient of 0.57). Although all the regression approach with word embedding does not predict values with high correlation coefficients, this word-embedding method could potentially contribute to construct numerical common sense for AI deployment.", "keywords": ["numerical common sense", "word embedding", "semantic representation"], "paperhash": "yamane|measuring_numerical_common_sense_is_a_word_embedding_approach_effective", "original_pdf": "/attachment/25ce288328b46bbb45af58213b8765ab5e79a2a1.pdf", "_bibtex": "@misc{\nyamane2020measuring,\ntitle={Measuring Numerical Common Sense: Is A Word Embedding Approach Effective?},\nauthor={Hiroaki Yamane and Chin-Yew Lin and Tatsuya Harada},\nyear={2020},\nurl={https://openreview.net/forum?id=B1xbTlBKwB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "B1xbTlBKwB", "replyto": "B1xbTlBKwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795703864, "tmdate": 1576800251331, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2563/-/Decision"}}}, {"id": "S1gt14y3YS", "original": null, "number": 1, "cdate": 1571709920812, "ddate": null, "tcdate": 1571709920812, "tmdate": 1574198617594, "tddate": null, "forum": "B1xbTlBKwB", "replyto": "B1xbTlBKwB", "invitation": "ICLR.cc/2020/Conference/Paper2563/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #1", "review": "I have read the author response.  Thank you for responding to my questions.\n\nThis paper aims to predict typical \u201ccommon sense\u201d values of quantities using word embeddings.  It includes the construction of a data set and some experiments with regression models.  The general direction of this work is worthy of study, but the paper needs additional justification for its task, better discussion of recent related work, and more development of its regression models.\n\nThe work starts by describing the construction of interesting crowdsourced data sets that include people\u2019s estimates of typical quantities, what they would consider to be low or high values for a given object in given units e.g. the temperature of a hot spring or the height of a giraffe.  Overall, the data sets are interesting but are not especially large (2300 total [low, high] pairs of 230 different quantities).  Further, the particular task formulation here needs more justification.  I think most of us would agree that common sense is a critical AI challenge, and that the question of whether embeddings reflect typical quantities is important.  But, in a paper where the data set is considered a primary contribution, I would expect more justification for exactly how this task is formulated, and which objects and units were selected.  As one example, why ask about \u201clarge\u201d and \u201csmall\u201d values rather than something with more precise semantics (like the 10th and 90th percentile, for example)?  I also felt that the introduction could be improved to provide more convincing motivation.  E.g., the first paragraph only says that humans apply different adjectives (like \u201chefty\u201d and \u201ccheap\u201d) to different things depending on their numerical attributes (weight, cost), but does not argue why teaching AI systems to use those adjectives is a priority.\n\nRegarding related work, the paper is missing a discussion of several relevant papers that use embeddings to obtain relative comparisons or estimates of commonsense properties of objects, including:\n\nForbes, Maxwell, and Yejin Choi. \"Verb physics: Relative physical knowledge of actions and objects.\" ACL 2017\n\nYang, Yiben, et al. \"Extracting commonsense properties from embeddings with limited human guidance.\" ACL 2018\n\nElazar, Yanai, et al. \"How Large Are Lions? Inducing Distributions over Quantitative Attributes.\" ACL 2019\n\nThe paper then presents the performance of some regression models.  These models are standard existing techniques, and given the relatively low performance I would have liked more development of the models and more analysis of the performance.  For a conference like ICLR I would expect to see a more thorough exploration and analysis of possible models for the task.  Looking at more powerful neural regressors (perhaps using contextual embeddings rather than just fixed word embeddings) might be one option.  Offering an explanation for why ARD seems to work better than the other approaches would be helpful.\n\nMinor: In Table 3, the way that small and large are interleaved makes it hard to compare systems, I think presenting all the small results together, and large results together may help.  In Figure 2, it would be helpful to see the histogram for size-large within the same plots here, so we could see how far apart they are.\n\n\u201cBecause Skip-gram has to handle more words to predict words, we assume Skip-gram will obtain more information about numerical values.\u201d\n-- I didn\u2019t understand what you meant about skip-gram having to \u201chandle more words to predict words.\u201d  Also, I did not understand how this entails that skip-gram would obtain more info about numerical values.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"}, "signatures": ["ICLR.cc/2020/Conference/Paper2563/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2563/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["hiroaki.yamane@riken.jp", "cyl@microsoft.com", "harada@mi.t.u-tokyo.ac.jp"], "title": "Measuring Numerical Common Sense: Is A Word Embedding Approach Effective?", "authors": ["Hiroaki Yamane", "Chin-Yew Lin", "Tatsuya Harada"], "pdf": "/pdf/08d261937c2acd3156dfb5bdfefe30ac2bfb07e1.pdf", "abstract": "Numerical common sense (e.g., ``a person with a height of 2m is very tall'') is essential when deploying artificial intelligence (AI) systems in society. To predict ranges of small and large values for a given target noun and unit, \nprevious studies have implemented a rule-based method that processed numeric values appearing in a natural language by using template matching. To obtain numerical knowledge, crawled textual data from web pages are frequently used as the input in the above method. Although this is an important task, few studies have addressed the availability of numerical common sense extracted from corresponding textual information. To this end, we first used a crowdsourcing service to obtain sufficient data for a subjective agreement on numerical common sense. Second, to examine whether common sense is attributed to current word embedding, we examined the performance of a regressor trained on the obtained data. In comparison with humans, the performance of an automatic relevance determination regression model was good, particularly when the unit was yen (a maximum correlation coefficient of 0.57). Although all the regression approach with word embedding does not predict values with high correlation coefficients, this word-embedding method could potentially contribute to construct numerical common sense for AI deployment.", "keywords": ["numerical common sense", "word embedding", "semantic representation"], "paperhash": "yamane|measuring_numerical_common_sense_is_a_word_embedding_approach_effective", "original_pdf": "/attachment/25ce288328b46bbb45af58213b8765ab5e79a2a1.pdf", "_bibtex": "@misc{\nyamane2020measuring,\ntitle={Measuring Numerical Common Sense: Is A Word Embedding Approach Effective?},\nauthor={Hiroaki Yamane and Chin-Yew Lin and Tatsuya Harada},\nyear={2020},\nurl={https://openreview.net/forum?id=B1xbTlBKwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "B1xbTlBKwB", "replyto": "B1xbTlBKwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2563/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2563/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574722376000, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2563/Reviewers"], "noninvitees": [], "tcdate": 1570237721060, "tmdate": 1574723094441, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2563/-/Official_Review"}}}, {"id": "Skl7ei7gcH", "original": null, "number": 2, "cdate": 1571990251274, "ddate": null, "tcdate": 1571990251274, "tmdate": 1572972321925, "tddate": null, "forum": "B1xbTlBKwB", "replyto": "B1xbTlBKwB", "invitation": "ICLR.cc/2020/Conference/Paper2563/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper describes the collection and analysis of a numerical common-sense dataset. The paper also states that a novel regression method is presented for quantifying numerical common sense.\n\nStrengths:\n- the numerical common sense task and its related challenges are presented and motivated clearly\n- the data/annotations and their analysis are presented clearly. The experiment can be replicated reasonably (provided that the data is released, as the authors state)\n\nWeaknesses:\n- the dataset is too small (230 pairs of units and values). Two observations follow from this: (1) such small-scale data is of limited use to state of the art (deep learning) data-hungry approaches; (2) the relatively low cost of crowdsourcing typically results in much bigger datasets. \n- some decisions or definitions seem a bit ad hoc and are not convincing. For instance: in Table 1, why is the apple measured in centimetres but the coffee cup measured in meters? Another example from section 1: why are temperature and weight described as nonphysical scales, but money described as a subjective scale? Another example of a definition: \"similar words share similar units and thus concrete words contains numerical information\". Statements like these are problematic because one could easily think of counter examples where this is not the case.\n- the experimental findings are not based on state on the art methods applied in a setup where the robustness and transferability of the methods on other data and domains has been analysed and discussed. \n\nOverall this work is interesting as a starting point. My advice is to consider scaling up both the data and the methods, and to accompany this by a more comprehensive analysis of limitations."}, "signatures": ["ICLR.cc/2020/Conference/Paper2563/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2563/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["hiroaki.yamane@riken.jp", "cyl@microsoft.com", "harada@mi.t.u-tokyo.ac.jp"], "title": "Measuring Numerical Common Sense: Is A Word Embedding Approach Effective?", "authors": ["Hiroaki Yamane", "Chin-Yew Lin", "Tatsuya Harada"], "pdf": "/pdf/08d261937c2acd3156dfb5bdfefe30ac2bfb07e1.pdf", "abstract": "Numerical common sense (e.g., ``a person with a height of 2m is very tall'') is essential when deploying artificial intelligence (AI) systems in society. To predict ranges of small and large values for a given target noun and unit, \nprevious studies have implemented a rule-based method that processed numeric values appearing in a natural language by using template matching. To obtain numerical knowledge, crawled textual data from web pages are frequently used as the input in the above method. Although this is an important task, few studies have addressed the availability of numerical common sense extracted from corresponding textual information. To this end, we first used a crowdsourcing service to obtain sufficient data for a subjective agreement on numerical common sense. Second, to examine whether common sense is attributed to current word embedding, we examined the performance of a regressor trained on the obtained data. In comparison with humans, the performance of an automatic relevance determination regression model was good, particularly when the unit was yen (a maximum correlation coefficient of 0.57). Although all the regression approach with word embedding does not predict values with high correlation coefficients, this word-embedding method could potentially contribute to construct numerical common sense for AI deployment.", "keywords": ["numerical common sense", "word embedding", "semantic representation"], "paperhash": "yamane|measuring_numerical_common_sense_is_a_word_embedding_approach_effective", "original_pdf": "/attachment/25ce288328b46bbb45af58213b8765ab5e79a2a1.pdf", "_bibtex": "@misc{\nyamane2020measuring,\ntitle={Measuring Numerical Common Sense: Is A Word Embedding Approach Effective?},\nauthor={Hiroaki Yamane and Chin-Yew Lin and Tatsuya Harada},\nyear={2020},\nurl={https://openreview.net/forum?id=B1xbTlBKwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "B1xbTlBKwB", "replyto": "B1xbTlBKwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2563/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2563/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574722376000, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2563/Reviewers"], "noninvitees": [], "tcdate": 1570237721060, "tmdate": 1574723094441, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2563/-/Official_Review"}}}, {"id": "SyxG5xWcqB", "original": null, "number": 3, "cdate": 1572634761974, "ddate": null, "tcdate": 1572634761974, "tmdate": 1572972321880, "tddate": null, "forum": "B1xbTlBKwB", "replyto": "B1xbTlBKwB", "invitation": "ICLR.cc/2020/Conference/Paper2563/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper attempts to study if learned word embeddings for common objects contain information about \"numerical common sense\". The hypothesis is that certain numerical information may co-occur with the words for certain objects/measurement units within their context windows. To verify this hypotheses, the authors have created a dataset through a crowd-sourcing service which represents \"numerical common sense\". Using this dataset, the authors examine the predict abilities of regressors trained on learned word embeddings and the aforementioned crowd-sourced dataset. The hypothesis is that if the regressors demonstrate good accuracy, then the word embeddings contained information relevant to \"numerical common sense\". To the best of my knowledge, this is the first paper that attempts to analyze learned word embeddings in the context of numerical common sense.\n\nThis paper should be rejected because (1) the NCS datasets are too small to represent \"numerical common sense\" (2) the NCS datasets contain faulty data points and (3) the results from the experiments conducted are not sufficient to accept or refute the hypotheses.\n\nMain argument\n\nThe first question that we must ask is - are the NCS-50x1 and NCS-60x3 datasets reliable for experiments on \"numerical common sense\". No, because of two flaws:\n\n(1) The number of samples in the dataset is too small to represent \"numerical common sense\". Consider the histogram for object \"dog\" in Figure 2. If the largest data point in this plot was absent, the average of the distribution would be smaller by several orders of magnitude. Perhaps there are other objects in the dataset which are missing samples from the tail end of the distribution that could have large effects on the mean of the collected dataset. \n\n(2) Some data points in the dataset don't make sense to me. For example, Fig 2 represents the \"small\" dataset, yet I see samples like 400m long dogs, 40m long cats, 150m long monitors and 20m long mice?\n\nAlso, it is not clear how the confidence scores of the participants were taken into account when training the regressors or if they were used at all.\n\nIf the NCS dataset does not represent \"numerical common sense\", it invalidates all experimental results from the paper.\n\nMy second issue with the paper is that it is not possible to conclude if the experimental results support or refute the hypothesis (ignoring the issue with the dataset):\n\n1. In tables 2 and 3, the correlation coefficients were quite low and and the MAEs were pretty large. In Table 3, rows 1 and 2, even though the correlation is 0.57 and 0.48, the MAE is 100 million yen and 7.5 million yen respectively which is quite large. To me this suggests that just because the correlation is larger we cannot conclude mean that the model is performing well.\n\n2. It is unclear why the correlation coefficient was chosen to decide that ARD is the superior model in experiment 1. The MAE for random forests with concatenated feature vectors was an order of magnitude smaller than that of the ARD model.\n\n3. Why are the correlation coefficients missing for the unit-only experiment in Table 2? The LS model shows very good MAE relative to the other models and perhaps the correlation should have been measured for that as well? In fact, if the correlation coefficients for this case is comparable to the case with concatenated features, it would mean that the word embedding for the object is not helping at all! Moreover, I find it surprising that the LS model with concatenated features performs worse than the unit-only features. We cannot conclude if paper's interpretation about the results is correct unless this missing information is provided.\n\n4. It is hard to judge what a correlation coefficient of 0.57 means. Why didn't you provide a scatter plot of the predictions vs targets as well? It often happens that even noisy plots demonstrate good correlations.\n\n5. The paper should have additional ablation studies - for example, what would happen in the concatenated feature vector experiment if you trained the regressors using randomly initialized word embeddings instead of the trained word embeddings? Do you get the same performance as learned word embeddings?"}, "signatures": ["ICLR.cc/2020/Conference/Paper2563/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2563/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["hiroaki.yamane@riken.jp", "cyl@microsoft.com", "harada@mi.t.u-tokyo.ac.jp"], "title": "Measuring Numerical Common Sense: Is A Word Embedding Approach Effective?", "authors": ["Hiroaki Yamane", "Chin-Yew Lin", "Tatsuya Harada"], "pdf": "/pdf/08d261937c2acd3156dfb5bdfefe30ac2bfb07e1.pdf", "abstract": "Numerical common sense (e.g., ``a person with a height of 2m is very tall'') is essential when deploying artificial intelligence (AI) systems in society. To predict ranges of small and large values for a given target noun and unit, \nprevious studies have implemented a rule-based method that processed numeric values appearing in a natural language by using template matching. To obtain numerical knowledge, crawled textual data from web pages are frequently used as the input in the above method. Although this is an important task, few studies have addressed the availability of numerical common sense extracted from corresponding textual information. To this end, we first used a crowdsourcing service to obtain sufficient data for a subjective agreement on numerical common sense. Second, to examine whether common sense is attributed to current word embedding, we examined the performance of a regressor trained on the obtained data. In comparison with humans, the performance of an automatic relevance determination regression model was good, particularly when the unit was yen (a maximum correlation coefficient of 0.57). Although all the regression approach with word embedding does not predict values with high correlation coefficients, this word-embedding method could potentially contribute to construct numerical common sense for AI deployment.", "keywords": ["numerical common sense", "word embedding", "semantic representation"], "paperhash": "yamane|measuring_numerical_common_sense_is_a_word_embedding_approach_effective", "original_pdf": "/attachment/25ce288328b46bbb45af58213b8765ab5e79a2a1.pdf", "_bibtex": "@misc{\nyamane2020measuring,\ntitle={Measuring Numerical Common Sense: Is A Word Embedding Approach Effective?},\nauthor={Hiroaki Yamane and Chin-Yew Lin and Tatsuya Harada},\nyear={2020},\nurl={https://openreview.net/forum?id=B1xbTlBKwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "B1xbTlBKwB", "replyto": "B1xbTlBKwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2563/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2563/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574722376000, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2563/Reviewers"], "noninvitees": [], "tcdate": 1570237721060, "tmdate": 1574723094441, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2563/-/Official_Review"}}}], "count": 5}