{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124464307, "tcdate": 1518461912279, "number": 209, "cdate": 1518461912279, "id": "HJly4D1vz", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "HJly4D1vz", "signatures": ["~I-Jeng_Wang1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Local Stability of Adversarial Examples", "abstract": "Neural networks\u2019 lack of stability to \u201csmall\u201d perturbations of the input signal is a topic of substantial interest. Recent work has explored a number of properties of these so-called adversarial examples (AE) in an attempt to further understand this phenomenon. The present work continues in this spirit and provides an explicit characterization of stability for AE derived from very small perturbations. We also suggest future directions for how this characterization might be used in practice to mitigate the impact of these AE.", "paperhash": "wang|local_stability_of_adversarial_examples", "keywords": ["Adversarial Examples", "Local Stability"], "_bibtex": "@misc{\n  wang2018local,\n  title={Local Stability of Adversarial Examples},\n  author={I-Jeng Wang and Michael Pekala and Evan Fuller},\n  year={2018},\n  url={https://openreview.net/forum?id=HJly4D1vz}\n}", "authorids": ["i-jeng.wang@jhuapl.edu", "mike.pekala@jhuapl.edu", "evan.fuller@jhuapl.edu"], "authors": ["I-Jeng Wang", "Michael Pekala", "Evan Fuller"], "TL;DR": "A theoretical result on the local stability of adversarial examples and preliminary results on its implication for potential defense schemes.", "pdf": "/pdf/5e7d63a8d336fb97d36295c236ab63f585685b6b.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582712303, "tcdate": 1520688033007, "number": 1, "cdate": 1520688033007, "id": "B1tso8WYG", "invitation": "ICLR.cc/2018/Workshop/-/Paper209/Official_Review", "forum": "HJly4D1vz", "replyto": "HJly4D1vz", "signatures": ["ICLR.cc/2018/Workshop/Paper209/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper209/AnonReviewer1"], "content": {"title": "Good formalism for a start; need more experimental evidence", "rating": "3: Clear rejection", "review": "The paper provides a characterization of stability for adversarial examples. \nClarity\n--------\n1) It is not clear what the goal of the paper is? Is it just limited to formalizing the idea of sampling based AE defense (such as  Cao & Gong (2017))? Or does the work propose something more?\n\n2) The x-axis of Figure 1, says distance and we still find points with negative distance. Please clairfy\n\nQuality\n---------\nIt is a good idea to check how far does the notion local stability differ between clean vs adversarial samples. However, the results presented here seems to be very limited and preliminary with a sample size of just around 100 points. It will be great to have more experimental coverage.\n\nOriginality\n--------------\nFormalization of local stability is important, however, neither the definitions nor Lemma 1 seem to be non-trivial to obtain.\n\nNovelty\n----------\nOther than formalizing local stability the paper does not find anything drastically 'new' about adversarial examples.\n\n\nSignificance\n---------------\nThe experiments lack coverage, and hence the significance of the work is limited.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Local Stability of Adversarial Examples", "abstract": "Neural networks\u2019 lack of stability to \u201csmall\u201d perturbations of the input signal is a topic of substantial interest. Recent work has explored a number of properties of these so-called adversarial examples (AE) in an attempt to further understand this phenomenon. The present work continues in this spirit and provides an explicit characterization of stability for AE derived from very small perturbations. We also suggest future directions for how this characterization might be used in practice to mitigate the impact of these AE.", "paperhash": "wang|local_stability_of_adversarial_examples", "keywords": ["Adversarial Examples", "Local Stability"], "_bibtex": "@misc{\n  wang2018local,\n  title={Local Stability of Adversarial Examples},\n  author={I-Jeng Wang and Michael Pekala and Evan Fuller},\n  year={2018},\n  url={https://openreview.net/forum?id=HJly4D1vz}\n}", "authorids": ["i-jeng.wang@jhuapl.edu", "mike.pekala@jhuapl.edu", "evan.fuller@jhuapl.edu"], "authors": ["I-Jeng Wang", "Michael Pekala", "Evan Fuller"], "TL;DR": "A theoretical result on the local stability of adversarial examples and preliminary results on its implication for potential defense schemes.", "pdf": "/pdf/5e7d63a8d336fb97d36295c236ab63f585685b6b.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582712117, "id": "ICLR.cc/2018/Workshop/-/Paper209/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper209/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper209/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper209/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper209/AnonReviewer3"], "reply": {"forum": "HJly4D1vz", "replyto": "HJly4D1vz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper209/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper209/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582712117}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582700465, "tcdate": 1520701489312, "number": 2, "cdate": 1520701489312, "id": "B1tNlcZYf", "invitation": "ICLR.cc/2018/Workshop/-/Paper209/Official_Review", "forum": "HJly4D1vz", "replyto": "HJly4D1vz", "signatures": ["ICLR.cc/2018/Workshop/Paper209/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper209/AnonReviewer2"], "content": {"title": "Simple (almost trivial) idea, somewhat confusing paper, deeply flawed experiments.", "rating": "3: Clear rejection", "review": "The paper defines, for a given trained model h, eps-stability for a clean example x if a random sample x' from a ball of radius eps around x has h(x) = h(x') with probability 1. While the authors couch this in terms of measure theory, I believe that even the tiniest amount of smoothness (which is always present in practice) lets us talk about this differently and more simply: an example is eps-stable if it has at least distance eps from any classification boundary. \n\nThe paper has a single lemma, which is that if we have an example that's x eps-stable, and an adversarial example (AE) x' at distance tau < 2*eps from from x, then x' cannot be eps-stable. Thinking in terms of smooth boundaries, this is true but fairy trivial: x has distance >= eps from the classification boundary, x' is on the other side but at distance < 2*eps from x, so x' is at distance < eps from the boundary. Fine.\n\nSo what are the implications? The paper is a bit confusing on this point, but I believe the authors want to explore the hypothesis that clean examples x have higher stability than associated AE's x': in other words that a clean example is farther from the classification boundary than an associated AE. If true, this possibly gives a means to detect AE's.\n\nThe authors attempt to design an experiment to measure this, but I view the experiment as deeply flawed. The authors *estimate* eps by choosing 100 random directions, finding the distance to the classification boundary, taking the minimum over the 100 directions, and then dividing by 5. They authors correctly point out that this is neither an upper nor a lower bound; they do not mention that the 100 and *especially* the 5 are completely unmotivated fudge factors, and that modifying that 5 may easily change the results of the experiment.\n\nThe authors say they want to focus on \"cases where an AE lies within the eps-stable region of the corresponding clean example.\" But this makes no sense: according to lemma 1, AE's within the eps-stable region of x occur w.p. 0, and under a smoothness assumption, there are none of them. Surely the authors are not suggesting that their method of finding AE's is finding measure zero sets? Based on this argument, there are no AE's within the eps-stable region. What the authors actually find is AEs within the ~eps-stable region, where ~eps is the *estimated* stability using the hack described in the previous paragraph. But, continuing the argument, what this is showing is that for any example where the authors find an AE within ~eps, then ~eps is an overestimate. (Put differently, if we *have* an AE x' for x, under very weak smoothness assumptions we can upper bound eps by using the distance to the boundary along the ray from x to x', rather than a random direction.) The authors want to show that for points where the AE is within the eps-stable region, the stability of the AE is lower, but since they're using ~eps which is a (possibly) gross overestimate of eps for these points, I'm not sure what the experiment shows.\n\nI think a better experiment would be to use an upper bound on eps which is the distance to the classifier boundary in the direction of the AE, and then explore whether the distance to the AE < 2 eps. This is still far from perfect, because eps may in fact be quite a bit smaller, but at least the experiment would tell us *something*: if we found that the AE's were (or could be generated to be) often at distance > 2 eps, that this relative stability approach to correcting wouldn't work.\n\nAlthough the paper is short and simple, it still manages to be confusing. There are many sentences that I can't quite figure out what they're trying to say. ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Local Stability of Adversarial Examples", "abstract": "Neural networks\u2019 lack of stability to \u201csmall\u201d perturbations of the input signal is a topic of substantial interest. Recent work has explored a number of properties of these so-called adversarial examples (AE) in an attempt to further understand this phenomenon. The present work continues in this spirit and provides an explicit characterization of stability for AE derived from very small perturbations. We also suggest future directions for how this characterization might be used in practice to mitigate the impact of these AE.", "paperhash": "wang|local_stability_of_adversarial_examples", "keywords": ["Adversarial Examples", "Local Stability"], "_bibtex": "@misc{\n  wang2018local,\n  title={Local Stability of Adversarial Examples},\n  author={I-Jeng Wang and Michael Pekala and Evan Fuller},\n  year={2018},\n  url={https://openreview.net/forum?id=HJly4D1vz}\n}", "authorids": ["i-jeng.wang@jhuapl.edu", "mike.pekala@jhuapl.edu", "evan.fuller@jhuapl.edu"], "authors": ["I-Jeng Wang", "Michael Pekala", "Evan Fuller"], "TL;DR": "A theoretical result on the local stability of adversarial examples and preliminary results on its implication for potential defense schemes.", "pdf": "/pdf/5e7d63a8d336fb97d36295c236ab63f585685b6b.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582712117, "id": "ICLR.cc/2018/Workshop/-/Paper209/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper209/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper209/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper209/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper209/AnonReviewer3"], "reply": {"forum": "HJly4D1vz", "replyto": "HJly4D1vz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper209/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper209/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582712117}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582656263, "tcdate": 1520780940860, "number": 3, "cdate": 1520780940860, "id": "H1BqIaMFM", "invitation": "ICLR.cc/2018/Workshop/-/Paper209/Official_Review", "forum": "HJly4D1vz", "replyto": "HJly4D1vz", "signatures": ["ICLR.cc/2018/Workshop/Paper209/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper209/AnonReviewer3"], "content": {"title": "Somewhat trivial results", "rating": "3: Clear rejection", "review": "Lemma 1 is almost trivial from the definitions, and I found the directions and claims are not that interesting.\nWhile I agree that the local stability is an interesting property to be examined, it is not interesting if the original prediction is wrong. For example, a classifier that predicts only one label every time is infinity-stable, but not interesting at all since the classifier's prediction is useless. Therefore I would encourage the authors to include the notion of \"correct\" label in the definition, instead of simply ignoring them.\n \nI also think the vast amount of adversarial example research is focusing on how to efficiently find a such an example, or computing the stability bound, etc. I believe that the theoritical foundation of classifier's stability and its behavior around the decision boundary are heavily investigated in the large margin based classifier, such as SVM, literature. I would suggest to outline the main difference between \"margin\" and \"stability\". Also I think it will be interesting to investigate the effect of loss function to the stability region, by training NN using a margin based loss (like hinge loss) instead of logistic loss (or softmax),\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Local Stability of Adversarial Examples", "abstract": "Neural networks\u2019 lack of stability to \u201csmall\u201d perturbations of the input signal is a topic of substantial interest. Recent work has explored a number of properties of these so-called adversarial examples (AE) in an attempt to further understand this phenomenon. The present work continues in this spirit and provides an explicit characterization of stability for AE derived from very small perturbations. We also suggest future directions for how this characterization might be used in practice to mitigate the impact of these AE.", "paperhash": "wang|local_stability_of_adversarial_examples", "keywords": ["Adversarial Examples", "Local Stability"], "_bibtex": "@misc{\n  wang2018local,\n  title={Local Stability of Adversarial Examples},\n  author={I-Jeng Wang and Michael Pekala and Evan Fuller},\n  year={2018},\n  url={https://openreview.net/forum?id=HJly4D1vz}\n}", "authorids": ["i-jeng.wang@jhuapl.edu", "mike.pekala@jhuapl.edu", "evan.fuller@jhuapl.edu"], "authors": ["I-Jeng Wang", "Michael Pekala", "Evan Fuller"], "TL;DR": "A theoretical result on the local stability of adversarial examples and preliminary results on its implication for potential defense schemes.", "pdf": "/pdf/5e7d63a8d336fb97d36295c236ab63f585685b6b.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582712117, "id": "ICLR.cc/2018/Workshop/-/Paper209/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper209/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper209/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper209/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper209/AnonReviewer3"], "reply": {"forum": "HJly4D1vz", "replyto": "HJly4D1vz", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper209/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper209/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582712117}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573607904, "tcdate": 1521573607904, "number": 273, "cdate": 1521573607552, "id": "rJggyk1qf", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "HJly4D1vz", "replyto": "HJly4D1vz", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Local Stability of Adversarial Examples", "abstract": "Neural networks\u2019 lack of stability to \u201csmall\u201d perturbations of the input signal is a topic of substantial interest. Recent work has explored a number of properties of these so-called adversarial examples (AE) in an attempt to further understand this phenomenon. The present work continues in this spirit and provides an explicit characterization of stability for AE derived from very small perturbations. We also suggest future directions for how this characterization might be used in practice to mitigate the impact of these AE.", "paperhash": "wang|local_stability_of_adversarial_examples", "keywords": ["Adversarial Examples", "Local Stability"], "_bibtex": "@misc{\n  wang2018local,\n  title={Local Stability of Adversarial Examples},\n  author={I-Jeng Wang and Michael Pekala and Evan Fuller},\n  year={2018},\n  url={https://openreview.net/forum?id=HJly4D1vz}\n}", "authorids": ["i-jeng.wang@jhuapl.edu", "mike.pekala@jhuapl.edu", "evan.fuller@jhuapl.edu"], "authors": ["I-Jeng Wang", "Michael Pekala", "Evan Fuller"], "TL;DR": "A theoretical result on the local stability of adversarial examples and preliminary results on its implication for potential defense schemes.", "pdf": "/pdf/5e7d63a8d336fb97d36295c236ab63f585685b6b.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}