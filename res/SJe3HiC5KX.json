{"notes": [{"id": "SJe3HiC5KX", "original": "BkxjxHotYm", "number": 123, "cdate": 1538087748218, "ddate": null, "tcdate": 1538087748218, "tmdate": 1550498564800, "tddate": null, "forum": "SJe3HiC5KX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "LEARNING FACTORIZED REPRESENTATIONS FOR OPEN-SET DOMAIN ADAPTATION", "abstract": "Domain adaptation for visual recognition has undergone great progress in the past few years. Nevertheless, most existing methods work in the so-called closed-set scenario, assuming that the classes depicted by the target images are exactly the same as those of the source domain. In this paper, we tackle the more challenging, yet more realistic case of open-set domain adaptation, where new, unknown classes can be present in the target data. While, in the unsupervised scenario, one cannot expect to be able to identify each specific new class, we aim to automatically detect which samples belong to these new classes and discard them from the recognition process. To this end, we rely on the intuition that the source and target samples depicting the known classes can be generated by a shared subspace, whereas the target samples from unknown classes come from a different, private subspace. We therefore introduce a framework that factorizes the data into shared and private parts, while encouraging the shared representation to be discriminative. Our experiments on standard benchmarks evidence that our approach significantly outperforms the state-of-the-art in open-set domain adaptation.", "keywords": ["Open Set Domain Adaptation"], "authorids": ["m.baktashmotlagh@qut.edu.au", "masoud.faraki@monash.edu", "tom.drummond@monash.edu", "mathieu.salzmann@epfl.ch"], "authors": ["Mahsa Baktashmotlagh", "Masoud Faraki", "Tom Drummond", "Mathieu Salzmann"], "pdf": "/pdf/c9b2fc8a08c538ceb36722d5427c3e947f4d8ffa.pdf", "paperhash": "baktashmotlagh|learning_factorized_representations_for_openset_domain_adaptation", "_bibtex": "@inproceedings{\nbaktashmotlagh2018learning,\ntitle={{LEARNING} {FACTORIZED} {REPRESENTATIONS} {FOR} {OPEN}-{SET} {DOMAIN} {ADAPTATION}},\nauthor={Mahsa Baktashmotlagh and Masoud Faraki and Tom Drummond and Mathieu Salzmann},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJe3HiC5KX},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 16, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "H1lIXkOel4", "original": null, "number": 1, "cdate": 1544744734245, "ddate": null, "tcdate": 1544744734245, "tmdate": 1545354515430, "tddate": null, "forum": "SJe3HiC5KX", "replyto": "SJe3HiC5KX", "invitation": "ICLR.cc/2019/Conference/-/Paper123/Meta_Review", "content": {"metareview": "This paper proposes a new approach to domain adaptation based on sub-spacing, such that outliers are filtered out. While similar ideas have been used e.g. in multi-view learning, their application to domain adaptation makes it a novel and interesting approach. \n\nWhile the above is considered by the AC an adequate contribution to ICLR, the authors are encouraged to investigate further the implications of the assumptions made, in a way that the derived criteria seem less heuristic, as R1 pointed out.\n\nThere had been some concerns regarding the experiments, but the authors have been very active in the rebuttal period and addressed these concerns satisfactorily.\n", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Accept (Poster)", "title": "Attacking the domain adaptation problem from an interesting angle"}, "signatures": ["ICLR.cc/2019/Conference/Paper123/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper123/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING FACTORIZED REPRESENTATIONS FOR OPEN-SET DOMAIN ADAPTATION", "abstract": "Domain adaptation for visual recognition has undergone great progress in the past few years. Nevertheless, most existing methods work in the so-called closed-set scenario, assuming that the classes depicted by the target images are exactly the same as those of the source domain. In this paper, we tackle the more challenging, yet more realistic case of open-set domain adaptation, where new, unknown classes can be present in the target data. While, in the unsupervised scenario, one cannot expect to be able to identify each specific new class, we aim to automatically detect which samples belong to these new classes and discard them from the recognition process. To this end, we rely on the intuition that the source and target samples depicting the known classes can be generated by a shared subspace, whereas the target samples from unknown classes come from a different, private subspace. We therefore introduce a framework that factorizes the data into shared and private parts, while encouraging the shared representation to be discriminative. Our experiments on standard benchmarks evidence that our approach significantly outperforms the state-of-the-art in open-set domain adaptation.", "keywords": ["Open Set Domain Adaptation"], "authorids": ["m.baktashmotlagh@qut.edu.au", "masoud.faraki@monash.edu", "tom.drummond@monash.edu", "mathieu.salzmann@epfl.ch"], "authors": ["Mahsa Baktashmotlagh", "Masoud Faraki", "Tom Drummond", "Mathieu Salzmann"], "pdf": "/pdf/c9b2fc8a08c538ceb36722d5427c3e947f4d8ffa.pdf", "paperhash": "baktashmotlagh|learning_factorized_representations_for_openset_domain_adaptation", "_bibtex": "@inproceedings{\nbaktashmotlagh2018learning,\ntitle={{LEARNING} {FACTORIZED} {REPRESENTATIONS} {FOR} {OPEN}-{SET} {DOMAIN} {ADAPTATION}},\nauthor={Mahsa Baktashmotlagh and Masoud Faraki and Tom Drummond and Mathieu Salzmann},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJe3HiC5KX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper123/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353330395, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJe3HiC5KX", "replyto": "SJe3HiC5KX", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper123/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper123/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper123/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353330395}}}, {"id": "S1e2Kwm41V", "original": null, "number": 13, "cdate": 1543939971664, "ddate": null, "tcdate": 1543939971664, "tmdate": 1544050238145, "tddate": null, "forum": "SJe3HiC5KX", "replyto": "rylFaU-Q1E", "invitation": "ICLR.cc/2019/Conference/-/Paper123/Official_Comment", "content": {"title": "Response to AnonReviewer3", "comment": "Thank you for your response.\n\nWe re-ran the experiments on truly-unknown classes by further removing the Phone class in the Office experiment and compared the accuracy of our approach against the SVM baseline and the open-set ATI method of (Busto & Gall, 2017) using remaining 4 truly-unknown classes. The conclusions essentially remain unchanged, with the new results being: SVM: 76.01%, ATI: 77.4%, and D-FRODA: 78.2%. Note that, in this case, FRODA performs even a bit better than D-FRODA with 78.5% accuracy.\n \nThe results in Fig. 2 of the revised version were computed with k=1 nearest-neighbors, instead of k=3 for those in Table 4. Thank you for noticing this. We recomputed all the curves with k=3 and will revise the paper accordingly. The updated plots are available at: https://ibb.co/DG1k13Z . Note that we now also evaluate the influence of the value k on the results, although this parameter is only required in the NN version of our algorithm."}, "signatures": ["ICLR.cc/2019/Conference/Paper123/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper123/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING FACTORIZED REPRESENTATIONS FOR OPEN-SET DOMAIN ADAPTATION", "abstract": "Domain adaptation for visual recognition has undergone great progress in the past few years. Nevertheless, most existing methods work in the so-called closed-set scenario, assuming that the classes depicted by the target images are exactly the same as those of the source domain. In this paper, we tackle the more challenging, yet more realistic case of open-set domain adaptation, where new, unknown classes can be present in the target data. While, in the unsupervised scenario, one cannot expect to be able to identify each specific new class, we aim to automatically detect which samples belong to these new classes and discard them from the recognition process. To this end, we rely on the intuition that the source and target samples depicting the known classes can be generated by a shared subspace, whereas the target samples from unknown classes come from a different, private subspace. We therefore introduce a framework that factorizes the data into shared and private parts, while encouraging the shared representation to be discriminative. Our experiments on standard benchmarks evidence that our approach significantly outperforms the state-of-the-art in open-set domain adaptation.", "keywords": ["Open Set Domain Adaptation"], "authorids": ["m.baktashmotlagh@qut.edu.au", "masoud.faraki@monash.edu", "tom.drummond@monash.edu", "mathieu.salzmann@epfl.ch"], "authors": ["Mahsa Baktashmotlagh", "Masoud Faraki", "Tom Drummond", "Mathieu Salzmann"], "pdf": "/pdf/c9b2fc8a08c538ceb36722d5427c3e947f4d8ffa.pdf", "paperhash": "baktashmotlagh|learning_factorized_representations_for_openset_domain_adaptation", "_bibtex": "@inproceedings{\nbaktashmotlagh2018learning,\ntitle={{LEARNING} {FACTORIZED} {REPRESENTATIONS} {FOR} {OPEN}-{SET} {DOMAIN} {ADAPTATION}},\nauthor={Mahsa Baktashmotlagh and Masoud Faraki and Tom Drummond and Mathieu Salzmann},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJe3HiC5KX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper123/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615085, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJe3HiC5KX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper123/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper123/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper123/Authors|ICLR.cc/2019/Conference/Paper123/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615085}}}, {"id": "B1xndmvrhm", "original": null, "number": 2, "cdate": 1540875123894, "ddate": null, "tcdate": 1540875123894, "tmdate": 1543948090919, "tddate": null, "forum": "SJe3HiC5KX", "replyto": "SJe3HiC5KX", "invitation": "ICLR.cc/2019/Conference/-/Paper123/Official_Review", "content": {"title": "Intriguing formulation and performance; flaws in experiments", "review": "Pros:\n- Paper proposes a somewhat complicated but easy to understand idea for open set classification. Formulation is quite intriguing.\n- Outperforming recent baselines on most scenarios, despite being a linear classifier on fixed CNN features.\n\nCons:\n- Experiment setup somewhat flawed (but the same flaw is in prior work too)\n    To elaborate: DeCAF7 is trained on ImageNet, which gives the underlying network extra categorical information of the 1000 classes. Some of these clases are arguably in the \"unknown classes\" in the open set setting. This may jeopardize the premise since the feature knows those classes are semantically different from known classes. Unfortunately (Busto & Gall, 2017) and (Saito et al., 2018) do this too.\n    This is especially problematic since DeCAF7 has a near-linear relationship to the final sigmoid logits, which are the 1000-way ImageNet class scores. This makes the authors formulation (separate subspaces for known and unknown classes) more easily exploit this leaked information. This is because the 1000-way scores obviously have subspaces for all 1000 ImageNet classes, and by extension, the \"known\" and \"unknown\" classes in the open set setting. \n    If this is true and is the main reason that the proposed method outperforms, I would not consider the conclusion of the paper very informative. Instead, its signifies the need of a better experiment setup for the problem.\n    A way to strengthen the paper is to use a network pre-trained on other datasets (e.g. Places, or a subset of ImageNet) to verify the findings of the paper.\n- Lacks clarity for what is being done at test time. \n    I cannot find whether the final SVM is trained on original DeCAF features, or S and T. If it is the latter, how are the representations of target domain data obtained at test time? Are they d dimentional or 2d dimentional?\n    Can you clarify that the test samples are not used for unsupervised training?\n- Experiment elaborate but feels incomplete.\n    It feels like the authors are proposing 3 variations of the method, and there is not one of them that consistently outperform the others. If so, the paper would lack some ablation analysis that provides insights of what makes the FRODA-SVM outperform prior art. For example, how much do the hyperparameters matter? What happens if e.g. d or lambda1 is very large/small?\n\nClarity:\n- Abstract spends too much time on defining problem setup\n- \"Faster than prior work\" refers to the training time, and excludes the DeCAF feature extraction.\n\nOriginality:\nI am not familiar with the related work.\n\nSignificance:\nIt is quite impressive that a linear model on fixed CNN activations outperforms prior art. However, see the first point in the cons.\n\n\n-----------\nEdit: most of the issues listed in \"cons\" are addressed. Although the additional experiments are not very comprehensive, they can better support the claims. I am bumping up the rating to 7.\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper123/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "LEARNING FACTORIZED REPRESENTATIONS FOR OPEN-SET DOMAIN ADAPTATION", "abstract": "Domain adaptation for visual recognition has undergone great progress in the past few years. Nevertheless, most existing methods work in the so-called closed-set scenario, assuming that the classes depicted by the target images are exactly the same as those of the source domain. In this paper, we tackle the more challenging, yet more realistic case of open-set domain adaptation, where new, unknown classes can be present in the target data. While, in the unsupervised scenario, one cannot expect to be able to identify each specific new class, we aim to automatically detect which samples belong to these new classes and discard them from the recognition process. To this end, we rely on the intuition that the source and target samples depicting the known classes can be generated by a shared subspace, whereas the target samples from unknown classes come from a different, private subspace. We therefore introduce a framework that factorizes the data into shared and private parts, while encouraging the shared representation to be discriminative. Our experiments on standard benchmarks evidence that our approach significantly outperforms the state-of-the-art in open-set domain adaptation.", "keywords": ["Open Set Domain Adaptation"], "authorids": ["m.baktashmotlagh@qut.edu.au", "masoud.faraki@monash.edu", "tom.drummond@monash.edu", "mathieu.salzmann@epfl.ch"], "authors": ["Mahsa Baktashmotlagh", "Masoud Faraki", "Tom Drummond", "Mathieu Salzmann"], "pdf": "/pdf/c9b2fc8a08c538ceb36722d5427c3e947f4d8ffa.pdf", "paperhash": "baktashmotlagh|learning_factorized_representations_for_openset_domain_adaptation", "_bibtex": "@inproceedings{\nbaktashmotlagh2018learning,\ntitle={{LEARNING} {FACTORIZED} {REPRESENTATIONS} {FOR} {OPEN}-{SET} {DOMAIN} {ADAPTATION}},\nauthor={Mahsa Baktashmotlagh and Masoud Faraki and Tom Drummond and Mathieu Salzmann},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJe3HiC5KX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper123/Official_Review", "cdate": 1542234532848, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJe3HiC5KX", "replyto": "SJe3HiC5KX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper123/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335654254, "tmdate": 1552335654254, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper123/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rylFaU-Q1E", "original": null, "number": 12, "cdate": 1543866049215, "ddate": null, "tcdate": 1543866049215, "tmdate": 1543866049215, "tddate": null, "forum": "SJe3HiC5KX", "replyto": "HJew2UzZ1N", "invitation": "ICLR.cc/2019/Conference/-/Paper123/Official_Comment", "content": {"title": "Thank you for the clarification", "comment": "- Unfortunately some of the classes you listed are still in ImageNet. Namely,\nPhone: 487, 528, 707\nTshirt: 610\nPeople: 981, 982, 983\nArguably, if subcategories of a class are seen, then the class is not really new, since the features are trained to distinguish them from the rest of the categories too.\nBut I have some confidence that your method can still perform better than compared methods if you leave these out. Please kindly include the experiment in the appendix on any updated versions, and either remove the classes I listed or argue that they are indeed new classes.\n\n- Apologies for not seeing the reference of Fig. 2. Can you update the text and its figure caption so that it is clearer? \nAlso, Figure 2 plots seem to peak at around 78%, while in Table 4 D-FRODA-NN's average performance is 79.9%. Are you sure this is the experiment you ran for Figure 2?\n\n- Thank you for the update. Please kindly include the variance in Table 1 in a future version."}, "signatures": ["ICLR.cc/2019/Conference/Paper123/AnonReviewer3"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper123/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper123/AnonReviewer3", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING FACTORIZED REPRESENTATIONS FOR OPEN-SET DOMAIN ADAPTATION", "abstract": "Domain adaptation for visual recognition has undergone great progress in the past few years. Nevertheless, most existing methods work in the so-called closed-set scenario, assuming that the classes depicted by the target images are exactly the same as those of the source domain. In this paper, we tackle the more challenging, yet more realistic case of open-set domain adaptation, where new, unknown classes can be present in the target data. While, in the unsupervised scenario, one cannot expect to be able to identify each specific new class, we aim to automatically detect which samples belong to these new classes and discard them from the recognition process. To this end, we rely on the intuition that the source and target samples depicting the known classes can be generated by a shared subspace, whereas the target samples from unknown classes come from a different, private subspace. We therefore introduce a framework that factorizes the data into shared and private parts, while encouraging the shared representation to be discriminative. Our experiments on standard benchmarks evidence that our approach significantly outperforms the state-of-the-art in open-set domain adaptation.", "keywords": ["Open Set Domain Adaptation"], "authorids": ["m.baktashmotlagh@qut.edu.au", "masoud.faraki@monash.edu", "tom.drummond@monash.edu", "mathieu.salzmann@epfl.ch"], "authors": ["Mahsa Baktashmotlagh", "Masoud Faraki", "Tom Drummond", "Mathieu Salzmann"], "pdf": "/pdf/c9b2fc8a08c538ceb36722d5427c3e947f4d8ffa.pdf", "paperhash": "baktashmotlagh|learning_factorized_representations_for_openset_domain_adaptation", "_bibtex": "@inproceedings{\nbaktashmotlagh2018learning,\ntitle={{LEARNING} {FACTORIZED} {REPRESENTATIONS} {FOR} {OPEN}-{SET} {DOMAIN} {ADAPTATION}},\nauthor={Mahsa Baktashmotlagh and Masoud Faraki and Tom Drummond and Mathieu Salzmann},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJe3HiC5KX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper123/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615085, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJe3HiC5KX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper123/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper123/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper123/Authors|ICLR.cc/2019/Conference/Paper123/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615085}}}, {"id": "Hklg2V-Yhm", "original": null, "number": 3, "cdate": 1541112999835, "ddate": null, "tcdate": 1541112999835, "tmdate": 1543756730026, "tddate": null, "forum": "SJe3HiC5KX", "replyto": "SJe3HiC5KX", "invitation": "ICLR.cc/2019/Conference/-/Paper123/Official_Review", "content": {"title": "A novel method for Open-set Domain Adaptation which is a rather new problem and is thus interesting. Experimental evaluation is good, but the method requires more justification and analysis.", "review": "The paper addresses the problem of Domain Adaptation (DA) in an open setting (OSDA): while traditional DA assumes that the set of classes of the source and the target are identical, in Open-set DA, there are samples in the target which do not belong to any class in the source (unknown classes that I will outliers in this review). The main difficulty of Open-set DA is to simultaneously discard outliers and correctly classify other samples in the target. There are only two papers on Open-set DA so far, Busto'17 and Saito'18.\nThe method proposed by the authors can be summarized in a single equation, eq. 2, where they aim at learning a linear mapping to a latent space, which can be separated into two sub-spaces U (private space) and V (shared space) such that target outliers will be mapped to 0 in V while source and target non-outliers will be mapped to 0 in U, and hence separate outliers with non-outliers. To solve eq. 2, the authors convert it to Eqs. 3, 4, and 5 and apply techniques in Lee'07 and Mairal'14. The authors propose an extension for learning a linear classifier simultaneously and an extension for incorporating also unknown source classes (i.e. source outliers) when appropriate. An experimental evaluation on 2 datasets show the good performance of the method.\n\nPros:\n-A novel method for a rather new and understudied so far, the work is then interesting for this setting\n-Good results reported\n\nCons:\n-The criterion used for choosing when examples are outliers seems heuristic, more discussion would be welcomed as well as some qualitative analysis for showing the interest of the method\n-Existing baseline of Saito'18 not used in the 1st experiment\n-Some parts require more justification\n\n*Comments:\n\n-The idea of the method is similar to the one of Jia'10 (Eq.6) for multi view learning, but this is rather new for Open-set DA.\n\n-In order to separate target samples to either private or shared, the authors \"encourage that either of these two parts (i.e. vectors T_i^u and T_i^v) goes to zero for each sample\", which is reasonable. To achieve this the authors use sparse coding method coming from Lee'07. However, this does not make sense to me, because the sparse coding algorithm will encourage both T_i^u and T_i^v to be sparse, but nothing forces one of them to go to the zero-vector.\nThe authors should then better justify this choice. In particular, I wonder if adding explicitly the criterion used for identifying outliers as a new constraint to satisfy. Then, the optimization problem considered would make more sense to me.\n\nAnyway, the authors could perform additional experiments to show the effectiveness of their method: (i) apply on a classic DA problem where we will expect that ||T^u|| or ||U|| (private subspace for outliers) should be close to zero. \nAdd a qualitative analysis on the values of  |T^u|| and |T^v|| - both in Open-set DA and classic DA - showing that the results are as expected. \n\n- The 1st method (Eq.2) learns the latent space without using any label in the source (i.e there are only two labels: outlier or non-outlier, and all source samples are labeled non-outlier). Thus, the authors resort to the assumption that outliers are farther from source samples than non-outliers. This assumption is strong and may not hold in practice for two reasons: (1) the domain shift can be large and (2) without clustering techniques, many outliers can easily fall into the safe non-outliers zone (consider 0-4 for outliers and 5-9 for non-outliers, high chance this method will incorrectly classify 0 or 3 as non-outliers since 6,8,9 are already non-outliers). \n\n- The Lagrange dual method (Lee'07, Eq. 6) solves an optimization problem with multiple quadratic constraints, i.e. ||U_j||^2 \\le c for every j. However, the authors apply it to solve a problem (eq. 3 and 4) with a single linear constraint which is not quadratic: \\sum ||U_j|| \\le 1. Please explain:\n(i) Why do you use that constrain instead of the one in Lee'07?\n(ii) With your constrain, does the Lagrange dual method still work? \n\n-The authors mention that they reported the results reported by Busto'17 in their experiment. Does this mean that the experiments were not reproduced? If so this seems rather unfair for other baselines since they may have worked on different instances. \nMany baselines are not specific to Open-set DA, so it is rather expected to see bad results.\nSince OSDA is new, it is true that there exists only two true baselines: Busto'17 and Saito'18. However, Saito'18 does not appear in BCIS benchmark (although appears in Office benchmark). Please add Saito'18 to the BCIS benchmark.\n\n-The authors use fixed parameters for all the subproblems, I am a bit surprised by this choice, I would rather expect a parameterization task-dependent. Does this mean that the method is hard to tune ?\n\n-The method seems complex, is there any convergence guarantee?\n\n--\nAfter rebuttal: thanks many points were answered.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper123/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "LEARNING FACTORIZED REPRESENTATIONS FOR OPEN-SET DOMAIN ADAPTATION", "abstract": "Domain adaptation for visual recognition has undergone great progress in the past few years. Nevertheless, most existing methods work in the so-called closed-set scenario, assuming that the classes depicted by the target images are exactly the same as those of the source domain. In this paper, we tackle the more challenging, yet more realistic case of open-set domain adaptation, where new, unknown classes can be present in the target data. While, in the unsupervised scenario, one cannot expect to be able to identify each specific new class, we aim to automatically detect which samples belong to these new classes and discard them from the recognition process. To this end, we rely on the intuition that the source and target samples depicting the known classes can be generated by a shared subspace, whereas the target samples from unknown classes come from a different, private subspace. We therefore introduce a framework that factorizes the data into shared and private parts, while encouraging the shared representation to be discriminative. Our experiments on standard benchmarks evidence that our approach significantly outperforms the state-of-the-art in open-set domain adaptation.", "keywords": ["Open Set Domain Adaptation"], "authorids": ["m.baktashmotlagh@qut.edu.au", "masoud.faraki@monash.edu", "tom.drummond@monash.edu", "mathieu.salzmann@epfl.ch"], "authors": ["Mahsa Baktashmotlagh", "Masoud Faraki", "Tom Drummond", "Mathieu Salzmann"], "pdf": "/pdf/c9b2fc8a08c538ceb36722d5427c3e947f4d8ffa.pdf", "paperhash": "baktashmotlagh|learning_factorized_representations_for_openset_domain_adaptation", "_bibtex": "@inproceedings{\nbaktashmotlagh2018learning,\ntitle={{LEARNING} {FACTORIZED} {REPRESENTATIONS} {FOR} {OPEN}-{SET} {DOMAIN} {ADAPTATION}},\nauthor={Mahsa Baktashmotlagh and Masoud Faraki and Tom Drummond and Mathieu Salzmann},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJe3HiC5KX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper123/Official_Review", "cdate": 1542234532848, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJe3HiC5KX", "replyto": "SJe3HiC5KX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper123/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335654254, "tmdate": 1552335654254, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper123/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HJew2UzZ1N", "original": null, "number": 10, "cdate": 1543739055493, "ddate": null, "tcdate": 1543739055493, "tmdate": 1543739055493, "tddate": null, "forum": "SJe3HiC5KX", "replyto": "HkxVfJFnCm", "invitation": "ICLR.cc/2019/Conference/-/Paper123/Official_Comment", "content": {"title": "Response to AnonReviewer3", "comment": "Thank you for your response.\n\n- We extracted the truly-new classes in Office and BCIS by comparing their classes with those of ImageNet (https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a). The truly-new classes in Office are:\nTape dispenser, Stapler, Scissors, Punchers, and Phone. Those in BCIS are: Windmill, Tshirt, Steering wheel, Can_soda, sneaker, skyscraper, Ladder, Motorcycle, Palmtree, and People. Computing results on these truly-new classes does not involve only evaluation because all methods work in the transductive setting and were thus re-trained for the truly-new class scenario. Note that, despite our best efforts at tuning hyper-parameters, we were unable to obtain reasonable results for AODA for this experiment.\n\nWe initially thought of incorporating these results to the main paper, but felt it would be confusing for the reader unless a rather long explanation was provided. Following the reviewer\u2019s suggestion, we will include and discuss them in detail in the appendix. \n\n- Figure 2 is referenced just above the paragraph Runtimes on Page 8, but we will clarify the details of this experiment. In particular, Fig. 2 evaluates the robustness of our method to the hyper-parameters of \u03b1, \u03b2, and \u03bb. To this end, we plot the average accuracy of D-FRODA-NN from Table 4 over all 6 pairs of the Office dataset as a function of the value of \u03b1, \u03b2, and \u03bb.\n\n- The variance of the average for AODA and our approach in Table 1 are 1.7 and 2.2, respectively. While we agree that we only have a small advantage over AODA on BCIS, the gap is larger on Office. We will clarify this in the final version of the paper."}, "signatures": ["ICLR.cc/2019/Conference/Paper123/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper123/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING FACTORIZED REPRESENTATIONS FOR OPEN-SET DOMAIN ADAPTATION", "abstract": "Domain adaptation for visual recognition has undergone great progress in the past few years. Nevertheless, most existing methods work in the so-called closed-set scenario, assuming that the classes depicted by the target images are exactly the same as those of the source domain. In this paper, we tackle the more challenging, yet more realistic case of open-set domain adaptation, where new, unknown classes can be present in the target data. While, in the unsupervised scenario, one cannot expect to be able to identify each specific new class, we aim to automatically detect which samples belong to these new classes and discard them from the recognition process. To this end, we rely on the intuition that the source and target samples depicting the known classes can be generated by a shared subspace, whereas the target samples from unknown classes come from a different, private subspace. We therefore introduce a framework that factorizes the data into shared and private parts, while encouraging the shared representation to be discriminative. Our experiments on standard benchmarks evidence that our approach significantly outperforms the state-of-the-art in open-set domain adaptation.", "keywords": ["Open Set Domain Adaptation"], "authorids": ["m.baktashmotlagh@qut.edu.au", "masoud.faraki@monash.edu", "tom.drummond@monash.edu", "mathieu.salzmann@epfl.ch"], "authors": ["Mahsa Baktashmotlagh", "Masoud Faraki", "Tom Drummond", "Mathieu Salzmann"], "pdf": "/pdf/c9b2fc8a08c538ceb36722d5427c3e947f4d8ffa.pdf", "paperhash": "baktashmotlagh|learning_factorized_representations_for_openset_domain_adaptation", "_bibtex": "@inproceedings{\nbaktashmotlagh2018learning,\ntitle={{LEARNING} {FACTORIZED} {REPRESENTATIONS} {FOR} {OPEN}-{SET} {DOMAIN} {ADAPTATION}},\nauthor={Mahsa Baktashmotlagh and Masoud Faraki and Tom Drummond and Mathieu Salzmann},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJe3HiC5KX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper123/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615085, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJe3HiC5KX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper123/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper123/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper123/Authors|ICLR.cc/2019/Conference/Paper123/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615085}}}, {"id": "HkxVfJFnCm", "original": null, "number": 9, "cdate": 1543438092412, "ddate": null, "tcdate": 1543438092412, "tmdate": 1543438429753, "tddate": null, "forum": "SJe3HiC5KX", "replyto": "S1gMYY4SRm", "invitation": "ICLR.cc/2019/Conference/-/Paper123/Official_Comment", "content": {"title": "Are the changes reflected in the text? They are a little hard to understand.", "comment": "Thank you for your response! I am glad that you did an extra evaluation on truly new samples. However, I am having a hard time interpreting the additional results, because there is not enough explanation in the rebuttal and the updated pdf.\n\n- Specifically, have you updated the truly-new samples' results in the paper, or at least as part of the appendix? Can you list the truly-new classes in Office that are not in ImageNet? Why are there classes in BCIS that are not in ImageNet, considering that ImageNet is actually one of the B,C,*I*,S datasets? Which source/target pair is your extra results performed on? Why not compare to all the compared methods, since it is only evaluation and is not computationally expensive?\n\n- Another hard-to-tell update is Figure 2 -- it is not referenced in the text, and I have no idea which experiment (which column of Table 3, if it is about an experiment in Table 3) this figure is referring to. What does \"revised version of Office\" mean? Is it on the 5 truly-new classes settings (there is no table or any reference in the text about this setting)?\n\n- Regarding the \"average\" column that Reviewer 2 has mentioned -- it lacks a variance. Considering Saito (2018) is close to your performance, I would like to see the variance of the average of both methods' performance.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper123/AnonReviewer3"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper123/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper123/AnonReviewer3", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING FACTORIZED REPRESENTATIONS FOR OPEN-SET DOMAIN ADAPTATION", "abstract": "Domain adaptation for visual recognition has undergone great progress in the past few years. Nevertheless, most existing methods work in the so-called closed-set scenario, assuming that the classes depicted by the target images are exactly the same as those of the source domain. In this paper, we tackle the more challenging, yet more realistic case of open-set domain adaptation, where new, unknown classes can be present in the target data. While, in the unsupervised scenario, one cannot expect to be able to identify each specific new class, we aim to automatically detect which samples belong to these new classes and discard them from the recognition process. To this end, we rely on the intuition that the source and target samples depicting the known classes can be generated by a shared subspace, whereas the target samples from unknown classes come from a different, private subspace. We therefore introduce a framework that factorizes the data into shared and private parts, while encouraging the shared representation to be discriminative. Our experiments on standard benchmarks evidence that our approach significantly outperforms the state-of-the-art in open-set domain adaptation.", "keywords": ["Open Set Domain Adaptation"], "authorids": ["m.baktashmotlagh@qut.edu.au", "masoud.faraki@monash.edu", "tom.drummond@monash.edu", "mathieu.salzmann@epfl.ch"], "authors": ["Mahsa Baktashmotlagh", "Masoud Faraki", "Tom Drummond", "Mathieu Salzmann"], "pdf": "/pdf/c9b2fc8a08c538ceb36722d5427c3e947f4d8ffa.pdf", "paperhash": "baktashmotlagh|learning_factorized_representations_for_openset_domain_adaptation", "_bibtex": "@inproceedings{\nbaktashmotlagh2018learning,\ntitle={{LEARNING} {FACTORIZED} {REPRESENTATIONS} {FOR} {OPEN}-{SET} {DOMAIN} {ADAPTATION}},\nauthor={Mahsa Baktashmotlagh and Masoud Faraki and Tom Drummond and Mathieu Salzmann},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJe3HiC5KX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper123/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615085, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJe3HiC5KX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper123/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper123/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper123/Authors|ICLR.cc/2019/Conference/Paper123/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615085}}}, {"id": "rkxO1KVBRQ", "original": null, "number": 5, "cdate": 1542961375737, "ddate": null, "tcdate": 1542961375737, "tmdate": 1542961560882, "tddate": null, "forum": "SJe3HiC5KX", "replyto": "HylgmsCnnm", "invitation": "ICLR.cc/2019/Conference/-/Paper123/Official_Comment", "content": {"title": "Response to AnonReviewer2", "comment": "As requested by AnonReviewer2, we have now added a column to each table showing the average for all methods. This column further evidences that we outperform the baselines.\n\nRegarding the AODA results, in our submission, we reported the numbers from the arXiv version of this paper, which was the only available version then. We have now updated the AODA results according to the final version of the paper. Note that the conclusions remain unchanged.\n\nTo evaluate the robustness of our method to the hyper-parameters \\alpha, \\beta and \\lambda, we have included a figure plotting the accuracy, averaged over all pairs of the Office dataset, as a function of the values of these hyper-parameters. As shown in Figure 2 of the revised version, our results are stable for a wide range of values.\n\nTo determine the dimensionality d of our subspaces, we make use of the subspace disagreement measure of Gong\u201912, as explained in the implementation details of the paper."}, "signatures": ["ICLR.cc/2019/Conference/Paper123/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper123/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING FACTORIZED REPRESENTATIONS FOR OPEN-SET DOMAIN ADAPTATION", "abstract": "Domain adaptation for visual recognition has undergone great progress in the past few years. Nevertheless, most existing methods work in the so-called closed-set scenario, assuming that the classes depicted by the target images are exactly the same as those of the source domain. In this paper, we tackle the more challenging, yet more realistic case of open-set domain adaptation, where new, unknown classes can be present in the target data. While, in the unsupervised scenario, one cannot expect to be able to identify each specific new class, we aim to automatically detect which samples belong to these new classes and discard them from the recognition process. To this end, we rely on the intuition that the source and target samples depicting the known classes can be generated by a shared subspace, whereas the target samples from unknown classes come from a different, private subspace. We therefore introduce a framework that factorizes the data into shared and private parts, while encouraging the shared representation to be discriminative. Our experiments on standard benchmarks evidence that our approach significantly outperforms the state-of-the-art in open-set domain adaptation.", "keywords": ["Open Set Domain Adaptation"], "authorids": ["m.baktashmotlagh@qut.edu.au", "masoud.faraki@monash.edu", "tom.drummond@monash.edu", "mathieu.salzmann@epfl.ch"], "authors": ["Mahsa Baktashmotlagh", "Masoud Faraki", "Tom Drummond", "Mathieu Salzmann"], "pdf": "/pdf/c9b2fc8a08c538ceb36722d5427c3e947f4d8ffa.pdf", "paperhash": "baktashmotlagh|learning_factorized_representations_for_openset_domain_adaptation", "_bibtex": "@inproceedings{\nbaktashmotlagh2018learning,\ntitle={{LEARNING} {FACTORIZED} {REPRESENTATIONS} {FOR} {OPEN}-{SET} {DOMAIN} {ADAPTATION}},\nauthor={Mahsa Baktashmotlagh and Masoud Faraki and Tom Drummond and Mathieu Salzmann},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJe3HiC5KX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper123/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615085, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJe3HiC5KX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper123/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper123/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper123/Authors|ICLR.cc/2019/Conference/Paper123/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615085}}}, {"id": "S1gMYY4SRm", "original": null, "number": 7, "cdate": 1542961530296, "ddate": null, "tcdate": 1542961530296, "tmdate": 1542961530296, "tddate": null, "forum": "SJe3HiC5KX", "replyto": "B1xndmvrhm", "invitation": "ICLR.cc/2019/Conference/-/Paper123/Official_Comment", "content": {"title": "Response to AnonReviewer3", "comment": "AnonRev3 is concerned that the experimental setup used in (Busto & Gall, 2017), (Saito et al., 2018) and our work for open-set DA is flawed because the methods rely on features extracted using a network pre-trained on ImageNet, which in fact has seen the unknown classes. To address this and validate our results, we observed that 5 of the unknown classes in the Office dataset do not appear in ImageNet. We therefore performed additional experiments with only these classes as unknown ones and the same 10 known classes as before. We compared the accuracy of our D-FRODA formulation against the SVM baseline and the open-set ATI method of (Busto & Gall, 2017). The gap with respect to both baselines remains large: SVM: 76.8%, ATI: 77.01%, and D-FRODA: 79.2%. This confirms that our method applies to truly never-seen-before classes. Note that among the 15 unknown classes in the current setup for BCIS, only 5 are shared with ImageNet.\n\nAt test time, we use the low-dimensional representations S and T for classification. Specifically, we first determine whether each target sample belongs to a known or unknown class based on the ratio of ||T_i^v|| to ||T_i^u||, as discussed in the Inference paragraph below Eq. 5. In the presence of C known classes, we then train a (C+1)-way classifier by augmenting the low-dimensional source data S, with the target samples T^u identified as unknown. We have clarified this in the paper.\nAs requested by the reviewer, we performed an ablation study to evaluate the influence of the hyper-parameters on our results. As shown in Figure 2 of the revised version for the Office dataset, our results are stable for a wide range of values.\n\nOur runtime comparison was done with respect to the approach of (Busto & Gall, 2017), which uses the same DeCAF features. We have clarified this in the paper."}, "signatures": ["ICLR.cc/2019/Conference/Paper123/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper123/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING FACTORIZED REPRESENTATIONS FOR OPEN-SET DOMAIN ADAPTATION", "abstract": "Domain adaptation for visual recognition has undergone great progress in the past few years. Nevertheless, most existing methods work in the so-called closed-set scenario, assuming that the classes depicted by the target images are exactly the same as those of the source domain. In this paper, we tackle the more challenging, yet more realistic case of open-set domain adaptation, where new, unknown classes can be present in the target data. While, in the unsupervised scenario, one cannot expect to be able to identify each specific new class, we aim to automatically detect which samples belong to these new classes and discard them from the recognition process. To this end, we rely on the intuition that the source and target samples depicting the known classes can be generated by a shared subspace, whereas the target samples from unknown classes come from a different, private subspace. We therefore introduce a framework that factorizes the data into shared and private parts, while encouraging the shared representation to be discriminative. Our experiments on standard benchmarks evidence that our approach significantly outperforms the state-of-the-art in open-set domain adaptation.", "keywords": ["Open Set Domain Adaptation"], "authorids": ["m.baktashmotlagh@qut.edu.au", "masoud.faraki@monash.edu", "tom.drummond@monash.edu", "mathieu.salzmann@epfl.ch"], "authors": ["Mahsa Baktashmotlagh", "Masoud Faraki", "Tom Drummond", "Mathieu Salzmann"], "pdf": "/pdf/c9b2fc8a08c538ceb36722d5427c3e947f4d8ffa.pdf", "paperhash": "baktashmotlagh|learning_factorized_representations_for_openset_domain_adaptation", "_bibtex": "@inproceedings{\nbaktashmotlagh2018learning,\ntitle={{LEARNING} {FACTORIZED} {REPRESENTATIONS} {FOR} {OPEN}-{SET} {DOMAIN} {ADAPTATION}},\nauthor={Mahsa Baktashmotlagh and Masoud Faraki and Tom Drummond and Mathieu Salzmann},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJe3HiC5KX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper123/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615085, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJe3HiC5KX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper123/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper123/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper123/Authors|ICLR.cc/2019/Conference/Paper123/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615085}}}, {"id": "HJgM4Y4BCm", "original": null, "number": 6, "cdate": 1542961450152, "ddate": null, "tcdate": 1542961450152, "tmdate": 1542961450152, "tddate": null, "forum": "SJe3HiC5KX", "replyto": "Hklg2V-Yhm", "invitation": "ICLR.cc/2019/Conference/-/Paper123/Official_Comment", "content": {"title": "Response to AnonReviewer1", "comment": "Our approach differs from that of Jia\u201910 and, for the open-set DA scenario, is more intuitive; we model each target sample as being generated by either the shared subspace or the private one, which is crucial to identify the target samples depicting unknown classes. By contrast, in Jia'10, each sample is encoded as a mixture of shared and private representations. This would make separating known and unknown target samples difficult. This is explained in the related work section of our paper.\n\nRegarding the sparsity of T_i^u and T_i^v, there seems to be a misunderstanding. We make use of group sparsity on these vectors, as indicated by the L_{1,2} norm in, e.g., Eq. 2. This differs from standard sparsity, which uses the L_1 norm. As a consequence, we encourage the entire vectors T_i^u and T_i^v to go to zero. The reconstruction term then prevents that they both go to 0 simultaneously. Because we use group sparsity and not standard sparsity, we cannot use the entire algorithm of Lee\u201907. However, we can use a part of this algorithm to update the bases U and V, since this step does not involve the group sparsity terms. Obtaining T is then done by proximal gradient descent. This is discussed in the Optimization paragraph below Eq. 2.\n\nOur formulation in Eq. 2 includes reconstruction terms based on the subspace representations. Our assumption is that the appearance variations between the known and unknown classes are more important than those across the domains for a given class. As such, it will be easier for our method to use a separate subspace for the unknown samples instead of using the source one, which is dedicated to modeling the appearance of the known classes. We believe that the good results of our FRODA approach confirm this intuition. We acknowledge, however, that adding a discriminative term (D-FRODA) typically improves the results.\n\nThere was a typo in our paper. We also use quadratic constraints of the form ||U_j||^2 \\leq 1. As such, the Lagrange dual algorithm used in Lee\u201907 to update the basis also applies for the same purpose in our case. We thank the reviewer for noticing this and fixed this in the revised version.\n\nComparison to Saito\u201918 on BCIS. We have now incorporated these results in Table 1. Note that, as mentioned in our earlier comment to the reviewer, for the comparison to be fair, we used DeCAF-fc7 features, which are used by all other methods, including ours, and are the only data available for this benchmark. We proposed to make use of a network with two Fully Connected (FC) layers, with 1024 and 128 units, respectively, and a final classification layer, and took the DeCAF-fc7 features as input. As suggested by Saito\u201918, we used Leakly-ReLU activation functions and batch normalisation for stable training. As shown in Table 1, we also outperform Saito\u201918 on this dataset.\n\nWe believe that the fact that we use fixed hyper-parameters for all our experiments rather shows the robustness of our approach. Note that, in domain adaptation, one does not have access to validation target data, since the target examples are unlabeled. Nevertheless, in Figure 2 of the revised paper, we now evaluate the influence of the hyper-parameters on the results for the Office dataset. Note that our method is robust to the values of these hyper-parameters.\n\nThe overall method is non-convex, because we learn both the bases and the coefficients. However, the individual subproblems that we solve are convex and solved to optimality. As such each step is guaranteed not to increase the objective function, and the method thus converges to a stationary point."}, "signatures": ["ICLR.cc/2019/Conference/Paper123/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper123/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING FACTORIZED REPRESENTATIONS FOR OPEN-SET DOMAIN ADAPTATION", "abstract": "Domain adaptation for visual recognition has undergone great progress in the past few years. Nevertheless, most existing methods work in the so-called closed-set scenario, assuming that the classes depicted by the target images are exactly the same as those of the source domain. In this paper, we tackle the more challenging, yet more realistic case of open-set domain adaptation, where new, unknown classes can be present in the target data. While, in the unsupervised scenario, one cannot expect to be able to identify each specific new class, we aim to automatically detect which samples belong to these new classes and discard them from the recognition process. To this end, we rely on the intuition that the source and target samples depicting the known classes can be generated by a shared subspace, whereas the target samples from unknown classes come from a different, private subspace. We therefore introduce a framework that factorizes the data into shared and private parts, while encouraging the shared representation to be discriminative. Our experiments on standard benchmarks evidence that our approach significantly outperforms the state-of-the-art in open-set domain adaptation.", "keywords": ["Open Set Domain Adaptation"], "authorids": ["m.baktashmotlagh@qut.edu.au", "masoud.faraki@monash.edu", "tom.drummond@monash.edu", "mathieu.salzmann@epfl.ch"], "authors": ["Mahsa Baktashmotlagh", "Masoud Faraki", "Tom Drummond", "Mathieu Salzmann"], "pdf": "/pdf/c9b2fc8a08c538ceb36722d5427c3e947f4d8ffa.pdf", "paperhash": "baktashmotlagh|learning_factorized_representations_for_openset_domain_adaptation", "_bibtex": "@inproceedings{\nbaktashmotlagh2018learning,\ntitle={{LEARNING} {FACTORIZED} {REPRESENTATIONS} {FOR} {OPEN}-{SET} {DOMAIN} {ADAPTATION}},\nauthor={Mahsa Baktashmotlagh and Masoud Faraki and Tom Drummond and Mathieu Salzmann},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJe3HiC5KX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper123/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615085, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJe3HiC5KX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper123/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper123/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper123/Authors|ICLR.cc/2019/Conference/Paper123/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615085}}}, {"id": "rJx5jO4BAX", "original": null, "number": 4, "cdate": 1542961313928, "ddate": null, "tcdate": 1542961313928, "tmdate": 1542961313928, "tddate": null, "forum": "SJe3HiC5KX", "replyto": "SJe3HiC5KX", "invitation": "ICLR.cc/2019/Conference/-/Paper123/Official_Comment", "content": {"title": "Summary", "comment": "We thank the reviewers for their constructive feedback and their overall positive comments. They mention that \u201cthe paper is well organized and easy to read\u201d, and the mathematical formulation of the method is \u201csound\u201d, and \u201cclearly explained\u201d. They also highlight that we propose a \u201cnovel method\u201d for an \u201cunderstudied\u201d problem.\n\nIn the following, we summarize the changes we made to the paper:\n    \u2022\tWe have added a column to each table showing the average for all methods.\n    \u2022\tTo evaluate the robustness of our method to the hyper-parameters \\alpha, \\beta and \\lambda, we have included a figure plotting the accuracy, averaged over all pairs of the Office dataset, as a function of the values of these hyper-parameters.\n   \u2022\tWe have incorporated the results of Saito\u201918 on the BCIS dataset in Table 1.\n   \u2022\tWe have added more details about our approach at test time.\n   \u2022\tWe have taken all minor comments of the reviewers into account.\n\nIn addition to this, we have compared the accuracy of our D-FRODA formulation against the SVM baseline and the open-set ATI method of (Busto & Gall, 2017) using as unknown classes the 5 classes in the Office dataset that do not appear in ImageNet, thus demonstrating the effectiveness of our approach in the presence of truly unknown classes.\n\nWe address the reviewers' main concerns in more detail in the individual responses."}, "signatures": ["ICLR.cc/2019/Conference/Paper123/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper123/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING FACTORIZED REPRESENTATIONS FOR OPEN-SET DOMAIN ADAPTATION", "abstract": "Domain adaptation for visual recognition has undergone great progress in the past few years. Nevertheless, most existing methods work in the so-called closed-set scenario, assuming that the classes depicted by the target images are exactly the same as those of the source domain. In this paper, we tackle the more challenging, yet more realistic case of open-set domain adaptation, where new, unknown classes can be present in the target data. While, in the unsupervised scenario, one cannot expect to be able to identify each specific new class, we aim to automatically detect which samples belong to these new classes and discard them from the recognition process. To this end, we rely on the intuition that the source and target samples depicting the known classes can be generated by a shared subspace, whereas the target samples from unknown classes come from a different, private subspace. We therefore introduce a framework that factorizes the data into shared and private parts, while encouraging the shared representation to be discriminative. Our experiments on standard benchmarks evidence that our approach significantly outperforms the state-of-the-art in open-set domain adaptation.", "keywords": ["Open Set Domain Adaptation"], "authorids": ["m.baktashmotlagh@qut.edu.au", "masoud.faraki@monash.edu", "tom.drummond@monash.edu", "mathieu.salzmann@epfl.ch"], "authors": ["Mahsa Baktashmotlagh", "Masoud Faraki", "Tom Drummond", "Mathieu Salzmann"], "pdf": "/pdf/c9b2fc8a08c538ceb36722d5427c3e947f4d8ffa.pdf", "paperhash": "baktashmotlagh|learning_factorized_representations_for_openset_domain_adaptation", "_bibtex": "@inproceedings{\nbaktashmotlagh2018learning,\ntitle={{LEARNING} {FACTORIZED} {REPRESENTATIONS} {FOR} {OPEN}-{SET} {DOMAIN} {ADAPTATION}},\nauthor={Mahsa Baktashmotlagh and Masoud Faraki and Tom Drummond and Mathieu Salzmann},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJe3HiC5KX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper123/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615085, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJe3HiC5KX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper123/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper123/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper123/Authors|ICLR.cc/2019/Conference/Paper123/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615085}}}, {"id": "HylQS64NAm", "original": null, "number": 3, "cdate": 1542896955025, "ddate": null, "tcdate": 1542896955025, "tmdate": 1542896955025, "tddate": null, "forum": "SJe3HiC5KX", "replyto": "rJgehkAj67", "invitation": "ICLR.cc/2019/Conference/-/Paper123/Official_Comment", "content": {"title": "Re: Results of Saito'18 on the BCIS benchmark", "comment": "Yes, what is important is to follow the principle of the main structure of Saito's architecture, for the layers it is up to you but you should tune them a bit to get an objective result. "}, "signatures": ["ICLR.cc/2019/Conference/Paper123/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper123/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper123/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING FACTORIZED REPRESENTATIONS FOR OPEN-SET DOMAIN ADAPTATION", "abstract": "Domain adaptation for visual recognition has undergone great progress in the past few years. Nevertheless, most existing methods work in the so-called closed-set scenario, assuming that the classes depicted by the target images are exactly the same as those of the source domain. In this paper, we tackle the more challenging, yet more realistic case of open-set domain adaptation, where new, unknown classes can be present in the target data. While, in the unsupervised scenario, one cannot expect to be able to identify each specific new class, we aim to automatically detect which samples belong to these new classes and discard them from the recognition process. To this end, we rely on the intuition that the source and target samples depicting the known classes can be generated by a shared subspace, whereas the target samples from unknown classes come from a different, private subspace. We therefore introduce a framework that factorizes the data into shared and private parts, while encouraging the shared representation to be discriminative. Our experiments on standard benchmarks evidence that our approach significantly outperforms the state-of-the-art in open-set domain adaptation.", "keywords": ["Open Set Domain Adaptation"], "authorids": ["m.baktashmotlagh@qut.edu.au", "masoud.faraki@monash.edu", "tom.drummond@monash.edu", "mathieu.salzmann@epfl.ch"], "authors": ["Mahsa Baktashmotlagh", "Masoud Faraki", "Tom Drummond", "Mathieu Salzmann"], "pdf": "/pdf/c9b2fc8a08c538ceb36722d5427c3e947f4d8ffa.pdf", "paperhash": "baktashmotlagh|learning_factorized_representations_for_openset_domain_adaptation", "_bibtex": "@inproceedings{\nbaktashmotlagh2018learning,\ntitle={{LEARNING} {FACTORIZED} {REPRESENTATIONS} {FOR} {OPEN}-{SET} {DOMAIN} {ADAPTATION}},\nauthor={Mahsa Baktashmotlagh and Masoud Faraki and Tom Drummond and Mathieu Salzmann},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJe3HiC5KX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper123/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615085, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJe3HiC5KX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper123/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper123/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper123/Authors|ICLR.cc/2019/Conference/Paper123/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615085}}}, {"id": "rJgehkAj67", "original": null, "number": 2, "cdate": 1542344616424, "ddate": null, "tcdate": 1542344616424, "tmdate": 1542344616424, "tddate": null, "forum": "SJe3HiC5KX", "replyto": "Hklg2V-Yhm", "invitation": "ICLR.cc/2019/Conference/-/Paper123/Official_Comment", "content": {"title": "Results of Saito'18 on the BCIS benchmark", "comment": "For the BCIS dataset, the only data that is publicly available, and that was used for all results in Table 1 of our paper, is the 4096-dimensional DeCAF-fc7 features. As such, to compare our results with Saito\u201918, which relies on deep learning, we need to define a neural network that takes these features as input. We propose to make use of a network with two Fully Connected (FC) layers, with 1024 and 128 units, respectively, with ReLU activation functions, and a final classification layer. Would AnonReviewer1 be satisfied with this comparison?"}, "signatures": ["ICLR.cc/2019/Conference/Paper123/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper123/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING FACTORIZED REPRESENTATIONS FOR OPEN-SET DOMAIN ADAPTATION", "abstract": "Domain adaptation for visual recognition has undergone great progress in the past few years. Nevertheless, most existing methods work in the so-called closed-set scenario, assuming that the classes depicted by the target images are exactly the same as those of the source domain. In this paper, we tackle the more challenging, yet more realistic case of open-set domain adaptation, where new, unknown classes can be present in the target data. While, in the unsupervised scenario, one cannot expect to be able to identify each specific new class, we aim to automatically detect which samples belong to these new classes and discard them from the recognition process. To this end, we rely on the intuition that the source and target samples depicting the known classes can be generated by a shared subspace, whereas the target samples from unknown classes come from a different, private subspace. We therefore introduce a framework that factorizes the data into shared and private parts, while encouraging the shared representation to be discriminative. Our experiments on standard benchmarks evidence that our approach significantly outperforms the state-of-the-art in open-set domain adaptation.", "keywords": ["Open Set Domain Adaptation"], "authorids": ["m.baktashmotlagh@qut.edu.au", "masoud.faraki@monash.edu", "tom.drummond@monash.edu", "mathieu.salzmann@epfl.ch"], "authors": ["Mahsa Baktashmotlagh", "Masoud Faraki", "Tom Drummond", "Mathieu Salzmann"], "pdf": "/pdf/c9b2fc8a08c538ceb36722d5427c3e947f4d8ffa.pdf", "paperhash": "baktashmotlagh|learning_factorized_representations_for_openset_domain_adaptation", "_bibtex": "@inproceedings{\nbaktashmotlagh2018learning,\ntitle={{LEARNING} {FACTORIZED} {REPRESENTATIONS} {FOR} {OPEN}-{SET} {DOMAIN} {ADAPTATION}},\nauthor={Mahsa Baktashmotlagh and Masoud Faraki and Tom Drummond and Mathieu Salzmann},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJe3HiC5KX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper123/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615085, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJe3HiC5KX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper123/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper123/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper123/Authors|ICLR.cc/2019/Conference/Paper123/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615085}}}, {"id": "HylgmsCnnm", "original": null, "number": 4, "cdate": 1541364504065, "ddate": null, "tcdate": 1541364504065, "tmdate": 1541534262474, "tddate": null, "forum": "SJe3HiC5KX", "replyto": "SJe3HiC5KX", "invitation": "ICLR.cc/2019/Conference/-/Paper123/Official_Review", "content": {"title": "effective method for open set domain adaptation", "review": "This paper tackles the problem of open-set unsupervised domain adaptation with a method based on \nsubspace learning. Specifically the proposed approach searches for two low-dimensional spaces, one shared \nby the known source and target categories while the other is specific for the unknown classes. \n\nOverall the paper is well organized and easy to read. The mathematical formulation of the method is sound and\nclearly explained in all its variants.\n\nI have few concerns \n- it would be good to have the \"average\" columns in the tables reporting the experimental results. This will help to have an overall idea on the performance of the different proposed and baseline methods.\n- it is not clear whether the authors are reporting the results of AODA from the original paper or if they re-ran the code to get the recognition accuracies. For instance in table 3 the result 70.1 for A->W is lower than those reported in the original paper for this setting.\n- the paper does not discuss how the hyperparameters of the methods are chosen. Only an analysis on epsilon is provided. It would be very helpful to understand the procedure used to select the values of alpha, beta and lambda and to evaluate the robustness of the method to those parameters. Moreover,  the value of the dimensionality d is not explicitly indicated in the text. This should be added together with a discussion about if and how the subspace disagreement measure (that was introduced for closed set domain adaptation) is reliable in the open set condition.\n\n\n\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper123/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING FACTORIZED REPRESENTATIONS FOR OPEN-SET DOMAIN ADAPTATION", "abstract": "Domain adaptation for visual recognition has undergone great progress in the past few years. Nevertheless, most existing methods work in the so-called closed-set scenario, assuming that the classes depicted by the target images are exactly the same as those of the source domain. In this paper, we tackle the more challenging, yet more realistic case of open-set domain adaptation, where new, unknown classes can be present in the target data. While, in the unsupervised scenario, one cannot expect to be able to identify each specific new class, we aim to automatically detect which samples belong to these new classes and discard them from the recognition process. To this end, we rely on the intuition that the source and target samples depicting the known classes can be generated by a shared subspace, whereas the target samples from unknown classes come from a different, private subspace. We therefore introduce a framework that factorizes the data into shared and private parts, while encouraging the shared representation to be discriminative. Our experiments on standard benchmarks evidence that our approach significantly outperforms the state-of-the-art in open-set domain adaptation.", "keywords": ["Open Set Domain Adaptation"], "authorids": ["m.baktashmotlagh@qut.edu.au", "masoud.faraki@monash.edu", "tom.drummond@monash.edu", "mathieu.salzmann@epfl.ch"], "authors": ["Mahsa Baktashmotlagh", "Masoud Faraki", "Tom Drummond", "Mathieu Salzmann"], "pdf": "/pdf/c9b2fc8a08c538ceb36722d5427c3e947f4d8ffa.pdf", "paperhash": "baktashmotlagh|learning_factorized_representations_for_openset_domain_adaptation", "_bibtex": "@inproceedings{\nbaktashmotlagh2018learning,\ntitle={{LEARNING} {FACTORIZED} {REPRESENTATIONS} {FOR} {OPEN}-{SET} {DOMAIN} {ADAPTATION}},\nauthor={Mahsa Baktashmotlagh and Masoud Faraki and Tom Drummond and Mathieu Salzmann},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJe3HiC5KX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper123/Official_Review", "cdate": 1542234532848, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJe3HiC5KX", "replyto": "SJe3HiC5KX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper123/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335654254, "tmdate": 1552335654254, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper123/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "ryx6iEO_9X", "original": null, "number": 1, "cdate": 1538978981319, "ddate": null, "tcdate": 1538978981319, "tmdate": 1540366293780, "tddate": null, "forum": "SJe3HiC5KX", "replyto": "r1lbmBkUq7", "invitation": "ICLR.cc/2019/Conference/-/Paper123/Official_Comment", "content": {"title": "Re: Baseline", "comment": "Note that domain generalization and open-set domain adaptation address fundamentally different tasks: Generalization relies on the availability of multiple source domains during training to learn a model that applies to yet another domain at test time. All the domains are assumed to contain the exact same classes. By contrast, open-set DA tackles the problem of accounting for new classes in the target domain. Domain generalization is inapplicable to this scenario, and existing generalization methods therefore cannot act as baselines for our approach."}, "signatures": ["ICLR.cc/2019/Conference/Paper123/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper123/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING FACTORIZED REPRESENTATIONS FOR OPEN-SET DOMAIN ADAPTATION", "abstract": "Domain adaptation for visual recognition has undergone great progress in the past few years. Nevertheless, most existing methods work in the so-called closed-set scenario, assuming that the classes depicted by the target images are exactly the same as those of the source domain. In this paper, we tackle the more challenging, yet more realistic case of open-set domain adaptation, where new, unknown classes can be present in the target data. While, in the unsupervised scenario, one cannot expect to be able to identify each specific new class, we aim to automatically detect which samples belong to these new classes and discard them from the recognition process. To this end, we rely on the intuition that the source and target samples depicting the known classes can be generated by a shared subspace, whereas the target samples from unknown classes come from a different, private subspace. We therefore introduce a framework that factorizes the data into shared and private parts, while encouraging the shared representation to be discriminative. Our experiments on standard benchmarks evidence that our approach significantly outperforms the state-of-the-art in open-set domain adaptation.", "keywords": ["Open Set Domain Adaptation"], "authorids": ["m.baktashmotlagh@qut.edu.au", "masoud.faraki@monash.edu", "tom.drummond@monash.edu", "mathieu.salzmann@epfl.ch"], "authors": ["Mahsa Baktashmotlagh", "Masoud Faraki", "Tom Drummond", "Mathieu Salzmann"], "pdf": "/pdf/c9b2fc8a08c538ceb36722d5427c3e947f4d8ffa.pdf", "paperhash": "baktashmotlagh|learning_factorized_representations_for_openset_domain_adaptation", "_bibtex": "@inproceedings{\nbaktashmotlagh2018learning,\ntitle={{LEARNING} {FACTORIZED} {REPRESENTATIONS} {FOR} {OPEN}-{SET} {DOMAIN} {ADAPTATION}},\nauthor={Mahsa Baktashmotlagh and Masoud Faraki and Tom Drummond and Mathieu Salzmann},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJe3HiC5KX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper123/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615085, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJe3HiC5KX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper123/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper123/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper123/Authors|ICLR.cc/2019/Conference/Paper123/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615085}}}, {"id": "HJguSukp57", "original": null, "number": 2, "cdate": 1539270719998, "ddate": null, "tcdate": 1539270719998, "tmdate": 1539270719998, "tddate": null, "forum": "SJe3HiC5KX", "replyto": "r1lbmBkUq7", "invitation": "ICLR.cc/2019/Conference/-/Paper123/Public_Comment", "content": {"comment": "This paper proposes a new method to detect unknown classes in the target domain, which is a generalization of standard single-source domain adaptation where the label set is exactly the same. Domain generalization is a special multi-source domain adaptation setting where target domain data are not given during learning. I could not see why domain generalization methods can be considered as baselines here.", "title": "Re: baseline"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper123/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "LEARNING FACTORIZED REPRESENTATIONS FOR OPEN-SET DOMAIN ADAPTATION", "abstract": "Domain adaptation for visual recognition has undergone great progress in the past few years. Nevertheless, most existing methods work in the so-called closed-set scenario, assuming that the classes depicted by the target images are exactly the same as those of the source domain. In this paper, we tackle the more challenging, yet more realistic case of open-set domain adaptation, where new, unknown classes can be present in the target data. While, in the unsupervised scenario, one cannot expect to be able to identify each specific new class, we aim to automatically detect which samples belong to these new classes and discard them from the recognition process. To this end, we rely on the intuition that the source and target samples depicting the known classes can be generated by a shared subspace, whereas the target samples from unknown classes come from a different, private subspace. We therefore introduce a framework that factorizes the data into shared and private parts, while encouraging the shared representation to be discriminative. Our experiments on standard benchmarks evidence that our approach significantly outperforms the state-of-the-art in open-set domain adaptation.", "keywords": ["Open Set Domain Adaptation"], "authorids": ["m.baktashmotlagh@qut.edu.au", "masoud.faraki@monash.edu", "tom.drummond@monash.edu", "mathieu.salzmann@epfl.ch"], "authors": ["Mahsa Baktashmotlagh", "Masoud Faraki", "Tom Drummond", "Mathieu Salzmann"], "pdf": "/pdf/c9b2fc8a08c538ceb36722d5427c3e947f4d8ffa.pdf", "paperhash": "baktashmotlagh|learning_factorized_representations_for_openset_domain_adaptation", "_bibtex": "@inproceedings{\nbaktashmotlagh2018learning,\ntitle={{LEARNING} {FACTORIZED} {REPRESENTATIONS} {FOR} {OPEN}-{SET} {DOMAIN} {ADAPTATION}},\nauthor={Mahsa Baktashmotlagh and Masoud Faraki and Tom Drummond and Mathieu Salzmann},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SJe3HiC5KX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper123/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311913423, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "SJe3HiC5KX", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper123/Authors", "ICLR.cc/2019/Conference/Paper123/Reviewers", "ICLR.cc/2019/Conference/Paper123/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311913423}}}], "count": 17}