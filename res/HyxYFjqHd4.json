{"notes": [{"id": "HyxYFjqHd4", "original": "SJgqXFFBuN", "number": 62, "cdate": 1553472384664, "ddate": null, "tcdate": 1553472384664, "tmdate": 1562082112077, "tddate": null, "forum": "HyxYFjqHd4", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "Interactions between Representation Learning and Supervision", "authors": ["Valliappa Chockalingam"], "authorids": ["valliapp@ualberta.ca"], "keywords": [], "abstract": "Representation learning is one of the fundamental problems of machine learning. On its own, this problem can be cast as an unsupervised dimensionality reduction problem. However, representation learning is often also used as an implicit step in supervised learning (SL) or reinforcement learning (RL) problems. In this paper, we study the possible \"interference\" supervision, commonly provided through a loss function in SL or a reward function in RL, might have on learning representations, through the lens of learning from limited data and continual learning. Particularly, in connectionist networks, we often face the problem of catastrophic interference whereby changes in the data distribution cause networks to fail to remember previously learned information and learning representations can be done without labeled data. A primary running hypothesis is that representations learned using unsupervised learning are more robust to changes in the data distribution as compared to the intermediate representations learned when using supervision because supervision interferes with otherwise \"unconstrained\" representation learning objectives. To empirically test hypotheses, we perform experiments using a standard dataset for continual learning, permuted MNIST. Additionally, through a heuristic quantifying the amount of change in the data distribution, we verify that the results are statistically significant.", "pdf": "/pdf/157bc0856ed9f597e7f4aef2e227b86ed9321284.pdf", "paperhash": "chockalingam|interactions_between_representation_learning_and_supervision"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "OpenReview.net"}, {"id": "BylW7o4dKE", "original": null, "number": 1, "cdate": 1554692889367, "ddate": null, "tcdate": 1554692889367, "tmdate": 1555511885119, "tddate": null, "forum": "HyxYFjqHd4", "replyto": "HyxYFjqHd4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper62/Official_Review", "content": {"title": "Review of \"Interactions between Representation Learning and Supervision\"", "review": "Summary of the paper:\n\nThis paper tries to propose an empirical investigation of the interference/side effect an intermediate representation learning step might have on the supervised learning process.\n\n\nReviewer\u2019s assessment:\nBesides the fact that the problem is not exposed clearly (even in the introduction) it is particularly hard to make sense of the \u201cProposed Approach\u201d, and in general to make sense of the whole point of the paper.  The paper is fairly hard to read and is filled with statements having no connection with the previous claims.\nLast, for such type of work, a broader diversity of numerical experiments is usually expected.\nHence, I cannot  recommend to accept this paper.\n", "rating": "1: Strong rejection", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper62/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper62/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Interactions between Representation Learning and Supervision", "authors": ["Valliappa Chockalingam"], "authorids": ["valliapp@ualberta.ca"], "keywords": [], "abstract": "Representation learning is one of the fundamental problems of machine learning. On its own, this problem can be cast as an unsupervised dimensionality reduction problem. However, representation learning is often also used as an implicit step in supervised learning (SL) or reinforcement learning (RL) problems. In this paper, we study the possible \"interference\" supervision, commonly provided through a loss function in SL or a reward function in RL, might have on learning representations, through the lens of learning from limited data and continual learning. Particularly, in connectionist networks, we often face the problem of catastrophic interference whereby changes in the data distribution cause networks to fail to remember previously learned information and learning representations can be done without labeled data. A primary running hypothesis is that representations learned using unsupervised learning are more robust to changes in the data distribution as compared to the intermediate representations learned when using supervision because supervision interferes with otherwise \"unconstrained\" representation learning objectives. To empirically test hypotheses, we perform experiments using a standard dataset for continual learning, permuted MNIST. Additionally, through a heuristic quantifying the amount of change in the data distribution, we verify that the results are statistically significant.", "pdf": "/pdf/157bc0856ed9f597e7f4aef2e227b86ed9321284.pdf", "paperhash": "chockalingam|interactions_between_representation_learning_and_supervision"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper62/Official_Review", "cdate": 1553713411102, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "HyxYFjqHd4", "replyto": "HyxYFjqHd4", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper62/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper62/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713411102, "tmdate": 1555511821262, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper62/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "S1gmK6tdY4", "original": null, "number": 2, "cdate": 1554713979429, "ddate": null, "tcdate": 1554713979429, "tmdate": 1555511883608, "tddate": null, "forum": "HyxYFjqHd4", "replyto": "HyxYFjqHd4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper62/Official_Review", "content": {"title": "Initial empirical evaluation on the robustness of learned representation to distribution shift", "review": "Summary\n\nIn this paper, the authors ask the question on if we lose general representation by implicitly performing representation learning in supervised settings. In order to empirically answer this question, the authors empirically demonstrate the following 2 observations using permuted MNIST dataset:\n\n1. Representation achieved from unsupervised learning can support fine tuning classifiers for different data distribution and achieve equally well performance. However, representation implicitly derived from supervised learning demonstrates degraded performance for fine-tuning classifier on new data distribution.\n\n2. By using representation achieved from unsupervised learning, a classifier can adapt to an old data distribution after being trained on new distributions, more quickly than using representation derived from supervised learning.\n\nComments:\n\n1. Technical question: In the computer vision literature, it is well recognized representation learned from supervised training (e.g. using imagenet) generalizes well when fine tuning other dataset in image recognition. However, to the best of my knowledge, there is not too much work on transfer representation from unsupervised learning to other recognition tasks. I was wondering if there is a trade-off between the performance of unsupervised representation and and its generality when the target goal is to achieve better performance for downstream tasks. \n\n2. Quality: In order to better demonstrate the investigation, I would suggest evaluate the learned representation on more different tasks. This will help better validate the claim that unsupervised learning can achieve better generally performant representation. Currently the validation focus on synthetically modified distribution. But I think this is fine as initial work for the workshop.\n\n3. Related work: I would suggest citing literatures in NLP and vision on using supervised/unsupervised representation (e.g. word embeddings, and transfer deep feature extractors in image recognition and other tasks.)\n", "rating": "3: Marginally above acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper62/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper62/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Interactions between Representation Learning and Supervision", "authors": ["Valliappa Chockalingam"], "authorids": ["valliapp@ualberta.ca"], "keywords": [], "abstract": "Representation learning is one of the fundamental problems of machine learning. On its own, this problem can be cast as an unsupervised dimensionality reduction problem. However, representation learning is often also used as an implicit step in supervised learning (SL) or reinforcement learning (RL) problems. In this paper, we study the possible \"interference\" supervision, commonly provided through a loss function in SL or a reward function in RL, might have on learning representations, through the lens of learning from limited data and continual learning. Particularly, in connectionist networks, we often face the problem of catastrophic interference whereby changes in the data distribution cause networks to fail to remember previously learned information and learning representations can be done without labeled data. A primary running hypothesis is that representations learned using unsupervised learning are more robust to changes in the data distribution as compared to the intermediate representations learned when using supervision because supervision interferes with otherwise \"unconstrained\" representation learning objectives. To empirically test hypotheses, we perform experiments using a standard dataset for continual learning, permuted MNIST. Additionally, through a heuristic quantifying the amount of change in the data distribution, we verify that the results are statistically significant.", "pdf": "/pdf/157bc0856ed9f597e7f4aef2e227b86ed9321284.pdf", "paperhash": "chockalingam|interactions_between_representation_learning_and_supervision"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper62/Official_Review", "cdate": 1553713411102, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "HyxYFjqHd4", "replyto": "HyxYFjqHd4", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper62/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper62/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713411102, "tmdate": 1555511821262, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper62/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "SJeYERnf54", "original": null, "number": 1, "cdate": 1555381808549, "ddate": null, "tcdate": 1555381808549, "tmdate": 1555510976596, "tddate": null, "forum": "HyxYFjqHd4", "replyto": "HyxYFjqHd4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper62/Decision", "content": {"title": "Acceptance Decision", "decision": "Reject", "comment": "reivewers found no proposed method and the current empirical analysis too narrow"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Interactions between Representation Learning and Supervision", "authors": ["Valliappa Chockalingam"], "authorids": ["valliapp@ualberta.ca"], "keywords": [], "abstract": "Representation learning is one of the fundamental problems of machine learning. On its own, this problem can be cast as an unsupervised dimensionality reduction problem. However, representation learning is often also used as an implicit step in supervised learning (SL) or reinforcement learning (RL) problems. In this paper, we study the possible \"interference\" supervision, commonly provided through a loss function in SL or a reward function in RL, might have on learning representations, through the lens of learning from limited data and continual learning. Particularly, in connectionist networks, we often face the problem of catastrophic interference whereby changes in the data distribution cause networks to fail to remember previously learned information and learning representations can be done without labeled data. A primary running hypothesis is that representations learned using unsupervised learning are more robust to changes in the data distribution as compared to the intermediate representations learned when using supervision because supervision interferes with otherwise \"unconstrained\" representation learning objectives. To empirically test hypotheses, we perform experiments using a standard dataset for continual learning, permuted MNIST. Additionally, through a heuristic quantifying the amount of change in the data distribution, we verify that the results are statistically significant.", "pdf": "/pdf/157bc0856ed9f597e7f4aef2e227b86ed9321284.pdf", "paperhash": "chockalingam|interactions_between_representation_learning_and_supervision"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper62/Decision", "cdate": 1554736072558, "reply": {"forum": "HyxYFjqHd4", "replyto": "HyxYFjqHd4", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736072558, "tmdate": 1555510966266, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 4}