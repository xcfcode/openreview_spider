{"notes": [{"id": "HkeAepVKDH", "original": "ByxckqH8DS", "number": 358, "cdate": 1569438966114, "ddate": null, "tcdate": 1569438966114, "tmdate": 1577168246875, "tddate": null, "forum": "HkeAepVKDH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "QGAN: Quantize Generative Adversarial Networks to Extreme low-bits", "authors": ["Peiqi Wang", "Yu Ji", "Xinfeng Xie", "Yongqiang Lyu", "Dongsheng Wang", "Yuan Xie"], "authorids": ["wpq14@tsinghua.org.cn", "jiy15@mails.tsinghua.edu.cn", "xinfeng@ucsb.edu", "luyq@tsinghua.edu.cn", "wds@mail.tsinghua.edu.cn", "yuanxie@ucsb.edu"], "keywords": ["generative adversarial networks", "quantization", "extreme low bits"], "abstract": "The intensive computation and memory requirements of generative adversarial neural networks (GANs) hinder its real-world deployment on edge devices such as smartphones. Despite the success in model reduction of convolutional neural networks (CNNs), neural network quantization methods have not yet been studied on GANs, which are mainly faced with the issues of both the effectiveness of quantization algorithms and the instability of training GAN models. In this paper, we start with an extensive study on applying existing successful CNN quantization methods to quantize GAN models to extreme low bits. Our observation reveals that none of them generates samples with reasonable quality because of the underrepresentation of quantized weights in models, and the generator and discriminator networks show different sensitivities upon the quantization precision. Motivated by these observations, we develop a novel quantization method for GANs based on EM algorithms, named as QGAN. We also propose a multi-precision algorithm to help find an appropriate quantization precision of GANs given image qualities requirements. Experiments on CIFAR-10 and CelebA show that QGAN can quantize weights in GANs to even 1-bit or 2-bit representations with results of quality comparable to original models.", "pdf": "/pdf/6b971cf2d0bffedcd02cfdf6bced6057264badb5.pdf", "paperhash": "wang|qgan_quantize_generative_adversarial_networks_to_extreme_lowbits", "original_pdf": "/attachment/6b971cf2d0bffedcd02cfdf6bced6057264badb5.pdf", "_bibtex": "@misc{\nwang2020qgan,\ntitle={{\\{}QGAN{\\}}: Quantize Generative Adversarial Networks to Extreme low-bits},\nauthor={Peiqi Wang and Yu Ji and Xinfeng Xie and Yongqiang Lyu and Dongsheng Wang and Yuan Xie},\nyear={2020},\nurl={https://openreview.net/forum?id=HkeAepVKDH}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "OZSvmQrcj", "original": null, "number": 1, "cdate": 1576798694124, "ddate": null, "tcdate": 1576798694124, "tmdate": 1576800941382, "tddate": null, "forum": "HkeAepVKDH", "replyto": "HkeAepVKDH", "invitation": "ICLR.cc/2020/Conference/Paper358/-/Decision", "content": {"decision": "Reject", "comment": "main summary:  method for quantizing GAN\n\ndiscussion:\nreviewer 1: well-written paper, but reviewer questions novelty\nreviewer 2: well-written, but some details are missing in the paper as well as comparisons to related work\nreviewer 3: well-written and interesting topic, related work section and clarity of results could be improved\nrecommendation: all reviewers agree paper could be improved by better comparison to related work and better clarity of presentation. Marking paper as reject.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "QGAN: Quantize Generative Adversarial Networks to Extreme low-bits", "authors": ["Peiqi Wang", "Yu Ji", "Xinfeng Xie", "Yongqiang Lyu", "Dongsheng Wang", "Yuan Xie"], "authorids": ["wpq14@tsinghua.org.cn", "jiy15@mails.tsinghua.edu.cn", "xinfeng@ucsb.edu", "luyq@tsinghua.edu.cn", "wds@mail.tsinghua.edu.cn", "yuanxie@ucsb.edu"], "keywords": ["generative adversarial networks", "quantization", "extreme low bits"], "abstract": "The intensive computation and memory requirements of generative adversarial neural networks (GANs) hinder its real-world deployment on edge devices such as smartphones. Despite the success in model reduction of convolutional neural networks (CNNs), neural network quantization methods have not yet been studied on GANs, which are mainly faced with the issues of both the effectiveness of quantization algorithms and the instability of training GAN models. In this paper, we start with an extensive study on applying existing successful CNN quantization methods to quantize GAN models to extreme low bits. Our observation reveals that none of them generates samples with reasonable quality because of the underrepresentation of quantized weights in models, and the generator and discriminator networks show different sensitivities upon the quantization precision. Motivated by these observations, we develop a novel quantization method for GANs based on EM algorithms, named as QGAN. We also propose a multi-precision algorithm to help find an appropriate quantization precision of GANs given image qualities requirements. Experiments on CIFAR-10 and CelebA show that QGAN can quantize weights in GANs to even 1-bit or 2-bit representations with results of quality comparable to original models.", "pdf": "/pdf/6b971cf2d0bffedcd02cfdf6bced6057264badb5.pdf", "paperhash": "wang|qgan_quantize_generative_adversarial_networks_to_extreme_lowbits", "original_pdf": "/attachment/6b971cf2d0bffedcd02cfdf6bced6057264badb5.pdf", "_bibtex": "@misc{\nwang2020qgan,\ntitle={{\\{}QGAN{\\}}: Quantize Generative Adversarial Networks to Extreme low-bits},\nauthor={Peiqi Wang and Yu Ji and Xinfeng Xie and Yongqiang Lyu and Dongsheng Wang and Yuan Xie},\nyear={2020},\nurl={https://openreview.net/forum?id=HkeAepVKDH}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "HkeAepVKDH", "replyto": "HkeAepVKDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795729767, "tmdate": 1576800282427, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper358/-/Decision"}}}, {"id": "H1ek2paPor", "original": null, "number": 5, "cdate": 1573539239483, "ddate": null, "tcdate": 1573539239483, "tmdate": 1573539239483, "tddate": null, "forum": "HkeAepVKDH", "replyto": "S1gsfgPVtS", "invitation": "ICLR.cc/2020/Conference/Paper358/-/Official_Comment", "content": {"title": "Response to Reviewer #3", "comment": "Thank you for your valuable comments! \n\nQ1: Related work\nA1: We add extra experiments on the other two related work, Outlier Channel Splitting (OCS) and Analytical Clipping for Integer Quantization (ACIQ). The results can be seen in the A1 in response to Reviewer #1. OCS duplicates channels containing outliers then halve the channel values, ACIQ uses an approximate closed-form solution to decide the clip threshold. The results shown in the above table indicate QGAN still gets the best or comparable results in all cases. We will add more related work and experiment results as you kindly suggested. \n\nQ2: Result validity\nA2: \n- Scale\nWe have shown the results on different image scale, i.e. 32x32 in cifar-10, 64x64 in celebA, and 128x128 in celebA. QGAN performs similarly on different scales compared with the baselines. Due to limited computational resources, it's very difficult for us to try a much larger model or dataset. On the other hand, the GAN quantization field is still in the early stage, and we believe some basic problems exist in both small scale and large scale models/datasets. For example, the unstable training of quantized GAN model, the accuracy loss of quantization. We believe our work has made initial steps on these problems and can motivate our research community.\n- Metrics\nThe GAN metrics have known shortcomings, thus we use both Inception Score (IS) and Frchet Inception Distance (FID) as numerical evaluation, which is widely used in GAN-related papers. At the same time, we show the generated samples as well to give the results as convincing as possible. We use all metrics as far as we know, and we hope the results can be accepted by the community.\n\nQ3: Novelty\nA3: \n- Our detailed sensitivity analysis brings insights for GAN quantizations.\n- The main contribution of our work is to propose a quantization method for GAN models. From the study in 3.1, results in Table 2, as well as the extra experiments we added in the table above, we can figure out directly apply the quantization methods which work well in CNN to GAN leads to huge quality loss. Our EM-based quantization is more accurate and narrows quantized errors. Smaller errors not only enable quantized GAN to be successfully trained but also improve the qualities of the result. It solves the unstable training problem of extreme low-bit quantized GAN, which is the biggest challenge compared to CNN.\n- Our multi-precision method gives solutions in smaller bits and reduces the search space effectively\n\nThank you again for the detailed review. We believe the observations and claims in our paper can help the community moving on the study on GAN quantization, which is an important problem in real-world deployment on edge devices.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper358/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "QGAN: Quantize Generative Adversarial Networks to Extreme low-bits", "authors": ["Peiqi Wang", "Yu Ji", "Xinfeng Xie", "Yongqiang Lyu", "Dongsheng Wang", "Yuan Xie"], "authorids": ["wpq14@tsinghua.org.cn", "jiy15@mails.tsinghua.edu.cn", "xinfeng@ucsb.edu", "luyq@tsinghua.edu.cn", "wds@mail.tsinghua.edu.cn", "yuanxie@ucsb.edu"], "keywords": ["generative adversarial networks", "quantization", "extreme low bits"], "abstract": "The intensive computation and memory requirements of generative adversarial neural networks (GANs) hinder its real-world deployment on edge devices such as smartphones. Despite the success in model reduction of convolutional neural networks (CNNs), neural network quantization methods have not yet been studied on GANs, which are mainly faced with the issues of both the effectiveness of quantization algorithms and the instability of training GAN models. In this paper, we start with an extensive study on applying existing successful CNN quantization methods to quantize GAN models to extreme low bits. Our observation reveals that none of them generates samples with reasonable quality because of the underrepresentation of quantized weights in models, and the generator and discriminator networks show different sensitivities upon the quantization precision. Motivated by these observations, we develop a novel quantization method for GANs based on EM algorithms, named as QGAN. We also propose a multi-precision algorithm to help find an appropriate quantization precision of GANs given image qualities requirements. Experiments on CIFAR-10 and CelebA show that QGAN can quantize weights in GANs to even 1-bit or 2-bit representations with results of quality comparable to original models.", "pdf": "/pdf/6b971cf2d0bffedcd02cfdf6bced6057264badb5.pdf", "paperhash": "wang|qgan_quantize_generative_adversarial_networks_to_extreme_lowbits", "original_pdf": "/attachment/6b971cf2d0bffedcd02cfdf6bced6057264badb5.pdf", "_bibtex": "@misc{\nwang2020qgan,\ntitle={{\\{}QGAN{\\}}: Quantize Generative Adversarial Networks to Extreme low-bits},\nauthor={Peiqi Wang and Yu Ji and Xinfeng Xie and Yongqiang Lyu and Dongsheng Wang and Yuan Xie},\nyear={2020},\nurl={https://openreview.net/forum?id=HkeAepVKDH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HkeAepVKDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper358/Authors", "ICLR.cc/2020/Conference/Paper358/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper358/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper358/Reviewers", "ICLR.cc/2020/Conference/Paper358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper358/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper358/Authors|ICLR.cc/2020/Conference/Paper358/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504172622, "tmdate": 1576860548394, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper358/Authors", "ICLR.cc/2020/Conference/Paper358/Reviewers", "ICLR.cc/2020/Conference/Paper358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper358/-/Official_Comment"}}}, {"id": "S1eI46pPor", "original": null, "number": 4, "cdate": 1573539117892, "ddate": null, "tcdate": 1573539117892, "tmdate": 1573539117892, "tddate": null, "forum": "HkeAepVKDH", "replyto": "BkxGc0P1qS", "invitation": "ICLR.cc/2020/Conference/Paper358/-/Official_Comment", "content": {"title": "Response to Reviewer #2", "comment": "Thank you for your valuable comments! \n\nQ1: Standard deviation for results\nA1: We add the standard deviation for the results of Minmax-Q and QGAN in Table 2 in Section 5.1. Here we quantize both generators and discriminators, thus the standard deviation is not too large. Comparing the standard deviation for the results of Minmax-Q and QGAN, we can figure out QGAN is more stable as an additional benefit. We will add the standard deviation for other results in our paper later.\n----------------------------------------------------------\n                             |  Minmax-Q |  QGAN     | \n----------------------------------------------------------\n1-bit | IS (dev)   | 1.16(0.36)  | 3.32(0.23) |\n         | FID(dev) | 407.9(67.4) | 96.7(9.8)  |\n----------------------------------------------------------\n2-bit | IS (dev)   | 2.65(0.18)  | 4.15(0.21) |\n         | FID(dev) | 132.4(26.1) | 54.3(4.9)  |\n----------------------------------------------------------\n3-bit | IS (dev)   | 4.35(0.31)  | 4.46(0.15) |\n         | FID(dev) | 65.1(9.8)    | 51.4(3.9)  |\n----------------------------------------------------------\n4-bit | IS (dev)   | 4.74(0.11)  | 4.60(0.20) |\n         | FID(dev) | 40.3(2.9)    | 39.6(4.7)  |\n----------------------------------------------------------\n\nQ2: Details of experiments implementations\nA2: In Section 3.1 we also quantize the pre-trained full precision model. We will describe the experimental methods clearly in the paper. \n\nQ3: Difference with vector quantization\nA3: The main difference between VQ and QGAN is the optimization objective. VQ uses k-means to optimize the quantization levels directly, while QGAN adopts an EM algorithm to optimize the coefficient of linear quantization.\n\nQ4: Question on the Equation(7)\nA4: $p(w_i, z_i|\\alpha, \\beta)$ is proportional to $exp{(-(w_i - f^{-1}(z_i; \\alpha, \\beta))^2}$, thus, in equation(7), C means the log term for the coefficient, which is a constant.\n\nQ5: Experiments in Section 5.1\nA5: In Section 5.1 we only use the EM-based quantization method proposed in Section 4.1. The two-phase training described in Section 4.2 are evaluated in Section 5.2, and Table 3 shows the final results combining the methods proposed in 4.1 and 4.2.\n\nQ6: Question on Figure 2c and 4c\nA6: We show the trend of IS over training epoch in Figure 2c, while in Figure 4c we only draw the best IS that can be obtained for a given number of bits. Therefore, the thrashing is not shown in Figure 4 but still exists. For example, only quantizing the generator to 4 bits using Log-Q can get IS up to over 4.5 but the lowest is only 1.0 (This case is shown in green line in Figure 2c). For more precise and clear analysis, we will add standard deviation for results as you suggested later. \n\nQ7: Results in Table 3\nA7: We use the two-phase quantization method proposed in 4.2 to obtain the quantized bits in Table 3, that is to say, we greedily first quantize the discriminator and then quantize the generator. This method reduces search times in the solution space efficiently and finally gives the lowest number of bits needed by the generator to meet the given requirement. We did traverse all cases in extreme low-bit (<= 4-bit) and verified the bit configurations given by our proposed methods are the best performance. \n\nQ8: Results in Section 3.1\nA8: GAN is unstable during training. It is more sensitive to quantized errors, which may result in non-convergence, mode collapse, or other problems during training, which motivates us to develop QGAN that quantizes weights more accurately to reduce errors, ensuring training quantized GAN stably.\n\nFurthermore, we will modify the typos and notations in our paper later. Thank you again for your constructive feedback!  \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper358/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "QGAN: Quantize Generative Adversarial Networks to Extreme low-bits", "authors": ["Peiqi Wang", "Yu Ji", "Xinfeng Xie", "Yongqiang Lyu", "Dongsheng Wang", "Yuan Xie"], "authorids": ["wpq14@tsinghua.org.cn", "jiy15@mails.tsinghua.edu.cn", "xinfeng@ucsb.edu", "luyq@tsinghua.edu.cn", "wds@mail.tsinghua.edu.cn", "yuanxie@ucsb.edu"], "keywords": ["generative adversarial networks", "quantization", "extreme low bits"], "abstract": "The intensive computation and memory requirements of generative adversarial neural networks (GANs) hinder its real-world deployment on edge devices such as smartphones. Despite the success in model reduction of convolutional neural networks (CNNs), neural network quantization methods have not yet been studied on GANs, which are mainly faced with the issues of both the effectiveness of quantization algorithms and the instability of training GAN models. In this paper, we start with an extensive study on applying existing successful CNN quantization methods to quantize GAN models to extreme low bits. Our observation reveals that none of them generates samples with reasonable quality because of the underrepresentation of quantized weights in models, and the generator and discriminator networks show different sensitivities upon the quantization precision. Motivated by these observations, we develop a novel quantization method for GANs based on EM algorithms, named as QGAN. We also propose a multi-precision algorithm to help find an appropriate quantization precision of GANs given image qualities requirements. Experiments on CIFAR-10 and CelebA show that QGAN can quantize weights in GANs to even 1-bit or 2-bit representations with results of quality comparable to original models.", "pdf": "/pdf/6b971cf2d0bffedcd02cfdf6bced6057264badb5.pdf", "paperhash": "wang|qgan_quantize_generative_adversarial_networks_to_extreme_lowbits", "original_pdf": "/attachment/6b971cf2d0bffedcd02cfdf6bced6057264badb5.pdf", "_bibtex": "@misc{\nwang2020qgan,\ntitle={{\\{}QGAN{\\}}: Quantize Generative Adversarial Networks to Extreme low-bits},\nauthor={Peiqi Wang and Yu Ji and Xinfeng Xie and Yongqiang Lyu and Dongsheng Wang and Yuan Xie},\nyear={2020},\nurl={https://openreview.net/forum?id=HkeAepVKDH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HkeAepVKDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper358/Authors", "ICLR.cc/2020/Conference/Paper358/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper358/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper358/Reviewers", "ICLR.cc/2020/Conference/Paper358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper358/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper358/Authors|ICLR.cc/2020/Conference/Paper358/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504172622, "tmdate": 1576860548394, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper358/Authors", "ICLR.cc/2020/Conference/Paper358/Reviewers", "ICLR.cc/2020/Conference/Paper358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper358/-/Official_Comment"}}}, {"id": "SkgBUnpDiS", "original": null, "number": 3, "cdate": 1573538892760, "ddate": null, "tcdate": 1573538892760, "tmdate": 1573538892760, "tddate": null, "forum": "HkeAepVKDH", "replyto": "BJxy0i2a5B", "invitation": "ICLR.cc/2020/Conference/Paper358/-/Official_Comment", "content": {"title": "Response to Reviewer #1", "comment": "Thank you for your valuable comments!\n\nQ1: Comparison to previous work\nA1: There are truly various complexed quantization methods based on linear functions that work well on CNN, like clip or OCS as you mentioned. We add extra experiments on Outlier Channel Splitting (OCS)[1] and Analytical Clipping for Integer Quantization (ACIQ)[2] to do a more comprehensive comparison. Due to the OCS do not need finetuning, we just implement it directly to the pre-trained model like the original paper. For ACIQ, we use the same experimental setup in Section 5, i.e. quantize a pre-trained model and then finetune 20 epochs. The results are shown below and we copy our results in Table 2 for ease of comparison. Compared to OCS and ACIQ, QGAN still gets the best or comparable results in all cases. The performance of ACIQ is similar to Minmax-Q, but it doesn't support the 1-bit case. In the 4-bit case, QGAN still performs as good as ACIQ with a little bit lower IS but better FID.\nWe will add these related work experiments and discussion to our paper later according to your kind suggestions, and we hope these results can eliminate your concerns.\n--------------------------------------------------------------------------------------\n                    |       1-bit      |    2-bit        |     3-bit       |  4-bit       |\n--------------------------------------------------------------------------------------\n                    |      IS/FID    |     IS/FID    |     IS/FID    |  IS/FID    |     \n--------------------------------------------------------------------------------------\nMinmax-Q | 1.16/407.9 | 2.65/132.4 | 4.35/65.1   | 4.74/40.3   |\nLog-Q         |     N/A         | 1.17/421.9 | 1.16/440.3 | 4.15/60.6   |\nTanh-Q       |    N/A          | 1.28/437.8 | 1.20/466.7 | 1.13/460.2 |\nOCS             | 1.00/438.9 | 2.22/283.0 | 3.16/133.3 | 3.80/138.4 |\nACIQ           |    N/A          | 3.87/65.9   | 4.30/51.6   | 4.80/40.4   |\nQGAN         |  3.32/96.7   |  4.15/54.3  | 4.46/51.4   | 4.60/39.6   |\n-----------------------------------------------------------------------------------------\n\nQ2: Comments on Defensive Quantization\nA2: Firstly, Defensive Quantization (DQ) focus on CNN quantization, and the adversarial attacks apply to classification tasks. Our QGAN is a quantization method on the GAN model, and the major task of quantized GAN is generating image samples. The adversarial example generation in the attack scenario is different from image generation using GAN. The adversarial example is obtained by adding subtle perturbations on the original input image, while GAN generates images using the generator networks. Secondly, the robustness mentioned in DQ refers to attack accuracy, while the robustness in GAN means the unstable training process. The concerns and application scenarios of DQ and QGAN are different, and it is difficult to directly apply DQ to GAN quantization. \n\nBesides, thank you for pointing out the typo and we will modify it later. \n\n[1] Improving Neural Network Quantization using Outlier Channel Splitting\n[2] ACIQ: Analytical Clipping for Integer Quantization of neural networks\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper358/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper358/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "QGAN: Quantize Generative Adversarial Networks to Extreme low-bits", "authors": ["Peiqi Wang", "Yu Ji", "Xinfeng Xie", "Yongqiang Lyu", "Dongsheng Wang", "Yuan Xie"], "authorids": ["wpq14@tsinghua.org.cn", "jiy15@mails.tsinghua.edu.cn", "xinfeng@ucsb.edu", "luyq@tsinghua.edu.cn", "wds@mail.tsinghua.edu.cn", "yuanxie@ucsb.edu"], "keywords": ["generative adversarial networks", "quantization", "extreme low bits"], "abstract": "The intensive computation and memory requirements of generative adversarial neural networks (GANs) hinder its real-world deployment on edge devices such as smartphones. Despite the success in model reduction of convolutional neural networks (CNNs), neural network quantization methods have not yet been studied on GANs, which are mainly faced with the issues of both the effectiveness of quantization algorithms and the instability of training GAN models. In this paper, we start with an extensive study on applying existing successful CNN quantization methods to quantize GAN models to extreme low bits. Our observation reveals that none of them generates samples with reasonable quality because of the underrepresentation of quantized weights in models, and the generator and discriminator networks show different sensitivities upon the quantization precision. Motivated by these observations, we develop a novel quantization method for GANs based on EM algorithms, named as QGAN. We also propose a multi-precision algorithm to help find an appropriate quantization precision of GANs given image qualities requirements. Experiments on CIFAR-10 and CelebA show that QGAN can quantize weights in GANs to even 1-bit or 2-bit representations with results of quality comparable to original models.", "pdf": "/pdf/6b971cf2d0bffedcd02cfdf6bced6057264badb5.pdf", "paperhash": "wang|qgan_quantize_generative_adversarial_networks_to_extreme_lowbits", "original_pdf": "/attachment/6b971cf2d0bffedcd02cfdf6bced6057264badb5.pdf", "_bibtex": "@misc{\nwang2020qgan,\ntitle={{\\{}QGAN{\\}}: Quantize Generative Adversarial Networks to Extreme low-bits},\nauthor={Peiqi Wang and Yu Ji and Xinfeng Xie and Yongqiang Lyu and Dongsheng Wang and Yuan Xie},\nyear={2020},\nurl={https://openreview.net/forum?id=HkeAepVKDH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HkeAepVKDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper358/Authors", "ICLR.cc/2020/Conference/Paper358/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper358/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper358/Reviewers", "ICLR.cc/2020/Conference/Paper358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper358/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper358/Authors|ICLR.cc/2020/Conference/Paper358/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504172622, "tmdate": 1576860548394, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper358/Authors", "ICLR.cc/2020/Conference/Paper358/Reviewers", "ICLR.cc/2020/Conference/Paper358/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper358/-/Official_Comment"}}}, {"id": "S1gsfgPVtS", "original": null, "number": 1, "cdate": 1571217426644, "ddate": null, "tcdate": 1571217426644, "tmdate": 1572972605510, "tddate": null, "forum": "HkeAepVKDH", "replyto": "HkeAepVKDH", "invitation": "ICLR.cc/2020/Conference/Paper358/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "Summary:\nThe authors address the quantization of Generative Adversarial Networks (GANs). The paper first performs a sensitivity study for both the generator and the discriminator to quantization methods. Building upon the conclusion of this study, the authors propose a scalar quantization method (QGAN) and compress models to 1 bit of 2 bits weights and show generated images and metrics by the compressed models. \n\nStrengths of the paper:\n- As well stated in the introduction, the compression of GANs (in particular the generator, which is used at inference time) is of practical interest and, to the best of my knowledge, novel. This novelty can be explained by (1) the fact that it takes tome for quantization methods to percolate the entire deep learning field and/or (2) the fact that quantizing GANs has its specificities and own challenges that have not been yet addressed (this is the claim of the authors).\n- The sensitivity study is of interest for the community that can build upon this work. The conclusions (discriminator more sensitive than generator to quantization, quantizing both generator and discriminator helps) are sensible and interesting. \n\nWeaknesses of the paper:\n- The related work section could be greatly improved, thereby showing the limited novelty of the proposed method (QGAN). Indeed, the authors propose to learn the optimal scaling parameters alpha and beta. Many works perform this already and are currently missing in this section, see for instance the two recent surveys: \"A Survey on Methods and Theories of Quantized Neural Networks\", Guo, \"A Survey of Model Compression and Acceleration for Deep Neural Networks\", Cheng et al. \n- Results. The results are not sufficient to justify the performance of the method for two reasons. (1) First, the scale is crucial in assessing the performance of a quantization method. As an example, it is easier to quantize small ResNets on CIFAR-10 than large ResNets on ImageNet. Thus, scales enables to better discriminate between various approaches. I acknowledge that this requires large computational resources but this would greatly strengthen the paper (2) Second, GAN metrics have known shortcomings (see for instance \"How good is my GAN?\", Shmelkov et al.), so the strength of Table 2 is limited. This is in part alleviated by the authors by showing generated images (which is a good practice), but again echoing point (1), larger images would have helped assess better the quality of the quantization.\n\nJustification of rating: \nThe authors propose a sensitivity study that is interesting for the community. However, the proposed method lacks novelty and the results are not convincing enough. I encourage the authors to pursue in this interesting direction which has important practical implications."}, "signatures": ["ICLR.cc/2020/Conference/Paper358/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper358/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "QGAN: Quantize Generative Adversarial Networks to Extreme low-bits", "authors": ["Peiqi Wang", "Yu Ji", "Xinfeng Xie", "Yongqiang Lyu", "Dongsheng Wang", "Yuan Xie"], "authorids": ["wpq14@tsinghua.org.cn", "jiy15@mails.tsinghua.edu.cn", "xinfeng@ucsb.edu", "luyq@tsinghua.edu.cn", "wds@mail.tsinghua.edu.cn", "yuanxie@ucsb.edu"], "keywords": ["generative adversarial networks", "quantization", "extreme low bits"], "abstract": "The intensive computation and memory requirements of generative adversarial neural networks (GANs) hinder its real-world deployment on edge devices such as smartphones. Despite the success in model reduction of convolutional neural networks (CNNs), neural network quantization methods have not yet been studied on GANs, which are mainly faced with the issues of both the effectiveness of quantization algorithms and the instability of training GAN models. In this paper, we start with an extensive study on applying existing successful CNN quantization methods to quantize GAN models to extreme low bits. Our observation reveals that none of them generates samples with reasonable quality because of the underrepresentation of quantized weights in models, and the generator and discriminator networks show different sensitivities upon the quantization precision. Motivated by these observations, we develop a novel quantization method for GANs based on EM algorithms, named as QGAN. We also propose a multi-precision algorithm to help find an appropriate quantization precision of GANs given image qualities requirements. Experiments on CIFAR-10 and CelebA show that QGAN can quantize weights in GANs to even 1-bit or 2-bit representations with results of quality comparable to original models.", "pdf": "/pdf/6b971cf2d0bffedcd02cfdf6bced6057264badb5.pdf", "paperhash": "wang|qgan_quantize_generative_adversarial_networks_to_extreme_lowbits", "original_pdf": "/attachment/6b971cf2d0bffedcd02cfdf6bced6057264badb5.pdf", "_bibtex": "@misc{\nwang2020qgan,\ntitle={{\\{}QGAN{\\}}: Quantize Generative Adversarial Networks to Extreme low-bits},\nauthor={Peiqi Wang and Yu Ji and Xinfeng Xie and Yongqiang Lyu and Dongsheng Wang and Yuan Xie},\nyear={2020},\nurl={https://openreview.net/forum?id=HkeAepVKDH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HkeAepVKDH", "replyto": "HkeAepVKDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper358/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper358/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575859341306, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper358/Reviewers"], "noninvitees": [], "tcdate": 1570237753317, "tmdate": 1575859341320, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper358/-/Official_Review"}}}, {"id": "BkxGc0P1qS", "original": null, "number": 2, "cdate": 1571942025867, "ddate": null, "tcdate": 1571942025867, "tmdate": 1572972605476, "tddate": null, "forum": "HkeAepVKDH", "replyto": "HkeAepVKDH", "invitation": "ICLR.cc/2020/Conference/Paper358/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper propose to study the quantization of GANs parameters. They show that standard methods to quantize the weights of neural networks fails when doing extreme quantization (1 or 2-bit quantization). They show that when using low-bit representation, some of the bits are used to model extremal values of the weights which are irrelevant and lead to numerical instability. To fix this issue they propose a new method based on Expectation-Maximization to quantify the weights of the neural networks. They then show experimentally that this enables them to quantize the weights of neural networks to low bit representation without a complete drop of performance and remaining stable.\n\nI'm overall in favour of accepting this work. The paper is well motivated, the authors clearly show the benefits of the proposed approach compared to other approach when using extreme quantization.\n\nMain argument:\n+ Great overview of previous methods and why they fail when applying extreme quantization\n+ Great study of the influence of the sensitivity to the number of bits used for quantization\n- It would have been nice if the author had provided standard deviation for the results by running each method several times. In particular figure 2.c seem to show that they might be a lot of variance in the results when using low bit quantization.\n- I feel some details are missing or at least lack some precision. For example are the networks pre-trained with full precision in all experiments ? if so can you precise it in section 3.1 also ? \n- The proposed approach seem very similar in spirit to vector quantization, can the author contrast their method to vector quantization ?\n- In equation (7) doesn't the constant C also depend on alpha and beta ?\n- In section 5.1 do you also use the two phase training described in section 4.2 ?\n- Figure 4.c seems to indicate that quantize the generator only is no more a problem ? Can you explain why this figure is very different from figure 2.c \n- In table 3 how is the number of bits chosen, did you try several different values and report the best performance ?\n\nMinor:\n- Some of the notations are a bit confusing. You call X the tensor of x, I think it would be more clear to say that X is the domain of x.\n- I'm surprised by the results in section 3.1, wouldn't the issue described in this section when training standard neural networks ? wasn't this known before ?\n- There is some typos in the text"}, "signatures": ["ICLR.cc/2020/Conference/Paper358/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper358/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "QGAN: Quantize Generative Adversarial Networks to Extreme low-bits", "authors": ["Peiqi Wang", "Yu Ji", "Xinfeng Xie", "Yongqiang Lyu", "Dongsheng Wang", "Yuan Xie"], "authorids": ["wpq14@tsinghua.org.cn", "jiy15@mails.tsinghua.edu.cn", "xinfeng@ucsb.edu", "luyq@tsinghua.edu.cn", "wds@mail.tsinghua.edu.cn", "yuanxie@ucsb.edu"], "keywords": ["generative adversarial networks", "quantization", "extreme low bits"], "abstract": "The intensive computation and memory requirements of generative adversarial neural networks (GANs) hinder its real-world deployment on edge devices such as smartphones. Despite the success in model reduction of convolutional neural networks (CNNs), neural network quantization methods have not yet been studied on GANs, which are mainly faced with the issues of both the effectiveness of quantization algorithms and the instability of training GAN models. In this paper, we start with an extensive study on applying existing successful CNN quantization methods to quantize GAN models to extreme low bits. Our observation reveals that none of them generates samples with reasonable quality because of the underrepresentation of quantized weights in models, and the generator and discriminator networks show different sensitivities upon the quantization precision. Motivated by these observations, we develop a novel quantization method for GANs based on EM algorithms, named as QGAN. We also propose a multi-precision algorithm to help find an appropriate quantization precision of GANs given image qualities requirements. Experiments on CIFAR-10 and CelebA show that QGAN can quantize weights in GANs to even 1-bit or 2-bit representations with results of quality comparable to original models.", "pdf": "/pdf/6b971cf2d0bffedcd02cfdf6bced6057264badb5.pdf", "paperhash": "wang|qgan_quantize_generative_adversarial_networks_to_extreme_lowbits", "original_pdf": "/attachment/6b971cf2d0bffedcd02cfdf6bced6057264badb5.pdf", "_bibtex": "@misc{\nwang2020qgan,\ntitle={{\\{}QGAN{\\}}: Quantize Generative Adversarial Networks to Extreme low-bits},\nauthor={Peiqi Wang and Yu Ji and Xinfeng Xie and Yongqiang Lyu and Dongsheng Wang and Yuan Xie},\nyear={2020},\nurl={https://openreview.net/forum?id=HkeAepVKDH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HkeAepVKDH", "replyto": "HkeAepVKDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper358/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper358/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575859341306, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper358/Reviewers"], "noninvitees": [], "tcdate": 1570237753317, "tmdate": 1575859341320, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper358/-/Official_Review"}}}, {"id": "BJxy0i2a5B", "original": null, "number": 3, "cdate": 1572879302546, "ddate": null, "tcdate": 1572879302546, "tmdate": 1572972605430, "tddate": null, "forum": "HkeAepVKDH", "replyto": "HkeAepVKDH", "invitation": "ICLR.cc/2020/Conference/Paper358/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper introduces a fairly simple yet seemly effective method for quantizing GAN. Existing quantization methods (namely minmax, log, and tanh quantization) for CNN/RNN fail brutally under GAN setting. From empirical observation of the distribution of quantized weights, the authors conjecture the reason being under-utilization of the low-bit representation, called under-representation in the paper. Based on such observation, linear scaling with EM is proposed and experimental results seem to be effective. \n\n[Advantage]\nThe paper is clearly written and easy to follow. The proposed method is well-motivated from the empirical observation presented in Sec 3, and seems to mitigate the difficulties from the discussion in Sec 5.\n\n[Disadvantage & Improvement]\nWhile I am not a direct expert in this area, I do have some concerns regarding the novelty of the method and comparison to previous works. Linear quantization seems to be a common/intuitive method and there are various improvement techniques built upon it (e.g. cliping, ocs,... etc [1,2]). These are related works, yet neither included nor discussed in this paper. How is the presented linear+EM method comparing with these variants, in term of effectiveness on training GAN and the reported test-time metrics? In short, the comparison to previous works seems insufficient in my point of view.\n\nAlso, can you comment on Defensive Quantization (DQ) [3]? The quantization method is specifically designed for adversarial attack/perturbation setting and seems applicable under GAN setting. \n\nLast, there is a typo at the end of Sec 4.2: should it be f_{em}(x) instead of f_{e}m(x)?\n\n[1] Low-bit Quantization of Neural Networks for Efficient Inference\n[2] Improving Neural Network Quantization using Outlier Channel Splitting\n[3] Defensive Quantization: When Efficiency Meets Robustness\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper358/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper358/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "QGAN: Quantize Generative Adversarial Networks to Extreme low-bits", "authors": ["Peiqi Wang", "Yu Ji", "Xinfeng Xie", "Yongqiang Lyu", "Dongsheng Wang", "Yuan Xie"], "authorids": ["wpq14@tsinghua.org.cn", "jiy15@mails.tsinghua.edu.cn", "xinfeng@ucsb.edu", "luyq@tsinghua.edu.cn", "wds@mail.tsinghua.edu.cn", "yuanxie@ucsb.edu"], "keywords": ["generative adversarial networks", "quantization", "extreme low bits"], "abstract": "The intensive computation and memory requirements of generative adversarial neural networks (GANs) hinder its real-world deployment on edge devices such as smartphones. Despite the success in model reduction of convolutional neural networks (CNNs), neural network quantization methods have not yet been studied on GANs, which are mainly faced with the issues of both the effectiveness of quantization algorithms and the instability of training GAN models. In this paper, we start with an extensive study on applying existing successful CNN quantization methods to quantize GAN models to extreme low bits. Our observation reveals that none of them generates samples with reasonable quality because of the underrepresentation of quantized weights in models, and the generator and discriminator networks show different sensitivities upon the quantization precision. Motivated by these observations, we develop a novel quantization method for GANs based on EM algorithms, named as QGAN. We also propose a multi-precision algorithm to help find an appropriate quantization precision of GANs given image qualities requirements. Experiments on CIFAR-10 and CelebA show that QGAN can quantize weights in GANs to even 1-bit or 2-bit representations with results of quality comparable to original models.", "pdf": "/pdf/6b971cf2d0bffedcd02cfdf6bced6057264badb5.pdf", "paperhash": "wang|qgan_quantize_generative_adversarial_networks_to_extreme_lowbits", "original_pdf": "/attachment/6b971cf2d0bffedcd02cfdf6bced6057264badb5.pdf", "_bibtex": "@misc{\nwang2020qgan,\ntitle={{\\{}QGAN{\\}}: Quantize Generative Adversarial Networks to Extreme low-bits},\nauthor={Peiqi Wang and Yu Ji and Xinfeng Xie and Yongqiang Lyu and Dongsheng Wang and Yuan Xie},\nyear={2020},\nurl={https://openreview.net/forum?id=HkeAepVKDH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HkeAepVKDH", "replyto": "HkeAepVKDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper358/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper358/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575859341306, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper358/Reviewers"], "noninvitees": [], "tcdate": 1570237753317, "tmdate": 1575859341320, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper358/-/Official_Review"}}}], "count": 8}