{"notes": [{"id": "HJe9cR4KvB", "original": "HJxFUpu_wB", "number": 1292, "cdate": 1569439377711, "ddate": null, "tcdate": 1569439377711, "tmdate": 1577168219484, "tddate": null, "forum": "HJe9cR4KvB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling", "authors": ["Ouyu Lan*", "Xiao Huang*", "Bill Yuchen Lin", "He Jiang", "Xiang Ren"], "authorids": ["olan@usc.edu", "huan183@usc.edu", "yuchen.lin@usc.edu", "jian567@usc.edu", "xiangren@usc.edu"], "keywords": ["crowdsourcing", "domain adaptation", "sequence labeling", "named entity recognition", "weak supervision"], "TL;DR": "A model to contextually aggregate multi-source supervision for sequence learning.", "abstract": "Sequence labeling is a fundamental framework for various natural language processing problems including part-of-speech tagging and named entity recognition. Its performance is largely influenced by the annotation quality and quantity in supervised learning scenarios.  In many cases, ground truth labels are costly and time-consuming to collect or even non-existent,  while imperfect ones could be easily accessed or transferred from different domains. A typical example is crowd-sourced datasets which have multiple annotations for each sentence which may be noisy or incomplete.   Additionally,  predictions from multiple source models in transfer learning can be seen as a case of multi-source supervision.  In this paper, we propose a novel framework named Consensus Network (CONNET) to conduct training with imperfect annotations from multiple sources.   It learns the representation for every weak supervision source and dynamically aggregates them by a context-aware attention mechanism.  Finally, it leads to a model reflecting the consensus among multiple sources.  We evaluate the proposed framework in two practical settings of multi-source learning:  learning with crowd annotations and unsupervised cross-domain model adaptation. Extensive experimental results show that our model achieves significant improvements over existing methods in both settings.", "pdf": "/pdf/33d72e3977a46779f756e0ed5fa803c8a3805bd9.pdf", "code": "https://www.dropbox.com/sh/ru7vdss4xsv2j29/AADji_r6MXGVi5-97mngNCV3a?dl=0", "paperhash": "lan|learning_to_contextually_aggregate_multisource_supervision_for_sequence_labeling", "original_pdf": "/attachment/7f6aa29fcbb1dbb9e071db03290746dd81489a43.pdf", "_bibtex": "@misc{\nlan*2020learning,\ntitle={Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling},\nauthor={Ouyu Lan* and Xiao Huang* and Bill Yuchen Lin and He Jiang and Xiang Ren},\nyear={2020},\nurl={https://openreview.net/forum?id=HJe9cR4KvB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "gAHR7n3M_", "original": null, "number": 1, "cdate": 1576798719534, "ddate": null, "tcdate": 1576798719534, "tmdate": 1576800916985, "tddate": null, "forum": "HJe9cR4KvB", "replyto": "HJe9cR4KvB", "invitation": "ICLR.cc/2020/Conference/Paper1292/-/Decision", "content": {"decision": "Reject", "comment": "While the revised paper was better and improved the reviewers assessment of the work, the paper is just below the threshold for acceptance. The authors are strongly encouraged to continue this work.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling", "authors": ["Ouyu Lan*", "Xiao Huang*", "Bill Yuchen Lin", "He Jiang", "Xiang Ren"], "authorids": ["olan@usc.edu", "huan183@usc.edu", "yuchen.lin@usc.edu", "jian567@usc.edu", "xiangren@usc.edu"], "keywords": ["crowdsourcing", "domain adaptation", "sequence labeling", "named entity recognition", "weak supervision"], "TL;DR": "A model to contextually aggregate multi-source supervision for sequence learning.", "abstract": "Sequence labeling is a fundamental framework for various natural language processing problems including part-of-speech tagging and named entity recognition. Its performance is largely influenced by the annotation quality and quantity in supervised learning scenarios.  In many cases, ground truth labels are costly and time-consuming to collect or even non-existent,  while imperfect ones could be easily accessed or transferred from different domains. A typical example is crowd-sourced datasets which have multiple annotations for each sentence which may be noisy or incomplete.   Additionally,  predictions from multiple source models in transfer learning can be seen as a case of multi-source supervision.  In this paper, we propose a novel framework named Consensus Network (CONNET) to conduct training with imperfect annotations from multiple sources.   It learns the representation for every weak supervision source and dynamically aggregates them by a context-aware attention mechanism.  Finally, it leads to a model reflecting the consensus among multiple sources.  We evaluate the proposed framework in two practical settings of multi-source learning:  learning with crowd annotations and unsupervised cross-domain model adaptation. Extensive experimental results show that our model achieves significant improvements over existing methods in both settings.", "pdf": "/pdf/33d72e3977a46779f756e0ed5fa803c8a3805bd9.pdf", "code": "https://www.dropbox.com/sh/ru7vdss4xsv2j29/AADji_r6MXGVi5-97mngNCV3a?dl=0", "paperhash": "lan|learning_to_contextually_aggregate_multisource_supervision_for_sequence_labeling", "original_pdf": "/attachment/7f6aa29fcbb1dbb9e071db03290746dd81489a43.pdf", "_bibtex": "@misc{\nlan*2020learning,\ntitle={Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling},\nauthor={Ouyu Lan* and Xiao Huang* and Bill Yuchen Lin and He Jiang and Xiang Ren},\nyear={2020},\nurl={https://openreview.net/forum?id=HJe9cR4KvB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "HJe9cR4KvB", "replyto": "HJe9cR4KvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795713266, "tmdate": 1576800262841, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1292/-/Decision"}}}, {"id": "BJlZKk6pKS", "original": null, "number": 2, "cdate": 1571831673300, "ddate": null, "tcdate": 1571831673300, "tmdate": 1574444301010, "tddate": null, "forum": "HJe9cR4KvB", "replyto": "HJe9cR4KvB", "invitation": "ICLR.cc/2020/Conference/Paper1292/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #1", "review": "\n## Updated review\n\nI have read the rebuttals. The new version of the paper is clearer and the new baseline experiments are a good addition. \n\n## Original review\n\nThis paper presents an approach to train a neural networks-based model for sequence modelling using labels from different sources. The proposed approach explicitly models the annotator and uses an attention model to select the best aggregation method. The model is used on two scenarios: learning with crowd annotation and cross-domain adaptation. For the first scenario, noisy annotators are simulated with models trained on subsets of the data, the proposed model is compared with related works and is shown to achieve the highest f-1 score. For the second scenario, different domains in three NLP tasks are used and the model is shown to yield the best performance.\n\nI think this paper should be accepted, for the following reasons:\n- The approach is novel as far as I can tell, and the approach of learning to aggregate labels is significant, as it could also be applied to tasks where inter-annotators agreement is a problem.\n- The experiments are convincing and show the potential of the proposed approach. \n- The comparison with related works is thorough.\n\nDetailed comments\n- I don't understand the notion of \"normalized expertise\" in Section 5.4, can the authors briefly describe it in the paper ?\n- The paper is not easy to read, for instance the first paragraph of Section 5 contains critical information to understand the experiments, maybe it should be moved the Section 4 and developed more, typically in two subsections \"Application to crowd annotation\" and \"Application to cross-domain\" for example.\n- Typos:\n    - Section 2, 3rd paragraph \"for traget corpora\" -> \"target\"\n    - Same paragraph: \"Yang & Eisenstien (2018) represented\" -> \"represents\" to be consistent\n    - Section 4.1: \"BiLSTM-CRF\" -> \"BLSTM-CRF\"\n ", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1292/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1292/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling", "authors": ["Ouyu Lan*", "Xiao Huang*", "Bill Yuchen Lin", "He Jiang", "Xiang Ren"], "authorids": ["olan@usc.edu", "huan183@usc.edu", "yuchen.lin@usc.edu", "jian567@usc.edu", "xiangren@usc.edu"], "keywords": ["crowdsourcing", "domain adaptation", "sequence labeling", "named entity recognition", "weak supervision"], "TL;DR": "A model to contextually aggregate multi-source supervision for sequence learning.", "abstract": "Sequence labeling is a fundamental framework for various natural language processing problems including part-of-speech tagging and named entity recognition. Its performance is largely influenced by the annotation quality and quantity in supervised learning scenarios.  In many cases, ground truth labels are costly and time-consuming to collect or even non-existent,  while imperfect ones could be easily accessed or transferred from different domains. A typical example is crowd-sourced datasets which have multiple annotations for each sentence which may be noisy or incomplete.   Additionally,  predictions from multiple source models in transfer learning can be seen as a case of multi-source supervision.  In this paper, we propose a novel framework named Consensus Network (CONNET) to conduct training with imperfect annotations from multiple sources.   It learns the representation for every weak supervision source and dynamically aggregates them by a context-aware attention mechanism.  Finally, it leads to a model reflecting the consensus among multiple sources.  We evaluate the proposed framework in two practical settings of multi-source learning:  learning with crowd annotations and unsupervised cross-domain model adaptation. Extensive experimental results show that our model achieves significant improvements over existing methods in both settings.", "pdf": "/pdf/33d72e3977a46779f756e0ed5fa803c8a3805bd9.pdf", "code": "https://www.dropbox.com/sh/ru7vdss4xsv2j29/AADji_r6MXGVi5-97mngNCV3a?dl=0", "paperhash": "lan|learning_to_contextually_aggregate_multisource_supervision_for_sequence_labeling", "original_pdf": "/attachment/7f6aa29fcbb1dbb9e071db03290746dd81489a43.pdf", "_bibtex": "@misc{\nlan*2020learning,\ntitle={Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling},\nauthor={Ouyu Lan* and Xiao Huang* and Bill Yuchen Lin and He Jiang and Xiang Ren},\nyear={2020},\nurl={https://openreview.net/forum?id=HJe9cR4KvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HJe9cR4KvB", "replyto": "HJe9cR4KvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1292/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1292/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575694634371, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1292/Reviewers"], "noninvitees": [], "tcdate": 1570237739499, "tmdate": 1575694634389, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1292/-/Official_Review"}}}, {"id": "BJgqBNdvjr", "original": null, "number": 4, "cdate": 1573516353908, "ddate": null, "tcdate": 1573516353908, "tmdate": 1573775797551, "tddate": null, "forum": "HJe9cR4KvB", "replyto": "Bkg21BVsYH", "invitation": "ICLR.cc/2020/Conference/Paper1292/-/Official_Comment", "content": {"title": "Thank you for the feedback", "comment": "Thank you for your comments!\n\n-------------------------------\nQ1: My main concern on the paper is its generalization. Crowdsourcing usually involves lots of annotators, and some of them only give very few labels. In these situations, the proposed model introduces lots of new parameters (A, Q), which may cause difficulty during training. So the positive results in Fig 3(b) are very important to dispel my worry, which requires more explanation. \n\nA1: Regarding Fig 3(b), each annotator model (CRF) is trained with only 1/50 of the training data (reliability=1/50) to simulate noisy annotators. The CRFs are used to make predictions on the entire training data which are then used as noisy annotations. The figure shows that (1) the performance of our model increases as the number of annotators and (2) regardless of the number of annotators, our method consistently outperforms than other baselines. \n\nWe compare our method and all baselines on performance and the number of parameters. The baseline models we used for comparison can be classified into two groups. The first group is those that treat all sources as a single source (concatenates training data from all sources): CONCAT-SLM, CRF-MA, Tri-Training. Compared to this group, our model introduces A and Q with additional parameters. But our model outperforms them, suggesting that it\u2019s beneficial to model each source separately. The second group is those that model each source specifically: MVT/MVS/DS/HMM-SLM, MTL-MVT/BEA, Crowd-Add/Cat, CL-MW. Compared to this group, our model only introduces Q with additional parameters and achieves better performance.\n\nWe argue that the number of parameters in A and Q is not very significant. The sizes of new parameters A and Q are linear to the number of annotators. Assume #tag = 10 (e.g., CoNLL 2003 has 9 tags), #annotator = 100, and #hidden_units = 100, the number of parameters in A is (#annotator x #tag x #tag = 10k) and in Q is (#annotator x 2#hidden_units = 20k). But a normal 300-to-100 BLSTM has around 300k parameters.\n\n-------------------------------\nQ2: How do you calculate the sentence embeddings h_i during training?\n\nA2: We concatenate the last hidden states of the forward LSTM and the backward LSTM as the sentence embedding\n\n-------------------------------\nQ3: Have you introduced some regularization terms on A and Q?\n\nA3: No, we don\u2019t have a motivation to regularize A and Q.\n\n-------------------------------\nQ4: What are the most important hyper-parameters for this model, and how to tune?\n\nA4: We did not include additional hyper-parameters to control the size of the crowd matrices or the attention module. Therefore all hyper-parameters are related to the base model BLSTM-CRF (and MLP for text classification), for example, pre-trained word embeddings, character representation, and hidden size of the encoder [1]. \n[1] Nils Reimers and Iryna Gurevych. 2017. Optimal Hyperparameters for Deep LSTM-Networks for Sequence Labeling Tasks.\n\n-------------------------------\nQ5: Can this method be extended to new tasks other than sequence labeling?\n\nA5: Yes, we have tested our method on text classification with an MLP as the encoder (see cross-domain experiments, we emphasized it more in the new version). Actually the proposed method can apply to any encoders, but we found it performs better with CRF.\n\n-------------------------------\nQ6: Can you compare your method with the aggregation method used in on-the-job learning paper [1]?\n\nA6: The paper does not focus on aggregation and only has a few words describing it: \u201c$p_\u03b8(y|x)$ is the prediction model\u2026 The CRF model $p_\u03b8(y|x)$ is learned based on all actual responses (not simulated ones) using AdaGrad\u201d. Based on these explanations it looks the same as concatenating data from all sources to train a single model (CONCAT-SLM). We are trying to look more into it and see if we can reimplement the method.\n\n-------------------------------\nQ7: 92.33 in tab 2 shouldn\u2019t be bold.\n\nA7: Nice catch! Thanks for pointing out and we will do another round of editing to improve the presentation.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1292/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1292/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling", "authors": ["Ouyu Lan*", "Xiao Huang*", "Bill Yuchen Lin", "He Jiang", "Xiang Ren"], "authorids": ["olan@usc.edu", "huan183@usc.edu", "yuchen.lin@usc.edu", "jian567@usc.edu", "xiangren@usc.edu"], "keywords": ["crowdsourcing", "domain adaptation", "sequence labeling", "named entity recognition", "weak supervision"], "TL;DR": "A model to contextually aggregate multi-source supervision for sequence learning.", "abstract": "Sequence labeling is a fundamental framework for various natural language processing problems including part-of-speech tagging and named entity recognition. Its performance is largely influenced by the annotation quality and quantity in supervised learning scenarios.  In many cases, ground truth labels are costly and time-consuming to collect or even non-existent,  while imperfect ones could be easily accessed or transferred from different domains. A typical example is crowd-sourced datasets which have multiple annotations for each sentence which may be noisy or incomplete.   Additionally,  predictions from multiple source models in transfer learning can be seen as a case of multi-source supervision.  In this paper, we propose a novel framework named Consensus Network (CONNET) to conduct training with imperfect annotations from multiple sources.   It learns the representation for every weak supervision source and dynamically aggregates them by a context-aware attention mechanism.  Finally, it leads to a model reflecting the consensus among multiple sources.  We evaluate the proposed framework in two practical settings of multi-source learning:  learning with crowd annotations and unsupervised cross-domain model adaptation. Extensive experimental results show that our model achieves significant improvements over existing methods in both settings.", "pdf": "/pdf/33d72e3977a46779f756e0ed5fa803c8a3805bd9.pdf", "code": "https://www.dropbox.com/sh/ru7vdss4xsv2j29/AADji_r6MXGVi5-97mngNCV3a?dl=0", "paperhash": "lan|learning_to_contextually_aggregate_multisource_supervision_for_sequence_labeling", "original_pdf": "/attachment/7f6aa29fcbb1dbb9e071db03290746dd81489a43.pdf", "_bibtex": "@misc{\nlan*2020learning,\ntitle={Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling},\nauthor={Ouyu Lan* and Xiao Huang* and Bill Yuchen Lin and He Jiang and Xiang Ren},\nyear={2020},\nurl={https://openreview.net/forum?id=HJe9cR4KvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJe9cR4KvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1292/Authors", "ICLR.cc/2020/Conference/Paper1292/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1292/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1292/Reviewers", "ICLR.cc/2020/Conference/Paper1292/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1292/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1292/Authors|ICLR.cc/2020/Conference/Paper1292/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504158242, "tmdate": 1576860559348, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1292/Authors", "ICLR.cc/2020/Conference/Paper1292/Reviewers", "ICLR.cc/2020/Conference/Paper1292/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1292/-/Official_Comment"}}}, {"id": "BJxt2vwiiS", "original": null, "number": 6, "cdate": 1573775281112, "ddate": null, "tcdate": 1573775281112, "tmdate": 1573775690481, "tddate": null, "forum": "HJe9cR4KvB", "replyto": "B1xyg9XT5B", "invitation": "ICLR.cc/2020/Conference/Paper1292/-/Official_Comment", "content": {"title": "Experimental results with a transformer", "comment": "Good news! We re-implement our method and some baselines (MTV-SLM, Crowd-Add, Gold) with a transformer encoder, and conduct experiments with crowd-annotation dataset AMTC on NER task and cross-domain dataset UD on POS task. Our model outperforms over other baselines in both tasks and applications as the following table shows. The experiments are mentioned in the first paragraph of section 5. Details and results can be found in Appendix B of the updated paper.\n\nmethod                        |    AMTC (F1%)    |     UD (acc%)    \nMTV-SLM                     |   60.21($\\pm$1.87)   |    87.23($\\pm$0.51)\nCrowd-Add                  |   60.68($\\pm$0.67)   |    88.20($\\pm$0.36)\nConNet (Ours)            |   65.05($\\pm$2.32)   |    89.27($\\pm$0.31)\nGold (Upper bound)  |   80.87($\\pm$0.79)   |    90.45($\\pm$0.71)"}, "signatures": ["ICLR.cc/2020/Conference/Paper1292/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1292/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling", "authors": ["Ouyu Lan*", "Xiao Huang*", "Bill Yuchen Lin", "He Jiang", "Xiang Ren"], "authorids": ["olan@usc.edu", "huan183@usc.edu", "yuchen.lin@usc.edu", "jian567@usc.edu", "xiangren@usc.edu"], "keywords": ["crowdsourcing", "domain adaptation", "sequence labeling", "named entity recognition", "weak supervision"], "TL;DR": "A model to contextually aggregate multi-source supervision for sequence learning.", "abstract": "Sequence labeling is a fundamental framework for various natural language processing problems including part-of-speech tagging and named entity recognition. Its performance is largely influenced by the annotation quality and quantity in supervised learning scenarios.  In many cases, ground truth labels are costly and time-consuming to collect or even non-existent,  while imperfect ones could be easily accessed or transferred from different domains. A typical example is crowd-sourced datasets which have multiple annotations for each sentence which may be noisy or incomplete.   Additionally,  predictions from multiple source models in transfer learning can be seen as a case of multi-source supervision.  In this paper, we propose a novel framework named Consensus Network (CONNET) to conduct training with imperfect annotations from multiple sources.   It learns the representation for every weak supervision source and dynamically aggregates them by a context-aware attention mechanism.  Finally, it leads to a model reflecting the consensus among multiple sources.  We evaluate the proposed framework in two practical settings of multi-source learning:  learning with crowd annotations and unsupervised cross-domain model adaptation. Extensive experimental results show that our model achieves significant improvements over existing methods in both settings.", "pdf": "/pdf/33d72e3977a46779f756e0ed5fa803c8a3805bd9.pdf", "code": "https://www.dropbox.com/sh/ru7vdss4xsv2j29/AADji_r6MXGVi5-97mngNCV3a?dl=0", "paperhash": "lan|learning_to_contextually_aggregate_multisource_supervision_for_sequence_labeling", "original_pdf": "/attachment/7f6aa29fcbb1dbb9e071db03290746dd81489a43.pdf", "_bibtex": "@misc{\nlan*2020learning,\ntitle={Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling},\nauthor={Ouyu Lan* and Xiao Huang* and Bill Yuchen Lin and He Jiang and Xiang Ren},\nyear={2020},\nurl={https://openreview.net/forum?id=HJe9cR4KvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJe9cR4KvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1292/Authors", "ICLR.cc/2020/Conference/Paper1292/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1292/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1292/Reviewers", "ICLR.cc/2020/Conference/Paper1292/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1292/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1292/Authors|ICLR.cc/2020/Conference/Paper1292/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504158242, "tmdate": 1576860559348, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1292/Authors", "ICLR.cc/2020/Conference/Paper1292/Reviewers", "ICLR.cc/2020/Conference/Paper1292/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1292/-/Official_Comment"}}}, {"id": "Skl66IDoiS", "original": null, "number": 5, "cdate": 1573775045327, "ddate": null, "tcdate": 1573775045327, "tmdate": 1573775045327, "tddate": null, "forum": "HJe9cR4KvB", "replyto": "HJe9cR4KvB", "invitation": "ICLR.cc/2020/Conference/Paper1292/-/Official_Comment", "content": {"title": "New experiments with a transformer encoder", "comment": "In response to reviewer #2, we re-implement our method and some baselines with a transformer encoder. New experiments are conducted with the crowd-annotation NER dataset and cross-domain POS dataset. The results show that our model outperforms over other baselines in both tasks and applications. \n\nThe new version mentions it in the first paragraph of section 5 and describes more details and results in Appendix B."}, "signatures": ["ICLR.cc/2020/Conference/Paper1292/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1292/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling", "authors": ["Ouyu Lan*", "Xiao Huang*", "Bill Yuchen Lin", "He Jiang", "Xiang Ren"], "authorids": ["olan@usc.edu", "huan183@usc.edu", "yuchen.lin@usc.edu", "jian567@usc.edu", "xiangren@usc.edu"], "keywords": ["crowdsourcing", "domain adaptation", "sequence labeling", "named entity recognition", "weak supervision"], "TL;DR": "A model to contextually aggregate multi-source supervision for sequence learning.", "abstract": "Sequence labeling is a fundamental framework for various natural language processing problems including part-of-speech tagging and named entity recognition. Its performance is largely influenced by the annotation quality and quantity in supervised learning scenarios.  In many cases, ground truth labels are costly and time-consuming to collect or even non-existent,  while imperfect ones could be easily accessed or transferred from different domains. A typical example is crowd-sourced datasets which have multiple annotations for each sentence which may be noisy or incomplete.   Additionally,  predictions from multiple source models in transfer learning can be seen as a case of multi-source supervision.  In this paper, we propose a novel framework named Consensus Network (CONNET) to conduct training with imperfect annotations from multiple sources.   It learns the representation for every weak supervision source and dynamically aggregates them by a context-aware attention mechanism.  Finally, it leads to a model reflecting the consensus among multiple sources.  We evaluate the proposed framework in two practical settings of multi-source learning:  learning with crowd annotations and unsupervised cross-domain model adaptation. Extensive experimental results show that our model achieves significant improvements over existing methods in both settings.", "pdf": "/pdf/33d72e3977a46779f756e0ed5fa803c8a3805bd9.pdf", "code": "https://www.dropbox.com/sh/ru7vdss4xsv2j29/AADji_r6MXGVi5-97mngNCV3a?dl=0", "paperhash": "lan|learning_to_contextually_aggregate_multisource_supervision_for_sequence_labeling", "original_pdf": "/attachment/7f6aa29fcbb1dbb9e071db03290746dd81489a43.pdf", "_bibtex": "@misc{\nlan*2020learning,\ntitle={Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling},\nauthor={Ouyu Lan* and Xiao Huang* and Bill Yuchen Lin and He Jiang and Xiang Ren},\nyear={2020},\nurl={https://openreview.net/forum?id=HJe9cR4KvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJe9cR4KvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1292/Authors", "ICLR.cc/2020/Conference/Paper1292/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1292/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1292/Reviewers", "ICLR.cc/2020/Conference/Paper1292/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1292/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1292/Authors|ICLR.cc/2020/Conference/Paper1292/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504158242, "tmdate": 1576860559348, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1292/Authors", "ICLR.cc/2020/Conference/Paper1292/Reviewers", "ICLR.cc/2020/Conference/Paper1292/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1292/-/Official_Comment"}}}, {"id": "B1gh27_woS", "original": null, "number": 3, "cdate": 1573516212168, "ddate": null, "tcdate": 1573516212168, "tmdate": 1573614792032, "tddate": null, "forum": "HJe9cR4KvB", "replyto": "B1xyg9XT5B", "invitation": "ICLR.cc/2020/Conference/Paper1292/-/Official_Comment", "content": {"title": "Thank you for the feedback", "comment": "Thank you for your comments and feedback! We have rewritten and rearranged the section in the new version to make it clearer and more readable. \n\n-------------------------------\nQ1: How to combine the source dependent representation in Section 4.2 with the aggregation phase presented in Section 4.3? In particular, how the model combines during the training Eq. 3 and Eq. 5? Similarly, how in Eq. 6 the model can calculate attention coefficients based only on information from the sentence embedding (h^(i))?\n\nA1: In the decoupling phase, we train a shared BLSTM-CRF model with source-specific matrices applied individually to the CRF (Eq.3). This is essentially a multi-task model. In this phase, the model is trained with the entire training data from all sources. \n\nIn the dynamic aggregation phase, we train only an attention module which takes as input the sentence encoding and outputs an attention score for each crowd matrix (Eq.4, where Q is trainable parameters). We then take a weighted average (weighted by attention scores) of all the crowd matrices to form the Consensus Matrix (Eq.5) which is to be applied to the CRF module the same way as the crowd matrices (same as Eq.3). In this phase, the attention module is trained on the target training data with \u201cpseudo labels\u201d (weighted voting of predictions of the multi-task model obtained in the decoupling phase, detailed in Appendix A.2).\n\nThe motivation of having such an attention module is that we want to take advantage of the source-specific knowledge in addition to the shared knowledge for the target data. And the target may be more related to some sources than other sources. So the attention module is used to determine the weight of each source to the target and aggregate source-specific information into the Consensus Matrix, which is then applied to the CRF. In cross-domain experiments, the attention module is trained on the target data with \u201cpseudo labels\u201d to be familiar with the style of the domain.\n\nWe also updated Section 4.3 and 4.5 for better clarification. Thank you!\n\n-------------------------------\nQ2: This work assumes a BLSTM-CRF architecture as a baseline, but it does not explore alternative approaches, such as a transformer. \n\nA2. Regarding the base model, we considered that BLSTM-CRF is generally used as the base model for sequence tagging [1, 2, 3]. In addition to BLSTM-CRF, we also explored our method with MLP encoder for text classification (see cross-domain experiments, we emphasized it more in the new version). We will conduct more experiments with the transformer as an encoder to demonstrate the effectiveness of our method.\n\n[1] Guillaume Lample, Miguel Ballesteros, Sandeep Subramanian, Kazuya Kawakami, and Chris Dyer.  Neural architectures for named entity recognition.\n[2] Liyuan Liu, Xiang Ren, Jingbo Shang, Jian Peng, and Jiawei Han.  Efficient Contextualized Representation: Language Model Pruning for Sequence Labeling\n[3] Hang Yan, Bocao Deng, Xiaonan Li, and Xipeng Qiu.  TENER: Adapting Transformer Encoder for Name Entity Recognition"}, "signatures": ["ICLR.cc/2020/Conference/Paper1292/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1292/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling", "authors": ["Ouyu Lan*", "Xiao Huang*", "Bill Yuchen Lin", "He Jiang", "Xiang Ren"], "authorids": ["olan@usc.edu", "huan183@usc.edu", "yuchen.lin@usc.edu", "jian567@usc.edu", "xiangren@usc.edu"], "keywords": ["crowdsourcing", "domain adaptation", "sequence labeling", "named entity recognition", "weak supervision"], "TL;DR": "A model to contextually aggregate multi-source supervision for sequence learning.", "abstract": "Sequence labeling is a fundamental framework for various natural language processing problems including part-of-speech tagging and named entity recognition. Its performance is largely influenced by the annotation quality and quantity in supervised learning scenarios.  In many cases, ground truth labels are costly and time-consuming to collect or even non-existent,  while imperfect ones could be easily accessed or transferred from different domains. A typical example is crowd-sourced datasets which have multiple annotations for each sentence which may be noisy or incomplete.   Additionally,  predictions from multiple source models in transfer learning can be seen as a case of multi-source supervision.  In this paper, we propose a novel framework named Consensus Network (CONNET) to conduct training with imperfect annotations from multiple sources.   It learns the representation for every weak supervision source and dynamically aggregates them by a context-aware attention mechanism.  Finally, it leads to a model reflecting the consensus among multiple sources.  We evaluate the proposed framework in two practical settings of multi-source learning:  learning with crowd annotations and unsupervised cross-domain model adaptation. Extensive experimental results show that our model achieves significant improvements over existing methods in both settings.", "pdf": "/pdf/33d72e3977a46779f756e0ed5fa803c8a3805bd9.pdf", "code": "https://www.dropbox.com/sh/ru7vdss4xsv2j29/AADji_r6MXGVi5-97mngNCV3a?dl=0", "paperhash": "lan|learning_to_contextually_aggregate_multisource_supervision_for_sequence_labeling", "original_pdf": "/attachment/7f6aa29fcbb1dbb9e071db03290746dd81489a43.pdf", "_bibtex": "@misc{\nlan*2020learning,\ntitle={Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling},\nauthor={Ouyu Lan* and Xiao Huang* and Bill Yuchen Lin and He Jiang and Xiang Ren},\nyear={2020},\nurl={https://openreview.net/forum?id=HJe9cR4KvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJe9cR4KvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1292/Authors", "ICLR.cc/2020/Conference/Paper1292/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1292/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1292/Reviewers", "ICLR.cc/2020/Conference/Paper1292/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1292/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1292/Authors|ICLR.cc/2020/Conference/Paper1292/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504158242, "tmdate": 1576860559348, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1292/Authors", "ICLR.cc/2020/Conference/Paper1292/Reviewers", "ICLR.cc/2020/Conference/Paper1292/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1292/-/Official_Comment"}}}, {"id": "SJeiQXuDoB", "original": null, "number": 2, "cdate": 1573516067173, "ddate": null, "tcdate": 1573516067173, "tmdate": 1573530562189, "tddate": null, "forum": "HJe9cR4KvB", "replyto": "BJlZKk6pKS", "invitation": "ICLR.cc/2020/Conference/Paper1292/-/Official_Comment", "content": {"title": "Thank you for the feedback", "comment": "Thank you for your comments and suggestions! \n\n-------------------------------\nQ1: What does the notion of \"normalized expertise\" in Section 5.4 mean?\n\nA1: \"Normalized expertise\" refers to the F1 score on the test set, which represents the expertise level of the annotator. To make the representation clearer, we change the terminology as \"test F1 score\" in the revision.\n\n-------------------------------\nQ2: The paper is not easy to read.\n\nA2: We appreciate your suggestions on the paper structure and typos. We have rearranged Section 4-5 and fix all the typos in the new version to make it clearer and more readable. Specifically, Section 4.5 is added for model applications: learning with crowd annotations and unsupervised cross-domain model adaptation while the first paragraph of Section 5 has been simplified."}, "signatures": ["ICLR.cc/2020/Conference/Paper1292/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1292/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling", "authors": ["Ouyu Lan*", "Xiao Huang*", "Bill Yuchen Lin", "He Jiang", "Xiang Ren"], "authorids": ["olan@usc.edu", "huan183@usc.edu", "yuchen.lin@usc.edu", "jian567@usc.edu", "xiangren@usc.edu"], "keywords": ["crowdsourcing", "domain adaptation", "sequence labeling", "named entity recognition", "weak supervision"], "TL;DR": "A model to contextually aggregate multi-source supervision for sequence learning.", "abstract": "Sequence labeling is a fundamental framework for various natural language processing problems including part-of-speech tagging and named entity recognition. Its performance is largely influenced by the annotation quality and quantity in supervised learning scenarios.  In many cases, ground truth labels are costly and time-consuming to collect or even non-existent,  while imperfect ones could be easily accessed or transferred from different domains. A typical example is crowd-sourced datasets which have multiple annotations for each sentence which may be noisy or incomplete.   Additionally,  predictions from multiple source models in transfer learning can be seen as a case of multi-source supervision.  In this paper, we propose a novel framework named Consensus Network (CONNET) to conduct training with imperfect annotations from multiple sources.   It learns the representation for every weak supervision source and dynamically aggregates them by a context-aware attention mechanism.  Finally, it leads to a model reflecting the consensus among multiple sources.  We evaluate the proposed framework in two practical settings of multi-source learning:  learning with crowd annotations and unsupervised cross-domain model adaptation. Extensive experimental results show that our model achieves significant improvements over existing methods in both settings.", "pdf": "/pdf/33d72e3977a46779f756e0ed5fa803c8a3805bd9.pdf", "code": "https://www.dropbox.com/sh/ru7vdss4xsv2j29/AADji_r6MXGVi5-97mngNCV3a?dl=0", "paperhash": "lan|learning_to_contextually_aggregate_multisource_supervision_for_sequence_labeling", "original_pdf": "/attachment/7f6aa29fcbb1dbb9e071db03290746dd81489a43.pdf", "_bibtex": "@misc{\nlan*2020learning,\ntitle={Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling},\nauthor={Ouyu Lan* and Xiao Huang* and Bill Yuchen Lin and He Jiang and Xiang Ren},\nyear={2020},\nurl={https://openreview.net/forum?id=HJe9cR4KvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJe9cR4KvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1292/Authors", "ICLR.cc/2020/Conference/Paper1292/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1292/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1292/Reviewers", "ICLR.cc/2020/Conference/Paper1292/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1292/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1292/Authors|ICLR.cc/2020/Conference/Paper1292/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504158242, "tmdate": 1576860559348, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1292/Authors", "ICLR.cc/2020/Conference/Paper1292/Reviewers", "ICLR.cc/2020/Conference/Paper1292/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1292/-/Official_Comment"}}}, {"id": "HJehLMuvoB", "original": null, "number": 1, "cdate": 1573515859823, "ddate": null, "tcdate": 1573515859823, "tmdate": 1573515859823, "tddate": null, "forum": "HJe9cR4KvB", "replyto": "HJe9cR4KvB", "invitation": "ICLR.cc/2020/Conference/Paper1292/-/Official_Comment", "content": {"title": "Paper Revised and Additional Experiments Running", "comment": "Thank all reviewers for careful reviews and helpful comments. We have taken each comment seriously and attempted to address every concern. \n\nWe updated the paper as follows: \n- Rearranged section 4 and 5, as suggested by reviewer #1;\n- Improved clarity in section 4.3, as reviewer #2 concerns;\n- Explained more about model parameters and Fig 3(b), as reviewer #3 suggests;\n- Emphasized more on the text classification task which may be missed by readers before.\n\nWe are also re-running some experiments with Transformer as substitution of BLSTM to demonstrate the effectiveness of our method with different encoders, which is in response to reviewer #2. We will report back the performance comparison in one or two days. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1292/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1292/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling", "authors": ["Ouyu Lan*", "Xiao Huang*", "Bill Yuchen Lin", "He Jiang", "Xiang Ren"], "authorids": ["olan@usc.edu", "huan183@usc.edu", "yuchen.lin@usc.edu", "jian567@usc.edu", "xiangren@usc.edu"], "keywords": ["crowdsourcing", "domain adaptation", "sequence labeling", "named entity recognition", "weak supervision"], "TL;DR": "A model to contextually aggregate multi-source supervision for sequence learning.", "abstract": "Sequence labeling is a fundamental framework for various natural language processing problems including part-of-speech tagging and named entity recognition. Its performance is largely influenced by the annotation quality and quantity in supervised learning scenarios.  In many cases, ground truth labels are costly and time-consuming to collect or even non-existent,  while imperfect ones could be easily accessed or transferred from different domains. A typical example is crowd-sourced datasets which have multiple annotations for each sentence which may be noisy or incomplete.   Additionally,  predictions from multiple source models in transfer learning can be seen as a case of multi-source supervision.  In this paper, we propose a novel framework named Consensus Network (CONNET) to conduct training with imperfect annotations from multiple sources.   It learns the representation for every weak supervision source and dynamically aggregates them by a context-aware attention mechanism.  Finally, it leads to a model reflecting the consensus among multiple sources.  We evaluate the proposed framework in two practical settings of multi-source learning:  learning with crowd annotations and unsupervised cross-domain model adaptation. Extensive experimental results show that our model achieves significant improvements over existing methods in both settings.", "pdf": "/pdf/33d72e3977a46779f756e0ed5fa803c8a3805bd9.pdf", "code": "https://www.dropbox.com/sh/ru7vdss4xsv2j29/AADji_r6MXGVi5-97mngNCV3a?dl=0", "paperhash": "lan|learning_to_contextually_aggregate_multisource_supervision_for_sequence_labeling", "original_pdf": "/attachment/7f6aa29fcbb1dbb9e071db03290746dd81489a43.pdf", "_bibtex": "@misc{\nlan*2020learning,\ntitle={Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling},\nauthor={Ouyu Lan* and Xiao Huang* and Bill Yuchen Lin and He Jiang and Xiang Ren},\nyear={2020},\nurl={https://openreview.net/forum?id=HJe9cR4KvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJe9cR4KvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1292/Authors", "ICLR.cc/2020/Conference/Paper1292/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1292/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1292/Reviewers", "ICLR.cc/2020/Conference/Paper1292/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1292/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1292/Authors|ICLR.cc/2020/Conference/Paper1292/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504158242, "tmdate": 1576860559348, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1292/Authors", "ICLR.cc/2020/Conference/Paper1292/Reviewers", "ICLR.cc/2020/Conference/Paper1292/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1292/-/Official_Comment"}}}, {"id": "Bkg21BVsYH", "original": null, "number": 1, "cdate": 1571665123590, "ddate": null, "tcdate": 1571665123590, "tmdate": 1572972487822, "tddate": null, "forum": "HJe9cR4KvB", "replyto": "HJe9cR4KvB", "invitation": "ICLR.cc/2020/Conference/Paper1292/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "\nThis paper proposes ConNet, a new label aggregation method for sequence labeling tasks, including crowd-annotation and cross-domain model adaptation. The model consists of a decoupling phase, which learns annotator-specific transforming matrices A, and an aggregation phase with an attention module. Extensive experimental results demonstrate the superiority of the proposed model over baselines. \nThe paper is generally well-written and easy to follow, and the results seem convincing, so I think it can inspire other works on this topic. My main concern on the paper is its generalization. Crowdsourcing usually involves lots of annotators, and some of them only give very few labels. In these situations, the proposed model introduces lots of new parameters (A, Q), which may cause difficulty during training. So the positive results in Fig 3(b) are very important to dispel my worry, which requires more explanation. \nBelow are some detailed questions:\n-      How do you calculate the sentence embeddings h_i during training?\n-      Have you introduced some regularization terms on A and Q?\n-      What are the most important hyper-parameters for this model, and how to tune?\n-      Can this method be extended to new tasks other than sequence labeling?\n-      Can you compare your method with the aggregation method used in on-the-job learning paper [1]?\n-      92.33 in tab 2 shouldn\u2019t be bold.\n \n[1] Werling K , Chaganty A , Liang P , et al. On-the-Job Learning with Bayesian Decision Theory[J]. Computer Science, 2015.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1292/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1292/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling", "authors": ["Ouyu Lan*", "Xiao Huang*", "Bill Yuchen Lin", "He Jiang", "Xiang Ren"], "authorids": ["olan@usc.edu", "huan183@usc.edu", "yuchen.lin@usc.edu", "jian567@usc.edu", "xiangren@usc.edu"], "keywords": ["crowdsourcing", "domain adaptation", "sequence labeling", "named entity recognition", "weak supervision"], "TL;DR": "A model to contextually aggregate multi-source supervision for sequence learning.", "abstract": "Sequence labeling is a fundamental framework for various natural language processing problems including part-of-speech tagging and named entity recognition. Its performance is largely influenced by the annotation quality and quantity in supervised learning scenarios.  In many cases, ground truth labels are costly and time-consuming to collect or even non-existent,  while imperfect ones could be easily accessed or transferred from different domains. A typical example is crowd-sourced datasets which have multiple annotations for each sentence which may be noisy or incomplete.   Additionally,  predictions from multiple source models in transfer learning can be seen as a case of multi-source supervision.  In this paper, we propose a novel framework named Consensus Network (CONNET) to conduct training with imperfect annotations from multiple sources.   It learns the representation for every weak supervision source and dynamically aggregates them by a context-aware attention mechanism.  Finally, it leads to a model reflecting the consensus among multiple sources.  We evaluate the proposed framework in two practical settings of multi-source learning:  learning with crowd annotations and unsupervised cross-domain model adaptation. Extensive experimental results show that our model achieves significant improvements over existing methods in both settings.", "pdf": "/pdf/33d72e3977a46779f756e0ed5fa803c8a3805bd9.pdf", "code": "https://www.dropbox.com/sh/ru7vdss4xsv2j29/AADji_r6MXGVi5-97mngNCV3a?dl=0", "paperhash": "lan|learning_to_contextually_aggregate_multisource_supervision_for_sequence_labeling", "original_pdf": "/attachment/7f6aa29fcbb1dbb9e071db03290746dd81489a43.pdf", "_bibtex": "@misc{\nlan*2020learning,\ntitle={Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling},\nauthor={Ouyu Lan* and Xiao Huang* and Bill Yuchen Lin and He Jiang and Xiang Ren},\nyear={2020},\nurl={https://openreview.net/forum?id=HJe9cR4KvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HJe9cR4KvB", "replyto": "HJe9cR4KvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1292/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1292/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575694634371, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1292/Reviewers"], "noninvitees": [], "tcdate": 1570237739499, "tmdate": 1575694634389, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1292/-/Official_Review"}}}, {"id": "B1xyg9XT5B", "original": null, "number": 3, "cdate": 1572841959203, "ddate": null, "tcdate": 1572841959203, "tmdate": 1572972487736, "tddate": null, "forum": "HJe9cR4KvB", "replyto": "HJe9cR4KvB", "invitation": "ICLR.cc/2020/Conference/Paper1292/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review": "This work proposes a method to learn how to aggregate weak supervision sources in the context of sequence labeling. In particular, the model has two main steps: i) it learns a source dependent transformation and ii) it learns a mechanism to combine them. \n\nIn general, the paper is well organized but it is not easy to follow. It was not clear to me how the authors combine the source dependent representation in Section 4.2 with the aggregation phase presented in Section 4.3. In particular, it is confusing to me how the model combines during the training Eq. 3 and Eq. 5. Similarly, it is not clear to me how in Eq. 6 the model can calculate attention coefficients based only on information from the sentence embedding (h^(i)).\n\nThis work assumes a BLSTM-CRF architecture as a baseline, but it does not explore alternative approaches, such as transformer.   \n\nIn terms of the experiments, authors evaluate the resulting model using two application settings: combining noisy crowd annotations (AMT) and unsupervised cross-domain model adaptation. Results are encouraging, the proposed method is able to outperforms several recent works in terms of F1 metric for the case of AMT and accuracy for the case of cross-domain adaptation. Qualitative results also shows reasonable performance. The supplemental material also include an ablation study.\n\nIn summary, the proposed method is interesting and results seem to be encouraging, however, there are parts of the proposed method that are not clear to me. I rate the paper as weak reject. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1292/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1292/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling", "authors": ["Ouyu Lan*", "Xiao Huang*", "Bill Yuchen Lin", "He Jiang", "Xiang Ren"], "authorids": ["olan@usc.edu", "huan183@usc.edu", "yuchen.lin@usc.edu", "jian567@usc.edu", "xiangren@usc.edu"], "keywords": ["crowdsourcing", "domain adaptation", "sequence labeling", "named entity recognition", "weak supervision"], "TL;DR": "A model to contextually aggregate multi-source supervision for sequence learning.", "abstract": "Sequence labeling is a fundamental framework for various natural language processing problems including part-of-speech tagging and named entity recognition. Its performance is largely influenced by the annotation quality and quantity in supervised learning scenarios.  In many cases, ground truth labels are costly and time-consuming to collect or even non-existent,  while imperfect ones could be easily accessed or transferred from different domains. A typical example is crowd-sourced datasets which have multiple annotations for each sentence which may be noisy or incomplete.   Additionally,  predictions from multiple source models in transfer learning can be seen as a case of multi-source supervision.  In this paper, we propose a novel framework named Consensus Network (CONNET) to conduct training with imperfect annotations from multiple sources.   It learns the representation for every weak supervision source and dynamically aggregates them by a context-aware attention mechanism.  Finally, it leads to a model reflecting the consensus among multiple sources.  We evaluate the proposed framework in two practical settings of multi-source learning:  learning with crowd annotations and unsupervised cross-domain model adaptation. Extensive experimental results show that our model achieves significant improvements over existing methods in both settings.", "pdf": "/pdf/33d72e3977a46779f756e0ed5fa803c8a3805bd9.pdf", "code": "https://www.dropbox.com/sh/ru7vdss4xsv2j29/AADji_r6MXGVi5-97mngNCV3a?dl=0", "paperhash": "lan|learning_to_contextually_aggregate_multisource_supervision_for_sequence_labeling", "original_pdf": "/attachment/7f6aa29fcbb1dbb9e071db03290746dd81489a43.pdf", "_bibtex": "@misc{\nlan*2020learning,\ntitle={Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling},\nauthor={Ouyu Lan* and Xiao Huang* and Bill Yuchen Lin and He Jiang and Xiang Ren},\nyear={2020},\nurl={https://openreview.net/forum?id=HJe9cR4KvB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HJe9cR4KvB", "replyto": "HJe9cR4KvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1292/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1292/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575694634371, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1292/Reviewers"], "noninvitees": [], "tcdate": 1570237739499, "tmdate": 1575694634389, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1292/-/Official_Review"}}}], "count": 11}