{"notes": [{"id": "PO0SuuafSX", "original": "B1uQqYJoNed", "number": 1575, "cdate": 1601308174616, "ddate": null, "tcdate": 1601308174616, "tmdate": 1614985634410, "tddate": null, "forum": "PO0SuuafSX", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "3D Scene Compression through Entropy  Penalized Neural Representation Functions", "authorids": ["~Thomas_Bird1", "~Johannes_Ball\u00e91", "~Saurabh_Singh1", "~Philip_Chou1"], "authors": ["Thomas Bird", "Johannes Ball\u00e9", "Saurabh Singh", "Philip Chou"], "keywords": ["scene representation", "compression", "neural rendering", "entropy coding"], "abstract": "Some forms of novel visual media enable the viewer to explore a 3D scene from essentially arbitrary viewpoints, by interpolating between a discrete set of original views. Compared to 2D imagery, these types of applications require much larger amounts of storage space, which we seek to reduce. Existing approaches for compressing 3D scenes are based on a separation of compression and rendering: each of the original views is compressed using traditional 2D image formats; the receiver decompresses the views and then performs the rendering. We unify these steps by directly compressing an implicit representation of the scene, a function that maps spatial coordinates to a radiance vector field, which can then be queried to render arbitrary viewpoints. The function is implemented as a neural network and jointly trained for reconstruction as well as compressibility, in an end-to-end manner, with the use of an entropy penalty on the parameters. Our method significantly outperforms a state-of-the-art conventional approach for scene compression, achieving simultaneously higher quality reconstructions and lower bitrates. Furthermore, we show that the performance at lower bitrates can be improved by jointly representing multiple scenes using a soft form of parameter sharing.", "one-sentence_summary": "Compressing neural representation functions by penalizing the entropy of the reparameterized weights results in a small and useful renderer", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bird|3d_scene_compression_through_entropy_penalized_neural_representation_functions", "pdf": "/pdf/5e809739fd052bd0f76aa59c01525832e2fd222d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=7CWfolaTIN", "_bibtex": "@misc{\nbird2021d,\ntitle={3D Scene Compression through Entropy  Penalized Neural Representation Functions},\nauthor={Thomas Bird and Johannes Ball{\\'e} and Saurabh Singh and Philip Chou},\nyear={2021},\nurl={https://openreview.net/forum?id=PO0SuuafSX}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 11, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "saeTXLcdBsZ", "original": null, "number": 1, "cdate": 1610040526804, "ddate": null, "tcdate": 1610040526804, "tmdate": 1610474135910, "tddate": null, "forum": "PO0SuuafSX", "replyto": "PO0SuuafSX", "invitation": "ICLR.cc/2021/Conference/Paper1575/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "Description:\nThe paper presents a method for encoding a compressed version of an implicit 3D scene, from given images from arbitrary view points. This is achieved via a function, learning with a NeRF model, that maps spatial coordinates to a radiance vector field and is optimized for high compressibility and low reconstruction error. Results shows better compression, higher reconstruction quality and lower bitrates compared to other STOA.\n\nStrengths:\n- Method for significantly compressing NerF models, which is very useful since such models are often trained for every new scene\n- Retain reconstruction quality after compression by an order of magnitude\n \nWeaknesses:\n- The need for decompressing the model before rendering can be done means reduced rendering speed. This also requires longer training times.\n- Experiments against other scene compression + neural rendering technique will have further strengthened the papers\u2019s claims \n- The techniques used are well established, and thus there is not as much technical novelty.\n"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "3D Scene Compression through Entropy  Penalized Neural Representation Functions", "authorids": ["~Thomas_Bird1", "~Johannes_Ball\u00e91", "~Saurabh_Singh1", "~Philip_Chou1"], "authors": ["Thomas Bird", "Johannes Ball\u00e9", "Saurabh Singh", "Philip Chou"], "keywords": ["scene representation", "compression", "neural rendering", "entropy coding"], "abstract": "Some forms of novel visual media enable the viewer to explore a 3D scene from essentially arbitrary viewpoints, by interpolating between a discrete set of original views. Compared to 2D imagery, these types of applications require much larger amounts of storage space, which we seek to reduce. Existing approaches for compressing 3D scenes are based on a separation of compression and rendering: each of the original views is compressed using traditional 2D image formats; the receiver decompresses the views and then performs the rendering. We unify these steps by directly compressing an implicit representation of the scene, a function that maps spatial coordinates to a radiance vector field, which can then be queried to render arbitrary viewpoints. The function is implemented as a neural network and jointly trained for reconstruction as well as compressibility, in an end-to-end manner, with the use of an entropy penalty on the parameters. Our method significantly outperforms a state-of-the-art conventional approach for scene compression, achieving simultaneously higher quality reconstructions and lower bitrates. Furthermore, we show that the performance at lower bitrates can be improved by jointly representing multiple scenes using a soft form of parameter sharing.", "one-sentence_summary": "Compressing neural representation functions by penalizing the entropy of the reparameterized weights results in a small and useful renderer", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bird|3d_scene_compression_through_entropy_penalized_neural_representation_functions", "pdf": "/pdf/5e809739fd052bd0f76aa59c01525832e2fd222d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=7CWfolaTIN", "_bibtex": "@misc{\nbird2021d,\ntitle={3D Scene Compression through Entropy  Penalized Neural Representation Functions},\nauthor={Thomas Bird and Johannes Ball{\\'e} and Saurabh Singh and Philip Chou},\nyear={2021},\nurl={https://openreview.net/forum?id=PO0SuuafSX}\n}"}, "tags": [], "invitation": {"reply": {"forum": "PO0SuuafSX", "replyto": "PO0SuuafSX", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040526791, "tmdate": 1610474135893, "id": "ICLR.cc/2021/Conference/Paper1575/-/Decision"}}}, {"id": "csETVrO2VbE", "original": null, "number": 7, "cdate": 1606274679260, "ddate": null, "tcdate": 1606274679260, "tmdate": 1606274679260, "tddate": null, "forum": "PO0SuuafSX", "replyto": "NQYZe4VUN_", "invitation": "ICLR.cc/2021/Conference/Paper1575/-/Official_Comment", "content": {"title": "Thanks", "comment": "Thanks for the rebuttal, however, I still have concerns\n\n1. I do agree the baseline I proposed will be time-consuming in the decoder side, however, this is the only comparison I can think of that can demonstrate the effectiveness of the proposed method (for 3D scene compression), The author argues the training of nerf would take time in the sender side, but this can be mitigated by first training the nerf (once), then can run any (infinite) numbers of inference.\n\n2. Can the author provide the exact numbers to convince us the time are comparable?\n\n3. What about the issues I raised in the multiple scene experiments?"}, "signatures": ["ICLR.cc/2021/Conference/Paper1575/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1575/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "3D Scene Compression through Entropy  Penalized Neural Representation Functions", "authorids": ["~Thomas_Bird1", "~Johannes_Ball\u00e91", "~Saurabh_Singh1", "~Philip_Chou1"], "authors": ["Thomas Bird", "Johannes Ball\u00e9", "Saurabh Singh", "Philip Chou"], "keywords": ["scene representation", "compression", "neural rendering", "entropy coding"], "abstract": "Some forms of novel visual media enable the viewer to explore a 3D scene from essentially arbitrary viewpoints, by interpolating between a discrete set of original views. Compared to 2D imagery, these types of applications require much larger amounts of storage space, which we seek to reduce. Existing approaches for compressing 3D scenes are based on a separation of compression and rendering: each of the original views is compressed using traditional 2D image formats; the receiver decompresses the views and then performs the rendering. We unify these steps by directly compressing an implicit representation of the scene, a function that maps spatial coordinates to a radiance vector field, which can then be queried to render arbitrary viewpoints. The function is implemented as a neural network and jointly trained for reconstruction as well as compressibility, in an end-to-end manner, with the use of an entropy penalty on the parameters. Our method significantly outperforms a state-of-the-art conventional approach for scene compression, achieving simultaneously higher quality reconstructions and lower bitrates. Furthermore, we show that the performance at lower bitrates can be improved by jointly representing multiple scenes using a soft form of parameter sharing.", "one-sentence_summary": "Compressing neural representation functions by penalizing the entropy of the reparameterized weights results in a small and useful renderer", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bird|3d_scene_compression_through_entropy_penalized_neural_representation_functions", "pdf": "/pdf/5e809739fd052bd0f76aa59c01525832e2fd222d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=7CWfolaTIN", "_bibtex": "@misc{\nbird2021d,\ntitle={3D Scene Compression through Entropy  Penalized Neural Representation Functions},\nauthor={Thomas Bird and Johannes Ball{\\'e} and Saurabh Singh and Philip Chou},\nyear={2021},\nurl={https://openreview.net/forum?id=PO0SuuafSX}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "PO0SuuafSX", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1575/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1575/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1575/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1575/Authors|ICLR.cc/2021/Conference/Paper1575/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1575/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858187, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1575/-/Official_Comment"}}}, {"id": "Eh7aqnqx5Gj", "original": null, "number": 6, "cdate": 1606212170566, "ddate": null, "tcdate": 1606212170566, "tmdate": 1606212170566, "tddate": null, "forum": "PO0SuuafSX", "replyto": "PO0SuuafSX", "invitation": "ICLR.cc/2021/Conference/Paper1575/-/Official_Comment", "content": {"title": "A message to all the reviewers", "comment": "Many of the reviewers raised concerns about the novelty of our work. Rather than repeating the same points in individual responses, we address that point here.\n\nAlthough we have not introduced many new architectures or designs in our work, we still believe there is novelty in our method. We are taking a very non-standard approach to compression of visual media - we compress the 3d scene not via compressing views or other data directly, but instead by compressing an implicit representation function, from which the views can be reconstructed. To our knowledge we are the first to seriously study this kind of compression pipeline.\n\nThe methods we use (from model compression and neural rendering) are well established. But the combination of these and the problem setting (of minimizing the message length used to describe a full 3d scene) are not obvious to study. We are the first to do so, and we do achieve good experimental results. Our results are interesting even from a model compression perspective, since model compression techniques are almost always applied to classification problems, for example CIFAR and ImageNet. The problem setting for our model is a difficult regression problem, mapping dense points in space to a radiance field, which is characteristically different to (and probably harder than) the classification settings usually seen. The fact that the model compression works so well on this rendering function is significant, since it has not been shown before that such models can be effectively compressed.\n\nIt is also worth mentioning that our method of compressing a representation function would apply equally well to other media types, e.g. 2d images or audio. As such, we believe there is value in the community being made aware of this general methodology.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1575/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1575/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "3D Scene Compression through Entropy  Penalized Neural Representation Functions", "authorids": ["~Thomas_Bird1", "~Johannes_Ball\u00e91", "~Saurabh_Singh1", "~Philip_Chou1"], "authors": ["Thomas Bird", "Johannes Ball\u00e9", "Saurabh Singh", "Philip Chou"], "keywords": ["scene representation", "compression", "neural rendering", "entropy coding"], "abstract": "Some forms of novel visual media enable the viewer to explore a 3D scene from essentially arbitrary viewpoints, by interpolating between a discrete set of original views. Compared to 2D imagery, these types of applications require much larger amounts of storage space, which we seek to reduce. Existing approaches for compressing 3D scenes are based on a separation of compression and rendering: each of the original views is compressed using traditional 2D image formats; the receiver decompresses the views and then performs the rendering. We unify these steps by directly compressing an implicit representation of the scene, a function that maps spatial coordinates to a radiance vector field, which can then be queried to render arbitrary viewpoints. The function is implemented as a neural network and jointly trained for reconstruction as well as compressibility, in an end-to-end manner, with the use of an entropy penalty on the parameters. Our method significantly outperforms a state-of-the-art conventional approach for scene compression, achieving simultaneously higher quality reconstructions and lower bitrates. Furthermore, we show that the performance at lower bitrates can be improved by jointly representing multiple scenes using a soft form of parameter sharing.", "one-sentence_summary": "Compressing neural representation functions by penalizing the entropy of the reparameterized weights results in a small and useful renderer", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bird|3d_scene_compression_through_entropy_penalized_neural_representation_functions", "pdf": "/pdf/5e809739fd052bd0f76aa59c01525832e2fd222d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=7CWfolaTIN", "_bibtex": "@misc{\nbird2021d,\ntitle={3D Scene Compression through Entropy  Penalized Neural Representation Functions},\nauthor={Thomas Bird and Johannes Ball{\\'e} and Saurabh Singh and Philip Chou},\nyear={2021},\nurl={https://openreview.net/forum?id=PO0SuuafSX}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "PO0SuuafSX", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1575/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1575/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1575/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1575/Authors|ICLR.cc/2021/Conference/Paper1575/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1575/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858187, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1575/-/Official_Comment"}}}, {"id": "iGH3nWvfMKy", "original": null, "number": 5, "cdate": 1606212002871, "ddate": null, "tcdate": 1606212002871, "tmdate": 1606212002871, "tddate": null, "forum": "PO0SuuafSX", "replyto": "dp-fG2Va-95", "invitation": "ICLR.cc/2021/Conference/Paper1575/-/Official_Comment", "content": {"title": "Response", "comment": "We thank the reviewer for their thoughtful comments. We provide responses below:\n\n*The first is that I am not convinced that the problem this paper seeks to solve, ie compression of a 3D scene, is so relevant to the ML research community*\n\nThe concept of compressing a representation of a 3d scene is relatively new, and the set of applications for such methods has not yet been well established. However, we do believe there is real value in the research of baseline methods which can be used to do 3d scene compression, given the clear emergence of the technology to create and consume 3d visual data. \n\n*My second concern is the lack of comparison to other approaches to scene compression... Examples of this would be compressing a 3D mesh, or surface defined by voxels with lighting parameters and textures*\n\nWe do accept that it will most likely be more efficient to transmit compressed meshes if the scene itself is easily described in this way, and there is a body of literature that proposes such methods (through for example the transmission of truncated signed distance fields). However, our method works equally for these synthetic scenes (which are easily described by meshes), and for natural scenes, which are far more complex. Sending a compressed representation of a natural scene is not feasible using the methods you propose.  In particular, meshes, voxels, and other traditional geometric representations cannot generally capture the view-dependent effects present in natural scenes.  This is why we do not use it as a method for comparison.\n\nGiven that we wish to compare to scene compression methods that can model both synthetic and natural scenes, the pool of methods that can do so shrinks considerably. We believe that we have used a method (HEVC + LLFF) which is a fair comparison, and it is directly inspired by methods within the field of light-field image (LFI) compression. This is a relatively well-studied topic, and which is trying to solve a problem that is a subset of the problem we are trying to solve, since LFI are views of a 3d scene with a small angular distance between views.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1575/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1575/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "3D Scene Compression through Entropy  Penalized Neural Representation Functions", "authorids": ["~Thomas_Bird1", "~Johannes_Ball\u00e91", "~Saurabh_Singh1", "~Philip_Chou1"], "authors": ["Thomas Bird", "Johannes Ball\u00e9", "Saurabh Singh", "Philip Chou"], "keywords": ["scene representation", "compression", "neural rendering", "entropy coding"], "abstract": "Some forms of novel visual media enable the viewer to explore a 3D scene from essentially arbitrary viewpoints, by interpolating between a discrete set of original views. Compared to 2D imagery, these types of applications require much larger amounts of storage space, which we seek to reduce. Existing approaches for compressing 3D scenes are based on a separation of compression and rendering: each of the original views is compressed using traditional 2D image formats; the receiver decompresses the views and then performs the rendering. We unify these steps by directly compressing an implicit representation of the scene, a function that maps spatial coordinates to a radiance vector field, which can then be queried to render arbitrary viewpoints. The function is implemented as a neural network and jointly trained for reconstruction as well as compressibility, in an end-to-end manner, with the use of an entropy penalty on the parameters. Our method significantly outperforms a state-of-the-art conventional approach for scene compression, achieving simultaneously higher quality reconstructions and lower bitrates. Furthermore, we show that the performance at lower bitrates can be improved by jointly representing multiple scenes using a soft form of parameter sharing.", "one-sentence_summary": "Compressing neural representation functions by penalizing the entropy of the reparameterized weights results in a small and useful renderer", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bird|3d_scene_compression_through_entropy_penalized_neural_representation_functions", "pdf": "/pdf/5e809739fd052bd0f76aa59c01525832e2fd222d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=7CWfolaTIN", "_bibtex": "@misc{\nbird2021d,\ntitle={3D Scene Compression through Entropy  Penalized Neural Representation Functions},\nauthor={Thomas Bird and Johannes Ball{\\'e} and Saurabh Singh and Philip Chou},\nyear={2021},\nurl={https://openreview.net/forum?id=PO0SuuafSX}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "PO0SuuafSX", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1575/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1575/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1575/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1575/Authors|ICLR.cc/2021/Conference/Paper1575/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1575/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858187, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1575/-/Official_Comment"}}}, {"id": "32K65143i_G", "original": null, "number": 4, "cdate": 1606211917220, "ddate": null, "tcdate": 1606211917220, "tmdate": 1606211917220, "tddate": null, "forum": "PO0SuuafSX", "replyto": "CYnYni84S-", "invitation": "ICLR.cc/2021/Conference/Paper1575/-/Official_Comment", "content": {"title": "Response", "comment": "We thank the reviewer for their comments. Find our responses below:\n\n*While one can train such a network for nerf scenes, the network may get overfit to these scenes since the whole dataset has no more than 20 scenes.*\n\nThe NeRF model is in fact just trained for a single scene - there is no generalization, except in the multi-scene approach where we learn jointly across scenes. Training a NeRF model for a wide range of scenes is an open problem in the research community.  \n\nThe decompressor for the (compressed) NeRF model, on the other hand, does not depend on any dataset.  Its parameters, which include scales and offsets applied to the integer latent variables, and which also include the probabilities used to entropy code the integer latents, are all transmitted to the decoder in a fixed-length (e.g., 16-bit) integer format, without need for any training, thus obviously generalizing to any data.\n\n*The authors compare their methods with HEVC+LLFF method, which is pretty unfair. Since HEVS is a traditional video compression method while LIFF is also a traditional blending view rendering method. The authors are encouraged to compare with some neural network compression methods + neural rendering methods.*\n\nLLFF is not a traditional blending approach - a neural network is trained to promote images to multi-plane images, which are then blended. It is a state-of-the-art, learned method for novel view synthesis. HEVC is not a learned approach, but is still a modern and widely used video codec. Given that neural network compression approaches for video are still in their infancy, there is no obvious neural compression codec to use. As such, we think that HEVC + LLFF is a strong and appropriate baseline, which gives the best chance to this general methodology of communicating a compressed set of views, and rendering any novel views conditioned on those."}, "signatures": ["ICLR.cc/2021/Conference/Paper1575/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1575/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "3D Scene Compression through Entropy  Penalized Neural Representation Functions", "authorids": ["~Thomas_Bird1", "~Johannes_Ball\u00e91", "~Saurabh_Singh1", "~Philip_Chou1"], "authors": ["Thomas Bird", "Johannes Ball\u00e9", "Saurabh Singh", "Philip Chou"], "keywords": ["scene representation", "compression", "neural rendering", "entropy coding"], "abstract": "Some forms of novel visual media enable the viewer to explore a 3D scene from essentially arbitrary viewpoints, by interpolating between a discrete set of original views. Compared to 2D imagery, these types of applications require much larger amounts of storage space, which we seek to reduce. Existing approaches for compressing 3D scenes are based on a separation of compression and rendering: each of the original views is compressed using traditional 2D image formats; the receiver decompresses the views and then performs the rendering. We unify these steps by directly compressing an implicit representation of the scene, a function that maps spatial coordinates to a radiance vector field, which can then be queried to render arbitrary viewpoints. The function is implemented as a neural network and jointly trained for reconstruction as well as compressibility, in an end-to-end manner, with the use of an entropy penalty on the parameters. Our method significantly outperforms a state-of-the-art conventional approach for scene compression, achieving simultaneously higher quality reconstructions and lower bitrates. Furthermore, we show that the performance at lower bitrates can be improved by jointly representing multiple scenes using a soft form of parameter sharing.", "one-sentence_summary": "Compressing neural representation functions by penalizing the entropy of the reparameterized weights results in a small and useful renderer", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bird|3d_scene_compression_through_entropy_penalized_neural_representation_functions", "pdf": "/pdf/5e809739fd052bd0f76aa59c01525832e2fd222d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=7CWfolaTIN", "_bibtex": "@misc{\nbird2021d,\ntitle={3D Scene Compression through Entropy  Penalized Neural Representation Functions},\nauthor={Thomas Bird and Johannes Ball{\\'e} and Saurabh Singh and Philip Chou},\nyear={2021},\nurl={https://openreview.net/forum?id=PO0SuuafSX}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "PO0SuuafSX", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1575/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1575/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1575/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1575/Authors|ICLR.cc/2021/Conference/Paper1575/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1575/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858187, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1575/-/Official_Comment"}}}, {"id": "NQYZe4VUN_", "original": null, "number": 3, "cdate": 1606211827022, "ddate": null, "tcdate": 1606211827022, "tmdate": 1606211827022, "tddate": null, "forum": "PO0SuuafSX", "replyto": "_oyaIfM066f", "invitation": "ICLR.cc/2021/Conference/Paper1575/-/Official_Comment", "content": {"title": "Response", "comment": "Thank you for the points raised. Find our responses below:\n\n*A more valid baseline should be: receiver receives the training images compressed by HEVC -> decode the images -> receiver train a new Nerf on the decoded images -> run the trained model on the test set.*\n\nAlthough this is a valid scheme, we do not consider this as a practical baseline, since it requires the receiver to incur a prohibitively large cost in training a new NeRF model. The decoding time for the receiver is of primary concern, due to the fact that one compressed scene can be decompressed and used by an unlimited number of receivers. As such, a long encode time is potentially acceptable, whereas a long decode time is less so. So we only consider methods that fit these restrictions, and the compressed NeRF model and the HEVC + LLFF baseline both have decode times that are an order of magnitude or more faster than training a NeRF model.\n\n*...the author did not report the running time when doing inference on a trained nerf model, and do not have a comparison with HEVC+LLFF baseline*\n\nThe inference times are roughly comparable between the two methods, in that they both require a forward pass through neural networks of comparable size. There has been no substantial optimization done for inference time in either method, so we do not provide detailed runtimes.\n\n*Nerf model takes more than one day to converge, while HEVC is very fast for both encoding and decoding.*\n\nThis is true, although the LLFF model still needs to be trained. The advantage of the HEVC + LLFF method is that it can be used on unseen scenes, whereas NeRF has to be trained for each individual scene. Although (as we have said above) since this is a price paid by the sender, we do not think that this makes the method impractical."}, "signatures": ["ICLR.cc/2021/Conference/Paper1575/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1575/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "3D Scene Compression through Entropy  Penalized Neural Representation Functions", "authorids": ["~Thomas_Bird1", "~Johannes_Ball\u00e91", "~Saurabh_Singh1", "~Philip_Chou1"], "authors": ["Thomas Bird", "Johannes Ball\u00e9", "Saurabh Singh", "Philip Chou"], "keywords": ["scene representation", "compression", "neural rendering", "entropy coding"], "abstract": "Some forms of novel visual media enable the viewer to explore a 3D scene from essentially arbitrary viewpoints, by interpolating between a discrete set of original views. Compared to 2D imagery, these types of applications require much larger amounts of storage space, which we seek to reduce. Existing approaches for compressing 3D scenes are based on a separation of compression and rendering: each of the original views is compressed using traditional 2D image formats; the receiver decompresses the views and then performs the rendering. We unify these steps by directly compressing an implicit representation of the scene, a function that maps spatial coordinates to a radiance vector field, which can then be queried to render arbitrary viewpoints. The function is implemented as a neural network and jointly trained for reconstruction as well as compressibility, in an end-to-end manner, with the use of an entropy penalty on the parameters. Our method significantly outperforms a state-of-the-art conventional approach for scene compression, achieving simultaneously higher quality reconstructions and lower bitrates. Furthermore, we show that the performance at lower bitrates can be improved by jointly representing multiple scenes using a soft form of parameter sharing.", "one-sentence_summary": "Compressing neural representation functions by penalizing the entropy of the reparameterized weights results in a small and useful renderer", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bird|3d_scene_compression_through_entropy_penalized_neural_representation_functions", "pdf": "/pdf/5e809739fd052bd0f76aa59c01525832e2fd222d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=7CWfolaTIN", "_bibtex": "@misc{\nbird2021d,\ntitle={3D Scene Compression through Entropy  Penalized Neural Representation Functions},\nauthor={Thomas Bird and Johannes Ball{\\'e} and Saurabh Singh and Philip Chou},\nyear={2021},\nurl={https://openreview.net/forum?id=PO0SuuafSX}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "PO0SuuafSX", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1575/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1575/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1575/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1575/Authors|ICLR.cc/2021/Conference/Paper1575/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1575/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858187, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1575/-/Official_Comment"}}}, {"id": "Y23I8Thc4RB", "original": null, "number": 2, "cdate": 1606211743007, "ddate": null, "tcdate": 1606211743007, "tmdate": 1606211743007, "tddate": null, "forum": "PO0SuuafSX", "replyto": "5cE0tr60YSZ", "invitation": "ICLR.cc/2021/Conference/Paper1575/-/Official_Comment", "content": {"title": "Response", "comment": "Thank you for the points raised. Find our responses below:\n\n*... there is no improvement in rendering speed. In fact, because of the additional decompression, rendering novel views might very well take longer than the original NeRF...Since improving the NeRF rendering speed is vital to eventually achieving real-time rendering, I consider this a major drawback of this work*\n\nThe goal of our paper is not to improve the rendering speed of NeRF. Our method of compressing a representation function could be applied to other scene rendering techniques, many of which would have faster rendering times. Indeed, there have been some recent works such as Neural Sparse Voxel Fields (NSVF) which claim to improve the rendering speed of NeRF up to 10x. Our method would apply equally to NSVF as to NeRF. As such, we don\u2019t think that our work should be judged in a negative light because of the limitations of the NeRF method (such as rendering speed).\n\nTraining the compressed NeRF model does take longer than training the uncompressed model, since we have the extra computation in the calculation of gradients for the differential entropy term. However, after training, using the compressed NeRF model requires only a very small amount of extra computation as compared to the uncompressed model. This is because we don\u2019t have to calculate the entropy penalty, and just have to use the pre-computed discrete probability tables to decode the weights - the time this takes is a negligible fraction of the current rendering speed.\n\n*the work does not demonstrate its usefulness under the multi-scene setup*\n\nWhilst it is true that the separate NeRF models perform slightly better at high bitrates, the multi-scene compressed NeRF models do achieve a significant improvement at low bitrates. Given that we are free to use separate or multi-scene compressed NeRF models for different bitrates, the multi-scene model therefore strictly improves the rate-distortion performance of the overall method.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1575/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1575/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "3D Scene Compression through Entropy  Penalized Neural Representation Functions", "authorids": ["~Thomas_Bird1", "~Johannes_Ball\u00e91", "~Saurabh_Singh1", "~Philip_Chou1"], "authors": ["Thomas Bird", "Johannes Ball\u00e9", "Saurabh Singh", "Philip Chou"], "keywords": ["scene representation", "compression", "neural rendering", "entropy coding"], "abstract": "Some forms of novel visual media enable the viewer to explore a 3D scene from essentially arbitrary viewpoints, by interpolating between a discrete set of original views. Compared to 2D imagery, these types of applications require much larger amounts of storage space, which we seek to reduce. Existing approaches for compressing 3D scenes are based on a separation of compression and rendering: each of the original views is compressed using traditional 2D image formats; the receiver decompresses the views and then performs the rendering. We unify these steps by directly compressing an implicit representation of the scene, a function that maps spatial coordinates to a radiance vector field, which can then be queried to render arbitrary viewpoints. The function is implemented as a neural network and jointly trained for reconstruction as well as compressibility, in an end-to-end manner, with the use of an entropy penalty on the parameters. Our method significantly outperforms a state-of-the-art conventional approach for scene compression, achieving simultaneously higher quality reconstructions and lower bitrates. Furthermore, we show that the performance at lower bitrates can be improved by jointly representing multiple scenes using a soft form of parameter sharing.", "one-sentence_summary": "Compressing neural representation functions by penalizing the entropy of the reparameterized weights results in a small and useful renderer", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bird|3d_scene_compression_through_entropy_penalized_neural_representation_functions", "pdf": "/pdf/5e809739fd052bd0f76aa59c01525832e2fd222d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=7CWfolaTIN", "_bibtex": "@misc{\nbird2021d,\ntitle={3D Scene Compression through Entropy  Penalized Neural Representation Functions},\nauthor={Thomas Bird and Johannes Ball{\\'e} and Saurabh Singh and Philip Chou},\nyear={2021},\nurl={https://openreview.net/forum?id=PO0SuuafSX}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "PO0SuuafSX", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1575/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1575/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1575/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1575/Authors|ICLR.cc/2021/Conference/Paper1575/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1575/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858187, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1575/-/Official_Comment"}}}, {"id": "dp-fG2Va-95", "original": null, "number": 1, "cdate": 1603554838625, "ddate": null, "tcdate": 1603554838625, "tmdate": 1605024411469, "tddate": null, "forum": "PO0SuuafSX", "replyto": "PO0SuuafSX", "invitation": "ICLR.cc/2021/Conference/Paper1575/-/Official_Review", "content": {"title": "3D Scene Compression through Entropy Penalized Neural Representation Functions", "review": "I think the paper is well written, and explains the details of the method well. I addition I think choices made in the method are intelligent and well justified. \n\nMy concerns with the paper lie in two area. The first is that I am not convinced that the problem this paper seeks to solve, ie  compression of a 3D scene, is so relevant to the ML research community that is justifies the lack of novelty in the method. From reading this paper it feel like 2 approaches have been found , ie, NeRF and model compression using entropy penalty, which happen to work well together, but the actual degree of novel research contribution seems low.  If 3D scene compression was an established area of research in the ML research community, with many previous works proposing high performing solutions,  this approach may be justified as sufficiently better across various metrics. However, given the lack of this prior work, the solution feels far more like an engineering solution to allow NeRF to work well on cellphones then machine learning research. \n\nMy second concern is the lack of comparison to other approaches to scene compression. From the way I view the problem you have proposed, you are assuming practically explicit 3D scene information as input and attempting to transfer this information between devices in as small a size as possible such that it images of the scene can be sampled on the new device in as high a quality as possible.  There are other ways of describing a 3D scene then with multiple images. The experiment I really want to see here is if this method is better then if the explicit scene information is compressed and rendered on the second device. If you can provide this in new experiments I will be happy to raise my score. Examples of this would be compressing  a 3D mesh, or surface defined by voxels with lighting parameters and textures.  My main concern here is that for simple scenes I am very sure that compressing or even transferring directly the 3D scene explicitly is a far superior, though there is probably some level of scene complexity at which your method overtakes it. I think it is important to establish this, and understand where your method is applicable. ", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1575/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1575/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "3D Scene Compression through Entropy  Penalized Neural Representation Functions", "authorids": ["~Thomas_Bird1", "~Johannes_Ball\u00e91", "~Saurabh_Singh1", "~Philip_Chou1"], "authors": ["Thomas Bird", "Johannes Ball\u00e9", "Saurabh Singh", "Philip Chou"], "keywords": ["scene representation", "compression", "neural rendering", "entropy coding"], "abstract": "Some forms of novel visual media enable the viewer to explore a 3D scene from essentially arbitrary viewpoints, by interpolating between a discrete set of original views. Compared to 2D imagery, these types of applications require much larger amounts of storage space, which we seek to reduce. Existing approaches for compressing 3D scenes are based on a separation of compression and rendering: each of the original views is compressed using traditional 2D image formats; the receiver decompresses the views and then performs the rendering. We unify these steps by directly compressing an implicit representation of the scene, a function that maps spatial coordinates to a radiance vector field, which can then be queried to render arbitrary viewpoints. The function is implemented as a neural network and jointly trained for reconstruction as well as compressibility, in an end-to-end manner, with the use of an entropy penalty on the parameters. Our method significantly outperforms a state-of-the-art conventional approach for scene compression, achieving simultaneously higher quality reconstructions and lower bitrates. Furthermore, we show that the performance at lower bitrates can be improved by jointly representing multiple scenes using a soft form of parameter sharing.", "one-sentence_summary": "Compressing neural representation functions by penalizing the entropy of the reparameterized weights results in a small and useful renderer", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bird|3d_scene_compression_through_entropy_penalized_neural_representation_functions", "pdf": "/pdf/5e809739fd052bd0f76aa59c01525832e2fd222d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=7CWfolaTIN", "_bibtex": "@misc{\nbird2021d,\ntitle={3D Scene Compression through Entropy  Penalized Neural Representation Functions},\nauthor={Thomas Bird and Johannes Ball{\\'e} and Saurabh Singh and Philip Chou},\nyear={2021},\nurl={https://openreview.net/forum?id=PO0SuuafSX}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "PO0SuuafSX", "replyto": "PO0SuuafSX", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1575/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538115618, "tmdate": 1606915807622, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1575/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1575/-/Official_Review"}}}, {"id": "CYnYni84S-", "original": null, "number": 2, "cdate": 1603862676781, "ddate": null, "tcdate": 1603862676781, "tmdate": 1605024411409, "tddate": null, "forum": "PO0SuuafSX", "replyto": "PO0SuuafSX", "invitation": "ICLR.cc/2021/Conference/Paper1575/-/Official_Review", "content": {"title": "Review", "review": "Summary:\n\nThis paper proposes to compress nerf models with entropy loss, where instead of directly training nerf model parameters, it trains a new function F which takes some compressed information and decodes to the nerf models. Then it did the same things as nerf, which render scenes in novel views. The authors show that the function F could largely compress the original nerf models while keeping similar PSNR.\n\nComments:\nThe paper combines network compression and neural renderings, which is pretty interesting. However, I have several concerns :\n\nNovelty:  The paper seems to combine two methods together, where in network compression, it adopts Oktay et al. (2020) while in neural renderings, it relies on nerf. Though it introduces compression to neural rendering, such a combination seems to be not very creative.\n\nGeneralization. While one can train such a network for nerf scenes, the network may get overfit to these scenes since the whole dataset has no more than 20 scenes.  It would be great to validate on shapenet datasets, or some dataset has at least 100 models.\n\nComaprison. The authors compare their methods with HEVC+LLFF method, which is pretty unfair. Since HEVS is a traditional video compression method while LIFF is also a traditional blending view rendering method. The authors are encouraged to compare with some neural network compression methods + neural rendering methods.\n\nConclusion: Overall, I think this paper proposes an interesting idea and shows good results. However, due to lack of creativity and unfair comparison, I rate it below the acceptance bar.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2021/Conference/Paper1575/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1575/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "3D Scene Compression through Entropy  Penalized Neural Representation Functions", "authorids": ["~Thomas_Bird1", "~Johannes_Ball\u00e91", "~Saurabh_Singh1", "~Philip_Chou1"], "authors": ["Thomas Bird", "Johannes Ball\u00e9", "Saurabh Singh", "Philip Chou"], "keywords": ["scene representation", "compression", "neural rendering", "entropy coding"], "abstract": "Some forms of novel visual media enable the viewer to explore a 3D scene from essentially arbitrary viewpoints, by interpolating between a discrete set of original views. Compared to 2D imagery, these types of applications require much larger amounts of storage space, which we seek to reduce. Existing approaches for compressing 3D scenes are based on a separation of compression and rendering: each of the original views is compressed using traditional 2D image formats; the receiver decompresses the views and then performs the rendering. We unify these steps by directly compressing an implicit representation of the scene, a function that maps spatial coordinates to a radiance vector field, which can then be queried to render arbitrary viewpoints. The function is implemented as a neural network and jointly trained for reconstruction as well as compressibility, in an end-to-end manner, with the use of an entropy penalty on the parameters. Our method significantly outperforms a state-of-the-art conventional approach for scene compression, achieving simultaneously higher quality reconstructions and lower bitrates. Furthermore, we show that the performance at lower bitrates can be improved by jointly representing multiple scenes using a soft form of parameter sharing.", "one-sentence_summary": "Compressing neural representation functions by penalizing the entropy of the reparameterized weights results in a small and useful renderer", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bird|3d_scene_compression_through_entropy_penalized_neural_representation_functions", "pdf": "/pdf/5e809739fd052bd0f76aa59c01525832e2fd222d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=7CWfolaTIN", "_bibtex": "@misc{\nbird2021d,\ntitle={3D Scene Compression through Entropy  Penalized Neural Representation Functions},\nauthor={Thomas Bird and Johannes Ball{\\'e} and Saurabh Singh and Philip Chou},\nyear={2021},\nurl={https://openreview.net/forum?id=PO0SuuafSX}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "PO0SuuafSX", "replyto": "PO0SuuafSX", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1575/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538115618, "tmdate": 1606915807622, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1575/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1575/-/Official_Review"}}}, {"id": "5cE0tr60YSZ", "original": null, "number": 4, "cdate": 1603941535480, "ddate": null, "tcdate": 1603941535480, "tmdate": 1605024411348, "tddate": null, "forum": "PO0SuuafSX", "replyto": "PO0SuuafSX", "invitation": "ICLR.cc/2021/Conference/Paper1575/-/Official_Review", "content": {"title": "Compressing NeRF's for single or multiple scenes", "review": "This paper proposes a method of compressing neural radience fields (NeRF's) by learning mappings from latent codes to model parameters such that both distortion/reconstruction quality and the rate get minimized. While maintaining the same level of quality, this method is able to compress NeRF models for more efficient sender-to-receiver transmission.\n\nThe strong aspects of this paper include:\n(1) it addresses the valid problem of compressing NeRF models, which is particularly valid given that one usually trains one NeRF per scene. Without compression, the storage of NeRF's will grow dramatically as more scenes are considered;\n(2) it achieves the same level of rendering quality, while compressing the model by 8-9x;\n(3) it might have implications to future work that attempts to render NeRF's in real time or under a sender-receiver setup.\n\nIn terms of drawbacks, this paper can be made stronger by addressing the following points:\n(1) while model sizes are compressed significantly at almost no cost of rendering quality, there is no improvement in rendering speed. In fact, because of the additional decompression, rendering novel views might very well take longer than the original NeRF. Since improving the NeRF rendering speed is vital to eventually achieving real-time rendering, I consider this a major drawback of this work;\n(2) another major drawback in my opinion is that the work does not demonstrate its usefulness under the multi-scene setup. As the original NeRF is per-scene, and people desire a multi-scene variant of NeRF, the work would be much more impactful if it provides significant compression while achieving the same quality in such setups. Unfortunately, Fig. 5 shows having separate NeRF's have higher rendering quality at comparable sizes as the compressed models;\n(3) it would be interesting to explain how this is related to meta-learning. One can imagine having a meta-NeRF that quickly adapts to different scenes. This also achieves similar compression effects, and may work better for the multi-scene setup. Maybe comparisons can be made to such meta-learning methods; and\n(4) the work heavily relies on prior works in the compression aspect, and it's unclear to me what the novelty is in that regard.", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1575/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1575/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "3D Scene Compression through Entropy  Penalized Neural Representation Functions", "authorids": ["~Thomas_Bird1", "~Johannes_Ball\u00e91", "~Saurabh_Singh1", "~Philip_Chou1"], "authors": ["Thomas Bird", "Johannes Ball\u00e9", "Saurabh Singh", "Philip Chou"], "keywords": ["scene representation", "compression", "neural rendering", "entropy coding"], "abstract": "Some forms of novel visual media enable the viewer to explore a 3D scene from essentially arbitrary viewpoints, by interpolating between a discrete set of original views. Compared to 2D imagery, these types of applications require much larger amounts of storage space, which we seek to reduce. Existing approaches for compressing 3D scenes are based on a separation of compression and rendering: each of the original views is compressed using traditional 2D image formats; the receiver decompresses the views and then performs the rendering. We unify these steps by directly compressing an implicit representation of the scene, a function that maps spatial coordinates to a radiance vector field, which can then be queried to render arbitrary viewpoints. The function is implemented as a neural network and jointly trained for reconstruction as well as compressibility, in an end-to-end manner, with the use of an entropy penalty on the parameters. Our method significantly outperforms a state-of-the-art conventional approach for scene compression, achieving simultaneously higher quality reconstructions and lower bitrates. Furthermore, we show that the performance at lower bitrates can be improved by jointly representing multiple scenes using a soft form of parameter sharing.", "one-sentence_summary": "Compressing neural representation functions by penalizing the entropy of the reparameterized weights results in a small and useful renderer", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bird|3d_scene_compression_through_entropy_penalized_neural_representation_functions", "pdf": "/pdf/5e809739fd052bd0f76aa59c01525832e2fd222d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=7CWfolaTIN", "_bibtex": "@misc{\nbird2021d,\ntitle={3D Scene Compression through Entropy  Penalized Neural Representation Functions},\nauthor={Thomas Bird and Johannes Ball{\\'e} and Saurabh Singh and Philip Chou},\nyear={2021},\nurl={https://openreview.net/forum?id=PO0SuuafSX}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "PO0SuuafSX", "replyto": "PO0SuuafSX", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1575/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538115618, "tmdate": 1606915807622, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1575/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1575/-/Official_Review"}}}, {"id": "_oyaIfM066f", "original": null, "number": 3, "cdate": 1603909291867, "ddate": null, "tcdate": 1603909291867, "tmdate": 1605024411290, "tddate": null, "forum": "PO0SuuafSX", "replyto": "PO0SuuafSX", "invitation": "ICLR.cc/2021/Conference/Paper1575/-/Official_Review", "content": {"title": "Interesting problem, but not enough novelty and the not well-conducted experiements", "review": "**Paper Summary**:\n\nCompressing 3D scene is an interesting problem to explore. The paper proposes to add entropy penalized reparametrization (Oktay et al. (2020)) technique into Nerf (Mildenhall et al. (2020)) and compress the neural network in Nerf. Experiments also show some compressing rates improvement with the proposed baseline, which I have some concerns in the weakness below.  \n\n**Strength**:\n1. The problem this paper is attacking is interesting, compressing 3D scene plays an important role in real-time applications. \n2. The paper also showed the approach to compress multiple scenes in one network (though I have some concerns for the experiments in weakness below).\n\n**Weakness**:\n1. Lack of novelty. The main technique from this paper is merging two methods together (Oktay et al. (2020), and Mildenhall et al. (2020)),  with some improvements by extending the nerf to multiple scenes. However, the multiple scenes experiments are not performed well to demonstrate the effectiveness of the proposed method (see below), so the overall novelty is not enough. \n\n2. Experiments are not great enough to show the effectiveness of the full pipeline. \n\n   a) In single scene experiment, I think the main reason why HEVC+LLFF has lower PSNR is that LLFF is interpolating multiple training views, and this is obvious and has already been shown in the original Nerf paper (Table 1, Fig 5 in  Mildenhall et al. (2020)). Therefore, this is not a valid experiment to show the pipeline in this paper is better in compression. A more valid baseline should be: receiver receives the training images compressed by HEVC -> decode the images -> receiver train a new Nerf on the decoded images -> run the trained model on the test set. \n\n  b) In multiple scenes experiment. The paper only showed the experiments on compressing two scenes, it's not clear how will the performance be and conclusion generalize to more scenes, e.g. train only one model on all 8 synthetic scenes together. \n\n3. The paper also didn't consider the efficiency problem, training a Nerf model takes a long time, and also the author did not report the running time when doing inference on a trained nerf model, and do not have a comparison with HEVC+LLFF baseline. In literature, Nerf model takes more than one day to converge, while HEVC is very fast for both encoding and decoding.\n\nOverall, considering the novelty and the experiment section in this paper, I don't think they are enough to reach the bar of ICLR, so I vote for rejection. \n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper1575/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1575/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "3D Scene Compression through Entropy  Penalized Neural Representation Functions", "authorids": ["~Thomas_Bird1", "~Johannes_Ball\u00e91", "~Saurabh_Singh1", "~Philip_Chou1"], "authors": ["Thomas Bird", "Johannes Ball\u00e9", "Saurabh Singh", "Philip Chou"], "keywords": ["scene representation", "compression", "neural rendering", "entropy coding"], "abstract": "Some forms of novel visual media enable the viewer to explore a 3D scene from essentially arbitrary viewpoints, by interpolating between a discrete set of original views. Compared to 2D imagery, these types of applications require much larger amounts of storage space, which we seek to reduce. Existing approaches for compressing 3D scenes are based on a separation of compression and rendering: each of the original views is compressed using traditional 2D image formats; the receiver decompresses the views and then performs the rendering. We unify these steps by directly compressing an implicit representation of the scene, a function that maps spatial coordinates to a radiance vector field, which can then be queried to render arbitrary viewpoints. The function is implemented as a neural network and jointly trained for reconstruction as well as compressibility, in an end-to-end manner, with the use of an entropy penalty on the parameters. Our method significantly outperforms a state-of-the-art conventional approach for scene compression, achieving simultaneously higher quality reconstructions and lower bitrates. Furthermore, we show that the performance at lower bitrates can be improved by jointly representing multiple scenes using a soft form of parameter sharing.", "one-sentence_summary": "Compressing neural representation functions by penalizing the entropy of the reparameterized weights results in a small and useful renderer", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "bird|3d_scene_compression_through_entropy_penalized_neural_representation_functions", "pdf": "/pdf/5e809739fd052bd0f76aa59c01525832e2fd222d.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=7CWfolaTIN", "_bibtex": "@misc{\nbird2021d,\ntitle={3D Scene Compression through Entropy  Penalized Neural Representation Functions},\nauthor={Thomas Bird and Johannes Ball{\\'e} and Saurabh Singh and Philip Chou},\nyear={2021},\nurl={https://openreview.net/forum?id=PO0SuuafSX}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "PO0SuuafSX", "replyto": "PO0SuuafSX", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1575/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538115618, "tmdate": 1606915807622, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1575/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1575/-/Official_Review"}}}], "count": 12}