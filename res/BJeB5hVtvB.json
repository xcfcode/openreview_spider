{"notes": [{"id": "yLP-AdRurJ8", "original": null, "number": 2, "cdate": 1593599245606, "ddate": null, "tcdate": 1593599245606, "tmdate": 1593599245606, "tddate": null, "forum": "BJeB5hVtvB", "replyto": "wEB2CNtu2rR", "invitation": "ICLR.cc/2020/Conference/Paper113/-/Public_Comment", "content": {"title": "Thanks for this thorough response", "comment": "Hi Chen,\n\nThank you for this thorough response.\n\nIn my opinion, calibration and misclassification detection are two different paths to improve the quality of uncertainty estimates. Equipped with a calibrated confidence measure, a neural network can be incorporated in probabilistic systems where insufficient confidence from one sensor could imply relying more on others. However, calibration doesn't affect the ranking of the confidence estimate on a given test set. On the other hand, improving misclassification detection is beneficial for various applications such as active learning, failure prediction or domain adaptation with self-training.\n\nWe evaluated calibration of ConfidNet's confidence score in Section 3.2 in the supplementary. While ConfidNet improves ECE score on complex datasets, it remains not as effective as dedicated methods such as temperature scaling. Regarding TCP criterion, we haven't measured its calibration score but its 'binary' behavior' may indeed not be beneficial for confidence calibration.\n\nSuch as in DBLE, the fact that state-of-the-art DNN yield few training errors may harm ConfidNet training. In supplementary, we tried to 'counter-balance' this effect with Focal loss but it didn't improve misclassification detection. We observed in this case that the confidence network output low confidence estimate for most of the inputs, included correctly-classified samples. On the same matter, a 2-step learning where the classifier weights are trained before the confidence network weights was more stable and yielded better results in our case. Due to the distance-based scores, I guess DBLE approach is more robust to train both networks simultaneously.\n\nAgain, thank you for taking the time to respond and let's keep in touch for further discussions on these subjects :)\n\n\nCharles"}, "signatures": ["~Charles_Corbi\u00e8re1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Charles_Corbi\u00e8re1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["xingchen1113@gmail.com", "soarik@google.com", "zizhaoz@google.com", "tpfister@google.com"], "title": "Distance-Based Learning from Errors for Confidence Calibration", "authors": ["Chen Xing", "Sercan Arik", "Zizhao Zhang", "Tomas Pfister"], "pdf": "/pdf/13ce35a49cc94ffbde2635c1c7f0c1f2593d77e7.pdf", "abstract": "Deep neural networks (DNNs) are poorly calibrated when trained in conventional ways. To improve confidence calibration of DNNs, we propose a novel training method, distance-based learning from errors (DBLE). DBLE bases its confidence estimation on distances in the representation space. In DBLE, we first adapt prototypical learning to train classification models. It yields a representation space where the distance between a test sample and its ground truth class center can calibrate the model's classification performance. At inference, however, these distances are not available due to the lack of ground truth labels. To circumvent this by inferring the distance for every test sample, we propose to train a confidence model jointly with the classification model. We integrate this into training by merely learning from mis-classified training samples, which we show to be highly beneficial for effective learning. On multiple datasets and DNN architectures, we demonstrate that DBLE outperforms alternative single-model confidence calibration approaches. DBLE also achieves comparable performance with computationally-expensive ensemble approaches with lower computational cost and lower number of parameters.", "keywords": ["Confidence Calibration", "Uncertainty Estimation", "Prototypical Learning"], "paperhash": "xing|distancebased_learning_from_errors_for_confidence_calibration", "code": "https://drive.google.com/open?id=1UThGvkkvFvKX8ogsfwvdA3uY8xzDlIuL", "_bibtex": "@inproceedings{\nXing2020Distance-Based,\ntitle={Distance-Based Learning from Errors for Confidence Calibration},\nauthor={Chen Xing and Sercan Arik and Zizhao Zhang and Tomas Pfister},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeB5hVtvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/d4d715434dfb3cf62f3df9859c7d67055aafea8e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJeB5hVtvB", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504213763, "tmdate": 1576860564514, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper113/Authors", "ICLR.cc/2020/Conference/Paper113/Reviewers", "ICLR.cc/2020/Conference/Paper113/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper113/-/Public_Comment"}}}, {"id": "wEB2CNtu2rR", "original": null, "number": 5, "cdate": 1593220357217, "ddate": null, "tcdate": 1593220357217, "tmdate": 1593220357217, "tddate": null, "forum": "BJeB5hVtvB", "replyto": "qB67tebO9bL", "invitation": "ICLR.cc/2020/Conference/Paper113/-/Official_Comment", "content": {"title": "Thank you for pointing out another related work!", "comment": "Hi Charles,\n\nThank you very much for your interest in our work.\n\nWe didn't notice TCP and include it into our related work in the submission because TCP appears available on-line after the submission ddl. NeurIPS 2019's accepted papers are out on NIPS Proceedings website after the ICLR submission ddl. And I checked that the TCP paper is firstly uploaded on arxiv at October 1 2019, which is also after the ICLR submission ddl. I have to make this clear first because I don't want other people to get a wrong impression from our discussion that we deliberately dodged your work when submitting.   \n\nI have read TCP carefully and consider it a very interesting empirical observation. In my opinion, the main difference between TCP and DBLE is that the task of confidence calibration has more fine-grained requirements than a binary classification task of misclassification detection. In confidence calibration, the confidence estimation has to ``calibrate\u2019\u2019 the model\u2019s performance on the sample. For example, if you sort all test samples according to their confidence estimations and partition them into bins accordingly, the bin of average confidence estimation 0.5 should have 50% classification accuracy. We empirically observed in the experiment section that under prototypical training and inference, DBLE has this feature (ECE measures that).\n\nI haven\u2019t checked if the true class possibility also has this feature. From Figure 1 in TCP\u2019s paper, it seems that the main chunk of misclassified samples have very low TCP (near 0), which probably means TCP is too binary for confidence calibration. But I think it is worth to check with the confidence calibration exp described in Section 3.2 DBLE paper, how TCP would perform. If TCP doesn\u2019t perform well because most misclassified samples have very low TCP, then an interesting question would be why most misclassified samples have very low TCP under classic training? Is it because the decision boundary is improperly located? Can we add some regularizations during training accordingly to prevent it from happening?\n\nAs far as I know, there is no previous work trying to analyze the true class possibility of misclassified samples under classic training. If you could go steps further in this direction and come up with regularizations for classic training to solve confidence calibration problem, the impact could be significantly larger than DBLE. Because DBLE uses prototypical training, which would be slow when the number of classes increases. While a potential regularization method for classic training could be less time-consuming. I would be very happy to see a more time-efficient method defeating DBLE on confidence calibration! :) You can also keep me posted if you want further discussions about new exp results. :)\n\n\nChen\n\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper113/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper113/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["xingchen1113@gmail.com", "soarik@google.com", "zizhaoz@google.com", "tpfister@google.com"], "title": "Distance-Based Learning from Errors for Confidence Calibration", "authors": ["Chen Xing", "Sercan Arik", "Zizhao Zhang", "Tomas Pfister"], "pdf": "/pdf/13ce35a49cc94ffbde2635c1c7f0c1f2593d77e7.pdf", "abstract": "Deep neural networks (DNNs) are poorly calibrated when trained in conventional ways. To improve confidence calibration of DNNs, we propose a novel training method, distance-based learning from errors (DBLE). DBLE bases its confidence estimation on distances in the representation space. In DBLE, we first adapt prototypical learning to train classification models. It yields a representation space where the distance between a test sample and its ground truth class center can calibrate the model's classification performance. At inference, however, these distances are not available due to the lack of ground truth labels. To circumvent this by inferring the distance for every test sample, we propose to train a confidence model jointly with the classification model. We integrate this into training by merely learning from mis-classified training samples, which we show to be highly beneficial for effective learning. On multiple datasets and DNN architectures, we demonstrate that DBLE outperforms alternative single-model confidence calibration approaches. DBLE also achieves comparable performance with computationally-expensive ensemble approaches with lower computational cost and lower number of parameters.", "keywords": ["Confidence Calibration", "Uncertainty Estimation", "Prototypical Learning"], "paperhash": "xing|distancebased_learning_from_errors_for_confidence_calibration", "code": "https://drive.google.com/open?id=1UThGvkkvFvKX8ogsfwvdA3uY8xzDlIuL", "_bibtex": "@inproceedings{\nXing2020Distance-Based,\ntitle={Distance-Based Learning from Errors for Confidence Calibration},\nauthor={Chen Xing and Sercan Arik and Zizhao Zhang and Tomas Pfister},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeB5hVtvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/d4d715434dfb3cf62f3df9859c7d67055aafea8e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJeB5hVtvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper113/Authors", "ICLR.cc/2020/Conference/Paper113/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper113/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper113/Reviewers", "ICLR.cc/2020/Conference/Paper113/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper113/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper113/Authors|ICLR.cc/2020/Conference/Paper113/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504176215, "tmdate": 1576860530821, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper113/Authors", "ICLR.cc/2020/Conference/Paper113/Reviewers", "ICLR.cc/2020/Conference/Paper113/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper113/-/Official_Comment"}}}, {"id": "qB67tebO9bL", "original": null, "number": 1, "cdate": 1593159484697, "ddate": null, "tcdate": 1593159484697, "tmdate": 1593159484697, "tddate": null, "forum": "BJeB5hVtvB", "replyto": "BJeB5hVtvB", "invitation": "ICLR.cc/2020/Conference/Paper113/-/Public_Comment", "content": {"title": "Related work of Learning from Errors", "comment": "Dear authors,\n\nThank you for the interesting paper and congratulations on the acceptance at ICLR.\n\nImproving calibration by learning a confidence model from errors is an interesting path. I would like to draw your attention to our work [1] as it shares some similarities with DBLE approach. In our paper, we aim to improve failure prediction, i.e. misclassification detection. Similar to section 3.2 in your paper, we first show empirically that the probability associated to the true class, True Class Probability (TCP), offers a better uncertainty criterion than the standard Maximum Class Probability used in vanilla training. As the true class of a sample is obviously not available at inference, we introduced a confidence model, named ConfidNet, to learn TCP from training data. Such as in DBLE, this confidence model is composed of several fully-connected layers and attached to the penultimate layer of the original classification layer.\n\nAs far as I understand, the main differences between your work and ours are the following:\n1. The paper address the task of calibration while we focused on misclassification detection ;\n2. Confidence model is learned jointly with the classification model in DBLE while ConfidNet is trained on an already trained classification model ;\n3. Training is performed only on misclassified samples in DBLE, which seems to be adequate for classification models learned with prototypical learning ;\n4. Scalar output of the confidence model in DBLE corresponds to the variance of a Gaussian distribution centered on the sample representation hs. In ConfidNet, we straightforwardly use the output as an uncertainty estimation for misclassification detection.\n\nPlease correct me if I have misunderstood anything. Your confidence training scheme combined with prototypical learning is inspiring. I would be very interested to know if this enable to better detect misclassifications.\n\nBest regards,\nCharles Corbi\u00e8re\n\n[1] \u201cAddressing Failure Prediction by Learning Model Confidence\u201d Charles Corbi\u00e8re, Nicolas Thome, Avner Bar-Hen, Matthieu Cord, Patrick P\u00e9rez. NeurIPS 2019\n"}, "signatures": ["~Charles_Corbi\u00e8re1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Charles_Corbi\u00e8re1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["xingchen1113@gmail.com", "soarik@google.com", "zizhaoz@google.com", "tpfister@google.com"], "title": "Distance-Based Learning from Errors for Confidence Calibration", "authors": ["Chen Xing", "Sercan Arik", "Zizhao Zhang", "Tomas Pfister"], "pdf": "/pdf/13ce35a49cc94ffbde2635c1c7f0c1f2593d77e7.pdf", "abstract": "Deep neural networks (DNNs) are poorly calibrated when trained in conventional ways. To improve confidence calibration of DNNs, we propose a novel training method, distance-based learning from errors (DBLE). DBLE bases its confidence estimation on distances in the representation space. In DBLE, we first adapt prototypical learning to train classification models. It yields a representation space where the distance between a test sample and its ground truth class center can calibrate the model's classification performance. At inference, however, these distances are not available due to the lack of ground truth labels. To circumvent this by inferring the distance for every test sample, we propose to train a confidence model jointly with the classification model. We integrate this into training by merely learning from mis-classified training samples, which we show to be highly beneficial for effective learning. On multiple datasets and DNN architectures, we demonstrate that DBLE outperforms alternative single-model confidence calibration approaches. DBLE also achieves comparable performance with computationally-expensive ensemble approaches with lower computational cost and lower number of parameters.", "keywords": ["Confidence Calibration", "Uncertainty Estimation", "Prototypical Learning"], "paperhash": "xing|distancebased_learning_from_errors_for_confidence_calibration", "code": "https://drive.google.com/open?id=1UThGvkkvFvKX8ogsfwvdA3uY8xzDlIuL", "_bibtex": "@inproceedings{\nXing2020Distance-Based,\ntitle={Distance-Based Learning from Errors for Confidence Calibration},\nauthor={Chen Xing and Sercan Arik and Zizhao Zhang and Tomas Pfister},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeB5hVtvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/d4d715434dfb3cf62f3df9859c7d67055aafea8e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJeB5hVtvB", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504213763, "tmdate": 1576860564514, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper113/Authors", "ICLR.cc/2020/Conference/Paper113/Reviewers", "ICLR.cc/2020/Conference/Paper113/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper113/-/Public_Comment"}}}, {"id": "BJeB5hVtvB", "original": "BkgWOT3RIH", "number": 113, "cdate": 1569438860537, "ddate": null, "tcdate": 1569438860537, "tmdate": 1583912054433, "tddate": null, "forum": "BJeB5hVtvB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["xingchen1113@gmail.com", "soarik@google.com", "zizhaoz@google.com", "tpfister@google.com"], "title": "Distance-Based Learning from Errors for Confidence Calibration", "authors": ["Chen Xing", "Sercan Arik", "Zizhao Zhang", "Tomas Pfister"], "pdf": "/pdf/13ce35a49cc94ffbde2635c1c7f0c1f2593d77e7.pdf", "abstract": "Deep neural networks (DNNs) are poorly calibrated when trained in conventional ways. To improve confidence calibration of DNNs, we propose a novel training method, distance-based learning from errors (DBLE). DBLE bases its confidence estimation on distances in the representation space. In DBLE, we first adapt prototypical learning to train classification models. It yields a representation space where the distance between a test sample and its ground truth class center can calibrate the model's classification performance. At inference, however, these distances are not available due to the lack of ground truth labels. To circumvent this by inferring the distance for every test sample, we propose to train a confidence model jointly with the classification model. We integrate this into training by merely learning from mis-classified training samples, which we show to be highly beneficial for effective learning. On multiple datasets and DNN architectures, we demonstrate that DBLE outperforms alternative single-model confidence calibration approaches. DBLE also achieves comparable performance with computationally-expensive ensemble approaches with lower computational cost and lower number of parameters.", "keywords": ["Confidence Calibration", "Uncertainty Estimation", "Prototypical Learning"], "paperhash": "xing|distancebased_learning_from_errors_for_confidence_calibration", "code": "https://drive.google.com/open?id=1UThGvkkvFvKX8ogsfwvdA3uY8xzDlIuL", "_bibtex": "@inproceedings{\nXing2020Distance-Based,\ntitle={Distance-Based Learning from Errors for Confidence Calibration},\nauthor={Chen Xing and Sercan Arik and Zizhao Zhang and Tomas Pfister},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeB5hVtvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/d4d715434dfb3cf62f3df9859c7d67055aafea8e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "C_JdAmsOuT", "original": null, "number": 1, "cdate": 1576798687757, "ddate": null, "tcdate": 1576798687757, "tmdate": 1576800947334, "tddate": null, "forum": "BJeB5hVtvB", "replyto": "BJeB5hVtvB", "invitation": "ICLR.cc/2020/Conference/Paper113/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "All reviewers voted to accept this paper.\nThe AC recommends acceptance.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["xingchen1113@gmail.com", "soarik@google.com", "zizhaoz@google.com", "tpfister@google.com"], "title": "Distance-Based Learning from Errors for Confidence Calibration", "authors": ["Chen Xing", "Sercan Arik", "Zizhao Zhang", "Tomas Pfister"], "pdf": "/pdf/13ce35a49cc94ffbde2635c1c7f0c1f2593d77e7.pdf", "abstract": "Deep neural networks (DNNs) are poorly calibrated when trained in conventional ways. To improve confidence calibration of DNNs, we propose a novel training method, distance-based learning from errors (DBLE). DBLE bases its confidence estimation on distances in the representation space. In DBLE, we first adapt prototypical learning to train classification models. It yields a representation space where the distance between a test sample and its ground truth class center can calibrate the model's classification performance. At inference, however, these distances are not available due to the lack of ground truth labels. To circumvent this by inferring the distance for every test sample, we propose to train a confidence model jointly with the classification model. We integrate this into training by merely learning from mis-classified training samples, which we show to be highly beneficial for effective learning. On multiple datasets and DNN architectures, we demonstrate that DBLE outperforms alternative single-model confidence calibration approaches. DBLE also achieves comparable performance with computationally-expensive ensemble approaches with lower computational cost and lower number of parameters.", "keywords": ["Confidence Calibration", "Uncertainty Estimation", "Prototypical Learning"], "paperhash": "xing|distancebased_learning_from_errors_for_confidence_calibration", "code": "https://drive.google.com/open?id=1UThGvkkvFvKX8ogsfwvdA3uY8xzDlIuL", "_bibtex": "@inproceedings{\nXing2020Distance-Based,\ntitle={Distance-Based Learning from Errors for Confidence Calibration},\nauthor={Chen Xing and Sercan Arik and Zizhao Zhang and Tomas Pfister},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeB5hVtvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/d4d715434dfb3cf62f3df9859c7d67055aafea8e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "BJeB5hVtvB", "replyto": "BJeB5hVtvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795712923, "tmdate": 1576800262416, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper113/-/Decision"}}}, {"id": "r1xCI1QosB", "original": null, "number": 1, "cdate": 1573756758422, "ddate": null, "tcdate": 1573756758422, "tmdate": 1573782052196, "tddate": null, "forum": "BJeB5hVtvB", "replyto": "rkgRPJHRYr", "invitation": "ICLR.cc/2020/Conference/Paper113/-/Official_Comment", "content": {"title": "Thanks for the comments!  Clarifications and additional results.", "comment": "Thank you for the constructive comments!  We address the two main concerns below.\n\n1. Why does DBLE use misclassified training samples instead of all training samples to train the confidence model?\n\nTo answer this question, we first describe our intuitions of training the confidence model with misclassified training samples, and then provide empirical results and statistics that verify the effectiveness of only using mis-classified training samples.\n\nThe goal of the confidence model is to capture $d_t$, a sample t\u2019s distance to its ground-truth label in the representation space (illustrated in Equation 7 in the paper), because $d_t$ of a test sample $x_t$ calibrates the model\u2019s performance on $x_t$ in DBLE (see Section 3). A straightforward way to train the confidence model to predict $d_t$ for every test sample would be to use all training samples and their corresponding $d_t$. However, for most deep learning applications, misclassified training samples can be quite rare in the last phase of training. Therefore, if we train the confidence model with all training samples, the correctly-classified samples and their small $d_t$ would dominate the training of the classification model. It may cause underfitting of the mis-classified samples and their large $d_t$. A consequence of this is that the estimation of $d_t$ of test samples would be biased to be small, which leads to overconfidence. Therefore, in DBLE we first initialize the confidence model to make the output $d_t$ for every sample small, and then train the confidence model to fit the large $d_t$ of mis-classified training samples.\n\nWe conducted experiments to test this intuition by comparing training the confidence model with only mis-classified samples to training the confidence model with all samples. In addition to the final results we report in the ablation study (the last two rows of Table 2), we also checked statistics of $\\sigma$, which is the standard deviation predicted by the confidence model, for the test set under the two training methods. For CIFAR-10, the mean of $\\sigma$ of the model trained with all samples is 0.203, while that of the model trained with misclassified training samples is 0.740. This suggests that if we train the confidence model with all training samples, the model outputs for test samples are indeed smaller in general, which is aligned with our intuition.\n\nWe agree with the reviewer that a discussion of this question along with the above empirical results would be good to include in the paper.  We have added the discussions above along with the histograms of $\\sigma$ in Appendix A.3.\n\n\n2. How will the proposed method perform when the classes are not well-defined or mixed?\n\nEven if the classes are mixed (e.g., there are two sub-classes under one class label), it is unlikely that there are two clusters under the same class label in the output space for prototypical learning. This is because for every episode the supports of each class are randomly selected, and the representations of the queries of the class are optimized to be close to the single prototype. Therefore the single Gaussian assumption we have for training the confidence model should still be effective even if there is structural information within the class. While we do agree with the reviewer that detecting unsupervised structural information in supervised data is a very interesting and influential research direction for future research, particularly to improve our method for the cases of well-defined or mixed classes.\n\n\nWe hope that we have fully addressed your questions. Please let us know if you have further comments. \n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper113/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper113/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["xingchen1113@gmail.com", "soarik@google.com", "zizhaoz@google.com", "tpfister@google.com"], "title": "Distance-Based Learning from Errors for Confidence Calibration", "authors": ["Chen Xing", "Sercan Arik", "Zizhao Zhang", "Tomas Pfister"], "pdf": "/pdf/13ce35a49cc94ffbde2635c1c7f0c1f2593d77e7.pdf", "abstract": "Deep neural networks (DNNs) are poorly calibrated when trained in conventional ways. To improve confidence calibration of DNNs, we propose a novel training method, distance-based learning from errors (DBLE). DBLE bases its confidence estimation on distances in the representation space. In DBLE, we first adapt prototypical learning to train classification models. It yields a representation space where the distance between a test sample and its ground truth class center can calibrate the model's classification performance. At inference, however, these distances are not available due to the lack of ground truth labels. To circumvent this by inferring the distance for every test sample, we propose to train a confidence model jointly with the classification model. We integrate this into training by merely learning from mis-classified training samples, which we show to be highly beneficial for effective learning. On multiple datasets and DNN architectures, we demonstrate that DBLE outperforms alternative single-model confidence calibration approaches. DBLE also achieves comparable performance with computationally-expensive ensemble approaches with lower computational cost and lower number of parameters.", "keywords": ["Confidence Calibration", "Uncertainty Estimation", "Prototypical Learning"], "paperhash": "xing|distancebased_learning_from_errors_for_confidence_calibration", "code": "https://drive.google.com/open?id=1UThGvkkvFvKX8ogsfwvdA3uY8xzDlIuL", "_bibtex": "@inproceedings{\nXing2020Distance-Based,\ntitle={Distance-Based Learning from Errors for Confidence Calibration},\nauthor={Chen Xing and Sercan Arik and Zizhao Zhang and Tomas Pfister},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeB5hVtvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/d4d715434dfb3cf62f3df9859c7d67055aafea8e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJeB5hVtvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper113/Authors", "ICLR.cc/2020/Conference/Paper113/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper113/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper113/Reviewers", "ICLR.cc/2020/Conference/Paper113/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper113/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper113/Authors|ICLR.cc/2020/Conference/Paper113/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504176215, "tmdate": 1576860530821, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper113/Authors", "ICLR.cc/2020/Conference/Paper113/Reviewers", "ICLR.cc/2020/Conference/Paper113/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper113/-/Official_Comment"}}}, {"id": "BJeoLeQojr", "original": null, "number": 3, "cdate": 1573757011017, "ddate": null, "tcdate": 1573757011017, "tmdate": 1573757011017, "tddate": null, "forum": "BJeB5hVtvB", "replyto": "r1llj41atS", "invitation": "ICLR.cc/2020/Conference/Paper113/-/Official_Comment", "content": {"title": "Thanks for the insightful discussions and valuable suggestions!", "comment": "Thank you for your thorough reading, insightful comments and valuable suggestions!  We will first address the minor comments and then the two main concerns.\n\nMinor comments:\n1. Thank you for the suggestions \u2013 indeed the \\mu and p could cause confusions. We have updated the notation system in the paper.\n2. We agree.  It also makes sense to avoid using the word \u2018training errors\u2019 which people usually use to refer to the measurement of the model\u2019s performance \u2013 we will replace.\n3. We will explain \\odot.\n\nConcerns:\n 1. Would the classification performance drop when dataset becomes bigger for prototypical learning? \n\nDatasets with larger number of classes present additional challenges, but it is possible to maintain the generalization performance. We note that the number of classes for CIFAR-100 is 10-fold higher than CIFAR-10, but in both cases DBLE classification performance is comparable to vanilla training. \n\nAmong the challenges for higher number of classes, the primary one is the increased compute and hyper-parameter tuning requirements. Hyper-parameter tuning matters when the data set gets bigger. We empirically find that for prototypical learning, larger number of classes within each episode can lead to better classification results. There may be practical limitations on the number of classes that can be sampled at each episode due to the memory limits of the processors, but it can be addressed by straightforward implementation approaches, such as separating each episode into sub-batches to process them in a certain sequential order.\n\nWe also note that compared with other distance-based losses such as triplet loss, training classification models with prototypical loss can be more robust to the size of the training set because it optimizes sample-prototype distance instead of sample-pair distances. We explain this in detail under the second question. \n\nIntegrating softmax loss together with other distance-based regularizations within our framework could also be an effective future exploration to address this concern. This is because the softmax loss is likely to guarantee the confidence performance without too much effort on hyper-parameter tuning and the distance-based regularization can encourage the effectiveness of $d_t$. We have conducted an experiment to explore this direction which we describe below.  \n\n2. Does the method work with prototypical networks only or does it generalize to other distance based methods as well (e.g. contrastive / triplet losses)?\n\nYes, by vanilla training we meant softmax + cross entropy loss \u2013 we have added clarifications of this in the paper.\n\nContrastive or triplet losses are distance-based losses, but we think that using them alone won\u2019t solve the problem we discussed under the first main concern. It is reported in multiple papers that models trained with contrastive and triplet losses struggle to reach comparable classification performance with vanilla training and are more complicated to train [1][2]. Moreover, since they optimize pairwise distances of samples, compared to prototypical loss they are also more difficult to optimize.  In contrast, prototypical loss optimizes the distance between query samples and class centers in which the class centers preserve more global information about the class compared to a random sample. This avoids optimizing samples to be overly close to outliers, which simplifies the training. \n\nAs a further analysis, we conducted an experiment in which we integrate softmax loss together with triplet loss as regularization. In this experiment, we train the classification model with vanilla training together with triplet loss, and for evaluation we use the distance metric described in Equation 5 and 6. We empirically observe that this gets the same classification performance (without the extra time complexity of episodic training) on CIFAR-10 and CIFAR-100. Moreover, since the classification decisions are still made based on the distances, d_t can still calibrate with the model performance. This proposed method gets NLL score 0.38 on CIFAR-10 and 1.29 on CIFAR-100, which are worse than DBLE (0.09 larger on CIFAR-10 and 0.2 larger on CIFAR-100) but better than vanilla training ( 0.05 smaller on CIFAR-10 and 0.29 smaller on CIFAR-100 ).  This demonstrates that the \u2018learning from errors\u2019 and the \u2018distance-based evaluation\u2019 components of DBLE can benefit vanilla training plus distance-based regularization methods, but the use of prototypical learning is still a better design choice.\n\n\nWe hope that we have fully addressed your questions. Please let us know if you have further comments. \n\n[1]Sohn, Kihyuk. \"Improved deep metric learning with multi-class n-pair loss objective.\" Advances in Neural Information Processing Systems. 2016.\n[2] Schroff, Florian, Dmitry Kalenichenko, and James Philbin. \"Facenet: A unified embedding for face recognition and clustering.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2015.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper113/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper113/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["xingchen1113@gmail.com", "soarik@google.com", "zizhaoz@google.com", "tpfister@google.com"], "title": "Distance-Based Learning from Errors for Confidence Calibration", "authors": ["Chen Xing", "Sercan Arik", "Zizhao Zhang", "Tomas Pfister"], "pdf": "/pdf/13ce35a49cc94ffbde2635c1c7f0c1f2593d77e7.pdf", "abstract": "Deep neural networks (DNNs) are poorly calibrated when trained in conventional ways. To improve confidence calibration of DNNs, we propose a novel training method, distance-based learning from errors (DBLE). DBLE bases its confidence estimation on distances in the representation space. In DBLE, we first adapt prototypical learning to train classification models. It yields a representation space where the distance between a test sample and its ground truth class center can calibrate the model's classification performance. At inference, however, these distances are not available due to the lack of ground truth labels. To circumvent this by inferring the distance for every test sample, we propose to train a confidence model jointly with the classification model. We integrate this into training by merely learning from mis-classified training samples, which we show to be highly beneficial for effective learning. On multiple datasets and DNN architectures, we demonstrate that DBLE outperforms alternative single-model confidence calibration approaches. DBLE also achieves comparable performance with computationally-expensive ensemble approaches with lower computational cost and lower number of parameters.", "keywords": ["Confidence Calibration", "Uncertainty Estimation", "Prototypical Learning"], "paperhash": "xing|distancebased_learning_from_errors_for_confidence_calibration", "code": "https://drive.google.com/open?id=1UThGvkkvFvKX8ogsfwvdA3uY8xzDlIuL", "_bibtex": "@inproceedings{\nXing2020Distance-Based,\ntitle={Distance-Based Learning from Errors for Confidence Calibration},\nauthor={Chen Xing and Sercan Arik and Zizhao Zhang and Tomas Pfister},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeB5hVtvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/d4d715434dfb3cf62f3df9859c7d67055aafea8e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJeB5hVtvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper113/Authors", "ICLR.cc/2020/Conference/Paper113/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper113/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper113/Reviewers", "ICLR.cc/2020/Conference/Paper113/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper113/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper113/Authors|ICLR.cc/2020/Conference/Paper113/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504176215, "tmdate": 1576860530821, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper113/Authors", "ICLR.cc/2020/Conference/Paper113/Reviewers", "ICLR.cc/2020/Conference/Paper113/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper113/-/Official_Comment"}}}, {"id": "B1eWo1XisH", "original": null, "number": 2, "cdate": 1573756824651, "ddate": null, "tcdate": 1573756824651, "tmdate": 1573756824651, "tddate": null, "forum": "BJeB5hVtvB", "replyto": "HkxX4zVCKB", "invitation": "ICLR.cc/2020/Conference/Paper113/-/Official_Comment", "content": {"title": "Thanks for the positive comments!", "comment": "We appreciate your positive comments that our work is valuable and well-placed contribution in the literature, and your insightful analysis of our paper.  Indeed, instead of making overambitious claims about statistical basis, we focus on improving the predicted confidence to calibrate the model\u2019s performance which can be more objectively evaluated. "}, "signatures": ["ICLR.cc/2020/Conference/Paper113/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper113/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["xingchen1113@gmail.com", "soarik@google.com", "zizhaoz@google.com", "tpfister@google.com"], "title": "Distance-Based Learning from Errors for Confidence Calibration", "authors": ["Chen Xing", "Sercan Arik", "Zizhao Zhang", "Tomas Pfister"], "pdf": "/pdf/13ce35a49cc94ffbde2635c1c7f0c1f2593d77e7.pdf", "abstract": "Deep neural networks (DNNs) are poorly calibrated when trained in conventional ways. To improve confidence calibration of DNNs, we propose a novel training method, distance-based learning from errors (DBLE). DBLE bases its confidence estimation on distances in the representation space. In DBLE, we first adapt prototypical learning to train classification models. It yields a representation space where the distance between a test sample and its ground truth class center can calibrate the model's classification performance. At inference, however, these distances are not available due to the lack of ground truth labels. To circumvent this by inferring the distance for every test sample, we propose to train a confidence model jointly with the classification model. We integrate this into training by merely learning from mis-classified training samples, which we show to be highly beneficial for effective learning. On multiple datasets and DNN architectures, we demonstrate that DBLE outperforms alternative single-model confidence calibration approaches. DBLE also achieves comparable performance with computationally-expensive ensemble approaches with lower computational cost and lower number of parameters.", "keywords": ["Confidence Calibration", "Uncertainty Estimation", "Prototypical Learning"], "paperhash": "xing|distancebased_learning_from_errors_for_confidence_calibration", "code": "https://drive.google.com/open?id=1UThGvkkvFvKX8ogsfwvdA3uY8xzDlIuL", "_bibtex": "@inproceedings{\nXing2020Distance-Based,\ntitle={Distance-Based Learning from Errors for Confidence Calibration},\nauthor={Chen Xing and Sercan Arik and Zizhao Zhang and Tomas Pfister},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeB5hVtvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/d4d715434dfb3cf62f3df9859c7d67055aafea8e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJeB5hVtvB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper113/Authors", "ICLR.cc/2020/Conference/Paper113/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper113/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper113/Reviewers", "ICLR.cc/2020/Conference/Paper113/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper113/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper113/Authors|ICLR.cc/2020/Conference/Paper113/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504176215, "tmdate": 1576860530821, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper113/Authors", "ICLR.cc/2020/Conference/Paper113/Reviewers", "ICLR.cc/2020/Conference/Paper113/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper113/-/Official_Comment"}}}, {"id": "r1llj41atS", "original": null, "number": 1, "cdate": 1571775639879, "ddate": null, "tcdate": 1571775639879, "tmdate": 1572972637147, "tddate": null, "forum": "BJeB5hVtvB", "replyto": "BJeB5hVtvB", "invitation": "ICLR.cc/2020/Conference/Paper113/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary:\nThe paper proposes a method to do confidence calibration for deep neural networks. It uses standard\nepisodic training for prototypical networks, and first shows empirically that the distances of the\nembedded test point to its ground truth class center embedding (*not* the predicted class embedding)\nare indicative of the confidence of the prediction. Further it proposes to exploit this by training\nan auxiliary confidence prediction MLP carefully. To do so they demonstrate that the training needs\nto be done of erroneously predicted training examples cf. all the traning examples. They show\nresults with MLP+MNIST, VGG11+CIFAR10, ResNet50+CIFAR100 and ResNet50+TinyImageNet.\n\n\nDetailed comments:\nThe paper is interesting but largely empirical. It shows empirically that:\n1. when prototypical networks (and episodic training) is used the distance of test example to true\nclass center reflects the confidence.\n2. this does not hold when `vanilla' training is used\n3. an auxiliary MLP can be used to learn to predict this while training only with erroneously \nclassified training examples cf. all training examples\n                                      \nThe results are reported on three networks (MLP, VGG11 and ResNet50) on different benchmarks of \nimage classification. The confidence prediction improvements wrt baselines are non trivial, while \nkeeping the accuracy similar, and the computation cost lower than competing methods. Ablations \nstudies are also convincing.                    \n            \nI would have two broad critical comments on the paper:\n1. Would this generalize to other image classification tasks and datasets. Generally distance\n(embedding) based networks perform less than softmax based networks on bigger datasets, so an\nimmediate disadvantage if that happens, is that you would be trading off accuracy cf. vanilla\nnetworks, for better confidence prediction using the required distance based network here.\n2. The vanilla training is never formally detailed. I am assuming it was softmax + cross entropy loss \nwith gradient descent. Would some other loss be helpful? Specially the metric learning based losses like \ncontrastive or triplet losses come to mind, since they are also distance based. Does the method work\nwith prototypical networks only or it generalizes to other distance based methods as well?\n                                                                                    \nMinor comments:\nThe notations are a bit confusing sometimes, and require going back and forth a bit. Eg. \\mu is used\nfor representation of feature (Eq4) while it usually denotes a mean of some sort (so the reader's expectation\ncould be that it represents class center). Similarly, boldface p is used for class centers, which is\nagain a bit confusing as being a probability of some sort. In general the notations are different\nfrom the original prototypical networks paper (which I needed to revise); keeping them similar would\nhelp the reader. The contribution of the present paper is more than that anyway.\n\nThe erroneously classified training examples are called errors (eg. just before eq8). By errors one\ncould think that it is a difference between some sort of prediction and the ground truth. Explicitly\ncalling them erroneously classified training examples would help the reader as well.\n\nThe notation \\odot is not explained (before eq.9).\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper113/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper113/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["xingchen1113@gmail.com", "soarik@google.com", "zizhaoz@google.com", "tpfister@google.com"], "title": "Distance-Based Learning from Errors for Confidence Calibration", "authors": ["Chen Xing", "Sercan Arik", "Zizhao Zhang", "Tomas Pfister"], "pdf": "/pdf/13ce35a49cc94ffbde2635c1c7f0c1f2593d77e7.pdf", "abstract": "Deep neural networks (DNNs) are poorly calibrated when trained in conventional ways. To improve confidence calibration of DNNs, we propose a novel training method, distance-based learning from errors (DBLE). DBLE bases its confidence estimation on distances in the representation space. In DBLE, we first adapt prototypical learning to train classification models. It yields a representation space where the distance between a test sample and its ground truth class center can calibrate the model's classification performance. At inference, however, these distances are not available due to the lack of ground truth labels. To circumvent this by inferring the distance for every test sample, we propose to train a confidence model jointly with the classification model. We integrate this into training by merely learning from mis-classified training samples, which we show to be highly beneficial for effective learning. On multiple datasets and DNN architectures, we demonstrate that DBLE outperforms alternative single-model confidence calibration approaches. DBLE also achieves comparable performance with computationally-expensive ensemble approaches with lower computational cost and lower number of parameters.", "keywords": ["Confidence Calibration", "Uncertainty Estimation", "Prototypical Learning"], "paperhash": "xing|distancebased_learning_from_errors_for_confidence_calibration", "code": "https://drive.google.com/open?id=1UThGvkkvFvKX8ogsfwvdA3uY8xzDlIuL", "_bibtex": "@inproceedings{\nXing2020Distance-Based,\ntitle={Distance-Based Learning from Errors for Confidence Calibration},\nauthor={Chen Xing and Sercan Arik and Zizhao Zhang and Tomas Pfister},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeB5hVtvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/d4d715434dfb3cf62f3df9859c7d67055aafea8e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJeB5hVtvB", "replyto": "BJeB5hVtvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper113/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper113/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575678419936, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper113/Reviewers"], "noninvitees": [], "tcdate": 1570237756882, "tmdate": 1575678419956, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper113/-/Official_Review"}}}, {"id": "HkxX4zVCKB", "original": null, "number": 2, "cdate": 1571861034712, "ddate": null, "tcdate": 1571861034712, "tmdate": 1572972637104, "tddate": null, "forum": "BJeB5hVtvB", "replyto": "BJeB5hVtvB", "invitation": "ICLR.cc/2020/Conference/Paper113/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The paper addresses the (long-standing) problem of classification systems being able to output reliable confidence estimates on its own output. The selected approach is to use the distance to (previously computed) class centers in multi-class classification to help compute the confidence interval. The method is shown to have comparable results on well known datasets but higher efficiency than 2 rival methods: ensemble ANNs and Bayesian neural networks. I would point out that such confidence intervals are all intuitive and have no statistical basis or other independent means of empirical validation. Experienced practitioners are aware of this, but I see that the paper steers wisely clear of overambitious claims. The general intuition of hybrid supervised and unsupervised learning for C.I. (or ellipse) estimation is not new, but an effective and compact representation of this intuition in a DNN context is a valuable contribution, well-placed in the literature - I recommend acceptance."}, "signatures": ["ICLR.cc/2020/Conference/Paper113/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper113/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["xingchen1113@gmail.com", "soarik@google.com", "zizhaoz@google.com", "tpfister@google.com"], "title": "Distance-Based Learning from Errors for Confidence Calibration", "authors": ["Chen Xing", "Sercan Arik", "Zizhao Zhang", "Tomas Pfister"], "pdf": "/pdf/13ce35a49cc94ffbde2635c1c7f0c1f2593d77e7.pdf", "abstract": "Deep neural networks (DNNs) are poorly calibrated when trained in conventional ways. To improve confidence calibration of DNNs, we propose a novel training method, distance-based learning from errors (DBLE). DBLE bases its confidence estimation on distances in the representation space. In DBLE, we first adapt prototypical learning to train classification models. It yields a representation space where the distance between a test sample and its ground truth class center can calibrate the model's classification performance. At inference, however, these distances are not available due to the lack of ground truth labels. To circumvent this by inferring the distance for every test sample, we propose to train a confidence model jointly with the classification model. We integrate this into training by merely learning from mis-classified training samples, which we show to be highly beneficial for effective learning. On multiple datasets and DNN architectures, we demonstrate that DBLE outperforms alternative single-model confidence calibration approaches. DBLE also achieves comparable performance with computationally-expensive ensemble approaches with lower computational cost and lower number of parameters.", "keywords": ["Confidence Calibration", "Uncertainty Estimation", "Prototypical Learning"], "paperhash": "xing|distancebased_learning_from_errors_for_confidence_calibration", "code": "https://drive.google.com/open?id=1UThGvkkvFvKX8ogsfwvdA3uY8xzDlIuL", "_bibtex": "@inproceedings{\nXing2020Distance-Based,\ntitle={Distance-Based Learning from Errors for Confidence Calibration},\nauthor={Chen Xing and Sercan Arik and Zizhao Zhang and Tomas Pfister},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeB5hVtvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/d4d715434dfb3cf62f3df9859c7d67055aafea8e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJeB5hVtvB", "replyto": "BJeB5hVtvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper113/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper113/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575678419936, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper113/Reviewers"], "noninvitees": [], "tcdate": 1570237756882, "tmdate": 1575678419956, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper113/-/Official_Review"}}}, {"id": "rkgRPJHRYr", "original": null, "number": 3, "cdate": 1571864421837, "ddate": null, "tcdate": 1571864421837, "tmdate": 1572972637057, "tddate": null, "forum": "BJeB5hVtvB", "replyto": "BJeB5hVtvB", "invitation": "ICLR.cc/2020/Conference/Paper113/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper describes an approach to improve the confidence on deep\nneural networks (DNN). The proposed approach uses a distance-based\napproach (distance to prototypes) and train using a confidence\nmodel with the classification model using mis-classified examples.\n\nIt first learns using a loss function based on pre-computed centroids\nof each class evaluated from the training examples. At inference it\nassigns the class with the closest center.\n\nTo estimate a confidence level, it learns a new model to estimate the\ndistance using only the misclassified examples.\n\nThe authors experimentally showed the benefits of the proposed approach\nover several methods.\n\nFinding prototypes and training with distances, on one hand, and\nevaluating confidence with Gaussian, on the other, assumes\nthat the classes are \"well defined\". Although the authors show\npromising results, it is not clear how well the proposed method will\nbehave in more challenging classification tasks where the classes are\nmixed.\n\nAlthough the authors show that estimating the confidence with\nmisclassified examples works better I will like to see a further\nanalysis in the paper.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper113/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper113/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["xingchen1113@gmail.com", "soarik@google.com", "zizhaoz@google.com", "tpfister@google.com"], "title": "Distance-Based Learning from Errors for Confidence Calibration", "authors": ["Chen Xing", "Sercan Arik", "Zizhao Zhang", "Tomas Pfister"], "pdf": "/pdf/13ce35a49cc94ffbde2635c1c7f0c1f2593d77e7.pdf", "abstract": "Deep neural networks (DNNs) are poorly calibrated when trained in conventional ways. To improve confidence calibration of DNNs, we propose a novel training method, distance-based learning from errors (DBLE). DBLE bases its confidence estimation on distances in the representation space. In DBLE, we first adapt prototypical learning to train classification models. It yields a representation space where the distance between a test sample and its ground truth class center can calibrate the model's classification performance. At inference, however, these distances are not available due to the lack of ground truth labels. To circumvent this by inferring the distance for every test sample, we propose to train a confidence model jointly with the classification model. We integrate this into training by merely learning from mis-classified training samples, which we show to be highly beneficial for effective learning. On multiple datasets and DNN architectures, we demonstrate that DBLE outperforms alternative single-model confidence calibration approaches. DBLE also achieves comparable performance with computationally-expensive ensemble approaches with lower computational cost and lower number of parameters.", "keywords": ["Confidence Calibration", "Uncertainty Estimation", "Prototypical Learning"], "paperhash": "xing|distancebased_learning_from_errors_for_confidence_calibration", "code": "https://drive.google.com/open?id=1UThGvkkvFvKX8ogsfwvdA3uY8xzDlIuL", "_bibtex": "@inproceedings{\nXing2020Distance-Based,\ntitle={Distance-Based Learning from Errors for Confidence Calibration},\nauthor={Chen Xing and Sercan Arik and Zizhao Zhang and Tomas Pfister},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeB5hVtvB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/d4d715434dfb3cf62f3df9859c7d67055aafea8e.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJeB5hVtvB", "replyto": "BJeB5hVtvB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper113/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper113/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575678419936, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper113/Reviewers"], "noninvitees": [], "tcdate": 1570237756882, "tmdate": 1575678419956, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper113/-/Official_Review"}}}], "count": 11}