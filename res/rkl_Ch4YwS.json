{"notes": [{"id": "rkl_Ch4YwS", "original": "rJeXnOgrDr", "number": 270, "cdate": 1569438928074, "ddate": null, "tcdate": 1569438928074, "tmdate": 1577168219337, "tddate": null, "forum": "rkl_Ch4YwS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"abstract": "\nAlthough mathematical expressions (MEs) recognition have achieved great progress, the development of MEs recognition in real scenes is still unsatisfactory. Inspired by the recent work of neutral network, this paper proposes a novel two-stage approach which takes a printed mathematical expression image as input and generates LaTeX sequence as output. In the first stage, this method locates and recognizes the math symbols of input image by object detection algorithm. In the second stage, it translates math symbols with position information into LaTeX sequences by seq2seq model equipped with attention mechanism. In particular, the detection of mathematical symbols and the structural analysis of mathematical formulas are carried out separately in two steps, which effectively improves the recognition accuracy and enhances the generalization ability. The experiment demonstrates that the two-stage method significantly outperforms the end-to-end method. Especially, the ExpRate(expression recognition rate) of our model is 74.1%, 20.3 percentage points higher than that of the end-to-end model on the test data that doesn\u2019t come from the same source as training data.", "title": "A TWO-STAGE FRAMEWORK FOR MATHEMATICAL EXPRESSION RECOGNITION", "keywords": ["mathematical expressions recognition", "seq2seq model"], "pdf": "/pdf/8a1e695c26e4c8c463d8744b2f68ae427c0dffa1.pdf", "authors": ["Jin Zhang", "Weipeng Ming", "Pengfei Liu"], "authorids": ["zhangjin9@100tal.com", "mingweipeng@100tal.com", "liupengfei1@100tal.com"], "paperhash": "zhang|a_twostage_framework_for_mathematical_expression_recognition", "original_pdf": "/attachment/8a1e695c26e4c8c463d8744b2f68ae427c0dffa1.pdf", "_bibtex": "@misc{\nzhang2020a,\ntitle={A {\\{}TWO{\\}}-{\\{}STAGE{\\}} {\\{}FRAMEWORK{\\}} {\\{}FOR{\\}} {\\{}MATHEMATICAL{\\}} {\\{}EXPRESSION{\\}} {\\{}RECOGNITION{\\}}},\nauthor={Jin Zhang and Weipeng Ming and Pengfei Liu},\nyear={2020},\nurl={https://openreview.net/forum?id=rkl_Ch4YwS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "h3JRl_YLaO", "original": null, "number": 1, "cdate": 1576798691928, "ddate": null, "tcdate": 1576798691928, "tmdate": 1576800943395, "tddate": null, "forum": "rkl_Ch4YwS", "replyto": "rkl_Ch4YwS", "invitation": "ICLR.cc/2020/Conference/Paper270/-/Decision", "content": {"decision": "Reject", "comment": "One reviewer is positive, while the others recommend rejection. The authors did not submit a rebuttal, thus the reviewers kept their original assessment.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "\nAlthough mathematical expressions (MEs) recognition have achieved great progress, the development of MEs recognition in real scenes is still unsatisfactory. Inspired by the recent work of neutral network, this paper proposes a novel two-stage approach which takes a printed mathematical expression image as input and generates LaTeX sequence as output. In the first stage, this method locates and recognizes the math symbols of input image by object detection algorithm. In the second stage, it translates math symbols with position information into LaTeX sequences by seq2seq model equipped with attention mechanism. In particular, the detection of mathematical symbols and the structural analysis of mathematical formulas are carried out separately in two steps, which effectively improves the recognition accuracy and enhances the generalization ability. The experiment demonstrates that the two-stage method significantly outperforms the end-to-end method. Especially, the ExpRate(expression recognition rate) of our model is 74.1%, 20.3 percentage points higher than that of the end-to-end model on the test data that doesn\u2019t come from the same source as training data.", "title": "A TWO-STAGE FRAMEWORK FOR MATHEMATICAL EXPRESSION RECOGNITION", "keywords": ["mathematical expressions recognition", "seq2seq model"], "pdf": "/pdf/8a1e695c26e4c8c463d8744b2f68ae427c0dffa1.pdf", "authors": ["Jin Zhang", "Weipeng Ming", "Pengfei Liu"], "authorids": ["zhangjin9@100tal.com", "mingweipeng@100tal.com", "liupengfei1@100tal.com"], "paperhash": "zhang|a_twostage_framework_for_mathematical_expression_recognition", "original_pdf": "/attachment/8a1e695c26e4c8c463d8744b2f68ae427c0dffa1.pdf", "_bibtex": "@misc{\nzhang2020a,\ntitle={A {\\{}TWO{\\}}-{\\{}STAGE{\\}} {\\{}FRAMEWORK{\\}} {\\{}FOR{\\}} {\\{}MATHEMATICAL{\\}} {\\{}EXPRESSION{\\}} {\\{}RECOGNITION{\\}}},\nauthor={Jin Zhang and Weipeng Ming and Pengfei Liu},\nyear={2020},\nurl={https://openreview.net/forum?id=rkl_Ch4YwS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "rkl_Ch4YwS", "replyto": "rkl_Ch4YwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795729960, "tmdate": 1576800282658, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper270/-/Decision"}}}, {"id": "Syle2m0aKH", "original": null, "number": 1, "cdate": 1571836839943, "ddate": null, "tcdate": 1571836839943, "tmdate": 1572972617083, "tddate": null, "forum": "rkl_Ch4YwS", "replyto": "rkl_Ch4YwS", "invitation": "ICLR.cc/2020/Conference/Paper270/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper considers the problem of converting an image of a math expression into LaTeX.  They note that while the model proposed in Deng et al works well on the IM2LATEX-100K dataset, is doesn't generalize well to equations in real-world settings that you'd have in a photograph or a scan of an equation.  They propose an approach that breaks the problem into two steps.  In the first step they detect all the characters in the image, identifying the  character type and bounding box for each.  In the second step they use an encoder/decoder (LSTM/LSTM with attention) model to translate this sequence of character encodings into a LaTeX sequence.  They create a new dataset of LaTeX equations rendered on backgrounds sampled from real photographs of books and papers.  They split this into a training and \"homologous\" test set.   They find performance of their two stage model is a bit better than Deng's model on this test set.  They then create a \"non-homologous\" test set, in which the test equations are rendered on a new set of backgrounds, unseen in training.  On this test set, the model in the paper performs essentially the same as on the homologous dataset, while the Deng model performs substantially worse.  The conclusion is that the two stage approach creates a model that is much more robust to the appearance of the equation.\n\nI think the main takeaway from this paper is that there can be disadvantages to an end-to-end approach.  To achieve their improvement, authors used their insight that there is an intermediate representation that summarizes all relevant information (the sequence of characters and positions), together with the ability to generate a new training set automatically to learn this intermediate representation.\n\nI think this is an interesting case study in applied machine learning, but I don't think it will be of enough general use or interest to the ICLR community to merit acceptance.\n\nAs an applications paper, I think there are several aspects that can be improved.  Here are some specific questions and comments that may help a further iteration of this paper:\n- You have examples of ME images from the real world, but you don't have any examples of your artificial \"real world\" equations, overlayed on your sampled backgrounds.  Those would be helpful. Are any other modifications done to the equation to simulate a real-life picture or scan, such as color or darkness distortions, angles, etc?\n- How does your proposed model perform on the original IM2LATEX-100K problem?\n- How well does the encoder-decoder model do an a gold encoding of the input?  It would be nice to separate the errors into translation errors vs object detection errors.\n- Can you give examples of scenarios where your model got things right and Deng's model did not, and vice versa?  Is there any interpretation to why each model does better or worse for various example?  I imagine the model may have more difficulty with equations where one needs to refer to characters that are on the left of the image quite late in the LaTeX expression.  For example, fractions with long numerator expressions and and cases environments.\n- Did you try or consider using a soft encoding of the character identity, instead of a one-hot?  Perhaps there are context clues that the encoder/decoder model could use to disambiguate between a 1 and an l, for example.  \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper270/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper270/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "\nAlthough mathematical expressions (MEs) recognition have achieved great progress, the development of MEs recognition in real scenes is still unsatisfactory. Inspired by the recent work of neutral network, this paper proposes a novel two-stage approach which takes a printed mathematical expression image as input and generates LaTeX sequence as output. In the first stage, this method locates and recognizes the math symbols of input image by object detection algorithm. In the second stage, it translates math symbols with position information into LaTeX sequences by seq2seq model equipped with attention mechanism. In particular, the detection of mathematical symbols and the structural analysis of mathematical formulas are carried out separately in two steps, which effectively improves the recognition accuracy and enhances the generalization ability. The experiment demonstrates that the two-stage method significantly outperforms the end-to-end method. Especially, the ExpRate(expression recognition rate) of our model is 74.1%, 20.3 percentage points higher than that of the end-to-end model on the test data that doesn\u2019t come from the same source as training data.", "title": "A TWO-STAGE FRAMEWORK FOR MATHEMATICAL EXPRESSION RECOGNITION", "keywords": ["mathematical expressions recognition", "seq2seq model"], "pdf": "/pdf/8a1e695c26e4c8c463d8744b2f68ae427c0dffa1.pdf", "authors": ["Jin Zhang", "Weipeng Ming", "Pengfei Liu"], "authorids": ["zhangjin9@100tal.com", "mingweipeng@100tal.com", "liupengfei1@100tal.com"], "paperhash": "zhang|a_twostage_framework_for_mathematical_expression_recognition", "original_pdf": "/attachment/8a1e695c26e4c8c463d8744b2f68ae427c0dffa1.pdf", "_bibtex": "@misc{\nzhang2020a,\ntitle={A {\\{}TWO{\\}}-{\\{}STAGE{\\}} {\\{}FRAMEWORK{\\}} {\\{}FOR{\\}} {\\{}MATHEMATICAL{\\}} {\\{}EXPRESSION{\\}} {\\{}RECOGNITION{\\}}},\nauthor={Jin Zhang and Weipeng Ming and Pengfei Liu},\nyear={2020},\nurl={https://openreview.net/forum?id=rkl_Ch4YwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkl_Ch4YwS", "replyto": "rkl_Ch4YwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper270/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper270/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575384676044, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper270/Reviewers"], "noninvitees": [], "tcdate": 1570237754572, "tmdate": 1575384676058, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper270/-/Official_Review"}}}, {"id": "BJlB2ry9cB", "original": null, "number": 2, "cdate": 1572627885105, "ddate": null, "tcdate": 1572627885105, "tmdate": 1572972617038, "tddate": null, "forum": "rkl_Ch4YwS", "replyto": "rkl_Ch4YwS", "invitation": "ICLR.cc/2020/Conference/Paper270/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "In this paper the authors propose a two stage pipeline that aims to solve for mathematical expression recognition. The main approach uses the following stages, a detection stage that is based on YoloV3 and a sequence to sequence approach. The authors compare their method against Image2Latex approach (2016) that is an end to end pipeline and show that there is significant improvement compared to this approach. \n\nHowever, this problem has been a standard task and solved both in the handwritten math expression problem (CROHME challenge of ICDAR and typeset formula detection and recognition. There have been much progress through these challenges with various teams competing. A variety of approaches have been tried for this task and unfortunately the present work has not compared nor evaluated against these approaches. \n\nIm2Latex work is quite old benchmark and there have been numerous works as have been cited by the authors and more as can be available from the challenge. The methods presented are also not novel. Using Yolov3 for detection and sequence2sequence for parsing expressions are more or less standard approaches. Hence, the proposed work does not add a significant insight in solving the problem. "}, "signatures": ["ICLR.cc/2020/Conference/Paper270/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper270/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "\nAlthough mathematical expressions (MEs) recognition have achieved great progress, the development of MEs recognition in real scenes is still unsatisfactory. Inspired by the recent work of neutral network, this paper proposes a novel two-stage approach which takes a printed mathematical expression image as input and generates LaTeX sequence as output. In the first stage, this method locates and recognizes the math symbols of input image by object detection algorithm. In the second stage, it translates math symbols with position information into LaTeX sequences by seq2seq model equipped with attention mechanism. In particular, the detection of mathematical symbols and the structural analysis of mathematical formulas are carried out separately in two steps, which effectively improves the recognition accuracy and enhances the generalization ability. The experiment demonstrates that the two-stage method significantly outperforms the end-to-end method. Especially, the ExpRate(expression recognition rate) of our model is 74.1%, 20.3 percentage points higher than that of the end-to-end model on the test data that doesn\u2019t come from the same source as training data.", "title": "A TWO-STAGE FRAMEWORK FOR MATHEMATICAL EXPRESSION RECOGNITION", "keywords": ["mathematical expressions recognition", "seq2seq model"], "pdf": "/pdf/8a1e695c26e4c8c463d8744b2f68ae427c0dffa1.pdf", "authors": ["Jin Zhang", "Weipeng Ming", "Pengfei Liu"], "authorids": ["zhangjin9@100tal.com", "mingweipeng@100tal.com", "liupengfei1@100tal.com"], "paperhash": "zhang|a_twostage_framework_for_mathematical_expression_recognition", "original_pdf": "/attachment/8a1e695c26e4c8c463d8744b2f68ae427c0dffa1.pdf", "_bibtex": "@misc{\nzhang2020a,\ntitle={A {\\{}TWO{\\}}-{\\{}STAGE{\\}} {\\{}FRAMEWORK{\\}} {\\{}FOR{\\}} {\\{}MATHEMATICAL{\\}} {\\{}EXPRESSION{\\}} {\\{}RECOGNITION{\\}}},\nauthor={Jin Zhang and Weipeng Ming and Pengfei Liu},\nyear={2020},\nurl={https://openreview.net/forum?id=rkl_Ch4YwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkl_Ch4YwS", "replyto": "rkl_Ch4YwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper270/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper270/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575384676044, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper270/Reviewers"], "noninvitees": [], "tcdate": 1570237754572, "tmdate": 1575384676058, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper270/-/Official_Review"}}}, {"id": "r1lT36Q5cS", "original": null, "number": 3, "cdate": 1572646325508, "ddate": null, "tcdate": 1572646325508, "tmdate": 1572972616993, "tddate": null, "forum": "rkl_Ch4YwS", "replyto": "rkl_Ch4YwS", "invitation": "ICLR.cc/2020/Conference/Paper270/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper proposes to recognise a mathmatical expression using a two-stage framework, including object detection by YOLOv3, and encoder-decoder based translation. The paper is written well, and easy to read. In the experiments, the recognition and translation methods both work well on Homologous and non-Homologous test data. In particular, the proposed method improved the performance over the state-of-the-art method Im2LaTex. Addtionally, the authors visualised the sample alignments of encoder-decoder model, which is helpful for understanding the method.\n\nA few comments are as follow:\n1) On Page 1, the first and second paragraphs both contain \"symbol segmentation, symbol recognition and structural analysis\". It looks this framework is repeated again and again.\n2) In formula (4), the reviewer did not see the explanation of \"v_{att}^T\" and \"u_T\".\n3) Some references have only authors and title information, without conference/journal information.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper270/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper270/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "\nAlthough mathematical expressions (MEs) recognition have achieved great progress, the development of MEs recognition in real scenes is still unsatisfactory. Inspired by the recent work of neutral network, this paper proposes a novel two-stage approach which takes a printed mathematical expression image as input and generates LaTeX sequence as output. In the first stage, this method locates and recognizes the math symbols of input image by object detection algorithm. In the second stage, it translates math symbols with position information into LaTeX sequences by seq2seq model equipped with attention mechanism. In particular, the detection of mathematical symbols and the structural analysis of mathematical formulas are carried out separately in two steps, which effectively improves the recognition accuracy and enhances the generalization ability. The experiment demonstrates that the two-stage method significantly outperforms the end-to-end method. Especially, the ExpRate(expression recognition rate) of our model is 74.1%, 20.3 percentage points higher than that of the end-to-end model on the test data that doesn\u2019t come from the same source as training data.", "title": "A TWO-STAGE FRAMEWORK FOR MATHEMATICAL EXPRESSION RECOGNITION", "keywords": ["mathematical expressions recognition", "seq2seq model"], "pdf": "/pdf/8a1e695c26e4c8c463d8744b2f68ae427c0dffa1.pdf", "authors": ["Jin Zhang", "Weipeng Ming", "Pengfei Liu"], "authorids": ["zhangjin9@100tal.com", "mingweipeng@100tal.com", "liupengfei1@100tal.com"], "paperhash": "zhang|a_twostage_framework_for_mathematical_expression_recognition", "original_pdf": "/attachment/8a1e695c26e4c8c463d8744b2f68ae427c0dffa1.pdf", "_bibtex": "@misc{\nzhang2020a,\ntitle={A {\\{}TWO{\\}}-{\\{}STAGE{\\}} {\\{}FRAMEWORK{\\}} {\\{}FOR{\\}} {\\{}MATHEMATICAL{\\}} {\\{}EXPRESSION{\\}} {\\{}RECOGNITION{\\}}},\nauthor={Jin Zhang and Weipeng Ming and Pengfei Liu},\nyear={2020},\nurl={https://openreview.net/forum?id=rkl_Ch4YwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkl_Ch4YwS", "replyto": "rkl_Ch4YwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper270/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper270/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575384676044, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper270/Reviewers"], "noninvitees": [], "tcdate": 1570237754572, "tmdate": 1575384676058, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper270/-/Official_Review"}}}], "count": 5}