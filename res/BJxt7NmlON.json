{"notes": [{"id": "BJxt7NmlON", "original": "SJl9yv8KwV", "number": 26, "cdate": 1553114144826, "ddate": null, "tcdate": 1553114144826, "tmdate": 1562082105913, "tddate": null, "forum": "BJxt7NmlON", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "Disentangled Representation Learning with Information Maximizing Autoencoder", "authors": ["Kazi Nazmul Haque", "Siddique Latif", "Rajib Rana"], "authorids": ["shezan.huq@gmail.com", "siddique.latif@usq.edu.au", "rajib.rana@usq.edu.au"], "keywords": ["Disentangled Representation Learning", "Data Augmentation", "Generative Adversarial Nets", "Unsupervised Learning"], "TL;DR": "Learn disentangle representation in an unsupervised manner.", "abstract": "Learning disentangled representation from any unlabelled data is a non-trivial problem. In this paper we propose Information Maximising Autoencoder (InfoAE) where the encoder learns powerful disentangled representation through maximizing the mutual information between the representation and given information in an unsupervised fashion. We have evaluated our model on MNIST dataset and achieved approximately 98.9 % test accuracy while using complete unsupervised training.", "pdf": "/pdf/6dace85bba82fd8f9c6a41e6caa746f315308dad.pdf", "paperhash": "haque|disentangled_representation_learning_with_information_maximizing_autoencoder"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "OpenReview.net"}, {"id": "SygmXDIftV", "original": null, "number": 1, "cdate": 1554306843001, "ddate": null, "tcdate": 1554306843001, "tmdate": 1555512027876, "tddate": null, "forum": "BJxt7NmlON", "replyto": "BJxt7NmlON", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper26/Official_Review", "content": {"title": "Nice contribution, Some clarifications on the main claim and terminology are needed", "review": "The authors present a framework in which an auto encoder (E, D) is regularized such that its latent representation to share mutual information with a generated latent space representation. This generated latent representation is an output of a generator network (G) that produces its latent variables based on a given random noise variable (z) plus a categorical input (c). The mutual information is maximized using another network (C, classifier network) that tries to map generated latent representations  to the categorical input (c) of the generator network. Moreover two discriminator networks (S, D_i) are used to ensure that the generated images come from the same distribution as the data.\n\nTo the best of my understanding the presented scheme performs, in an unsupervised manner, a clustering to a pre-defined number of clusters, that are defined by the one hot encoding categorical (c) input of G, while at the same time G disentangles the inter-cluster variability to the random noise variable (z).\n\nThe language of the text is clear and the methodology is described in details. I have however a few comments concerning the presentation of the main claim.\n\n1. According to the description of the proposed scheme, I find it difficult to understand how a disentangled representation is learned by the encoder (z_e). I understand that it is possible to generate a latent representation using the G network with c and z as inputs, yet this does not prove that the generated representation z_g (~z_e) are also disentangled.\n\n2. Unfortunately the experimental setup does also not support the disentanglement claim in the auto-encoder representation space. An experiment on how the generated image looks when interpolating samples within the auto-encoder representation would be more insightful.\n\n", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper26/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper26/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Disentangled Representation Learning with Information Maximizing Autoencoder", "authors": ["Kazi Nazmul Haque", "Siddique Latif", "Rajib Rana"], "authorids": ["shezan.huq@gmail.com", "siddique.latif@usq.edu.au", "rajib.rana@usq.edu.au"], "keywords": ["Disentangled Representation Learning", "Data Augmentation", "Generative Adversarial Nets", "Unsupervised Learning"], "TL;DR": "Learn disentangle representation in an unsupervised manner.", "abstract": "Learning disentangled representation from any unlabelled data is a non-trivial problem. In this paper we propose Information Maximising Autoencoder (InfoAE) where the encoder learns powerful disentangled representation through maximizing the mutual information between the representation and given information in an unsupervised fashion. We have evaluated our model on MNIST dataset and achieved approximately 98.9 % test accuracy while using complete unsupervised training.", "pdf": "/pdf/6dace85bba82fd8f9c6a41e6caa746f315308dad.pdf", "paperhash": "haque|disentangled_representation_learning_with_information_maximizing_autoencoder"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper26/Official_Review", "cdate": 1553713417877, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "BJxt7NmlON", "replyto": "BJxt7NmlON", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper26/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper26/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713417877, "tmdate": 1555511815620, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper26/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "H1gXWc7VFN", "original": null, "number": 2, "cdate": 1554426363026, "ddate": null, "tcdate": 1554426363026, "tmdate": 1555512027439, "tddate": null, "forum": "BJxt7NmlON", "replyto": "BJxt7NmlON", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper26/Official_Review", "content": {"title": "Review: Disentangled Representation Learning with Information Maximizing Autoencoder", "review": "The introduction lacks some exposition/definition of \"disentanglement\" in the context of representations. Why are disentangled representations good?\n\nPlease remove the nested parentheses within the citations within parentheses (or change the citation style to one that doesn't have nested parentheses).\n\nFigure 1 is a difficult to read. It would be easier if each component/input/output were labeled with the name of the component, rather than the variable. It also isn't clear from the figure which variables exist in the \"latent variable space\" (embedding?).\n\nThe notation p(x) almost always denotes a probability (i.e. a real value between 0 and 1) and so the notation x \\in p(x) is somewhat confusing, since I assume x is meant to be an event in the probability space whose probability (function/density) is given by p(x).\n\nMinor: In the variables with hats, the hats are off-center. To avoid this, use \\hat{x}_r instead of \\hat{x_r}.\n\nIt is also unclear what the relationship is between p(x), p(z), u(z), and q(z). Do p(x) and p(z) refer to the same distribution? This makes it very difficult for the reader to understand your approach.\n\nIs the discriminator D_i indexed by i? Or is there only one discriminator? If there is only one discriminator, do not use subscript i as the variable name, since subcript i is almost always used as an index.\n\nThere is very little to motivate your architecture. Why have a self-critic?\n\nWhat is V in equation 2? Same comment as above on the variable names in the loss expressions: it is easy to confuse l in S_l (among others) as an index.\n\nHow do you perform classification if you train on completely unlabeled data? The alternate methods you cite perform semi-supervised training.\n\nGrammatical errors detract from the reader's ability to easily understand the content. For example, many nouns are missing determiners (e.g. should be \"representations\" or \"a/the representation\", \"the G network\", etc), and/or they should be plural (e.g. \"adversarial autoencoders\"). There are also some spelling errors (e.g. \"training\").\n\nMinor: \"Mutual information\" need not be capitalized. Same with \"convolutional neural network\", \"batch normalization\", etc.\n\nThe bibliography items are inconsistently formatted.\n", "rating": "1: Strong rejection", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper26/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper26/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Disentangled Representation Learning with Information Maximizing Autoencoder", "authors": ["Kazi Nazmul Haque", "Siddique Latif", "Rajib Rana"], "authorids": ["shezan.huq@gmail.com", "siddique.latif@usq.edu.au", "rajib.rana@usq.edu.au"], "keywords": ["Disentangled Representation Learning", "Data Augmentation", "Generative Adversarial Nets", "Unsupervised Learning"], "TL;DR": "Learn disentangle representation in an unsupervised manner.", "abstract": "Learning disentangled representation from any unlabelled data is a non-trivial problem. In this paper we propose Information Maximising Autoencoder (InfoAE) where the encoder learns powerful disentangled representation through maximizing the mutual information between the representation and given information in an unsupervised fashion. We have evaluated our model on MNIST dataset and achieved approximately 98.9 % test accuracy while using complete unsupervised training.", "pdf": "/pdf/6dace85bba82fd8f9c6a41e6caa746f315308dad.pdf", "paperhash": "haque|disentangled_representation_learning_with_information_maximizing_autoencoder"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper26/Official_Review", "cdate": 1553713417877, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "BJxt7NmlON", "replyto": "BJxt7NmlON", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper26/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper26/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713417877, "tmdate": 1555511815620, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper26/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "SklqYIhzc4", "original": null, "number": 1, "cdate": 1555379841658, "ddate": null, "tcdate": 1555379841658, "tmdate": 1555510981252, "tddate": null, "forum": "BJxt7NmlON", "replyto": "BJxt7NmlON", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper26/Decision", "content": {"title": "Acceptance Decision", "decision": "Reject", "comment": "The reviewers found a number of issues in clarity and were not fully convinced of the experiments"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Disentangled Representation Learning with Information Maximizing Autoencoder", "authors": ["Kazi Nazmul Haque", "Siddique Latif", "Rajib Rana"], "authorids": ["shezan.huq@gmail.com", "siddique.latif@usq.edu.au", "rajib.rana@usq.edu.au"], "keywords": ["Disentangled Representation Learning", "Data Augmentation", "Generative Adversarial Nets", "Unsupervised Learning"], "TL;DR": "Learn disentangle representation in an unsupervised manner.", "abstract": "Learning disentangled representation from any unlabelled data is a non-trivial problem. In this paper we propose Information Maximising Autoencoder (InfoAE) where the encoder learns powerful disentangled representation through maximizing the mutual information between the representation and given information in an unsupervised fashion. We have evaluated our model on MNIST dataset and achieved approximately 98.9 % test accuracy while using complete unsupervised training.", "pdf": "/pdf/6dace85bba82fd8f9c6a41e6caa746f315308dad.pdf", "paperhash": "haque|disentangled_representation_learning_with_information_maximizing_autoencoder"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper26/Decision", "cdate": 1554736066824, "reply": {"forum": "BJxt7NmlON", "replyto": "BJxt7NmlON", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736066824, "tmdate": 1555510971851, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 4}