{"notes": [{"tddate": null, "ddate": null, "tmdate": 1518730185051, "tcdate": 1509067016720, "number": 218, "cdate": 1518730185039, "id": "rkZzY-lCb", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "rkZzY-lCb", "original": "ByxMYbx0W", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features", "abstract": "Methods that calculate dense vector representations for features in unstructured data\u2014such as words in a document\u2014have proven to be very successful for knowledge representation. We study how to estimate dense representations when multiple feature types exist within a dataset for supervised learning where explicit labels are available, as well as for unsupervised learning where there are no labels. Feat2Vec calculates embeddings for data with multiple feature types enforcing that all different feature types exist in a common space. In the supervised case, we show that our method has advantages over recently proposed methods; such as enabling higher prediction accuracy, and providing a way to avoid the cold-start\nproblem. In the unsupervised case, our experiments suggest that Feat2Vec significantly outperforms existing algorithms that do not leverage the structure of the data. We believe that we are the first to propose a method for learning unsuper vised embeddings that leverage the structure of multiple feature types.", "pdf": "/pdf/cfbe2eeef1804fb287b88b26ea994b8c1614c57a.pdf", "TL;DR": "Learn dense vector representations of arbitrary types of features in labeled and unlabeled datasets", "paperhash": "armona|feat2vec_dense_vector_representation_for_data_with_arbitrary_features", "_bibtex": "@misc{\narmona2018featvec,\ntitle={Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features},\nauthor={Luis Armona and Jos\u00e9 P. Gonz\u00e1lez-Brenes and Ralph Edezhath},\nyear={2018},\nurl={https://openreview.net/forum?id=rkZzY-lCb},\n}", "keywords": ["unsupervised learning", "supervised learning", "knowledge representation", "deep learning"], "authors": ["Luis Armona", "Jos\u00e9 P. Gonz\u00e1lez-Brenes", "Ralph Edezhath"], "authorids": ["luisarmona@gmail.com", "jgonzalez@chegg.com", "ralph.angelus@gmail.com"]}, "nonreaders": [], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}}, "tauthor": "ICLR.cc/2018/Conference"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1517260079617, "tcdate": 1517250066474, "number": 739, "cdate": 1517250066461, "id": "BJqM81pBG", "invitation": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "forum": "rkZzY-lCb", "replyto": "rkZzY-lCb", "signatures": ["ICLR.cc/2018/Conference/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Conference Acceptance Decision", "comment": "The paper presents an approach for learning continuous-valued vector representations combining multiple input feature sets of different types, in both unsupervised and supervised settings.  The revised paper is a merger of the original submission and another ICLR submission.  This meta-review takes into account all of the comments on both submissions and revisions.\n\nThe merged paper is an improvement over the two separate ones.  However, the contribution over previous work is still a bit unclear.  It still does not sufficiently compare to/discuss in the context of other recent work on combining multiple feature groups.\n\nThe experiments are also quite limited.  The idea is introduced as extremely general, but the experiments focus on a small number of specific tasks, some of them non-standard."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features", "abstract": "Methods that calculate dense vector representations for features in unstructured data\u2014such as words in a document\u2014have proven to be very successful for knowledge representation. We study how to estimate dense representations when multiple feature types exist within a dataset for supervised learning where explicit labels are available, as well as for unsupervised learning where there are no labels. Feat2Vec calculates embeddings for data with multiple feature types enforcing that all different feature types exist in a common space. In the supervised case, we show that our method has advantages over recently proposed methods; such as enabling higher prediction accuracy, and providing a way to avoid the cold-start\nproblem. In the unsupervised case, our experiments suggest that Feat2Vec significantly outperforms existing algorithms that do not leverage the structure of the data. We believe that we are the first to propose a method for learning unsuper vised embeddings that leverage the structure of multiple feature types.", "pdf": "/pdf/cfbe2eeef1804fb287b88b26ea994b8c1614c57a.pdf", "TL;DR": "Learn dense vector representations of arbitrary types of features in labeled and unlabeled datasets", "paperhash": "armona|feat2vec_dense_vector_representation_for_data_with_arbitrary_features", "_bibtex": "@misc{\narmona2018featvec,\ntitle={Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features},\nauthor={Luis Armona and Jos\u00e9 P. Gonz\u00e1lez-Brenes and Ralph Edezhath},\nyear={2018},\nurl={https://openreview.net/forum?id=rkZzY-lCb},\n}", "keywords": ["unsupervised learning", "supervised learning", "knowledge representation", "deep learning"], "authors": ["Luis Armona", "Jos\u00e9 P. Gonz\u00e1lez-Brenes", "Ralph Edezhath"], "authorids": ["luisarmona@gmail.com", "jgonzalez@chegg.com", "ralph.angelus@gmail.com"]}, "tags": [], "invitation": {"id": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "rdate": null, "ddate": null, "expdate": 1541175629000, "duedate": null, "tmdate": 1541177635767, "tddate": null, "super": null, "final": null, "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": {"values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Conference/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Conference Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": [], "noninvitees": [], "writers": ["ICLR.cc/2018/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1541177635767}}}, {"tddate": null, "ddate": null, "tmdate": 1516829186925, "tcdate": 1516829186925, "number": 11, "cdate": 1516829186925, "id": "HJoZquUSM", "invitation": "ICLR.cc/2018/Conference/-/Paper218/Official_Comment", "forum": "rkZzY-lCb", "replyto": "rJygCYHHM", "signatures": ["ICLR.cc/2018/Conference/Paper218/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper218/Authors"], "content": {"title": "Key distinctions between our work and prior work", "comment": "Thank you for your insightful comments.\n\nI. NOVELTY\nAfter reviewing your two references, we believe that our novelty claims still stand:\n\n1) Regarding the \"exponential family embeddings,\" our claim refers to general-purpose embeddings, which we define as \u201cembeddings of an unsupervised method that can be used for a variety of auxiliary prediction tasks.\u201d Therefore, our novelty claim is about unsupervised learning of embedding models with features, while the paper that you link to is a supervised approach.   \n\n2) The \"structured factorization\" work that you point out is a way to introduce structured sparsity, and could be used in tandem with our method. We define the structure in the loss function (not as regularization), as a novel way to combine features to get embeddings at different levels of granularity. \n\nWhile structured PCA requires groups of features to disappear simultaneously, the features that remain in the model are jointly projected to a common space. The \"embeddings\" that structured PCA discovers are a mixture of the remaining features. On the other hand, our approach can find an embedding for *each* value of the different *group* of features. Thus, PCA finds different vectors that are useful for a fundamentally different problem.\n\nWe were unaware of these works and agree they should be cited in a published version of our work. We will include these references in a future revision. \n\nII. EVALUATION\nOur evaluation for Unsupervised Feat2Vec differs from the standard evaluations for word embeddings since we are not dealing with language data - for example, word analogy is not applicable for the IMDB dataset. The evaluations used for supervised methods such as exponential family embeddings are also not applicable, as in our case there is no specific prediction task the embeddings are tuned for. Since building unsupervised embeddings for arbitrary feature types is not a well-studied problem, we are unaware of any standard way to evaluate them.\n\nThanks again for reading our work. I hope this response addresses your reservations.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features", "abstract": "Methods that calculate dense vector representations for features in unstructured data\u2014such as words in a document\u2014have proven to be very successful for knowledge representation. We study how to estimate dense representations when multiple feature types exist within a dataset for supervised learning where explicit labels are available, as well as for unsupervised learning where there are no labels. Feat2Vec calculates embeddings for data with multiple feature types enforcing that all different feature types exist in a common space. In the supervised case, we show that our method has advantages over recently proposed methods; such as enabling higher prediction accuracy, and providing a way to avoid the cold-start\nproblem. In the unsupervised case, our experiments suggest that Feat2Vec significantly outperforms existing algorithms that do not leverage the structure of the data. We believe that we are the first to propose a method for learning unsuper vised embeddings that leverage the structure of multiple feature types.", "pdf": "/pdf/cfbe2eeef1804fb287b88b26ea994b8c1614c57a.pdf", "TL;DR": "Learn dense vector representations of arbitrary types of features in labeled and unlabeled datasets", "paperhash": "armona|feat2vec_dense_vector_representation_for_data_with_arbitrary_features", "_bibtex": "@misc{\narmona2018featvec,\ntitle={Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features},\nauthor={Luis Armona and Jos\u00e9 P. Gonz\u00e1lez-Brenes and Ralph Edezhath},\nyear={2018},\nurl={https://openreview.net/forum?id=rkZzY-lCb},\n}", "keywords": ["unsupervised learning", "supervised learning", "knowledge representation", "deep learning"], "authors": ["Luis Armona", "Jos\u00e9 P. Gonz\u00e1lez-Brenes", "Ralph Edezhath"], "authorids": ["luisarmona@gmail.com", "jgonzalez@chegg.com", "ralph.angelus@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825737371, "id": "ICLR.cc/2018/Conference/-/Paper218/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "rkZzY-lCb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper218/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper218/Authors|ICLR.cc/2018/Conference/Paper218/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper218/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper218/Authors|ICLR.cc/2018/Conference/Paper218/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper218/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper218/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper218/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper218/Reviewers", "ICLR.cc/2018/Conference/Paper218/Authors", "ICLR.cc/2018/Conference/Paper218/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825737371}}}, {"tddate": null, "ddate": null, "tmdate": 1516768742713, "tcdate": 1516768742713, "number": 1, "cdate": 1516768742713, "id": "rJygCYHHM", "invitation": "ICLR.cc/2018/Conference/-/Paper218/Public_Comment", "forum": "rkZzY-lCb", "replyto": "rkZzY-lCb", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Missing Related Work", "comment": "The paper makes claims about being the \"first algorithm that is able to calculate general-purpose embeddings that are not tuned for a single specific prediction task for arbitrary features\". I don't think this is true:\n\nThis paper \"Exponential family embeddings\" (https://arxiv.org/pdf/1608.00778.pdf) was in NIPS 2016 and presents a principled approach to handling various feature types.\n\n-Leveraging structure/groups in the data. I think this was popular a few years ago in the matrix factorization / dictionary learning / sparse learning community e.g. the references in:\nhttps://www.di.ens.fr/~fbach/talk_sparse_pca_DL_online.pdf\n\nbut the authors don't seem to mention any of this work.  \n\nThus, I find the novelty of the paper limited.\n\n\n(2) Evaluation. I am not persuaded that some of the experiments are standard evaluation, particularly Section 4.2 \"General purpose embeddings\".  For instance they take a movie dataset (IMDB) and compare the similarity of movie directors to those of actors who were cast in the same film. I don't think that is standard.\n\nPerhaps the authors could consider some of the data/tasks used in the following papers to evaluate the nature of their embeddings compared to word2vec.\n\n1. https://arxiv.org/abs/1411.4166\n\n2. https://nlp.stanford.edu/pubs/glove.pdf\n\n3. https://arxiv.org/pdf/1608.00778.pdf"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features", "abstract": "Methods that calculate dense vector representations for features in unstructured data\u2014such as words in a document\u2014have proven to be very successful for knowledge representation. We study how to estimate dense representations when multiple feature types exist within a dataset for supervised learning where explicit labels are available, as well as for unsupervised learning where there are no labels. Feat2Vec calculates embeddings for data with multiple feature types enforcing that all different feature types exist in a common space. In the supervised case, we show that our method has advantages over recently proposed methods; such as enabling higher prediction accuracy, and providing a way to avoid the cold-start\nproblem. In the unsupervised case, our experiments suggest that Feat2Vec significantly outperforms existing algorithms that do not leverage the structure of the data. We believe that we are the first to propose a method for learning unsuper vised embeddings that leverage the structure of multiple feature types.", "pdf": "/pdf/cfbe2eeef1804fb287b88b26ea994b8c1614c57a.pdf", "TL;DR": "Learn dense vector representations of arbitrary types of features in labeled and unlabeled datasets", "paperhash": "armona|feat2vec_dense_vector_representation_for_data_with_arbitrary_features", "_bibtex": "@misc{\narmona2018featvec,\ntitle={Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features},\nauthor={Luis Armona and Jos\u00e9 P. Gonz\u00e1lez-Brenes and Ralph Edezhath},\nyear={2018},\nurl={https://openreview.net/forum?id=rkZzY-lCb},\n}", "keywords": ["unsupervised learning", "supervised learning", "knowledge representation", "deep learning"], "authors": ["Luis Armona", "Jos\u00e9 P. Gonz\u00e1lez-Brenes", "Ralph Edezhath"], "authorids": ["luisarmona@gmail.com", "jgonzalez@chegg.com", "ralph.angelus@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791690767, "id": "ICLR.cc/2018/Conference/-/Paper218/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "rkZzY-lCb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper218/Authors", "ICLR.cc/2018/Conference/Paper218/Reviewers", "ICLR.cc/2018/Conference/Paper218/Area_Chair"], "cdate": 1512791690767}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1516658567138, "tcdate": 1511560368421, "number": 1, "cdate": 1511560368421, "id": "r1_2VGLlz", "invitation": "ICLR.cc/2018/Conference/-/Paper218/Official_Review", "forum": "rkZzY-lCb", "replyto": "rkZzY-lCb", "signatures": ["ICLR.cc/2018/Conference/Paper218/AnonReviewer2"], "readers": ["everyone"], "content": {"title": "Interesting paper with convincing results, but the approach has limited novelty. Proposed method is based on an approach that is concurrently under review at ICLR18", "rating": "7: Good paper, accept", "review": "Summary:\nThis paper proposes an approach to learn embeddings for structured datasets i.e. datasets which have heterogeneous set of features, as opposed to just words or just pixels. The paper proposes an approach called Feat2vec that relies on Structured Deep-In Factorization machines-- a paper that is concurrently under review at ICLR2018, which I haven't read in depth. The paper compares against a Word2vec baseline that pools all the heterogeneous content learns just one set of embeddings. Results are shown on IMDB movies and a proprietary education platform datasets. In both the tasks, Feat2vec leads to significant reduction in error compared to Word2vec.\n\nComments:\n\nThe paper is well written and addresses an important problem of learning word embeddings when there is inherent structure in the feature space. It is a very practically relevant problem. The novelty of the proposed approach seems limited in light of the related paper that is concurrently under review at ICLR2018, on which this paper heavily relies. Perhaps the authors should consider combining the two papers into one complete paper? The structured deep-in factorization machines allow higher-level interactions in embedding learning which allows the authors to learn embeddings for heterogeneous set of features. The sampling approaches proposed seem pretty straightforward adaptations of existing methods and not novel enough.\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features", "abstract": "Methods that calculate dense vector representations for features in unstructured data\u2014such as words in a document\u2014have proven to be very successful for knowledge representation. We study how to estimate dense representations when multiple feature types exist within a dataset for supervised learning where explicit labels are available, as well as for unsupervised learning where there are no labels. Feat2Vec calculates embeddings for data with multiple feature types enforcing that all different feature types exist in a common space. In the supervised case, we show that our method has advantages over recently proposed methods; such as enabling higher prediction accuracy, and providing a way to avoid the cold-start\nproblem. In the unsupervised case, our experiments suggest that Feat2Vec significantly outperforms existing algorithms that do not leverage the structure of the data. We believe that we are the first to propose a method for learning unsuper vised embeddings that leverage the structure of multiple feature types.", "pdf": "/pdf/cfbe2eeef1804fb287b88b26ea994b8c1614c57a.pdf", "TL;DR": "Learn dense vector representations of arbitrary types of features in labeled and unlabeled datasets", "paperhash": "armona|feat2vec_dense_vector_representation_for_data_with_arbitrary_features", "_bibtex": "@misc{\narmona2018featvec,\ntitle={Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features},\nauthor={Luis Armona and Jos\u00e9 P. Gonz\u00e1lez-Brenes and Ralph Edezhath},\nyear={2018},\nurl={https://openreview.net/forum?id=rkZzY-lCb},\n}", "keywords": ["unsupervised learning", "supervised learning", "knowledge representation", "deep learning"], "authors": ["Luis Armona", "Jos\u00e9 P. Gonz\u00e1lez-Brenes", "Ralph Edezhath"], "authorids": ["luisarmona@gmail.com", "jgonzalez@chegg.com", "ralph.angelus@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642410652, "id": "ICLR.cc/2018/Conference/-/Paper218/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper218/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper218/AnonReviewer2", "ICLR.cc/2018/Conference/Paper218/AnonReviewer3", "ICLR.cc/2018/Conference/Paper218/AnonReviewer1"], "reply": {"forum": "rkZzY-lCb", "replyto": "rkZzY-lCb", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper218/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642410652}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642410708, "tcdate": 1511778761747, "number": 2, "cdate": 1511778761747, "id": "HJfRKPFeM", "invitation": "ICLR.cc/2018/Conference/-/Paper218/Official_Review", "forum": "rkZzY-lCb", "replyto": "rkZzY-lCb", "signatures": ["ICLR.cc/2018/Conference/Paper218/AnonReviewer3"], "readers": ["everyone"], "content": {"title": "Not clear what I can learn from this", "rating": "2: Strong rejection", "review": "SUMMARY.\n\nThe paper presents an extension of word2vec for structured features.\nThe authors introduced a new compatibility function between features and, as in the skipgram approach, they propose a variation of negative sampling to deal with structured features.\nThe learned representation of features is tested on a recommendation-like task.\n\n\n----------\n\nOVERALL JUDGMENT\nThe paper is not clear and thus I am not sure what I can learn from it.\nFrom what is written on the paper I have trouble to understand the definition of the model the authors propose and also an actual NLP task where the representation induced by the model can be useful.\nFor this reason, I would suggest the authors make clear with a more formal notation, and the use of examples, what the model is supposed to achieve.\n\n----------\n\nDETAILED COMMENTS\nWhen the authors refer to word2vec is not clear if they are referring to skipgram or cbow algorithm, please make it clear.\nBottom of page one: \"a positive example is 'semantic'\", please, use another expression to describe observable examples, 'semantic' does not make sense in this context.\nLevi and Goldberg (2014)  do not say anything about factorization machines, could the authors clarify this point?\nEquation (4), what do i and j stand for? what does \\beta represent? is it the embedding vector? How is this formula related to skipgram or cbow?\nThe introduction of structured deep-in factorization machine should be more clear with examples that give the intuition on the rationale of the model.\nThe experimental section is rather poor, first, the authors only compare themselves with word2ve (cbow), it is not clear what the reader should learn from the results the authors got.\nFinally, the most striking flaw of this paper is the lack of references to previous works on word embeddings and feature representation, I would suggest the author check and compare themselves with previous work on this topic.", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features", "abstract": "Methods that calculate dense vector representations for features in unstructured data\u2014such as words in a document\u2014have proven to be very successful for knowledge representation. We study how to estimate dense representations when multiple feature types exist within a dataset for supervised learning where explicit labels are available, as well as for unsupervised learning where there are no labels. Feat2Vec calculates embeddings for data with multiple feature types enforcing that all different feature types exist in a common space. In the supervised case, we show that our method has advantages over recently proposed methods; such as enabling higher prediction accuracy, and providing a way to avoid the cold-start\nproblem. In the unsupervised case, our experiments suggest that Feat2Vec significantly outperforms existing algorithms that do not leverage the structure of the data. We believe that we are the first to propose a method for learning unsuper vised embeddings that leverage the structure of multiple feature types.", "pdf": "/pdf/cfbe2eeef1804fb287b88b26ea994b8c1614c57a.pdf", "TL;DR": "Learn dense vector representations of arbitrary types of features in labeled and unlabeled datasets", "paperhash": "armona|feat2vec_dense_vector_representation_for_data_with_arbitrary_features", "_bibtex": "@misc{\narmona2018featvec,\ntitle={Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features},\nauthor={Luis Armona and Jos\u00e9 P. Gonz\u00e1lez-Brenes and Ralph Edezhath},\nyear={2018},\nurl={https://openreview.net/forum?id=rkZzY-lCb},\n}", "keywords": ["unsupervised learning", "supervised learning", "knowledge representation", "deep learning"], "authors": ["Luis Armona", "Jos\u00e9 P. Gonz\u00e1lez-Brenes", "Ralph Edezhath"], "authorids": ["luisarmona@gmail.com", "jgonzalez@chegg.com", "ralph.angelus@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642410652, "id": "ICLR.cc/2018/Conference/-/Paper218/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper218/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper218/AnonReviewer2", "ICLR.cc/2018/Conference/Paper218/AnonReviewer3", "ICLR.cc/2018/Conference/Paper218/AnonReviewer1"], "reply": {"forum": "rkZzY-lCb", "replyto": "rkZzY-lCb", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper218/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642410652}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642410669, "tcdate": 1512080091476, "number": 3, "cdate": 1512080091476, "id": "ByQ1mb0xM", "invitation": "ICLR.cc/2018/Conference/-/Paper218/Official_Review", "forum": "rkZzY-lCb", "replyto": "rkZzY-lCb", "signatures": ["ICLR.cc/2018/Conference/Paper218/AnonReviewer1"], "readers": ["everyone"], "content": {"title": "Neat representation learning scheme for structured features", "rating": "7: Good paper, accept", "review": "This paper provides a clean way of learning embeddings for structured features that can be discrete -- indicating presence / absence of a certain quality. Further, these features can be structured i.e. a set of them are of the same 'type'. Unlike, word2vec there is no hard constraint that similar objects must have similar representations and so, the learnt embeddings reflect the likelihood of the observed features. Therefore, this can be used as a multi-label classifier by using two feature types -- the input and the set of categories. This proposed scheme is evaluated on two datasets -- movies and education in a retrieval setting. \n\nI would like to see an evaluation of these features in a classification setting to further demonstrate the utility of these embeddings as compared to directly embedding the discrete features and then performing a K-way classification. For example, I am aware of -- http://manikvarma.org/downloads/XC/XMLRepository.html contains some interesting datasets which have a large number of discrete features and classes. ", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features", "abstract": "Methods that calculate dense vector representations for features in unstructured data\u2014such as words in a document\u2014have proven to be very successful for knowledge representation. We study how to estimate dense representations when multiple feature types exist within a dataset for supervised learning where explicit labels are available, as well as for unsupervised learning where there are no labels. Feat2Vec calculates embeddings for data with multiple feature types enforcing that all different feature types exist in a common space. In the supervised case, we show that our method has advantages over recently proposed methods; such as enabling higher prediction accuracy, and providing a way to avoid the cold-start\nproblem. In the unsupervised case, our experiments suggest that Feat2Vec significantly outperforms existing algorithms that do not leverage the structure of the data. We believe that we are the first to propose a method for learning unsuper vised embeddings that leverage the structure of multiple feature types.", "pdf": "/pdf/cfbe2eeef1804fb287b88b26ea994b8c1614c57a.pdf", "TL;DR": "Learn dense vector representations of arbitrary types of features in labeled and unlabeled datasets", "paperhash": "armona|feat2vec_dense_vector_representation_for_data_with_arbitrary_features", "_bibtex": "@misc{\narmona2018featvec,\ntitle={Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features},\nauthor={Luis Armona and Jos\u00e9 P. Gonz\u00e1lez-Brenes and Ralph Edezhath},\nyear={2018},\nurl={https://openreview.net/forum?id=rkZzY-lCb},\n}", "keywords": ["unsupervised learning", "supervised learning", "knowledge representation", "deep learning"], "authors": ["Luis Armona", "Jos\u00e9 P. Gonz\u00e1lez-Brenes", "Ralph Edezhath"], "authorids": ["luisarmona@gmail.com", "jgonzalez@chegg.com", "ralph.angelus@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642410652, "id": "ICLR.cc/2018/Conference/-/Paper218/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper218/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper218/AnonReviewer2", "ICLR.cc/2018/Conference/Paper218/AnonReviewer3", "ICLR.cc/2018/Conference/Paper218/AnonReviewer1"], "reply": {"forum": "rkZzY-lCb", "replyto": "rkZzY-lCb", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper218/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642410652}}}, {"tddate": null, "ddate": null, "tmdate": 1515186802173, "tcdate": 1515186802173, "number": 4, "cdate": 1515186802173, "id": "H1cuqDpXf", "invitation": "ICLR.cc/2018/Conference/-/Paper218/Official_Comment", "forum": "rkZzY-lCb", "replyto": "rkZzY-lCb", "signatures": ["ICLR.cc/2018/Conference/Paper218/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper218/Authors"], "content": {"title": "Summary for major revision ", "comment": "Dear Chair,\n\nThe two main criticisms of the paper by the reviewers were (i) lack of references and (ii) that the results of the study were not significant enough to justify the two publications that we were aiming for.  For this reason, we added roughly 3x more citations to the paper to better situate the contributions in the literature.  Additionally, we merged this submission with our other concurrent ICLR manuscript.\n\nWe are hoping that we can get an opportunity to share our results with the ICLR community.  In the unsupervised setting, our work  is the first one to enable leveraging arbitrary feature types (a more general approach than exists in the literature).   In the supervised scenario, we provide evidence that our general method can have better performance than ad-hoc networks that work for a single purpose. \n\nThanks,\nAuthors\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features", "abstract": "Methods that calculate dense vector representations for features in unstructured data\u2014such as words in a document\u2014have proven to be very successful for knowledge representation. We study how to estimate dense representations when multiple feature types exist within a dataset for supervised learning where explicit labels are available, as well as for unsupervised learning where there are no labels. Feat2Vec calculates embeddings for data with multiple feature types enforcing that all different feature types exist in a common space. In the supervised case, we show that our method has advantages over recently proposed methods; such as enabling higher prediction accuracy, and providing a way to avoid the cold-start\nproblem. In the unsupervised case, our experiments suggest that Feat2Vec significantly outperforms existing algorithms that do not leverage the structure of the data. We believe that we are the first to propose a method for learning unsuper vised embeddings that leverage the structure of multiple feature types.", "pdf": "/pdf/cfbe2eeef1804fb287b88b26ea994b8c1614c57a.pdf", "TL;DR": "Learn dense vector representations of arbitrary types of features in labeled and unlabeled datasets", "paperhash": "armona|feat2vec_dense_vector_representation_for_data_with_arbitrary_features", "_bibtex": "@misc{\narmona2018featvec,\ntitle={Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features},\nauthor={Luis Armona and Jos\u00e9 P. Gonz\u00e1lez-Brenes and Ralph Edezhath},\nyear={2018},\nurl={https://openreview.net/forum?id=rkZzY-lCb},\n}", "keywords": ["unsupervised learning", "supervised learning", "knowledge representation", "deep learning"], "authors": ["Luis Armona", "Jos\u00e9 P. Gonz\u00e1lez-Brenes", "Ralph Edezhath"], "authorids": ["luisarmona@gmail.com", "jgonzalez@chegg.com", "ralph.angelus@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825737371, "id": "ICLR.cc/2018/Conference/-/Paper218/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "rkZzY-lCb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper218/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper218/Authors|ICLR.cc/2018/Conference/Paper218/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper218/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper218/Authors|ICLR.cc/2018/Conference/Paper218/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper218/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper218/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper218/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper218/Reviewers", "ICLR.cc/2018/Conference/Paper218/Authors", "ICLR.cc/2018/Conference/Paper218/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825737371}}}, {"tddate": null, "ddate": null, "tmdate": 1515186668751, "tcdate": 1515186668751, "number": 3, "cdate": 1515186668751, "id": "SJSx5wTmz", "invitation": "ICLR.cc/2018/Conference/-/Paper218/Official_Comment", "forum": "rkZzY-lCb", "replyto": "HJfRKPFeM", "signatures": ["ICLR.cc/2018/Conference/Paper218/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper218/Authors"], "content": {"title": "Major revision - significantly improved", "comment": "Thank you for your helpful comments.  Because another reviewer suggested merging our two ICLR submissions, we underwent a major revision of the paper and now have two main contributions -- this is, we can calculate embeddings in a supervised setting (labels are available), and in an unsupervised setting (labels are not available). \n\nYou stated two main criticisms to the paper:\n* References. You mentioned that the most striking flaw of the paper is lack of references. We added roughly three times more citations (we increased references from ~12 to ~36). We believe that the paper is now much better situated in the literature.\n* Evaluation. To our knowledge we are the first ones to propose learning unsupervised embeddings for multiple feature types.  The Word2Vec algorithms are  other unsupervised  embedding methods (though, W2V only works with words), and that is why we compare with them. \nBecause of the major revision of the paper, we believe we improved the empirical result section significantly. We added 2 additional datasets (total of 4), and added 4 baselines altogether (CBOW W2V, Matrix Factorization, Collaborative Topic Regression and  DeepCoNN)\n\n\nOther detailed comments:\nWe removed the reference of Levy & Goldberg (but the general point is that factorization machines are a general case of matrix factorization)\nWe rewrote the introduction to make more salient our contributions, and we believe that it is now more clear what the model achieves. We streamlined the notation. Additionally, we clarified the language surrounding Word2Vec. \n\nWe hope that these major revisions address your reservations.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features", "abstract": "Methods that calculate dense vector representations for features in unstructured data\u2014such as words in a document\u2014have proven to be very successful for knowledge representation. We study how to estimate dense representations when multiple feature types exist within a dataset for supervised learning where explicit labels are available, as well as for unsupervised learning where there are no labels. Feat2Vec calculates embeddings for data with multiple feature types enforcing that all different feature types exist in a common space. In the supervised case, we show that our method has advantages over recently proposed methods; such as enabling higher prediction accuracy, and providing a way to avoid the cold-start\nproblem. In the unsupervised case, our experiments suggest that Feat2Vec significantly outperforms existing algorithms that do not leverage the structure of the data. We believe that we are the first to propose a method for learning unsuper vised embeddings that leverage the structure of multiple feature types.", "pdf": "/pdf/cfbe2eeef1804fb287b88b26ea994b8c1614c57a.pdf", "TL;DR": "Learn dense vector representations of arbitrary types of features in labeled and unlabeled datasets", "paperhash": "armona|feat2vec_dense_vector_representation_for_data_with_arbitrary_features", "_bibtex": "@misc{\narmona2018featvec,\ntitle={Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features},\nauthor={Luis Armona and Jos\u00e9 P. Gonz\u00e1lez-Brenes and Ralph Edezhath},\nyear={2018},\nurl={https://openreview.net/forum?id=rkZzY-lCb},\n}", "keywords": ["unsupervised learning", "supervised learning", "knowledge representation", "deep learning"], "authors": ["Luis Armona", "Jos\u00e9 P. Gonz\u00e1lez-Brenes", "Ralph Edezhath"], "authorids": ["luisarmona@gmail.com", "jgonzalez@chegg.com", "ralph.angelus@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825737371, "id": "ICLR.cc/2018/Conference/-/Paper218/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "rkZzY-lCb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper218/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper218/Authors|ICLR.cc/2018/Conference/Paper218/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper218/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper218/Authors|ICLR.cc/2018/Conference/Paper218/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper218/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper218/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper218/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper218/Reviewers", "ICLR.cc/2018/Conference/Paper218/Authors", "ICLR.cc/2018/Conference/Paper218/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825737371}}}, {"tddate": null, "ddate": null, "tmdate": 1515186414707, "tcdate": 1515186384345, "number": 2, "cdate": 1515186384345, "id": "Bk_CuPamf", "invitation": "ICLR.cc/2018/Conference/-/Paper218/Official_Comment", "forum": "rkZzY-lCb", "replyto": "r1_2VGLlz", "signatures": ["ICLR.cc/2018/Conference/Paper218/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper218/Authors"], "content": {"title": "Stronger contribution (better novelty) is in place", "comment": "Thank you for the constructive comments. Your main criticism for the paper was that the contribution of our work was not significant enough to justify the two publications that we were aiming for. Following your suggestion, we have combined the two papers and added the relevant parts of the other paper (we only extended our submission with the results that would be relevant to the combined version).\n\nWhile the original paper only addressed unsupervised learning of embeddings,  the revised manuscript also addresses supervised learning of embeddings.  We demonstrate that our general supervised method can have better performance  than recently published single purpose methods (DeepCoNN and Collaborative Topic Regression) on two publicly available datasets, Yelp and CiteULike.  We also explain in more detail how Feat2Vec extends Factorization Machines.   \n\nWe hope that this major revision address your reservations.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features", "abstract": "Methods that calculate dense vector representations for features in unstructured data\u2014such as words in a document\u2014have proven to be very successful for knowledge representation. We study how to estimate dense representations when multiple feature types exist within a dataset for supervised learning where explicit labels are available, as well as for unsupervised learning where there are no labels. Feat2Vec calculates embeddings for data with multiple feature types enforcing that all different feature types exist in a common space. In the supervised case, we show that our method has advantages over recently proposed methods; such as enabling higher prediction accuracy, and providing a way to avoid the cold-start\nproblem. In the unsupervised case, our experiments suggest that Feat2Vec significantly outperforms existing algorithms that do not leverage the structure of the data. We believe that we are the first to propose a method for learning unsuper vised embeddings that leverage the structure of multiple feature types.", "pdf": "/pdf/cfbe2eeef1804fb287b88b26ea994b8c1614c57a.pdf", "TL;DR": "Learn dense vector representations of arbitrary types of features in labeled and unlabeled datasets", "paperhash": "armona|feat2vec_dense_vector_representation_for_data_with_arbitrary_features", "_bibtex": "@misc{\narmona2018featvec,\ntitle={Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features},\nauthor={Luis Armona and Jos\u00e9 P. Gonz\u00e1lez-Brenes and Ralph Edezhath},\nyear={2018},\nurl={https://openreview.net/forum?id=rkZzY-lCb},\n}", "keywords": ["unsupervised learning", "supervised learning", "knowledge representation", "deep learning"], "authors": ["Luis Armona", "Jos\u00e9 P. Gonz\u00e1lez-Brenes", "Ralph Edezhath"], "authorids": ["luisarmona@gmail.com", "jgonzalez@chegg.com", "ralph.angelus@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825737371, "id": "ICLR.cc/2018/Conference/-/Paper218/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "rkZzY-lCb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper218/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper218/Authors|ICLR.cc/2018/Conference/Paper218/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper218/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper218/Authors|ICLR.cc/2018/Conference/Paper218/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper218/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper218/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper218/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper218/Reviewers", "ICLR.cc/2018/Conference/Paper218/Authors", "ICLR.cc/2018/Conference/Paper218/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825737371}}}, {"tddate": null, "ddate": null, "tmdate": 1515186284063, "tcdate": 1515186284063, "number": 1, "cdate": 1515186284063, "id": "rkNuOP6XG", "invitation": "ICLR.cc/2018/Conference/-/Paper218/Official_Comment", "forum": "rkZzY-lCb", "replyto": "ByQ1mb0xM", "signatures": ["ICLR.cc/2018/Conference/Paper218/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper218/Authors"], "content": {"title": "Thank you", "comment": "Thank you for your informative comments on our paper. We have added experiments for supervised Feat2Vec, which includes a multi-label prediction task on a public dataset (CiteULike) benchmarked against other state of the art methods. We hope that this experiment at least partially addresses your desire to see Feat2Vec in a K-way classification task.  We would also like to point you to the ranking task done classifying the director of a film based on its task members. The 2.43% Top-1 Precision can be imagined as the performance of the unsupervised F2V embedding algorithm on a K-way classification task (as compared to Word2Vec\u2019s CBOW algorithm). \n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features", "abstract": "Methods that calculate dense vector representations for features in unstructured data\u2014such as words in a document\u2014have proven to be very successful for knowledge representation. We study how to estimate dense representations when multiple feature types exist within a dataset for supervised learning where explicit labels are available, as well as for unsupervised learning where there are no labels. Feat2Vec calculates embeddings for data with multiple feature types enforcing that all different feature types exist in a common space. In the supervised case, we show that our method has advantages over recently proposed methods; such as enabling higher prediction accuracy, and providing a way to avoid the cold-start\nproblem. In the unsupervised case, our experiments suggest that Feat2Vec significantly outperforms existing algorithms that do not leverage the structure of the data. We believe that we are the first to propose a method for learning unsuper vised embeddings that leverage the structure of multiple feature types.", "pdf": "/pdf/cfbe2eeef1804fb287b88b26ea994b8c1614c57a.pdf", "TL;DR": "Learn dense vector representations of arbitrary types of features in labeled and unlabeled datasets", "paperhash": "armona|feat2vec_dense_vector_representation_for_data_with_arbitrary_features", "_bibtex": "@misc{\narmona2018featvec,\ntitle={Feat2Vec:  Dense Vector Representation for Data with Arbitrary Features},\nauthor={Luis Armona and Jos\u00e9 P. Gonz\u00e1lez-Brenes and Ralph Edezhath},\nyear={2018},\nurl={https://openreview.net/forum?id=rkZzY-lCb},\n}", "keywords": ["unsupervised learning", "supervised learning", "knowledge representation", "deep learning"], "authors": ["Luis Armona", "Jos\u00e9 P. Gonz\u00e1lez-Brenes", "Ralph Edezhath"], "authorids": ["luisarmona@gmail.com", "jgonzalez@chegg.com", "ralph.angelus@gmail.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825737371, "id": "ICLR.cc/2018/Conference/-/Paper218/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "rkZzY-lCb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper218/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper218/Authors|ICLR.cc/2018/Conference/Paper218/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper218/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper218/Authors|ICLR.cc/2018/Conference/Paper218/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper218/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper218/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper218/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper218/Reviewers", "ICLR.cc/2018/Conference/Paper218/Authors", "ICLR.cc/2018/Conference/Paper218/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825737371}}}], "count": 11}