{"notes": [{"id": "rkepX8LFuE", "original": "BJenXfCUw4", "number": 6, "cdate": 1553716773032, "ddate": null, "tcdate": 1553716773032, "tmdate": 1562083042674, "tddate": null, "forum": "rkepX8LFuE", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Blind_Submission", "content": {"title": "Improved Adversarial Image Captioning", "authors": ["Pierre Dognin", "Igor Melnyk", "Youssef Mroueh", "Jarret Ross", "Tom Sercu"], "authorids": ["pdognin@us.ibm.com", "igor.melnyk@ibm.com", "mroueh@us.ibm.com", "rossja@us.ibm.com", "tom.sercu1@ibm.com"], "keywords": ["image captioning", "discrete GAN training"], "TL;DR": "Image captioning as a conditional GAN training with novel architectures, also study two discrete GAN training methods. ", "abstract": "In this paper we study image captioning as a conditional GAN training, proposing both a context-aware LSTM captioner and co-attentive discriminator, which enforces semantic alignment between images and captions. We investigate the viability of two discrete GAN training methods: Self-critical Sequence Training (SCST) and Gumbel Straight-Through (ST) and demonstrate that SCST shows more stable gradient behavior and improved results over Gumbel ST.", "pdf": "/pdf/e8a2705c751699bbb58f2c82e3ccceabe8122af5.pdf", "paperhash": "dognin|improved_adversarial_image_captioning"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Blind_Submission", "cdate": 1547567085825, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": [".*"]}, "writers": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1547567085825, "tmdate": 1555704438520, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}}, "tauthor": "OpenReview.net"}, {"id": "B1xgOSOWcN", "original": null, "number": 2, "cdate": 1555297639670, "ddate": null, "tcdate": 1555297639670, "tmdate": 1556906122113, "tddate": null, "forum": "rkepX8LFuE", "replyto": "rkepX8LFuE", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper6/Official_Review", "content": {"title": "Review", "review": "This paper compares two adversarial training approach for image captioning: self-critical sequence training (SCST) and Gumbel Straight-Through method. The discriminator utilizes a co-attention pooling mechanism to compute the compatibility of the caption and image. During training, the discriminator is trained to distinguish real captions from fake, as well as to detect unrelated real sentences (randomly chosen). To backpropogate the gradient from the discriminator to generator, the author using both SCST and Gumbel ST. The experimental results show that SCST performs better in terms CIDEr and BLEU.\n\nThis paper presents a thorough empirical evaluation between the two methods. However, the reviewer's main criticism of this paper is lack of technical innovation. Both SCST and Gumbel ST method have been proposed in previous work and the contribution of this paper is no more than empirical comparison.", "rating": "2: Marginally below acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper6/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper6/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improved Adversarial Image Captioning", "authors": ["Pierre Dognin", "Igor Melnyk", "Youssef Mroueh", "Jarret Ross", "Tom Sercu"], "authorids": ["pdognin@us.ibm.com", "igor.melnyk@ibm.com", "mroueh@us.ibm.com", "rossja@us.ibm.com", "tom.sercu1@ibm.com"], "keywords": ["image captioning", "discrete GAN training"], "TL;DR": "Image captioning as a conditional GAN training with novel architectures, also study two discrete GAN training methods. ", "abstract": "In this paper we study image captioning as a conditional GAN training, proposing both a context-aware LSTM captioner and co-attentive discriminator, which enforces semantic alignment between images and captions. We investigate the viability of two discrete GAN training methods: Self-critical Sequence Training (SCST) and Gumbel Straight-Through (ST) and demonstrate that SCST shows more stable gradient behavior and improved results over Gumbel ST.", "pdf": "/pdf/e8a2705c751699bbb58f2c82e3ccceabe8122af5.pdf", "paperhash": "dognin|improved_adversarial_image_captioning"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper6/Official_Review", "cdate": 1554234180834, "reply": {"forum": "rkepX8LFuE", "replyto": "rkepX8LFuE", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper6/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper6/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1554234180834, "tmdate": 1556906084194, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper6/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}, {"id": "Byl9kPcRtE", "original": null, "number": 1, "cdate": 1555109602143, "ddate": null, "tcdate": 1555109602143, "tmdate": 1556906121895, "tddate": null, "forum": "rkepX8LFuE", "replyto": "rkepX8LFuE", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper6/Official_Review", "content": {"title": "The experiments look solid, but the overall contribution of the paper looks marginal", "review": "The main contribution of this paper is an improved GAN model for image captioning. First, a context-aware LSTM captioner is proposed, which provides some moderate modifications to the original adaptive attention paper. Second, a stronger co-attentive discriminator is introduced, which shows better performance than previous discriminator design. Third, SCST is used for this GAN training. \n\nPros: The experiments are relatively well designed to understand the effect of each individual model design. \n\nCons:\nThe novelty of this paper is limited. It improves the original conditional GAN for image captioning marginally by using different generator and discriminator design, and a new training method. However, each individual module only provides marginal contributions. There is no surprise in the generator and discriminator design, and the usage of SCST for GAN training is also a direct application of previous methods. ", "rating": "3: Marginally above acceptance threshold", "confidence": "3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper6/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper6/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improved Adversarial Image Captioning", "authors": ["Pierre Dognin", "Igor Melnyk", "Youssef Mroueh", "Jarret Ross", "Tom Sercu"], "authorids": ["pdognin@us.ibm.com", "igor.melnyk@ibm.com", "mroueh@us.ibm.com", "rossja@us.ibm.com", "tom.sercu1@ibm.com"], "keywords": ["image captioning", "discrete GAN training"], "TL;DR": "Image captioning as a conditional GAN training with novel architectures, also study two discrete GAN training methods. ", "abstract": "In this paper we study image captioning as a conditional GAN training, proposing both a context-aware LSTM captioner and co-attentive discriminator, which enforces semantic alignment between images and captions. We investigate the viability of two discrete GAN training methods: Self-critical Sequence Training (SCST) and Gumbel Straight-Through (ST) and demonstrate that SCST shows more stable gradient behavior and improved results over Gumbel ST.", "pdf": "/pdf/e8a2705c751699bbb58f2c82e3ccceabe8122af5.pdf", "paperhash": "dognin|improved_adversarial_image_captioning"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper6/Official_Review", "cdate": 1554234180834, "reply": {"forum": "rkepX8LFuE", "replyto": "rkepX8LFuE", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper6/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper6/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1554234180834, "tmdate": 1556906084194, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper6/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}, {"id": "HylTRfYv54", "original": null, "number": 1, "cdate": 1555694293102, "ddate": null, "tcdate": 1555694293102, "tmdate": 1556906121681, "tddate": null, "forum": "rkepX8LFuE", "replyto": "rkepX8LFuE", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper6/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept", "comment": "As the reviewers note, it is true that both SCST and Gumbel ST have been utilized in the past for reinforcement-learning style problems. However the application to GAN-based image captioning and the thorough experiments will make a nice contribution to the workshop."}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improved Adversarial Image Captioning", "authors": ["Pierre Dognin", "Igor Melnyk", "Youssef Mroueh", "Jarret Ross", "Tom Sercu"], "authorids": ["pdognin@us.ibm.com", "igor.melnyk@ibm.com", "mroueh@us.ibm.com", "rossja@us.ibm.com", "tom.sercu1@ibm.com"], "keywords": ["image captioning", "discrete GAN training"], "TL;DR": "Image captioning as a conditional GAN training with novel architectures, also study two discrete GAN training methods. ", "abstract": "In this paper we study image captioning as a conditional GAN training, proposing both a context-aware LSTM captioner and co-attentive discriminator, which enforces semantic alignment between images and captions. We investigate the viability of two discrete GAN training methods: Self-critical Sequence Training (SCST) and Gumbel Straight-Through (ST) and demonstrate that SCST shows more stable gradient behavior and improved results over Gumbel ST.", "pdf": "/pdf/e8a2705c751699bbb58f2c82e3ccceabe8122af5.pdf", "paperhash": "dognin|improved_adversarial_image_captioning"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper6/Decision", "cdate": 1555612281500, "reply": {"forum": "rkepX8LFuE", "replyto": "rkepX8LFuE", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1555612281500, "tmdate": 1556906095179, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}], "count": 4}