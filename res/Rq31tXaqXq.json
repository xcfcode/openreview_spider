{"notes": [{"id": "Rq31tXaqXq", "original": "fDv-r4ol0dKw", "number": 2615, "cdate": 1601308289628, "ddate": null, "tcdate": 1601308289628, "tmdate": 1614985641146, "tddate": null, "forum": "Rq31tXaqXq", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "VideoFlow: A Framework for Building Visual Analysis Pipelines", "authorids": ["~Yue_Wu18", "jianqiang.hjq@alibaba-inc.com", "moevis.zjj@alibaba-inc.com", "guokun.wgk@alibaba-inc.com", "jason.sc@alibaba-inc.com", "zhouchang.zc@alibaba-inc.com", "xiansheng.hxs@alibaba-inc.com"], "authors": ["Yue Wu", "Jianqiang Huang", "Jiangjie Zhen", "Guokun Wang", "Chen Shen", "Chang Zhou", "Xian-Sheng Hua"], "keywords": ["Computation graph", "Resource", "Computer vision", "Deep learning", "Framework", "Software"], "abstract": "The past years have witnessed an explosion of deep learning frameworks like PyTorch and TensorFlow since the success of deep neural networks. These frameworks have significantly facilitated algorithm development in multimedia research and production. However, how to easily and efficiently build an end-to-end visual analysis pipeline with these algorithms is still an open issue. In most cases, developers have to spend a huge amount of time tackling data input and output, optimizing computation efficiency, or even debugging exhausting memory leaks together with algorithm development. VideoFlow aims to overcome these challenges by providing a flexible, efficient, extensible, and secure visual analysis framework for both the academia and industry. With VideoFlow, developers can focus on the improvement of algorithms themselves, as well as the construction of a complete visual analysis workflow. VideoFlow has been incubated in the practices of smart city innovation for more than three years. It has been widely used in tens of intelligent visual analysis systems. VideoFlow will be open-sourced at \\url{https://github.com/xxx/videoflow}.", "one-sentence_summary": "a flexible, efficient, extensible and secure framework to build visual analysis pipelines for both the academia and industry.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wu|videoflow_a_framework_for_building_visual_analysis_pipelines", "supplementary_material": "/attachment/f8c6f406909d45054e570cfd028d60421bbb95b4.zip", "pdf": "/pdf/75583d0c22c9ffb48a073f9a8f25209cbf0a6474.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=jVpiejLSm8", "_bibtex": "@misc{\nwu2021videoflow,\ntitle={VideoFlow: A Framework for Building Visual Analysis Pipelines},\nauthor={Yue Wu and Jianqiang Huang and Jiangjie Zhen and Guokun Wang and Chen Shen and Chang Zhou and Xian-Sheng Hua},\nyear={2021},\nurl={https://openreview.net/forum?id=Rq31tXaqXq}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 6, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "vG5fwMuR-iz", "original": null, "number": 1, "cdate": 1610040520493, "ddate": null, "tcdate": 1610040520493, "tmdate": 1610474129161, "tddate": null, "forum": "Rq31tXaqXq", "replyto": "Rq31tXaqXq", "invitation": "ICLR.cc/2021/Conference/Paper2615/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "All reviewers appreciate the framework described in the paper and say it is a \"useful tool\", a \"flexible, efficient, extensible, and secure visual analysis framework\"  and \"in full fledged form may help the productivity while building visual analysis applications.\"\n\nHowever, the reviewers also point to significant shortcomings in terms of fit to ICLR, e.g. \"looks more like a technical report than a research paper\", \"key contributions of the VideoFlow should be only counted as engineering efforts rather than any novelty in the scientific or research perspective\", or \"major concern is that if it is appropriate for ICLR to publish this tutorial which may be regarded as an endorsement to this software\".\n\nThe authors did not reply to the reviewers comments.\n\nOverall the paper does not seem to contain sufficient scientific contributions for being accepted."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "VideoFlow: A Framework for Building Visual Analysis Pipelines", "authorids": ["~Yue_Wu18", "jianqiang.hjq@alibaba-inc.com", "moevis.zjj@alibaba-inc.com", "guokun.wgk@alibaba-inc.com", "jason.sc@alibaba-inc.com", "zhouchang.zc@alibaba-inc.com", "xiansheng.hxs@alibaba-inc.com"], "authors": ["Yue Wu", "Jianqiang Huang", "Jiangjie Zhen", "Guokun Wang", "Chen Shen", "Chang Zhou", "Xian-Sheng Hua"], "keywords": ["Computation graph", "Resource", "Computer vision", "Deep learning", "Framework", "Software"], "abstract": "The past years have witnessed an explosion of deep learning frameworks like PyTorch and TensorFlow since the success of deep neural networks. These frameworks have significantly facilitated algorithm development in multimedia research and production. However, how to easily and efficiently build an end-to-end visual analysis pipeline with these algorithms is still an open issue. In most cases, developers have to spend a huge amount of time tackling data input and output, optimizing computation efficiency, or even debugging exhausting memory leaks together with algorithm development. VideoFlow aims to overcome these challenges by providing a flexible, efficient, extensible, and secure visual analysis framework for both the academia and industry. With VideoFlow, developers can focus on the improvement of algorithms themselves, as well as the construction of a complete visual analysis workflow. VideoFlow has been incubated in the practices of smart city innovation for more than three years. It has been widely used in tens of intelligent visual analysis systems. VideoFlow will be open-sourced at \\url{https://github.com/xxx/videoflow}.", "one-sentence_summary": "a flexible, efficient, extensible and secure framework to build visual analysis pipelines for both the academia and industry.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wu|videoflow_a_framework_for_building_visual_analysis_pipelines", "supplementary_material": "/attachment/f8c6f406909d45054e570cfd028d60421bbb95b4.zip", "pdf": "/pdf/75583d0c22c9ffb48a073f9a8f25209cbf0a6474.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=jVpiejLSm8", "_bibtex": "@misc{\nwu2021videoflow,\ntitle={VideoFlow: A Framework for Building Visual Analysis Pipelines},\nauthor={Yue Wu and Jianqiang Huang and Jiangjie Zhen and Guokun Wang and Chen Shen and Chang Zhou and Xian-Sheng Hua},\nyear={2021},\nurl={https://openreview.net/forum?id=Rq31tXaqXq}\n}"}, "tags": [], "invitation": {"reply": {"forum": "Rq31tXaqXq", "replyto": "Rq31tXaqXq", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040520480, "tmdate": 1610474129146, "id": "ICLR.cc/2021/Conference/Paper2615/-/Decision"}}}, {"id": "BfSI5ZHhobA", "original": null, "number": 1, "cdate": 1603724590269, "ddate": null, "tcdate": 1603724590269, "tmdate": 1605024169106, "tddate": null, "forum": "Rq31tXaqXq", "replyto": "Rq31tXaqXq", "invitation": "ICLR.cc/2021/Conference/Paper2615/-/Official_Review", "content": {"title": "A tutorial to a video analysis platform software", "review": "The paper presents a tutorial to a video analysis platform software, i.e., VideoFlow, which represents a video analysis task as a computation graph, provides common functions like video decoding and database storage, integrates deep learning frameworks, e.g. Caffe/Pytorch/MXNet as built-in inference engines, and supports heterogeneous hardware such as CPU/GPU/FPGA. VideoFlow also allows the customers to develop operator, decoder, and model inference extensions. The paper presents an example application of person ReID using the VideoFlow platform. The paper claims this VideoFlow software could be used in both academic and industrial scenarios. \n\nThe VideoFlow platform software is certainly a great development tool for video analysis tasks. The major concern is that if it is appropriate for ICLR to publish this tutorial which may be regarded as an endorsement to this software. Perhaps, VideoFlow could demonstrate in the exhibition of academic conferences to promote the usage in academia. \n\nSome detailed comments:\n\n1)\tIs VideoFlow a commercial software or a free open-source software? What kind of license does VideoFlow follow? As it integrates some functions of other software like Caffe/Pytorch/MxNet. \n\n2)\tThe major issue of adopting VideoFlow could be the learning curve how to use and debug applications on VideoFlow. VideoFlow appears a powerful and comprehensive video analysis platform, which abstracts and defines the interfaces among the components in a computation graph. For most of academia users, PyTorch/TensorFlow may be good to develop and verify some new deep model or algorithms. For industrial users, debugging any problem on VideoFlow requires a profound understanding of the platform. Deployment of an application could encounter issues on run-time library dependency, cross-compilation, resource limitation, e.g, on an embedded system. It would be a critical decision to adopt an open-sourced development platform for commercial applications for industrial users.\n\n3)\tSome minor questions:  As there is already a software named VideoFlow (de Armas, 2019), why not choose a different name for this software?  Vector<void*> appears a C++ implementation of a C-style concept, which implicitly requires the caller to agree with a protocol specified in other documents. The users may make mistakes that are hard to debug.  \n\nOverall, the proposed VideoFlow software is a great development tool for video analysis tasks using deep learning models. I encourage the authors to promote this software in the open-source community and demonstrate it in conference exhibition and trade shows.\n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2615/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2615/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "VideoFlow: A Framework for Building Visual Analysis Pipelines", "authorids": ["~Yue_Wu18", "jianqiang.hjq@alibaba-inc.com", "moevis.zjj@alibaba-inc.com", "guokun.wgk@alibaba-inc.com", "jason.sc@alibaba-inc.com", "zhouchang.zc@alibaba-inc.com", "xiansheng.hxs@alibaba-inc.com"], "authors": ["Yue Wu", "Jianqiang Huang", "Jiangjie Zhen", "Guokun Wang", "Chen Shen", "Chang Zhou", "Xian-Sheng Hua"], "keywords": ["Computation graph", "Resource", "Computer vision", "Deep learning", "Framework", "Software"], "abstract": "The past years have witnessed an explosion of deep learning frameworks like PyTorch and TensorFlow since the success of deep neural networks. These frameworks have significantly facilitated algorithm development in multimedia research and production. However, how to easily and efficiently build an end-to-end visual analysis pipeline with these algorithms is still an open issue. In most cases, developers have to spend a huge amount of time tackling data input and output, optimizing computation efficiency, or even debugging exhausting memory leaks together with algorithm development. VideoFlow aims to overcome these challenges by providing a flexible, efficient, extensible, and secure visual analysis framework for both the academia and industry. With VideoFlow, developers can focus on the improvement of algorithms themselves, as well as the construction of a complete visual analysis workflow. VideoFlow has been incubated in the practices of smart city innovation for more than three years. It has been widely used in tens of intelligent visual analysis systems. VideoFlow will be open-sourced at \\url{https://github.com/xxx/videoflow}.", "one-sentence_summary": "a flexible, efficient, extensible and secure framework to build visual analysis pipelines for both the academia and industry.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wu|videoflow_a_framework_for_building_visual_analysis_pipelines", "supplementary_material": "/attachment/f8c6f406909d45054e570cfd028d60421bbb95b4.zip", "pdf": "/pdf/75583d0c22c9ffb48a073f9a8f25209cbf0a6474.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=jVpiejLSm8", "_bibtex": "@misc{\nwu2021videoflow,\ntitle={VideoFlow: A Framework for Building Visual Analysis Pipelines},\nauthor={Yue Wu and Jianqiang Huang and Jiangjie Zhen and Guokun Wang and Chen Shen and Chang Zhou and Xian-Sheng Hua},\nyear={2021},\nurl={https://openreview.net/forum?id=Rq31tXaqXq}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Rq31tXaqXq", "replyto": "Rq31tXaqXq", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2615/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538092321, "tmdate": 1606915805864, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2615/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2615/-/Official_Review"}}}, {"id": "wYvd3_7Xb6j", "original": null, "number": 2, "cdate": 1603993379929, "ddate": null, "tcdate": 1603993379929, "tmdate": 1605024169035, "tddate": null, "forum": "Rq31tXaqXq", "replyto": "Rq31tXaqXq", "invitation": "ICLR.cc/2021/Conference/Paper2615/-/Official_Review", "content": {"title": "A fit for system communities, but not for the machine learning community", "review": "This manuscript describes a framework, VideoFlow, for deploying and analyzing video execution flows. VideoFlow abstracts the workload into computation graph and resource, and dynamically executes the graph given the resource.\n\nAlthough this work seems helpful for system integration and deployment, I did not see a strong connection between it and the topic of this conference. In this framework, learned models are treated as an atomic node and executed on other DL libraries. The graph mentioned in this paper, as well as terms like forward/backward, has nothing to do with the graph in machine learning concept. Therefore, I do not see this paper as a good candidate for machine learning community, but a better fit for system communities.\n\nThere are some additional comments:\n1. Figures should come with captions to illustrate themselves, instead of just a title.\n2. Figure 2 is confusing. It is hard to infer from the figure what forward function is. The authors need to emphasize this forward/backward function is different from DL models' forward/backward.\n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2615/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2615/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "VideoFlow: A Framework for Building Visual Analysis Pipelines", "authorids": ["~Yue_Wu18", "jianqiang.hjq@alibaba-inc.com", "moevis.zjj@alibaba-inc.com", "guokun.wgk@alibaba-inc.com", "jason.sc@alibaba-inc.com", "zhouchang.zc@alibaba-inc.com", "xiansheng.hxs@alibaba-inc.com"], "authors": ["Yue Wu", "Jianqiang Huang", "Jiangjie Zhen", "Guokun Wang", "Chen Shen", "Chang Zhou", "Xian-Sheng Hua"], "keywords": ["Computation graph", "Resource", "Computer vision", "Deep learning", "Framework", "Software"], "abstract": "The past years have witnessed an explosion of deep learning frameworks like PyTorch and TensorFlow since the success of deep neural networks. These frameworks have significantly facilitated algorithm development in multimedia research and production. However, how to easily and efficiently build an end-to-end visual analysis pipeline with these algorithms is still an open issue. In most cases, developers have to spend a huge amount of time tackling data input and output, optimizing computation efficiency, or even debugging exhausting memory leaks together with algorithm development. VideoFlow aims to overcome these challenges by providing a flexible, efficient, extensible, and secure visual analysis framework for both the academia and industry. With VideoFlow, developers can focus on the improvement of algorithms themselves, as well as the construction of a complete visual analysis workflow. VideoFlow has been incubated in the practices of smart city innovation for more than three years. It has been widely used in tens of intelligent visual analysis systems. VideoFlow will be open-sourced at \\url{https://github.com/xxx/videoflow}.", "one-sentence_summary": "a flexible, efficient, extensible and secure framework to build visual analysis pipelines for both the academia and industry.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wu|videoflow_a_framework_for_building_visual_analysis_pipelines", "supplementary_material": "/attachment/f8c6f406909d45054e570cfd028d60421bbb95b4.zip", "pdf": "/pdf/75583d0c22c9ffb48a073f9a8f25209cbf0a6474.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=jVpiejLSm8", "_bibtex": "@misc{\nwu2021videoflow,\ntitle={VideoFlow: A Framework for Building Visual Analysis Pipelines},\nauthor={Yue Wu and Jianqiang Huang and Jiangjie Zhen and Guokun Wang and Chen Shen and Chang Zhou and Xian-Sheng Hua},\nyear={2021},\nurl={https://openreview.net/forum?id=Rq31tXaqXq}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Rq31tXaqXq", "replyto": "Rq31tXaqXq", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2615/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538092321, "tmdate": 1606915805864, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2615/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2615/-/Official_Review"}}}, {"id": "ErXNDYINUT0", "original": null, "number": 3, "cdate": 1604175000785, "ddate": null, "tcdate": 1604175000785, "tmdate": 1605024168969, "tddate": null, "forum": "Rq31tXaqXq", "replyto": "Rq31tXaqXq", "invitation": "ICLR.cc/2021/Conference/Paper2615/-/Official_Review", "content": {"title": "VideoFlow: A Framework for Building Visual Analysis Pipelines", "review": "Summary of contribution:\n\nThis paper presents VideoFlow, a domain-specific deep learning framework that focuses on building pipelines for video analytics. The goal of VideoFlow is to facilitate both development and deployment of visual data analysis pipelines for real-world applications. The paper describes the design and implementation of this framework. VideoFlow seems like a useful tool, but its novelty and contributions to the state of the art have not been clearly articulated in the paper.\n\nStrong points:\n- The need for VideoFlow is well motivated.\n- Flexibility, efficiency, extensibility, and security have been identified to be the key design goals for VideoFlow's architecture.\n- VideoFlow has been in practical use in the smart city domain for the past few years.\n- VideoFlow supports utilizing heterogeneous hardware.     \n\nWeak points:\n- The paper reads more like a system demo paper. Its contribution as a research paper is not clear.\n- Good coverage of related work, but it is not clear how exactly VideoFlow compares to the state of the art. In what ways is it superior? No experimental evidence and/or user/case studies have been provided to show this.\n- There is not enough experimental evidence in the paper that the four design goals are all completely met.\n- It would have been nice to include more experience from the smart city deployment.\n\nAdditional comments:\n- Open-sourcing VideoFlow beyond its current incubated use would help enable community's use, feedback, and contributions.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2615/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2615/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "VideoFlow: A Framework for Building Visual Analysis Pipelines", "authorids": ["~Yue_Wu18", "jianqiang.hjq@alibaba-inc.com", "moevis.zjj@alibaba-inc.com", "guokun.wgk@alibaba-inc.com", "jason.sc@alibaba-inc.com", "zhouchang.zc@alibaba-inc.com", "xiansheng.hxs@alibaba-inc.com"], "authors": ["Yue Wu", "Jianqiang Huang", "Jiangjie Zhen", "Guokun Wang", "Chen Shen", "Chang Zhou", "Xian-Sheng Hua"], "keywords": ["Computation graph", "Resource", "Computer vision", "Deep learning", "Framework", "Software"], "abstract": "The past years have witnessed an explosion of deep learning frameworks like PyTorch and TensorFlow since the success of deep neural networks. These frameworks have significantly facilitated algorithm development in multimedia research and production. However, how to easily and efficiently build an end-to-end visual analysis pipeline with these algorithms is still an open issue. In most cases, developers have to spend a huge amount of time tackling data input and output, optimizing computation efficiency, or even debugging exhausting memory leaks together with algorithm development. VideoFlow aims to overcome these challenges by providing a flexible, efficient, extensible, and secure visual analysis framework for both the academia and industry. With VideoFlow, developers can focus on the improvement of algorithms themselves, as well as the construction of a complete visual analysis workflow. VideoFlow has been incubated in the practices of smart city innovation for more than three years. It has been widely used in tens of intelligent visual analysis systems. VideoFlow will be open-sourced at \\url{https://github.com/xxx/videoflow}.", "one-sentence_summary": "a flexible, efficient, extensible and secure framework to build visual analysis pipelines for both the academia and industry.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wu|videoflow_a_framework_for_building_visual_analysis_pipelines", "supplementary_material": "/attachment/f8c6f406909d45054e570cfd028d60421bbb95b4.zip", "pdf": "/pdf/75583d0c22c9ffb48a073f9a8f25209cbf0a6474.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=jVpiejLSm8", "_bibtex": "@misc{\nwu2021videoflow,\ntitle={VideoFlow: A Framework for Building Visual Analysis Pipelines},\nauthor={Yue Wu and Jianqiang Huang and Jiangjie Zhen and Guokun Wang and Chen Shen and Chang Zhou and Xian-Sheng Hua},\nyear={2021},\nurl={https://openreview.net/forum?id=Rq31tXaqXq}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Rq31tXaqXq", "replyto": "Rq31tXaqXq", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2615/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538092321, "tmdate": 1606915805864, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2615/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2615/-/Official_Review"}}}, {"id": "9f_CIX4_5l", "original": null, "number": 4, "cdate": 1604213482980, "ddate": null, "tcdate": 1604213482980, "tmdate": 1605024168901, "tddate": null, "forum": "Rq31tXaqXq", "replyto": "Rq31tXaqXq", "invitation": "ICLR.cc/2021/Conference/Paper2615/-/Official_Review", "content": {"title": "An engineering introduction to a visual analysis system but not a scientific paper", "review": "Summary\n-------\n\nThis paper introduce a framework for visual analysis (so-called VideoFlow) that will be open-sourced. VideoFlow is introduced with providing a flexible, efficient, extensible, and secure visual analysis framework for both academia and industry. It has been adopted in tens of intelligent visual analysis systems.\n\nHowever, through the whole paper, the key contributions of the VideoFlow should be only counted as engineering efforts rather than any novelty in the scientific or research perspective.\n\nTherefore, ICLR would be not an appropriate venue for the submitted paper to be published. It is more valuable for authors to submit to other venues such as OSDI (USENIX Symposium on Operating Systems Design and Implementation).\n\nStrengths\n---------\n\n- The paper introduces the architecture of the proposed framework (VideoFlow) in detail, including operator, data flow, resource, graph construction, execution scheduling, etc. These details should be helpful for users to understand the logic of its working flow and how the framework should be used.\n\n- The paper also presents the evaluation of person re-identification (ReID) task on VideoFlow to show its efficiency. \n\n\nWeaknesses\n----------\n\n- The motivation of presenting such a practical framework is clear and understandable, however, as a research paper, scientific contributions are required to prove its novelty rather than the only engineering efforts. For such a purpose, the following points could be considered to improve the current paper towards a more scientific-like research paper.\n\n\t- Address some scientific issues that were made in the architecture of VideoFlow: original methods solving the computation/IO intensive problem, theoretical efforts for graph construction and the design of execution scheduling.\n\n\t- Provide some theoretical or mathematical guarantees of the efficiency in the working flow of execution scheduling (Fig. 2).\n\t\n- The evaluation is not sufficient to show the advantages (flexible, efficient, extensible, and secure) that claimed by authors. In this paper, only the evaluation of ReID task is presented, but how about its efficiency and other advantages for other computer vision tasks such as object detection, segmentation, face recognition, and so on.\n\n\n\n \n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2615/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2615/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "VideoFlow: A Framework for Building Visual Analysis Pipelines", "authorids": ["~Yue_Wu18", "jianqiang.hjq@alibaba-inc.com", "moevis.zjj@alibaba-inc.com", "guokun.wgk@alibaba-inc.com", "jason.sc@alibaba-inc.com", "zhouchang.zc@alibaba-inc.com", "xiansheng.hxs@alibaba-inc.com"], "authors": ["Yue Wu", "Jianqiang Huang", "Jiangjie Zhen", "Guokun Wang", "Chen Shen", "Chang Zhou", "Xian-Sheng Hua"], "keywords": ["Computation graph", "Resource", "Computer vision", "Deep learning", "Framework", "Software"], "abstract": "The past years have witnessed an explosion of deep learning frameworks like PyTorch and TensorFlow since the success of deep neural networks. These frameworks have significantly facilitated algorithm development in multimedia research and production. However, how to easily and efficiently build an end-to-end visual analysis pipeline with these algorithms is still an open issue. In most cases, developers have to spend a huge amount of time tackling data input and output, optimizing computation efficiency, or even debugging exhausting memory leaks together with algorithm development. VideoFlow aims to overcome these challenges by providing a flexible, efficient, extensible, and secure visual analysis framework for both the academia and industry. With VideoFlow, developers can focus on the improvement of algorithms themselves, as well as the construction of a complete visual analysis workflow. VideoFlow has been incubated in the practices of smart city innovation for more than three years. It has been widely used in tens of intelligent visual analysis systems. VideoFlow will be open-sourced at \\url{https://github.com/xxx/videoflow}.", "one-sentence_summary": "a flexible, efficient, extensible and secure framework to build visual analysis pipelines for both the academia and industry.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wu|videoflow_a_framework_for_building_visual_analysis_pipelines", "supplementary_material": "/attachment/f8c6f406909d45054e570cfd028d60421bbb95b4.zip", "pdf": "/pdf/75583d0c22c9ffb48a073f9a8f25209cbf0a6474.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=jVpiejLSm8", "_bibtex": "@misc{\nwu2021videoflow,\ntitle={VideoFlow: A Framework for Building Visual Analysis Pipelines},\nauthor={Yue Wu and Jianqiang Huang and Jiangjie Zhen and Guokun Wang and Chen Shen and Chang Zhou and Xian-Sheng Hua},\nyear={2021},\nurl={https://openreview.net/forum?id=Rq31tXaqXq}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Rq31tXaqXq", "replyto": "Rq31tXaqXq", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2615/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538092321, "tmdate": 1606915805864, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2615/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2615/-/Official_Review"}}}, {"id": "2IabjocZRYY", "original": null, "number": 5, "cdate": 1604457897436, "ddate": null, "tcdate": 1604457897436, "tmdate": 1605024168833, "tddate": null, "forum": "Rq31tXaqXq", "replyto": "Rq31tXaqXq", "invitation": "ICLR.cc/2021/Conference/Paper2615/-/Official_Review", "content": {"title": "Official Blind Review #5", "review": "This paper points out the fact that just developing models using deep learning frameworks is not the end of the story when it comes to building end-to-end visual pipelines. The paper introduces VideoFlow which is a framework that aims to improve the development process of streaming pipelines.\n\nCompared to the widely used TensorFlow, PyTorch, and MXNet, VisualFlow focuses on more coarse-grained blocks like a \"whole network\" itself instead of \"layers.\" As such, the work is developed around a rather different units of data compared to Tensors in DNNs. This work also incorporates a GUI that lets the user edit the computation graphs. I believe this work in full fledged form may help the productivity while building visual analysis applications.\n\nSadly, there are many shortcomings of the paper. First, the paper literally spends over 60% of the paper to describe the implementation details which does not lead to much intellectual insights. This looks more like a technical report than a research paper.\n\nFurthermore, the paper lacks on evaluation in many aspects. For example, there is no evaluation about the potential overhead of the framework. I have listed a number of questions below with my comments.\n\nThe paper began with a luring abstract; however, after reading through the paper, the reader is left with only minor insights. Up to this point, the paper seems to be an amalgamation of various libraries and frameworks with a GUI wrapper. While I do believe the paper has some prospect as it does touch upon a real problem that does indeed take up a lot of resources in industry, I believe the paper is yet in a premature state to merit a publication at ICLR.\n\nAlso, I believe the paper would receive a more pertinent evaluation from a systems community like OSDI, SOSP, ATC. This is because these frameworks should not be just about putting things together to make something working, but should also entail a through experimentation of the performance and overhead.\n\nQuestions:\n- Could you please provide running examples of applications that have graphs with a complex topology?\n- How does the resource management behave for different scenarios such as underutilization? Could you show some visualization of that? For example, it would be very interesting to see how Dynamic Batching dynamically improves the utilization and the performance at runtime.\n- How can this be used for on-device scenarios, or cases where there are numerous devices? For example how does this compare to NNStreamer [1]?\n- If this framework were to be used in cases like Inference-as-a-Service scenario, how would this perform in terms of various QoS metrics?\n\n[1] NNStreamer, https://nnstreamer.ai", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2615/AnonReviewer5"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2615/AnonReviewer5"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "VideoFlow: A Framework for Building Visual Analysis Pipelines", "authorids": ["~Yue_Wu18", "jianqiang.hjq@alibaba-inc.com", "moevis.zjj@alibaba-inc.com", "guokun.wgk@alibaba-inc.com", "jason.sc@alibaba-inc.com", "zhouchang.zc@alibaba-inc.com", "xiansheng.hxs@alibaba-inc.com"], "authors": ["Yue Wu", "Jianqiang Huang", "Jiangjie Zhen", "Guokun Wang", "Chen Shen", "Chang Zhou", "Xian-Sheng Hua"], "keywords": ["Computation graph", "Resource", "Computer vision", "Deep learning", "Framework", "Software"], "abstract": "The past years have witnessed an explosion of deep learning frameworks like PyTorch and TensorFlow since the success of deep neural networks. These frameworks have significantly facilitated algorithm development in multimedia research and production. However, how to easily and efficiently build an end-to-end visual analysis pipeline with these algorithms is still an open issue. In most cases, developers have to spend a huge amount of time tackling data input and output, optimizing computation efficiency, or even debugging exhausting memory leaks together with algorithm development. VideoFlow aims to overcome these challenges by providing a flexible, efficient, extensible, and secure visual analysis framework for both the academia and industry. With VideoFlow, developers can focus on the improvement of algorithms themselves, as well as the construction of a complete visual analysis workflow. VideoFlow has been incubated in the practices of smart city innovation for more than three years. It has been widely used in tens of intelligent visual analysis systems. VideoFlow will be open-sourced at \\url{https://github.com/xxx/videoflow}.", "one-sentence_summary": "a flexible, efficient, extensible and secure framework to build visual analysis pipelines for both the academia and industry.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wu|videoflow_a_framework_for_building_visual_analysis_pipelines", "supplementary_material": "/attachment/f8c6f406909d45054e570cfd028d60421bbb95b4.zip", "pdf": "/pdf/75583d0c22c9ffb48a073f9a8f25209cbf0a6474.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=jVpiejLSm8", "_bibtex": "@misc{\nwu2021videoflow,\ntitle={VideoFlow: A Framework for Building Visual Analysis Pipelines},\nauthor={Yue Wu and Jianqiang Huang and Jiangjie Zhen and Guokun Wang and Chen Shen and Chang Zhou and Xian-Sheng Hua},\nyear={2021},\nurl={https://openreview.net/forum?id=Rq31tXaqXq}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "Rq31tXaqXq", "replyto": "Rq31tXaqXq", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2615/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538092321, "tmdate": 1606915805864, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2615/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2615/-/Official_Review"}}}], "count": 7}