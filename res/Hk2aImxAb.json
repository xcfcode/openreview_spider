{"notes": [{"tddate": null, "ddate": null, "tmdate": 1519730733104, "tcdate": 1519730733104, "number": 2, "cdate": 1519730733104, "id": "SkBVeaMuz", "invitation": "ICLR.cc/2018/Conference/-/Paper229/Public_Comment", "forum": "Hk2aImxAb", "replyto": "Hk2aImxAb", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Reproducibility challenge report", "comment": "As our deep learning seminar project, we participated in ICLR reproducibility challenge. The project included re-implementing MSDNet paper, reproducibility of the results, and testing a new variant on the original MSDNet architecture.\nSummary of our results:\n1. We managed to reproduce the results presented in the paper, both with the provided implementation in Lua, and with our implementation in pytorch.\n2. We tested some variants of plugging Global Convolutional Network (with separable kernel) to the features network, in order to reduce its parameters and runtime.\n\nLink to the full report and code: https://github.com/avirambh/MSDNet-GCN/blob/master/report/MSDNet_reproducibility_report.pdf"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-Scale Dense Networks for Resource Efficient Image Classification", "abstract": "In this paper we investigate image classification with computational resource limits at test time. Two such settings are: 1. anytime classification, where the network\u2019s prediction for a test example is progressively updated, facilitating the output of a prediction at any time; and 2. budgeted batch classification, where a fixed amount of computation is available to classify a set of examples that can be spent unevenly across \u201ceasier\u201d and \u201charder\u201d inputs. In contrast to most prior work, such as the popular Viola and Jones algorithm, our approach is based on convolutional neural networks. We train multiple classifiers with varying resource demands, which we adaptively apply during test time. To maximally re-use computation between the classifiers, we incorporate them as early-exits into a single deep convolutional neural network and inter-connect them with dense connectivity. To facilitate high quality classification early on, we use a two-dimensional multi-scale network architecture that maintains coarse and fine level features all-throughout the network. Experiments on three image-classification tasks demonstrate that our framework substantially improves the existing state-of-the-art in both settings.", "pdf": "/pdf/b92cc4191e13816cacce262b4e421aac1052ec10.pdf", "paperhash": "huang|multiscale_dense_networks_for_resource_efficient_image_classification", "_bibtex": "@inproceedings{\nhuang2018multiscale,\ntitle={Multi-Scale Dense Networks for Resource Efficient Image Classification},\nauthor={Gao Huang and Danlu Chen and Tianhong Li and Felix Wu and Laurens van der Maaten and Kilian Weinberger},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=Hk2aImxAb},\n}", "keywords": ["efficient learning", "budgeted learning", "deep learning", "image classification", "convolutional networks"], "authors": ["Gao Huang", "Danlu Chen", "Tianhong Li", "Felix Wu", "Laurens van der Maaten", "Kilian Weinberger"], "authorids": ["gh349@cornell.edu", "taineleau@gmail.com", "lth14@mails.tsinghua.edu.cn", "fw245@cornell.edu", "lvdmaaten@fb.com", "kqw4@cornell.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791690532, "id": "ICLR.cc/2018/Conference/-/Paper229/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "Hk2aImxAb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper229/Authors", "ICLR.cc/2018/Conference/Paper229/Reviewers", "ICLR.cc/2018/Conference/Paper229/Area_Chair"], "cdate": 1512791690532}}}, {"tddate": null, "ddate": null, "tmdate": 1519355674745, "tcdate": 1509074627666, "number": 229, "cdate": 1518730184646, "id": "Hk2aImxAb", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "Hk2aImxAb", "original": "BJ9TUmlR-", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "Multi-Scale Dense Networks for Resource Efficient Image Classification", "abstract": "In this paper we investigate image classification with computational resource limits at test time. Two such settings are: 1. anytime classification, where the network\u2019s prediction for a test example is progressively updated, facilitating the output of a prediction at any time; and 2. budgeted batch classification, where a fixed amount of computation is available to classify a set of examples that can be spent unevenly across \u201ceasier\u201d and \u201charder\u201d inputs. In contrast to most prior work, such as the popular Viola and Jones algorithm, our approach is based on convolutional neural networks. We train multiple classifiers with varying resource demands, which we adaptively apply during test time. To maximally re-use computation between the classifiers, we incorporate them as early-exits into a single deep convolutional neural network and inter-connect them with dense connectivity. To facilitate high quality classification early on, we use a two-dimensional multi-scale network architecture that maintains coarse and fine level features all-throughout the network. Experiments on three image-classification tasks demonstrate that our framework substantially improves the existing state-of-the-art in both settings.", "pdf": "/pdf/b92cc4191e13816cacce262b4e421aac1052ec10.pdf", "paperhash": "huang|multiscale_dense_networks_for_resource_efficient_image_classification", "_bibtex": "@inproceedings{\nhuang2018multiscale,\ntitle={Multi-Scale Dense Networks for Resource Efficient Image Classification},\nauthor={Gao Huang and Danlu Chen and Tianhong Li and Felix Wu and Laurens van der Maaten and Kilian Weinberger},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=Hk2aImxAb},\n}", "keywords": ["efficient learning", "budgeted learning", "deep learning", "image classification", "convolutional networks"], "authors": ["Gao Huang", "Danlu Chen", "Tianhong Li", "Felix Wu", "Laurens van der Maaten", "Kilian Weinberger"], "authorids": ["gh349@cornell.edu", "taineleau@gmail.com", "lth14@mails.tsinghua.edu.cn", "fw245@cornell.edu", "lvdmaaten@fb.com", "kqw4@cornell.edu"]}, "nonreaders": [], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}}, "tauthor": "ICLR.cc/2018/Conference"}, {"tddate": null, "ddate": null, "tmdate": 1518025631543, "tcdate": 1518025631543, "number": 1, "cdate": 1518025631543, "id": "r1wisn_UM", "invitation": "ICLR.cc/2018/Conference/-/Paper229/Public_Comment", "forum": "Hk2aImxAb", "replyto": "Hk2aImxAb", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Reproducibility challenge report", "comment": "Summary\n* We've run the actual implementation. The net worked really well, so we focused on implementing it in PyTorch and testing on other datasets (CIFAR-10 and Caltech 101).\n* We've checked if training large network (with multiple classifiers) and using just a part of it during testing is possible (we can use earlier classifiers as an early-exits) and what are the results. It's actually working and yielding great results.\n\nLink to the full report here: https://github.com/janchorowski/nn_assignments/blob/nn17_fall/project_reports/MSDNet/REPORT.md"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-Scale Dense Networks for Resource Efficient Image Classification", "abstract": "In this paper we investigate image classification with computational resource limits at test time. Two such settings are: 1. anytime classification, where the network\u2019s prediction for a test example is progressively updated, facilitating the output of a prediction at any time; and 2. budgeted batch classification, where a fixed amount of computation is available to classify a set of examples that can be spent unevenly across \u201ceasier\u201d and \u201charder\u201d inputs. In contrast to most prior work, such as the popular Viola and Jones algorithm, our approach is based on convolutional neural networks. We train multiple classifiers with varying resource demands, which we adaptively apply during test time. To maximally re-use computation between the classifiers, we incorporate them as early-exits into a single deep convolutional neural network and inter-connect them with dense connectivity. To facilitate high quality classification early on, we use a two-dimensional multi-scale network architecture that maintains coarse and fine level features all-throughout the network. Experiments on three image-classification tasks demonstrate that our framework substantially improves the existing state-of-the-art in both settings.", "pdf": "/pdf/b92cc4191e13816cacce262b4e421aac1052ec10.pdf", "paperhash": "huang|multiscale_dense_networks_for_resource_efficient_image_classification", "_bibtex": "@inproceedings{\nhuang2018multiscale,\ntitle={Multi-Scale Dense Networks for Resource Efficient Image Classification},\nauthor={Gao Huang and Danlu Chen and Tianhong Li and Felix Wu and Laurens van der Maaten and Kilian Weinberger},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=Hk2aImxAb},\n}", "keywords": ["efficient learning", "budgeted learning", "deep learning", "image classification", "convolutional networks"], "authors": ["Gao Huang", "Danlu Chen", "Tianhong Li", "Felix Wu", "Laurens van der Maaten", "Kilian Weinberger"], "authorids": ["gh349@cornell.edu", "taineleau@gmail.com", "lth14@mails.tsinghua.edu.cn", "fw245@cornell.edu", "lvdmaaten@fb.com", "kqw4@cornell.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791690532, "id": "ICLR.cc/2018/Conference/-/Paper229/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "Hk2aImxAb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper229/Authors", "ICLR.cc/2018/Conference/Paper229/Reviewers", "ICLR.cc/2018/Conference/Paper229/Area_Chair"], "cdate": 1512791690532}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1517260101414, "tcdate": 1517249182210, "number": 3, "cdate": 1517249182192, "id": "S1LszJpSz", "invitation": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "forum": "Hk2aImxAb", "replyto": "Hk2aImxAb", "signatures": ["ICLR.cc/2018/Conference/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Program_Chairs"], "content": {"title": "ICLR 2018 Conference Acceptance Decision", "comment": "As stated by reviewer 3 \"This paper introduces a new model to perform image classification with limited computational resources at test time. The model is based on a multi-scale convolutional neural network similar to the neural fabric (Saxena and Verbeek 2016), but with dense connections (Huang et al., 2017) and with a classifier at each layer.\"\nAs stated by reviewer 2 \"My only major concern is the degree of technical novelty with respect to the original DenseNet paper of Huang et al. (2017). \".  The authors assert novelty in the sense that they provide a solution to improve computational efficiency and focus on this aspect of the problem. Overall, the technical innovation is not huge, but I think this could be a very useful idea in practice.\n", "decision": "Accept (Oral)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-Scale Dense Networks for Resource Efficient Image Classification", "abstract": "In this paper we investigate image classification with computational resource limits at test time. Two such settings are: 1. anytime classification, where the network\u2019s prediction for a test example is progressively updated, facilitating the output of a prediction at any time; and 2. budgeted batch classification, where a fixed amount of computation is available to classify a set of examples that can be spent unevenly across \u201ceasier\u201d and \u201charder\u201d inputs. In contrast to most prior work, such as the popular Viola and Jones algorithm, our approach is based on convolutional neural networks. We train multiple classifiers with varying resource demands, which we adaptively apply during test time. To maximally re-use computation between the classifiers, we incorporate them as early-exits into a single deep convolutional neural network and inter-connect them with dense connectivity. To facilitate high quality classification early on, we use a two-dimensional multi-scale network architecture that maintains coarse and fine level features all-throughout the network. Experiments on three image-classification tasks demonstrate that our framework substantially improves the existing state-of-the-art in both settings.", "pdf": "/pdf/b92cc4191e13816cacce262b4e421aac1052ec10.pdf", "paperhash": "huang|multiscale_dense_networks_for_resource_efficient_image_classification", "_bibtex": "@inproceedings{\nhuang2018multiscale,\ntitle={Multi-Scale Dense Networks for Resource Efficient Image Classification},\nauthor={Gao Huang and Danlu Chen and Tianhong Li and Felix Wu and Laurens van der Maaten and Kilian Weinberger},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=Hk2aImxAb},\n}", "keywords": ["efficient learning", "budgeted learning", "deep learning", "image classification", "convolutional networks"], "authors": ["Gao Huang", "Danlu Chen", "Tianhong Li", "Felix Wu", "Laurens van der Maaten", "Kilian Weinberger"], "authorids": ["gh349@cornell.edu", "taineleau@gmail.com", "lth14@mails.tsinghua.edu.cn", "fw245@cornell.edu", "lvdmaaten@fb.com", "kqw4@cornell.edu"]}, "tags": [], "invitation": {"id": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "rdate": null, "ddate": null, "expdate": 1541175629000, "duedate": null, "tmdate": 1541177635767, "tddate": null, "super": null, "final": null, "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": {"values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Conference/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Conference Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": [], "noninvitees": [], "writers": ["ICLR.cc/2018/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1541177635767}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642413495, "tcdate": 1511432045514, "number": 1, "cdate": 1511432045514, "id": "rJSuJm4lG", "invitation": "ICLR.cc/2018/Conference/-/Paper229/Official_Review", "forum": "Hk2aImxAb", "replyto": "Hk2aImxAb", "signatures": ["ICLR.cc/2018/Conference/Paper229/AnonReviewer2"], "readers": ["everyone"], "content": {"title": "This is a well written paper that incorporates CPU budgets at test time via a multi-scale design of the DenseNet architecture.", "rating": "8: Top 50% of accepted papers, clear accept", "review": "This work proposes a variation of the DenseNet architecture that can cope with computational resource limits at test time. The paper is very well written, experiments are clearly presented and convincing and, most importantly, the research question is exciting (and often overlooked). \n\nMy only major concern is the degree of technical novelty with respect to the original DenseNet paper of Huang et al. (2017). The authors add a hierarchical, multi-scale structure and show that DenseNet can better cope with it than ResNet (e.g., Fig. 3). They investigate pros and cons in detail adding more valuable analysis in the appendix. However, this work is basically an extension of the DenseNet approach with a new problem statement and additional, in-depth analysis.   \n\nSome more minor comments: \n\n-\tPlease enlarge Fig. 4. \n-\tI did not fully grasp the details in the first \"Solution\" paragraph on P5. Please extend and describe in more detail. \n\nIn conclusion, this is a very well written paper that designs the network architecture (of DenseNet) such that it is optimized to include CPU budgets at test time. I recommend acceptance to ICLR18.\n    \n\n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-Scale Dense Networks for Resource Efficient Image Classification", "abstract": "In this paper we investigate image classification with computational resource limits at test time. Two such settings are: 1. anytime classification, where the network\u2019s prediction for a test example is progressively updated, facilitating the output of a prediction at any time; and 2. budgeted batch classification, where a fixed amount of computation is available to classify a set of examples that can be spent unevenly across \u201ceasier\u201d and \u201charder\u201d inputs. In contrast to most prior work, such as the popular Viola and Jones algorithm, our approach is based on convolutional neural networks. We train multiple classifiers with varying resource demands, which we adaptively apply during test time. To maximally re-use computation between the classifiers, we incorporate them as early-exits into a single deep convolutional neural network and inter-connect them with dense connectivity. To facilitate high quality classification early on, we use a two-dimensional multi-scale network architecture that maintains coarse and fine level features all-throughout the network. Experiments on three image-classification tasks demonstrate that our framework substantially improves the existing state-of-the-art in both settings.", "pdf": "/pdf/b92cc4191e13816cacce262b4e421aac1052ec10.pdf", "paperhash": "huang|multiscale_dense_networks_for_resource_efficient_image_classification", "_bibtex": "@inproceedings{\nhuang2018multiscale,\ntitle={Multi-Scale Dense Networks for Resource Efficient Image Classification},\nauthor={Gao Huang and Danlu Chen and Tianhong Li and Felix Wu and Laurens van der Maaten and Kilian Weinberger},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=Hk2aImxAb},\n}", "keywords": ["efficient learning", "budgeted learning", "deep learning", "image classification", "convolutional networks"], "authors": ["Gao Huang", "Danlu Chen", "Tianhong Li", "Felix Wu", "Laurens van der Maaten", "Kilian Weinberger"], "authorids": ["gh349@cornell.edu", "taineleau@gmail.com", "lth14@mails.tsinghua.edu.cn", "fw245@cornell.edu", "lvdmaaten@fb.com", "kqw4@cornell.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642413392, "id": "ICLR.cc/2018/Conference/-/Paper229/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper229/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper229/AnonReviewer2", "ICLR.cc/2018/Conference/Paper229/AnonReviewer1", "ICLR.cc/2018/Conference/Paper229/AnonReviewer3"], "reply": {"forum": "Hk2aImxAb", "replyto": "Hk2aImxAb", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper229/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642413392}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642413457, "tcdate": 1511808491283, "number": 2, "cdate": 1511808491283, "id": "SJ7lAAYgG", "invitation": "ICLR.cc/2018/Conference/-/Paper229/Official_Review", "forum": "Hk2aImxAb", "replyto": "Hk2aImxAb", "signatures": ["ICLR.cc/2018/Conference/Paper229/AnonReviewer1"], "readers": ["everyone"], "content": {"title": "clear and effective method connecting image scale and evaluation times", "rating": "7: Good paper, accept", "review": "This paper presents a method for image classification given test-time computational budgeting constraints.  Two problems are considered:  \"any-time\" classification, in which there is a time constraint to evaluate a single example, and batched budgets, in which there is a fixed budget available to classify a large batch of images.  A convolutional neural network structure with a diagonal propagation layout over depth and scale is used, so that each activation map is constructed using dense connections from both same and finer scale features.  In this way, coarse-scale maps are constructed quickly, then continuously updated with feed-forward propagation from lower layers and finer scales, so they can be used for image classification at any intermediate stage.  Evaluations are performed on ImageNet and CIFAR-100.\n\nI would have liked to see the MC baselines also evaluated on ImageNet --- I'm not sure why they aren't there as well?  Also on p.6 I'm not entirely clear on how the \"network reduction\" is performed --- it looks like finer scales are progressively dropped in successive blocks, but I don't think they exactly correspond to those that would be needed to evaluate the full model (this is \"lazy evaluation\").  A picture would help here, showing where the depth-layers are divided between blocks.\n\nI was also initially a bit unclear on how the procedure described for batched budgeted evaluation achieves the desired result:  It seems this relies on having a batch that is both large and varied, so that its evaluation time will converge towards the expectation.  So this isn't really a hard constraint (just an expected result for batches that are large and varied enough).  This is fine, but could perhaps be pointed out if that is indeed the case.\n\nOverall, this seems like a natural and effective approach, and achieves good results.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-Scale Dense Networks for Resource Efficient Image Classification", "abstract": "In this paper we investigate image classification with computational resource limits at test time. Two such settings are: 1. anytime classification, where the network\u2019s prediction for a test example is progressively updated, facilitating the output of a prediction at any time; and 2. budgeted batch classification, where a fixed amount of computation is available to classify a set of examples that can be spent unevenly across \u201ceasier\u201d and \u201charder\u201d inputs. In contrast to most prior work, such as the popular Viola and Jones algorithm, our approach is based on convolutional neural networks. We train multiple classifiers with varying resource demands, which we adaptively apply during test time. To maximally re-use computation between the classifiers, we incorporate them as early-exits into a single deep convolutional neural network and inter-connect them with dense connectivity. To facilitate high quality classification early on, we use a two-dimensional multi-scale network architecture that maintains coarse and fine level features all-throughout the network. Experiments on three image-classification tasks demonstrate that our framework substantially improves the existing state-of-the-art in both settings.", "pdf": "/pdf/b92cc4191e13816cacce262b4e421aac1052ec10.pdf", "paperhash": "huang|multiscale_dense_networks_for_resource_efficient_image_classification", "_bibtex": "@inproceedings{\nhuang2018multiscale,\ntitle={Multi-Scale Dense Networks for Resource Efficient Image Classification},\nauthor={Gao Huang and Danlu Chen and Tianhong Li and Felix Wu and Laurens van der Maaten and Kilian Weinberger},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=Hk2aImxAb},\n}", "keywords": ["efficient learning", "budgeted learning", "deep learning", "image classification", "convolutional networks"], "authors": ["Gao Huang", "Danlu Chen", "Tianhong Li", "Felix Wu", "Laurens van der Maaten", "Kilian Weinberger"], "authorids": ["gh349@cornell.edu", "taineleau@gmail.com", "lth14@mails.tsinghua.edu.cn", "fw245@cornell.edu", "lvdmaaten@fb.com", "kqw4@cornell.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642413392, "id": "ICLR.cc/2018/Conference/-/Paper229/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper229/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper229/AnonReviewer2", "ICLR.cc/2018/Conference/Paper229/AnonReviewer1", "ICLR.cc/2018/Conference/Paper229/AnonReviewer3"], "reply": {"forum": "Hk2aImxAb", "replyto": "Hk2aImxAb", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper229/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642413392}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642413419, "tcdate": 1511845365149, "number": 3, "cdate": 1511845365149, "id": "rk6gRwcxz", "invitation": "ICLR.cc/2018/Conference/-/Paper229/Official_Review", "forum": "Hk2aImxAb", "replyto": "Hk2aImxAb", "signatures": ["ICLR.cc/2018/Conference/Paper229/AnonReviewer3"], "readers": ["everyone"], "content": {"title": "Great speed-up and performance for CNN classification", "rating": "10: Top 5% of accepted papers, seminal paper", "review": "This paper introduces a new model to perform image classification with limited computational resources at test time. The model is based on a multi-scale convolutional neural network similar to the neural fabric (Saxena and Verbeek 2016), but with dense connections (Huang et al., 2017) and with a classifier at each layer. The multiple classifiers allow for a finer selection of the amount of computation needed for a given input image. The multi-scale representation allows for better performance at early stages of the network. Finally the dense connectivity allows to reduce the negative effect that early classifiers have on the feature representation for the following layers.\nA thorough evaluation on ImageNet and Cifar100 shows that the network can perform better than previous models and ensembles of previous models with a reduced amount of computation.\n\nPros:\n- The presentation is clear and easy to follow.\n- The structure of the network is clearly justified in section 4.\n- The use of dense connectivity to avoid the loss of performance of using early-exit classifier is very interesting.\n- The evaluation in terms of anytime prediction and budgeted batch classification can represent real case scenarios.\n- Results are very promising, with 5x speed-ups and same or better accuracy that previous models.\n- The extensive experimentation shows that the proposed network is better than previous approaches under different regimes.\n\nCons:\n- Results about the more efficient densenet* could be shown in the main paper\n\nAdditional Comments:\n- Why in training you used logistic loss instead of the more common cross-entropy loss? Has this any connection with the final performance of the network?\n- In fig. 5 left for completeness I would like to see also results for DenseNet^MT and ResNet^MT\n- In fig. 5 left I cannot find the 4% and 8% higher accuracy with 0.5x10^10 to 1.0x10^10 FLOPs, as mentioned in section 5.1 anytime prediction results\n- How the budget in terms of Mul-Adds is actually estimated?\n\nI think that this paper present a very powerful approach to speed-up the computational cost of a CNN at test time and clearly explains some of the common trade-offs between speed and accuracy and how to improve them. The experimental evaluation is complete and accurate. \n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-Scale Dense Networks for Resource Efficient Image Classification", "abstract": "In this paper we investigate image classification with computational resource limits at test time. Two such settings are: 1. anytime classification, where the network\u2019s prediction for a test example is progressively updated, facilitating the output of a prediction at any time; and 2. budgeted batch classification, where a fixed amount of computation is available to classify a set of examples that can be spent unevenly across \u201ceasier\u201d and \u201charder\u201d inputs. In contrast to most prior work, such as the popular Viola and Jones algorithm, our approach is based on convolutional neural networks. We train multiple classifiers with varying resource demands, which we adaptively apply during test time. To maximally re-use computation between the classifiers, we incorporate them as early-exits into a single deep convolutional neural network and inter-connect them with dense connectivity. To facilitate high quality classification early on, we use a two-dimensional multi-scale network architecture that maintains coarse and fine level features all-throughout the network. Experiments on three image-classification tasks demonstrate that our framework substantially improves the existing state-of-the-art in both settings.", "pdf": "/pdf/b92cc4191e13816cacce262b4e421aac1052ec10.pdf", "paperhash": "huang|multiscale_dense_networks_for_resource_efficient_image_classification", "_bibtex": "@inproceedings{\nhuang2018multiscale,\ntitle={Multi-Scale Dense Networks for Resource Efficient Image Classification},\nauthor={Gao Huang and Danlu Chen and Tianhong Li and Felix Wu and Laurens van der Maaten and Kilian Weinberger},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=Hk2aImxAb},\n}", "keywords": ["efficient learning", "budgeted learning", "deep learning", "image classification", "convolutional networks"], "authors": ["Gao Huang", "Danlu Chen", "Tianhong Li", "Felix Wu", "Laurens van der Maaten", "Kilian Weinberger"], "authorids": ["gh349@cornell.edu", "taineleau@gmail.com", "lth14@mails.tsinghua.edu.cn", "fw245@cornell.edu", "lvdmaaten@fb.com", "kqw4@cornell.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642413392, "id": "ICLR.cc/2018/Conference/-/Paper229/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper229/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper229/AnonReviewer2", "ICLR.cc/2018/Conference/Paper229/AnonReviewer1", "ICLR.cc/2018/Conference/Paper229/AnonReviewer3"], "reply": {"forum": "Hk2aImxAb", "replyto": "Hk2aImxAb", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper229/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642413392}}}, {"tddate": null, "ddate": null, "tmdate": 1515072031661, "tcdate": 1515072031661, "number": 3, "cdate": 1515072031661, "id": "Hy_75oomz", "invitation": "ICLR.cc/2018/Conference/-/Paper229/Official_Comment", "forum": "Hk2aImxAb", "replyto": "rJSuJm4lG", "signatures": ["ICLR.cc/2018/Conference/Paper229/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper229/Authors"], "content": {"title": "response", "comment": "Thanks for positive comments. \n\n# difference to DenseNet\nAlthough dense connectivity is one of the two key components in our MSDNet, this paper is quite different from the original DenseNet paper: (1) in this paper we tackle a very different problem, the inference of deep models with computational resource limits at test time; (2) we show the multi-scale features are crucial for learning accurate early classifiers. Finally, MSDNet yields 2x to 5x faster inference speed than DenseNet under the batch budgeted setting.\n\n# minors\nThanks for these suggestions. We have incorporated them in the updated version."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-Scale Dense Networks for Resource Efficient Image Classification", "abstract": "In this paper we investigate image classification with computational resource limits at test time. Two such settings are: 1. anytime classification, where the network\u2019s prediction for a test example is progressively updated, facilitating the output of a prediction at any time; and 2. budgeted batch classification, where a fixed amount of computation is available to classify a set of examples that can be spent unevenly across \u201ceasier\u201d and \u201charder\u201d inputs. In contrast to most prior work, such as the popular Viola and Jones algorithm, our approach is based on convolutional neural networks. We train multiple classifiers with varying resource demands, which we adaptively apply during test time. To maximally re-use computation between the classifiers, we incorporate them as early-exits into a single deep convolutional neural network and inter-connect them with dense connectivity. To facilitate high quality classification early on, we use a two-dimensional multi-scale network architecture that maintains coarse and fine level features all-throughout the network. Experiments on three image-classification tasks demonstrate that our framework substantially improves the existing state-of-the-art in both settings.", "pdf": "/pdf/b92cc4191e13816cacce262b4e421aac1052ec10.pdf", "paperhash": "huang|multiscale_dense_networks_for_resource_efficient_image_classification", "_bibtex": "@inproceedings{\nhuang2018multiscale,\ntitle={Multi-Scale Dense Networks for Resource Efficient Image Classification},\nauthor={Gao Huang and Danlu Chen and Tianhong Li and Felix Wu and Laurens van der Maaten and Kilian Weinberger},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=Hk2aImxAb},\n}", "keywords": ["efficient learning", "budgeted learning", "deep learning", "image classification", "convolutional networks"], "authors": ["Gao Huang", "Danlu Chen", "Tianhong Li", "Felix Wu", "Laurens van der Maaten", "Kilian Weinberger"], "authorids": ["gh349@cornell.edu", "taineleau@gmail.com", "lth14@mails.tsinghua.edu.cn", "fw245@cornell.edu", "lvdmaaten@fb.com", "kqw4@cornell.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825737187, "id": "ICLR.cc/2018/Conference/-/Paper229/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "Hk2aImxAb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper229/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper229/Authors|ICLR.cc/2018/Conference/Paper229/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper229/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper229/Authors|ICLR.cc/2018/Conference/Paper229/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper229/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper229/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper229/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper229/Reviewers", "ICLR.cc/2018/Conference/Paper229/Authors", "ICLR.cc/2018/Conference/Paper229/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825737187}}}, {"tddate": null, "ddate": null, "tmdate": 1515071943308, "tcdate": 1515071943308, "number": 2, "cdate": 1515071943308, "id": "HkJRFjomf", "invitation": "ICLR.cc/2018/Conference/-/Paper229/Official_Comment", "forum": "Hk2aImxAb", "replyto": "SJ7lAAYgG", "signatures": ["ICLR.cc/2018/Conference/Paper229/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper229/Authors"], "content": {"title": "Response", "comment": "Thanks for the positive comments.\n\n# MC baselines on ImageNet\nWe exclude these results in our current version as we observed that they are far from competitive on both CIFAR-10 and CIFAR-100. We are testing the MC baselines on ImageNet, and will include it in a later version, but won\u2019t expect them to be strong baselines.\n\n# network reduction\nThe \u2018network reduction\u2019 is a design choice to reduce redundancy in the network, while \u2018lazy evaluation\u2019 is a strategy to avoid redundant computations. We have added a figure (Figure 9) in the appendix to illustrate the reduced network as suggested. \n\n# batched budgeted evaluation\nThanks for pointing out. We have emphasize that the notion of budget in this context is a \u201csoft constraint\u201d given a large batch of testing samples."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-Scale Dense Networks for Resource Efficient Image Classification", "abstract": "In this paper we investigate image classification with computational resource limits at test time. Two such settings are: 1. anytime classification, where the network\u2019s prediction for a test example is progressively updated, facilitating the output of a prediction at any time; and 2. budgeted batch classification, where a fixed amount of computation is available to classify a set of examples that can be spent unevenly across \u201ceasier\u201d and \u201charder\u201d inputs. In contrast to most prior work, such as the popular Viola and Jones algorithm, our approach is based on convolutional neural networks. We train multiple classifiers with varying resource demands, which we adaptively apply during test time. To maximally re-use computation between the classifiers, we incorporate them as early-exits into a single deep convolutional neural network and inter-connect them with dense connectivity. To facilitate high quality classification early on, we use a two-dimensional multi-scale network architecture that maintains coarse and fine level features all-throughout the network. Experiments on three image-classification tasks demonstrate that our framework substantially improves the existing state-of-the-art in both settings.", "pdf": "/pdf/b92cc4191e13816cacce262b4e421aac1052ec10.pdf", "paperhash": "huang|multiscale_dense_networks_for_resource_efficient_image_classification", "_bibtex": "@inproceedings{\nhuang2018multiscale,\ntitle={Multi-Scale Dense Networks for Resource Efficient Image Classification},\nauthor={Gao Huang and Danlu Chen and Tianhong Li and Felix Wu and Laurens van der Maaten and Kilian Weinberger},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=Hk2aImxAb},\n}", "keywords": ["efficient learning", "budgeted learning", "deep learning", "image classification", "convolutional networks"], "authors": ["Gao Huang", "Danlu Chen", "Tianhong Li", "Felix Wu", "Laurens van der Maaten", "Kilian Weinberger"], "authorids": ["gh349@cornell.edu", "taineleau@gmail.com", "lth14@mails.tsinghua.edu.cn", "fw245@cornell.edu", "lvdmaaten@fb.com", "kqw4@cornell.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825737187, "id": "ICLR.cc/2018/Conference/-/Paper229/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "Hk2aImxAb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper229/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper229/Authors|ICLR.cc/2018/Conference/Paper229/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper229/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper229/Authors|ICLR.cc/2018/Conference/Paper229/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper229/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper229/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper229/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper229/Reviewers", "ICLR.cc/2018/Conference/Paper229/Authors", "ICLR.cc/2018/Conference/Paper229/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825737187}}}, {"tddate": null, "ddate": null, "tmdate": 1515071778598, "tcdate": 1515071778598, "number": 1, "cdate": 1515071778598, "id": "HJiXYjjQz", "invitation": "ICLR.cc/2018/Conference/-/Paper229/Official_Comment", "forum": "Hk2aImxAb", "replyto": "rk6gRwcxz", "signatures": ["ICLR.cc/2018/Conference/Paper229/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper229/Authors"], "content": {"title": "Response", "comment": "Thank you for the encouraging comments! \n\n# DenseNet*\nWe have included the DenseNet* results in the main paper as suggested. We placed this network originally in the appendix to keep the focus of the main manuscript on the MSDNet architecture, and it was introduced for the first time in this paper (although as a competitive baseline).\n\n# logistic loss\nWe actually used the cross entropy loss in our experiments. We have fixed this sentence. Thanks for pointing out.\n\n# DenseNet^MC and ResNet^MC on ImageNet (left panel of Fig.5)\nWe observed that DenseNet^MC and ResNet^MC are two of the weakest baselines on both CIFAR-10 and CIFAR-100 datasets. Therefore, we thought their results on ImageNet probably won\u2019t add much to the paper. We can add these results in a later version.\n\n# improvements in the anytime setting\nIt should be 4% and 8% higher accuracy when the budget ranges from 0.1x10^10* to 0.3x10^10* FLOPs. We have corrected it in the updated version.\n\n# actually budget\nFor many devices, e.g., ARM processor, the actual inference time is basically a linear function of the number of Mul-Add operations. Thus in practice, given a specific device, we can estimate the budget in terms of Mul-Add according to the real time budget."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Multi-Scale Dense Networks for Resource Efficient Image Classification", "abstract": "In this paper we investigate image classification with computational resource limits at test time. Two such settings are: 1. anytime classification, where the network\u2019s prediction for a test example is progressively updated, facilitating the output of a prediction at any time; and 2. budgeted batch classification, where a fixed amount of computation is available to classify a set of examples that can be spent unevenly across \u201ceasier\u201d and \u201charder\u201d inputs. In contrast to most prior work, such as the popular Viola and Jones algorithm, our approach is based on convolutional neural networks. We train multiple classifiers with varying resource demands, which we adaptively apply during test time. To maximally re-use computation between the classifiers, we incorporate them as early-exits into a single deep convolutional neural network and inter-connect them with dense connectivity. To facilitate high quality classification early on, we use a two-dimensional multi-scale network architecture that maintains coarse and fine level features all-throughout the network. Experiments on three image-classification tasks demonstrate that our framework substantially improves the existing state-of-the-art in both settings.", "pdf": "/pdf/b92cc4191e13816cacce262b4e421aac1052ec10.pdf", "paperhash": "huang|multiscale_dense_networks_for_resource_efficient_image_classification", "_bibtex": "@inproceedings{\nhuang2018multiscale,\ntitle={Multi-Scale Dense Networks for Resource Efficient Image Classification},\nauthor={Gao Huang and Danlu Chen and Tianhong Li and Felix Wu and Laurens van der Maaten and Kilian Weinberger},\nbooktitle={International Conference on Learning Representations},\nyear={2018},\nurl={https://openreview.net/forum?id=Hk2aImxAb},\n}", "keywords": ["efficient learning", "budgeted learning", "deep learning", "image classification", "convolutional networks"], "authors": ["Gao Huang", "Danlu Chen", "Tianhong Li", "Felix Wu", "Laurens van der Maaten", "Kilian Weinberger"], "authorids": ["gh349@cornell.edu", "taineleau@gmail.com", "lth14@mails.tsinghua.edu.cn", "fw245@cornell.edu", "lvdmaaten@fb.com", "kqw4@cornell.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825737187, "id": "ICLR.cc/2018/Conference/-/Paper229/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "Hk2aImxAb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper229/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper229/Authors|ICLR.cc/2018/Conference/Paper229/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper229/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper229/Authors|ICLR.cc/2018/Conference/Paper229/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper229/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper229/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper229/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper229/Reviewers", "ICLR.cc/2018/Conference/Paper229/Authors", "ICLR.cc/2018/Conference/Paper229/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825737187}}}], "count": 10}