{"notes": [{"id": "r1lpx3A9K7", "original": "SJlfQAp9t7", "number": 1120, "cdate": 1538087924994, "ddate": null, "tcdate": 1538087924994, "tmdate": 1545355436445, "tddate": null, "forum": "r1lpx3A9K7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Featurized Bidirectional GAN: Adversarial Defense via Adversarially Learned Semantic Inference", "abstract": "Deep neural networks have been demonstrated to be vulnerable to adversarial attacks, where small perturbations intentionally added to the original inputs can fool the classifier. In this paper, we propose a defense method, Featurized Bidirectional Generative Adversarial Networks (FBGAN), to extract the semantic features of the input and filter the non-semantic perturbation. FBGAN is pre-trained on the clean dataset in an unsupervised manner, adversarially learning a bidirectional mapping between a high-dimensional data space and a low-dimensional semantic space; also mutual information is applied to disentangle the semantically meaningful features. After the bidirectional mapping, the adversarial data can be reconstructed to denoised data, which could be fed into any pre-trained classifier. We empirically show the quality of reconstruction images and the effectiveness of defense.", "keywords": [], "authorids": ["rbao@princeton.edu", "sihangl@princeton.edu", "qingcanw@princeton.edu"], "authors": ["Ruying Bao", "Sihang Liang", "Qingcan Wang"], "pdf": "/pdf/9738a275f7113bead3ff53fb05b6e5620a9f6e1b.pdf", "paperhash": "bao|featurized_bidirectional_gan_adversarial_defense_via_adversarially_learned_semantic_inference", "_bibtex": "@misc{\nbao2019featurized,\ntitle={Featurized Bidirectional {GAN}: Adversarial Defense via Adversarially Learned Semantic Inference},\nauthor={Ruying Bao and Sihang Liang and Qingcan Wang},\nyear={2019},\nurl={https://openreview.net/forum?id=r1lpx3A9K7},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "rJgqyiqHl4", "original": null, "number": 1, "cdate": 1545083617747, "ddate": null, "tcdate": 1545083617747, "tmdate": 1545354480571, "tddate": null, "forum": "r1lpx3A9K7", "replyto": "r1lpx3A9K7", "invitation": "ICLR.cc/2019/Conference/-/Paper1120/Meta_Review", "content": {"metareview": "The reviewers agree the paper is not ready for publication. ", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "Reject"}, "signatures": ["ICLR.cc/2019/Conference/Paper1120/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1120/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Featurized Bidirectional GAN: Adversarial Defense via Adversarially Learned Semantic Inference", "abstract": "Deep neural networks have been demonstrated to be vulnerable to adversarial attacks, where small perturbations intentionally added to the original inputs can fool the classifier. In this paper, we propose a defense method, Featurized Bidirectional Generative Adversarial Networks (FBGAN), to extract the semantic features of the input and filter the non-semantic perturbation. FBGAN is pre-trained on the clean dataset in an unsupervised manner, adversarially learning a bidirectional mapping between a high-dimensional data space and a low-dimensional semantic space; also mutual information is applied to disentangle the semantically meaningful features. After the bidirectional mapping, the adversarial data can be reconstructed to denoised data, which could be fed into any pre-trained classifier. We empirically show the quality of reconstruction images and the effectiveness of defense.", "keywords": [], "authorids": ["rbao@princeton.edu", "sihangl@princeton.edu", "qingcanw@princeton.edu"], "authors": ["Ruying Bao", "Sihang Liang", "Qingcan Wang"], "pdf": "/pdf/9738a275f7113bead3ff53fb05b6e5620a9f6e1b.pdf", "paperhash": "bao|featurized_bidirectional_gan_adversarial_defense_via_adversarially_learned_semantic_inference", "_bibtex": "@misc{\nbao2019featurized,\ntitle={Featurized Bidirectional {GAN}: Adversarial Defense via Adversarially Learned Semantic Inference},\nauthor={Ruying Bao and Sihang Liang and Qingcan Wang},\nyear={2019},\nurl={https://openreview.net/forum?id=r1lpx3A9K7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1120/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352959399, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1lpx3A9K7", "replyto": "r1lpx3A9K7", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1120/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1120/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1120/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352959399}}}, {"id": "r1lOxLgv3X", "original": null, "number": 2, "cdate": 1540978159692, "ddate": null, "tcdate": 1540978159692, "tmdate": 1543309688148, "tddate": null, "forum": "r1lpx3A9K7", "replyto": "r1lpx3A9K7", "invitation": "ICLR.cc/2019/Conference/-/Paper1120/Official_Review", "content": {"title": "Novelty and evidence is not yet sufficiently clarified", "review": "This work proposes to defend against adversarial examples by \u201cdenoising\u201d the input image through an autoencoder (a BiGAN trained similar to InfoGAN) before classifying it with a standard CNN. The robustness of the model is evaluated on the L_infinity metric against FGSM and PGD.\n\nMy main criticism is as follows:\n* Novelty: several defences are based on a similar principle and the contributions of this paper are unclear.\n* Insufficient evidence: The evaluation is minimal (only FGSM and PGD, no decision-, transfer- or score-based attacks) and insufficient to support the claims.\n* Gradient masking: There is at least one clear sign of gradient masking in the results (FGSM performing better than PGD).\n\n### Novelty\nThe only prior work against which the paper compares is DefenseGAN. The only advantage over DefenseGAN being stated is performance (because no intermediate optimisation step is used). However, besides DefenseGAN there are several other defences that project the input onto the learned manifold of \u201cnatural\u201d inputs, including (see prior work section in [1] for an up-to-date list):\n\n* Adversarial Perturbation Elimination GAN\n* Robust Manifold Defense\n* PixelDefend (autoregressive probabilistic model)\n* MagNets\n\n### Insufficient evidence\nThe only attacks employed are two gradient-based techniques (FGSM and PGD). It is known that gradient-based techniques may suffer from gradient-masking (see also next point) and that the effectiveness of different attacks various greatly (which is why one should use many different attacks). Hence, a full evaluation of the model should include score-based and decision-based attacks.\n\n### Gradient masking\nIn Figure 5 (b) the FGSM attack performs better than PGD for epsilon = 0.05 (66.4% vs 71.5%). PGD, however, should be strictly more powerful than FGSM if the gradients and the hyperparameters are ok.\n\nGradient masking is the primary reason for why 95% of all proposed defences turned out to be ineffective, and there are good reasons to believe that the same might affect this defence. The robustness evaluation has to be much more thorough and convincing before any substantiated claims about the bidirectional architecture proposed here can be derived. In addition, the difference to prior work has to be made much clearer.\n\n[1] Schott et al. \u201cTowards the first adversarially robust neural network model on MNIST\u201d", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper1120/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Featurized Bidirectional GAN: Adversarial Defense via Adversarially Learned Semantic Inference", "abstract": "Deep neural networks have been demonstrated to be vulnerable to adversarial attacks, where small perturbations intentionally added to the original inputs can fool the classifier. In this paper, we propose a defense method, Featurized Bidirectional Generative Adversarial Networks (FBGAN), to extract the semantic features of the input and filter the non-semantic perturbation. FBGAN is pre-trained on the clean dataset in an unsupervised manner, adversarially learning a bidirectional mapping between a high-dimensional data space and a low-dimensional semantic space; also mutual information is applied to disentangle the semantically meaningful features. After the bidirectional mapping, the adversarial data can be reconstructed to denoised data, which could be fed into any pre-trained classifier. We empirically show the quality of reconstruction images and the effectiveness of defense.", "keywords": [], "authorids": ["rbao@princeton.edu", "sihangl@princeton.edu", "qingcanw@princeton.edu"], "authors": ["Ruying Bao", "Sihang Liang", "Qingcan Wang"], "pdf": "/pdf/9738a275f7113bead3ff53fb05b6e5620a9f6e1b.pdf", "paperhash": "bao|featurized_bidirectional_gan_adversarial_defense_via_adversarially_learned_semantic_inference", "_bibtex": "@misc{\nbao2019featurized,\ntitle={Featurized Bidirectional {GAN}: Adversarial Defense via Adversarially Learned Semantic Inference},\nauthor={Ruying Bao and Sihang Liang and Qingcan Wang},\nyear={2019},\nurl={https://openreview.net/forum?id=r1lpx3A9K7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1120/Official_Review", "cdate": 1542234301490, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "r1lpx3A9K7", "replyto": "r1lpx3A9K7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1120/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335877054, "tmdate": 1552335877054, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1120/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "BJxwxKK9R7", "original": null, "number": 6, "cdate": 1543309551479, "ddate": null, "tcdate": 1543309551479, "tmdate": 1543309551479, "tddate": null, "forum": "r1lpx3A9K7", "replyto": "SkgRopH90X", "invitation": "ICLR.cc/2019/Conference/-/Paper1120/Official_Comment", "content": {"title": "some points taken, main concerns are not addressed", "comment": "2. \"DefenseGAN is broken\"\nYou are right about DefenseGAN not being broken.\n\n3. The evaluation methods used in our work are standard methods which are widely used in all other previous adversarial defense works. \n\nFGSM and PGD are indeed widely used, but many previously proposed defences used additional attacks (like transfer-based, score-based, decision-based). Please check https://arxiv.org/pdf/1802.05666.pdf for an in-depth discussion of this issue.\n\n4. \"Gradient masking\"\nYou are right that the gradient masking effects visible in the graybox attack doesn't necessarily indicate gradient masking in the white-box setting (but still means that hyper parameters of the attack have not been tuned properly).\n\nGiven the discussion I will increase my score by one point, but the lack of a reliable robustness evaluation and the reduced novelty compared to DefenseGAN still puts it below the acceptance threshold in my opinion."}, "signatures": ["ICLR.cc/2019/Conference/Paper1120/AnonReviewer3"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1120/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1120/AnonReviewer3", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Featurized Bidirectional GAN: Adversarial Defense via Adversarially Learned Semantic Inference", "abstract": "Deep neural networks have been demonstrated to be vulnerable to adversarial attacks, where small perturbations intentionally added to the original inputs can fool the classifier. In this paper, we propose a defense method, Featurized Bidirectional Generative Adversarial Networks (FBGAN), to extract the semantic features of the input and filter the non-semantic perturbation. FBGAN is pre-trained on the clean dataset in an unsupervised manner, adversarially learning a bidirectional mapping between a high-dimensional data space and a low-dimensional semantic space; also mutual information is applied to disentangle the semantically meaningful features. After the bidirectional mapping, the adversarial data can be reconstructed to denoised data, which could be fed into any pre-trained classifier. We empirically show the quality of reconstruction images and the effectiveness of defense.", "keywords": [], "authorids": ["rbao@princeton.edu", "sihangl@princeton.edu", "qingcanw@princeton.edu"], "authors": ["Ruying Bao", "Sihang Liang", "Qingcan Wang"], "pdf": "/pdf/9738a275f7113bead3ff53fb05b6e5620a9f6e1b.pdf", "paperhash": "bao|featurized_bidirectional_gan_adversarial_defense_via_adversarially_learned_semantic_inference", "_bibtex": "@misc{\nbao2019featurized,\ntitle={Featurized Bidirectional {GAN}: Adversarial Defense via Adversarially Learned Semantic Inference},\nauthor={Ruying Bao and Sihang Liang and Qingcan Wang},\nyear={2019},\nurl={https://openreview.net/forum?id=r1lpx3A9K7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1120/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621625516, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1lpx3A9K7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1120/Authors", "ICLR.cc/2019/Conference/Paper1120/Reviewers", "ICLR.cc/2019/Conference/Paper1120/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1120/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1120/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1120/Authors|ICLR.cc/2019/Conference/Paper1120/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1120/Reviewers", "ICLR.cc/2019/Conference/Paper1120/Authors", "ICLR.cc/2019/Conference/Paper1120/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621625516}}}, {"id": "SkgRopH90X", "original": null, "number": 4, "cdate": 1543294373941, "ddate": null, "tcdate": 1543294373941, "tmdate": 1543294373941, "tddate": null, "forum": "r1lpx3A9K7", "replyto": "r1lOxLgv3X", "invitation": "ICLR.cc/2019/Conference/-/Paper1120/Official_Comment", "content": {"title": "Reply", "comment": "Thanks for your comments. And we really appreciate for your contribution and time. Here are our feedbacks to your concerns:\n\n1. \"Novelty: several defences are based on a similar principle and the contributions of this paper are unclear.\"\n\nAt the time we submitted our paper, the only relevant defense mechanism we noticed at that time was DefenseGAN. There were also some other defense mechanisms which leveraged generative models but none of them attempted to extract semantic codes from the adversarial images, which is the main novelty of our model.\n\nOur contribuition is as following. FBGAN is the first model trying to understand the semantic meaning of an adversarial image and using this semantic meaning to reconstruct the original one. Our model is easily to be applied after training on the original data. On contrary, for example, defenseGAN, which also leverages the generative capability of GAN, needs to do search in the generated sample space every time it meets a new adversarial sample. FBGAN is not only faster but also has better performance than other generative model based defense methods.\n\n2. \"DefenseGAN is broken: the most similar work, DefenseGAN, has already been broken by Athalye et al. 2018, which is not discussed. The attacks deployed in this paper do not break DefenseGAN.\"\n\nWe are very glad this reviewer mentioned the paper by Athalye et al. 2018. This work provided a very good method called BPDA which can defeat all seemingly strong methods related to so-called obfuscated gradient in last year\u2019s ICLR. However, in that paper, they mentioned that defenseGAN was NOT broken at the time they wrote the paper. In addition, BPDA is an attack method to deal with those obfuscated gradient masking defend methods, which has nothing to do with DefenseGAN nor our FBGAN. Nonetheless, we are still happy to provide our defense result against BPDA method in that paper. Please see the second point in our reply to AnonReviewer1 for experiment details.\n\n3. \"Insufficient evidence: The evaluation is minimal (only FGSM and PGD, no decision-, transfer- or score-based attacks) and insufficient to support the claims.\"\n\nThe evaluation methods used in our work are standard methods which are widely used in all other previous adversarial defense works. We don\u2019t think the methods this reviewer mentioned are popular nor necessary to show the effectiveness of our work.\n\n4. \"Gradient masking: There is at least one clear sign of gradient masking in the results (FGSM performing better than PGD).\"\n\nThe reviewer believes that there exists gradient masking in Figure 5 (b). However, Figure 5 (b) is the results of gray-box attack, and the gray-box attack is calculated on the original non-robust classifier, so there is no gradient masking at all. Although the gradient masking may result in the fact that the defense accuracy of PGD is better than the defense accuracy of FGSM, it is not always true to claim that the gradient masking is the only reason that causes this phenomenon. Also our new experiment shows that BPDA, an attack method that works well on defenses utilizing the gradient masking, fails on our FBGAN (the detailed experiment results is shown under the feedback for AnonReviewer1). \n\nThanks again for your feedbacks."}, "signatures": ["ICLR.cc/2019/Conference/Paper1120/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1120/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1120/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Featurized Bidirectional GAN: Adversarial Defense via Adversarially Learned Semantic Inference", "abstract": "Deep neural networks have been demonstrated to be vulnerable to adversarial attacks, where small perturbations intentionally added to the original inputs can fool the classifier. In this paper, we propose a defense method, Featurized Bidirectional Generative Adversarial Networks (FBGAN), to extract the semantic features of the input and filter the non-semantic perturbation. FBGAN is pre-trained on the clean dataset in an unsupervised manner, adversarially learning a bidirectional mapping between a high-dimensional data space and a low-dimensional semantic space; also mutual information is applied to disentangle the semantically meaningful features. After the bidirectional mapping, the adversarial data can be reconstructed to denoised data, which could be fed into any pre-trained classifier. We empirically show the quality of reconstruction images and the effectiveness of defense.", "keywords": [], "authorids": ["rbao@princeton.edu", "sihangl@princeton.edu", "qingcanw@princeton.edu"], "authors": ["Ruying Bao", "Sihang Liang", "Qingcan Wang"], "pdf": "/pdf/9738a275f7113bead3ff53fb05b6e5620a9f6e1b.pdf", "paperhash": "bao|featurized_bidirectional_gan_adversarial_defense_via_adversarially_learned_semantic_inference", "_bibtex": "@misc{\nbao2019featurized,\ntitle={Featurized Bidirectional {GAN}: Adversarial Defense via Adversarially Learned Semantic Inference},\nauthor={Ruying Bao and Sihang Liang and Qingcan Wang},\nyear={2019},\nurl={https://openreview.net/forum?id=r1lpx3A9K7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1120/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621625516, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1lpx3A9K7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1120/Authors", "ICLR.cc/2019/Conference/Paper1120/Reviewers", "ICLR.cc/2019/Conference/Paper1120/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1120/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1120/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1120/Authors|ICLR.cc/2019/Conference/Paper1120/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1120/Reviewers", "ICLR.cc/2019/Conference/Paper1120/Authors", "ICLR.cc/2019/Conference/Paper1120/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621625516}}}, {"id": "rJgINoH9CQ", "original": null, "number": 3, "cdate": 1543293741622, "ddate": null, "tcdate": 1543293741622, "tmdate": 1543293741622, "tddate": null, "forum": "r1lpx3A9K7", "replyto": "S1lODbPZp7", "invitation": "ICLR.cc/2019/Conference/-/Paper1120/Official_Comment", "content": {"title": "Reply", "comment": "Thanks for your comments. And we really appreciate for your contribution and time. Here are our feedbacks to your concerns:\n\n1. \"Only two attacks are considered (FGSM and PGD).\"\n\nFGSM is the simplest and fastest adversarial attack method and it is widely used as a first-step robustness check for all state-of-art defense papers. As far as we know, most of attack methods invented by researchers in this community are based on the prototype FGSM, but with different approaches to doing gradient iteratively. Among those methods, PGD has been shown to be the strongest representative. Thus, our defense results under FGSM and PGD is enough to show our model's robustness.\n\n2. \"DefenseGAN is similar in defense mechanism but the authors do not attempt to use the attacks of Athalye et al 2018 (ICML 2018) in their evaluation. \"\n\nAnonReviewer3 and his/her reference [1] claims that \"Defense-GAN is broken\" under the BPDA attack proposed by Athalye et al. (2018). However, Table 1 in Athalye et al. (2018) shows that Defense-GAN is one of the only two survivors under BPDA. We think that BPDA is an effective attack for gradient masking defense methods, but not for generative-model-based methods, so we did not test BPDA in our original paper.\n\nAccording to the reviewers' request, we implemented the following BPDA experiment: Recall that our prediction is C(G(E(x))), where E, G and C are the encoder, generator and classifier respectively. Following Section 4.1, 5.4 and Appendix B in BPDA, we approximate the backward pass of G(E(x)) with the identity function to calculate the adversarial images. For MNIST, the defense accuracy under Carlini and Wagner\u2019s attack is 94.8% where the l_2 perturbation is 4.42, and the defense accuracy under PGD attack with l_\\infty perturbation 0.3 is 91.6%. It suggests that FBGAN is robust under the attack aiming to gradient masking.\n\n3. \"In Figure 5b, the attack FGSM performs better than PGD, but FGSM is the single step case of PGD. This indicates that the attacks were not tuned properly, as you should always have PGD as a stronger attacker than FGSM.\"\n\nFrankly speaking, we don't quite understand the meaning of \"the attacks were not tuned properly\". The attack methods we used were all from CleverHans. We are pretty sure that we used them properly. In addition, methods like FGSM and PGD, the attack performance only depends on the bound of the perturbation. Furthermore, it is actually not necessary for PGD to always outperform FGSM in adversarial attack. PGD is a multi-step gradient-based method and FGSM is a single-step method. The performance of them depends on the landscape of the object function, which is still an unsolved question for deep learning community.\n\n4. \"The method does not perform as well as adversarial training in standard defense tasks.\"\n\nAs mentioned in the main text, the defense performance of our FBGAN highly depends on the training of GAN. Adversarial training is a method only requires doing maximum worst case optimization during training process and it does not require extra networks' training. Thus, it is unfair to compare these two different mechanisms together. If comparing with method of the same category which also using generative model as a re-constructor, for example DefenseGAN, our model outperforms it by 1.4% , 5.0% on FGSM 0.1 and 0.3 attack respectively. \n\nThanks again for bringing out those typos, we will correct all of them in our next revision."}, "signatures": ["ICLR.cc/2019/Conference/Paper1120/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1120/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1120/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Featurized Bidirectional GAN: Adversarial Defense via Adversarially Learned Semantic Inference", "abstract": "Deep neural networks have been demonstrated to be vulnerable to adversarial attacks, where small perturbations intentionally added to the original inputs can fool the classifier. In this paper, we propose a defense method, Featurized Bidirectional Generative Adversarial Networks (FBGAN), to extract the semantic features of the input and filter the non-semantic perturbation. FBGAN is pre-trained on the clean dataset in an unsupervised manner, adversarially learning a bidirectional mapping between a high-dimensional data space and a low-dimensional semantic space; also mutual information is applied to disentangle the semantically meaningful features. After the bidirectional mapping, the adversarial data can be reconstructed to denoised data, which could be fed into any pre-trained classifier. We empirically show the quality of reconstruction images and the effectiveness of defense.", "keywords": [], "authorids": ["rbao@princeton.edu", "sihangl@princeton.edu", "qingcanw@princeton.edu"], "authors": ["Ruying Bao", "Sihang Liang", "Qingcan Wang"], "pdf": "/pdf/9738a275f7113bead3ff53fb05b6e5620a9f6e1b.pdf", "paperhash": "bao|featurized_bidirectional_gan_adversarial_defense_via_adversarially_learned_semantic_inference", "_bibtex": "@misc{\nbao2019featurized,\ntitle={Featurized Bidirectional {GAN}: Adversarial Defense via Adversarially Learned Semantic Inference},\nauthor={Ruying Bao and Sihang Liang and Qingcan Wang},\nyear={2019},\nurl={https://openreview.net/forum?id=r1lpx3A9K7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1120/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621625516, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1lpx3A9K7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1120/Authors", "ICLR.cc/2019/Conference/Paper1120/Reviewers", "ICLR.cc/2019/Conference/Paper1120/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1120/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1120/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1120/Authors|ICLR.cc/2019/Conference/Paper1120/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1120/Reviewers", "ICLR.cc/2019/Conference/Paper1120/Authors", "ICLR.cc/2019/Conference/Paper1120/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621625516}}}, {"id": "BJgNu_B5AX", "original": null, "number": 2, "cdate": 1543293036143, "ddate": null, "tcdate": 1543293036143, "tmdate": 1543293036143, "tddate": null, "forum": "r1lpx3A9K7", "replyto": "HJgJ3w4LhQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1120/Official_Comment", "content": {"title": "Reply", "comment": "Thanks for your comments. And we really appreciate for your contribution and time. Here are our feedbacks to some of your concerns. \n1. Weaker performance of FBGAN than that of adversarial training. Our argument is to emphasize that we do not need to re-train the classifier when we have adversarial examples with different attacks in FBGAN; however, adversarial training does need to re-train the classifier under different attacks. This is the limitation of adversarial training that we try to state. Actually, the defense mechanisms of our FBGAN and the adversarial training are quite different. Adversarial training improves the accuracy of the classifier by having access to as many adversarial examples with their corresponding correct labels as possible; while FBGAN only needs to train one classifier with the original clean data, and we may use this classifier to defend different attacks without any re-train process.\n\n2. Both PixelDefend and our FBGAN are based on generative models, however, the mechanisms of utilizing generative models are quite different. PixelDefend reconstructs the images from adversarial examples pixel by pixel, which does not care about the overall structure or semantic meaning of images; FBGAN learns the semantic meanings of adversarial examples first, and use these semantic meanings to reconstruct images. \n\nThanks again for your precious feedbacks."}, "signatures": ["ICLR.cc/2019/Conference/Paper1120/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1120/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1120/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Featurized Bidirectional GAN: Adversarial Defense via Adversarially Learned Semantic Inference", "abstract": "Deep neural networks have been demonstrated to be vulnerable to adversarial attacks, where small perturbations intentionally added to the original inputs can fool the classifier. In this paper, we propose a defense method, Featurized Bidirectional Generative Adversarial Networks (FBGAN), to extract the semantic features of the input and filter the non-semantic perturbation. FBGAN is pre-trained on the clean dataset in an unsupervised manner, adversarially learning a bidirectional mapping between a high-dimensional data space and a low-dimensional semantic space; also mutual information is applied to disentangle the semantically meaningful features. After the bidirectional mapping, the adversarial data can be reconstructed to denoised data, which could be fed into any pre-trained classifier. We empirically show the quality of reconstruction images and the effectiveness of defense.", "keywords": [], "authorids": ["rbao@princeton.edu", "sihangl@princeton.edu", "qingcanw@princeton.edu"], "authors": ["Ruying Bao", "Sihang Liang", "Qingcan Wang"], "pdf": "/pdf/9738a275f7113bead3ff53fb05b6e5620a9f6e1b.pdf", "paperhash": "bao|featurized_bidirectional_gan_adversarial_defense_via_adversarially_learned_semantic_inference", "_bibtex": "@misc{\nbao2019featurized,\ntitle={Featurized Bidirectional {GAN}: Adversarial Defense via Adversarially Learned Semantic Inference},\nauthor={Ruying Bao and Sihang Liang and Qingcan Wang},\nyear={2019},\nurl={https://openreview.net/forum?id=r1lpx3A9K7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1120/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621625516, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1lpx3A9K7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1120/Authors", "ICLR.cc/2019/Conference/Paper1120/Reviewers", "ICLR.cc/2019/Conference/Paper1120/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1120/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1120/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1120/Authors|ICLR.cc/2019/Conference/Paper1120/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1120/Reviewers", "ICLR.cc/2019/Conference/Paper1120/Authors", "ICLR.cc/2019/Conference/Paper1120/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621625516}}}, {"id": "S1lODbPZp7", "original": null, "number": 3, "cdate": 1541661023538, "ddate": null, "tcdate": 1541661023538, "tmdate": 1541661023538, "tddate": null, "forum": "r1lpx3A9K7", "replyto": "r1lpx3A9K7", "invitation": "ICLR.cc/2019/Conference/-/Paper1120/Official_Review", "content": {"title": "Review", "review": "Summary:\nThis paper gives a novel adversarial defense that consists of denoising images before classification. The denoising procedure consists of passing an image through a bidirectional GAN, which the authors use to map inputs to the latent space and then back to the original input space. \n\nNovelty:\nThe exact mechanism through which this paper operates is novel, but many similar defenses have been proposed before that involve a latent space mapping followed by a mapping back to the original space; examples include DefenseGAN and PixelDefend. \n\nConcerns:\n- The evaluation is not thorough enough: Only two attacks are considered (FGSM and PGD, with the former being strictly weaker than the latter)\n- DefenseGAN is similar in defense mechanism but the authors do not attempt to use the attacks of Athalye et al 2018 (ICML 2018) in their evaluation. We thus do not have strong lower bounds on adversarial robustness.\n- In Figure 5b, the attack FGSM performs better than PGD, but FGSM is the single step case of PGD. This indicates that the attacks were not tuned properly, as you should always have PGD as a stronger attacker than FGSM\n- The method does not perform as well as adversarial training in standard defense tasks\n- Several writing/clarity errors (detailed below)\n\nSmaller edits:\nPage 2: paragraph 2: second last line: \"feed\" instead of \"fed\"\nPage 2: bullet 1: under our contribution: line 3: \"which are unchanged\" instead of \"which is unchanged\"\nPage 3: paragraph 3: second last line: \"two distribution\" missing an s (plural)\nPage 3: Section 2.2: paragraph 2: line 2: \"here are two most famous attacks\" missing \"the\" before \"two most famous\"\nPage 4: Section 3.2: first paragraph: line 4: \"the latent codes is decomposed\" should be \"are\" instead of \"is\"\nPage 5: Paragraph 1: line 9: \"E are trained\" should be \"E is trained\"\nPage 5: Section 4: Paragraph 1: last line: \"are those have access \" should be \"are those which have access\" missing which/that\nPage 6: Last paragraph: Line 1: \"the attacker can only access to the classifier\" there is no need for \"to\"\n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1120/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Featurized Bidirectional GAN: Adversarial Defense via Adversarially Learned Semantic Inference", "abstract": "Deep neural networks have been demonstrated to be vulnerable to adversarial attacks, where small perturbations intentionally added to the original inputs can fool the classifier. In this paper, we propose a defense method, Featurized Bidirectional Generative Adversarial Networks (FBGAN), to extract the semantic features of the input and filter the non-semantic perturbation. FBGAN is pre-trained on the clean dataset in an unsupervised manner, adversarially learning a bidirectional mapping between a high-dimensional data space and a low-dimensional semantic space; also mutual information is applied to disentangle the semantically meaningful features. After the bidirectional mapping, the adversarial data can be reconstructed to denoised data, which could be fed into any pre-trained classifier. We empirically show the quality of reconstruction images and the effectiveness of defense.", "keywords": [], "authorids": ["rbao@princeton.edu", "sihangl@princeton.edu", "qingcanw@princeton.edu"], "authors": ["Ruying Bao", "Sihang Liang", "Qingcan Wang"], "pdf": "/pdf/9738a275f7113bead3ff53fb05b6e5620a9f6e1b.pdf", "paperhash": "bao|featurized_bidirectional_gan_adversarial_defense_via_adversarially_learned_semantic_inference", "_bibtex": "@misc{\nbao2019featurized,\ntitle={Featurized Bidirectional {GAN}: Adversarial Defense via Adversarially Learned Semantic Inference},\nauthor={Ruying Bao and Sihang Liang and Qingcan Wang},\nyear={2019},\nurl={https://openreview.net/forum?id=r1lpx3A9K7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1120/Official_Review", "cdate": 1542234301490, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "r1lpx3A9K7", "replyto": "r1lpx3A9K7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1120/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335877054, "tmdate": 1552335877054, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1120/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HJgJ3w4LhQ", "original": null, "number": 1, "cdate": 1540929447172, "ddate": null, "tcdate": 1540929447172, "tmdate": 1541533404784, "tddate": null, "forum": "r1lpx3A9K7", "replyto": "r1lpx3A9K7", "invitation": "ICLR.cc/2019/Conference/-/Paper1120/Official_Review", "content": {"title": "Performs worse than adversarial training", "review": "This paper presents a new adversarial defense based on \"cleaning\" images using a round trip through a bidirectional gan.  Specifically, an image is cleaned by mapping it to latent space and back to image space using a bidirectional gan.  To encourage the bidirectional gan to focus on the semantic properties, and ignore the noise, the gan is trained to maximize the mutual information between z and x, similar to the info gan.\n\nPros:\n\t1. The paper presents a novel (as far as I am aware) way to defend against adversarial attacks by cleaning images using a round trip in a bidirectional gan\n\nCons:\n\t1. The method performs significantly worse than existing techniques, specifically adversarial training.\n\t\ta. The authors argue \"Although better than FBGAN, adversarial training has its limitation: if the attack method is harder than the one used in training(PGD is harder than FGSM), or the perturbation is larger, then the defense may totally fail. FBGAN is effective and consistent for any given classifier, regardless of the attack method or perturbation.\"\n\t\tb. I do not buy their argument, however, because one can simply apply the strongest defense (PGD 0.3 in their results) and this outperforms their method in *all* attack scenarios.  And if someone comes out with a new stronger attack there's no guarantee their method will be strong defense against that method\n\t2. The paper is not written that well.  Even though the technique itself is very simple, I was unable to understand it from the introduction, and didn't really understand what they were doing until I reached the 4th page of the paper. \n\t\n\nMissing citation:\nPixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples  (ICLR 2018)\n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1120/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Featurized Bidirectional GAN: Adversarial Defense via Adversarially Learned Semantic Inference", "abstract": "Deep neural networks have been demonstrated to be vulnerable to adversarial attacks, where small perturbations intentionally added to the original inputs can fool the classifier. In this paper, we propose a defense method, Featurized Bidirectional Generative Adversarial Networks (FBGAN), to extract the semantic features of the input and filter the non-semantic perturbation. FBGAN is pre-trained on the clean dataset in an unsupervised manner, adversarially learning a bidirectional mapping between a high-dimensional data space and a low-dimensional semantic space; also mutual information is applied to disentangle the semantically meaningful features. After the bidirectional mapping, the adversarial data can be reconstructed to denoised data, which could be fed into any pre-trained classifier. We empirically show the quality of reconstruction images and the effectiveness of defense.", "keywords": [], "authorids": ["rbao@princeton.edu", "sihangl@princeton.edu", "qingcanw@princeton.edu"], "authors": ["Ruying Bao", "Sihang Liang", "Qingcan Wang"], "pdf": "/pdf/9738a275f7113bead3ff53fb05b6e5620a9f6e1b.pdf", "paperhash": "bao|featurized_bidirectional_gan_adversarial_defense_via_adversarially_learned_semantic_inference", "_bibtex": "@misc{\nbao2019featurized,\ntitle={Featurized Bidirectional {GAN}: Adversarial Defense via Adversarially Learned Semantic Inference},\nauthor={Ruying Bao and Sihang Liang and Qingcan Wang},\nyear={2019},\nurl={https://openreview.net/forum?id=r1lpx3A9K7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1120/Official_Review", "cdate": 1542234301490, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "r1lpx3A9K7", "replyto": "r1lpx3A9K7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1120/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335877054, "tmdate": 1552335877054, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1120/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 9}