{"notes": [{"id": "BJgd81SYwr", "original": "HylbYP6OwB", "number": 1735, "cdate": 1569439568158, "ddate": null, "tcdate": 1569439568158, "tmdate": 1583912046554, "tddate": null, "forum": "BJgd81SYwr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["haebeom.lee@kaist.ac.kr", "namsan@kaist.ac.kr", "eunhoy@kaist.ac.kr", "sjhwang82@kaist.ac.kr"], "title": "Meta Dropout: Learning to Perturb Latent Features for Generalization", "authors": ["Hae Beom Lee", "Taewook Nam", "Eunho Yang", "Sung Ju Hwang"], "pdf": "/pdf/0eed1795c32d19171f8f21961a0cdc58d8315d41.pdf", "abstract": "A machine learning model that generalizes well should obtain low errors on unseen test examples. Thus, if we know how to optimally perturb training examples to account for test examples, we may achieve better generalization performance. However, obtaining such perturbation is not possible in standard machine learning frameworks as the distribution of the test data is unknown. To tackle this challenge, we propose a novel regularization method, meta-dropout, which learns to perturb the latent features of training examples for generalization in a meta-learning framework. Specifically, we meta-learn a noise generator which outputs a multiplicative noise distribution for latent features, to obtain low errors on the test instances in an input-dependent manner. Then, the learned noise generator can perturb the training examples of unseen tasks at the meta-test time for improved generalization. We validate our method on few-shot classification datasets, whose results show that it significantly improves the generalization performance of the base model, and largely outperforms existing regularization methods such as information bottleneck, manifold mixup, and information dropout.", "code": "https://github.com/haebeom-lee/metadrop", "keywords": [], "paperhash": "lee|meta_dropout_learning_to_perturb_latent_features_for_generalization", "_bibtex": "@inproceedings{\nLee2020Meta,\ntitle={Meta Dropout: Learning to Perturb Latent Features for Generalization},\nauthor={Hae Beom Lee and Taewook Nam and Eunho Yang and Sung Ju Hwang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJgd81SYwr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/178c856fe689f5a2dc8005380358efe7b5f252aa.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "N6YZNAvJX", "original": null, "number": 1, "cdate": 1576798731139, "ddate": null, "tcdate": 1576798731139, "tmdate": 1576800905332, "tddate": null, "forum": "BJgd81SYwr", "replyto": "BJgd81SYwr", "invitation": "ICLR.cc/2020/Conference/Paper1735/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "This paper proposes a type of adaptive dropout to regularize gradient based meta-learning models. The reviewers found the idea interesting and it is supported by improvements on standard benchmarks. The authors addressed several concerns of the reviewers during the rebutal phase. In particular, revisions added results against other regularization mthods. We recommend that further attention is given to ablations, in particular the baseline proposed by Reviewer 1.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["haebeom.lee@kaist.ac.kr", "namsan@kaist.ac.kr", "eunhoy@kaist.ac.kr", "sjhwang82@kaist.ac.kr"], "title": "Meta Dropout: Learning to Perturb Latent Features for Generalization", "authors": ["Hae Beom Lee", "Taewook Nam", "Eunho Yang", "Sung Ju Hwang"], "pdf": "/pdf/0eed1795c32d19171f8f21961a0cdc58d8315d41.pdf", "abstract": "A machine learning model that generalizes well should obtain low errors on unseen test examples. Thus, if we know how to optimally perturb training examples to account for test examples, we may achieve better generalization performance. However, obtaining such perturbation is not possible in standard machine learning frameworks as the distribution of the test data is unknown. To tackle this challenge, we propose a novel regularization method, meta-dropout, which learns to perturb the latent features of training examples for generalization in a meta-learning framework. Specifically, we meta-learn a noise generator which outputs a multiplicative noise distribution for latent features, to obtain low errors on the test instances in an input-dependent manner. Then, the learned noise generator can perturb the training examples of unseen tasks at the meta-test time for improved generalization. We validate our method on few-shot classification datasets, whose results show that it significantly improves the generalization performance of the base model, and largely outperforms existing regularization methods such as information bottleneck, manifold mixup, and information dropout.", "code": "https://github.com/haebeom-lee/metadrop", "keywords": [], "paperhash": "lee|meta_dropout_learning_to_perturb_latent_features_for_generalization", "_bibtex": "@inproceedings{\nLee2020Meta,\ntitle={Meta Dropout: Learning to Perturb Latent Features for Generalization},\nauthor={Hae Beom Lee and Taewook Nam and Eunho Yang and Sung Ju Hwang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJgd81SYwr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/178c856fe689f5a2dc8005380358efe7b5f252aa.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "BJgd81SYwr", "replyto": "BJgd81SYwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795709327, "tmdate": 1576800258040, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1735/-/Decision"}}}, {"id": "rJxKsYxycS", "original": null, "number": 2, "cdate": 1571912097516, "ddate": null, "tcdate": 1571912097516, "tmdate": 1574350172879, "tddate": null, "forum": "BJgd81SYwr", "replyto": "BJgd81SYwr", "invitation": "ICLR.cc/2020/Conference/Paper1735/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #2", "review": "The authors propose to meta-learn, using MAML, the mean of an elementwise, input-dependent, multiplicative noise to improve generalization in few-shot learning.\nThe motivation is that meta-learning the noise allows to learn how to best perturb examples in order to improve generlization.  This claim is supported by ample experimental evidence and comparisons against many baselines, as well as additional ablation studies w.r.t design choices of the algorithm itself. The paper is well written and easy to read. Consequently, I think this is a nice paper and should be accepted. \n\nEdit (leaving everything else unchanged for now): After reading R3's assessment, I agree with them that it's worrying that the Deterministic Meta-Dropout performs better than baseline MAML - maybe it's an effect of a larger number of parameters in the model? \n\nEdit:\nThank you for your response.\n\nI will leave my score as is.\n I would strongly encourage the authors to incorporate the baseline \"(1)\" as proposed by R3 in a future version of the paper as I agree with them that this is a relevant baseline.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1735/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1735/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["haebeom.lee@kaist.ac.kr", "namsan@kaist.ac.kr", "eunhoy@kaist.ac.kr", "sjhwang82@kaist.ac.kr"], "title": "Meta Dropout: Learning to Perturb Latent Features for Generalization", "authors": ["Hae Beom Lee", "Taewook Nam", "Eunho Yang", "Sung Ju Hwang"], "pdf": "/pdf/0eed1795c32d19171f8f21961a0cdc58d8315d41.pdf", "abstract": "A machine learning model that generalizes well should obtain low errors on unseen test examples. Thus, if we know how to optimally perturb training examples to account for test examples, we may achieve better generalization performance. However, obtaining such perturbation is not possible in standard machine learning frameworks as the distribution of the test data is unknown. To tackle this challenge, we propose a novel regularization method, meta-dropout, which learns to perturb the latent features of training examples for generalization in a meta-learning framework. Specifically, we meta-learn a noise generator which outputs a multiplicative noise distribution for latent features, to obtain low errors on the test instances in an input-dependent manner. Then, the learned noise generator can perturb the training examples of unseen tasks at the meta-test time for improved generalization. We validate our method on few-shot classification datasets, whose results show that it significantly improves the generalization performance of the base model, and largely outperforms existing regularization methods such as information bottleneck, manifold mixup, and information dropout.", "code": "https://github.com/haebeom-lee/metadrop", "keywords": [], "paperhash": "lee|meta_dropout_learning_to_perturb_latent_features_for_generalization", "_bibtex": "@inproceedings{\nLee2020Meta,\ntitle={Meta Dropout: Learning to Perturb Latent Features for Generalization},\nauthor={Hae Beom Lee and Taewook Nam and Eunho Yang and Sung Ju Hwang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJgd81SYwr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/178c856fe689f5a2dc8005380358efe7b5f252aa.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJgd81SYwr", "replyto": "BJgd81SYwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1735/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1735/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575579109125, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1735/Reviewers"], "noninvitees": [], "tcdate": 1570237733058, "tmdate": 1575579109138, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1735/-/Official_Review"}}}, {"id": "HkgSRBhniH", "original": null, "number": 8, "cdate": 1573860812720, "ddate": null, "tcdate": 1573860812720, "tmdate": 1573860812720, "tddate": null, "forum": "BJgd81SYwr", "replyto": "ByemJtbwsB", "invitation": "ICLR.cc/2020/Conference/Paper1735/-/Official_Comment", "content": {"title": "still not convinced", "comment": "I would like to thank the authors for the detailed response.\n\nIt\u2019s indeed true that the formulas in Section 3.2 are correct, I apologize for the confusion. But I agree with other reviewers that the connection between the proposed method and variational inference is not significant. There is no variational approximation in the proposed method, only the Jensen lower bound. Equation 7 could be safely skipped. \n\nI spent significant time deliberating whether the baseline results provided in the paper and in the rebuttal provide enough evidence to say that meta-learning input-dependent noisy regularization is useful. Let me share my thoughts.\n\nThe proposed method can be seen as introducing 3 changes to the model and the learning algorithm:\n\nThe first change to the model: element-wise multipliers z^(l), as well as the parameters \\phi that are used to compute z^(l)\nThe second change to the model: adding a form of multiplicative noise\nA change to the algorithm: the parameters \\phi are now treated differently and receive a different kind of derivative\n\nMeaningful subsets of the three proposed changes include: \n(1), whereby \\phi and \\theta are treated identically and no noise is used. I am not sure if this is what the authors tried in their rebuttal, they did not say if they kept noise on. This is an important baseline because it isolates the change to the model. \n(1, 2), which is to my best understanding what the authors did in the rebuttal when they tried \u201c\\phi treated as \\theta\u201d\n(2): \u201cFixed Gaussian\u201d in Table 3\n(1, 3): \u201cDeterministic Meta-Dropout\u201d in Table 3\n(2, 3): \u201cIndependent Gaussian\u201d in Table 3\n\nTo justify that all these 3 changes are needed, one needs to show in several experiments how the combination of all 3 performs better than subsets. The paper performs 4 experiments: 1-shot Omniglot, 5-shot Omniglot, 1-shot MiniImageNet, 5-shot MiniImageNet.\n\nHere\u2019s my summary of the results:\n1-shot OmniGlot: the proposed method works significantly better than baselines \n5-shot OmniGlot: using just (2) performs as well as the proposed method\n1-shot ImageNet: the proposed method works significantly better than baselines, but the 42.08 accuracy that is reported in the rebuttal for (1, 2) baseline looks not very trust-worthy. Why would there be such a deterioration in this case, when in OmniGlot 1-shot case this baseline almost approached Meta-Dropout?\n5-shot ImageNet: the 95% confidence intervals overlap for (1,3), (2,3) and the proposed method\nAdditionally, to my best understanding, the baseline (1) was not tried. That said, I still can\u2019t be sure that the main source of improvement is not the change in the model. \n\nGiven this summary of the results, I am not convinced that the paper clearly shows the benefit of meta-learning input-dependent noisy regularization. \n\nLastly, I disagree with the authors that the paper is clear w.r.t. what exactly \\phi is and how exactly is used. I did not find this information in Figure 2 and \u201cForm of the noise\u201d paragraph."}, "signatures": ["ICLR.cc/2020/Conference/Paper1735/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1735/AnonReviewer3", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["haebeom.lee@kaist.ac.kr", "namsan@kaist.ac.kr", "eunhoy@kaist.ac.kr", "sjhwang82@kaist.ac.kr"], "title": "Meta Dropout: Learning to Perturb Latent Features for Generalization", "authors": ["Hae Beom Lee", "Taewook Nam", "Eunho Yang", "Sung Ju Hwang"], "pdf": "/pdf/0eed1795c32d19171f8f21961a0cdc58d8315d41.pdf", "abstract": "A machine learning model that generalizes well should obtain low errors on unseen test examples. Thus, if we know how to optimally perturb training examples to account for test examples, we may achieve better generalization performance. However, obtaining such perturbation is not possible in standard machine learning frameworks as the distribution of the test data is unknown. To tackle this challenge, we propose a novel regularization method, meta-dropout, which learns to perturb the latent features of training examples for generalization in a meta-learning framework. Specifically, we meta-learn a noise generator which outputs a multiplicative noise distribution for latent features, to obtain low errors on the test instances in an input-dependent manner. Then, the learned noise generator can perturb the training examples of unseen tasks at the meta-test time for improved generalization. We validate our method on few-shot classification datasets, whose results show that it significantly improves the generalization performance of the base model, and largely outperforms existing regularization methods such as information bottleneck, manifold mixup, and information dropout.", "code": "https://github.com/haebeom-lee/metadrop", "keywords": [], "paperhash": "lee|meta_dropout_learning_to_perturb_latent_features_for_generalization", "_bibtex": "@inproceedings{\nLee2020Meta,\ntitle={Meta Dropout: Learning to Perturb Latent Features for Generalization},\nauthor={Hae Beom Lee and Taewook Nam and Eunho Yang and Sung Ju Hwang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJgd81SYwr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/178c856fe689f5a2dc8005380358efe7b5f252aa.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJgd81SYwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1735/Authors", "ICLR.cc/2020/Conference/Paper1735/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1735/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1735/Reviewers", "ICLR.cc/2020/Conference/Paper1735/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1735/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1735/Authors|ICLR.cc/2020/Conference/Paper1735/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504151650, "tmdate": 1576860530614, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1735/Authors", "ICLR.cc/2020/Conference/Paper1735/Reviewers", "ICLR.cc/2020/Conference/Paper1735/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1735/-/Official_Comment"}}}, {"id": "HJe3wYbPoS", "original": null, "number": 5, "cdate": 1573488996181, "ddate": null, "tcdate": 1573488996181, "tmdate": 1573824247347, "tddate": null, "forum": "BJgd81SYwr", "replyto": "BJgd81SYwr", "invitation": "ICLR.cc/2020/Conference/Paper1735/-/Official_Comment", "content": {"title": "Summary of updates in the revision", "comment": "We thank all reviewers for their constructive comments. Here we briefly mention what have been updated in the revision. For more detailed explanations, please refer to the response to each reviewer.\n\n1. New experimental results on adversarial robustness: we replaced the FGSM attack with PGD attacks with $L_1$, $L_2$, $L_\\infty$ norm, and included more baselines (e.g. Mixup, VIB, and Information Dropout). The results show that our meta-dropout yields deep neural networks that are significantly more robust to adversarial attacks than baselines, regardless of the types of attacks used ($L_1$, $L_2$, $L_\\infty$) on few-shot classification tasks. We believe that these results will significantly strengthen our work, as we have shown that our meta-dropout not only achieves models that generalize better, but are more robust. While these findings are from few-shot classification tasks, we believe that they are meaningful, since existing models for adversarial learning achieved robustness at the expense of generalization accuracy and most of them do not generalize across different types of attacks. Please see the paragraph \u201cAdversarial robustness\u201d and Figure 5 in Page 7, as well as our response to the R1\u2019s comment below for more detailed explanations.\n\n2. In Section 3.2, based on R1\u2019s comment, we toned down on our claims. We changed \u201cLearning to regularize variational inference\u201c into \u201cConnection to variational inference\u201d and corrected corresponding sentences that look overstated. \n\n3. In Table 3, for each baseline, we added in the indication on whether it has the following properties: Random sampling, Learned multiplication, and Input-dependency. This allows us to better see the effect of each component to the generalization performance. We also denote that the input-dependent meta-learning of multiplicative noise with stochasticity as the core components of our meta-dropout. We provide more in-depth analysis on \u201cAblation study\u201d paragraph in Page 8. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1735/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1735/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["haebeom.lee@kaist.ac.kr", "namsan@kaist.ac.kr", "eunhoy@kaist.ac.kr", "sjhwang82@kaist.ac.kr"], "title": "Meta Dropout: Learning to Perturb Latent Features for Generalization", "authors": ["Hae Beom Lee", "Taewook Nam", "Eunho Yang", "Sung Ju Hwang"], "pdf": "/pdf/0eed1795c32d19171f8f21961a0cdc58d8315d41.pdf", "abstract": "A machine learning model that generalizes well should obtain low errors on unseen test examples. Thus, if we know how to optimally perturb training examples to account for test examples, we may achieve better generalization performance. However, obtaining such perturbation is not possible in standard machine learning frameworks as the distribution of the test data is unknown. To tackle this challenge, we propose a novel regularization method, meta-dropout, which learns to perturb the latent features of training examples for generalization in a meta-learning framework. Specifically, we meta-learn a noise generator which outputs a multiplicative noise distribution for latent features, to obtain low errors on the test instances in an input-dependent manner. Then, the learned noise generator can perturb the training examples of unseen tasks at the meta-test time for improved generalization. We validate our method on few-shot classification datasets, whose results show that it significantly improves the generalization performance of the base model, and largely outperforms existing regularization methods such as information bottleneck, manifold mixup, and information dropout.", "code": "https://github.com/haebeom-lee/metadrop", "keywords": [], "paperhash": "lee|meta_dropout_learning_to_perturb_latent_features_for_generalization", "_bibtex": "@inproceedings{\nLee2020Meta,\ntitle={Meta Dropout: Learning to Perturb Latent Features for Generalization},\nauthor={Hae Beom Lee and Taewook Nam and Eunho Yang and Sung Ju Hwang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJgd81SYwr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/178c856fe689f5a2dc8005380358efe7b5f252aa.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJgd81SYwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1735/Authors", "ICLR.cc/2020/Conference/Paper1735/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1735/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1735/Reviewers", "ICLR.cc/2020/Conference/Paper1735/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1735/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1735/Authors|ICLR.cc/2020/Conference/Paper1735/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504151650, "tmdate": 1576860530614, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1735/Authors", "ICLR.cc/2020/Conference/Paper1735/Reviewers", "ICLR.cc/2020/Conference/Paper1735/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1735/-/Official_Comment"}}}, {"id": "ryg4oUWPsH", "original": null, "number": 1, "cdate": 1573488283967, "ddate": null, "tcdate": 1573488283967, "tmdate": 1573521643227, "tddate": null, "forum": "BJgd81SYwr", "replyto": "S1e1sc_GqB", "invitation": "ICLR.cc/2020/Conference/Paper1735/-/Official_Comment", "content": {"title": "Response to Reviewer #1", "comment": "We really appreciate your constructive comments. We respond to each comment as follows.\n\n1. Meta dropout does not regularize the variational framework because there is no variational inference framework.\n\n- Thank you for your comment. We agree with you that the current lower bound is not a variational form due to the assumption of q=p. In Section 3.2, we toned down the original expression \u201cLearning to regularize variational inference\u201c into \u201cConnection to variational inference\u201d, and corrected the corresponding sentences. Still, there exists a clear connection between standard variational inference and our learning framework. Thus we believe that discussion in Section 3.2 will be helpful to readers who want to understand the meaning of learning objective Eq.(2) in depth.\n\n2. Improving adversarial robustness experiment.\n\n- Thank you for the helpful suggestion. During the rebuttal period, we conducted additional experiments on adversarial robustness as you suggested:\n\na) We replaced the previous FGSM attack with stronger PGD attack (200 iter.), with $L_1$, $L_2$, and $L_\\infty$ norm constraints. \n\nb) We included more baselines (e.g. Mixup, VIB, and information dropout), and show that our meta-dropout largely and consistently outperforms all of them.\n\nc) We added more detailed descriptions of the adversarial meta-learning baseline and in-depth analysis on the results.\n\nd) We further show that the learned perturbation from our Meta-dropout also generalize across different types of adversarial attacks with $L_1$, $L_2$, and $L_\\infty$ attacks. The generalization to different types of attacks is an important problem in adversarial learning, and most existing models fail to achieve this goal.  \n\nPlease see the corresponding section in the revision. We believe that the adversarial robustness part of our paper has become much stronger than before, thanks to your suggestion."}, "signatures": ["ICLR.cc/2020/Conference/Paper1735/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1735/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["haebeom.lee@kaist.ac.kr", "namsan@kaist.ac.kr", "eunhoy@kaist.ac.kr", "sjhwang82@kaist.ac.kr"], "title": "Meta Dropout: Learning to Perturb Latent Features for Generalization", "authors": ["Hae Beom Lee", "Taewook Nam", "Eunho Yang", "Sung Ju Hwang"], "pdf": "/pdf/0eed1795c32d19171f8f21961a0cdc58d8315d41.pdf", "abstract": "A machine learning model that generalizes well should obtain low errors on unseen test examples. Thus, if we know how to optimally perturb training examples to account for test examples, we may achieve better generalization performance. However, obtaining such perturbation is not possible in standard machine learning frameworks as the distribution of the test data is unknown. To tackle this challenge, we propose a novel regularization method, meta-dropout, which learns to perturb the latent features of training examples for generalization in a meta-learning framework. Specifically, we meta-learn a noise generator which outputs a multiplicative noise distribution for latent features, to obtain low errors on the test instances in an input-dependent manner. Then, the learned noise generator can perturb the training examples of unseen tasks at the meta-test time for improved generalization. We validate our method on few-shot classification datasets, whose results show that it significantly improves the generalization performance of the base model, and largely outperforms existing regularization methods such as information bottleneck, manifold mixup, and information dropout.", "code": "https://github.com/haebeom-lee/metadrop", "keywords": [], "paperhash": "lee|meta_dropout_learning_to_perturb_latent_features_for_generalization", "_bibtex": "@inproceedings{\nLee2020Meta,\ntitle={Meta Dropout: Learning to Perturb Latent Features for Generalization},\nauthor={Hae Beom Lee and Taewook Nam and Eunho Yang and Sung Ju Hwang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJgd81SYwr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/178c856fe689f5a2dc8005380358efe7b5f252aa.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJgd81SYwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1735/Authors", "ICLR.cc/2020/Conference/Paper1735/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1735/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1735/Reviewers", "ICLR.cc/2020/Conference/Paper1735/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1735/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1735/Authors|ICLR.cc/2020/Conference/Paper1735/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504151650, "tmdate": 1576860530614, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1735/Authors", "ICLR.cc/2020/Conference/Paper1735/Reviewers", "ICLR.cc/2020/Conference/Paper1735/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1735/-/Official_Comment"}}}, {"id": "rJgYVv-PoB", "original": null, "number": 2, "cdate": 1573488433295, "ddate": null, "tcdate": 1573488433295, "tmdate": 1573496165982, "tddate": null, "forum": "BJgd81SYwr", "replyto": "rJxKsYxycS", "invitation": "ICLR.cc/2020/Conference/Paper1735/-/Official_Comment", "content": {"title": "Response to Reviewer #2", "comment": "We sincerely appreciate your constructive comments. We respond to your main concerns below:\n\n1. The Deterministic Meta-Dropout performs better than baseline MAML - maybe it's an effect of a larger number of parameters in the model?\n\n- To demonstrate that strong generalization performance of Meta-Dropout is not the effect of using larger number of model parameters, we doubled the number of channels for the base model and report its performances (MAML(x2)).\n\nModels\t\t   #param.\tOmni-1shot\tOmni-5shot\tmimg-1shot\tmimg-5shot\nMAML\t\t   x1\t        \t95.23+-0.17\t98.38+-0.07\t49.58+-0.65\t64.55+-0.52\nMAML(x2)\t   x4\t        \t94.96+-0.16\t98.36+-0.08\t48.19+-0.64\t65.84+-0.52\nMeta-SGD         x2\t        \t96.16+-0.14\t98.54+-0.07\t48.30+-0.64\t65.55+-0.56\nMeta-dropout  x2\t        \t96.63+-0.13\t98.73+-0.06\t51.93+-0.67\t67.42+-0.52\n\nThe number of parameters of MAML(chx2) is four times of that of MAML, while Meta-dropout is only doubled. Nonetheless, MAML(chx2) does not improve on MAML, demonstrating that the effectiveness of meta-dropout does not simply come from using larger number of parameters. Meta-SGD also doubles the number of parameters in the base MAML model, but is significantly outperformed by Meta-dropout. \n\nWe want to emphasize that Deterministic meta-dropout is also one of our models, and that its good performance does not hurt our claim on the effectiveness of the multiplicative noise. This is because meta-dropout consists of two parts: meta-learned deterministic multiplicative perturbation and random noise. Thus the deterministic meta-dropout still \u201clearns to perturb\u201d, although not random, and is actually a core component of meta-dropout (See Table 3 in the revision). Please also see our response to the Reviewer #3, comment #4."}, "signatures": ["ICLR.cc/2020/Conference/Paper1735/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1735/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["haebeom.lee@kaist.ac.kr", "namsan@kaist.ac.kr", "eunhoy@kaist.ac.kr", "sjhwang82@kaist.ac.kr"], "title": "Meta Dropout: Learning to Perturb Latent Features for Generalization", "authors": ["Hae Beom Lee", "Taewook Nam", "Eunho Yang", "Sung Ju Hwang"], "pdf": "/pdf/0eed1795c32d19171f8f21961a0cdc58d8315d41.pdf", "abstract": "A machine learning model that generalizes well should obtain low errors on unseen test examples. Thus, if we know how to optimally perturb training examples to account for test examples, we may achieve better generalization performance. However, obtaining such perturbation is not possible in standard machine learning frameworks as the distribution of the test data is unknown. To tackle this challenge, we propose a novel regularization method, meta-dropout, which learns to perturb the latent features of training examples for generalization in a meta-learning framework. Specifically, we meta-learn a noise generator which outputs a multiplicative noise distribution for latent features, to obtain low errors on the test instances in an input-dependent manner. Then, the learned noise generator can perturb the training examples of unseen tasks at the meta-test time for improved generalization. We validate our method on few-shot classification datasets, whose results show that it significantly improves the generalization performance of the base model, and largely outperforms existing regularization methods such as information bottleneck, manifold mixup, and information dropout.", "code": "https://github.com/haebeom-lee/metadrop", "keywords": [], "paperhash": "lee|meta_dropout_learning_to_perturb_latent_features_for_generalization", "_bibtex": "@inproceedings{\nLee2020Meta,\ntitle={Meta Dropout: Learning to Perturb Latent Features for Generalization},\nauthor={Hae Beom Lee and Taewook Nam and Eunho Yang and Sung Ju Hwang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJgd81SYwr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/178c856fe689f5a2dc8005380358efe7b5f252aa.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJgd81SYwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1735/Authors", "ICLR.cc/2020/Conference/Paper1735/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1735/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1735/Reviewers", "ICLR.cc/2020/Conference/Paper1735/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1735/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1735/Authors|ICLR.cc/2020/Conference/Paper1735/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504151650, "tmdate": 1576860530614, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1735/Authors", "ICLR.cc/2020/Conference/Paper1735/Reviewers", "ICLR.cc/2020/Conference/Paper1735/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1735/-/Official_Comment"}}}, {"id": "BJgDya-vsB", "original": null, "number": 7, "cdate": 1573489887128, "ddate": null, "tcdate": 1573489887128, "tmdate": 1573489965623, "tddate": null, "forum": "BJgd81SYwr", "replyto": "H1lRMzRpYr", "invitation": "ICLR.cc/2020/Conference/Paper1735/-/Official_Comment", "content": {"title": "Response to Reviewer #3 (1/2)", "comment": "We appreciate your constructive comments. We respond to each comment as follows.\n\n1. The paper is somewhat incremental considering that Li et al, (2017) and Balaji et al., (2018) have already proposed meta-learning parameter-wise learning rates and parameter-wise regularization coefficient respectively.\n\n- This is a critical misunderstanding. The two papers you mentioned are not even superficially similar to our model. First Meta-SGD (Li et al., 2017) aims to meta-learn the element-wise learning rate, which is completely orthogonal to our model that meta-learns input-dependent perturbation of latent features. It also largely underperforms our method (See Table 1). \n\nMeta-Reg (Balaji et al., 2018) meta-learns the hyperparameter for a global regularizer while our Meta-Dropout directly learns to perturb each feature in an input-dependent manner. and aims to tackle a completely different problem of domain generalization. Nonetheless, to the best of our efforts, we tried to import the MetaReg idea to the conventional few-shot classification setting, such that for each task, its inner-optimization objective includes L1 regularization whose coefficients are element-wisely meta-learned. The results are as follows.\n \nModels\t\t        \tOmni-1shot\tOmni-5shot\tmimg-1shot\tmimg-5shot\nMAML\t\t        \t95.23+-0.17\t98.38+-0.07\t49.58+-0.65\t64.55+-0.52\nMetaReg (Ours)\t\t95.28+-0.15\t98.85+-0.06\t49.76+-0.67\t65.42+-0.53\nMeta-dropout\t\t96.63+-0.13\t98.73+-0.06\t51.93+-0.67\t67.42+-0.52\n\nAs shown, Meta-dropout largely outperforms MetaReg, demonstrating the effectiveness of our framework, which meta-learns the input-dependent perturbation function.\n\n\n2. It seems like the choice of the particular method for adding the noise was performed using the test set.\n\n- This is a complete misunderstanding. We never used a meta-test set for training or hyperparameter tuning. Test in the paper refers to the instances *simulating* test instances within the meta-training dataset, which is a common terminology in meta-learning.\n\n\n3. Table 2 contains some results named \u201cAdd.\u201d, which I guess stands for additive noise. I did not find an explanation of what is the specific method for adding noise used in this case. \n\n- We apologize for the confusion. This is indeed an additive noise version of our meta-dropout. We updated the revision with the full description of the method in Appendix B. Since we compare against this additive version in the main table (Table 2), which is already an ablation study of the two, it is excluded from the Ablation study in Table 3. \n\n\n4. Overall, it seems that paper falls short of clearly proving that back-propagating through MAML to the noise parameters is helpful. \n\n- The slightly good performance of \u201cDeterministic Meta-dropout\u201d and \u201cFixed Gaussian\u201d does not hurt our claim on the effectiveness of multiplicative noise, because multiplicative noise, by definition, consists of two parts: deterministic multiplication and pure random noise. For example, Bernoulli dropout consists of Bernoulli retain probability $0 \\leq p \\leq 1$ (deterministic multiplication) and actual random sampling (pure random noise). In this vein, we can say that \u201cDeterministic Meta-dropout \u201cdemonstrates the effectiveness of meta-learning the probability p, and \u201cFixed Gaussian\u201d shows the effectiveness of injecting (multiplying) pure random noise N(0,I) on each feature location.\n\nOverall, our meta-dropout combines the two components, which are complementary each other, into a novel input-dependent form of perturbation function. In this regard, we have clearly demonstrated that meta-learning input-dependent multiplicative noise is beneficial for improving generalization, jointly as well as component-wisely.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1735/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1735/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["haebeom.lee@kaist.ac.kr", "namsan@kaist.ac.kr", "eunhoy@kaist.ac.kr", "sjhwang82@kaist.ac.kr"], "title": "Meta Dropout: Learning to Perturb Latent Features for Generalization", "authors": ["Hae Beom Lee", "Taewook Nam", "Eunho Yang", "Sung Ju Hwang"], "pdf": "/pdf/0eed1795c32d19171f8f21961a0cdc58d8315d41.pdf", "abstract": "A machine learning model that generalizes well should obtain low errors on unseen test examples. Thus, if we know how to optimally perturb training examples to account for test examples, we may achieve better generalization performance. However, obtaining such perturbation is not possible in standard machine learning frameworks as the distribution of the test data is unknown. To tackle this challenge, we propose a novel regularization method, meta-dropout, which learns to perturb the latent features of training examples for generalization in a meta-learning framework. Specifically, we meta-learn a noise generator which outputs a multiplicative noise distribution for latent features, to obtain low errors on the test instances in an input-dependent manner. Then, the learned noise generator can perturb the training examples of unseen tasks at the meta-test time for improved generalization. We validate our method on few-shot classification datasets, whose results show that it significantly improves the generalization performance of the base model, and largely outperforms existing regularization methods such as information bottleneck, manifold mixup, and information dropout.", "code": "https://github.com/haebeom-lee/metadrop", "keywords": [], "paperhash": "lee|meta_dropout_learning_to_perturb_latent_features_for_generalization", "_bibtex": "@inproceedings{\nLee2020Meta,\ntitle={Meta Dropout: Learning to Perturb Latent Features for Generalization},\nauthor={Hae Beom Lee and Taewook Nam and Eunho Yang and Sung Ju Hwang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJgd81SYwr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/178c856fe689f5a2dc8005380358efe7b5f252aa.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJgd81SYwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1735/Authors", "ICLR.cc/2020/Conference/Paper1735/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1735/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1735/Reviewers", "ICLR.cc/2020/Conference/Paper1735/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1735/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1735/Authors|ICLR.cc/2020/Conference/Paper1735/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504151650, "tmdate": 1576860530614, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1735/Authors", "ICLR.cc/2020/Conference/Paper1735/Reviewers", "ICLR.cc/2020/Conference/Paper1735/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1735/-/Official_Comment"}}}, {"id": "ByemJtbwsB", "original": null, "number": 4, "cdate": 1573488859171, "ddate": null, "tcdate": 1573488859171, "tmdate": 1573488859171, "tddate": null, "forum": "BJgd81SYwr", "replyto": "H1lRMzRpYr", "invitation": "ICLR.cc/2020/Conference/Paper1735/-/Official_Comment", "content": {"title": "Response to Reviewer #3 (2/2)", "comment": "5. It seems like Equation 7 is wrong because y_i is missing from the second argument of the KL divergence term. The transition to Equation 8 is therefore also wrong, and as far as I can understand, the whole argument breaks down.\n\n- This is a critical misunderstanding. Equation 7 is correct. In Equation 7, the second argument p(z|x) is called a \u201cconditional prior\u201d, which does not observe the label y since p(z|x) is part of the generative process. See the Equation 4 of Sohn et al. [1] which is exactly the same as the Equation 7 of our paper.\n\nIt seems that you are confused with the following decomposition of log evidence:\n\nLog evidence = ELBO + $KL[q(z|x,y)\\|p(z|x,y)]$,\t\t        (a)\nELBO = E[Log-likelihood] - $KL[q(z|x,y)\\|p(z|x)]$\t\t(b)\n \nThe log evidence term is decomposed of ELBO and the KL term involving $p(z|x,y)$ in Eq. (a). However, what Eq.7 in the main paper describes is the actual ELBO expression in Eq.(b), which contains the KL divergence between the approximate posterior and the prior $p(z|x)$. \n\nReference: [1] Sohn et al., Learning Structured Output Representation using Deep Conditional Generative Models, In NIPS, 2015.\n \n\n6. Line 7 in Algorithm 1 in Appendix A (which by the way should really be in the main text) does not make sense. The second sentence of the abstract is not implied by the first, the usage of \u201cthus\u201d does not seem appropriate. The intro should probably mention L1 and L2 regularization as well. \u201cmeta-droput\u201d, \u201crobustenss\u201d: typos in many places.\n\n- Thank you for pointing them out. We updated the revision based on your suggestions. \n\n\n7. Figure 4 visualization is not clear.\n\n- Figure 4 visualizes the perturbations generated by our Meta-Dropout and the decision boundary for classification. Could you provide us more specific comments on which part of Figure 4 is not clear? \n\n\n8. The architectural change required to add noise is not explained in the paper (i.e. what is \\phi and how it\u2019s used).\n\n- The architectural change and \\phi are clearly explained in Figure 2 and the paragraph \u201cform of the noise\u201d at the end of page 4.\n\n\n9. Additional baselines\n\n- We conduct experiments on additional baselines as requested:\n(1) MetaReg: MAML + L1 regularization\n(2) MAML (R3): \\phi treated as \\theta, as R3 requested\n\nModels\t\t\t\tOmni-1shot\tOmni-5shot\tmimg-1shot\tmimg-5shot\nMAML\t\t\t\t95.23+-0.17\t98.38+-0.07\t49.58+-0.65\t64.55+-0.52\nMetaReg (Ours)\t\t95.28+-0.15\t98.85+-0.06\t49.76+-0.67\t65.42+-0.53\nMAML (R3)\t\t\t96.15+-0.15\t98.69+-0.07\t42.08+-0.63\t62.82+-0.53\nMeta-dropout\t\t96.63+-0.13\t98.73+-0.06\t51.93+-0.67\t67.42+-0.52\n \nAs shown, all the suggested baseline models largely underperform Meta-Dropout.  \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1735/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1735/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["haebeom.lee@kaist.ac.kr", "namsan@kaist.ac.kr", "eunhoy@kaist.ac.kr", "sjhwang82@kaist.ac.kr"], "title": "Meta Dropout: Learning to Perturb Latent Features for Generalization", "authors": ["Hae Beom Lee", "Taewook Nam", "Eunho Yang", "Sung Ju Hwang"], "pdf": "/pdf/0eed1795c32d19171f8f21961a0cdc58d8315d41.pdf", "abstract": "A machine learning model that generalizes well should obtain low errors on unseen test examples. Thus, if we know how to optimally perturb training examples to account for test examples, we may achieve better generalization performance. However, obtaining such perturbation is not possible in standard machine learning frameworks as the distribution of the test data is unknown. To tackle this challenge, we propose a novel regularization method, meta-dropout, which learns to perturb the latent features of training examples for generalization in a meta-learning framework. Specifically, we meta-learn a noise generator which outputs a multiplicative noise distribution for latent features, to obtain low errors on the test instances in an input-dependent manner. Then, the learned noise generator can perturb the training examples of unseen tasks at the meta-test time for improved generalization. We validate our method on few-shot classification datasets, whose results show that it significantly improves the generalization performance of the base model, and largely outperforms existing regularization methods such as information bottleneck, manifold mixup, and information dropout.", "code": "https://github.com/haebeom-lee/metadrop", "keywords": [], "paperhash": "lee|meta_dropout_learning_to_perturb_latent_features_for_generalization", "_bibtex": "@inproceedings{\nLee2020Meta,\ntitle={Meta Dropout: Learning to Perturb Latent Features for Generalization},\nauthor={Hae Beom Lee and Taewook Nam and Eunho Yang and Sung Ju Hwang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJgd81SYwr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/178c856fe689f5a2dc8005380358efe7b5f252aa.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJgd81SYwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1735/Authors", "ICLR.cc/2020/Conference/Paper1735/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1735/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1735/Reviewers", "ICLR.cc/2020/Conference/Paper1735/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1735/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1735/Authors|ICLR.cc/2020/Conference/Paper1735/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504151650, "tmdate": 1576860530614, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1735/Authors", "ICLR.cc/2020/Conference/Paper1735/Reviewers", "ICLR.cc/2020/Conference/Paper1735/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1735/-/Official_Comment"}}}, {"id": "H1lRMzRpYr", "original": null, "number": 1, "cdate": 1571836438249, "ddate": null, "tcdate": 1571836438249, "tmdate": 1572972430343, "tddate": null, "forum": "BJgd81SYwr", "replyto": "BJgd81SYwr", "invitation": "ICLR.cc/2020/Conference/Paper1735/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "The paper proposes learning to add input-dependent noise to improve the generalization of MAML-style meta-learning algorithm. The proposed method is evaluated on OmniGlot and miniImageNet. The paper reports improvements upon MAML, MAML with meta-learned parameter-wise learning rates, as well as a few regularization methods that are based on input/hidden state perturbations (Mixup, Variational Information Bottleneck). An ablation study also compares the proposed meta-dropout algorithm with a number of modifications, such as a fixed noise, input-independent noise, etc. It is furthermore shown that meta-dropout somewhat improves the model\u2019s robustness against an adversarial attack. \n\nThe paper is somewhat incremental considering that Li et al, (2017) and Balaji et al, (2018) have already proposed meta-learning parameter-wise learning rates and parameter-wise regularization coefficient respectively. One difference from the methods above is that in the proposed method noise is controlled by the input. The ablation however shows that in 5-shot classification case simply adding non-trainable noise works quite well. \n\nIt seems like the choice of the particular method for adding the noise was performed using the test set. If it\u2019s true, this is methodologically wrong: model selection should be performed on a development set (or meta-development) set. Futhermore, Table 2 contains some results named \u201cAdd.\u201d, which I guess stands for additive noise. I did not find an explanation of what is the specific method for adding noise used in this case. Such additive noise is also missing from ablation experiments. \n\nOverall, it seems that paper falls short of clearly proving that back-propagating through MAML to the noise parameters is helpful. The \u201cDeterministic Meta-Dropout\u201d performs better than baseline MAML, and arguably, meaning that some part of the improvement upon MAML can be due to the architectural differences and not due to noise. \u201cIndependent Gaussian\u201d and \u201cWeight Gaussian\u201d baselines perform worse than non-trainable noise (\u201cFixed Gaussian\u201d). Learning the variance for the noise is shown to be detrimental. There is just too much confusion in the results, the improvements are not very robust. \n\nThe paper writing is okay, but there are serious issues. I am not sure I understand the argument in Section 3.2 that meta-dropout performs variational inference. It seems like Equation 7 is wrong because  y_i is missing from the second argument of the KL divergence term. The transition to Equation 8 is therefore also wrong, and as far as I can understand, the whole argument breaks down. Line 7 in Algorithm 1 in Appendix A (which by the way should really be in the main text) does not make sense.\n\nOther issues: \n- the second sentence of the abstract is not implied by the first, the usage of \u201cthus\u201d does not seem appropriate\n- the intro should probably mention L1 and L2 regularization as well\n- in Section 3.1 there is a forward reference to Equation 5, makes understanding the text quite hard\n- \u201cmeta-droput\u201d, \u201crobustenss\u201d: typos in many places\n- Figure 4 visualization is not clear. \n- the architectural change required to add noise is not explained in the paper (i.e. what is \\phi and how it\u2019s used) \n- no comparison to meta-learned L1 regularization \n- a baseline is missing in which \\phi is treated as a part of \\theta and trained with vanilla MAML\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1735/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1735/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["haebeom.lee@kaist.ac.kr", "namsan@kaist.ac.kr", "eunhoy@kaist.ac.kr", "sjhwang82@kaist.ac.kr"], "title": "Meta Dropout: Learning to Perturb Latent Features for Generalization", "authors": ["Hae Beom Lee", "Taewook Nam", "Eunho Yang", "Sung Ju Hwang"], "pdf": "/pdf/0eed1795c32d19171f8f21961a0cdc58d8315d41.pdf", "abstract": "A machine learning model that generalizes well should obtain low errors on unseen test examples. Thus, if we know how to optimally perturb training examples to account for test examples, we may achieve better generalization performance. However, obtaining such perturbation is not possible in standard machine learning frameworks as the distribution of the test data is unknown. To tackle this challenge, we propose a novel regularization method, meta-dropout, which learns to perturb the latent features of training examples for generalization in a meta-learning framework. Specifically, we meta-learn a noise generator which outputs a multiplicative noise distribution for latent features, to obtain low errors on the test instances in an input-dependent manner. Then, the learned noise generator can perturb the training examples of unseen tasks at the meta-test time for improved generalization. We validate our method on few-shot classification datasets, whose results show that it significantly improves the generalization performance of the base model, and largely outperforms existing regularization methods such as information bottleneck, manifold mixup, and information dropout.", "code": "https://github.com/haebeom-lee/metadrop", "keywords": [], "paperhash": "lee|meta_dropout_learning_to_perturb_latent_features_for_generalization", "_bibtex": "@inproceedings{\nLee2020Meta,\ntitle={Meta Dropout: Learning to Perturb Latent Features for Generalization},\nauthor={Hae Beom Lee and Taewook Nam and Eunho Yang and Sung Ju Hwang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJgd81SYwr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/178c856fe689f5a2dc8005380358efe7b5f252aa.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJgd81SYwr", "replyto": "BJgd81SYwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1735/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1735/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575579109125, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1735/Reviewers"], "noninvitees": [], "tcdate": 1570237733058, "tmdate": 1575579109138, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1735/-/Official_Review"}}}, {"id": "S1e1sc_GqB", "original": null, "number": 3, "cdate": 1572141718603, "ddate": null, "tcdate": 1572141718603, "tmdate": 1572972430255, "tddate": null, "forum": "BJgd81SYwr", "replyto": "BJgd81SYwr", "invitation": "ICLR.cc/2020/Conference/Paper1735/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes meta dropout, which leverages adaptive dropout training for regularizing gradient based meta learning models, e.g., MAML and MetaSGD. Experiments on few shot learning show that meta dropout achieves better performance.\n\nOverally, I think this paper is well motivated and experiments on few shot learning are impressive. I have only two major concerns.\n\n1. Sec 3.2. According to my understanding, Meta dropout introduces a learnable prior for latent $z$, but the training objective does not require posterior inference and thus no variational inference is needed. I think it is ok to say that meta dropout tries to optimize a lower bound of log p(Y|X;\\theta,\\phi^*), but meta dropout does not regularize the variational framework because there is no variational inference framework.\n\n2. Experiments on adversarial robustness can be further improved. (1) the settings and the analysis of adversarial robustness experiment can be discussed in details. For example, how to build ''adversarial learning baseline'' in meta learning settings and why the result implies the perturbation directions for generalization and robustness relates to each other; (2) how other regularization methods (e.g., Mixup, VIB and Information dropout) perform on adversarial robustness? Does Meta dropout performs better than them? (3) FGSM is a quite weak adversarial attack method, which makes evaluating adversarial robustness on FGSM may be misleading. I suggest trying some other STOA attack methods (e.g., iterative methods).\n\nSome typos: \nPage 3, Regularization methods, 3rd line, ````wwwdiscuss\nPage 7, 2nd line from the bottom, FSGM->FGSM\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1735/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1735/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["haebeom.lee@kaist.ac.kr", "namsan@kaist.ac.kr", "eunhoy@kaist.ac.kr", "sjhwang82@kaist.ac.kr"], "title": "Meta Dropout: Learning to Perturb Latent Features for Generalization", "authors": ["Hae Beom Lee", "Taewook Nam", "Eunho Yang", "Sung Ju Hwang"], "pdf": "/pdf/0eed1795c32d19171f8f21961a0cdc58d8315d41.pdf", "abstract": "A machine learning model that generalizes well should obtain low errors on unseen test examples. Thus, if we know how to optimally perturb training examples to account for test examples, we may achieve better generalization performance. However, obtaining such perturbation is not possible in standard machine learning frameworks as the distribution of the test data is unknown. To tackle this challenge, we propose a novel regularization method, meta-dropout, which learns to perturb the latent features of training examples for generalization in a meta-learning framework. Specifically, we meta-learn a noise generator which outputs a multiplicative noise distribution for latent features, to obtain low errors on the test instances in an input-dependent manner. Then, the learned noise generator can perturb the training examples of unseen tasks at the meta-test time for improved generalization. We validate our method on few-shot classification datasets, whose results show that it significantly improves the generalization performance of the base model, and largely outperforms existing regularization methods such as information bottleneck, manifold mixup, and information dropout.", "code": "https://github.com/haebeom-lee/metadrop", "keywords": [], "paperhash": "lee|meta_dropout_learning_to_perturb_latent_features_for_generalization", "_bibtex": "@inproceedings{\nLee2020Meta,\ntitle={Meta Dropout: Learning to Perturb Latent Features for Generalization},\nauthor={Hae Beom Lee and Taewook Nam and Eunho Yang and Sung Ju Hwang},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJgd81SYwr}\n}", "full_presentation_video": "", "original_pdf": "/attachment/178c856fe689f5a2dc8005380358efe7b5f252aa.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJgd81SYwr", "replyto": "BJgd81SYwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1735/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1735/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575579109125, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1735/Reviewers"], "noninvitees": [], "tcdate": 1570237733058, "tmdate": 1575579109138, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1735/-/Official_Review"}}}], "count": 11}