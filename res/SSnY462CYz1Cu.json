{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1363278840000, "tcdate": 1363278840000, "number": 2, "id": "L8RreQWdPS3jz", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "SSnY462CYz1Cu", "replyto": "SSnY462CYz1Cu", "signatures": ["\u00c7a\u011flar G\u00fcl\u00e7ehre"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "Replies for the reviewers' comments are prepared by the both authors of the paper: Yoshua Bengio and Caglar Gulcehre."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Knowledge Matters: Importance of Prior Information for Optimization", "decision": "conferenceOral-iclr2013-conference", "abstract": "We explore the effect of introducing prior information into the intermediate level of neural networks for a learning task on which all the state-of-the-art machine learning algorithms tested failed to learn. We motivate our work from the hypothesis that humans learn such intermediate concepts from other individuals via a form of supervision or guidance using a curriculum. The experiments we have conducted provide positive evidence in favor of this hypothesis. In our experiments, a two-tiered MLP architecture is trained on a dataset with 64x64 binary inputs images, each image with three sprites. The final task is to decide whether all the sprites are the same or one of them is different. Sprites are pentomino tetris shapes and they are placed in an image with different locations using scaling and rotation transformations. The first part of the two-tiered MLP is pre-trained with intermediate-level targets being the presence of sprites at each location, while the second part takes the output of the first part as input and predicts the final task's target binary event. The two-tiered MLP architecture, with a few tens of thousand examples, was able to learn the task perfectly, whereas all other algorithms (include unsupervised pre-training, but also traditional algorithms like SVMs, decision trees and boosting) all perform no better than chance. We hypothesize that the optimization difficulty involved when the intermediate pre-training is not performed is due to the {em composition} of two highly non-linear tasks. Our findings are also consistent with hypotheses on cultural learning inspired by the observations of optimization problems with deep learning, presumably because of effective local minima.", "pdf": "https://arxiv.org/abs/1301.4083", "paperhash": "g\u00fcl\u00e7ehre|knowledge_matters_importance_of_prior_information_for_optimization", "keywords": [], "conflicts": [], "authors": ["\u00c7a\u011flar G\u00fcl\u00e7ehre", "Yoshua Bengio"], "authorids": ["ca9lar@gmail.com", "yoshua.bengio@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1363246680000, "tcdate": 1363246680000, "number": 4, "id": "lLgil9MwiZ3Vu", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "SSnY462CYz1Cu", "replyto": "SSnY462CYz1Cu", "signatures": ["\u00c7a\u011flar G\u00fcl\u00e7ehre"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "We have uploaded the revision of the paper to arxiv. The revision will be announced by Arxiv soon."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Knowledge Matters: Importance of Prior Information for Optimization", "decision": "conferenceOral-iclr2013-conference", "abstract": "We explore the effect of introducing prior information into the intermediate level of neural networks for a learning task on which all the state-of-the-art machine learning algorithms tested failed to learn. We motivate our work from the hypothesis that humans learn such intermediate concepts from other individuals via a form of supervision or guidance using a curriculum. The experiments we have conducted provide positive evidence in favor of this hypothesis. In our experiments, a two-tiered MLP architecture is trained on a dataset with 64x64 binary inputs images, each image with three sprites. The final task is to decide whether all the sprites are the same or one of them is different. Sprites are pentomino tetris shapes and they are placed in an image with different locations using scaling and rotation transformations. The first part of the two-tiered MLP is pre-trained with intermediate-level targets being the presence of sprites at each location, while the second part takes the output of the first part as input and predicts the final task's target binary event. The two-tiered MLP architecture, with a few tens of thousand examples, was able to learn the task perfectly, whereas all other algorithms (include unsupervised pre-training, but also traditional algorithms like SVMs, decision trees and boosting) all perform no better than chance. We hypothesize that the optimization difficulty involved when the intermediate pre-training is not performed is due to the {em composition} of two highly non-linear tasks. Our findings are also consistent with hypotheses on cultural learning inspired by the observations of optimization problems with deep learning, presumably because of effective local minima.", "pdf": "https://arxiv.org/abs/1301.4083", "paperhash": "g\u00fcl\u00e7ehre|knowledge_matters_importance_of_prior_information_for_optimization", "keywords": [], "conflicts": [], "authors": ["\u00c7a\u011flar G\u00fcl\u00e7ehre", "Yoshua Bengio"], "authorids": ["ca9lar@gmail.com", "yoshua.bengio@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1363246380000, "tcdate": 1363246380000, "number": 1, "id": "OblAf-quHwf1V", "invitation": "ICLR.cc/2013/-/submission/reply", "forum": "SSnY462CYz1Cu", "replyto": "nMIynqm1yCndY", "signatures": ["\u00c7a\u011flar G\u00fcl\u00e7ehre"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "> However, I think it would have been helpful to provide more empirical or theoretical analysis into *why* these algorithms fail, and what makes the task difficult. In particular, at what point does the complexity come in? Is the difficulty of the task qualitative or quantitative? The task would be qualitatively the same with just three patches and three categories of objects, or perhaps even just three multinomial units as input. I would be curious to see at least an empirical analysis into this question, by varying the complexity of the task, not just the types of algorithms and their parameters. \r\n\r\nWe have done more experiments to explore the effect of the difficulty of the task. In particular, we considered three settings aimed at making the task gradually easier: (1) map each possible patch-level input vector into an integer (one out of 81=(1 for no-object + 10 x 4 x 2) and a corresponding one-hot 80-bit input vector (and feed the concatenation of these 64 vectors as input to a classifier), (2) map each possible patch-level input vector into a disentangled representation with 3 one-hot vectors (10 bits + 4 bits + 2 bits) in which the class can be read directly (and one could imagine as the best possible outcome of unsupervised pre-training), and (3) only retain the actual object categories (with only the first 10 bits per patch, for the 10 classes). We found that (2) and (3) can be learned perfectly while (1) can be partially learned (down to about 30% error with 80k training examples). So it looks like part of the problem (as we had surmised) is to separate class information from the factors, while somehow the image-like encoding is actually harder to learn from (probably an ill-conditioning problem) than the one-hot encoding per patch.\r\n\r\n> As for answering the question of what makes the task difficult, the crux appears to be that the task implicitly requires invariant object recognition: to solve the second stage task (are all objects of the same category?), the algorithm essentially has to solve the problem of invariant object recognition first (what makes a category?). As the authors have shown, given the knowledge about object categories, the second stage task becomes easy to solve. It is interesting that the weak supervision signal provided in stage two alone is not enough to guide the algorithm to discover the object categories first, but I'm not sure that it is that surprising.\r\n\r\nVisually much more complex tasks are being rather successfully handled with deep convolutional nets, as in the recent work by Kryzhevski & Hinton at NIPS 2012. It is therefore surprising that such a simplified task would make most learning algorithms fail. We believe it boils down to an optimization issue (the difficulty of training the lower layers well, in spite of correct supervised learning gradients being computed through the upper layers) and our experiments are consistent with that hypothesis.\r\n\r\nThe experiments described above with disentangled inputs suggest that if unsupervised learning was doing an optimal job, it should be possible to solve the problem.\r\n\r\n> In this light, it is not clear to me how the work relates to specifically 'cultural learning'. The authors do not model knowledge exchange between agents as such, and it is not clear why the task at hand would be one where cultural learning is particularly relevant. The general issue of what knowledge or inductive biases are needed to learn useful representations, in particular for invariant object recognition, is indeed very interesting, and I think seldom addressed in deep learning beyond building in translation invariance. For the example of invariant object recognition, learning from temporal sequences and building in biases about 'temporal coherence' or 'slowness' (F\u00f6ldi\u00e1k 91, Wiskott & Sejnowski 02) have been suggested as solutions. This has indeed been explored in deep learning at least in one case (Mobahi et al, 09), and might be more appropriate to address the task at hand (with sequential images). I think that if the authors believe that cultural learning is an important ingredient to deep learning or an interesting issue on its own, they perhaps need to find a more relevant task and then show that it can solved with a model that really utilizes cultural learning specifically, not just general supervision\r\n\r\nThe main difficulty of this task stems from the composition of two distinct tasks, the first task is the invariant object recognition and second task is learning the logical relation between the objects in the image. Each task can be solved fairly easily on its own, otherwise IKGNN couldn't learn this task. But we claim that combination of these two tasks raises an optimization difficulty that the machine learning algorithms that we have tried failed to overcome.\r\n\r\nWe are aware that slow features might be useful for solving this task and we plan to investigate that as well. We also believe that as such, temporal coherence would be a much more plausible explanation as to how humans learn such visual tasks, since humans learn to see quite well with little or no verbal cues from parents or teachers (and of course, all the other animals that have very good vision do not have a culture or one nearly as developed as that of humans).  On the other hand, we believe that this kind of two-level abstraction learning problem illustrates a more general training difficulty that humans may face when trying to learn higher level abstractions (precisely of the kind that we need teachers for).\r\n\r\nUnfortunately there is not yet much work combining cultural learning and deep learning. This paper is meant to lay the motivational grounds for such work, by showing simple examples where we might need cultural learning and where ordinary supervised learning (without intermediate concepts guidance) or even unsupervised pre-training face a very difficult training challenge.  The other connection is that these experiments are consistent with aspects of the cultural learning hypotheses laid down in Bengio 2012: if learning more abstract concepts (that require a deeper architecture that captures distinct abstractions, as in our task) is a serious optimization challenge, this challenge could also be an issue for brains, making it all the more important to explain how humans manage to deal with such problems (presumably thanks to the guidance of other humans, e.g., by providing hints about intermediate abstractions).\r\n\r\nWe wanted to show that there are problems that are inherently hard for current machine learning algorithms and motivate cultural learning: distributed and parallelized learning of such higher level concepts might be more efficient for solving this kind of tasks.\r\n\r\n> Lastly, an issue I am confused by: if the second stage task (given the correct intermediate results from the first stage) corresponds to an 'XOR-like' problem, how come a single perceptron in the second stage can solve it?\r\n\r\nIn the second stage THERE ARE HIDDEN UNITS. It is not a simple perceptron but a simple MLP. We have used a RELU MLP with 2048 hidden units and a sigmoid output trained with a crossentropy training objective."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Knowledge Matters: Importance of Prior Information for Optimization", "decision": "conferenceOral-iclr2013-conference", "abstract": "We explore the effect of introducing prior information into the intermediate level of neural networks for a learning task on which all the state-of-the-art machine learning algorithms tested failed to learn. We motivate our work from the hypothesis that humans learn such intermediate concepts from other individuals via a form of supervision or guidance using a curriculum. The experiments we have conducted provide positive evidence in favor of this hypothesis. In our experiments, a two-tiered MLP architecture is trained on a dataset with 64x64 binary inputs images, each image with three sprites. The final task is to decide whether all the sprites are the same or one of them is different. Sprites are pentomino tetris shapes and they are placed in an image with different locations using scaling and rotation transformations. The first part of the two-tiered MLP is pre-trained with intermediate-level targets being the presence of sprites at each location, while the second part takes the output of the first part as input and predicts the final task's target binary event. The two-tiered MLP architecture, with a few tens of thousand examples, was able to learn the task perfectly, whereas all other algorithms (include unsupervised pre-training, but also traditional algorithms like SVMs, decision trees and boosting) all perform no better than chance. We hypothesize that the optimization difficulty involved when the intermediate pre-training is not performed is due to the {em composition} of two highly non-linear tasks. Our findings are also consistent with hypotheses on cultural learning inspired by the observations of optimization problems with deep learning, presumably because of effective local minima.", "pdf": "https://arxiv.org/abs/1301.4083", "paperhash": "g\u00fcl\u00e7ehre|knowledge_matters_importance_of_prior_information_for_optimization", "keywords": [], "conflicts": [], "authors": ["\u00c7a\u011flar G\u00fcl\u00e7ehre", "Yoshua Bengio"], "authorids": ["ca9lar@gmail.com", "yoshua.bengio@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1363246320000, "tcdate": 1363246320000, "number": 1, "id": "MF7RMafDRkF_A", "invitation": "ICLR.cc/2013/-/submission/reply", "forum": "SSnY462CYz1Cu", "replyto": "TiDHTEGclh1ro", "signatures": ["\u00c7a\u011flar G\u00fcl\u00e7ehre"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "> The work by Fleuret et al (Comparing machines and humans on a visual categorization test. PNAS 2011) needs to be discussed. This paper focuses on a single task which appears to be a special case from the longer list of 'reasoning' tasks proposed by Fleuret et al.\r\n\r\nYes we agree that some of the tasks in the Fleuret et al. paper are similar to our task.  We cited this paper in the new revision. Thanks for pointing it out.\r\n\r\nThe biggest difference between the Fleuret et al paper and our approach is that we purposely did not use any preprocessing, in order to make the task *difficult* and show the limitations of a vast range of learning algorithms. This highlights differences between the goals of those papers, of course.\r\n\r\n> In addition, the proposed study reports a null result, which is of course always a little problematic (the fact that the authors did not manage to train a classical NN to solve the problem does not mean it is impossible). At the same time, the authors have explored reasonably well the space of hyper parameters and seem to have done their best in getting the NN to succeed.\r\n\r\nWe agree with that statement. Nonetheless, negative results (especially when they are confirmed by other labs) can have a powerful impact of research, by highlighting the limitations of current algorithms and thus directing research fruitfully towards addressing important challenges. It is unfortunately more difficult to publish negative results in our community, in part because computer scientists do not have as much as other scientists (such as biologists) the culture of replicating experiments and publishing these validations.\r\n\r\n> Minor points: The structure of the paper is relatively confusing. Sections 1.1 and 2 provide a review of some published work by the authors and does not appear to be needed for understanding the paper. In my view the paper could be shortened or at least most of the opinions/speculations in the introduction should be moved to the discussion section.\r\n\r\nWe disagree. The main motivation for these experiments was to empirically validate some aspects of the hypotheses discussed in Bengio 2012 on local minima and cultural evolution. If learning more abstract concepts (that require a deeper architecture) is a serious optimization challenge, this challenge could also be an issue for brains, making it all the more important to explain how humans manage to deal with such problems (presumably thanks to the guidance of other humans, e.g., by providing hints about intermediate abstractions)."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Knowledge Matters: Importance of Prior Information for Optimization", "decision": "conferenceOral-iclr2013-conference", "abstract": "We explore the effect of introducing prior information into the intermediate level of neural networks for a learning task on which all the state-of-the-art machine learning algorithms tested failed to learn. We motivate our work from the hypothesis that humans learn such intermediate concepts from other individuals via a form of supervision or guidance using a curriculum. The experiments we have conducted provide positive evidence in favor of this hypothesis. In our experiments, a two-tiered MLP architecture is trained on a dataset with 64x64 binary inputs images, each image with three sprites. The final task is to decide whether all the sprites are the same or one of them is different. Sprites are pentomino tetris shapes and they are placed in an image with different locations using scaling and rotation transformations. The first part of the two-tiered MLP is pre-trained with intermediate-level targets being the presence of sprites at each location, while the second part takes the output of the first part as input and predicts the final task's target binary event. The two-tiered MLP architecture, with a few tens of thousand examples, was able to learn the task perfectly, whereas all other algorithms (include unsupervised pre-training, but also traditional algorithms like SVMs, decision trees and boosting) all perform no better than chance. We hypothesize that the optimization difficulty involved when the intermediate pre-training is not performed is due to the {em composition} of two highly non-linear tasks. Our findings are also consistent with hypotheses on cultural learning inspired by the observations of optimization problems with deep learning, presumably because of effective local minima.", "pdf": "https://arxiv.org/abs/1301.4083", "paperhash": "g\u00fcl\u00e7ehre|knowledge_matters_importance_of_prior_information_for_optimization", "keywords": [], "conflicts": [], "authors": ["\u00c7a\u011flar G\u00fcl\u00e7ehre", "Yoshua Bengio"], "authorids": ["ca9lar@gmail.com", "yoshua.bengio@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1363246260000, "tcdate": 1363246260000, "number": 1, "id": "wX4ew9_0vK2CA", "invitation": "ICLR.cc/2013/-/submission/reply", "forum": "SSnY462CYz1Cu", "replyto": "6s7Ys8Q5JbfHZ", "signatures": ["\u00c7a\u011flar G\u00fcl\u00e7ehre"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "> The exposition on curriculum learning could be condensed. (minor) The demonstrative problem (sprite counting) is a visual perception problem and therefore carries with it the biases of our own perception and inferred strategies. Maybe the overall argument might be bolstered by the addition of a more abstract example?\r\n\r\nYes that's right. We have performed an experiment in which all the possible bit configurations of a single patch were enumerated (there are 80 of them plus the special case where no object is present).  With this input representation, there is no vision prior knowledge that can help a human learner.  The task is strangely easier  but still difficult: we achieved 25% test error up to now, i.e., better than chance (i.e. 50%) but far from the less than 1% error of the IKGNN.  In future work, we will measure how well humans learn that task.\r\n\r\n> why so many image regions? Why use an 8x8 grid? Won't 3 regions suffice to make the point? Or is this related to the complexity of the problem. A related question: how are the results effected by the number of these regions? Maybe some reduced tests at the extremes would be interesting, i.e.  with only 3 regions, and 32 (you have 64 already)?\r\n\r\nThe current architecture is trained on 64=8x8 patches, with sprites centered inside the patches.  We have also tried to train the IKGNN on 16x16 patches, corresponding to 4x4=16 patches in a same-size image, and we allowed the objects to be randomly translated inside the patch but IKGNN couldn't learn the task. Probably because of the translation, the P1NN required a convolutional architecture.\r\n\r\nWe have also conducted experiments with the tetromino dataset (which is not in that paper) that has 16x16 images and objects are placed in 4x4 patches with less variations and 7 sprite categories.  An ordinary MLP with 3 tanh hidden layers was able to learn this task after a very long training.\r\n\r\nWe trained Structured MLP on the 3 patches(8x8) that has sprite in it for 120 training epochs with 100k\r\ntraining examples. The best result we could get with that setting is 37 percent error on training\r\nset and SMLP was still doing chance on the test set.\r\n\r\nIn a nutshell, reducing the number of regions and centering the objects inside each sprite in those regions implies reducing the complexity of the problem and yes if you reduce the complexity of the problem, you reduce the complexity of the task and you start seeing models that can learn it, with ordinary MLPs learning the task after a very long training on a large training set. \r\n\r\n> In the networks that solve the task, are the weights that are learned symmetric over the image regions? i.e. are these weights identical (maybe up to some scaling and sign flip). Is there anything you have determined about the structure of the learned second layer of the IKGNN?\r\n\r\nIn the first layer on each patch, we trained exactly the same (first level) MLP on each patch, while the second level MLP is trained on the standardized softmax probabilites of the first level. Hence the weights are shared across patches in the first level. The first level of IKGNN (P1NN) has translation equivariance, but the second level (P2NN) is fully-connected and does not have any prior knowledge of symmetries.\r\n\r\n> Furthermore, what about including a 'weight sharing' constraint in the general MLP model (the one that does not solve the problem, but has the same structure as the one that does)? Would including this constraint change the solution? (the constraint is already in the P1NN, but what about adding it into the P2NN?) Another way to ask this is: Is enforcing translation invariance in the network sufficient to achieve good performance, or do we need to specifically train for the sprite discrimination?\r\n\r\nIndeed, it would be possible to use a convolutional architecture (with pooling, because the output is for the whole image) for the second level as well.  We have not tried that yet but we agree that it would indeed be an interesting possibility and we certainly plan to try it out. Up to now, though, we have found that enforcing translation equivariance (in the lower level) was important but not sufficient to solve the problem. Indeed, the poor result obtained by the structured MLP demonstrates that.\r\n\r\n> Do we know if humans can solve this problem 'in a glance?': flashing the image for a small amount of time ~100-200msecs. Either with or without a mask? It seems that the networks you have derived are solving such a problem 'in a glance.'\r\n\r\nWe didn't conduct any trials for measuring response times and learning speed of human subjects on this dataset. However, we agree such a study would be an important follow-up to this paper.\r\n\r\n\r\n> Is there an argument to be made that the sequential nature of language allows humans to solve this task? Even the way you formulate the problem suggests this sequential process: 'are all of the sprites in the image the same?': in other words 'find the sprites, then decide if they are the same' When I imagine solving this problem myself, I imagine performing a more sequential process: look at one sprite, then the next, (is it the same?, if it is): look at the next sprite (is it the same?). I know that we can consider this problem to be a concrete example of a more abstract learning problem, but it's not clear if humans can solve such problems without sequential processing. Anyway, this is not a criticism, per se, just food for thought.\r\n\r\nYes we agree that the essence of the tasks requires a sequential processing and you can also find this sequential processing in our IKGNN architecture as well (and in deep architectures in general). P1NN looks at each patch and identifies the type of objects inside that patch and P2NN decides if the objects identified by P1NN has a different object. What is less clear is whether humans solve such problems by re-using the same 'hardware' (as in a recurrent net) or by composing different computations (e.g., associated with different areas in the brain).\r\n\r\nThere are few studies that investigates the sequential learning in non-human primates which you might find interesting [3].\r\n\r\n[3] Conway, Christopher M., and Morten H. Christiansen. 'Sequential learning in non-human\r\nprimates.' Trends in cognitive Sciences 5, no. 12 (2001): 539-546."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Knowledge Matters: Importance of Prior Information for Optimization", "decision": "conferenceOral-iclr2013-conference", "abstract": "We explore the effect of introducing prior information into the intermediate level of neural networks for a learning task on which all the state-of-the-art machine learning algorithms tested failed to learn. We motivate our work from the hypothesis that humans learn such intermediate concepts from other individuals via a form of supervision or guidance using a curriculum. The experiments we have conducted provide positive evidence in favor of this hypothesis. In our experiments, a two-tiered MLP architecture is trained on a dataset with 64x64 binary inputs images, each image with three sprites. The final task is to decide whether all the sprites are the same or one of them is different. Sprites are pentomino tetris shapes and they are placed in an image with different locations using scaling and rotation transformations. The first part of the two-tiered MLP is pre-trained with intermediate-level targets being the presence of sprites at each location, while the second part takes the output of the first part as input and predicts the final task's target binary event. The two-tiered MLP architecture, with a few tens of thousand examples, was able to learn the task perfectly, whereas all other algorithms (include unsupervised pre-training, but also traditional algorithms like SVMs, decision trees and boosting) all perform no better than chance. We hypothesize that the optimization difficulty involved when the intermediate pre-training is not performed is due to the {em composition} of two highly non-linear tasks. Our findings are also consistent with hypotheses on cultural learning inspired by the observations of optimization problems with deep learning, presumably because of effective local minima.", "pdf": "https://arxiv.org/abs/1301.4083", "paperhash": "g\u00fcl\u00e7ehre|knowledge_matters_importance_of_prior_information_for_optimization", "keywords": [], "conflicts": [], "authors": ["\u00c7a\u011flar G\u00fcl\u00e7ehre", "Yoshua Bengio"], "authorids": ["ca9lar@gmail.com", "yoshua.bengio@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1363246140000, "tcdate": 1363246140000, "number": 1, "id": "PJcXvClTX8vdE", "invitation": "ICLR.cc/2013/-/submission/reply", "forum": "SSnY462CYz1Cu", "replyto": "D5ft5XCZd1cZw", "signatures": ["\u00c7a\u011flar G\u00fcl\u00e7ehre"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "> It is surprising that structured MLP does chance even on training set. On the other hand with 11 output units per parch this is perhaps not so surprising as the network has to fit everything into minimal representation. However one would expect to get better training set resuts with larger sizes. You should put such results into Table 1 and go to even larger sizes, like 100.\r\n\r\nWe conducted experiments with the structured MLP(SMLP) using 11, 50 and 100 hidden units per patch in the final layer of the locally connected part, yielding to chance performance on both the training and the test set. The revision will have a table listing the results we obtained with different number of hidden units.\r\n\r\n\r\n> To continue on this, if you trained sparse coding with high sparsity on each patch you should get 1 in N representation for each instance (with 11x4x3 or more units). It would be good to see what the P2NN would do with such representation. I think this is the primary missing piece of this work.\r\n\r\nThat's a very nice suggestion and indeed it was already in our list of experiments to investigate. We conducted several experiments by using a one-hot representation for each patch and we put the results on these datasets in the revision.\r\n\r\n> It is not quite fair to compare to humans as humans have prior knowledge, specifically of rotations, probably learned from seeing objects rotate.\r\n\r\nHumans are probably doing mental rotation (see [1]) instead of having rotation invariance, which indeed exploits one form of prior knowledge (learned or innate) or another (see [2]).  We have modified the statement accordingly. We have also performed an experiment (reported in the revision) in which all the possible bit configurations of a single patch were enumerated (there are 80 of them plus the special case where no object is present).  With this input representation, there is no vision prior knowledge that can help a human learner.  The task is strangely easier  but still difficult: we achieved 25% test error up to now, i.e., better than chance (i.e. 50%) but far from the less than 1% error of the IKGNN.  In future work, we will measure how well humans learn that task.\r\n\r\n\r\n> I don't think 'Local descent hypothesis' is quite true. We don't just do local approximate descent. First we do one shot learning in hippocampus. Second, we do search for explanations and solutions and we do planning (both unconsciously and consciously). Sure having more agents helps it's a little like running a genetic algorithm - an algorithm that overcomes local minima.\r\n\r\nOne-shot learning is not incompatible with local approximate descent. For example, allocating new parameters to an example to learn by heart is moving in the descent direction from the point of view of functional gradient descent. Searching for explanations and planning belong to the realm of inference. We have inference in many graphical models while training itself still proceeds by local approximate descent. And you are right that having multiple agents sharing knowledge is like running a genetic algorithm and helps overcome some of the local minima issues.\r\n\r\n\r\n> At the end of page 6 you say P1NN had 2048 units and P2NN 1024 but this is reversed in 3.2.2. Typo?\r\n\r\nThanks for pointing to that typo. The numbers in 3.2.2 are correct.\r\n\r\n[1] K\u00f6hler, C., Hoffmann, K. P., Dehnhardt, G., & Mauck, B. (2005). Mental Rotation and Rotational\r\nInvariance in the Rhesus Monkey<i>(Macaca mulatta)</i>. Brain, Behavior and Evolution, 66(3),\r\n158-166.\r\n\r\n[2] Corballis, Michael C. 'Mental rotation and the right hemisphere.' Brain and Language 57.1\r\n(1997): 100-121."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Knowledge Matters: Importance of Prior Information for Optimization", "decision": "conferenceOral-iclr2013-conference", "abstract": "We explore the effect of introducing prior information into the intermediate level of neural networks for a learning task on which all the state-of-the-art machine learning algorithms tested failed to learn. We motivate our work from the hypothesis that humans learn such intermediate concepts from other individuals via a form of supervision or guidance using a curriculum. The experiments we have conducted provide positive evidence in favor of this hypothesis. In our experiments, a two-tiered MLP architecture is trained on a dataset with 64x64 binary inputs images, each image with three sprites. The final task is to decide whether all the sprites are the same or one of them is different. Sprites are pentomino tetris shapes and they are placed in an image with different locations using scaling and rotation transformations. The first part of the two-tiered MLP is pre-trained with intermediate-level targets being the presence of sprites at each location, while the second part takes the output of the first part as input and predicts the final task's target binary event. The two-tiered MLP architecture, with a few tens of thousand examples, was able to learn the task perfectly, whereas all other algorithms (include unsupervised pre-training, but also traditional algorithms like SVMs, decision trees and boosting) all perform no better than chance. We hypothesize that the optimization difficulty involved when the intermediate pre-training is not performed is due to the {em composition} of two highly non-linear tasks. Our findings are also consistent with hypotheses on cultural learning inspired by the observations of optimization problems with deep learning, presumably because of effective local minima.", "pdf": "https://arxiv.org/abs/1301.4083", "paperhash": "g\u00fcl\u00e7ehre|knowledge_matters_importance_of_prior_information_for_optimization", "keywords": [], "conflicts": [], "authors": ["\u00c7a\u011flar G\u00fcl\u00e7ehre", "Yoshua Bengio"], "authorids": ["ca9lar@gmail.com", "yoshua.bengio@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362784440000, "tcdate": 1362784440000, "number": 3, "id": "nMIynqm1yCndY", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "SSnY462CYz1Cu", "replyto": "SSnY462CYz1Cu", "signatures": ["David Reichert"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "I would like to add some further comments for the purpose of constructive discussion.\r\n\r\nThe authors try to provide further insights into why and when deep learning works, and to broaden the focus of the kind of questions usually asked in this community, in particular by making connections to biological cognition and learning. I think this a good motivation. There are some issues that I would like to address though.\r\n\r\nAt the core of this work is the result that algorithms can fail at solving the given classification task unless 'intermediate learning cues' are supplied. The authors cover many different algorithms to make this point. However, I think it would have been helpful to provide more empirical or theoretical analysis into *why* these algorithms fail, and what makes the task difficult. In particular, at what point does the complexity come in? Is the difficulty of the task qualitative or quantitative? The task would be qualitatively the same with just three patches and three categories of objects, or perhaps even just three multinomial units as input. I would be curious to see at least an empirical analysis into this question, by varying the complexity of the task, not just the types of algorithms and their parameters.\r\n\r\nAs for answering the question of what makes the task difficult, the crux appears to be that the task implicitly requires invariant object recognition: to solve the second stage task (are all objects of the same category?), the algorithm essentially has to solve the problem of invariant object recognition first (what makes a category?). As the authors have shown, given the knowledge about object categories, the second stage task becomes easy to solve. It is interesting that the weak supervision signal provided in stage two alone is not enough to guide the algorithm to discover the object categories first, but I'm not sure that it is that surprising.\r\n\r\nOnce the problem of invariant recognition has been identified, I don't think it is that 'surprising' either that unsupervised learning did not help at all. No matter how much data and how clever the algorithm, there is simply no way for an unsupervised algorithm to discover that a given tetris object and its rotated version are in some sense the same thing. This knowledge is however necessary to solve the subsequent same/different task across categories. An algorithm can only learn invariant object recognition given some additional information, either with explicit supervision or with more structure in the data and some in-built inductive biases (some form of semi-supervised learning).\r\n\r\nIn this light, it is not clear to me how the work relates to specifically 'cultural learning'. The authors do not model knowledge exchange between agents as such, and it is not clear why the task at hand would be one where cultural learning is particularly relevant. The general issue of what knowledge or inductive biases are needed to learn useful representations, in particular for invariant object recognition, is indeed very interesting, and I think seldom addressed in deep learning beyond building in translation invariance. For the example of invariant object recognition, learning from temporal sequences and building in biases about 'temporal coherence' or 'slowness' (F\u00f6ldi\u00e1k 91, Wiskott & Sejnowski 02) have been suggested as solutions. This has indeed been explored in deep learning at least in one case (Mobahi et al, 09), and might be more appropriate to address the task at hand (with sequential images). I think that if the authors believe that cultural learning is an important ingredient to deep learning or an interesting issue on its own, they perhaps need to find a more relevant task and then show that it can solved with a model that really utilizes cultural learning specifically, not just general supervision.\r\n\r\nLastly, an issue I am confused by: if the second stage task (given the correct intermediate results from the first stage) corresponds to an 'XOR-like' problem, how come a single perceptron in the second stage can solve it?"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Knowledge Matters: Importance of Prior Information for Optimization", "decision": "conferenceOral-iclr2013-conference", "abstract": "We explore the effect of introducing prior information into the intermediate level of neural networks for a learning task on which all the state-of-the-art machine learning algorithms tested failed to learn. We motivate our work from the hypothesis that humans learn such intermediate concepts from other individuals via a form of supervision or guidance using a curriculum. The experiments we have conducted provide positive evidence in favor of this hypothesis. In our experiments, a two-tiered MLP architecture is trained on a dataset with 64x64 binary inputs images, each image with three sprites. The final task is to decide whether all the sprites are the same or one of them is different. Sprites are pentomino tetris shapes and they are placed in an image with different locations using scaling and rotation transformations. The first part of the two-tiered MLP is pre-trained with intermediate-level targets being the presence of sprites at each location, while the second part takes the output of the first part as input and predicts the final task's target binary event. The two-tiered MLP architecture, with a few tens of thousand examples, was able to learn the task perfectly, whereas all other algorithms (include unsupervised pre-training, but also traditional algorithms like SVMs, decision trees and boosting) all perform no better than chance. We hypothesize that the optimization difficulty involved when the intermediate pre-training is not performed is due to the {em composition} of two highly non-linear tasks. Our findings are also consistent with hypotheses on cultural learning inspired by the observations of optimization problems with deep learning, presumably because of effective local minima.", "pdf": "https://arxiv.org/abs/1301.4083", "paperhash": "g\u00fcl\u00e7ehre|knowledge_matters_importance_of_prior_information_for_optimization", "keywords": [], "conflicts": [], "authors": ["\u00c7a\u011flar G\u00fcl\u00e7ehre", "Yoshua Bengio"], "authorids": ["ca9lar@gmail.com", "yoshua.bengio@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362381600000, "tcdate": 1362381600000, "number": 1, "id": "TiDHTEGclh1ro", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "SSnY462CYz1Cu", "replyto": "SSnY462CYz1Cu", "signatures": ["anonymous reviewer 858d"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Knowledge Matters: Importance of Prior Information for Optimization", "review": "The paper by Gulcehre & Bengio entitled 'Knowledge Matters: Importance of Prior Information for Optimization' presents an empirical study which compares a two-tiered MLP architecture against traditional algorithms including SVM, decision trees and boosting. Images used for this task are 64x64 pixel images containing tetris-like sprite shapes. The proposed task consists in trying to figure out whether all the sprites in the image are from the same category or not (invariant to 2D transformations). \r\n\r\nThe main result from this study is that intermediate guidance (aka building by hand an architecture which 'exploits intermediate level concepts' by dividing the problem in two stages (a classification stage followed by a XOR stage)  solves the problem for which a 'naive' neural net (as well as classical machine learning algorithms) fail.\r\n\r\nPros: The proposed task is relatively interesting as it offers an alternative to traditional pattern matching tasks used in computer vision.  The experiments seem well conducted. The fact that a neural network and other universal approximators do not seem to even get close to learning the task with ~80K training examples is relatively surprising.\r\n\r\nCons:  The work by Fleuret et al (Comparing machines and humans on a visual categorization test. PNAS 2011) needs to be discussed. This paper focuses on a single task which appears to be a special case from the longer list of 'reasoning' tasks proposed by Fleuret et al. \r\n\r\nIn addition, the proposed study reports a null result, which is of course always a little problematic (the fact that the authors did not manage to train a classical NN to solve the problem does not mean it is impossible). At the same time, the authors have explored reasonably well the space of hyper parameters and seem to have done their best in getting the NN to succeed.\r\n\r\n\r\nMinor points: The structure of the paper is relatively confusing. Sections 1.1 and 2  provide a review of some published work by the authors and does not appear to be needed for understanding the paper. In my view the paper could be shortened or at least most of the opinions/speculations in the introduction should be moved to the discussion section."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Knowledge Matters: Importance of Prior Information for Optimization", "decision": "conferenceOral-iclr2013-conference", "abstract": "We explore the effect of introducing prior information into the intermediate level of neural networks for a learning task on which all the state-of-the-art machine learning algorithms tested failed to learn. We motivate our work from the hypothesis that humans learn such intermediate concepts from other individuals via a form of supervision or guidance using a curriculum. The experiments we have conducted provide positive evidence in favor of this hypothesis. In our experiments, a two-tiered MLP architecture is trained on a dataset with 64x64 binary inputs images, each image with three sprites. The final task is to decide whether all the sprites are the same or one of them is different. Sprites are pentomino tetris shapes and they are placed in an image with different locations using scaling and rotation transformations. The first part of the two-tiered MLP is pre-trained with intermediate-level targets being the presence of sprites at each location, while the second part takes the output of the first part as input and predicts the final task's target binary event. The two-tiered MLP architecture, with a few tens of thousand examples, was able to learn the task perfectly, whereas all other algorithms (include unsupervised pre-training, but also traditional algorithms like SVMs, decision trees and boosting) all perform no better than chance. We hypothesize that the optimization difficulty involved when the intermediate pre-training is not performed is due to the {em composition} of two highly non-linear tasks. Our findings are also consistent with hypotheses on cultural learning inspired by the observations of optimization problems with deep learning, presumably because of effective local minima.", "pdf": "https://arxiv.org/abs/1301.4083", "paperhash": "g\u00fcl\u00e7ehre|knowledge_matters_importance_of_prior_information_for_optimization", "keywords": [], "conflicts": [], "authors": ["\u00c7a\u011flar G\u00fcl\u00e7ehre", "Yoshua Bengio"], "authorids": ["ca9lar@gmail.com", "yoshua.bengio@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362262800000, "tcdate": 1362262800000, "number": 6, "id": "6s7Ys8Q5JbfHZ", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "SSnY462CYz1Cu", "replyto": "SSnY462CYz1Cu", "signatures": ["anonymous reviewer dfef"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Knowledge Matters: Importance of Prior Information for Optimization", "review": "In this paper, the authors provide an exposition of curriculum learning and cultural evolution as solutions to the effective local minimum problem.  The authors provide a detailed set of simulations that support a curriculum theory of learning, which rely on a supervisory training signal of intermediate task variables that are relevant for the task.\r\n\r\nPros:\r\nThis work is important to probe the limitations of current algorithms, especially as the deep learning field continues to have success.\r\n\r\nA great thing about this paper is that it got me thinking about new classes of algorithms that might effectively solve the mid-level optimization and more effective strategies for training deep networks for practical tasks.\r\n\r\nThe simulations are well described and compelling.\r\n\r\nCons:\r\nThe exposition on curriculum learning could be condensed.\r\n(minor) The demonstrative problem (sprite counting) is a visual perception problem and therefore carries with it the biases of our own perception and inferred strategies.  Maybe the overall argument might be bolstered by the addition of a more abstract example?\r\n\r\n\r\nHere are some questions:\r\nwhy so many image regions?  Why use an 8x8 grid?\r\nWon't 3 regions suffice to make the point? Or is this related to the complexity of the problem.\r\nA related question: how are the results effected by the number of these regions?  Maybe some reduced tests at the extremes would be interesting, i.e. with only 3 regions, and 32 (you have 64 already)?\r\n\r\nIn the networks that solve the task, are the weights that are learned symmetric over the image regions? i.e. are these weights identical (maybe up to some scaling and sign flip).  Is there anything you have determined about the structure of the learned second layer of the IKGNN?\r\n\r\nFurthermore, what about including a 'weight sharing' constraint in the general MLP model (the one that does not solve the problem, but has the same structure as the one that does)?  Would including this constraint change the solution? (the constraint is already in the P1NN, but what about adding it into the P2NN?)\r\nAnother way to ask this is: Is enforcing translation invariance in the network sufficient to achieve good performance, or do we need to specifically train for the sprite discrimination?\r\n\r\nA technical point about the assumption of human performance on this task:\r\nDo we know if humans can solve this problem 'in a glance?': flashing the image for a small amount of time ~100-200msecs.  Either with or without a mask?\r\nIt seems that the networks you have derived are solving such a problem 'in a glance.'\r\n\r\nA more meta comment:\r\nIs there an argument to be made that the sequential nature of language allows humans to solve this task?\r\nEven the way you formulate the problem suggests this sequential process:\r\n'are all of the sprites in the image the same?': in other words 'find the sprites, then decide if they are the same'\r\nWhen I imagine solving this problem myself, I imagine performing a more sequential process: look at one sprite, then the next, (is it the same?, if it is): look at the next sprite (is it the same?).\r\nI know that we can consider this problem to be a concrete example of a more abstract learning problem, but it's not clear if humans can solve such problems without sequential processing.\r\nAnyway, this is not a criticism, per se, just food for thought."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Knowledge Matters: Importance of Prior Information for Optimization", "decision": "conferenceOral-iclr2013-conference", "abstract": "We explore the effect of introducing prior information into the intermediate level of neural networks for a learning task on which all the state-of-the-art machine learning algorithms tested failed to learn. We motivate our work from the hypothesis that humans learn such intermediate concepts from other individuals via a form of supervision or guidance using a curriculum. The experiments we have conducted provide positive evidence in favor of this hypothesis. In our experiments, a two-tiered MLP architecture is trained on a dataset with 64x64 binary inputs images, each image with three sprites. The final task is to decide whether all the sprites are the same or one of them is different. Sprites are pentomino tetris shapes and they are placed in an image with different locations using scaling and rotation transformations. The first part of the two-tiered MLP is pre-trained with intermediate-level targets being the presence of sprites at each location, while the second part takes the output of the first part as input and predicts the final task's target binary event. The two-tiered MLP architecture, with a few tens of thousand examples, was able to learn the task perfectly, whereas all other algorithms (include unsupervised pre-training, but also traditional algorithms like SVMs, decision trees and boosting) all perform no better than chance. We hypothesize that the optimization difficulty involved when the intermediate pre-training is not performed is due to the {em composition} of two highly non-linear tasks. Our findings are also consistent with hypotheses on cultural learning inspired by the observations of optimization problems with deep learning, presumably because of effective local minima.", "pdf": "https://arxiv.org/abs/1301.4083", "paperhash": "g\u00fcl\u00e7ehre|knowledge_matters_importance_of_prior_information_for_optimization", "keywords": [], "conflicts": [], "authors": ["\u00c7a\u011flar G\u00fcl\u00e7ehre", "Yoshua Bengio"], "authorids": ["ca9lar@gmail.com", "yoshua.bengio@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1361980800000, "tcdate": 1361980800000, "number": 5, "id": "D5ft5XCZd1cZw", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "SSnY462CYz1Cu", "replyto": "SSnY462CYz1Cu", "signatures": ["anonymous reviewer ed64"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Knowledge Matters: Importance of Prior Information for Optimization", "review": "The paper give an example of a task that neural net solves perfectly when intermediate labels are provided but that is not solved at all by several machine learning algorithms including neural net when the intermediate labels are not provided. I consider the result important.\r\n\r\nComments:\r\nIt is surprising that structured MLP does chance even on training set. On the other hand with 11 output units per parch this is perhaps not so surprising as the network has to fit everything into minimal representation. However one would expect to get better training set resuts with larger sizes. You should put such results into Table 1 and go to even larger sizes, like 100. \r\n\r\nTo continue on this, if you trained sparse coding with high sparsity on each patch you should get 1 in N representation for each instance (with 11x4x3 or more units). It would be good to see what the P2NN would do with such representation. I think this is the primary missing piece of this work. \r\n\r\nIt is not quite fair to compare to humans as humans have prior knowledge, specifically of rotations, probably learned from seeing objects rotate.\r\n\r\nI don't think 'Local descent hypothesis' is quite true. We don't just do local approximate descent. First we do one shot learning in hippocampus. Second, we do search for explanations and solutions and we do planning (both unconsciously and consciously). Sure having more agents helps - it's a little like running a genetic algorithm - an algorithm that overcomes local minima.\r\n\r\nAt the end of page 6 you say P1NN had 2048 units and P2NN 1024 but this is reversed in 3.2.2. Typo?"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Knowledge Matters: Importance of Prior Information for Optimization", "decision": "conferenceOral-iclr2013-conference", "abstract": "We explore the effect of introducing prior information into the intermediate level of neural networks for a learning task on which all the state-of-the-art machine learning algorithms tested failed to learn. We motivate our work from the hypothesis that humans learn such intermediate concepts from other individuals via a form of supervision or guidance using a curriculum. The experiments we have conducted provide positive evidence in favor of this hypothesis. In our experiments, a two-tiered MLP architecture is trained on a dataset with 64x64 binary inputs images, each image with three sprites. The final task is to decide whether all the sprites are the same or one of them is different. Sprites are pentomino tetris shapes and they are placed in an image with different locations using scaling and rotation transformations. The first part of the two-tiered MLP is pre-trained with intermediate-level targets being the presence of sprites at each location, while the second part takes the output of the first part as input and predicts the final task's target binary event. The two-tiered MLP architecture, with a few tens of thousand examples, was able to learn the task perfectly, whereas all other algorithms (include unsupervised pre-training, but also traditional algorithms like SVMs, decision trees and boosting) all perform no better than chance. We hypothesize that the optimization difficulty involved when the intermediate pre-training is not performed is due to the {em composition} of two highly non-linear tasks. Our findings are also consistent with hypotheses on cultural learning inspired by the observations of optimization problems with deep learning, presumably because of effective local minima.", "pdf": "https://arxiv.org/abs/1301.4083", "paperhash": "g\u00fcl\u00e7ehre|knowledge_matters_importance_of_prior_information_for_optimization", "keywords": [], "conflicts": [], "authors": ["\u00c7a\u011flar G\u00fcl\u00e7ehre", "Yoshua Bengio"], "authorids": ["ca9lar@gmail.com", "yoshua.bengio@gmail.com"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1358528400000, "tcdate": 1358528400000, "number": 36, "id": "SSnY462CYz1Cu", "invitation": "ICLR.cc/2013/conference/-/submission", "forum": "SSnY462CYz1Cu", "signatures": ["ca9lar@gmail.com"], "readers": ["everyone"], "content": {"title": "Knowledge Matters: Importance of Prior Information for Optimization", "decision": "conferenceOral-iclr2013-conference", "abstract": "We explore the effect of introducing prior information into the intermediate level of neural networks for a learning task on which all the state-of-the-art machine learning algorithms tested failed to learn. We motivate our work from the hypothesis that humans learn such intermediate concepts from other individuals via a form of supervision or guidance using a curriculum. The experiments we have conducted provide positive evidence in favor of this hypothesis. In our experiments, a two-tiered MLP architecture is trained on a dataset with 64x64 binary inputs images, each image with three sprites. The final task is to decide whether all the sprites are the same or one of them is different. Sprites are pentomino tetris shapes and they are placed in an image with different locations using scaling and rotation transformations. The first part of the two-tiered MLP is pre-trained with intermediate-level targets being the presence of sprites at each location, while the second part takes the output of the first part as input and predicts the final task's target binary event. The two-tiered MLP architecture, with a few tens of thousand examples, was able to learn the task perfectly, whereas all other algorithms (include unsupervised pre-training, but also traditional algorithms like SVMs, decision trees and boosting) all perform no better than chance. We hypothesize that the optimization difficulty involved when the intermediate pre-training is not performed is due to the {em composition} of two highly non-linear tasks. Our findings are also consistent with hypotheses on cultural learning inspired by the observations of optimization problems with deep learning, presumably because of effective local minima.", "pdf": "https://arxiv.org/abs/1301.4083", "paperhash": "g\u00fcl\u00e7ehre|knowledge_matters_importance_of_prior_information_for_optimization", "keywords": [], "conflicts": [], "authors": ["\u00c7a\u011flar G\u00fcl\u00e7ehre", "Yoshua Bengio"], "authorids": ["ca9lar@gmail.com", "yoshua.bengio@gmail.com"]}, "writers": [], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496673673639, "cdate": 1496673673639, "tcdate": 1496673673639, "id": "ICLR.cc/2013/conference/-/submission", "writers": ["ICLR.cc/2013"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717}}}], "count": 11}