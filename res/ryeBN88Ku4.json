{"notes": [{"id": "ryeBN88Ku4", "original": "Hkgt7BkqP4", "number": 22, "cdate": 1553716781304, "ddate": null, "tcdate": 1553716781304, "tmdate": 1562083042023, "tddate": null, "forum": "ryeBN88Ku4", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Blind_Submission", "content": {"title": "Generating Diverse High-Resolution Images with VQ-VAE", "authors": ["Ali Razavi", "Aaron van den Oord", "Oriol Vinyals"], "authorids": ["alirazavi@google.com", "avdnoord@google.com", "vinyals@google.com"], "keywords": ["Vector Quantization", "Autoregressive models", "Generative Models"], "TL;DR": "scale and enhance VQ-VAE with powerful priors to generate near realistic images.", "abstract": "We explore the use of Vector Quantized Variational AutoEncoder (VQ-VAE) models for large scale image generation. To this end, we scale and enhance the autoregressive priors used in VQ-VAE to generate synthetic samples of much higher coherence and fidelity than possible before.  We use simple feed-forward encoder and decoder networks, thus our model is an attractive candidate for applications where the encoding and decoding speed is critical. Additionally, this  allows us to only sample autoregressively in the compressed latent space, which is an order of magnitude faster than sampling in the pixel space, especially for large images. We demonstrate that a multi-scale hierarchical organization of  VQ-VAE, augmented with powerful priors over the latent codes, is able to generate samples with quality that rivals that of state of the art Generative Adversarial Networks on multifaceted datasets such as ImageNet, while not suffering from GAN's known shortcomings such as mode collapse and lack of diversity.", "pdf": "/pdf/e48c9fbfd0ccdf8826a6e4be7a8cc18025491497.pdf", "paperhash": "razavi|generating_diverse_highresolution_images_with_vqvae"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Blind_Submission", "cdate": 1547567085825, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": [".*"]}, "writers": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1547567085825, "tmdate": 1555704438520, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}}, "tauthor": "OpenReview.net"}, {"id": "S1xrQYsfq4", "original": null, "number": 2, "cdate": 1555376412737, "ddate": null, "tcdate": 1555376412737, "tmdate": 1556906118603, "tddate": null, "forum": "ryeBN88Ku4", "replyto": "ryeBN88Ku4", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper22/Official_Review", "content": {"title": "Review", "review": "The paper proposes a method for generating diverse high resolution images with vector-quantised autoencoders (VQ-VAEs). The approach can generate images with much higher visual fidelity than the original VQ-VAE paper via two main ingredients: (1) hierarchical multi-scale latent maps and (2) PixelSNAIL instead of PixelCNN.\n\nThe motivation and the contributions of this paper are very similar to De Fauw et al., 2019 (Hierarchical Autoregressive Image Models with Auxiliary Decoders; https://arxiv.org/abs/1903.04933), in that De Fauw et al. also used hierarchical VQ-VAEs (specifically, 2-layer) to generate high fidelity images. Also their autoregressive priors are closely related to PixelSNAIL. I'm assuming the authors were not aware of this paper, as they did not cite it. De Fauw et al. report IS/FID/Test NLL, none of which this paper reports. Given De Fauw et al. 2019 was submitted to arxiv on March 9th, this should be considered concurrent work, but should be cited in the revision.\n\nPros\n- Clear exposition and motivation\n- High fidelity and diversity in the generated images\n\nCons\n- No test NLL comparisons with other likelihood based approaches (e.g. SPN, Parallel Multiscale)\n- I'd have liked to see Inception/FID results from the proposed model (as done by De Fauw et al., 2019).", "rating": "2: Marginally below acceptance threshold", "confidence": "3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper22/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper22/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Generating Diverse High-Resolution Images with VQ-VAE", "authors": ["Ali Razavi", "Aaron van den Oord", "Oriol Vinyals"], "authorids": ["alirazavi@google.com", "avdnoord@google.com", "vinyals@google.com"], "keywords": ["Vector Quantization", "Autoregressive models", "Generative Models"], "TL;DR": "scale and enhance VQ-VAE with powerful priors to generate near realistic images.", "abstract": "We explore the use of Vector Quantized Variational AutoEncoder (VQ-VAE) models for large scale image generation. To this end, we scale and enhance the autoregressive priors used in VQ-VAE to generate synthetic samples of much higher coherence and fidelity than possible before.  We use simple feed-forward encoder and decoder networks, thus our model is an attractive candidate for applications where the encoding and decoding speed is critical. Additionally, this  allows us to only sample autoregressively in the compressed latent space, which is an order of magnitude faster than sampling in the pixel space, especially for large images. We demonstrate that a multi-scale hierarchical organization of  VQ-VAE, augmented with powerful priors over the latent codes, is able to generate samples with quality that rivals that of state of the art Generative Adversarial Networks on multifaceted datasets such as ImageNet, while not suffering from GAN's known shortcomings such as mode collapse and lack of diversity.", "pdf": "/pdf/e48c9fbfd0ccdf8826a6e4be7a8cc18025491497.pdf", "paperhash": "razavi|generating_diverse_highresolution_images_with_vqvae"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper22/Official_Review", "cdate": 1554234176716, "reply": {"forum": "ryeBN88Ku4", "replyto": "ryeBN88Ku4", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper22/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper22/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1554234176716, "tmdate": 1556906087876, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper22/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}, {"id": "r1xK9aFAY4", "original": null, "number": 1, "cdate": 1555107217291, "ddate": null, "tcdate": 1555107217291, "tmdate": 1556906118390, "tddate": null, "forum": "ryeBN88Ku4", "replyto": "ryeBN88Ku4", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper22/Official_Review", "content": {"title": "Well written paper with great looking generated images", "review": "This paper proposes to use Hierarchical VQ-VAE for the purposes of large image generation. The paper is written clearly and well justified. \n\nThe authors extend the originally proposed VQ-VAE model to learn two (top & bottom) level hierarchies of images. The only con of the model is that, post-hoc PixelCNN (or PixelSnail in this paper) needs to be used to learn the prior over discrete codes in order to sample images at generation time.\n\nAlthough authors claim that the model generates diverse & high quality looking it would be great to put some quantitative number on it. Doing with side-by-side samples from BigGAN and Hierarchical VQ-VAE and asking people to rate which models generated samples they prefer. As well as it would be great to see the nearest neighboring training images from the dataset according to closest distance in the embedding space.", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper22/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper22/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Generating Diverse High-Resolution Images with VQ-VAE", "authors": ["Ali Razavi", "Aaron van den Oord", "Oriol Vinyals"], "authorids": ["alirazavi@google.com", "avdnoord@google.com", "vinyals@google.com"], "keywords": ["Vector Quantization", "Autoregressive models", "Generative Models"], "TL;DR": "scale and enhance VQ-VAE with powerful priors to generate near realistic images.", "abstract": "We explore the use of Vector Quantized Variational AutoEncoder (VQ-VAE) models for large scale image generation. To this end, we scale and enhance the autoregressive priors used in VQ-VAE to generate synthetic samples of much higher coherence and fidelity than possible before.  We use simple feed-forward encoder and decoder networks, thus our model is an attractive candidate for applications where the encoding and decoding speed is critical. Additionally, this  allows us to only sample autoregressively in the compressed latent space, which is an order of magnitude faster than sampling in the pixel space, especially for large images. We demonstrate that a multi-scale hierarchical organization of  VQ-VAE, augmented with powerful priors over the latent codes, is able to generate samples with quality that rivals that of state of the art Generative Adversarial Networks on multifaceted datasets such as ImageNet, while not suffering from GAN's known shortcomings such as mode collapse and lack of diversity.", "pdf": "/pdf/e48c9fbfd0ccdf8826a6e4be7a8cc18025491497.pdf", "paperhash": "razavi|generating_diverse_highresolution_images_with_vqvae"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper22/Official_Review", "cdate": 1554234176716, "reply": {"forum": "ryeBN88Ku4", "replyto": "ryeBN88Ku4", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper22/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper22/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1554234176716, "tmdate": 1556906087876, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper22/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}, {"id": "ryxglVuv9V", "original": null, "number": 1, "cdate": 1555690471709, "ddate": null, "tcdate": 1555690471709, "tmdate": 1556906118164, "tddate": null, "forum": "ryeBN88Ku4", "replyto": "ryeBN88Ku4", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper22/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept", "comment": "The generated images are impressive but as the reviewers note, it would be good to have quantitative comparison against existing methosd."}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Generating Diverse High-Resolution Images with VQ-VAE", "authors": ["Ali Razavi", "Aaron van den Oord", "Oriol Vinyals"], "authorids": ["alirazavi@google.com", "avdnoord@google.com", "vinyals@google.com"], "keywords": ["Vector Quantization", "Autoregressive models", "Generative Models"], "TL;DR": "scale and enhance VQ-VAE with powerful priors to generate near realistic images.", "abstract": "We explore the use of Vector Quantized Variational AutoEncoder (VQ-VAE) models for large scale image generation. To this end, we scale and enhance the autoregressive priors used in VQ-VAE to generate synthetic samples of much higher coherence and fidelity than possible before.  We use simple feed-forward encoder and decoder networks, thus our model is an attractive candidate for applications where the encoding and decoding speed is critical. Additionally, this  allows us to only sample autoregressively in the compressed latent space, which is an order of magnitude faster than sampling in the pixel space, especially for large images. We demonstrate that a multi-scale hierarchical organization of  VQ-VAE, augmented with powerful priors over the latent codes, is able to generate samples with quality that rivals that of state of the art Generative Adversarial Networks on multifaceted datasets such as ImageNet, while not suffering from GAN's known shortcomings such as mode collapse and lack of diversity.", "pdf": "/pdf/e48c9fbfd0ccdf8826a6e4be7a8cc18025491497.pdf", "paperhash": "razavi|generating_diverse_highresolution_images_with_vqvae"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper22/Decision", "cdate": 1554814607419, "reply": {"forum": "ryeBN88Ku4", "replyto": "ryeBN88Ku4", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554814607419, "tmdate": 1556906098211, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}], "count": 4}