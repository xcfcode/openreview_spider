{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396575732, "tcdate": 1486396575732, "number": 1, "id": "rJOj2fUul", "invitation": "ICLR.cc/2017/conference/-/paper424/acceptance", "forum": "r1Usiwcex", "replyto": "r1Usiwcex", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "This paper applies an existing idea (Yao's block Gibbs sampling of NADE) to a music model. There is also prior art for applying NADE to music. The main novel and interesting result is that block Gibbs sampling (an approximation) actually improves performance, highlighting problems with NADE.\n \n This work is borderline for inclusion. The paper is mainly an application of existing ideas. The implications of the interesting results could perhaps have been explored further for a paper at a meeting on learning representations."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Counterpoint by Convolution", "abstract": "Machine learning models of music typically break down the task of composition into a chronological process, composing a piece of music in a single pass from beginning to end. On the contrary, human composers write music in a nonlinear fashion, scribbling motifs here and there, often revisiting choices previously made. We explore the use of blocked Gibbs sampling as an analogue to the human approach, and introduce Coconet, a convolutional neural network in the NADE family of generative models. Despite ostensibly sampling from the same distribution as the NADE ancestral sampling procedure, we find that a blocked Gibbs approach significantly improves sample quality. We provide evidence that this is due to some conditional distributions being poorly modeled. Moreover, we show that even the cheap approximate blocked Gibbs procedure from Yao et al. (2014) yields better samples than ancestral sampling. We demonstrate the versatility of our method on unconditioned polyphonic music generation.", "pdf": "/pdf/fbfa9f4044a6f033361d0e1c10d31e61e4f15a36.pdf", "TL;DR": "NADE generative model of music, with new insights on sampling", "paperhash": "huang|counterpoint_by_convolution", "keywords": ["Deep learning", "Applications", "Unsupervised Learning"], "conflicts": ["umontreal.ca", "google.com"], "authors": ["Cheng-Zhi Anna Huang", "Tim Cooijmans", "Adam Roberts", "Aaron Courville", "Douglas Eck"], "authorids": ["chengzhiannahuang@gmail.com", "tim.cooijmans@umontreal.ca", "adarob@google.com", "aaron.courville@umontreal.ca", "deck@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396576320, "id": "ICLR.cc/2017/conference/-/paper424/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "r1Usiwcex", "replyto": "r1Usiwcex", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396576320}}}, {"tddate": null, "tmdate": 1484958344772, "tcdate": 1481733433435, "number": 1, "id": "rkWBSxyNe", "invitation": "ICLR.cc/2017/conference/-/paper424/official/review", "forum": "r1Usiwcex", "replyto": "r1Usiwcex", "signatures": ["ICLR.cc/2017/conference/paper424/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper424/AnonReviewer3"], "content": {"title": "A nice work that apply NADE-based model to music composition", "rating": "6: Marginally above acceptance threshold", "review": "This paper proposed COCONET, which is a neural autoregressive model with convolution, to do music composition task. This paper also proposed to use blocked Gibbs sampling instead of the ancestral sampling of the original NADE model to generate better pieces of music. The experimental results showed that the NLL of COCONET is better than the other baselines and the human evaluation task by Amazon\u2019s Mechanical Turk illustrated that the model can generate compelling music.\n\nIn general, I think the paper is good. Using NADE based model with convolution operations on music generation tasks and using blocked Gibbs sampling contains some kind of novelty. However, the novelty of the paper is incremental, since the blocked Gibbs sampling for NADE model is already proposed by Yao et al., (2014) and the using NADE based model for music modeling has also been proposed by Boulanger-Lewandowski  et al., (2012).\n\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Counterpoint by Convolution", "abstract": "Machine learning models of music typically break down the task of composition into a chronological process, composing a piece of music in a single pass from beginning to end. On the contrary, human composers write music in a nonlinear fashion, scribbling motifs here and there, often revisiting choices previously made. We explore the use of blocked Gibbs sampling as an analogue to the human approach, and introduce Coconet, a convolutional neural network in the NADE family of generative models. Despite ostensibly sampling from the same distribution as the NADE ancestral sampling procedure, we find that a blocked Gibbs approach significantly improves sample quality. We provide evidence that this is due to some conditional distributions being poorly modeled. Moreover, we show that even the cheap approximate blocked Gibbs procedure from Yao et al. (2014) yields better samples than ancestral sampling. We demonstrate the versatility of our method on unconditioned polyphonic music generation.", "pdf": "/pdf/fbfa9f4044a6f033361d0e1c10d31e61e4f15a36.pdf", "TL;DR": "NADE generative model of music, with new insights on sampling", "paperhash": "huang|counterpoint_by_convolution", "keywords": ["Deep learning", "Applications", "Unsupervised Learning"], "conflicts": ["umontreal.ca", "google.com"], "authors": ["Cheng-Zhi Anna Huang", "Tim Cooijmans", "Adam Roberts", "Aaron Courville", "Douglas Eck"], "authorids": ["chengzhiannahuang@gmail.com", "tim.cooijmans@umontreal.ca", "adarob@google.com", "aaron.courville@umontreal.ca", "deck@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512592141, "id": "ICLR.cc/2017/conference/-/paper424/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper424/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper424/AnonReviewer3", "ICLR.cc/2017/conference/paper424/AnonReviewer4", "ICLR.cc/2017/conference/paper424/AnonReviewer5"], "reply": {"forum": "r1Usiwcex", "replyto": "r1Usiwcex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper424/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper424/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512592141}}}, {"tddate": null, "tmdate": 1484949429972, "tcdate": 1484949429972, "number": 6, "id": "BJAnPZevg", "invitation": "ICLR.cc/2017/conference/-/paper424/public/comment", "forum": "r1Usiwcex", "replyto": "SyJrf3rEg", "signatures": ["~Cheng-Zhi_Anna_Huang1"], "readers": ["everyone"], "writers": ["~Cheng-Zhi_Anna_Huang1"], "content": {"title": "Response above", "comment": "Thank you for your review.  We respond to your question above.  "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Counterpoint by Convolution", "abstract": "Machine learning models of music typically break down the task of composition into a chronological process, composing a piece of music in a single pass from beginning to end. On the contrary, human composers write music in a nonlinear fashion, scribbling motifs here and there, often revisiting choices previously made. We explore the use of blocked Gibbs sampling as an analogue to the human approach, and introduce Coconet, a convolutional neural network in the NADE family of generative models. Despite ostensibly sampling from the same distribution as the NADE ancestral sampling procedure, we find that a blocked Gibbs approach significantly improves sample quality. We provide evidence that this is due to some conditional distributions being poorly modeled. Moreover, we show that even the cheap approximate blocked Gibbs procedure from Yao et al. (2014) yields better samples than ancestral sampling. We demonstrate the versatility of our method on unconditioned polyphonic music generation.", "pdf": "/pdf/fbfa9f4044a6f033361d0e1c10d31e61e4f15a36.pdf", "TL;DR": "NADE generative model of music, with new insights on sampling", "paperhash": "huang|counterpoint_by_convolution", "keywords": ["Deep learning", "Applications", "Unsupervised Learning"], "conflicts": ["umontreal.ca", "google.com"], "authors": ["Cheng-Zhi Anna Huang", "Tim Cooijmans", "Adam Roberts", "Aaron Courville", "Douglas Eck"], "authorids": ["chengzhiannahuang@gmail.com", "tim.cooijmans@umontreal.ca", "adarob@google.com", "aaron.courville@umontreal.ca", "deck@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287582989, "id": "ICLR.cc/2017/conference/-/paper424/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "r1Usiwcex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper424/reviewers", "ICLR.cc/2017/conference/paper424/areachairs"], "cdate": 1485287582989}}}, {"tddate": null, "tmdate": 1484949321503, "tcdate": 1484949321503, "number": 5, "id": "ryZUPWewx", "invitation": "ICLR.cc/2017/conference/-/paper424/public/comment", "forum": "r1Usiwcex", "replyto": "HJNRbAbVe", "signatures": ["~Cheng-Zhi_Anna_Huang1"], "readers": ["everyone"], "writers": ["~Cheng-Zhi_Anna_Huang1"], "content": {"title": "Response", "comment": "In previous rounds of human evaluation, we did use your proposed question: \"which piece do you prefer?\". However, users' stated reasons revealed that they based their ratings on (to us) irrelevant properties such as mood and synthesis details. The question \"which piece is more musical?\" reduced but did not eliminate this effect.\n\nWe have added more details on the human evaluation, including direct comparisons, in an appendix.\n\nWe are responding to your other questions in the response at the top of this page."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Counterpoint by Convolution", "abstract": "Machine learning models of music typically break down the task of composition into a chronological process, composing a piece of music in a single pass from beginning to end. On the contrary, human composers write music in a nonlinear fashion, scribbling motifs here and there, often revisiting choices previously made. We explore the use of blocked Gibbs sampling as an analogue to the human approach, and introduce Coconet, a convolutional neural network in the NADE family of generative models. Despite ostensibly sampling from the same distribution as the NADE ancestral sampling procedure, we find that a blocked Gibbs approach significantly improves sample quality. We provide evidence that this is due to some conditional distributions being poorly modeled. Moreover, we show that even the cheap approximate blocked Gibbs procedure from Yao et al. (2014) yields better samples than ancestral sampling. We demonstrate the versatility of our method on unconditioned polyphonic music generation.", "pdf": "/pdf/fbfa9f4044a6f033361d0e1c10d31e61e4f15a36.pdf", "TL;DR": "NADE generative model of music, with new insights on sampling", "paperhash": "huang|counterpoint_by_convolution", "keywords": ["Deep learning", "Applications", "Unsupervised Learning"], "conflicts": ["umontreal.ca", "google.com"], "authors": ["Cheng-Zhi Anna Huang", "Tim Cooijmans", "Adam Roberts", "Aaron Courville", "Douglas Eck"], "authorids": ["chengzhiannahuang@gmail.com", "tim.cooijmans@umontreal.ca", "adarob@google.com", "aaron.courville@umontreal.ca", "deck@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287582989, "id": "ICLR.cc/2017/conference/-/paper424/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "r1Usiwcex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper424/reviewers", "ICLR.cc/2017/conference/paper424/areachairs"], "cdate": 1485287582989}}}, {"tddate": null, "tmdate": 1484949223100, "tcdate": 1484949223100, "number": 4, "id": "SJyxPZgvl", "invitation": "ICLR.cc/2017/conference/-/paper424/public/comment", "forum": "r1Usiwcex", "replyto": "r1Usiwcex", "signatures": ["~Cheng-Zhi_Anna_Huang1"], "readers": ["everyone"], "writers": ["~Cheng-Zhi_Anna_Huang1"], "content": {"title": "Response to reviews", "comment": "Thank you all for your reviews!  \n\nWe share your concern regarding quantitative comparison to other works, and regarding the generality of our method.  We have looked into the datasets used in prior works, but found that their preprocessing severely degraded the musical structure. For example, the temporal granularity used in Boulanger-Lewandowski et al. is too coarse: in several pieces, discarding all notes that do not have their onsets on the eighth-note grid results in sparse notes with long stretches of silence between them. The pieces become unrecognizable, and (worse) non-musical.  Downsampling or blurring does not work in symbolic music like it does in images: music is more similar to language, and using a coarse grid is analogous to removing words from a sentence and asking a model to learn this new distribution of broken sentences. This turns it into a different task, and makes qualitative judgement of samples not very meaningful.\n\nWe also considered applying our method to image data as suggested. Unlike (symbolic) music which is discrete and intricately structured, the domain of images is smooth and forgiving of small errors. It is plausible that the NADE sampling approach generates fine images (indeed, that's what Yao et al. found), for reasons that don't carry over to our domain of interest, which is music.\n\nThe development of a larger-scale, more diverse and higher-quality MIDI music dataset is a major component of our ongoing project.  We nonetheless believe that the advances we show are of sufficient interest to justify publication at this time."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Counterpoint by Convolution", "abstract": "Machine learning models of music typically break down the task of composition into a chronological process, composing a piece of music in a single pass from beginning to end. On the contrary, human composers write music in a nonlinear fashion, scribbling motifs here and there, often revisiting choices previously made. We explore the use of blocked Gibbs sampling as an analogue to the human approach, and introduce Coconet, a convolutional neural network in the NADE family of generative models. Despite ostensibly sampling from the same distribution as the NADE ancestral sampling procedure, we find that a blocked Gibbs approach significantly improves sample quality. We provide evidence that this is due to some conditional distributions being poorly modeled. Moreover, we show that even the cheap approximate blocked Gibbs procedure from Yao et al. (2014) yields better samples than ancestral sampling. We demonstrate the versatility of our method on unconditioned polyphonic music generation.", "pdf": "/pdf/fbfa9f4044a6f033361d0e1c10d31e61e4f15a36.pdf", "TL;DR": "NADE generative model of music, with new insights on sampling", "paperhash": "huang|counterpoint_by_convolution", "keywords": ["Deep learning", "Applications", "Unsupervised Learning"], "conflicts": ["umontreal.ca", "google.com"], "authors": ["Cheng-Zhi Anna Huang", "Tim Cooijmans", "Adam Roberts", "Aaron Courville", "Douglas Eck"], "authorids": ["chengzhiannahuang@gmail.com", "tim.cooijmans@umontreal.ca", "adarob@google.com", "aaron.courville@umontreal.ca", "deck@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287582989, "id": "ICLR.cc/2017/conference/-/paper424/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "r1Usiwcex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper424/reviewers", "ICLR.cc/2017/conference/paper424/areachairs"], "cdate": 1485287582989}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1484949134842, "tcdate": 1478290333804, "number": 424, "id": "r1Usiwcex", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "r1Usiwcex", "signatures": ["~Tim_Cooijmans1"], "readers": ["everyone"], "content": {"title": "Counterpoint by Convolution", "abstract": "Machine learning models of music typically break down the task of composition into a chronological process, composing a piece of music in a single pass from beginning to end. On the contrary, human composers write music in a nonlinear fashion, scribbling motifs here and there, often revisiting choices previously made. We explore the use of blocked Gibbs sampling as an analogue to the human approach, and introduce Coconet, a convolutional neural network in the NADE family of generative models. Despite ostensibly sampling from the same distribution as the NADE ancestral sampling procedure, we find that a blocked Gibbs approach significantly improves sample quality. We provide evidence that this is due to some conditional distributions being poorly modeled. Moreover, we show that even the cheap approximate blocked Gibbs procedure from Yao et al. (2014) yields better samples than ancestral sampling. We demonstrate the versatility of our method on unconditioned polyphonic music generation.", "pdf": "/pdf/fbfa9f4044a6f033361d0e1c10d31e61e4f15a36.pdf", "TL;DR": "NADE generative model of music, with new insights on sampling", "paperhash": "huang|counterpoint_by_convolution", "keywords": ["Deep learning", "Applications", "Unsupervised Learning"], "conflicts": ["umontreal.ca", "google.com"], "authors": ["Cheng-Zhi Anna Huang", "Tim Cooijmans", "Adam Roberts", "Aaron Courville", "Douglas Eck"], "authorids": ["chengzhiannahuang@gmail.com", "tim.cooijmans@umontreal.ca", "adarob@google.com", "aaron.courville@umontreal.ca", "deck@google.com"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 12, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "tmdate": 1482175030601, "tcdate": 1482175030601, "number": 3, "id": "SyJrf3rEg", "invitation": "ICLR.cc/2017/conference/-/paper424/official/review", "forum": "r1Usiwcex", "replyto": "r1Usiwcex", "signatures": ["ICLR.cc/2017/conference/paper424/AnonReviewer5"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper424/AnonReviewer5"], "content": {"title": "Review", "rating": "5: Marginally below acceptance threshold", "review": "The paper tackles the task of music generation. They use an orderless NADE model for the task of \"fill in the notes\". Given a roll of T timesteps of pitches, they randomly mask out some pitches, and the model is trained to predict the missing notes. This follows how the orderless NADE model can be trained. During sampling, one normally follows an ancestral sampling procedure. For this, an ordering is defined over outputs, and one runs the model on the current input, samples one of the outputs according to the order, adds this output to the next input, and continues this procedure until all outputs have been sampled. The key point of the paper is that this is a bad sampling strategy. Instead, they suggest the strategy of Yao et al. 2014, which uses a blocked Gibbs sampling approach. The blocked Gibbs strategy instead masks N inputs randomly and independently, samples them, and repeats this procedure. The point of this strategy is the make sure the sampling chain mixes well, which will happen for large N. However, since the samples are independent, having a large N gives incoherent samples. Thus, the authors follow an annealed schedule for N, making it smaller over time, which will eventually reduce to ancestral sampling (giving global structure to the sample). They conduct a variety of experiments involving both normal metrics and human evaluations, and find that this blocked Gibbs sampling outperforms other sampling procedures.\n\nThis is a well written paper - great job.\n\nMy main problem with the paper is that having read Uria and Yao, I don't know how much I have learned from this work in the context of this being an ICLR submission. If this was submitted to some computational music / art conference, this paper would be a clear accept. However, for ICLR, I don't see enough novelty compared with previous works this builds upon. Orderless NADE is an established model. The blocked Gibbs sampling and annealing scheme are basically the exact same one used in Yao. Thus, the main novelty of this paper is its application to the music domain, and finding that Yao's method works better for sampling music. This is a good contribution, but more tailored to those working in the music domain. If the authors found that these results also hold for other domains like images (e.g. on CIFAR / tiny Imagenet) and text (e.g. document generation), then I would change my mind and accept this paper for ICLR. Even just trying musical domains other than Bach chorales would be useful. However, as it stands, the experiments are not convincing enough.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Counterpoint by Convolution", "abstract": "Machine learning models of music typically break down the task of composition into a chronological process, composing a piece of music in a single pass from beginning to end. On the contrary, human composers write music in a nonlinear fashion, scribbling motifs here and there, often revisiting choices previously made. We explore the use of blocked Gibbs sampling as an analogue to the human approach, and introduce Coconet, a convolutional neural network in the NADE family of generative models. Despite ostensibly sampling from the same distribution as the NADE ancestral sampling procedure, we find that a blocked Gibbs approach significantly improves sample quality. We provide evidence that this is due to some conditional distributions being poorly modeled. Moreover, we show that even the cheap approximate blocked Gibbs procedure from Yao et al. (2014) yields better samples than ancestral sampling. We demonstrate the versatility of our method on unconditioned polyphonic music generation.", "pdf": "/pdf/fbfa9f4044a6f033361d0e1c10d31e61e4f15a36.pdf", "TL;DR": "NADE generative model of music, with new insights on sampling", "paperhash": "huang|counterpoint_by_convolution", "keywords": ["Deep learning", "Applications", "Unsupervised Learning"], "conflicts": ["umontreal.ca", "google.com"], "authors": ["Cheng-Zhi Anna Huang", "Tim Cooijmans", "Adam Roberts", "Aaron Courville", "Douglas Eck"], "authorids": ["chengzhiannahuang@gmail.com", "tim.cooijmans@umontreal.ca", "adarob@google.com", "aaron.courville@umontreal.ca", "deck@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512592141, "id": "ICLR.cc/2017/conference/-/paper424/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper424/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper424/AnonReviewer3", "ICLR.cc/2017/conference/paper424/AnonReviewer4", "ICLR.cc/2017/conference/paper424/AnonReviewer5"], "reply": {"forum": "r1Usiwcex", "replyto": "r1Usiwcex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper424/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper424/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512592141}}}, {"tddate": null, "tmdate": 1481920971995, "tcdate": 1481920971995, "number": 2, "id": "HJNRbAbVe", "invitation": "ICLR.cc/2017/conference/-/paper424/official/review", "forum": "r1Usiwcex", "replyto": "r1Usiwcex", "signatures": ["ICLR.cc/2017/conference/paper424/AnonReviewer4"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper424/AnonReviewer4"], "content": {"title": "Review", "rating": "6: Marginally above acceptance threshold", "review": "The paper presents a way to model the distribution of four-part Bach chorales using Convolutional Neural Networks. Furthermore it addresses the task of artificial music generation by sampling from the model using blocked Gibbs sampling and shows\n\nThe CNN model for the distribution seems very appropriate for the data at hand. Also the analysis of the proposed sampling schemes with the analogy between Gibbs sampling and human music composition are very interesting.\nI am not too sure about the evaluation though. Since the reported likelihoods are not directly comparable to previous work, I have difficulties judging the quality of the quantitative results.  For the human evaluation I would like to see the data for the direct comparisons between the models. E.g. How did NADE vs. Bach perform. Also I find the question: \u2018what piece of music do you prefer\u2019 a stronger test than the question \u2018what piece is more musical to you\u2019 because I don\u2019t really know what \u2018musical\u2019 means to the AMT workers.\n\nFinally, while I think the Bach Chorales are interesting musical pieces that deserve to be subject of the analysis but I find it hard to judge how well this modelling approach will transfer to other types of music which might have a very different data distribution.\n\nNevertheless, in conclusion, I believe this is an exciting model for an interesting task that produces non-trivial musical data.\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Counterpoint by Convolution", "abstract": "Machine learning models of music typically break down the task of composition into a chronological process, composing a piece of music in a single pass from beginning to end. On the contrary, human composers write music in a nonlinear fashion, scribbling motifs here and there, often revisiting choices previously made. We explore the use of blocked Gibbs sampling as an analogue to the human approach, and introduce Coconet, a convolutional neural network in the NADE family of generative models. Despite ostensibly sampling from the same distribution as the NADE ancestral sampling procedure, we find that a blocked Gibbs approach significantly improves sample quality. We provide evidence that this is due to some conditional distributions being poorly modeled. Moreover, we show that even the cheap approximate blocked Gibbs procedure from Yao et al. (2014) yields better samples than ancestral sampling. We demonstrate the versatility of our method on unconditioned polyphonic music generation.", "pdf": "/pdf/fbfa9f4044a6f033361d0e1c10d31e61e4f15a36.pdf", "TL;DR": "NADE generative model of music, with new insights on sampling", "paperhash": "huang|counterpoint_by_convolution", "keywords": ["Deep learning", "Applications", "Unsupervised Learning"], "conflicts": ["umontreal.ca", "google.com"], "authors": ["Cheng-Zhi Anna Huang", "Tim Cooijmans", "Adam Roberts", "Aaron Courville", "Douglas Eck"], "authorids": ["chengzhiannahuang@gmail.com", "tim.cooijmans@umontreal.ca", "adarob@google.com", "aaron.courville@umontreal.ca", "deck@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512592141, "id": "ICLR.cc/2017/conference/-/paper424/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper424/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper424/AnonReviewer3", "ICLR.cc/2017/conference/paper424/AnonReviewer4", "ICLR.cc/2017/conference/paper424/AnonReviewer5"], "reply": {"forum": "r1Usiwcex", "replyto": "r1Usiwcex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper424/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper424/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512592141}}}, {"tddate": null, "tmdate": 1481854590861, "tcdate": 1481854590861, "number": 3, "id": "H1wKCagEx", "invitation": "ICLR.cc/2017/conference/-/paper424/public/comment", "forum": "r1Usiwcex", "replyto": "rkWBSxyNe", "signatures": ["~Cheng-Zhi_Anna_Huang1"], "readers": ["everyone"], "writers": ["~Cheng-Zhi_Anna_Huang1"], "content": {"title": "Clarifying a few points in response to review", "comment": "Thank you for your review!  To clarify a few points:  \n\nThere are two ways in which NADEs (Larochelle & Murray, 2011) are used in Boulanger-Lewandowski et al. (2012), both of which are different from our approach.  As a baseline, NADE was used to model distribution of chords/simultaneities, without considering temporal dynamics.  Then, as an alternative to RNN-RBMs, NADE was used to model the output distribution of RNNs, giving rise to RNN-NADEs.  Temporally, RNN-NADE factorizes sequences chronologically, and hence can only generate left to right.  As only one ordering is modeled, Gibbs sampling can not be used to improve sample quality.\n\nIn contrast, we adopt an orderless NADE (Uria et al., 2014) which is trained to learn all possible orders of factorization, making it possible to use Gibbs sampling to improve sample quality.  Furthermore, this approach frees music models from generating left to right, and can support tasks such as partial score completion that requires the versatility of conditioning on arbitrary context and to generate in any order.  \n\nYao et al (2014) only expected independent blocked Gibbs to perform as well as ancestral sampling at best in terms of sample quality.  Their work focused on MNIST.  For the more intricate domain of music, we report the surprising observation that independent blocked Gibbs actually beats ancestral sampling.  We investigate why this might be the case.  Our finding softens the main drawback of autoregressive models, which is that sampling from them is slow. We believe our contribution is especially relevant given the recent popularity of autoregressive models (such as PixelCNN and WaveNet (van den Oord et al., 2016) etc.)."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Counterpoint by Convolution", "abstract": "Machine learning models of music typically break down the task of composition into a chronological process, composing a piece of music in a single pass from beginning to end. On the contrary, human composers write music in a nonlinear fashion, scribbling motifs here and there, often revisiting choices previously made. We explore the use of blocked Gibbs sampling as an analogue to the human approach, and introduce Coconet, a convolutional neural network in the NADE family of generative models. Despite ostensibly sampling from the same distribution as the NADE ancestral sampling procedure, we find that a blocked Gibbs approach significantly improves sample quality. We provide evidence that this is due to some conditional distributions being poorly modeled. Moreover, we show that even the cheap approximate blocked Gibbs procedure from Yao et al. (2014) yields better samples than ancestral sampling. We demonstrate the versatility of our method on unconditioned polyphonic music generation.", "pdf": "/pdf/fbfa9f4044a6f033361d0e1c10d31e61e4f15a36.pdf", "TL;DR": "NADE generative model of music, with new insights on sampling", "paperhash": "huang|counterpoint_by_convolution", "keywords": ["Deep learning", "Applications", "Unsupervised Learning"], "conflicts": ["umontreal.ca", "google.com"], "authors": ["Cheng-Zhi Anna Huang", "Tim Cooijmans", "Adam Roberts", "Aaron Courville", "Douglas Eck"], "authorids": ["chengzhiannahuang@gmail.com", "tim.cooijmans@umontreal.ca", "adarob@google.com", "aaron.courville@umontreal.ca", "deck@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287582989, "id": "ICLR.cc/2017/conference/-/paper424/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "r1Usiwcex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper424/reviewers", "ICLR.cc/2017/conference/paper424/areachairs"], "cdate": 1485287582989}}}, {"tddate": null, "tmdate": 1481774780672, "tcdate": 1481267649976, "number": 1, "id": "H19TKAvmg", "invitation": "ICLR.cc/2017/conference/-/paper424/public/comment", "forum": "r1Usiwcex", "replyto": "BygZ5o8Xl", "signatures": ["~Tim_Cooijmans1"], "readers": ["everyone"], "writers": ["~Tim_Cooijmans1"], "content": {"title": "Yes!", "comment": "We started this work at Magenta[1] and as such the code will be checked into the Magenta github[2] soon. However our (messy) research code is already available in our development repository[3].\n\n[1] https://magenta.tensorflow.org\n[2] https://github.com/tensorflow/magenta\n[3] https://github.com/czhuang/magenta-autofill/tree/fixing/magenta/models/basic_autofill_cnn"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Counterpoint by Convolution", "abstract": "Machine learning models of music typically break down the task of composition into a chronological process, composing a piece of music in a single pass from beginning to end. On the contrary, human composers write music in a nonlinear fashion, scribbling motifs here and there, often revisiting choices previously made. We explore the use of blocked Gibbs sampling as an analogue to the human approach, and introduce Coconet, a convolutional neural network in the NADE family of generative models. Despite ostensibly sampling from the same distribution as the NADE ancestral sampling procedure, we find that a blocked Gibbs approach significantly improves sample quality. We provide evidence that this is due to some conditional distributions being poorly modeled. Moreover, we show that even the cheap approximate blocked Gibbs procedure from Yao et al. (2014) yields better samples than ancestral sampling. We demonstrate the versatility of our method on unconditioned polyphonic music generation.", "pdf": "/pdf/fbfa9f4044a6f033361d0e1c10d31e61e4f15a36.pdf", "TL;DR": "NADE generative model of music, with new insights on sampling", "paperhash": "huang|counterpoint_by_convolution", "keywords": ["Deep learning", "Applications", "Unsupervised Learning"], "conflicts": ["umontreal.ca", "google.com"], "authors": ["Cheng-Zhi Anna Huang", "Tim Cooijmans", "Adam Roberts", "Aaron Courville", "Douglas Eck"], "authorids": ["chengzhiannahuang@gmail.com", "tim.cooijmans@umontreal.ca", "adarob@google.com", "aaron.courville@umontreal.ca", "deck@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287582989, "id": "ICLR.cc/2017/conference/-/paper424/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "r1Usiwcex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper424/reviewers", "ICLR.cc/2017/conference/paper424/areachairs"], "cdate": 1485287582989}}}, {"tddate": null, "tmdate": 1481720073514, "tcdate": 1481720073505, "number": 2, "id": "SyWzZa0mg", "invitation": "ICLR.cc/2017/conference/-/paper424/public/comment", "forum": "r1Usiwcex", "replyto": "BJ3988YQg", "signatures": ["~Cheng-Zhi_Anna_Huang1"], "readers": ["everyone"], "writers": ["~Cheng-Zhi_Anna_Huang1"], "content": {"title": "Response", "comment": "Thank you for your comments.  We have been improving the paper in response to comments from colleagues and the new version of the paper addresses some of your comments.  The new version puts greater emphasis on sampling, particularly on our main finding that blocked Gibbs sampling improves upon NADE ancestral sampling, and notably the approximate scheme from Yao et al is both faster and better in terms of sample quality. This is surprising as all three sampling procedures we discuss theoretically sample from the same distribution, and we conjecture (and tentatively confirm) that this is caused by some conditional distributions being poorly modeled. We evaluate sample quality primarily by likelihood under the model, supplemented with a new human evaluation study.\n\n\n> Is there a principled value for the number of sampling loops n in algorithm 1? If not, how did the authors typically chose n. Also, in the conditioned rewriting task, how did the results change for varying n? In particular, is the musical quality stable for large values of n?\n\nThere is no principled way of choosing N, however Section 6.2 now discusses the convergence behavior of different Gibbs procedures.  Figure 2 shows results on how negative log-likelihood (NLL) of samples under the model improves with the length of the Gibbs chain.  In particular we see that all of them converge, which suggests that musical quality is indeed stable for large values of n.\n\nIndependent blocked Gibbs (due to Yao et al, see Section 5.2 for a description of the algorithm) is the preferred sampling procedure because it is among the sampling procedures that achieve the best log-likelihoods (see Table 2) and it is dramatically faster as it requires only one model evaluation per Gibbs step (as opposed to O(IT) model evaluations for the ancestral blocked Gibbs procedures (previously Algorithm 1)).  We show in Section 6.3 through human listening tests that samples from the independent Gibbs procedure are considered more musical than those from ancestral sampling (NADE).\n\n\n> In Section 7.3, a model that was trained on denoising is introduced. How does this model relate to the other models? In particular, how was the context C chosen during training?\n\nFor the denoising model, the context was chosen according to independent Bernoulli variables with inclusion probability 0.5.  The difference in this model is in how the input data is set up, in particular no masks are used: the variables not in the context C are randomly perturbed rather than masked, and the model does not know which variables constitute the context (i.e. no mask is fed in). This setup essentially requires the model to both identify which parts have been perturbed as well as how to correct them. However, in the process of revising our paper to better bring out our main finding, we decided to omit the denoising variant.\n\n\n> It would make sense to me to include a trivial baseline model in the human evaluation to better judge the significance of those results. Even a model that just randomly shuffles the time dimension would be a helpful sanity check for the quality of the AMT responses.\n\nAs a result of focusing more on comparing sampling procedures rather than model types, we have removed the previous human evaluation results on model types and added new results on comparing sampling procedures (see Section 6.3).  Here the baseline used is ancestral sampling (NADE), which is the conventional way of sampling from orderless NADEs (see Section 5.1 for a discussion).  In Section 6.4, we see Independent Gibbs outperform ancestral sampling (NADE) by a large margin on the human evaluation test.  This ordering was also found in the log-likelihood evaluations (see Table 2).\n\nWe share your concern on the reliability of Amazon Mechanical Turk.  However, our new human evaluation is stronger than the previous one.  Our previous human evaluation did not have a clear baseline.  Now, ancestral sampling (NADE) forms our baseline as this is the conventional way of sampling from NADE models.  Also, the performance margins between the models are much more pronounced than in the previous experiment.  This in our opinion lessens the need to compare to a trivial baseline.  We agree though that it would be a good sanity check, and will definitely include a trivial baseline if/when we redo the human evaluation.\n\n\nThank you again for spending the time to help us improve our work.\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Counterpoint by Convolution", "abstract": "Machine learning models of music typically break down the task of composition into a chronological process, composing a piece of music in a single pass from beginning to end. On the contrary, human composers write music in a nonlinear fashion, scribbling motifs here and there, often revisiting choices previously made. We explore the use of blocked Gibbs sampling as an analogue to the human approach, and introduce Coconet, a convolutional neural network in the NADE family of generative models. Despite ostensibly sampling from the same distribution as the NADE ancestral sampling procedure, we find that a blocked Gibbs approach significantly improves sample quality. We provide evidence that this is due to some conditional distributions being poorly modeled. Moreover, we show that even the cheap approximate blocked Gibbs procedure from Yao et al. (2014) yields better samples than ancestral sampling. We demonstrate the versatility of our method on unconditioned polyphonic music generation.", "pdf": "/pdf/fbfa9f4044a6f033361d0e1c10d31e61e4f15a36.pdf", "TL;DR": "NADE generative model of music, with new insights on sampling", "paperhash": "huang|counterpoint_by_convolution", "keywords": ["Deep learning", "Applications", "Unsupervised Learning"], "conflicts": ["umontreal.ca", "google.com"], "authors": ["Cheng-Zhi Anna Huang", "Tim Cooijmans", "Adam Roberts", "Aaron Courville", "Douglas Eck"], "authorids": ["chengzhiannahuang@gmail.com", "tim.cooijmans@umontreal.ca", "adarob@google.com", "aaron.courville@umontreal.ca", "deck@google.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287582989, "id": "ICLR.cc/2017/conference/-/paper424/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "r1Usiwcex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper424/reviewers", "ICLR.cc/2017/conference/paper424/areachairs"], "cdate": 1485287582989}}}, {"tddate": null, "tmdate": 1481376523893, "tcdate": 1481365139728, "number": 2, "id": "BJ3988YQg", "invitation": "ICLR.cc/2017/conference/-/paper424/pre-review/question", "forum": "r1Usiwcex", "replyto": "r1Usiwcex", "signatures": ["ICLR.cc/2017/conference/paper424/AnonReviewer4"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper424/AnonReviewer4"], "content": {"title": "Stopping criterion for sampling procedure and denoising model", "question": "- Is there a principled value for the number of sampling loops n in algorithm 1? If not, how did the authors typically chose n. Also, in the conditioned rewriting task, how did the results change for varying n? In particular, is the musical quality stable for large values of n?\n\n- In section 7.3, a model that was trained on denoising is introduced. How does this model relate to the other models? In particular, how was the context C chosen during training?\n\nEdit: \n- It would make sense to me to include a trivial baseline model in the human evaluation to better judge the significance of those results. Even a model that just randomly shuffles the time dimension would be a helpful sanity check for the quality of the AMT responses."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Counterpoint by Convolution", "abstract": "Machine learning models of music typically break down the task of composition into a chronological process, composing a piece of music in a single pass from beginning to end. On the contrary, human composers write music in a nonlinear fashion, scribbling motifs here and there, often revisiting choices previously made. We explore the use of blocked Gibbs sampling as an analogue to the human approach, and introduce Coconet, a convolutional neural network in the NADE family of generative models. Despite ostensibly sampling from the same distribution as the NADE ancestral sampling procedure, we find that a blocked Gibbs approach significantly improves sample quality. We provide evidence that this is due to some conditional distributions being poorly modeled. Moreover, we show that even the cheap approximate blocked Gibbs procedure from Yao et al. (2014) yields better samples than ancestral sampling. We demonstrate the versatility of our method on unconditioned polyphonic music generation.", "pdf": "/pdf/fbfa9f4044a6f033361d0e1c10d31e61e4f15a36.pdf", "TL;DR": "NADE generative model of music, with new insights on sampling", "paperhash": "huang|counterpoint_by_convolution", "keywords": ["Deep learning", "Applications", "Unsupervised Learning"], "conflicts": ["umontreal.ca", "google.com"], "authors": ["Cheng-Zhi Anna Huang", "Tim Cooijmans", "Adam Roberts", "Aaron Courville", "Douglas Eck"], "authorids": ["chengzhiannahuang@gmail.com", "tim.cooijmans@umontreal.ca", "adarob@google.com", "aaron.courville@umontreal.ca", "deck@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481365140326, "id": "ICLR.cc/2017/conference/-/paper424/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper424/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper424/AnonReviewer3", "ICLR.cc/2017/conference/paper424/AnonReviewer4"], "reply": {"forum": "r1Usiwcex", "replyto": "r1Usiwcex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper424/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper424/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481365140326}}}, {"tddate": null, "tmdate": 1481189880557, "tcdate": 1481189880551, "number": 1, "id": "BygZ5o8Xl", "invitation": "ICLR.cc/2017/conference/-/paper424/pre-review/question", "forum": "r1Usiwcex", "replyto": "r1Usiwcex", "signatures": ["ICLR.cc/2017/conference/paper424/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper424/AnonReviewer3"], "content": {"title": "Nice paper", "question": "Will the authors release the code to github?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Counterpoint by Convolution", "abstract": "Machine learning models of music typically break down the task of composition into a chronological process, composing a piece of music in a single pass from beginning to end. On the contrary, human composers write music in a nonlinear fashion, scribbling motifs here and there, often revisiting choices previously made. We explore the use of blocked Gibbs sampling as an analogue to the human approach, and introduce Coconet, a convolutional neural network in the NADE family of generative models. Despite ostensibly sampling from the same distribution as the NADE ancestral sampling procedure, we find that a blocked Gibbs approach significantly improves sample quality. We provide evidence that this is due to some conditional distributions being poorly modeled. Moreover, we show that even the cheap approximate blocked Gibbs procedure from Yao et al. (2014) yields better samples than ancestral sampling. We demonstrate the versatility of our method on unconditioned polyphonic music generation.", "pdf": "/pdf/fbfa9f4044a6f033361d0e1c10d31e61e4f15a36.pdf", "TL;DR": "NADE generative model of music, with new insights on sampling", "paperhash": "huang|counterpoint_by_convolution", "keywords": ["Deep learning", "Applications", "Unsupervised Learning"], "conflicts": ["umontreal.ca", "google.com"], "authors": ["Cheng-Zhi Anna Huang", "Tim Cooijmans", "Adam Roberts", "Aaron Courville", "Douglas Eck"], "authorids": ["chengzhiannahuang@gmail.com", "tim.cooijmans@umontreal.ca", "adarob@google.com", "aaron.courville@umontreal.ca", "deck@google.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481365140326, "id": "ICLR.cc/2017/conference/-/paper424/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper424/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper424/AnonReviewer3", "ICLR.cc/2017/conference/paper424/AnonReviewer4"], "reply": {"forum": "r1Usiwcex", "replyto": "r1Usiwcex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper424/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper424/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481365140326}}}], "count": 13}