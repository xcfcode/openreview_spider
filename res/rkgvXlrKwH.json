{"notes": [{"id": "rkgvXlrKwH", "original": "r1gBEVeKwS", "number": 2213, "cdate": 1569439774590, "ddate": null, "tcdate": 1569439774590, "tmdate": 1583912021745, "tddate": null, "forum": "rkgvXlrKwH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["lespeholt@google.com", "raphaelm@google.com", "stanczyk@google.com", "kewa@google.com", "michalski@google.com"], "title": "SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference", "authors": ["Lasse Espeholt", "Rapha\u00ebl Marinier", "Piotr Stanczyk", "Ke Wang", "Marcin Michalski\u200e"], "pdf": "/pdf/bce334f7e39344120d107d0806e64d13b8c8f874.pdf", "TL;DR": "SEED RL, a scalable and efficient deep reinforcement learning agent with accelerated central inference. State of the art results, reduces cost and can process millions of frames per second. ", "abstract": "We present a modern scalable reinforcement learning agent called SEED (Scalable, Efficient Deep-RL). By effectively utilizing modern accelerators, we show that it is not only possible to train on millions of frames per second but also to lower the cost. of experiments compared to current methods. We achieve this with a simple architecture that features centralized inference and an optimized communication layer. SEED adopts two state-of-the-art distributed algorithms, IMPALA/V-trace (policy gradients) and R2D2 (Q-learning), and is evaluated on Atari-57, DeepMind Lab and Google Research Football. We improve the state of the art on Football and are able to reach state of the art on Atari-57 twice as fast in wall-time. For the scenarios we consider, a 40% to 80% cost reduction for running experiments is achieved. The implementation along with experiments is open-sourced so results can be reproduced and novel ideas tried out.", "code": "https://drive.google.com/file/d/144yp7PQf486dmctE2oS2md_qmNBTFbez/view?usp=sharing", "keywords": ["machine learning", "reinforcement learning", "scalability", "distributed", "DeepMind Lab", "ALE", "Atari-57", "Google Research Football"], "paperhash": "espeholt|seed_rl_scalable_and_efficient_deeprl_with_accelerated_central_inference", "_bibtex": "@inproceedings{\nEspeholt2020SEED,\ntitle={SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference},\nauthor={Lasse Espeholt and Rapha\u00ebl Marinier and Piotr Stanczyk and Ke Wang and Marcin Michalski\u200e},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgvXlrKwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/c27c18b2100faeacaaa4f2e4a6cf5e2cec421815.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "eEx-yC4jiT", "original": null, "number": 1, "cdate": 1576798743364, "ddate": null, "tcdate": 1576798743364, "tmdate": 1576800892844, "tddate": null, "forum": "rkgvXlrKwH", "replyto": "rkgvXlrKwH", "invitation": "ICLR.cc/2020/Conference/Paper2213/-/Decision", "content": {"decision": "Accept (Talk)", "comment": "The paper presents a framework for scalable Deep-RL on really large-scale architecture, which addresses several problems on multi-machine training of such systems with many actors and learners running.  Large-scale experiments and impovements over IMPALA are presented, leading to new SOTA results. The reviewers are very positive over this work, and I think this is an important contribution to the overall learning / RL community.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["lespeholt@google.com", "raphaelm@google.com", "stanczyk@google.com", "kewa@google.com", "michalski@google.com"], "title": "SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference", "authors": ["Lasse Espeholt", "Rapha\u00ebl Marinier", "Piotr Stanczyk", "Ke Wang", "Marcin Michalski\u200e"], "pdf": "/pdf/bce334f7e39344120d107d0806e64d13b8c8f874.pdf", "TL;DR": "SEED RL, a scalable and efficient deep reinforcement learning agent with accelerated central inference. State of the art results, reduces cost and can process millions of frames per second. ", "abstract": "We present a modern scalable reinforcement learning agent called SEED (Scalable, Efficient Deep-RL). By effectively utilizing modern accelerators, we show that it is not only possible to train on millions of frames per second but also to lower the cost. of experiments compared to current methods. We achieve this with a simple architecture that features centralized inference and an optimized communication layer. SEED adopts two state-of-the-art distributed algorithms, IMPALA/V-trace (policy gradients) and R2D2 (Q-learning), and is evaluated on Atari-57, DeepMind Lab and Google Research Football. We improve the state of the art on Football and are able to reach state of the art on Atari-57 twice as fast in wall-time. For the scenarios we consider, a 40% to 80% cost reduction for running experiments is achieved. The implementation along with experiments is open-sourced so results can be reproduced and novel ideas tried out.", "code": "https://drive.google.com/file/d/144yp7PQf486dmctE2oS2md_qmNBTFbez/view?usp=sharing", "keywords": ["machine learning", "reinforcement learning", "scalability", "distributed", "DeepMind Lab", "ALE", "Atari-57", "Google Research Football"], "paperhash": "espeholt|seed_rl_scalable_and_efficient_deeprl_with_accelerated_central_inference", "_bibtex": "@inproceedings{\nEspeholt2020SEED,\ntitle={SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference},\nauthor={Lasse Espeholt and Rapha\u00ebl Marinier and Piotr Stanczyk and Ke Wang and Marcin Michalski\u200e},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgvXlrKwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/c27c18b2100faeacaaa4f2e4a6cf5e2cec421815.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "rkgvXlrKwH", "replyto": "rkgvXlrKwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795708081, "tmdate": 1576800256411, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2213/-/Decision"}}}, {"id": "B1lAv2N2jr", "original": null, "number": 4, "cdate": 1573829733606, "ddate": null, "tcdate": 1573829733606, "tmdate": 1573829733606, "tddate": null, "forum": "rkgvXlrKwH", "replyto": "ryeuWTbPsH", "invitation": "ICLR.cc/2020/Conference/Paper2213/-/Official_Comment", "content": {"title": "Paper updated with apple-to-apple comparison", "comment": "We thank again the reviewer for their positive comments.\n\nWe have updated the paper with an \"apple-to-apple\" comparison by running both agents on an Nvidia P100 GPU. See table 1 for update figures, as well as additional analysis in section 4.1.2 and additional cost comparison in section A.6.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2213/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2213/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["lespeholt@google.com", "raphaelm@google.com", "stanczyk@google.com", "kewa@google.com", "michalski@google.com"], "title": "SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference", "authors": ["Lasse Espeholt", "Rapha\u00ebl Marinier", "Piotr Stanczyk", "Ke Wang", "Marcin Michalski\u200e"], "pdf": "/pdf/bce334f7e39344120d107d0806e64d13b8c8f874.pdf", "TL;DR": "SEED RL, a scalable and efficient deep reinforcement learning agent with accelerated central inference. State of the art results, reduces cost and can process millions of frames per second. ", "abstract": "We present a modern scalable reinforcement learning agent called SEED (Scalable, Efficient Deep-RL). By effectively utilizing modern accelerators, we show that it is not only possible to train on millions of frames per second but also to lower the cost. of experiments compared to current methods. We achieve this with a simple architecture that features centralized inference and an optimized communication layer. SEED adopts two state-of-the-art distributed algorithms, IMPALA/V-trace (policy gradients) and R2D2 (Q-learning), and is evaluated on Atari-57, DeepMind Lab and Google Research Football. We improve the state of the art on Football and are able to reach state of the art on Atari-57 twice as fast in wall-time. For the scenarios we consider, a 40% to 80% cost reduction for running experiments is achieved. The implementation along with experiments is open-sourced so results can be reproduced and novel ideas tried out.", "code": "https://drive.google.com/file/d/144yp7PQf486dmctE2oS2md_qmNBTFbez/view?usp=sharing", "keywords": ["machine learning", "reinforcement learning", "scalability", "distributed", "DeepMind Lab", "ALE", "Atari-57", "Google Research Football"], "paperhash": "espeholt|seed_rl_scalable_and_efficient_deeprl_with_accelerated_central_inference", "_bibtex": "@inproceedings{\nEspeholt2020SEED,\ntitle={SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference},\nauthor={Lasse Espeholt and Rapha\u00ebl Marinier and Piotr Stanczyk and Ke Wang and Marcin Michalski\u200e},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgvXlrKwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/c27c18b2100faeacaaa4f2e4a6cf5e2cec421815.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkgvXlrKwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2213/Authors", "ICLR.cc/2020/Conference/Paper2213/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2213/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2213/Reviewers", "ICLR.cc/2020/Conference/Paper2213/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2213/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2213/Authors|ICLR.cc/2020/Conference/Paper2213/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504144683, "tmdate": 1576860557910, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2213/Authors", "ICLR.cc/2020/Conference/Paper2213/Reviewers", "ICLR.cc/2020/Conference/Paper2213/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2213/-/Official_Comment"}}}, {"id": "rJlXiabPsS", "original": null, "number": 3, "cdate": 1573490075329, "ddate": null, "tcdate": 1573490075329, "tmdate": 1573490075329, "tddate": null, "forum": "rkgvXlrKwH", "replyto": "S1g1dnlAYS", "invitation": "ICLR.cc/2020/Conference/Paper2213/-/Official_Comment", "content": {"title": "Response", "comment": "We thank the reviewer for the time, comments on the paper and the appreciation of open sourcing the content of the paper."}, "signatures": ["ICLR.cc/2020/Conference/Paper2213/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2213/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["lespeholt@google.com", "raphaelm@google.com", "stanczyk@google.com", "kewa@google.com", "michalski@google.com"], "title": "SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference", "authors": ["Lasse Espeholt", "Rapha\u00ebl Marinier", "Piotr Stanczyk", "Ke Wang", "Marcin Michalski\u200e"], "pdf": "/pdf/bce334f7e39344120d107d0806e64d13b8c8f874.pdf", "TL;DR": "SEED RL, a scalable and efficient deep reinforcement learning agent with accelerated central inference. State of the art results, reduces cost and can process millions of frames per second. ", "abstract": "We present a modern scalable reinforcement learning agent called SEED (Scalable, Efficient Deep-RL). By effectively utilizing modern accelerators, we show that it is not only possible to train on millions of frames per second but also to lower the cost. of experiments compared to current methods. We achieve this with a simple architecture that features centralized inference and an optimized communication layer. SEED adopts two state-of-the-art distributed algorithms, IMPALA/V-trace (policy gradients) and R2D2 (Q-learning), and is evaluated on Atari-57, DeepMind Lab and Google Research Football. We improve the state of the art on Football and are able to reach state of the art on Atari-57 twice as fast in wall-time. For the scenarios we consider, a 40% to 80% cost reduction for running experiments is achieved. The implementation along with experiments is open-sourced so results can be reproduced and novel ideas tried out.", "code": "https://drive.google.com/file/d/144yp7PQf486dmctE2oS2md_qmNBTFbez/view?usp=sharing", "keywords": ["machine learning", "reinforcement learning", "scalability", "distributed", "DeepMind Lab", "ALE", "Atari-57", "Google Research Football"], "paperhash": "espeholt|seed_rl_scalable_and_efficient_deeprl_with_accelerated_central_inference", "_bibtex": "@inproceedings{\nEspeholt2020SEED,\ntitle={SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference},\nauthor={Lasse Espeholt and Rapha\u00ebl Marinier and Piotr Stanczyk and Ke Wang and Marcin Michalski\u200e},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgvXlrKwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/c27c18b2100faeacaaa4f2e4a6cf5e2cec421815.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkgvXlrKwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2213/Authors", "ICLR.cc/2020/Conference/Paper2213/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2213/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2213/Reviewers", "ICLR.cc/2020/Conference/Paper2213/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2213/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2213/Authors|ICLR.cc/2020/Conference/Paper2213/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504144683, "tmdate": 1576860557910, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2213/Authors", "ICLR.cc/2020/Conference/Paper2213/Reviewers", "ICLR.cc/2020/Conference/Paper2213/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2213/-/Official_Comment"}}}, {"id": "Skxw_a-vjr", "original": null, "number": 2, "cdate": 1573490030804, "ddate": null, "tcdate": 1573490030804, "tmdate": 1573490030804, "tddate": null, "forum": "rkgvXlrKwH", "replyto": "S1lmYz5Ycr", "invitation": "ICLR.cc/2020/Conference/Paper2213/-/Official_Comment", "content": {"title": "Support for including SEED at the ICLR conference", "comment": "We thank the reviewer for the time and positive comments on the paper.\n\nTo support including the paper at the ICLR conference, we note that ICLR in previous years included papers with similar flavor to SEED such as,\nDistributed Prioritized Experience Replay (Ape-X), ICLR 2018\nRecurrent Experience Replay in Distributed Reinforcement Learning (R2D2), ICLR 2019"}, "signatures": ["ICLR.cc/2020/Conference/Paper2213/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2213/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["lespeholt@google.com", "raphaelm@google.com", "stanczyk@google.com", "kewa@google.com", "michalski@google.com"], "title": "SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference", "authors": ["Lasse Espeholt", "Rapha\u00ebl Marinier", "Piotr Stanczyk", "Ke Wang", "Marcin Michalski\u200e"], "pdf": "/pdf/bce334f7e39344120d107d0806e64d13b8c8f874.pdf", "TL;DR": "SEED RL, a scalable and efficient deep reinforcement learning agent with accelerated central inference. State of the art results, reduces cost and can process millions of frames per second. ", "abstract": "We present a modern scalable reinforcement learning agent called SEED (Scalable, Efficient Deep-RL). By effectively utilizing modern accelerators, we show that it is not only possible to train on millions of frames per second but also to lower the cost. of experiments compared to current methods. We achieve this with a simple architecture that features centralized inference and an optimized communication layer. SEED adopts two state-of-the-art distributed algorithms, IMPALA/V-trace (policy gradients) and R2D2 (Q-learning), and is evaluated on Atari-57, DeepMind Lab and Google Research Football. We improve the state of the art on Football and are able to reach state of the art on Atari-57 twice as fast in wall-time. For the scenarios we consider, a 40% to 80% cost reduction for running experiments is achieved. The implementation along with experiments is open-sourced so results can be reproduced and novel ideas tried out.", "code": "https://drive.google.com/file/d/144yp7PQf486dmctE2oS2md_qmNBTFbez/view?usp=sharing", "keywords": ["machine learning", "reinforcement learning", "scalability", "distributed", "DeepMind Lab", "ALE", "Atari-57", "Google Research Football"], "paperhash": "espeholt|seed_rl_scalable_and_efficient_deeprl_with_accelerated_central_inference", "_bibtex": "@inproceedings{\nEspeholt2020SEED,\ntitle={SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference},\nauthor={Lasse Espeholt and Rapha\u00ebl Marinier and Piotr Stanczyk and Ke Wang and Marcin Michalski\u200e},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgvXlrKwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/c27c18b2100faeacaaa4f2e4a6cf5e2cec421815.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkgvXlrKwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2213/Authors", "ICLR.cc/2020/Conference/Paper2213/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2213/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2213/Reviewers", "ICLR.cc/2020/Conference/Paper2213/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2213/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2213/Authors|ICLR.cc/2020/Conference/Paper2213/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504144683, "tmdate": 1576860557910, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2213/Authors", "ICLR.cc/2020/Conference/Paper2213/Reviewers", "ICLR.cc/2020/Conference/Paper2213/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2213/-/Official_Comment"}}}, {"id": "ryeuWTbPsH", "original": null, "number": 1, "cdate": 1573489919533, "ddate": null, "tcdate": 1573489919533, "tmdate": 1573489919533, "tddate": null, "forum": "rkgvXlrKwH", "replyto": "Byg1qYe5qS", "invitation": "ICLR.cc/2020/Conference/Paper2213/-/Official_Comment", "content": {"title": "Regarding apple-to-apple comparison", "comment": "We thank the reviewer for the time and the positive comments.\n\nWith regards to comparing apples-to-apples, we will add the performance of running SEED with Nvidia P100\u2019s. Note, the cost of running IMPALA does not improve significantly with TPUs as the cost is dominated by inference on CPU."}, "signatures": ["ICLR.cc/2020/Conference/Paper2213/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2213/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["lespeholt@google.com", "raphaelm@google.com", "stanczyk@google.com", "kewa@google.com", "michalski@google.com"], "title": "SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference", "authors": ["Lasse Espeholt", "Rapha\u00ebl Marinier", "Piotr Stanczyk", "Ke Wang", "Marcin Michalski\u200e"], "pdf": "/pdf/bce334f7e39344120d107d0806e64d13b8c8f874.pdf", "TL;DR": "SEED RL, a scalable and efficient deep reinforcement learning agent with accelerated central inference. State of the art results, reduces cost and can process millions of frames per second. ", "abstract": "We present a modern scalable reinforcement learning agent called SEED (Scalable, Efficient Deep-RL). By effectively utilizing modern accelerators, we show that it is not only possible to train on millions of frames per second but also to lower the cost. of experiments compared to current methods. We achieve this with a simple architecture that features centralized inference and an optimized communication layer. SEED adopts two state-of-the-art distributed algorithms, IMPALA/V-trace (policy gradients) and R2D2 (Q-learning), and is evaluated on Atari-57, DeepMind Lab and Google Research Football. We improve the state of the art on Football and are able to reach state of the art on Atari-57 twice as fast in wall-time. For the scenarios we consider, a 40% to 80% cost reduction for running experiments is achieved. The implementation along with experiments is open-sourced so results can be reproduced and novel ideas tried out.", "code": "https://drive.google.com/file/d/144yp7PQf486dmctE2oS2md_qmNBTFbez/view?usp=sharing", "keywords": ["machine learning", "reinforcement learning", "scalability", "distributed", "DeepMind Lab", "ALE", "Atari-57", "Google Research Football"], "paperhash": "espeholt|seed_rl_scalable_and_efficient_deeprl_with_accelerated_central_inference", "_bibtex": "@inproceedings{\nEspeholt2020SEED,\ntitle={SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference},\nauthor={Lasse Espeholt and Rapha\u00ebl Marinier and Piotr Stanczyk and Ke Wang and Marcin Michalski\u200e},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgvXlrKwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/c27c18b2100faeacaaa4f2e4a6cf5e2cec421815.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkgvXlrKwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2213/Authors", "ICLR.cc/2020/Conference/Paper2213/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2213/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2213/Reviewers", "ICLR.cc/2020/Conference/Paper2213/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2213/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2213/Authors|ICLR.cc/2020/Conference/Paper2213/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504144683, "tmdate": 1576860557910, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2213/Authors", "ICLR.cc/2020/Conference/Paper2213/Reviewers", "ICLR.cc/2020/Conference/Paper2213/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2213/-/Official_Comment"}}}, {"id": "S1g1dnlAYS", "original": null, "number": 1, "cdate": 1571847271195, "ddate": null, "tcdate": 1571847271195, "tmdate": 1572972368287, "tddate": null, "forum": "rkgvXlrKwH", "replyto": "rkgvXlrKwH", "invitation": "ICLR.cc/2020/Conference/Paper2213/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper presents SEED RL, which is a scalable reinforcement learning agent. The approach restructure the interface / division of functionality between the actors (environments) and the learner as compared to the distributed approach in IMPALA (a state-of-the-art distributed RL framework). Most importantly, the model is only in the learner in SEED while it is distributed in IMPALA. \n\nThe architectural change from to IMPALA to SEED feels reasonable, and the results support the choices in a positive way.\n\nSEED is evaluated using a large number of benchmarks using three environments, and the performance is compared to IMPALA. The results are very good, shows good scalability, and significantly reduced training times.  \n\nThe paper is well written, easy to read, and I enjoyed it. \n\nThe code for SEED is released open source, which enables future research to build upon SEED. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2213/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2213/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["lespeholt@google.com", "raphaelm@google.com", "stanczyk@google.com", "kewa@google.com", "michalski@google.com"], "title": "SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference", "authors": ["Lasse Espeholt", "Rapha\u00ebl Marinier", "Piotr Stanczyk", "Ke Wang", "Marcin Michalski\u200e"], "pdf": "/pdf/bce334f7e39344120d107d0806e64d13b8c8f874.pdf", "TL;DR": "SEED RL, a scalable and efficient deep reinforcement learning agent with accelerated central inference. State of the art results, reduces cost and can process millions of frames per second. ", "abstract": "We present a modern scalable reinforcement learning agent called SEED (Scalable, Efficient Deep-RL). By effectively utilizing modern accelerators, we show that it is not only possible to train on millions of frames per second but also to lower the cost. of experiments compared to current methods. We achieve this with a simple architecture that features centralized inference and an optimized communication layer. SEED adopts two state-of-the-art distributed algorithms, IMPALA/V-trace (policy gradients) and R2D2 (Q-learning), and is evaluated on Atari-57, DeepMind Lab and Google Research Football. We improve the state of the art on Football and are able to reach state of the art on Atari-57 twice as fast in wall-time. For the scenarios we consider, a 40% to 80% cost reduction for running experiments is achieved. The implementation along with experiments is open-sourced so results can be reproduced and novel ideas tried out.", "code": "https://drive.google.com/file/d/144yp7PQf486dmctE2oS2md_qmNBTFbez/view?usp=sharing", "keywords": ["machine learning", "reinforcement learning", "scalability", "distributed", "DeepMind Lab", "ALE", "Atari-57", "Google Research Football"], "paperhash": "espeholt|seed_rl_scalable_and_efficient_deeprl_with_accelerated_central_inference", "_bibtex": "@inproceedings{\nEspeholt2020SEED,\ntitle={SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference},\nauthor={Lasse Espeholt and Rapha\u00ebl Marinier and Piotr Stanczyk and Ke Wang and Marcin Michalski\u200e},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgvXlrKwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/c27c18b2100faeacaaa4f2e4a6cf5e2cec421815.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkgvXlrKwH", "replyto": "rkgvXlrKwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2213/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2213/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575632959929, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2213/Reviewers"], "noninvitees": [], "tcdate": 1570237726083, "tmdate": 1575632959945, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2213/-/Official_Review"}}}, {"id": "S1lmYz5Ycr", "original": null, "number": 2, "cdate": 1572606587166, "ddate": null, "tcdate": 1572606587166, "tmdate": 1572972368240, "tddate": null, "forum": "rkgvXlrKwH", "replyto": "rkgvXlrKwH", "invitation": "ICLR.cc/2020/Conference/Paper2213/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper proposes a new reinforcement learning agent architecture which is significantly faster and way less costly than previously distributed architectures. To this end, the paper proposes a new architecture that utilizes modern accelerators more efficiently.  The paper reads very well and the experimental results indeed demonstrate improvement. Nevertheless, even though working in deep learning for years and have also some experience with Reinforcement learning I am not in the position to provide an expert judgment on the novelty of the work. I do not know if ICLR is the right place of the paper (I would probably suggest a system architectures conference for better assessment of the work)."}, "signatures": ["ICLR.cc/2020/Conference/Paper2213/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2213/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["lespeholt@google.com", "raphaelm@google.com", "stanczyk@google.com", "kewa@google.com", "michalski@google.com"], "title": "SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference", "authors": ["Lasse Espeholt", "Rapha\u00ebl Marinier", "Piotr Stanczyk", "Ke Wang", "Marcin Michalski\u200e"], "pdf": "/pdf/bce334f7e39344120d107d0806e64d13b8c8f874.pdf", "TL;DR": "SEED RL, a scalable and efficient deep reinforcement learning agent with accelerated central inference. State of the art results, reduces cost and can process millions of frames per second. ", "abstract": "We present a modern scalable reinforcement learning agent called SEED (Scalable, Efficient Deep-RL). By effectively utilizing modern accelerators, we show that it is not only possible to train on millions of frames per second but also to lower the cost. of experiments compared to current methods. We achieve this with a simple architecture that features centralized inference and an optimized communication layer. SEED adopts two state-of-the-art distributed algorithms, IMPALA/V-trace (policy gradients) and R2D2 (Q-learning), and is evaluated on Atari-57, DeepMind Lab and Google Research Football. We improve the state of the art on Football and are able to reach state of the art on Atari-57 twice as fast in wall-time. For the scenarios we consider, a 40% to 80% cost reduction for running experiments is achieved. The implementation along with experiments is open-sourced so results can be reproduced and novel ideas tried out.", "code": "https://drive.google.com/file/d/144yp7PQf486dmctE2oS2md_qmNBTFbez/view?usp=sharing", "keywords": ["machine learning", "reinforcement learning", "scalability", "distributed", "DeepMind Lab", "ALE", "Atari-57", "Google Research Football"], "paperhash": "espeholt|seed_rl_scalable_and_efficient_deeprl_with_accelerated_central_inference", "_bibtex": "@inproceedings{\nEspeholt2020SEED,\ntitle={SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference},\nauthor={Lasse Espeholt and Rapha\u00ebl Marinier and Piotr Stanczyk and Ke Wang and Marcin Michalski\u200e},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgvXlrKwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/c27c18b2100faeacaaa4f2e4a6cf5e2cec421815.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkgvXlrKwH", "replyto": "rkgvXlrKwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2213/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2213/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575632959929, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2213/Reviewers"], "noninvitees": [], "tcdate": 1570237726083, "tmdate": 1575632959945, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2213/-/Official_Review"}}}, {"id": "Byg1qYe5qS", "original": null, "number": 3, "cdate": 1572632966591, "ddate": null, "tcdate": 1572632966591, "tmdate": 1572972368193, "tddate": null, "forum": "rkgvXlrKwH", "replyto": "rkgvXlrKwH", "invitation": "ICLR.cc/2020/Conference/Paper2213/-/Official_Review", "content": {"rating": "8: Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #5", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper presents a scalable reinforcement learning training architecture which combines a number of modern engineering advances to address the inefficiencies of prior methods. The proposed architecture shows good performance on a wide variety of benchmarks from ALE to DeepMind Lab and Google Research Football. Important to the community, authors also open source their code and provide an estimate which shows that the proposed framework is cheaper to run on cloud platforms.\n\nPros:\n1. This work is solid from the engineering perspective. It effectively addresses the problems with prior architectures and the accompanying source code is clear and well structured. It is also extensively tested on several RL benchmarks.\n\n2. The proposed framework is especially suited for training large models as the model parameters are not transferred between actors and learners.\n\n3. The paper is well written and organized.\n\nCons:\n\n1. The gain of the main algorithmic improvement (SEED architecture) over the baseline (IMPALA architecture) is obscured by the usage of different hardware. TPUv3 has different characteristics than Nvidia P100/V100 GPU chips which also might contribute to the speed up.\n\nQuestions:\n\n1. Is it possible to provide more \u201capple-to-apple\u201d comparison by running SEED and IMPALA on the same hardware (TPUv3 or Nvidia P100/V100 GPU)? "}, "signatures": ["ICLR.cc/2020/Conference/Paper2213/AnonReviewer5"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2213/AnonReviewer5"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["lespeholt@google.com", "raphaelm@google.com", "stanczyk@google.com", "kewa@google.com", "michalski@google.com"], "title": "SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference", "authors": ["Lasse Espeholt", "Rapha\u00ebl Marinier", "Piotr Stanczyk", "Ke Wang", "Marcin Michalski\u200e"], "pdf": "/pdf/bce334f7e39344120d107d0806e64d13b8c8f874.pdf", "TL;DR": "SEED RL, a scalable and efficient deep reinforcement learning agent with accelerated central inference. State of the art results, reduces cost and can process millions of frames per second. ", "abstract": "We present a modern scalable reinforcement learning agent called SEED (Scalable, Efficient Deep-RL). By effectively utilizing modern accelerators, we show that it is not only possible to train on millions of frames per second but also to lower the cost. of experiments compared to current methods. We achieve this with a simple architecture that features centralized inference and an optimized communication layer. SEED adopts two state-of-the-art distributed algorithms, IMPALA/V-trace (policy gradients) and R2D2 (Q-learning), and is evaluated on Atari-57, DeepMind Lab and Google Research Football. We improve the state of the art on Football and are able to reach state of the art on Atari-57 twice as fast in wall-time. For the scenarios we consider, a 40% to 80% cost reduction for running experiments is achieved. The implementation along with experiments is open-sourced so results can be reproduced and novel ideas tried out.", "code": "https://drive.google.com/file/d/144yp7PQf486dmctE2oS2md_qmNBTFbez/view?usp=sharing", "keywords": ["machine learning", "reinforcement learning", "scalability", "distributed", "DeepMind Lab", "ALE", "Atari-57", "Google Research Football"], "paperhash": "espeholt|seed_rl_scalable_and_efficient_deeprl_with_accelerated_central_inference", "_bibtex": "@inproceedings{\nEspeholt2020SEED,\ntitle={SEED RL: Scalable and Efficient Deep-RL with Accelerated Central Inference},\nauthor={Lasse Espeholt and Rapha\u00ebl Marinier and Piotr Stanczyk and Ke Wang and Marcin Michalski\u200e},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=rkgvXlrKwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/c27c18b2100faeacaaa4f2e4a6cf5e2cec421815.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkgvXlrKwH", "replyto": "rkgvXlrKwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2213/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2213/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575632959929, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2213/Reviewers"], "noninvitees": [], "tcdate": 1570237726083, "tmdate": 1575632959945, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2213/-/Official_Review"}}}], "count": 9}