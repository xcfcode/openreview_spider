{"notes": [{"id": "HylznxrYDr", "original": "rJxjmxWFPH", "number": 2529, "cdate": 1569439914217, "ddate": null, "tcdate": 1569439914217, "tmdate": 1577168217851, "tddate": null, "forum": "HylznxrYDr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["dogu.araci@naspers.com", "zulkuf.genc@naspers.com"], "title": "FINBERT:  FINANCIAL SENTIMENT ANALYSIS   WITH PRE-TRAINED LANGUAGE MODELS", "authors": ["Dogu Araci", "Zulkuf Genc"], "TL;DR": "We introduce FinBERT, a language model based on BERT for financial text classification, where we improved state-of-the-art performance by 14 percentage points.", "abstract": "While many sentiment classification solutions report  high accuracy scores in product or movie review datasets, the performance of the methods in niche domains such as finance still largely falls behind. The reason of this gap is the domain-specific language, which decreases the applicability of existing models, and lack of quality labeled data to learn the new context of positive and negative in the specific domain. Transfer learning has been shown to be successful in adapting to new domains without large training data sets. In this paper, we explore the effectiveness of NLP transfer learning in financial sentiment classification. We introduce FinBERT, a language model based on BERT, which improved the state-of-the-art performance by 14 percentage points for a financial sentiment classification task in FinancialPhrasebank dataset.", "keywords": ["Financial sentiment analysis", "financial text classification", "transfer learning", "pre-trained language models", "BERT", "NLP"], "pdf": "/pdf/5dbefc43f37cf73dbcb6ad14c3b31b99748296fa.pdf", "paperhash": "araci|finbert_financial_sentiment_analysis_with_pretrained_language_models", "original_pdf": "/attachment/5dbefc43f37cf73dbcb6ad14c3b31b99748296fa.pdf", "_bibtex": "@misc{\naraci2020finbert,\ntitle={{\\{}FINBERT{\\}}:  {\\{}FINANCIAL{\\}} {\\{}SENTIMENT{\\}} {\\{}ANALYSIS{\\}}   {\\{}WITH{\\}} {\\{}PRE{\\}}-{\\{}TRAINED{\\}} {\\{}LANGUAGE{\\}} {\\{}MODELS{\\}}},\nauthor={Dogu Araci and Zulkuf Genc},\nyear={2020},\nurl={https://openreview.net/forum?id=HylznxrYDr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "Ykoc8KR8VD", "original": null, "number": 1, "cdate": 1576798751327, "ddate": null, "tcdate": 1576798751327, "tmdate": 1576800884364, "tddate": null, "forum": "HylznxrYDr", "replyto": "HylznxrYDr", "invitation": "ICLR.cc/2020/Conference/Paper2529/-/Decision", "content": {"decision": "Reject", "comment": "This paper presents FinBERT, a BERT-based model that is further trained on a financial corpus and evaluated on Financial PhraseBank and Financial QA. The authors show that FinBERT slightly outperforms baseline methods on both tasks.\n\nThe reviewers agree that the novelty is limited and this seems to be an application of BERT to financial dataset. There are many cases when it is okay to not present something entirely novel in terms of model as long as a paper still provides new insights on other things. Unfortunately, the new experiments in this paper are also not convincing. The improvements are very minor on small evaluation datasets, which makes the main contributions of the paper not enough for a venue such as ICLR.\n\nThe authors did not respond to any of the reviewers' concerns. I recommend rejecting this paper.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["dogu.araci@naspers.com", "zulkuf.genc@naspers.com"], "title": "FINBERT:  FINANCIAL SENTIMENT ANALYSIS   WITH PRE-TRAINED LANGUAGE MODELS", "authors": ["Dogu Araci", "Zulkuf Genc"], "TL;DR": "We introduce FinBERT, a language model based on BERT for financial text classification, where we improved state-of-the-art performance by 14 percentage points.", "abstract": "While many sentiment classification solutions report  high accuracy scores in product or movie review datasets, the performance of the methods in niche domains such as finance still largely falls behind. The reason of this gap is the domain-specific language, which decreases the applicability of existing models, and lack of quality labeled data to learn the new context of positive and negative in the specific domain. Transfer learning has been shown to be successful in adapting to new domains without large training data sets. In this paper, we explore the effectiveness of NLP transfer learning in financial sentiment classification. We introduce FinBERT, a language model based on BERT, which improved the state-of-the-art performance by 14 percentage points for a financial sentiment classification task in FinancialPhrasebank dataset.", "keywords": ["Financial sentiment analysis", "financial text classification", "transfer learning", "pre-trained language models", "BERT", "NLP"], "pdf": "/pdf/5dbefc43f37cf73dbcb6ad14c3b31b99748296fa.pdf", "paperhash": "araci|finbert_financial_sentiment_analysis_with_pretrained_language_models", "original_pdf": "/attachment/5dbefc43f37cf73dbcb6ad14c3b31b99748296fa.pdf", "_bibtex": "@misc{\naraci2020finbert,\ntitle={{\\{}FINBERT{\\}}:  {\\{}FINANCIAL{\\}} {\\{}SENTIMENT{\\}} {\\{}ANALYSIS{\\}}   {\\{}WITH{\\}} {\\{}PRE{\\}}-{\\{}TRAINED{\\}} {\\{}LANGUAGE{\\}} {\\{}MODELS{\\}}},\nauthor={Dogu Araci and Zulkuf Genc},\nyear={2020},\nurl={https://openreview.net/forum?id=HylznxrYDr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "HylznxrYDr", "replyto": "HylznxrYDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795724666, "tmdate": 1576800276348, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2529/-/Decision"}}}, {"id": "r1g2yTe2Yr", "original": null, "number": 1, "cdate": 1571716324197, "ddate": null, "tcdate": 1571716324197, "tmdate": 1572972326721, "tddate": null, "forum": "HylznxrYDr", "replyto": "HylznxrYDr", "invitation": "ICLR.cc/2020/Conference/Paper2529/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper proposes a domain adaptation type of task via proposing fine-tuning of pre-trained models such as BERT on data from financial domains. The paper starts off with a good motivation about requiring some kind of domain adaptation particularly when performing tasks such as sentiment analysis on data sets from the financial domain. However, there is not much novelty in this paper.\n\n1)The authors do not propose any new model architectures. Even if we were to argue the novelty is in terms of their empirical work, there are some flaws/missing details in the experiments.\n2)In table 1 authors present agreement amongst annotators, it would be nice if in addition to mentioning the source of the data, the authors included what metric was used to attain agreement. I had to read the original paper releasing the data set to figure this out.\n3)Table 4 presents results that do not seem significant. It is hard to conclude if a certain pre-training strategy worked for sure.\n\nOn the whole I am very lukewarm on this paper. I find this paper lacking in novelty. Seems like an ambitious class project turned into an ICLR submission."}, "signatures": ["ICLR.cc/2020/Conference/Paper2529/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2529/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["dogu.araci@naspers.com", "zulkuf.genc@naspers.com"], "title": "FINBERT:  FINANCIAL SENTIMENT ANALYSIS   WITH PRE-TRAINED LANGUAGE MODELS", "authors": ["Dogu Araci", "Zulkuf Genc"], "TL;DR": "We introduce FinBERT, a language model based on BERT for financial text classification, where we improved state-of-the-art performance by 14 percentage points.", "abstract": "While many sentiment classification solutions report  high accuracy scores in product or movie review datasets, the performance of the methods in niche domains such as finance still largely falls behind. The reason of this gap is the domain-specific language, which decreases the applicability of existing models, and lack of quality labeled data to learn the new context of positive and negative in the specific domain. Transfer learning has been shown to be successful in adapting to new domains without large training data sets. In this paper, we explore the effectiveness of NLP transfer learning in financial sentiment classification. We introduce FinBERT, a language model based on BERT, which improved the state-of-the-art performance by 14 percentage points for a financial sentiment classification task in FinancialPhrasebank dataset.", "keywords": ["Financial sentiment analysis", "financial text classification", "transfer learning", "pre-trained language models", "BERT", "NLP"], "pdf": "/pdf/5dbefc43f37cf73dbcb6ad14c3b31b99748296fa.pdf", "paperhash": "araci|finbert_financial_sentiment_analysis_with_pretrained_language_models", "original_pdf": "/attachment/5dbefc43f37cf73dbcb6ad14c3b31b99748296fa.pdf", "_bibtex": "@misc{\naraci2020finbert,\ntitle={{\\{}FINBERT{\\}}:  {\\{}FINANCIAL{\\}} {\\{}SENTIMENT{\\}} {\\{}ANALYSIS{\\}}   {\\{}WITH{\\}} {\\{}PRE{\\}}-{\\{}TRAINED{\\}} {\\{}LANGUAGE{\\}} {\\{}MODELS{\\}}},\nauthor={Dogu Araci and Zulkuf Genc},\nyear={2020},\nurl={https://openreview.net/forum?id=HylznxrYDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HylznxrYDr", "replyto": "HylznxrYDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2529/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2529/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574943878244, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2529/Reviewers"], "noninvitees": [], "tcdate": 1570237721562, "tmdate": 1574943878257, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2529/-/Official_Review"}}}, {"id": "HkeWvWtCtr", "original": null, "number": 2, "cdate": 1571881305068, "ddate": null, "tcdate": 1571881305068, "tmdate": 1572972326685, "tddate": null, "forum": "HylznxrYDr", "replyto": "HylznxrYDr", "invitation": "ICLR.cc/2020/Conference/Paper2529/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2529", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents an analysis of the BERT language model on financial text. FinBERT is evaluated on two datasets from the financial domain: a sentiment prediction dataset (classification with 3 different classes) and a sentiment score prediction (the score is a float number between -1 and 1). \n\nI find the phrasing \"FinBERT is a language model based on BERT\" misleading; I think FinBERT is BERT trained on financial text. There is no modification that is done to the original BERT model.\n\nThe paper presents several experiments using BERT as the language model and fine-tuning for the financial tasks. FinBERT is compared to a few baselines such as LSTMs with ElMO embeddings and ULMfit. I find interesting that the model performs better on the subset of the dataset for which there is perfect agreement between the annotators.\n\nI also find the results on training on financial data interesting. The results seem to indicate that further training on financial text does not seem to result in additional improvement when compared to original BERT.\n\nWhile I find the analysis and the experiments presented in the paper interesting, the novelty of the paper is rather low. There is no new idea introduced in this paper, it contains a series of experiments with BERT on financial text and tasks.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2529/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2529/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["dogu.araci@naspers.com", "zulkuf.genc@naspers.com"], "title": "FINBERT:  FINANCIAL SENTIMENT ANALYSIS   WITH PRE-TRAINED LANGUAGE MODELS", "authors": ["Dogu Araci", "Zulkuf Genc"], "TL;DR": "We introduce FinBERT, a language model based on BERT for financial text classification, where we improved state-of-the-art performance by 14 percentage points.", "abstract": "While many sentiment classification solutions report  high accuracy scores in product or movie review datasets, the performance of the methods in niche domains such as finance still largely falls behind. The reason of this gap is the domain-specific language, which decreases the applicability of existing models, and lack of quality labeled data to learn the new context of positive and negative in the specific domain. Transfer learning has been shown to be successful in adapting to new domains without large training data sets. In this paper, we explore the effectiveness of NLP transfer learning in financial sentiment classification. We introduce FinBERT, a language model based on BERT, which improved the state-of-the-art performance by 14 percentage points for a financial sentiment classification task in FinancialPhrasebank dataset.", "keywords": ["Financial sentiment analysis", "financial text classification", "transfer learning", "pre-trained language models", "BERT", "NLP"], "pdf": "/pdf/5dbefc43f37cf73dbcb6ad14c3b31b99748296fa.pdf", "paperhash": "araci|finbert_financial_sentiment_analysis_with_pretrained_language_models", "original_pdf": "/attachment/5dbefc43f37cf73dbcb6ad14c3b31b99748296fa.pdf", "_bibtex": "@misc{\naraci2020finbert,\ntitle={{\\{}FINBERT{\\}}:  {\\{}FINANCIAL{\\}} {\\{}SENTIMENT{\\}} {\\{}ANALYSIS{\\}}   {\\{}WITH{\\}} {\\{}PRE{\\}}-{\\{}TRAINED{\\}} {\\{}LANGUAGE{\\}} {\\{}MODELS{\\}}},\nauthor={Dogu Araci and Zulkuf Genc},\nyear={2020},\nurl={https://openreview.net/forum?id=HylznxrYDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HylznxrYDr", "replyto": "HylznxrYDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2529/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2529/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574943878244, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2529/Reviewers"], "noninvitees": [], "tcdate": 1570237721562, "tmdate": 1574943878257, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2529/-/Official_Review"}}}, {"id": "H1xnFZHVqH", "original": null, "number": 3, "cdate": 1572258180266, "ddate": null, "tcdate": 1572258180266, "tmdate": 1572972326642, "tddate": null, "forum": "HylznxrYDr", "replyto": "HylznxrYDr", "invitation": "ICLR.cc/2020/Conference/Paper2529/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This paper presents a method for financial sentiment analysis based on the texts obtained from news. The method is based on an existing method BERT (Devlin et al. 2018).  The authors have performed thorough experimental studies of the BERT method on an existing dataset TRC2-financial, a subset of TRC2 consisting of 1.8M news articles. Although the results may be of interest to communities working in this area, there are no or little novel contributions. By reading section 2 (only one page), which describes the method used, I have the impression that the authors took the method BERT and then applied this to the TRC2-financial dataset and then reported the results and also discussed some parameter choices in the BERT method. Therefore, the only value about this paper is the experimental results. Apart from this, there are no other contributions or insights to the methods/problems. In addition, section 2 is over-brief and very unclear, and it only contains a brief summary of the BERT method. For these reasons, I think the paper should be rejected for lacking novelty and writing quality. "}, "signatures": ["ICLR.cc/2020/Conference/Paper2529/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2529/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["dogu.araci@naspers.com", "zulkuf.genc@naspers.com"], "title": "FINBERT:  FINANCIAL SENTIMENT ANALYSIS   WITH PRE-TRAINED LANGUAGE MODELS", "authors": ["Dogu Araci", "Zulkuf Genc"], "TL;DR": "We introduce FinBERT, a language model based on BERT for financial text classification, where we improved state-of-the-art performance by 14 percentage points.", "abstract": "While many sentiment classification solutions report  high accuracy scores in product or movie review datasets, the performance of the methods in niche domains such as finance still largely falls behind. The reason of this gap is the domain-specific language, which decreases the applicability of existing models, and lack of quality labeled data to learn the new context of positive and negative in the specific domain. Transfer learning has been shown to be successful in adapting to new domains without large training data sets. In this paper, we explore the effectiveness of NLP transfer learning in financial sentiment classification. We introduce FinBERT, a language model based on BERT, which improved the state-of-the-art performance by 14 percentage points for a financial sentiment classification task in FinancialPhrasebank dataset.", "keywords": ["Financial sentiment analysis", "financial text classification", "transfer learning", "pre-trained language models", "BERT", "NLP"], "pdf": "/pdf/5dbefc43f37cf73dbcb6ad14c3b31b99748296fa.pdf", "paperhash": "araci|finbert_financial_sentiment_analysis_with_pretrained_language_models", "original_pdf": "/attachment/5dbefc43f37cf73dbcb6ad14c3b31b99748296fa.pdf", "_bibtex": "@misc{\naraci2020finbert,\ntitle={{\\{}FINBERT{\\}}:  {\\{}FINANCIAL{\\}} {\\{}SENTIMENT{\\}} {\\{}ANALYSIS{\\}}   {\\{}WITH{\\}} {\\{}PRE{\\}}-{\\{}TRAINED{\\}} {\\{}LANGUAGE{\\}} {\\{}MODELS{\\}}},\nauthor={Dogu Araci and Zulkuf Genc},\nyear={2020},\nurl={https://openreview.net/forum?id=HylznxrYDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HylznxrYDr", "replyto": "HylznxrYDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2529/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2529/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574943878244, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2529/Reviewers"], "noninvitees": [], "tcdate": 1570237721562, "tmdate": 1574943878257, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2529/-/Official_Review"}}}, {"id": "r1gkpwkhcH", "original": null, "number": 4, "cdate": 1572759479504, "ddate": null, "tcdate": 1572759479504, "tmdate": 1572972326596, "tddate": null, "forum": "HylznxrYDr", "replyto": "HylznxrYDr", "invitation": "ICLR.cc/2020/Conference/Paper2529/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper described the application of BERT in the field of financial sentiment analysis. Authors find that when fine-tuned with in-domain data, BERT outperforms the state-of-the-art, demonstrating that language model pre-training can transfer knowledge learned from unsupervised large corpus to new domain with minimum effort. Experiments are conducted to explore 1) the utility of different in-domain dataset for further pre-training; 2) strategies to avoid catastrophic forgetting, and 3) effectiveness of fine-tuning a subset of the full model. \n\nI am in favor of rejecting this paper and my reasons are as follows:\n\nFirst, this paper may lack deeper innovation, although it demonstrates a good application of the BERT models in financial domain. For example, the framework of general-domain LM pretraining, to in-domain LM pretraining and finally in-domain classifier fine-tuning, as well as techniques of catastrophic forgetting were already proposed in Howard & Ruder 2018. Therefore, I think this paper may be more suitable for other (finance) application-oriented venues.\n\nSecond, the dataset used in evaluation is of small size (for example, Financial PhraseBank test set has one 1K). Thus, even though the paper is about transfer learning to domains without large data, I find it might be more convincing to draw a solid conclusion with a larger test set.\n\nThis paper is well organized and easy to follow. It may be beneficial to clarify in a few places (if space permits):\n1) Some description or statistics of the data may be helpful (e.g., average sentence length or some examples);\n2) Citations to Elmo and ULMFit can be made more explicit. Authors did cite Peters 2018 and Howard 2018 at the beginning of the paper, but may want to explicitly associate them with \u2018Elmo\u2019 and \u2018ULMFit\u2019 when these two terms first occur respectively;\n3) For table 2, does the \u2018all data\u2019 or \u2018data with 100% agreement\u2019 include training data (80%) or just the test data (20%)?\nThe difference between FinBERT(-domain) and ULMFit can be explicitly contrasted in the paper. Is the former initialized with BERT while latter with ULMFit?\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2529/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2529/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["dogu.araci@naspers.com", "zulkuf.genc@naspers.com"], "title": "FINBERT:  FINANCIAL SENTIMENT ANALYSIS   WITH PRE-TRAINED LANGUAGE MODELS", "authors": ["Dogu Araci", "Zulkuf Genc"], "TL;DR": "We introduce FinBERT, a language model based on BERT for financial text classification, where we improved state-of-the-art performance by 14 percentage points.", "abstract": "While many sentiment classification solutions report  high accuracy scores in product or movie review datasets, the performance of the methods in niche domains such as finance still largely falls behind. The reason of this gap is the domain-specific language, which decreases the applicability of existing models, and lack of quality labeled data to learn the new context of positive and negative in the specific domain. Transfer learning has been shown to be successful in adapting to new domains without large training data sets. In this paper, we explore the effectiveness of NLP transfer learning in financial sentiment classification. We introduce FinBERT, a language model based on BERT, which improved the state-of-the-art performance by 14 percentage points for a financial sentiment classification task in FinancialPhrasebank dataset.", "keywords": ["Financial sentiment analysis", "financial text classification", "transfer learning", "pre-trained language models", "BERT", "NLP"], "pdf": "/pdf/5dbefc43f37cf73dbcb6ad14c3b31b99748296fa.pdf", "paperhash": "araci|finbert_financial_sentiment_analysis_with_pretrained_language_models", "original_pdf": "/attachment/5dbefc43f37cf73dbcb6ad14c3b31b99748296fa.pdf", "_bibtex": "@misc{\naraci2020finbert,\ntitle={{\\{}FINBERT{\\}}:  {\\{}FINANCIAL{\\}} {\\{}SENTIMENT{\\}} {\\{}ANALYSIS{\\}}   {\\{}WITH{\\}} {\\{}PRE{\\}}-{\\{}TRAINED{\\}} {\\{}LANGUAGE{\\}} {\\{}MODELS{\\}}},\nauthor={Dogu Araci and Zulkuf Genc},\nyear={2020},\nurl={https://openreview.net/forum?id=HylznxrYDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HylznxrYDr", "replyto": "HylznxrYDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2529/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2529/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574943878244, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2529/Reviewers"], "noninvitees": [], "tcdate": 1570237721562, "tmdate": 1574943878257, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2529/-/Official_Review"}}}], "count": 6}