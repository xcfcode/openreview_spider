{"notes": [{"id": "H1e7g4edw4", "original": "rkefxNeOwE", "number": 15, "cdate": 1552577514990, "ddate": null, "tcdate": 1552577514990, "tmdate": 1562082108072, "tddate": null, "forum": "H1e7g4edw4", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "Improved Self-Supervised Deep Image Denoising", "authors": ["Samuli Laine", "Jaakko Lehtinen", "Timo Aila"], "authorids": ["slaine@nvidia.com", "jlehtinen@nvidia.com", "taila@nvidia.com"], "keywords": ["denoising", "self-supervised learning"], "TL;DR": "We learn high-quality denoising using only single instances of corrupted images as training data.", "abstract": "We describe techniques for training high-quality image denoising models that require only single instances of corrupted images as training data. Inspired by a recent technique that removes the need for supervision through image pairs by employing networks with a \"blind spot\" in the receptive field, we address two of its  shortcomings: inefficient training and poor final denoising performance. This is achieved through a novel blind-spot convolutional network architecture that allows efficient self-supervised training, as well as application of Bayesian distribution prediction on output colors. Together, they bring the self-supervised model on par with fully supervised deep learning techniques in terms of both quality and training speed in the case of i.i.d. Gaussian noise.", "pdf": "/pdf/4c606e80eab4280b6b9385407c594d04b33ab091.pdf", "paperhash": "laine|improved_selfsupervised_deep_image_denoising"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "ICLR.cc/2019/Workshop/LLD"}, {"id": "HygkmNAPKV", "original": null, "number": 1, "cdate": 1554666519325, "ddate": null, "tcdate": 1554666519325, "tmdate": 1555512017555, "tddate": null, "forum": "H1e7g4edw4", "replyto": "H1e7g4edw4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper15/Official_Review", "content": {"title": "Interesting method that is well-described; additional experiments could strengthen the paper", "review": "Paper Summary:\nThe authors present a method by which a denoising network can be trained using only examples of single noisy images.  The technique relies on idea of blind-spot networks, where the center pixel is eliminated from the receptive field, and reasonably strong statistical assumptions about the noise profile.  The authors define a network architecture based on a directional CNN applied to four rotations of the same image, with the receptive field of each restricted to a half-plane (just excluding the center row/column), which is then combined via a set of 1-D convolutions.  The network is then optimized to learn the parameters of a multivariate Gaussian distribution describing the mean and covariance matrix characterizing each pixel value.  Using the assumption of additive Gaussian noise that is IID between the pixels, these parameters are used in a MAP estimation procedure at test time to arrive at the denoised value.  Empirical performance on several datasets appears promising.\n\nQuality (Pros):\nThe technical content of the paper represents an interesting approach to the denoising problem, which draws heavy inspiration from the recent Noise2Void technique.  Proposed improvements over this previous technique include (1) a more efficiently trainable network architecture (2) utilization of a Bayesian modeling approach and (3) integration of information from the center pixel at test time.  The network architecture itself is adequately described in Section 2, and the design choices seem reasonable.  Given the length requirements of the paper, it is reasonable that ablations were not performed on network design, but the lack of quantitative training efficiency comparisons to the Noise2Void technique limits this aspect of the contribution.  The Bayesian training approach seems a natural fit for this type of denoising problem, where the noise in an image is characterized by a probability distribution that is local to the pixel in question; of course, the assumption the the noise is additive, Gaussian, and IID amongst pixels is strong, but the relatively straightforward MAP estimation procedure these assumptions enable is a strength of the proposed approach.  Finally, integration of integration from the center pixel at test time, but not train time, is an important result of this modeling approach.\n\nOverall, the paper presents an interesting technique that contains several distinct improvements over previous approaches, and acknowledges that these are applicable only under strong statistical assumptions.  The performance experiments appear well-posed to assess how the proposed technique compares to appropriate baselines (Noise2Void, Noise2Noise, Noise2Clean), but comparison to the most similar baseline (Noise2Void) is only presented for one dataset.  Though these results appear compelling, the paper could be improved by adding the Noise2Void numbers for other tested datasets.\n\nClarity\nThe paper is clearly written, and at an appropriate level of detail.\n\nSignificance\nIn addition to suggesting the potential for improved image denoising results using only single noisy images for training, this paper presents an interesting application of Bayesian modeling approaches for denoising that may inspire future work that yields similar results without the strong statistical assumptions currently imposed on the noise distribution.\n\nLimitations (Cons)\nCurrent limitations of this work are as follows:\n(1) Lack of experiments quantitatively demonstrating training efficiency relative to Noise2Void\n(2) Lack of experiments demonstrating comparison to Noise2Void on any dataset but BSD68\n(3) No description of the various datasets in Table 1 is given; this would be helpful\n(4) Strong statistical assumptions required on the noise distributions -- to be clear, this is less a limitation of the authors\u2019 analysis, but rather of the setting they chose to analyze; in particular, the assumption that all images are characterized by additive Gaussian noise with the same standard deviation, and that this standard deviation is known, may be limiting in practice\n(5) It would be instructive to demonstrate how performance of this method compares to others if statistical assumptions on the noise distribution are violated.\n", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper15/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper15/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improved Self-Supervised Deep Image Denoising", "authors": ["Samuli Laine", "Jaakko Lehtinen", "Timo Aila"], "authorids": ["slaine@nvidia.com", "jlehtinen@nvidia.com", "taila@nvidia.com"], "keywords": ["denoising", "self-supervised learning"], "TL;DR": "We learn high-quality denoising using only single instances of corrupted images as training data.", "abstract": "We describe techniques for training high-quality image denoising models that require only single instances of corrupted images as training data. Inspired by a recent technique that removes the need for supervision through image pairs by employing networks with a \"blind spot\" in the receptive field, we address two of its  shortcomings: inefficient training and poor final denoising performance. This is achieved through a novel blind-spot convolutional network architecture that allows efficient self-supervised training, as well as application of Bayesian distribution prediction on output colors. Together, they bring the self-supervised model on par with fully supervised deep learning techniques in terms of both quality and training speed in the case of i.i.d. Gaussian noise.", "pdf": "/pdf/4c606e80eab4280b6b9385407c594d04b33ab091.pdf", "paperhash": "laine|improved_selfsupervised_deep_image_denoising"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper15/Official_Review", "cdate": 1553713419918, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "H1e7g4edw4", "replyto": "H1e7g4edw4", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper15/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper15/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713419918, "tmdate": 1555511817681, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper15/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "rJepWPJ9t4", "original": null, "number": 2, "cdate": 1554802437350, "ddate": null, "tcdate": 1554802437350, "tmdate": 1555511881215, "tddate": null, "forum": "H1e7g4edw4", "replyto": "H1e7g4edw4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper15/Official_Review", "content": {"title": "An interesting architecture and training technique for self-supervised denoising", "review": "The authors propose techniques for training image denoising models without supervision, using only corrupted images and seeing each corrupted image once.\n\nPositives:\n- Interesting blind-spot network architecture with \"4-directional\" reading head and shared weights;\n- The Bayesian training is also a nice contribution, and proves to be important in the evaluation;\n- Concisely written and straight to the point\n\nRemarks & questions:\na) One extra baseline I am curious of: one could train N2N under the same constraint of using each image once using extra synthetic noise. Given a corrupted image, one can add extra corruption to obtain copies of it with different noise levels, and this could be enough supervision to train N2N to reasonable accuracy. It would be an interesting additional baseline, since it would use the same constraint as your work.\nb) Inference speed: can you compare the inference speed between your network and other baselines e.g. N2N?\nc) It seems to me that the datasets used in evaluation have standard image artifacts: JPEG, scale, noise... This makes the problematic of designing methods for seeing each image once a bit artificial because N2N is already well suited to the task. I wonder if one could showcase the benefits of the method on datasets with a special type of artifacts, e.g. medical imagery or hyperspectral data.\n\nOverall I think the paper is a worthwhile contribution to the workshop.", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper15/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper15/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improved Self-Supervised Deep Image Denoising", "authors": ["Samuli Laine", "Jaakko Lehtinen", "Timo Aila"], "authorids": ["slaine@nvidia.com", "jlehtinen@nvidia.com", "taila@nvidia.com"], "keywords": ["denoising", "self-supervised learning"], "TL;DR": "We learn high-quality denoising using only single instances of corrupted images as training data.", "abstract": "We describe techniques for training high-quality image denoising models that require only single instances of corrupted images as training data. Inspired by a recent technique that removes the need for supervision through image pairs by employing networks with a \"blind spot\" in the receptive field, we address two of its  shortcomings: inefficient training and poor final denoising performance. This is achieved through a novel blind-spot convolutional network architecture that allows efficient self-supervised training, as well as application of Bayesian distribution prediction on output colors. Together, they bring the self-supervised model on par with fully supervised deep learning techniques in terms of both quality and training speed in the case of i.i.d. Gaussian noise.", "pdf": "/pdf/4c606e80eab4280b6b9385407c594d04b33ab091.pdf", "paperhash": "laine|improved_selfsupervised_deep_image_denoising"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper15/Official_Review", "cdate": 1553713419918, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "H1e7g4edw4", "replyto": "H1e7g4edw4", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper15/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper15/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713419918, "tmdate": 1555511817681, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper15/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "HkeALwG9KN", "original": null, "number": 1, "cdate": 1554814805744, "ddate": null, "tcdate": 1554814805744, "tmdate": 1555510984038, "tddate": null, "forum": "H1e7g4edw4", "replyto": "H1e7g4edw4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper15/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Improved Self-Supervised Deep Image Denoising", "authors": ["Samuli Laine", "Jaakko Lehtinen", "Timo Aila"], "authorids": ["slaine@nvidia.com", "jlehtinen@nvidia.com", "taila@nvidia.com"], "keywords": ["denoising", "self-supervised learning"], "TL;DR": "We learn high-quality denoising using only single instances of corrupted images as training data.", "abstract": "We describe techniques for training high-quality image denoising models that require only single instances of corrupted images as training data. Inspired by a recent technique that removes the need for supervision through image pairs by employing networks with a \"blind spot\" in the receptive field, we address two of its  shortcomings: inefficient training and poor final denoising performance. This is achieved through a novel blind-spot convolutional network architecture that allows efficient self-supervised training, as well as application of Bayesian distribution prediction on output colors. Together, they bring the self-supervised model on par with fully supervised deep learning techniques in terms of both quality and training speed in the case of i.i.d. Gaussian noise.", "pdf": "/pdf/4c606e80eab4280b6b9385407c594d04b33ab091.pdf", "paperhash": "laine|improved_selfsupervised_deep_image_denoising"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper15/Decision", "cdate": 1554736068865, "reply": {"forum": "H1e7g4edw4", "replyto": "H1e7g4edw4", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736068865, "tmdate": 1555510969828, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 4}