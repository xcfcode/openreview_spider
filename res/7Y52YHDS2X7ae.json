{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1392853980000, "tcdate": 1392853980000, "number": 5, "id": "R2JU265o6CRLV", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "7Y52YHDS2X7ae", "replyto": "7Y52YHDS2X7ae", "signatures": ["Mohammad Norouzi"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "We thank reviewers for their valuable feedback. We will prepare a new version of the paper shortly to address your comments.\r\n\r\nR1: ... concern regarding the results which either indicates (i) the implementation differs from the paper description, (ii) I missed something ...\r\nR2: ... why the performance of ConSE(1) in hits@1 is not 0 in the +1K setting ...\r\nSumit Chopra: ... ConSE(1) is exactly the same as Softmax baseline ... What's going on?\r\n\r\nThis is a good point related to a technical detail of our implementation. In the Imagenet experiments, following the experimental setup of the DeViSE model, there is not a one-to-one correspondence between the class labels and the word embedding vectors. Rather, because of the way the Imagenet synsets are defined, each class label is associated with several synonym terms, and hence several word vectors. When we perform the mapping from the softmax scores to the continuous embedding space, we average the word vectors associated with each class label, and then linearly combine the average vectors according to the softmax scores. However, when we rank the word vectors to find the k most likely class labels, we search over individual word vectors, without any averaging of the synonym words. Thus, the ConSE(1) might produce an average embedding, which is not the closest vector to any of the word vectors corresponding to the original class label, and this results in a slight difference in the hit@1 scores for ConSE(1) and the softmax baseline in the +1K setting. While other alternatives exist for this part of the algorithm, we intentionally kept the ranking procedure exactly the same as the DeViSE model to perform a direct comparison with DeViSE. We will include this description in the new version of the paper.\r\n\r\nSumit Chopra: The evaluation based on excluding and including the 1K classes ... a bit artificial. ... one should have the classes from training set as part of your evaluation classes. And that is the true performance of ConSE(*).\r\n\r\nThe separation of the training and unseen classes enables for a more detailed analysis of the results to obtain better insights into the behavior of the algorithm. Based on these results we concluded that our model overfits to the training class labels, and we need some better regularization mechanism to overcome this behavior. We believe that one can exploit better methods for distinguishing between the 1K training labels and the zero-shot labels, one of which was mentioned in the conclusion. Alternatively, one can collect training labels for a category called 'none-of-training', which includes instances from all categories except the 1K training classes (not reflecting their specific labels). Using examples from this additional category, one can re-train an additional node for the softmax layer to detect examples of the none-of-training category. This helps deciding whether we should perform a zero-shot prediction or we should stick to the original softmax predictions. That said, the experimental results that exclude the 1K training classes report the accuracy that one can hope for in the best case scenario, i.e., when the zero-shot labels can be perfectly distinguished from the 1K training labels. Moreover, these results suggest that our naive way of combining the 1K training labels with the zero-shot labels, i.e., treating them as if they are the same hurts the performance, and it is important to implement a better method for detecting the zero-shot labels.\r\n\r\nR2: ... it is claimed several times that ConSE can be used with any semantic embeddings. Is this really true? ...\r\nSumit Chopra: ... simple weighted averages of the embeddings of a collection of words is a by-product of the linear model used to train the word embeddings ...\r\n\r\nWe do not argue that any word embedding model used within our framework is equally effective. However, our observation is that we did not fine-tune our algorithm for any specific word embedding representation. This suggests that our algorithm is relatively robust to the specific choice of the word embedding representation, and in fact, we obtained some promising results on the use of a very different word embedding model within exactly the same model. That said, we agree that the topology of the manifold of the word embedding vectors matters, and some word embedding representations might be more suitable for our framework than others. We will reword the paper to clarify that we claim some degree of robustness, and not invariance against the choice of the language model.\r\n\r\nR2: ... how important is it to normalize the T top probabilities of the combination? ...\r\n\r\nIt is not important to normalize the top T probabilities. In our model, all of the word embedding vectors are unit-norm, and we use cosine similarity between the ConSE's prediction and the unit-norm word vectors for k-nearest neighbor ranking. Thus, even if the ConSE's prediction is not normalized, the ranking of the word vectors does not change. We agree that using the norm of the ConSE's prediction, one can come up with better ways to address the separation of training and unseen classes, but we keep this as a future work.\r\n\r\nR2: ... how significant are the results. ... perhaps ConSE outperforms DeVISE, but performance are very low ... Can we consider that such poor performance is still actually meaningful and useful in some way?\r\n\r\nAlthough the performances do not look great (5% on hits@10), they are somewhat much better in reality. Humans are robust to minor mistakes between very similar concepts (e.g., multiple types of sea lion, or types of hamster), but our flat metric is not good at rating minor mistakes higher than major errors. If the model predicts 'Australian sea lion' but the correct label is 'Steller sea lion', then we get a score of zero according to the flat metric. Figure 1 shows some actual predictions of the model, which demonstrates that even when we fail to return the right answer (most of the time), we often return very reasonable labels. So, if the question is whether this is useful for applications, the answer is clearly we are moving in that direction."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Zero-Shot Learning by Convex Combination of Semantic Embeddings", "decision": "submitted, no decision", "abstract": "Several recent publications have proposed methods for mapping images into continuous semantic embedding spaces. In some cases the semantic embedding space is trained jointly with the image transformation, while in other cases the semantic embedding space is established independently by a separate natural language processing task, and then the image transformation into that space is learned in a second stage. Proponents of these image embedding systems have stressed their advantages over the traditional n-way classification framing of image understanding, particularly in terms of the promise of zero-shot learning -- the ability to correctly annotate images of previously unseen object categories. Here we propose a simple method for constructing an image embedding system from any existing n-way image classifier and any semantic word embedding model, which contains the n class labels in its vocabulary. Our method maps images into the semantic embedding space via convex combination of the class label embedding vectors, and requires no additional learning. We show that this simple and direct method confers many of the advantages associated with more complex image embedding schemes, and indeed outperforms state of the art methods on the ImageNet zero-shot learning task.", "pdf": "https://arxiv.org/abs/1312.5650", "paperhash": "mikolov|zeroshot_learning_by_convex_combination_of_semantic_embeddings", "keywords": [], "conflicts": [], "authors": ["Tomas Mikolov", "Andrea Frome", "Samy Bengio", "Jonathon Shlens", "Yoram Singer", "Greg S. Corrado", "Jeffrey Dean", "Mohammad Norouzi"], "authorids": ["tmikolov@google.com", "afrome@google.com", "bengio@gmail.com", "shlens@google.com", "singer@google.com", "gcorrado@google.com", "jeff@google.com", "mohammad.n@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392558540000, "tcdate": 1392558540000, "number": 4, "id": "LyRby_-q2onfK", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "7Y52YHDS2X7ae", "replyto": "7Y52YHDS2X7ae", "signatures": ["anonymous reviewer 8598"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Zero-Shot Learning by Convex Combination of Semantic Embeddings", "review": "This paper presents a simple but really neat idea of combining semantic word vectors trained on text with a softmax classifier's output.\r\nInstead of taking the softmax output as is, it uses its probabilities to weigh the semantic vectors of all the classes which allows the model to assign labels that were not present in the training data.\r\n\r\nThe results are not always better than previous work from the group but in many settings they are.\r\n\r\nSimple but overall very cool idea."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Zero-Shot Learning by Convex Combination of Semantic Embeddings", "decision": "submitted, no decision", "abstract": "Several recent publications have proposed methods for mapping images into continuous semantic embedding spaces. In some cases the semantic embedding space is trained jointly with the image transformation, while in other cases the semantic embedding space is established independently by a separate natural language processing task, and then the image transformation into that space is learned in a second stage. Proponents of these image embedding systems have stressed their advantages over the traditional n-way classification framing of image understanding, particularly in terms of the promise of zero-shot learning -- the ability to correctly annotate images of previously unseen object categories. Here we propose a simple method for constructing an image embedding system from any existing n-way image classifier and any semantic word embedding model, which contains the n class labels in its vocabulary. Our method maps images into the semantic embedding space via convex combination of the class label embedding vectors, and requires no additional learning. We show that this simple and direct method confers many of the advantages associated with more complex image embedding schemes, and indeed outperforms state of the art methods on the ImageNet zero-shot learning task.", "pdf": "https://arxiv.org/abs/1312.5650", "paperhash": "mikolov|zeroshot_learning_by_convex_combination_of_semantic_embeddings", "keywords": [], "conflicts": [], "authors": ["Tomas Mikolov", "Andrea Frome", "Samy Bengio", "Jonathon Shlens", "Yoram Singer", "Greg S. Corrado", "Jeffrey Dean", "Mohammad Norouzi"], "authorids": ["tmikolov@google.com", "afrome@google.com", "bengio@gmail.com", "shlens@google.com", "singer@google.com", "gcorrado@google.com", "jeff@google.com", "mohammad.n@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392310800000, "tcdate": 1392310800000, "number": 3, "id": "KkSQkxO6x4jcH", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "7Y52YHDS2X7ae", "replyto": "7Y52YHDS2X7ae", "signatures": ["anonymous reviewer 06d4"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Zero-Shot Learning by Convex Combination of Semantic Embeddings", "review": "This paper proposes a method for performing zero-shot learning of an image labeling system. The proposed method is very simple and yet general and efficient: it consistently outperforms the DeVISE system presented recently on the ImageNet benchmark.\r\n\r\nThe paper is nicely written and ConSE is actually so simple that the paper is not too complicated too understand anyway. But I have no problem accepting a paper even if the method is simple, if it proves to be efficient. ConSE appears to be but some questions/comments remain.\r\n\r\nThe method is simple so I would have expected more studies/experiments/discussions to explain its good performance. A simple intuition is given is Section 4.1 with the (funny) 'liger' example. But this could perhaps detailed more. For instance:\r\n\r\n- it is claimed several times that ConSE can be used with any semantic embeddings. Is this really true? According to the 'liger' example, ConSE works because s(liger) ~ 0.5*s(tiger) + 0.5*s(lion). It is true for the skip-grams embeddings, since it has been shown that such linear relationships (and translations) were existing among those embeddings. I'm not sure that one can claim that all word embeddings work the same way and have such linear relationships. Without such property within the embedding space, would ConSE still perform well?\r\n\r\n- how important is it to normalize the T top probabilities of the combination? Doing so, they are implicitly calibrated on the train labels, whereas one would like better to calibrate them on train + test labels. In the conclusion, there is an interesting comment regarding the norm of the convex embedding combination, especially when probabilities are not normalized, indicating that it gives a measure of the confidence of the prediction. I feel like the main point of the paper might be there but the paper does not exploit it well. Basically, one of the most difficult problem in zero-shot learning is to detect whether to choose a label among training labels or test labels (before even trying to choose the right one). That's why for me the most interesting (and realistic) experiments of the paper are when train labels are also added to the candidate label sets (+1K setting). These show that the bias towards training labels is big, especially at top-1 (this is not surprising). The intuition about the norm of the convex combination and its connection to confidence seems to be promising to soften this bias, but this is just sketched unfortunately.\r\n\r\nI wonder why the performance of ConSE(1) in hits@1 is not 0 in the +1K setting. If I understand correctly, the output of ConsE(1) is simply the embedding of the top-predicted train label and hence, the closest according to the cosine distance should be this very train label. Since, no test example is labeled with a train label, it should always be a mistake.\r\n\r\nOn a more general point, it could also be discussed how significant are the results. I mean, perhaps ConSE outperforms DeVISE, but performance are very low (5% of hits@10 in the most general setting). Can we consider that such poor performance is still actually meaningful and useful in some way?\r\n\r\nMinor:\r\n- Tables 1 & 4 are in %, whereas tables 2 & 3. It should be consistent."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Zero-Shot Learning by Convex Combination of Semantic Embeddings", "decision": "submitted, no decision", "abstract": "Several recent publications have proposed methods for mapping images into continuous semantic embedding spaces. In some cases the semantic embedding space is trained jointly with the image transformation, while in other cases the semantic embedding space is established independently by a separate natural language processing task, and then the image transformation into that space is learned in a second stage. Proponents of these image embedding systems have stressed their advantages over the traditional n-way classification framing of image understanding, particularly in terms of the promise of zero-shot learning -- the ability to correctly annotate images of previously unseen object categories. Here we propose a simple method for constructing an image embedding system from any existing n-way image classifier and any semantic word embedding model, which contains the n class labels in its vocabulary. Our method maps images into the semantic embedding space via convex combination of the class label embedding vectors, and requires no additional learning. We show that this simple and direct method confers many of the advantages associated with more complex image embedding schemes, and indeed outperforms state of the art methods on the ImageNet zero-shot learning task.", "pdf": "https://arxiv.org/abs/1312.5650", "paperhash": "mikolov|zeroshot_learning_by_convex_combination_of_semantic_embeddings", "keywords": [], "conflicts": [], "authors": ["Tomas Mikolov", "Andrea Frome", "Samy Bengio", "Jonathon Shlens", "Yoram Singer", "Greg S. Corrado", "Jeffrey Dean", "Mohammad Norouzi"], "authorids": ["tmikolov@google.com", "afrome@google.com", "bengio@gmail.com", "shlens@google.com", "singer@google.com", "gcorrado@google.com", "jeff@google.com", "mohammad.n@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391734380000, "tcdate": 1391734380000, "number": 2, "id": "FWp1FD6f1Qa45", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "7Y52YHDS2X7ae", "replyto": "7Y52YHDS2X7ae", "signatures": ["Sumit Chopra"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "A very interesting paper that proposes an extremely simple technique of mapping words and images to the same latent space for facilitating zero-shot learning. The paper shows how such a simple technique beats the recently proposed and more complicated DeVISE model. A few minor points though: \r\n\r\n1. As discussed by the above reader, ConSE(1) is exactly the same as Softmax baseline, especially when we include the 1K classes from the training set. The  results table seem to suggest something else. What's going on? \r\n\r\n2. The evaluation based on excluding and including the 1K classes from the training set seems to be a bit artificial. In the real deployment scenario one does not have access to this information and hence by default one should have the classes from training set as part of your evaluation classes. And that is the true performance of ConSE(*). \r\n\r\n3. Lastly, I don't really buy the author's argument that the proposed model is general and independent of how the word embeddings or the image features are generated. While I agree with the image part (that the model is independent of how the image features are generated), the same is not true for the word embeddings. My sense is that one is able to meaningfully take simple weighted averages of the embeddings of a collection of words is a by-product of the linear model used to train the word embeddings. If one was to use a non-linear model (NN for instance) so that the embeddings lie on a non-linear manifold, things might not work as well. Any thoughts? \r\n\r\nOtherwise, a very nice paper. Well written too."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Zero-Shot Learning by Convex Combination of Semantic Embeddings", "decision": "submitted, no decision", "abstract": "Several recent publications have proposed methods for mapping images into continuous semantic embedding spaces. In some cases the semantic embedding space is trained jointly with the image transformation, while in other cases the semantic embedding space is established independently by a separate natural language processing task, and then the image transformation into that space is learned in a second stage. Proponents of these image embedding systems have stressed their advantages over the traditional n-way classification framing of image understanding, particularly in terms of the promise of zero-shot learning -- the ability to correctly annotate images of previously unseen object categories. Here we propose a simple method for constructing an image embedding system from any existing n-way image classifier and any semantic word embedding model, which contains the n class labels in its vocabulary. Our method maps images into the semantic embedding space via convex combination of the class label embedding vectors, and requires no additional learning. We show that this simple and direct method confers many of the advantages associated with more complex image embedding schemes, and indeed outperforms state of the art methods on the ImageNet zero-shot learning task.", "pdf": "https://arxiv.org/abs/1312.5650", "paperhash": "mikolov|zeroshot_learning_by_convex_combination_of_semantic_embeddings", "keywords": [], "conflicts": [], "authors": ["Tomas Mikolov", "Andrea Frome", "Samy Bengio", "Jonathon Shlens", "Yoram Singer", "Greg S. Corrado", "Jeffrey Dean", "Mohammad Norouzi"], "authorids": ["tmikolov@google.com", "afrome@google.com", "bengio@gmail.com", "shlens@google.com", "singer@google.com", "gcorrado@google.com", "jeff@google.com", "mohammad.n@gmail.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391687340000, "tcdate": 1391687340000, "number": 1, "id": "44qhlhKQh31nZ", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "7Y52YHDS2X7ae", "replyto": "7Y52YHDS2X7ae", "signatures": ["anonymous reviewer 936e"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Zero-Shot Learning by Convex Combination of Semantic Embeddings", "review": "This paper addresses the problem of zero shot learning for image classification. Like in their recent NIPS2013 work, the authors relies on an embedding representation of the classes inferred from a language model. Their prediction scheme first predicts an embedding vector which linearly combines the vectors representing the n-best prediction among the training classes and  then looks for the nearest neighbors of the predicted vector among the test class embedding.\r\n\r\nThe paper reads well and appropriate reference to related work is given. The proposed approach is very simple and yet improve over the DEVISE classifier. I have however a concern regarding the results which either indicates (i) the implementation differs from the paper description, (ii) I missed something. It seems to me that hit@1 for ConSE(1) predicts the embedding of the best prediction of the 'Softmax baseline' over the 1,000 training classes, i.e. f(x) = s(y_0(x,t)) and outputs its nearest neighbor in the search space. When the search space include the training classes, it should output y_0(x,t). This implies that in table 4, the first column should contain hit@1 for ConSE(1) = 55.6. Similarly, the result of hit@1 for ConSE(1) in the (+1K) results should be 0. This is not the case, could you explain/correct?\r\n\r\nApart from this technicality, this is a good paper. The approach is simple and improves the state of the art. It might be further improved by a deeper analysis of the errors, possibly grouping them according by type of classes, looking at the accuracy of the convnet on the classes related to the labels or the quality of the corresponding text embeddings."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Zero-Shot Learning by Convex Combination of Semantic Embeddings", "decision": "submitted, no decision", "abstract": "Several recent publications have proposed methods for mapping images into continuous semantic embedding spaces. In some cases the semantic embedding space is trained jointly with the image transformation, while in other cases the semantic embedding space is established independently by a separate natural language processing task, and then the image transformation into that space is learned in a second stage. Proponents of these image embedding systems have stressed their advantages over the traditional n-way classification framing of image understanding, particularly in terms of the promise of zero-shot learning -- the ability to correctly annotate images of previously unseen object categories. Here we propose a simple method for constructing an image embedding system from any existing n-way image classifier and any semantic word embedding model, which contains the n class labels in its vocabulary. Our method maps images into the semantic embedding space via convex combination of the class label embedding vectors, and requires no additional learning. We show that this simple and direct method confers many of the advantages associated with more complex image embedding schemes, and indeed outperforms state of the art methods on the ImageNet zero-shot learning task.", "pdf": "https://arxiv.org/abs/1312.5650", "paperhash": "mikolov|zeroshot_learning_by_convex_combination_of_semantic_embeddings", "keywords": [], "conflicts": [], "authors": ["Tomas Mikolov", "Andrea Frome", "Samy Bengio", "Jonathon Shlens", "Yoram Singer", "Greg S. Corrado", "Jeffrey Dean", "Mohammad Norouzi"], "authorids": ["tmikolov@google.com", "afrome@google.com", "bengio@gmail.com", "shlens@google.com", "singer@google.com", "gcorrado@google.com", "jeff@google.com", "mohammad.n@gmail.com"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1387873860000, "tcdate": 1387873860000, "number": 47, "id": "7Y52YHDS2X7ae", "invitation": "ICLR.cc/2014/conference/-/submission", "forum": "7Y52YHDS2X7ae", "signatures": ["tmikolov@google.com"], "readers": ["everyone"], "content": {"title": "Zero-Shot Learning by Convex Combination of Semantic Embeddings", "decision": "submitted, no decision", "abstract": "Several recent publications have proposed methods for mapping images into continuous semantic embedding spaces. In some cases the semantic embedding space is trained jointly with the image transformation, while in other cases the semantic embedding space is established independently by a separate natural language processing task, and then the image transformation into that space is learned in a second stage. Proponents of these image embedding systems have stressed their advantages over the traditional n-way classification framing of image understanding, particularly in terms of the promise of zero-shot learning -- the ability to correctly annotate images of previously unseen object categories. Here we propose a simple method for constructing an image embedding system from any existing n-way image classifier and any semantic word embedding model, which contains the n class labels in its vocabulary. Our method maps images into the semantic embedding space via convex combination of the class label embedding vectors, and requires no additional learning. We show that this simple and direct method confers many of the advantages associated with more complex image embedding schemes, and indeed outperforms state of the art methods on the ImageNet zero-shot learning task.", "pdf": "https://arxiv.org/abs/1312.5650", "paperhash": "mikolov|zeroshot_learning_by_convex_combination_of_semantic_embeddings", "keywords": [], "conflicts": [], "authors": ["Tomas Mikolov", "Andrea Frome", "Samy Bengio", "Jonathon Shlens", "Yoram Singer", "Greg S. Corrado", "Jeffrey Dean", "Mohammad Norouzi"], "authorids": ["tmikolov@google.com", "afrome@google.com", "bengio@gmail.com", "shlens@google.com", "singer@google.com", "gcorrado@google.com", "jeff@google.com", "mohammad.n@gmail.com"]}, "writers": [], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496674357195, "id": "ICLR.cc/2014/conference/-/submission", "writers": ["ICLR.cc/2014"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717, "cdate": 1496674357195}}}], "count": 6}