{"notes": [{"id": "UAAJMiVjTY_", "original": "pQ9_HyZoTN0s", "number": 1133, "cdate": 1601308127397, "ddate": null, "tcdate": 1601308127397, "tmdate": 1614985629427, "tddate": null, "forum": "UAAJMiVjTY_", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Abductive Knowledge Induction from Raw Data", "authorids": ["~Wang-Zhou_Dai2", "~Stephen_Muggleton1"], "authors": ["Wang-Zhou Dai", "Stephen Muggleton"], "keywords": ["Neural-Symbolic Model", "Inductive Logic Programming", "Abduction"], "abstract": "For many reasoning-heavy tasks, it is challenging to find an appropriate end-to-end differentiable approximation to domain-specific inference mechanisms. Neural-Symbolic (NeSy) AI divides the end-to-end pipeline into neural perception and symbolic reasoning, which can directly exploit general domain knowledge such as algorithms and logic rules. However, it suffers from the exponential computational complexity caused by the interface between the two components, where the neural model lacks direct supervision, and the symbolic model lacks accurate input facts. As a result, they usually focus on learning the neural model with a sound and complete symbolic knowledge base while avoiding a crucial problem: where does the knowledge come from? In this paper, we present Abductive Meta-Interpretive Learning ($Meta_{Abd}$), which unites abduction and induction to learn perceptual neural network and first-order logic theories simultaneously from raw data. Given the same amount of domain knowledge, we demonstrate that $Meta_{Abd}$ not only outperforms the compared end-to-end models in predictive accuracy and data efficiency but also induces logic programs that can be re-used as background knowledge in subsequent learning tasks. To the best of our knowledge, $Meta_{Abd}$ is the first system that can jointly learn neural networks and recursive first-order logic theories with predicate invention.", "one-sentence_summary": "We propose an approach combining abduction and induction to jointly learn neural models and recursive first-order logic programs with predicate invention.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dai|abductive_knowledge_induction_from_raw_data", "supplementary_material": "/attachment/e23429030deac6f4e92abcb9aeb20a95e6e77e45.zip", "pdf": "/pdf/3a7f97a5938549dfd0fa5219a365aa126f660751.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H_yDVmut58", "_bibtex": "@misc{\ndai2021abductive,\ntitle={Abductive Knowledge Induction from Raw Data},\nauthor={Wang-Zhou Dai and Stephen Muggleton},\nyear={2021},\nurl={https://openreview.net/forum?id=UAAJMiVjTY_}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 17, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "bvkDQ3tJHA", "original": null, "number": 1, "cdate": 1610040530913, "ddate": null, "tcdate": 1610040530913, "tmdate": 1610474140464, "tddate": null, "forum": "UAAJMiVjTY_", "replyto": "UAAJMiVjTY_", "invitation": "ICLR.cc/2021/Conference/Paper1133/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The paper addresses the difficult problem of combining ILP in a meta-interpretive framework with noisy inputs from a neural system.   The essential idea is to use MIL to \"efficiently\" search for constraints on the neural outputs (eg z1 + z2 + z3 = 7, or z2< z3) as well as logic programs, with a score related to program complexity as well as probability of the best constraint-satisfying neural outputs.  It is interesting work for the right audience but it's clear from the reviews that the presentation was difficult for ICLR readers, even ones with appropriate background. \n\nSome potential weaknesses of the approach include:\n\n1 - it's unclear how scalable the MIL framework is - presumably the intrinsic difficultly of the search means that programs and constraint sets must be small\n\n2 - it's unclear how general the approach is beyond the digits-as-separate-inputs setting of the two experimental studies, and its unclear how accurate the perceptual layer needs to be - MNIST obviously being an example of a case where there is little noise with a modern classifier.\n\n3 - it's unclear how constraints can in general be used to backprop any information to the underlying neural system, and without this the joint training seems to be quite limited.\n\nOverall the paper is judged as inappropriate for ICLR."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Abductive Knowledge Induction from Raw Data", "authorids": ["~Wang-Zhou_Dai2", "~Stephen_Muggleton1"], "authors": ["Wang-Zhou Dai", "Stephen Muggleton"], "keywords": ["Neural-Symbolic Model", "Inductive Logic Programming", "Abduction"], "abstract": "For many reasoning-heavy tasks, it is challenging to find an appropriate end-to-end differentiable approximation to domain-specific inference mechanisms. Neural-Symbolic (NeSy) AI divides the end-to-end pipeline into neural perception and symbolic reasoning, which can directly exploit general domain knowledge such as algorithms and logic rules. However, it suffers from the exponential computational complexity caused by the interface between the two components, where the neural model lacks direct supervision, and the symbolic model lacks accurate input facts. As a result, they usually focus on learning the neural model with a sound and complete symbolic knowledge base while avoiding a crucial problem: where does the knowledge come from? In this paper, we present Abductive Meta-Interpretive Learning ($Meta_{Abd}$), which unites abduction and induction to learn perceptual neural network and first-order logic theories simultaneously from raw data. Given the same amount of domain knowledge, we demonstrate that $Meta_{Abd}$ not only outperforms the compared end-to-end models in predictive accuracy and data efficiency but also induces logic programs that can be re-used as background knowledge in subsequent learning tasks. To the best of our knowledge, $Meta_{Abd}$ is the first system that can jointly learn neural networks and recursive first-order logic theories with predicate invention.", "one-sentence_summary": "We propose an approach combining abduction and induction to jointly learn neural models and recursive first-order logic programs with predicate invention.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dai|abductive_knowledge_induction_from_raw_data", "supplementary_material": "/attachment/e23429030deac6f4e92abcb9aeb20a95e6e77e45.zip", "pdf": "/pdf/3a7f97a5938549dfd0fa5219a365aa126f660751.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H_yDVmut58", "_bibtex": "@misc{\ndai2021abductive,\ntitle={Abductive Knowledge Induction from Raw Data},\nauthor={Wang-Zhou Dai and Stephen Muggleton},\nyear={2021},\nurl={https://openreview.net/forum?id=UAAJMiVjTY_}\n}"}, "tags": [], "invitation": {"reply": {"forum": "UAAJMiVjTY_", "replyto": "UAAJMiVjTY_", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040530899, "tmdate": 1610474140449, "id": "ICLR.cc/2021/Conference/Paper1133/-/Decision"}}}, {"id": "Za7kj-HW5Lb", "original": null, "number": 13, "cdate": 1606201092937, "ddate": null, "tcdate": 1606201092937, "tmdate": 1606201830901, "tddate": null, "forum": "UAAJMiVjTY_", "replyto": "ZrgE83Mvb0q", "invitation": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment", "content": {"title": "Thanks for the Clarifications", "comment": "Thank you for the clarifications. My biggest concern about this paper remains to be missing comparison with other related works.\n\nIn general, combining rule learning and pattern recognition tools, such as deep networks have been broadly studied. The authors have presented a hybrid approach of deep nets + ILP. They are connected by an abductive reasoning layer.\nHowever, there have been other approaches in this field.\n- Partial ILP and Machine Apperception use gradient-based methods to connect deep nets learning and ILP. For Partial ILP, if you treat the inference engine as a black box, it naturally provides gradients to its input, and thus the entire system can be optimized with gradient descent.\n- Neural GPU, Neural logic machines use end-to-end neural architectures to simulate forward chaining. They can realize logic rules of certain forms.\n- Differentiable neural computer and neural programmer-interpreters use policy gradient to differentiate through non-differentiable primitive operations. \n\nAlthough many of these works have been originally tested on symbolic inputs only, or used pretrained neural networks, they can definitely be extended to image inputs. I still think that the current experimental setups do not fully demonstrate the power of the proposed methods.\n\nGiven all that, I am not willing to increase my rating to a positive one at this moment."}, "signatures": ["ICLR.cc/2021/Conference/Paper1133/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Abductive Knowledge Induction from Raw Data", "authorids": ["~Wang-Zhou_Dai2", "~Stephen_Muggleton1"], "authors": ["Wang-Zhou Dai", "Stephen Muggleton"], "keywords": ["Neural-Symbolic Model", "Inductive Logic Programming", "Abduction"], "abstract": "For many reasoning-heavy tasks, it is challenging to find an appropriate end-to-end differentiable approximation to domain-specific inference mechanisms. Neural-Symbolic (NeSy) AI divides the end-to-end pipeline into neural perception and symbolic reasoning, which can directly exploit general domain knowledge such as algorithms and logic rules. However, it suffers from the exponential computational complexity caused by the interface between the two components, where the neural model lacks direct supervision, and the symbolic model lacks accurate input facts. As a result, they usually focus on learning the neural model with a sound and complete symbolic knowledge base while avoiding a crucial problem: where does the knowledge come from? In this paper, we present Abductive Meta-Interpretive Learning ($Meta_{Abd}$), which unites abduction and induction to learn perceptual neural network and first-order logic theories simultaneously from raw data. Given the same amount of domain knowledge, we demonstrate that $Meta_{Abd}$ not only outperforms the compared end-to-end models in predictive accuracy and data efficiency but also induces logic programs that can be re-used as background knowledge in subsequent learning tasks. To the best of our knowledge, $Meta_{Abd}$ is the first system that can jointly learn neural networks and recursive first-order logic theories with predicate invention.", "one-sentence_summary": "We propose an approach combining abduction and induction to jointly learn neural models and recursive first-order logic programs with predicate invention.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dai|abductive_knowledge_induction_from_raw_data", "supplementary_material": "/attachment/e23429030deac6f4e92abcb9aeb20a95e6e77e45.zip", "pdf": "/pdf/3a7f97a5938549dfd0fa5219a365aa126f660751.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H_yDVmut58", "_bibtex": "@misc{\ndai2021abductive,\ntitle={Abductive Knowledge Induction from Raw Data},\nauthor={Wang-Zhou Dai and Stephen Muggleton},\nyear={2021},\nurl={https://openreview.net/forum?id=UAAJMiVjTY_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "UAAJMiVjTY_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1133/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1133/Authors|ICLR.cc/2021/Conference/Paper1133/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923863265, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment"}}}, {"id": "Hd84txFYpce", "original": null, "number": 12, "cdate": 1606030650417, "ddate": null, "tcdate": 1606030650417, "tmdate": 1606031133095, "tddate": null, "forum": "UAAJMiVjTY_", "replyto": "6e_mJJvwI1a", "invitation": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment", "content": {"title": "Follow-up Answers", "comment": "**Q6+:** How does Meta_abd initialize EM, and how sensitive are its results to\nthe initialization?\n\n**A6+:** Sorry for my misunderstanding.\n\nThe EM is initialized as follows:\n\n- In $Meta_{abd}$, the perceptual CNN is initialised randomly;\n- In $Meta_{abd+\\text{1-shot CNN}}$, we randomly sample one example from 0-9 to\n  pre-train the CNN as initialisation.\n  \nFor the logic rules $H$, $Meta_{abd}$ does not initialise them. They are treated as\nhidden variables together with the pseudo-labels $z$ (of the images). However,\nthe randomly initialised neural net parameter $\\theta_0$ results in a randomly\ninitialised distribution of the probabilistic facts, which will affect\nabduction score (Eq. 5) with $P(z|x,\\theta_0)$. Therefore, the estimated\nthe expectation of programs $H$ in the first epoch varies accordingly. For example,\nit may output the following hypotheses during the first round of EM in the\naccumulative sum experiments:\n\n```prolog\nf(A,B):-head(A,B).\n\nf(A,B):-tail(A,C),f(C,B).\nf(A,B):-eq(C,B).\n\nf(A,B):-add(A,C),f(C,B).\nf(A,B):-eq(A,B).\n\nf(A,B):-tail(A,C),f(C,B).\nf(A,B):-mult(A,C),eq(C,B).\n\nf(A,B):-f_1(A,C),f(C,B).\nf_1(A,B):-add(A,C),mult(C,B).\nf(A,B):-eq(A,B).\n\nf(A,B):-f_1(A,B).\nf_1(A,B):-f_2(A,C),eq(C,B).\nf_2(A,B):-mult(A,C),f_2(C,B).\nf_2(A,B):-mult(A,C),add(C,B).\n\n...\n```\n\n\n\n**Q9+:** Could you quantify the contribution, say, by removing a metarule one at\na time and examining the impact on runtime and accuracy/MAE?\n\n**A9+:** Thanks for your suggestion. As we answered in A5+, the accuracy/MAE\nwon't change when the hypothesis space defined by metarules contains the correct\nprograms (there could be multiple semantically identical programs). Otherwise,\nthe incomplete hypothesis space makes $Meta_{abd}$ fail to estimate the\nexpectation of $H\\cup z$, which causes EM to fail to converge in 100 epochs.\n\nFollowing are the time difference measured by the average number of Prolog\ninferences in each batch of $Meta_{abd}$'s abduction-induction inference in the\naccumulative sum task. The settings are as follows:\n\n- $Meta_{abd}$ contains at least one metarule, which is `P(A,B):-Q(A,B)`, i.e.,\n  calling a primitive function, it is counted as `metarule 1`;\n- The perceptual CNN is randomly initialised and un-trained, i.e., the\n  distribution of probabilistic facts is random, which is the **worst-case** for\n  abduction, so the result here is slower than the average result in Fig. 3b;\n- Choosing metarules is a subset selection problem. Following the traditions in\n  combinatorial optimisation, we report the **worst result** among all varied\n  combinations;\n- The number of Prolog inferences includes the CLP(Z) optimisation.\n  \nResults:\n- 9 metarules: 26324856 inferences in 1.571 seconds.\n- 8 metarules: 26324638 inferences in 1.567 seconds.\n- 7 metarules: 26324626 inferences in 1.567 seconds.\n- 6 metarules: 26324287 inferences in 1.527 seconds.\n- 5 metarules: 26324009 inferences in 1.528 seconds.\n- 4 metarules: 26321479 inferences in 1.521 seconds.\n- 3 metarules: 26314047 inferences in 1.521 seconds.\n- 2 metarules (under this setting, $Meta_{abd}$ is equivalent to RNNs which are\n  forced to learn a minimum recursive program): 10991735 inferences in 0.635 seconds.\n\nAs we can see, there is not much difference from 9-3 metarules (when the program\nhypothesis space is complete). However, if the users have a strong bias on the\ntarget theory and only use the relevant metarules, the search speed can be\nsignificantly improved. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1133/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Abductive Knowledge Induction from Raw Data", "authorids": ["~Wang-Zhou_Dai2", "~Stephen_Muggleton1"], "authors": ["Wang-Zhou Dai", "Stephen Muggleton"], "keywords": ["Neural-Symbolic Model", "Inductive Logic Programming", "Abduction"], "abstract": "For many reasoning-heavy tasks, it is challenging to find an appropriate end-to-end differentiable approximation to domain-specific inference mechanisms. Neural-Symbolic (NeSy) AI divides the end-to-end pipeline into neural perception and symbolic reasoning, which can directly exploit general domain knowledge such as algorithms and logic rules. However, it suffers from the exponential computational complexity caused by the interface between the two components, where the neural model lacks direct supervision, and the symbolic model lacks accurate input facts. As a result, they usually focus on learning the neural model with a sound and complete symbolic knowledge base while avoiding a crucial problem: where does the knowledge come from? In this paper, we present Abductive Meta-Interpretive Learning ($Meta_{Abd}$), which unites abduction and induction to learn perceptual neural network and first-order logic theories simultaneously from raw data. Given the same amount of domain knowledge, we demonstrate that $Meta_{Abd}$ not only outperforms the compared end-to-end models in predictive accuracy and data efficiency but also induces logic programs that can be re-used as background knowledge in subsequent learning tasks. To the best of our knowledge, $Meta_{Abd}$ is the first system that can jointly learn neural networks and recursive first-order logic theories with predicate invention.", "one-sentence_summary": "We propose an approach combining abduction and induction to jointly learn neural models and recursive first-order logic programs with predicate invention.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dai|abductive_knowledge_induction_from_raw_data", "supplementary_material": "/attachment/e23429030deac6f4e92abcb9aeb20a95e6e77e45.zip", "pdf": "/pdf/3a7f97a5938549dfd0fa5219a365aa126f660751.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H_yDVmut58", "_bibtex": "@misc{\ndai2021abductive,\ntitle={Abductive Knowledge Induction from Raw Data},\nauthor={Wang-Zhou Dai and Stephen Muggleton},\nyear={2021},\nurl={https://openreview.net/forum?id=UAAJMiVjTY_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "UAAJMiVjTY_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1133/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1133/Authors|ICLR.cc/2021/Conference/Paper1133/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923863265, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment"}}}, {"id": "DBEX4geIFF2", "original": null, "number": 11, "cdate": 1606030443843, "ddate": null, "tcdate": 1606030443843, "tmdate": 1606030692081, "tddate": null, "forum": "UAAJMiVjTY_", "replyto": "9CR7iFWsCBK", "invitation": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment", "content": {"title": "Follow-up Answers", "comment": "**Q5+**: Figure 3b shows the impact on the number of prolog inferences. What's the\nimpact on Acc/MAE?\n\n**A5+**: The Acc/MAE are the same because of the results of logical inferences are\nthe same. The logical inferences of using/without using abduction are\nsemantically identical, because they both follow the resolution-based logic\nprogram inference. Since the background knowledge for Meta_abd's\nabduction-induction and Metagol's induction are the same, the output programs\nand pseudo-labels for updating the neural net are also the same, which does not\naffect the Acc/MAE performance.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1133/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Abductive Knowledge Induction from Raw Data", "authorids": ["~Wang-Zhou_Dai2", "~Stephen_Muggleton1"], "authors": ["Wang-Zhou Dai", "Stephen Muggleton"], "keywords": ["Neural-Symbolic Model", "Inductive Logic Programming", "Abduction"], "abstract": "For many reasoning-heavy tasks, it is challenging to find an appropriate end-to-end differentiable approximation to domain-specific inference mechanisms. Neural-Symbolic (NeSy) AI divides the end-to-end pipeline into neural perception and symbolic reasoning, which can directly exploit general domain knowledge such as algorithms and logic rules. However, it suffers from the exponential computational complexity caused by the interface between the two components, where the neural model lacks direct supervision, and the symbolic model lacks accurate input facts. As a result, they usually focus on learning the neural model with a sound and complete symbolic knowledge base while avoiding a crucial problem: where does the knowledge come from? In this paper, we present Abductive Meta-Interpretive Learning ($Meta_{Abd}$), which unites abduction and induction to learn perceptual neural network and first-order logic theories simultaneously from raw data. Given the same amount of domain knowledge, we demonstrate that $Meta_{Abd}$ not only outperforms the compared end-to-end models in predictive accuracy and data efficiency but also induces logic programs that can be re-used as background knowledge in subsequent learning tasks. To the best of our knowledge, $Meta_{Abd}$ is the first system that can jointly learn neural networks and recursive first-order logic theories with predicate invention.", "one-sentence_summary": "We propose an approach combining abduction and induction to jointly learn neural models and recursive first-order logic programs with predicate invention.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dai|abductive_knowledge_induction_from_raw_data", "supplementary_material": "/attachment/e23429030deac6f4e92abcb9aeb20a95e6e77e45.zip", "pdf": "/pdf/3a7f97a5938549dfd0fa5219a365aa126f660751.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H_yDVmut58", "_bibtex": "@misc{\ndai2021abductive,\ntitle={Abductive Knowledge Induction from Raw Data},\nauthor={Wang-Zhou Dai and Stephen Muggleton},\nyear={2021},\nurl={https://openreview.net/forum?id=UAAJMiVjTY_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "UAAJMiVjTY_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1133/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1133/Authors|ICLR.cc/2021/Conference/Paper1133/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923863265, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment"}}}, {"id": "9CR7iFWsCBK", "original": null, "number": 10, "cdate": 1605965596268, "ddate": null, "tcdate": 1605965596268, "tmdate": 1605965596268, "tddate": null, "forum": "UAAJMiVjTY_", "replyto": "kdy-1I8Z66j", "invitation": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment", "content": {"title": "Follow-up Questions", "comment": "Q5/A5: There is an ablation study, whose result has been shown in Figure 3b.\n\nFigure 3b shows the impact on the number of prolog inferences. What's the impact on Acc/MAE?"}, "signatures": ["ICLR.cc/2021/Conference/Paper1133/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Abductive Knowledge Induction from Raw Data", "authorids": ["~Wang-Zhou_Dai2", "~Stephen_Muggleton1"], "authors": ["Wang-Zhou Dai", "Stephen Muggleton"], "keywords": ["Neural-Symbolic Model", "Inductive Logic Programming", "Abduction"], "abstract": "For many reasoning-heavy tasks, it is challenging to find an appropriate end-to-end differentiable approximation to domain-specific inference mechanisms. Neural-Symbolic (NeSy) AI divides the end-to-end pipeline into neural perception and symbolic reasoning, which can directly exploit general domain knowledge such as algorithms and logic rules. However, it suffers from the exponential computational complexity caused by the interface between the two components, where the neural model lacks direct supervision, and the symbolic model lacks accurate input facts. As a result, they usually focus on learning the neural model with a sound and complete symbolic knowledge base while avoiding a crucial problem: where does the knowledge come from? In this paper, we present Abductive Meta-Interpretive Learning ($Meta_{Abd}$), which unites abduction and induction to learn perceptual neural network and first-order logic theories simultaneously from raw data. Given the same amount of domain knowledge, we demonstrate that $Meta_{Abd}$ not only outperforms the compared end-to-end models in predictive accuracy and data efficiency but also induces logic programs that can be re-used as background knowledge in subsequent learning tasks. To the best of our knowledge, $Meta_{Abd}$ is the first system that can jointly learn neural networks and recursive first-order logic theories with predicate invention.", "one-sentence_summary": "We propose an approach combining abduction and induction to jointly learn neural models and recursive first-order logic programs with predicate invention.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dai|abductive_knowledge_induction_from_raw_data", "supplementary_material": "/attachment/e23429030deac6f4e92abcb9aeb20a95e6e77e45.zip", "pdf": "/pdf/3a7f97a5938549dfd0fa5219a365aa126f660751.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H_yDVmut58", "_bibtex": "@misc{\ndai2021abductive,\ntitle={Abductive Knowledge Induction from Raw Data},\nauthor={Wang-Zhou Dai and Stephen Muggleton},\nyear={2021},\nurl={https://openreview.net/forum?id=UAAJMiVjTY_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "UAAJMiVjTY_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1133/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1133/Authors|ICLR.cc/2021/Conference/Paper1133/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923863265, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment"}}}, {"id": "6e_mJJvwI1a", "original": null, "number": 9, "cdate": 1605965481904, "ddate": null, "tcdate": 1605965481904, "tmdate": 1605965481904, "tddate": null, "forum": "UAAJMiVjTY_", "replyto": "nY6lW3kz9F6", "invitation": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment", "content": {"title": "Follow-up Questions", "comment": "Thanks for your responses.\n\nQ6/A6: \"There is no parameter of rules,\"\n\nI think there may be a misunderstanding. I'm not asking about the parameters of rules, but rather, about how EM is initialized. Modulo convnet, how does Meta_abd initialize EM, and how sensitive are its results to the initialization? (My original comments have more related questions in the same paragraph.)\n\nQ9/A9: \"we argue that the bias of metarules in this work is not strong at all.\"\n\nCould you quantify the contribution, say, by removing a metarule one at a time and examining the impact on runtime and accuracy/MAE?\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1133/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Abductive Knowledge Induction from Raw Data", "authorids": ["~Wang-Zhou_Dai2", "~Stephen_Muggleton1"], "authors": ["Wang-Zhou Dai", "Stephen Muggleton"], "keywords": ["Neural-Symbolic Model", "Inductive Logic Programming", "Abduction"], "abstract": "For many reasoning-heavy tasks, it is challenging to find an appropriate end-to-end differentiable approximation to domain-specific inference mechanisms. Neural-Symbolic (NeSy) AI divides the end-to-end pipeline into neural perception and symbolic reasoning, which can directly exploit general domain knowledge such as algorithms and logic rules. However, it suffers from the exponential computational complexity caused by the interface between the two components, where the neural model lacks direct supervision, and the symbolic model lacks accurate input facts. As a result, they usually focus on learning the neural model with a sound and complete symbolic knowledge base while avoiding a crucial problem: where does the knowledge come from? In this paper, we present Abductive Meta-Interpretive Learning ($Meta_{Abd}$), which unites abduction and induction to learn perceptual neural network and first-order logic theories simultaneously from raw data. Given the same amount of domain knowledge, we demonstrate that $Meta_{Abd}$ not only outperforms the compared end-to-end models in predictive accuracy and data efficiency but also induces logic programs that can be re-used as background knowledge in subsequent learning tasks. To the best of our knowledge, $Meta_{Abd}$ is the first system that can jointly learn neural networks and recursive first-order logic theories with predicate invention.", "one-sentence_summary": "We propose an approach combining abduction and induction to jointly learn neural models and recursive first-order logic programs with predicate invention.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dai|abductive_knowledge_induction_from_raw_data", "supplementary_material": "/attachment/e23429030deac6f4e92abcb9aeb20a95e6e77e45.zip", "pdf": "/pdf/3a7f97a5938549dfd0fa5219a365aa126f660751.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H_yDVmut58", "_bibtex": "@misc{\ndai2021abductive,\ntitle={Abductive Knowledge Induction from Raw Data},\nauthor={Wang-Zhou Dai and Stephen Muggleton},\nyear={2021},\nurl={https://openreview.net/forum?id=UAAJMiVjTY_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "UAAJMiVjTY_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1133/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1133/Authors|ICLR.cc/2021/Conference/Paper1133/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923863265, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment"}}}, {"id": "ZrgE83Mvb0q", "original": null, "number": 5, "cdate": 1605407540089, "ddate": null, "tcdate": 1605407540089, "tmdate": 1605415474985, "tddate": null, "forum": "UAAJMiVjTY_", "replyto": "C4imHvOcWH", "invitation": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment", "content": {"title": "Reply to Reviewer 2", "comment": "**Q1:** The MetaAbd model has very strong inductive biases, because of the\nbuiltin \"add\" operation and the metarules built into the system, which strongly\nfavors recursive rules of specific forms.\n\n**A1:** We argue that, comparing to the compared end-to-end methods, the\nbackground knowledge exploited by $Meta_{Abd}$ is not strong at all. \n\nThe NAC and NALU module has built-in functions of summation and multiplication;\nthe RNNs force the end-to-end model to learn recursive function. Meanwhile,\n$Meta_{Abd}$ also uses summation and multiplication as primitives; the metarules\nare set of generic metarules (shown in figure 10 in the appendix) which do not\nhave any preference on learning recursive theories. Table 1 briefly summarised\nthe comparison of domain knowledge between $Meta_{Abd}$ and the compared\nmethods; we will add more clarifications in the revised version. \n\n\n**Q2:** The experiment sections are relatively weak and they have definitely\nmissed some important baseline comparisons.\n\n**A2:** Although the tasks are made from synthetic examples, they are not\ntrivial problems for both end-to-end models and neuro-symbolic methods. As we\ncan observe from the experimental results, even though all the compared methods\nhave used a certain amount of domain knowledge, the problems are still hard to\nsolve. For more explanations, please refer to our answer A7 to reviewer 1.\n\nWe appreciate that the reviewer points out more related works, we will add more\ndiscussion (please see A3-A5) about them in the revised version. \n\n\n**Q3:** partial ILP (Evans & Grefenstette, 2018) and machine apperception (Evans et\nal., 2019) that can learn mnist digits with much weaker assumptions: they can\neven learn the \"succ\" relationship between digits.\n  \n**A3:** The input to Partial ILP are symbolic data, which requires a pre-trained\nCNN to extract the raw data into symbols; Machine Apperception uses a Binary\nNeural Net to learn perception; however, it cannot handle very noisy inputs due\nto the high complexity of BNN that is optimised by answer set programming (a\ndiscrete search-based approach like SAT solvers). In fact, it is possible to use MNIST\nimages for the Seek Whence task. However, due to the highly noisy inputs, the ASP-based\noptimisation of Binary Neural Network for image recognition is very inefficient. \nThat's why we say it is difficult for partial ILP and Machine Apperception to\njointly learn NN and logical theories from noisy sub-symbolic domains like MNIST\nimages. \n\nSpecifically, Machine Apperception can only use Binary Neural Net for\nperception, while $Meta_{Abd}$ is a more general approach that does not\nconstrain the type of perception model. Furthermore, during the Machine\nApperception engine can invent concepts of objects (i.e., monadic predicate),\n$Meta_Abd$ can perform general predicate invention, which subsumes object\ninvention. We are sorry that we haven't made it clearer in the submission and\nwill revise it in the next version.\n\n$Meta_Abd$ has successfully learned the \"success\" relation between images in the\nbogosort task, even without background knowledge about that success is a\ntransitive relation. More details are described in the appendix A.3, Paragraph\nExample of Dyadic facts abduction, the dyadic neural predicate `nn_pred/2`\nlearns the success relation automatically from the MNIST images.\n\n\n**Q4:** Neural GPU (Kaiser and Sutskever 2015), Differentiable Neural Computer,\nNeural Programmer-Interpreters (Reed et al 2015), Neural Logical Machines.\n\n**A4:** All these methods are assuming symbolic inputs, which means they are not\ndesigned for learning perception and reasoning. For example, in (Dai et al.,\nBridging machine learning and logical reasoning by abductive learning, NeurIPS\n2019), it has been shown that Differentiable Neural Computer does not perform\nwell in heavy-reasoning tasks with raw inputs.\n\n\n**Q5:** About Graph Neural Networks.\n\n**A5:** As we have discussed in section 1, GNNs usually require a fixed\nrelational graph structure before learning, while the motivation of this work is\nto learn such relational structures (e.g., logic programs) when they are not\navailable.\n\n**Q6:** The learned logic rules are relatively simple. This makes me less\nconvinced about the applicability of the paper.\n\n**A6:** The difficulty of the tasks is not only coming from the rules, but also\nresulted by the noisy raw data inputs. Therefore, we argue that these tasks are\nnon-trival. Please see our answer A7 to Reviewer 1."}, "signatures": ["ICLR.cc/2021/Conference/Paper1133/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Abductive Knowledge Induction from Raw Data", "authorids": ["~Wang-Zhou_Dai2", "~Stephen_Muggleton1"], "authors": ["Wang-Zhou Dai", "Stephen Muggleton"], "keywords": ["Neural-Symbolic Model", "Inductive Logic Programming", "Abduction"], "abstract": "For many reasoning-heavy tasks, it is challenging to find an appropriate end-to-end differentiable approximation to domain-specific inference mechanisms. Neural-Symbolic (NeSy) AI divides the end-to-end pipeline into neural perception and symbolic reasoning, which can directly exploit general domain knowledge such as algorithms and logic rules. However, it suffers from the exponential computational complexity caused by the interface between the two components, where the neural model lacks direct supervision, and the symbolic model lacks accurate input facts. As a result, they usually focus on learning the neural model with a sound and complete symbolic knowledge base while avoiding a crucial problem: where does the knowledge come from? In this paper, we present Abductive Meta-Interpretive Learning ($Meta_{Abd}$), which unites abduction and induction to learn perceptual neural network and first-order logic theories simultaneously from raw data. Given the same amount of domain knowledge, we demonstrate that $Meta_{Abd}$ not only outperforms the compared end-to-end models in predictive accuracy and data efficiency but also induces logic programs that can be re-used as background knowledge in subsequent learning tasks. To the best of our knowledge, $Meta_{Abd}$ is the first system that can jointly learn neural networks and recursive first-order logic theories with predicate invention.", "one-sentence_summary": "We propose an approach combining abduction and induction to jointly learn neural models and recursive first-order logic programs with predicate invention.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dai|abductive_knowledge_induction_from_raw_data", "supplementary_material": "/attachment/e23429030deac6f4e92abcb9aeb20a95e6e77e45.zip", "pdf": "/pdf/3a7f97a5938549dfd0fa5219a365aa126f660751.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H_yDVmut58", "_bibtex": "@misc{\ndai2021abductive,\ntitle={Abductive Knowledge Induction from Raw Data},\nauthor={Wang-Zhou Dai and Stephen Muggleton},\nyear={2021},\nurl={https://openreview.net/forum?id=UAAJMiVjTY_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "UAAJMiVjTY_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1133/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1133/Authors|ICLR.cc/2021/Conference/Paper1133/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923863265, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment"}}}, {"id": "kdy-1I8Z66j", "original": null, "number": 7, "cdate": 1605408226914, "ddate": null, "tcdate": 1605408226914, "tmdate": 1605408299483, "tddate": null, "forum": "UAAJMiVjTY_", "replyto": "WGgOeUWU-t2", "invitation": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment", "content": {"title": "Reply to Reviewer 3 (Part 1)", "comment": "**Q1:** EM as a framework for bridging noisy inputs and symbolic reasoning has\nbeen explored by prior work.\n\n**A1:** We thank the reviewer for pointing out these papers, we will add them in\nthe related work section in the revised version.\n\n\n**Q2:** In the context of these existing systems, the contribution of Meta_abd\nappears to lie only in learning rules with the existing MIL system, and thus\nseems moderately incremental.\n\n**A2:** We argue that rule learning in neural-symbolic learning is a crucial\nproblem, and $Meta_{Abd}$ is not just an incremental work comparing to existing\napproaches.\n\nFirstly, almost all existing method bridging neural net and symbolic reasoning\nare assuming that the given domain knowledge is sound and complete, i.e., once\nthe sub-symbolic model like NN can be trained to give correct outputs\n(embeddings, labels, etc.), the reasoning part will always succeed. However,\nthis setting enforces users to provide strong domain knowledge before learning,\nwhich could be impossible in many cases like those of expert systems many years\nago.\n\nSecondly, first-order logic rules are a kind of programs having nice theoretical\nguarantees (soundness and completeness). A lot of problems can be naturally\nexpressed by programs rather than differentiable neural nets, for example the\nsum/product and sorting algorithms in our experiments. Moreover, programs can be\ndirectly re-used, and they can easily extrapolate to unseen data. The benefits\nhave been reflected in our experiments.\n\nLastly, learning (logic) programs and perceptual neural net together is a\nnon-trivial problem. As we have stated in section 3 and previous answers to the\nother reviewers, the interface between sub-symbolic learning and symbolic\nlearning is an exponentially-growing set of grounded atoms, only adding MIL\ncannot solve this problem. Previous works in this topic (Dai, et al, 2019;\nEvans, et al., 2019; Li et al., 2020) has shown the difficulty. The major\ncontribution of this work is combining abduction and induction to prune the\nsearch space of the truth-values of the grounded atoms in the interface to make\nthe jointly training possible.\n\n**Q3:** Page 4, Figure 1: When optimizing the \\theta parameters of the neural\nnetwork in the M-step, are the labels for each digit image probabilistic?\n\n**A3:** The pseudo-labels ($z$) for training the neural net are not\nprobabilistic. They are the expectation of the conditional distribution\n$P(z|B,x,y,\\theta)$, i.e., the most probable label given background knowledge\n$B$, images $x$, targets $y$ and the current neural network with parameter\n$\\theta$. In other words, it is the expectation of the hidden variable $z$ in Eq\n1 and 2.\n\n**Q4:** How is H sampled? \n\n**A4:** $H$ is sampled during the MIL process. MIL tries to prove each example\nby synthesise a logic program. The synthesise process can be seen as a search\ntree, which can be easily sampled according to the prior distribution.\n\n**Q5:** How much does the pruning of z with the abduced constraints help?\nThere is no ablation study to verify the contribution of the abduced\nconstraints.\n\n**A5:** There is an ablation study, whose result has been shown in Figure 3b.\n$H\\rightarrow z$ is $Meta_{Abd}$, which induces abductive theories $H$ first and\nthen use it to constrain the abduction of $z$; $z\\rightarrow H$ first performs a\ngreedy search on $z$ with probability $p_\\theta(z|x)$ to find the most probable\n$z$ and then use it as examples of conventional MIL to learn a valid hypothesis $H$.\nFigure 3b is the average time cost on *one* training example, as we can see, the\nbenefit from abduction is huge. We will make it clearer in the revised version.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1133/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Abductive Knowledge Induction from Raw Data", "authorids": ["~Wang-Zhou_Dai2", "~Stephen_Muggleton1"], "authors": ["Wang-Zhou Dai", "Stephen Muggleton"], "keywords": ["Neural-Symbolic Model", "Inductive Logic Programming", "Abduction"], "abstract": "For many reasoning-heavy tasks, it is challenging to find an appropriate end-to-end differentiable approximation to domain-specific inference mechanisms. Neural-Symbolic (NeSy) AI divides the end-to-end pipeline into neural perception and symbolic reasoning, which can directly exploit general domain knowledge such as algorithms and logic rules. However, it suffers from the exponential computational complexity caused by the interface between the two components, where the neural model lacks direct supervision, and the symbolic model lacks accurate input facts. As a result, they usually focus on learning the neural model with a sound and complete symbolic knowledge base while avoiding a crucial problem: where does the knowledge come from? In this paper, we present Abductive Meta-Interpretive Learning ($Meta_{Abd}$), which unites abduction and induction to learn perceptual neural network and first-order logic theories simultaneously from raw data. Given the same amount of domain knowledge, we demonstrate that $Meta_{Abd}$ not only outperforms the compared end-to-end models in predictive accuracy and data efficiency but also induces logic programs that can be re-used as background knowledge in subsequent learning tasks. To the best of our knowledge, $Meta_{Abd}$ is the first system that can jointly learn neural networks and recursive first-order logic theories with predicate invention.", "one-sentence_summary": "We propose an approach combining abduction and induction to jointly learn neural models and recursive first-order logic programs with predicate invention.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dai|abductive_knowledge_induction_from_raw_data", "supplementary_material": "/attachment/e23429030deac6f4e92abcb9aeb20a95e6e77e45.zip", "pdf": "/pdf/3a7f97a5938549dfd0fa5219a365aa126f660751.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H_yDVmut58", "_bibtex": "@misc{\ndai2021abductive,\ntitle={Abductive Knowledge Induction from Raw Data},\nauthor={Wang-Zhou Dai and Stephen Muggleton},\nyear={2021},\nurl={https://openreview.net/forum?id=UAAJMiVjTY_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "UAAJMiVjTY_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1133/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1133/Authors|ICLR.cc/2021/Conference/Paper1133/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923863265, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment"}}}, {"id": "nY6lW3kz9F6", "original": null, "number": 8, "cdate": 1605408268878, "ddate": null, "tcdate": 1605408268878, "tmdate": 1605408268878, "tddate": null, "forum": "UAAJMiVjTY_", "replyto": "WGgOeUWU-t2", "invitation": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment", "content": {"title": "Reply to Reviewer 3 (Part 2)", "comment": "**Q6:** How are the parameters and/or rules initialized? \n\n**A6:** There is no parameter of rules, and the rule structures are learned from\nscratch. Involving probabilities in logic reasoning makes the inference and\nrule structure learning infeasible (see Statistical Relational Learning and\nProbabilistic Graphical Models). This is also the reason why we propose\n$Meta_{Abd}$ and integrate abduction and induction in **pure first-order logic\ninference**. Noises only exist in the raw inputs, which forms the possible\nworlds represented by the probabilistic facts output from neural nets. Please\nsee our answer A3 to reviewer 3.\n\n**Q7:** How much does the pre-trained convent help exactly? And from what base?\n\n**A7:** The improvements have been shown in Table 2 and Figure 5 (in appendix).\nThe one-shot pre-train of covnet provides a good initialisation of $\\theta$,\nwhich makes EM converges faster and less-probable to be trapped in local\noptima.\n\n**Q8:** The empirical evaluation only uses fairly small datasets from a narrow\ndomain. Concerns on Meta_abd's scalability.\n\n**A8:** One of the motivations of introducing relational domain knowledge in\nmachine learning is to **reduce the number of required labelled data**.\nNeural-symbolic learning, self-supervised learning and many other machine\nlearning areas are aiming at this target. So we think small dataset is not a\ndrawback, but a benefit.\n\nThe complexity of the induction part of $Meta_{abd}$ is identical to MIL; the\ncomplexity of abduction is different in each different tasks, because it is\nrelated to the number of pseudo-labels (potential symbols in raw data). \n\nBy enabling full-featured ILP in neural symbolic learning, $Meta_{Abd}$ is able\nto learn large scale knowledge base by simply re-using the learned programs as\nbackground knowledge in a curriculum of tasks, which is the major benefit of\nsymbolic machine learning.\n\nThe main target of symbolic machine learning (ILP and program synthesis) is not\nlearning \"large\" programs. Without enough background knowledge, it is impossible\nto learn a good theory/program, because the search space of program grows\nexponential with the length of programs. For example, it is very hard to teach a\npupil calculus, but it is very easy to teach it to a high-school student.  To\nlearn large programs, the most natural way is using curriculum learning, in\nwhich the background knowledge is continuously accumulated and reused. It can be\neasily realised with $Meta_{Abd}$ because it learns reusable logic theories,\nwhich is verified by the experiment on learning bogosort.\n\n\n**Q9:** Would it be fair to say that the meta-rules are cleverly specified to\nprovide a strong enough structural bias for Meta_abd to be able to learn the\ncorrect rules?\n\n**A9:** Metarules can be seen as basic grammars in programming language. When\nwriting/synthesising a program, the grammars/metarules of course will provide a\nstructural bias.\n\nHowever, we argue that the bias of metarules in this work is not strong at all.\nWe use a general set of dyadic metarules, which is not specially picked for any\ntask. Removing some of them will even increase the learning speed as it reduces\nthe search space.\n\nComparing to the RNNs, which enforce the end-to-end model to learn a recursive\nprogram, metarules actually are more general and does not have advantage because\nthe resulted space of structural hypotheses is larger and more general in the\nsense of expressive power.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1133/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Abductive Knowledge Induction from Raw Data", "authorids": ["~Wang-Zhou_Dai2", "~Stephen_Muggleton1"], "authors": ["Wang-Zhou Dai", "Stephen Muggleton"], "keywords": ["Neural-Symbolic Model", "Inductive Logic Programming", "Abduction"], "abstract": "For many reasoning-heavy tasks, it is challenging to find an appropriate end-to-end differentiable approximation to domain-specific inference mechanisms. Neural-Symbolic (NeSy) AI divides the end-to-end pipeline into neural perception and symbolic reasoning, which can directly exploit general domain knowledge such as algorithms and logic rules. However, it suffers from the exponential computational complexity caused by the interface between the two components, where the neural model lacks direct supervision, and the symbolic model lacks accurate input facts. As a result, they usually focus on learning the neural model with a sound and complete symbolic knowledge base while avoiding a crucial problem: where does the knowledge come from? In this paper, we present Abductive Meta-Interpretive Learning ($Meta_{Abd}$), which unites abduction and induction to learn perceptual neural network and first-order logic theories simultaneously from raw data. Given the same amount of domain knowledge, we demonstrate that $Meta_{Abd}$ not only outperforms the compared end-to-end models in predictive accuracy and data efficiency but also induces logic programs that can be re-used as background knowledge in subsequent learning tasks. To the best of our knowledge, $Meta_{Abd}$ is the first system that can jointly learn neural networks and recursive first-order logic theories with predicate invention.", "one-sentence_summary": "We propose an approach combining abduction and induction to jointly learn neural models and recursive first-order logic programs with predicate invention.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dai|abductive_knowledge_induction_from_raw_data", "supplementary_material": "/attachment/e23429030deac6f4e92abcb9aeb20a95e6e77e45.zip", "pdf": "/pdf/3a7f97a5938549dfd0fa5219a365aa126f660751.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H_yDVmut58", "_bibtex": "@misc{\ndai2021abductive,\ntitle={Abductive Knowledge Induction from Raw Data},\nauthor={Wang-Zhou Dai and Stephen Muggleton},\nyear={2021},\nurl={https://openreview.net/forum?id=UAAJMiVjTY_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "UAAJMiVjTY_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1133/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1133/Authors|ICLR.cc/2021/Conference/Paper1133/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923863265, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment"}}}, {"id": "fgc_q8m7IHt", "original": null, "number": 6, "cdate": 1605407821090, "ddate": null, "tcdate": 1605407821090, "tmdate": 1605407821090, "tddate": null, "forum": "UAAJMiVjTY_", "replyto": "5CPJwzn4rM5", "invitation": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment", "content": {"title": "Reply to Reviewer 1", "comment": "**Q1:** In Meta_abd, NN is only used for data pre-processing which is\ncompletely agnostic to the later logic component. diff-ILP (Evans &\nGrefenstette, 2018) also uses NN for pre-processing MNIST digits for ILP task\nand it is similar to the proposed method.\n\n**A1:** This is not true. In $Meta_{Abd}$, NN is learned simultaneously with\nlogic programs. The two components affect each other during the learning\nprocess, where the logical learning part helps estimate the label of the raw input\ndata; the estimated labels are then used to train the neural net to improve its\nclassification accuracy; the probabilistic distribution of NN's output labels\nhelp the logical learning to induce the most probable program.\n\nPartial-ILP is designed for learning symbolic model with gradient-based deep\nlearning, which requires symbolic inputs and does not train perceptual networks.\nPlease see our answer A3 to reviewer 2.\n\n**Q2:** In section 2, the author claims that differentiable ILP methods rely on\nfully trained NN for pre-processing - this is untrue.\n\n**A2:** Please note that, in section 2, we only say \"original ILP, early works on\ncombining abduction and induction, and partial ILP are designed for learning\nfrom symbolic domains (sorry for the typo)\". For domains with raw inputs, they\nneed to use a fully trained neural model to extract primitive facts from raw\ndata before symbolic learning. The motivation of this work is to learn programs\nfrom raw data.\n\nMost existing works integrates neural nets and logic reasoning do\nnot need pre-processing, but they also cannot learn first-order logic rule\nstructure and programs. On the other hand, works that can learn logic rule\nstructure and programs usually require symbolic inputs (S Russell, Unifying\nLogic and Probability, Comm of ACM, 2015). Hence, they need a pre-processing\nneural network to extract symbols from raw data.\n\n**Q3:** The author also claims that most existing NeSy systems only utilize a\npre-defined knowledge base. I find this claim to be confusing...\n\n**A3:** We are sorry that we haven't made it clearer about this in section 2.\nOur claim in the abstract and section 1 has stated it in a better way: \"they\n(existing NeSy and StarAI methods) usually focus on learning the neural model\nwith a **sound and complete symbolic knowledge base**\". Our main contribution in\nthis work is to enable the learning of recursive logic programs with general\npredicate invention from a weak background knowledge base in a sub-symbolic\ndomain, which, to the best of our knowledge, has not been done before.\n\n**Q4:** The author defines the learning problem with Eq1 and Eq2 in Section 3.1\nand claims to it would be learned through EM...and the exact procedure of EM is\nunclear to me.\n\n**A4:** EM is used for parameter learning in problems having hidden variables.\nIn Eq1 and Eq2 the $H$ and $z$ in the expectation terms are hidden variables.\nTherefore, EM can solve it by estimating the expectation of $H$ and $z$ and then\nuse them to optimise the parameter $\\theta$. We will make it clearer in the\nrevised version.\n\n**Q5:** Introduction to MIL and relation to Prolog.\n\n**A5:** Meta-Interpretive Learning is an Inductive Logic Programming framework\nimplemented with Prolog language. We will add more text to introduce them in the\nrevised paper.\n\n**Q6:** The author should include some ILP baselines such as diff-ILP or\nNeuralLP and substitute the digit image into its ground-truth digit symbol for\nreference.\n\n**A6:** As claimed in section 1 and 2, pre-training and pre-processing are what\nwe try to avoid in this work. The motivation of this work is to combine\nsub-symbolic and symbolic learning, in which the labels for training the\nperception model are **unknown**. Therefore they should be trained jointly. If\nwe use pre-trained NN to pre-process raw data into symbols, we could directly\napply StarAI or ILP to learn symbolic models. However, in this way, we need to\nprovide the label for training the NN model, which could be impossible in many\napplications.\n\n**Q7:** 3 benchmarks are fairly small consisting of only a few predicates and\nrules. How does the proposed method scale with the number of predicates and the\nsize of the grounding space?\n\n**A7:** We argue that the three benchmarks are not small in the area program\nsynthesis and inductive logic programming. The learned programs are recursive;\none of them even requires predicate invention. These tasks are all non-trivial\nin the area of symbolic machine learning. Moreover, the main challenge lies the\nuncertainty of \"what symbols exist in the raw data\". For the ILP model, because\nthe input facts extracted from raw data are uncertain, the program induction\nbecomes even harder. Scalability of ILP and program synthesis w.r.t. the size of\nbackground knowledge remains an open problem in these areas, which is not the\nmain issue of our paper."}, "signatures": ["ICLR.cc/2021/Conference/Paper1133/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Abductive Knowledge Induction from Raw Data", "authorids": ["~Wang-Zhou_Dai2", "~Stephen_Muggleton1"], "authors": ["Wang-Zhou Dai", "Stephen Muggleton"], "keywords": ["Neural-Symbolic Model", "Inductive Logic Programming", "Abduction"], "abstract": "For many reasoning-heavy tasks, it is challenging to find an appropriate end-to-end differentiable approximation to domain-specific inference mechanisms. Neural-Symbolic (NeSy) AI divides the end-to-end pipeline into neural perception and symbolic reasoning, which can directly exploit general domain knowledge such as algorithms and logic rules. However, it suffers from the exponential computational complexity caused by the interface between the two components, where the neural model lacks direct supervision, and the symbolic model lacks accurate input facts. As a result, they usually focus on learning the neural model with a sound and complete symbolic knowledge base while avoiding a crucial problem: where does the knowledge come from? In this paper, we present Abductive Meta-Interpretive Learning ($Meta_{Abd}$), which unites abduction and induction to learn perceptual neural network and first-order logic theories simultaneously from raw data. Given the same amount of domain knowledge, we demonstrate that $Meta_{Abd}$ not only outperforms the compared end-to-end models in predictive accuracy and data efficiency but also induces logic programs that can be re-used as background knowledge in subsequent learning tasks. To the best of our knowledge, $Meta_{Abd}$ is the first system that can jointly learn neural networks and recursive first-order logic theories with predicate invention.", "one-sentence_summary": "We propose an approach combining abduction and induction to jointly learn neural models and recursive first-order logic programs with predicate invention.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dai|abductive_knowledge_induction_from_raw_data", "supplementary_material": "/attachment/e23429030deac6f4e92abcb9aeb20a95e6e77e45.zip", "pdf": "/pdf/3a7f97a5938549dfd0fa5219a365aa126f660751.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H_yDVmut58", "_bibtex": "@misc{\ndai2021abductive,\ntitle={Abductive Knowledge Induction from Raw Data},\nauthor={Wang-Zhou Dai and Stephen Muggleton},\nyear={2021},\nurl={https://openreview.net/forum?id=UAAJMiVjTY_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "UAAJMiVjTY_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1133/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1133/Authors|ICLR.cc/2021/Conference/Paper1133/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923863265, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment"}}}, {"id": "0XD_iigxXJ5", "original": null, "number": 4, "cdate": 1605407448057, "ddate": null, "tcdate": 1605407448057, "tmdate": 1605407448057, "tddate": null, "forum": "UAAJMiVjTY_", "replyto": "EvjRWfDQjo8", "invitation": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment", "content": {"title": "Reply to Reviewer 4", "comment": "**Q1:** `nn()` is never explained in the text.\n\n**A1:** We are sorry that we haven't clarified the meaning of `nn` predicate in\nthe main text, it is explained in the appendix A.2 (second paragraph on page\n12). We will revise to make it clearer.\n\n**Q2:** what are the inputs and outputs? What is the relationship\nbetween them? prove() used in Figure 2 is never explained.\n\n**A2:** The inputs and outputs and their relationship have been clearly\nexplained in the first and second paragraph of section 3.1.\n\nFigure 2 is a Prolog meta-interpreter, which is briefly explained in the second\nparagraph of section 3.3. Considering that most of audience of ICLR does not\nhave a background in ILP or program synthesis, we will add detailed explanatory\ntext for the algorithm in the revised version.\n\n\n**Q3:** It seems funny to have 0/1 probabilities (equation (4)). Surely there is\nso much noise that you can't perfectly predict the outputs.\n\n**A3:** First-order logical reasoning **should be** noise-free, that's why it\nhas solid theoretical guarantees like soundness and completeness.\n\n$Meta_Abd$ adopts the *distribution semantics* in probabilistic logic (T Sato, A\nstatistical learning method for logic programs with distribution semantics, ICLP\n1995), in which the noises are handled by the **possible worlds** of ground\nfacts, in each possible world, the inference is deterministic. For example in\nFigure 2, the interpretation of MNIST images are noisy, but once the symbol\n(i.e., digits) are recognised, the logical inference for summation will only\nhave 0/1 probabilities, isn't it?\n\n\n**Q4:** why do you think (exponential complexity) is caused by the interface? how\nyou overcome it?\n\n**A4:** For example, given 3000 MNIST sequences with length 5, there are 15000\nlabels to be predicted, i.e., $10^15000$ possible pseudo-label ($z$)\nassignments. The pseudo-label $z$ is used to induce a program to calculate the\nfinal label ($y$, e.g., the sum of each MNIST sequence). Without an accurate\n$z$, it is very difficult to learn the correct program. Hence, the challenge is\nintroduced by the interface $z$.\n\nWe overcome it by combining abduction and induction. $Meta_{Abd}$ learns an\nabductive logic program $H$, and then uses $H$ to infer (which is called\nabduction in first-order logic) the possible values of $z$. A detailed\nexplanation is in the second paragraph of section 3.2; and a more detailed\nexplanation is in the appendix (first paragraph on page 12). \n\n\n**Q5:** why use MAE (or log MAE)? What is the accuracy of the correct program?\nIs the correct program in the search space with a non-zero prior?\n\n**A5:** MAE is the evaluation metric in the original paper of NALU, and we\nagree with them because summation and multiplication are regression tasks.\n\nThe accuracy of learning programs is either 0 or 1, i.e., whether $Meta_{Abd}$\noutputs a correct program (covers all positive examples and no negative example)\nor a wrong program (does not cover all positive examples or covers at least one\nnegative example), following the definition of Inductive Logic Programming, as\nwe explained in *A3*. The learned programs are clearly shown in Figure 3a.\n\n\n**Q6:** Is \"Acc\" in table 2 correspond to just predicting the digit? Why is\nthere so much variability? What is the accuracy of nn()?\n\n**A6:** Yes, \"Acc\" is the accuracy of the learned CNN, which predicts the label\nof a single image. The metric is also used in the original NALU paper. It is the\nfinal accuracy of `nn`. The training curve of `nn` is shown in Figure 5 in the\nappendix.\n\n\n**Q7:** The paper needs to be self contained. Concerns on reproducibility.\n\n**A7:** We are sorry that we have put too many details in the Appendix, and we\nwill improve the presentation by moving the important contents into the main\ntext. We have a section about reproducibility in the Appendix, our codes and\ndata are also available in the supplementary materials.\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1133/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Abductive Knowledge Induction from Raw Data", "authorids": ["~Wang-Zhou_Dai2", "~Stephen_Muggleton1"], "authors": ["Wang-Zhou Dai", "Stephen Muggleton"], "keywords": ["Neural-Symbolic Model", "Inductive Logic Programming", "Abduction"], "abstract": "For many reasoning-heavy tasks, it is challenging to find an appropriate end-to-end differentiable approximation to domain-specific inference mechanisms. Neural-Symbolic (NeSy) AI divides the end-to-end pipeline into neural perception and symbolic reasoning, which can directly exploit general domain knowledge such as algorithms and logic rules. However, it suffers from the exponential computational complexity caused by the interface between the two components, where the neural model lacks direct supervision, and the symbolic model lacks accurate input facts. As a result, they usually focus on learning the neural model with a sound and complete symbolic knowledge base while avoiding a crucial problem: where does the knowledge come from? In this paper, we present Abductive Meta-Interpretive Learning ($Meta_{Abd}$), which unites abduction and induction to learn perceptual neural network and first-order logic theories simultaneously from raw data. Given the same amount of domain knowledge, we demonstrate that $Meta_{Abd}$ not only outperforms the compared end-to-end models in predictive accuracy and data efficiency but also induces logic programs that can be re-used as background knowledge in subsequent learning tasks. To the best of our knowledge, $Meta_{Abd}$ is the first system that can jointly learn neural networks and recursive first-order logic theories with predicate invention.", "one-sentence_summary": "We propose an approach combining abduction and induction to jointly learn neural models and recursive first-order logic programs with predicate invention.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dai|abductive_knowledge_induction_from_raw_data", "supplementary_material": "/attachment/e23429030deac6f4e92abcb9aeb20a95e6e77e45.zip", "pdf": "/pdf/3a7f97a5938549dfd0fa5219a365aa126f660751.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H_yDVmut58", "_bibtex": "@misc{\ndai2021abductive,\ntitle={Abductive Knowledge Induction from Raw Data},\nauthor={Wang-Zhou Dai and Stephen Muggleton},\nyear={2021},\nurl={https://openreview.net/forum?id=UAAJMiVjTY_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "UAAJMiVjTY_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1133/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1133/Authors|ICLR.cc/2021/Conference/Paper1133/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923863265, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment"}}}, {"id": "ZloEDUa71Y", "original": null, "number": 3, "cdate": 1605407399555, "ddate": null, "tcdate": 1605407399555, "tmdate": 1605407399555, "tddate": null, "forum": "UAAJMiVjTY_", "replyto": "iOF3pnR1Rg", "invitation": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment", "content": {"title": "More clarifications", "comment": "=== Contribution of This Work ===\n\nThe main contribution of this work is combining neural network with\nfull-featured Inductive Logic Programming and let the two systems to be trained\nsimultaneously in a unified framework. To the best of our knowledge, this is\nthe first work does this job. Nevertheless, our knowledge is limited, we are\nhappy to hear comments about related works and works that sharing similar ideas.\n\nHowever, simply combining the two systems requires an interface between them.\nThe ILP system needs symbolic inputs for logical inference (both induction and\ndeduction); the neural net requires labels for supervised training. The\ninterface is discrete, and its search space grows exponentially with the number\nof examples. To make the simultaneously training possible, we propose to\nintegrate induction and abduction to reduce the cost of the optimisation.\n\nAbduction can be seen as \"reversed deduction\". Different from induction, it does\nnot learn any \"general rule\" from empirical data. Instead, it tries to explain\nthe observed outcome based on background knowledge. For example, when we see the\ngrass in front of our house is wet, abduction will tell us it might have rained\nor the sprinkler was on. As an analogy to gradient descent in the deep learning\ncontext, abduction \"propagates the error\" backwards from the output facts to\nfind the most probable input values.\n\nBy integrating abduction and induction, our proposed method can drastically\nreduce the search time (see Figure 3b) of truth values of the unknown interface\nsymbols (labels of the images), which makes training neural networks with\nfull-featured ILP together possible.\n\n=== Baseline Methods and Experimental Tasks ===\n\nAs we have mentioned before, integrating neural nets and ILP will: 1) enable\nmachine learning the ability to exploit domain knowledge expressed with formal\nlanguage; and 2) learning human interpretable programs from raw data. Therefore,\nthe baseline methods of end-to-end deep neural networks should 1) exploit the\nsame (or at least equivalent) domain knowledge; 2) is designed for learning\n\"program-like\" models from sub-symbolic data. Neural Arithmetic Logic Units and\nNeural Sort are the most representative examples in this category. This is also\nwhy we use the same tasks and performance measures in their original papers.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1133/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Abductive Knowledge Induction from Raw Data", "authorids": ["~Wang-Zhou_Dai2", "~Stephen_Muggleton1"], "authors": ["Wang-Zhou Dai", "Stephen Muggleton"], "keywords": ["Neural-Symbolic Model", "Inductive Logic Programming", "Abduction"], "abstract": "For many reasoning-heavy tasks, it is challenging to find an appropriate end-to-end differentiable approximation to domain-specific inference mechanisms. Neural-Symbolic (NeSy) AI divides the end-to-end pipeline into neural perception and symbolic reasoning, which can directly exploit general domain knowledge such as algorithms and logic rules. However, it suffers from the exponential computational complexity caused by the interface between the two components, where the neural model lacks direct supervision, and the symbolic model lacks accurate input facts. As a result, they usually focus on learning the neural model with a sound and complete symbolic knowledge base while avoiding a crucial problem: where does the knowledge come from? In this paper, we present Abductive Meta-Interpretive Learning ($Meta_{Abd}$), which unites abduction and induction to learn perceptual neural network and first-order logic theories simultaneously from raw data. Given the same amount of domain knowledge, we demonstrate that $Meta_{Abd}$ not only outperforms the compared end-to-end models in predictive accuracy and data efficiency but also induces logic programs that can be re-used as background knowledge in subsequent learning tasks. To the best of our knowledge, $Meta_{Abd}$ is the first system that can jointly learn neural networks and recursive first-order logic theories with predicate invention.", "one-sentence_summary": "We propose an approach combining abduction and induction to jointly learn neural models and recursive first-order logic programs with predicate invention.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dai|abductive_knowledge_induction_from_raw_data", "supplementary_material": "/attachment/e23429030deac6f4e92abcb9aeb20a95e6e77e45.zip", "pdf": "/pdf/3a7f97a5938549dfd0fa5219a365aa126f660751.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H_yDVmut58", "_bibtex": "@misc{\ndai2021abductive,\ntitle={Abductive Knowledge Induction from Raw Data},\nauthor={Wang-Zhou Dai and Stephen Muggleton},\nyear={2021},\nurl={https://openreview.net/forum?id=UAAJMiVjTY_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "UAAJMiVjTY_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1133/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1133/Authors|ICLR.cc/2021/Conference/Paper1133/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923863265, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment"}}}, {"id": "iOF3pnR1Rg", "original": null, "number": 2, "cdate": 1605407311328, "ddate": null, "tcdate": 1605407311328, "tmdate": 1605407356114, "tddate": null, "forum": "UAAJMiVjTY_", "replyto": "UAAJMiVjTY_", "invitation": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment", "content": {"title": "About motivation and contribution", "comment": "Thanks to all the reviewers for the detailed comments. After reading all the\nreviews, we found that most of the reviewers do not have much background in\nInductive Logic Programming (ILP) or program synthesis. We are sorry that our initial\nsubmission hasn't included more preliminaries about these subjects, which will\nbe added in the revised version.\n\nIn order to help the reviewers and readers understand our work better, we mildly\nintroduce ILP and clarify our main contribution and motivation as follows.\n\n=== Inductive Logic Programming and Meta-Interpretive Learning ===\n\nInductive Logic Programming is a symbolic machine learning paradigm for learning\nfirst-order logic theories from data. Given some background knowledge $B$ and a\nset of examples $E=E^+\\cup E^-$, where $E^+$ are positive examples and $E^-$ are\nnegative examples, the target of ILP is to induce a hypothetical first-order\nlogic theory $H$, such that $B\\cup H\\models E+$ and $B\\cup H\\not\\models E^-$.\nBecause $B$, $E$ and $H$ are all represented by *Logic Program* (e.g., Prolog\nprogram), this machine learning technique is named as *Inductive Logic\nProgramming*, i.e., \"inducing logic programs from data\".\n\nBriefly speaking, ILP has the same target of program synthesis, which tries to\nteach computers how to write programs by providing a number of working\nexamples ($E$) and some primitive functions ($B$). But different to ordinary\nprogram synthesis, ILP uses *first-order logic* as its programming language,\nwhich has a firm and solid foundation in mathematics, it brings ILP some very\nimportant theoretical guarantees such as *soundness* and *completeness*. For\nmore information about ILP, please refer to the very good introductory\n[article](https://arxiv.org/pdf/2008.07912.pdf) by Andrew Cropper and Sebastijan\nDuman\u010di\u0107 recently.\n\nMeta-Interpretive Learning (MIL) is an ILP approach that implements a\nsecond-order logical meta-interpreter for learning first-order logic. The\nmeta-interpreter tries to prove the positive training examples (and disprove the\nnegative ones) by backward chaining. During the proving procedure, MIL uses\nmetarules as templates to construct logic programs as the hypothesis $H$. Once\n$H$ can satisfy all positive examples and disprove all negative examples then\nthe learning process will be terminated, otherwise it will backtrack and search\nfor another hypothesis. Many neural-symbolic algorithms use a similar idea to MIL and\nmetarules to learn logic rules, for example, the Neural Theorem Prover\n(Rocktaschel et al., 2017) and partial-ILP (Evans and Grefenstette, 2018).\n\n=== Why Integrating Neural Networks with ILP ===\n\nAlthough end-to-end deep learning has achieved great success in many areas, it\nstill have some drawbacks.\n\nThere are many problems that should be solved by high-level reasoning. Algorithms and\nprograms are the most important components in computer science, they use formal\nlanguage to represent and solve problems. There are many (System 2) tasks in AI\ncan be naturally expressed by formal language and solved by programming. As a\ngeneric program synthesis method with a solid mathematical foundation, we believe\nILP suits such purpose very well.\n\nTake the MNIST summation task in our paper as an example, the training examples\nconsist of a sequence of MNIST images as input and an associated number as\noutput. To learn a model to solve this problem, the most natural idea (at least\nfor us) is to divide the task into two steps: 1) recognise the digits from\nimages; 2) learn a program to calculate the digits. Hence, task 1) should be\nsolved by neural nets, which is very good at learning perceptual model from\nsensory data; task 2) can be solved by program synthesis or ILP.\n\nBecause ILP is formulated with first-order logic, which is a general\nway to express knowledge. The background knowledge, examples and hypotheses are\nall represented in a unified way. As a result, humans can easily inject domain\nknowledge in ILP-based machine learning, the learned models are interpretable,\n*debuggable* and *reusable*.\n\nHowever, ILP and program synthesis both requires symbolic inputs, i.e., the\nexamples and background knowledge are logic programs. In real applications,\nthe data is usually noisy. Therefore, ILP and program synthesis cannot be\ndirectly applied on this kind of tasks, and previous work that tries to induce\nlogical theory or computer programs from raw data requires a pre-processing step,\nwhich filters the noises and extracts symbols from raw data."}, "signatures": ["ICLR.cc/2021/Conference/Paper1133/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Abductive Knowledge Induction from Raw Data", "authorids": ["~Wang-Zhou_Dai2", "~Stephen_Muggleton1"], "authors": ["Wang-Zhou Dai", "Stephen Muggleton"], "keywords": ["Neural-Symbolic Model", "Inductive Logic Programming", "Abduction"], "abstract": "For many reasoning-heavy tasks, it is challenging to find an appropriate end-to-end differentiable approximation to domain-specific inference mechanisms. Neural-Symbolic (NeSy) AI divides the end-to-end pipeline into neural perception and symbolic reasoning, which can directly exploit general domain knowledge such as algorithms and logic rules. However, it suffers from the exponential computational complexity caused by the interface between the two components, where the neural model lacks direct supervision, and the symbolic model lacks accurate input facts. As a result, they usually focus on learning the neural model with a sound and complete symbolic knowledge base while avoiding a crucial problem: where does the knowledge come from? In this paper, we present Abductive Meta-Interpretive Learning ($Meta_{Abd}$), which unites abduction and induction to learn perceptual neural network and first-order logic theories simultaneously from raw data. Given the same amount of domain knowledge, we demonstrate that $Meta_{Abd}$ not only outperforms the compared end-to-end models in predictive accuracy and data efficiency but also induces logic programs that can be re-used as background knowledge in subsequent learning tasks. To the best of our knowledge, $Meta_{Abd}$ is the first system that can jointly learn neural networks and recursive first-order logic theories with predicate invention.", "one-sentence_summary": "We propose an approach combining abduction and induction to jointly learn neural models and recursive first-order logic programs with predicate invention.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dai|abductive_knowledge_induction_from_raw_data", "supplementary_material": "/attachment/e23429030deac6f4e92abcb9aeb20a95e6e77e45.zip", "pdf": "/pdf/3a7f97a5938549dfd0fa5219a365aa126f660751.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H_yDVmut58", "_bibtex": "@misc{\ndai2021abductive,\ntitle={Abductive Knowledge Induction from Raw Data},\nauthor={Wang-Zhou Dai and Stephen Muggleton},\nyear={2021},\nurl={https://openreview.net/forum?id=UAAJMiVjTY_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "UAAJMiVjTY_", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1133/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1133/Authors|ICLR.cc/2021/Conference/Paper1133/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923863265, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1133/-/Official_Comment"}}}, {"id": "WGgOeUWU-t2", "original": null, "number": 1, "cdate": 1603694865476, "ddate": null, "tcdate": 1603694865476, "tmdate": 1605024522218, "tddate": null, "forum": "UAAJMiVjTY_", "replyto": "UAAJMiVjTY_", "invitation": "ICLR.cc/2021/Conference/Paper1133/-/Official_Review", "content": {"title": "Interesting EM framework for bridging perception and reasoning, but with exposition gaps.", "review": "The paper proposes an EM framework (Meta_abd) for iteratively learning the parameters of a neural network (\"perception\" component), and inducing the logical rules underlying a domain (\"reasoning\" component). The rule-learning component is the existing MIL system (with some modifications that are bolded in Figure 2). The paper's ability to learn recursive theories and invent predicates is directly inherited from MIL. Hence, I find its contributions with respect to these two aspects to be incremental at best.\n\nThough interesting, I find that significant details about the Meta_abd's EM model are omitted, and this prevents one from ascertaining Meta_abd's true effectiveness (please see questions below).\n\nFurther, EM as a framework for bridging noisy inputs and symbolic reasoning has been explored by prior work (the pLogic, ExpressGNN, and pGAT systems listed below). Could the authors position Meta_abd vis-a-vis these systems, and mention them as related work? Meta_abd's \"neural probabilistic facts\" map to uncertain knowledge graph triples in these systems (the \"ground logical expressions\" mentioned in Section 3.1 of the paper), and Meta_abd's neural network's parameters map to entities' embeddings. Like Meta-abd's logical component, the logical part of these systems are used to infer the probabilities of the triples (neural probabilistic facts), which in turn are used to train an embedding model. The difference between these prior systems and Meta_abd is that Meta_abd learns its logical rules whereas the previous systems require the rules to be pre-specified. In the context of these existing systems, the contribution of Meta_abd appears to lie only in learning rules with the existing MIL system, and thus seems moderately incremental.\n\n\n* Probabilistic Logic Neural Networks for Reasoning. Qu and Tang, 2019\n* Efficient Probabilistic Logic Reasoning with Graph Neural Networks, Zhang et al., 2020\n* Probabilistic Logic Graph Attention Networks for Reasoning, Vardhan et al., 2020\n\n\n\nQUESTIONS\n\n* Page 4, Figure 1: When optimizing the \\theta parameters of the neural network in the M-step, are the labels for each digit image probabilistic? If they are, how are the probabilities derived (e.g., from conflicting pseudo-labels)? If the label per image is deterministic, how is the label chosen?\n\n* Page 5, Eqn 5, step 1: How is H *sampled*? From the paper's description, it seems that H is learned deterministically from themodified MIL (Figure 2). Do you perturb the H returned by MIL probabilistically in some way? If not, how does one justify the claim that H is sampled? (Is H the mode?)\n\n* Page 5, Eqn 5, step 2: How much does the the pruning of z with the abduced constraints help? There is no ablation study to verify the contribution of the abduced constraints.\n\n* Page 5, Eqn 5: How are the parameters and/or rules initialized? EM is particularly sensitive to initialization conditions. This is something that the paper alludes to too on page 7 paragraph 2 (\"converges to saddle points or local optima\"). How does Meta_abd ameliorate this sensitivity? Does it make multiple runs of EM, each from a different initialization? If so, how does it choose the best model? What is the \"success rate\" of these runs, or how many runs are needed to learn a good model? Are the comparison systems treated fairly in being allowed multiple runs too? The answers to these questions would help to elucidate the workings of Meta_abd.\n\n* Page 6, para 2, \"provides a good initialization ... improves the learning performance\". \nHow much does the pre-trained convent help exactly? And from what base?\n\n* Could the authors comment on Meta_abd's scalability? What're its space and time complexity? This information is particularly helpful in view that the empirical evaluation only uses fairly small datasets from a narrow domain.\n\n* Supplementary material, Page 4, Figure 10:\nHow sensitive is Meta_abd to the meta-rules? Would it be fair to say that the meta-rules are cleverly specified to provide a strong enough structural bias for Meta_abd to be able to learn the correct rules? What happens empirically if the meta-rules are removed (one at a time)? These meta-rules seem to imbue Meta_abd with an unfair advantage over the comparison systems.\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1133/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Abductive Knowledge Induction from Raw Data", "authorids": ["~Wang-Zhou_Dai2", "~Stephen_Muggleton1"], "authors": ["Wang-Zhou Dai", "Stephen Muggleton"], "keywords": ["Neural-Symbolic Model", "Inductive Logic Programming", "Abduction"], "abstract": "For many reasoning-heavy tasks, it is challenging to find an appropriate end-to-end differentiable approximation to domain-specific inference mechanisms. Neural-Symbolic (NeSy) AI divides the end-to-end pipeline into neural perception and symbolic reasoning, which can directly exploit general domain knowledge such as algorithms and logic rules. However, it suffers from the exponential computational complexity caused by the interface between the two components, where the neural model lacks direct supervision, and the symbolic model lacks accurate input facts. As a result, they usually focus on learning the neural model with a sound and complete symbolic knowledge base while avoiding a crucial problem: where does the knowledge come from? In this paper, we present Abductive Meta-Interpretive Learning ($Meta_{Abd}$), which unites abduction and induction to learn perceptual neural network and first-order logic theories simultaneously from raw data. Given the same amount of domain knowledge, we demonstrate that $Meta_{Abd}$ not only outperforms the compared end-to-end models in predictive accuracy and data efficiency but also induces logic programs that can be re-used as background knowledge in subsequent learning tasks. To the best of our knowledge, $Meta_{Abd}$ is the first system that can jointly learn neural networks and recursive first-order logic theories with predicate invention.", "one-sentence_summary": "We propose an approach combining abduction and induction to jointly learn neural models and recursive first-order logic programs with predicate invention.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dai|abductive_knowledge_induction_from_raw_data", "supplementary_material": "/attachment/e23429030deac6f4e92abcb9aeb20a95e6e77e45.zip", "pdf": "/pdf/3a7f97a5938549dfd0fa5219a365aa126f660751.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H_yDVmut58", "_bibtex": "@misc{\ndai2021abductive,\ntitle={Abductive Knowledge Induction from Raw Data},\nauthor={Wang-Zhou Dai and Stephen Muggleton},\nyear={2021},\nurl={https://openreview.net/forum?id=UAAJMiVjTY_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "UAAJMiVjTY_", "replyto": "UAAJMiVjTY_", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1133/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538126039, "tmdate": 1606915808698, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1133/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1133/-/Official_Review"}}}, {"id": "5CPJwzn4rM5", "original": null, "number": 2, "cdate": 1603895410771, "ddate": null, "tcdate": 1603895410771, "tmdate": 1605024522151, "tddate": null, "forum": "UAAJMiVjTY_", "replyto": "UAAJMiVjTY_", "invitation": "ICLR.cc/2021/Conference/Paper1133/-/Official_Review", "content": {"title": "Review", "review": "In this paper, the author proposes Meta_abd which is a hybrid model that learns a deep recognition model and FOL rules the same time. The goal of this work is to learn FOL rules from raw data such as digits presented in image patches in an end-to-end fashion. The model is evaluated with 3 induction benchmarks associated to the MINST digit dataset.\n\nPersonally, I find this paper to be difficult to read and many details in methods and experiments are missing, making it hard to understand the authors' contribution. Given its current state, I would recommend rejection. My concerns are as follows:\n\nMotivation:\n\n- Neural-symbolic integration usually refers to combining logic reasoning into deep model's decision process for better interpretability or sample-efficiency, or to use deep models to help the logic reasoning tasks such as ILP or deduction.\n\n- With that being said, I find the claim for this hybrid model to be unjustified. In Meta_abd, NN is only used for data pre-processing which is completely agnostic to the later logic component.\n\n- In fact, diff-ILP (Evans & Grefenstette, 2018) also uses NN for pre-processing MNIST digits for ILP task which I personally find to be similar to the proposed method, though I'm happy to be proven wrong.\n\nClaims: I find many of the claims in the paper to be ambiguous and lack justifications\n\n- In section 2, the author claims that differentiable ILP methods rely on fully trained NN for pre-processing -  this is untrue, for example NeuralLP is an end2end model that can be extended to the MINST benchmark with a perception module that's jointly trainable\n\n- The author also claims that most existing NeSy systems only utilize a pre-defined knowledge base. I find this claim to be confusing and the author does not discuss how the proposed method has addressed this limitation\n\t\n\nMethod: I find the method to miss many details\n\n- The author defines the learning problem with Eq1 and Eq2 in Section 3.1 and claims to it would be learned through EM. However, Eq1 and 2 do not reveal details about the method, and the exact procedure of EM is unclear to me\n\n- In section 3.3 the author claims the proposed method is an extension of MIL, but this concept is not formally introduced in the paper.\n\n- I find Figure 2 to be difficult to understand - why is Prolog used here? What's the connection of Prolog to the proposed method? It seems to suggest the proposed method is using Prolog for solving the constraints?\n\nExperiment: \n\n- The proposed method is only compared to LSTM and RNN.  The author should include some ILP baselines such as diff-ILP or NeuralLP and substitute the digit image into its ground-truth digit symbol for reference, though I personally think adding a NN pre-processing module is straightforward  as well.\n\n- 3 benchmarks are fairly small consisting of only a few predicates and rules. How does the proposed method scale with the number of predicates and the size of the grounding space?\n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1133/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Abductive Knowledge Induction from Raw Data", "authorids": ["~Wang-Zhou_Dai2", "~Stephen_Muggleton1"], "authors": ["Wang-Zhou Dai", "Stephen Muggleton"], "keywords": ["Neural-Symbolic Model", "Inductive Logic Programming", "Abduction"], "abstract": "For many reasoning-heavy tasks, it is challenging to find an appropriate end-to-end differentiable approximation to domain-specific inference mechanisms. Neural-Symbolic (NeSy) AI divides the end-to-end pipeline into neural perception and symbolic reasoning, which can directly exploit general domain knowledge such as algorithms and logic rules. However, it suffers from the exponential computational complexity caused by the interface between the two components, where the neural model lacks direct supervision, and the symbolic model lacks accurate input facts. As a result, they usually focus on learning the neural model with a sound and complete symbolic knowledge base while avoiding a crucial problem: where does the knowledge come from? In this paper, we present Abductive Meta-Interpretive Learning ($Meta_{Abd}$), which unites abduction and induction to learn perceptual neural network and first-order logic theories simultaneously from raw data. Given the same amount of domain knowledge, we demonstrate that $Meta_{Abd}$ not only outperforms the compared end-to-end models in predictive accuracy and data efficiency but also induces logic programs that can be re-used as background knowledge in subsequent learning tasks. To the best of our knowledge, $Meta_{Abd}$ is the first system that can jointly learn neural networks and recursive first-order logic theories with predicate invention.", "one-sentence_summary": "We propose an approach combining abduction and induction to jointly learn neural models and recursive first-order logic programs with predicate invention.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dai|abductive_knowledge_induction_from_raw_data", "supplementary_material": "/attachment/e23429030deac6f4e92abcb9aeb20a95e6e77e45.zip", "pdf": "/pdf/3a7f97a5938549dfd0fa5219a365aa126f660751.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H_yDVmut58", "_bibtex": "@misc{\ndai2021abductive,\ntitle={Abductive Knowledge Induction from Raw Data},\nauthor={Wang-Zhou Dai and Stephen Muggleton},\nyear={2021},\nurl={https://openreview.net/forum?id=UAAJMiVjTY_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "UAAJMiVjTY_", "replyto": "UAAJMiVjTY_", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1133/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538126039, "tmdate": 1606915808698, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1133/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1133/-/Official_Review"}}}, {"id": "C4imHvOcWH", "original": null, "number": 3, "cdate": 1603921196856, "ddate": null, "tcdate": 1603921196856, "tmdate": 1605024522086, "tddate": null, "forum": "UAAJMiVjTY_", "replyto": "UAAJMiVjTY_", "invitation": "ICLR.cc/2021/Conference/Paper1133/-/Official_Review", "content": {"title": "Review", "review": "Summary.\n\nIn this paper, the authors have presented a framework that combines meta-interpretive learning and the abductive learning of neural networks. The high-level idea is to formulate a unified probabilistic interpretation of the entire algorithm so that both the inductive logic programming module and the neural network modules can be trained jointly from data. The authors have demonstrated the application of the proposed algorithm to learning arithmetic operations and sorting operations by looking at input-output mnist digits.\n\nComments.\nThe key idea of the paper has been presented clearly. The authors demonstrated two tasks: cumulative sum/product, and sorting. Both tasks require learning recursive rules, and the bogosort task requires predicate invention. These are challenging tasks for both neural networks and ILP algorithms.\n\nHowever, my major comments about the paper is that the experiment sections are relatively weak and they have definitely missed some important baseline comparisons. Concretely, taking the cumulative summation task as an example, the MetaAbd model has very strong inductive biases, because of the builtin \"add\" operation and the metarules built into the system, which strongly favors recursive rules of specific forms. However, at least the \"add\" operation was not built into other baselines.\n\nSecond, there have also been many other works trying to solve this task:\n- partial ILP (Evans & Grefenstette, 2018) and machine apperception (Evans et al.,\n2019) that can learn mnist digits with much weaker assumptions: they can even learn the \"succ\" relationship between digits.\n- Neural GPU (Kaiser and Sutskever 2015) that can learn to add multi-digit numbers without any builtin \"add\" operations.\n- Differentiable Neural Computer (https://deepmind.com/blog/article/differentiable-neural-computers)\n- Neural Programmer-Interpreters (Reed et al 2015) and its follow-ups: they support integrating human-written primitive functions (such as the \"add\" operation) with neural networks.\nThe authors are encouraged to make comparisons with these methods as well.\n\nThird, the learned logic rules are relatively simple. This makes me less convinced about the applicability of the paper. The authors have made very strong claims in the abstract/intro about \"To the best of our knowledge, MetaAbd is the first system that can jointly learn neural networks and recursive first-order logic theories with predicate invention.\" For example, partial ILP and machine apperception can do that, too. Recently, there have also been other trials on using relational neural networks for bridging perception and rule learning, such as,\n- Graph Neural Networks (https://arxiv.org/abs/1806.01261)\n- Neural Logic Machines (https://arxiv.org/abs/1904.11694)\n\nOverall, I think this paper is not matching the publication standard of ICLR.\n\nMinor:\nPlease change the latex formatting of the model name. There is currently an extra space between M and e.", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper1133/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Abductive Knowledge Induction from Raw Data", "authorids": ["~Wang-Zhou_Dai2", "~Stephen_Muggleton1"], "authors": ["Wang-Zhou Dai", "Stephen Muggleton"], "keywords": ["Neural-Symbolic Model", "Inductive Logic Programming", "Abduction"], "abstract": "For many reasoning-heavy tasks, it is challenging to find an appropriate end-to-end differentiable approximation to domain-specific inference mechanisms. Neural-Symbolic (NeSy) AI divides the end-to-end pipeline into neural perception and symbolic reasoning, which can directly exploit general domain knowledge such as algorithms and logic rules. However, it suffers from the exponential computational complexity caused by the interface between the two components, where the neural model lacks direct supervision, and the symbolic model lacks accurate input facts. As a result, they usually focus on learning the neural model with a sound and complete symbolic knowledge base while avoiding a crucial problem: where does the knowledge come from? In this paper, we present Abductive Meta-Interpretive Learning ($Meta_{Abd}$), which unites abduction and induction to learn perceptual neural network and first-order logic theories simultaneously from raw data. Given the same amount of domain knowledge, we demonstrate that $Meta_{Abd}$ not only outperforms the compared end-to-end models in predictive accuracy and data efficiency but also induces logic programs that can be re-used as background knowledge in subsequent learning tasks. To the best of our knowledge, $Meta_{Abd}$ is the first system that can jointly learn neural networks and recursive first-order logic theories with predicate invention.", "one-sentence_summary": "We propose an approach combining abduction and induction to jointly learn neural models and recursive first-order logic programs with predicate invention.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dai|abductive_knowledge_induction_from_raw_data", "supplementary_material": "/attachment/e23429030deac6f4e92abcb9aeb20a95e6e77e45.zip", "pdf": "/pdf/3a7f97a5938549dfd0fa5219a365aa126f660751.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H_yDVmut58", "_bibtex": "@misc{\ndai2021abductive,\ntitle={Abductive Knowledge Induction from Raw Data},\nauthor={Wang-Zhou Dai and Stephen Muggleton},\nyear={2021},\nurl={https://openreview.net/forum?id=UAAJMiVjTY_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "UAAJMiVjTY_", "replyto": "UAAJMiVjTY_", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1133/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538126039, "tmdate": 1606915808698, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1133/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1133/-/Official_Review"}}}, {"id": "EvjRWfDQjo8", "original": null, "number": 4, "cdate": 1603923211287, "ddate": null, "tcdate": 1603923211287, "tmdate": 1605024522020, "tddate": null, "forum": "UAAJMiVjTY_", "replyto": "UAAJMiVjTY_", "invitation": "ICLR.cc/2021/Conference/Paper1133/-/Official_Review", "content": {"title": "Potentially exciting, but not explained well enough", "review": "I like the idea of this paper, however the paper seems to be more written to impress rather than inform.\n\nI cannot see how it \"learns ... simultaneously from raw data.\"  I think the interface is in the nn(image=value,prob) but nn() is never explained in the text. I can't work out: what are the inputs? What are the outputs? What. is the relationship between them? Similarly,  prove() used in Figure 2 is never explained; what are the argument? What is the intended interpretation?\n\nIt seems funny to have 0/1 probabilities (equation (4)). Surely there is so much noise that you can't perfectly predict the outputs.\n\nI didn't see how you overcome the exponential complexity promised in the abstract (and why do you think it is caused by the interface?).\n\nIn the experiments, why is MAE (or log MAE) a reasonable measure? What is the accuracy of the correct program? (I think there is supposed to be a correct program you are learning).  Is the correct program in the search space with a non-zero prior?\n\nIs \"Acc\" in table 2 correspond to just predicting the digit? Why is there so much variability? What is the accuracy of nn()?\n\nThe paper needs to be self contained. For example, you need to tell us that #= means equality and what Prolog's permutation  predicate is  (is it related to permute() in Figure 3?)\n\nI understand you are trying to learn the simplest logic program that can produce the output from raw images. What you did at the top-level seems right, but it is not described well enough. You need to provide enough details so that it is reproducible.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1133/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1133/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Abductive Knowledge Induction from Raw Data", "authorids": ["~Wang-Zhou_Dai2", "~Stephen_Muggleton1"], "authors": ["Wang-Zhou Dai", "Stephen Muggleton"], "keywords": ["Neural-Symbolic Model", "Inductive Logic Programming", "Abduction"], "abstract": "For many reasoning-heavy tasks, it is challenging to find an appropriate end-to-end differentiable approximation to domain-specific inference mechanisms. Neural-Symbolic (NeSy) AI divides the end-to-end pipeline into neural perception and symbolic reasoning, which can directly exploit general domain knowledge such as algorithms and logic rules. However, it suffers from the exponential computational complexity caused by the interface between the two components, where the neural model lacks direct supervision, and the symbolic model lacks accurate input facts. As a result, they usually focus on learning the neural model with a sound and complete symbolic knowledge base while avoiding a crucial problem: where does the knowledge come from? In this paper, we present Abductive Meta-Interpretive Learning ($Meta_{Abd}$), which unites abduction and induction to learn perceptual neural network and first-order logic theories simultaneously from raw data. Given the same amount of domain knowledge, we demonstrate that $Meta_{Abd}$ not only outperforms the compared end-to-end models in predictive accuracy and data efficiency but also induces logic programs that can be re-used as background knowledge in subsequent learning tasks. To the best of our knowledge, $Meta_{Abd}$ is the first system that can jointly learn neural networks and recursive first-order logic theories with predicate invention.", "one-sentence_summary": "We propose an approach combining abduction and induction to jointly learn neural models and recursive first-order logic programs with predicate invention.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "dai|abductive_knowledge_induction_from_raw_data", "supplementary_material": "/attachment/e23429030deac6f4e92abcb9aeb20a95e6e77e45.zip", "pdf": "/pdf/3a7f97a5938549dfd0fa5219a365aa126f660751.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=H_yDVmut58", "_bibtex": "@misc{\ndai2021abductive,\ntitle={Abductive Knowledge Induction from Raw Data},\nauthor={Wang-Zhou Dai and Stephen Muggleton},\nyear={2021},\nurl={https://openreview.net/forum?id=UAAJMiVjTY_}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "UAAJMiVjTY_", "replyto": "UAAJMiVjTY_", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1133/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538126039, "tmdate": 1606915808698, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1133/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1133/-/Official_Review"}}}], "count": 18}