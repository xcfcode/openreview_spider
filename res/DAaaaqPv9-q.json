{"notes": [{"id": "DAaaaqPv9-q", "original": "ELd3j8_pDVu", "number": 177, "cdate": 1601308028422, "ddate": null, "tcdate": 1601308028422, "tmdate": 1614985663259, "tddate": null, "forum": "DAaaaqPv9-q", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Self-supervised Graph-level Representation Learning with Local and Global Structure", "authorids": ["~Minghao_Xu1", "~Hang_Wang1", "~Bingbing_Ni3", "~Hongyu_Guo1", "~Jian_Tang1"], "authors": ["Minghao Xu", "Hang Wang", "Bingbing Ni", "Hongyu Guo", "Jian Tang"], "keywords": ["Self-supervised Representation Learning", "Graph Representation Learning", "Hierarchical Semantic Learning"], "abstract": "This paper focuses on unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks including drug and material discovery. Current methods can effectively model the local structure between different graph instances, but they fail to discover the global semantic structure of the entire dataset. In this work, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local instance-level structure, GraphLoG leverages a nonparametric strategy to learn hierarchical prototypes of the data. These prototypes capture the semantic clusters in the latent space, and the number of prototypes can automatically adapt to different feature distributions. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark datasets demonstrate the effectiveness of our approach. ", "one-sentence_summary": "This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|selfsupervised_graphlevel_representation_learning_with_local_and_global_structure", "supplementary_material": "/attachment/5d9e09603b2a9b000859921b7fe4e1ddc1ccef83.zip", "pdf": "/pdf/2fe3e8d8c91ff90b4960cc121baf1bcb727dde10.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ittVdeg0zj", "_bibtex": "@misc{\nxu2021selfsupervised,\ntitle={Self-supervised Graph-level Representation Learning with Local and Global Structure},\nauthor={Minghao Xu and Hang Wang and Bingbing Ni and Hongyu Guo and Jian Tang},\nyear={2021},\nurl={https://openreview.net/forum?id=DAaaaqPv9-q}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 22, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "CaHh-afTcf", "original": null, "number": 1, "cdate": 1610040498593, "ddate": null, "tcdate": 1610040498593, "tmdate": 1610474105119, "tddate": null, "forum": "DAaaaqPv9-q", "replyto": "DAaaaqPv9-q", "invitation": "ICLR.cc/2021/Conference/Paper177/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "This paper proposes a self-supervised learning method for learning representations for graph-structured data, with both local and global objectives. The local objective aims to maximize the mutual information between two correlated graphs generated with attribute masking [Hu et al. 19], with the InfoNCE loss [van den Oord et al. 18], and the global objective aims to cluster the graphs using the RPCL [Xu et al. 93] objective, which pulls the sample toward the closest cluster while pushing it away from the rival clusters. The proposed method is validated on standard graph classification benchmarks by training a linear classifier on top of the GNN pre-trained with it, and the results show that it largely outperforms existing graph pre-training methods. \n\nThis paper fell into a borderline case, receiving split reviews with two of the reviewers learning toward rejection, and two others proposing to accept. The reviewers in general agreed that the experimental validation is thorough (except for one reviewer), and some of the reviewers mentioned that the proposed idea of performing self-supervised learning at both local and global level makes sense. However, the negative reviewers were concerned with the limited novelty of the proposed method, since the proposed method seems like a simple combination of two objectives each of which are based on existing ideas (although the latter has not been explored for GNN pre-training). The reviewers had interactive discussions with the authors, and the authors provided detailed feedback. Yet, the reviewers were not convinced that the method has sufficient novelty to warrant publication even after the internal discussion period, and decided to keep their negative ratings.\n\nI believe that this is a simple yet effective pre-training method for GNNs on graph-structured data. The proposed method of combining the local and global objective seems like a promising solution to learn a metric space that well-captures the graph-level similarity and also is well-separated for discriminative classification, and it may have some practical impact given its good performance on benchmark datasets. However, as the two negative reviewers mentioned, the paper in its current form is presented as a simple combination of existing approaches. The local objective is a slight modification of attribute masking strategy of [Hu et al. 19], and the global objective of clustering has been explored in self-supervised learning of CNNs for image data [Asano et al. 20]. Thus, I lean toward rejecting the paper, considering its relative novelty and quality. \n\nHowever, I find the proposed work highly promising, and encourage the authors to further develop the method while also improving on the paper writing. I suggest the authors to focus more on the main idea of learning with both local and global objectives, without specifically tying each objective to any of the existing methods. The authors may consider various techniques for both local and global objectives (such as hinge loss-based contrastive loss with k-means clustering as shown in the response to R3), and suggest the proposed work as a more general framework.  \n\n[Asano et al. 20] Self-Labeling via Simultaneous Clustering and Representation Learning, ICLR 2020"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-supervised Graph-level Representation Learning with Local and Global Structure", "authorids": ["~Minghao_Xu1", "~Hang_Wang1", "~Bingbing_Ni3", "~Hongyu_Guo1", "~Jian_Tang1"], "authors": ["Minghao Xu", "Hang Wang", "Bingbing Ni", "Hongyu Guo", "Jian Tang"], "keywords": ["Self-supervised Representation Learning", "Graph Representation Learning", "Hierarchical Semantic Learning"], "abstract": "This paper focuses on unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks including drug and material discovery. Current methods can effectively model the local structure between different graph instances, but they fail to discover the global semantic structure of the entire dataset. In this work, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local instance-level structure, GraphLoG leverages a nonparametric strategy to learn hierarchical prototypes of the data. These prototypes capture the semantic clusters in the latent space, and the number of prototypes can automatically adapt to different feature distributions. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark datasets demonstrate the effectiveness of our approach. ", "one-sentence_summary": "This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|selfsupervised_graphlevel_representation_learning_with_local_and_global_structure", "supplementary_material": "/attachment/5d9e09603b2a9b000859921b7fe4e1ddc1ccef83.zip", "pdf": "/pdf/2fe3e8d8c91ff90b4960cc121baf1bcb727dde10.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ittVdeg0zj", "_bibtex": "@misc{\nxu2021selfsupervised,\ntitle={Self-supervised Graph-level Representation Learning with Local and Global Structure},\nauthor={Minghao Xu and Hang Wang and Bingbing Ni and Hongyu Guo and Jian Tang},\nyear={2021},\nurl={https://openreview.net/forum?id=DAaaaqPv9-q}\n}"}, "tags": [], "invitation": {"reply": {"forum": "DAaaaqPv9-q", "replyto": "DAaaaqPv9-q", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040498581, "tmdate": 1610474105100, "id": "ICLR.cc/2021/Conference/Paper177/-/Decision"}}}, {"id": "lVaICbG3nWr", "original": null, "number": 18, "cdate": 1606271234357, "ddate": null, "tcdate": 1606271234357, "tmdate": 1606289308908, "tddate": null, "forum": "DAaaaqPv9-q", "replyto": "sV_pbElOkH", "invitation": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment", "content": {"title": "Official Response to AnonReviewer3", "comment": "Thanks for your insightful feedback!\n\nExactly as you said, the main contribution of this work lies in modeling the global-semantic structure of graph embeddings via clustering different graphs in a hierarchical fashion. To the best of our knowledge, it is the first attempt to explore the semantic structure of a set of graphs in an unsupervised/self-supervised way. In the proposed GraphLoG framework, this global clustering is established on the local instance-level structure which is an essential prior guarantee for the subsequent clustering. \n\nIn summary, this work embodies its novelty mainly on the global-semantic learning part, and also possesses the contribution of unifying both the local-instance and global-semantic learning into a single framework. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper177/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-supervised Graph-level Representation Learning with Local and Global Structure", "authorids": ["~Minghao_Xu1", "~Hang_Wang1", "~Bingbing_Ni3", "~Hongyu_Guo1", "~Jian_Tang1"], "authors": ["Minghao Xu", "Hang Wang", "Bingbing Ni", "Hongyu Guo", "Jian Tang"], "keywords": ["Self-supervised Representation Learning", "Graph Representation Learning", "Hierarchical Semantic Learning"], "abstract": "This paper focuses on unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks including drug and material discovery. Current methods can effectively model the local structure between different graph instances, but they fail to discover the global semantic structure of the entire dataset. In this work, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local instance-level structure, GraphLoG leverages a nonparametric strategy to learn hierarchical prototypes of the data. These prototypes capture the semantic clusters in the latent space, and the number of prototypes can automatically adapt to different feature distributions. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark datasets demonstrate the effectiveness of our approach. ", "one-sentence_summary": "This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|selfsupervised_graphlevel_representation_learning_with_local_and_global_structure", "supplementary_material": "/attachment/5d9e09603b2a9b000859921b7fe4e1ddc1ccef83.zip", "pdf": "/pdf/2fe3e8d8c91ff90b4960cc121baf1bcb727dde10.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ittVdeg0zj", "_bibtex": "@misc{\nxu2021selfsupervised,\ntitle={Self-supervised Graph-level Representation Learning with Local and Global Structure},\nauthor={Minghao Xu and Hang Wang and Bingbing Ni and Hongyu Guo and Jian Tang},\nyear={2021},\nurl={https://openreview.net/forum?id=DAaaaqPv9-q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "DAaaaqPv9-q", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper177/Authors|ICLR.cc/2021/Conference/Paper177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873789, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment"}}}, {"id": "FtDCBf4RY8y", "original": null, "number": 20, "cdate": 1606275865648, "ddate": null, "tcdate": 1606275865648, "tmdate": 1606288700490, "tddate": null, "forum": "DAaaaqPv9-q", "replyto": "jR0UpSK7Mzg", "invitation": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment", "content": {"title": "Official Response to AnonReviewer4 ", "comment": "Thanks for your appreciation of our work!\n\nWe further respond to your question as follows:\n\nQ: Can randomly initialized prototypes also work in the proposed GraphLoG model?\n\nA: The results in **Section E.4** mainly illustrate that, when the hierarchical prototypes are initialized with different clustering initialization (i.e. different initial candidate cluster centers in the RPCL algorithm), the performance of the pre-trained model on downstream tasks is not affected so much. \n\nHowever, if we directly use the initial candidate cluster centers as the initial prototypes without conducting RPCL clustering, these prototypes cannot represent the local instance-level structure established by local-instance learning and thus derive random semantic structure that does not match with the graphs in the dataset, which will hurt the GraphLoG model\u2019s ability of producing graph embeddings with meaningful semantic structure. Because of the limitation of time in the discussion period, the experimental verification of this point has not been done, and we will finish it as soon as possible. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper177/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-supervised Graph-level Representation Learning with Local and Global Structure", "authorids": ["~Minghao_Xu1", "~Hang_Wang1", "~Bingbing_Ni3", "~Hongyu_Guo1", "~Jian_Tang1"], "authors": ["Minghao Xu", "Hang Wang", "Bingbing Ni", "Hongyu Guo", "Jian Tang"], "keywords": ["Self-supervised Representation Learning", "Graph Representation Learning", "Hierarchical Semantic Learning"], "abstract": "This paper focuses on unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks including drug and material discovery. Current methods can effectively model the local structure between different graph instances, but they fail to discover the global semantic structure of the entire dataset. In this work, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local instance-level structure, GraphLoG leverages a nonparametric strategy to learn hierarchical prototypes of the data. These prototypes capture the semantic clusters in the latent space, and the number of prototypes can automatically adapt to different feature distributions. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark datasets demonstrate the effectiveness of our approach. ", "one-sentence_summary": "This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|selfsupervised_graphlevel_representation_learning_with_local_and_global_structure", "supplementary_material": "/attachment/5d9e09603b2a9b000859921b7fe4e1ddc1ccef83.zip", "pdf": "/pdf/2fe3e8d8c91ff90b4960cc121baf1bcb727dde10.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ittVdeg0zj", "_bibtex": "@misc{\nxu2021selfsupervised,\ntitle={Self-supervised Graph-level Representation Learning with Local and Global Structure},\nauthor={Minghao Xu and Hang Wang and Bingbing Ni and Hongyu Guo and Jian Tang},\nyear={2021},\nurl={https://openreview.net/forum?id=DAaaaqPv9-q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "DAaaaqPv9-q", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper177/Authors|ICLR.cc/2021/Conference/Paper177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873789, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment"}}}, {"id": "jR0UpSK7Mzg", "original": null, "number": 19, "cdate": 1606271314527, "ddate": null, "tcdate": 1606271314527, "tmdate": 1606271314527, "tddate": null, "forum": "DAaaaqPv9-q", "replyto": "FAm9-78C9-t", "invitation": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment", "content": {"title": "An interesting work for self-supervised graph representation learning", "comment": "To my best knowledge, this is the first work that learns graph embedding by exploiting the clustering structure of graphs and proves its effectiveness by detailed experiments.\n\n-For Q2, does the result mean the initialization of the prototypes is not important? How about use random initialization?"}, "signatures": ["ICLR.cc/2021/Conference/Paper177/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-supervised Graph-level Representation Learning with Local and Global Structure", "authorids": ["~Minghao_Xu1", "~Hang_Wang1", "~Bingbing_Ni3", "~Hongyu_Guo1", "~Jian_Tang1"], "authors": ["Minghao Xu", "Hang Wang", "Bingbing Ni", "Hongyu Guo", "Jian Tang"], "keywords": ["Self-supervised Representation Learning", "Graph Representation Learning", "Hierarchical Semantic Learning"], "abstract": "This paper focuses on unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks including drug and material discovery. Current methods can effectively model the local structure between different graph instances, but they fail to discover the global semantic structure of the entire dataset. In this work, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local instance-level structure, GraphLoG leverages a nonparametric strategy to learn hierarchical prototypes of the data. These prototypes capture the semantic clusters in the latent space, and the number of prototypes can automatically adapt to different feature distributions. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark datasets demonstrate the effectiveness of our approach. ", "one-sentence_summary": "This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|selfsupervised_graphlevel_representation_learning_with_local_and_global_structure", "supplementary_material": "/attachment/5d9e09603b2a9b000859921b7fe4e1ddc1ccef83.zip", "pdf": "/pdf/2fe3e8d8c91ff90b4960cc121baf1bcb727dde10.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ittVdeg0zj", "_bibtex": "@misc{\nxu2021selfsupervised,\ntitle={Self-supervised Graph-level Representation Learning with Local and Global Structure},\nauthor={Minghao Xu and Hang Wang and Bingbing Ni and Hongyu Guo and Jian Tang},\nyear={2021},\nurl={https://openreview.net/forum?id=DAaaaqPv9-q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "DAaaaqPv9-q", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper177/Authors|ICLR.cc/2021/Conference/Paper177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873789, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment"}}}, {"id": "sV_pbElOkH", "original": null, "number": 17, "cdate": 1606238402327, "ddate": null, "tcdate": 1606238402327, "tmdate": 1606238402327, "tddate": null, "forum": "DAaaaqPv9-q", "replyto": "y49jRnRy45N", "invitation": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment", "content": {"title": "on novelty of the work", "comment": "This work has three main components: \n(1) identify local views/parts of a graph, \n(2) enfoce contrastive loss, and \n(3) enforce a global clustering.\n\nAmong them, (1) follows a masking idea already proposed; for (2), Regardless of the hinge loss or mutual information loss, both are known in the literature and the idea of contrastive representation learning is not new, and so not a contribution. \n\nThen the main novelty of the work is to add a component of global clustering on top of the contrastive loss. I feel that the novelty of the work is still a concern.  "}, "signatures": ["ICLR.cc/2021/Conference/Paper177/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-supervised Graph-level Representation Learning with Local and Global Structure", "authorids": ["~Minghao_Xu1", "~Hang_Wang1", "~Bingbing_Ni3", "~Hongyu_Guo1", "~Jian_Tang1"], "authors": ["Minghao Xu", "Hang Wang", "Bingbing Ni", "Hongyu Guo", "Jian Tang"], "keywords": ["Self-supervised Representation Learning", "Graph Representation Learning", "Hierarchical Semantic Learning"], "abstract": "This paper focuses on unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks including drug and material discovery. Current methods can effectively model the local structure between different graph instances, but they fail to discover the global semantic structure of the entire dataset. In this work, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local instance-level structure, GraphLoG leverages a nonparametric strategy to learn hierarchical prototypes of the data. These prototypes capture the semantic clusters in the latent space, and the number of prototypes can automatically adapt to different feature distributions. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark datasets demonstrate the effectiveness of our approach. ", "one-sentence_summary": "This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|selfsupervised_graphlevel_representation_learning_with_local_and_global_structure", "supplementary_material": "/attachment/5d9e09603b2a9b000859921b7fe4e1ddc1ccef83.zip", "pdf": "/pdf/2fe3e8d8c91ff90b4960cc121baf1bcb727dde10.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ittVdeg0zj", "_bibtex": "@misc{\nxu2021selfsupervised,\ntitle={Self-supervised Graph-level Representation Learning with Local and Global Structure},\nauthor={Minghao Xu and Hang Wang and Bingbing Ni and Hongyu Guo and Jian Tang},\nyear={2021},\nurl={https://openreview.net/forum?id=DAaaaqPv9-q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "DAaaaqPv9-q", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper177/Authors|ICLR.cc/2021/Conference/Paper177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873789, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment"}}}, {"id": "LqJCuONt-zR", "original": null, "number": 16, "cdate": 1606223552270, "ddate": null, "tcdate": 1606223552270, "tmdate": 1606223552270, "tddate": null, "forum": "DAaaaqPv9-q", "replyto": "w3qHnI1IXyh", "invitation": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment", "content": {"title": "Official Response to AnonReviewer2", "comment": "Thanks for your insightful feedback and careful review of the revised paper!\n\nWe further respond to your questions as follows:\n\nQ1: In many datasets, the number of categories is limited, which makes it hard to construct hierarchical prototypes with effective structure.\n\nA1: As you said, some datasets in MoleculeNet (i.e. BBBP, HIV and BACE) contain only one binary classification task and thus two categories for constructing bottom layer prototypes. Therefore, for implementing the sup-GraphLoG model on various datasets, we use different depths of hierarchical prototypes, as listed in Table A. We would like to point out that, in the proposed model, the complexity of such semantic hierarchy is determined by the tasks studied in various datasets, *i.e.* the structure of hierarchical prototypes is task-specific. As a result, although the semantic hierarchy is quite simple for some datasets (containing only one hierarchy), the hierarchical prototypes are able to refine the structure of graph embeddings according to the tasks studied in each dataset.\n\nTable A: The depth of hierarchical prototypes for different datasets in MoleculeNet.\n \n|Dataset|BBBP|Tox21|ToxCast|SIDER|ClinTox|MUV|HIV|BACE|\n|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|\n|Number of binary classification tasks|1|12|617|27|2|17|1|1|\n|Depth of hierarchical prototypes|1|2|4|3|2|2|1|1|\n\nQ2: How can the correlated graph pairs obtained by attribute masking effectively constrain the structure of graph embeddings?\n\nA2: We think the global-semantic loss (**Eq. (13)**) plays a critical role in constraining the global structure of graph embeddings. In specific, it can push the embeddings of the graphs with different structures but potentially similar semantics towards the same prototypes, such that the graph embeddings within a semantic cluster are embedded more compactly. Such statement is also demonstrated by the t-SNE visualization results on ZINC15 database (**Figure 3**), in which the embeddings of different molecules form more compact clusters after applying the global-semantic loss $\\mathcal{L}_{global}$.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper177/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-supervised Graph-level Representation Learning with Local and Global Structure", "authorids": ["~Minghao_Xu1", "~Hang_Wang1", "~Bingbing_Ni3", "~Hongyu_Guo1", "~Jian_Tang1"], "authors": ["Minghao Xu", "Hang Wang", "Bingbing Ni", "Hongyu Guo", "Jian Tang"], "keywords": ["Self-supervised Representation Learning", "Graph Representation Learning", "Hierarchical Semantic Learning"], "abstract": "This paper focuses on unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks including drug and material discovery. Current methods can effectively model the local structure between different graph instances, but they fail to discover the global semantic structure of the entire dataset. In this work, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local instance-level structure, GraphLoG leverages a nonparametric strategy to learn hierarchical prototypes of the data. These prototypes capture the semantic clusters in the latent space, and the number of prototypes can automatically adapt to different feature distributions. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark datasets demonstrate the effectiveness of our approach. ", "one-sentence_summary": "This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|selfsupervised_graphlevel_representation_learning_with_local_and_global_structure", "supplementary_material": "/attachment/5d9e09603b2a9b000859921b7fe4e1ddc1ccef83.zip", "pdf": "/pdf/2fe3e8d8c91ff90b4960cc121baf1bcb727dde10.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ittVdeg0zj", "_bibtex": "@misc{\nxu2021selfsupervised,\ntitle={Self-supervised Graph-level Representation Learning with Local and Global Structure},\nauthor={Minghao Xu and Hang Wang and Bingbing Ni and Hongyu Guo and Jian Tang},\nyear={2021},\nurl={https://openreview.net/forum?id=DAaaaqPv9-q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "DAaaaqPv9-q", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper177/Authors|ICLR.cc/2021/Conference/Paper177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873789, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment"}}}, {"id": "Y38wFBmjJrW", "original": null, "number": 4, "cdate": 1604211060778, "ddate": null, "tcdate": 1604211060778, "tmdate": 1606209328975, "tddate": null, "forum": "DAaaaqPv9-q", "replyto": "DAaaaqPv9-q", "invitation": "ICLR.cc/2021/Conference/Paper177/-/Official_Review", "content": {"title": "Official Blind Review #2", "review": "This paper proposes an unsupervised framework to perform graph representation learning. The local-instance structure is learned by first gets patch-level and graph-level representations for each graph, then maximize the mutual information between both correlated patches and correlated graphs, which are decided by attribute masking strategy. The global-semantic structure is maintained by leveraging RPCL to derive hierarchical prototypes of the representation and maximizing the mutual information between correlated graph representation and the searching path in the prototypes.\n\nStrengths:\n+  This paper presents a framework to jointly consider the local instance structure and global-semantic structure of graphs. It is a meaningful direction and could be beneficial for explainability.\n+  The experimental results are quite thorough with comparisons to several baseline methods. Moreover, the ablation study of different mechanisms is provided in the experiments.\n\nWeaknesses:\n-  The proposed model seems like a simple combination of several existing techniques and thus lacks novelty.\n-  The performance of this model seems to heavily rely on the attribute masking strategy as all the operations are built upon the correlated graph pairing from the attribute masking strategy. But how reliable is this technique? It seems to be a bottleneck of the model, and I think there should be an explanation on this either theoretically or experimentally.\n\nOverall, the proposes a reasonable model for learning hierarchical graph representations. However, the novelty is limited since the proposed method seems like a simple combination of several existing techniques.\n\nQuestions:\n\n1.  As I mentioned earlier, I wonder how reliable the attribute masking strategy is. As graph matching is an extremely hard problem, can this strategy provide a reliable pairing between correlated graphs?\n2.  It is not clear how to leverage prototypes in classification tasks? I understand that the prototypes serve to ensure a better structure of the embeddings, but when classifying graphs, I wonder whether embeddings and prototypes are both used or not?\n3.  In the Constraint for the global-semantic structure part, the loss for a graph embedding includes both the representations for its correlated graph and its searching path consisting of several prototypes. When minimizing the loss, I wonder both representations of the correlated graph and prototypes are updated together? Or the prototypes are only updated in eq. (11) and (12).\n", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper177/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-supervised Graph-level Representation Learning with Local and Global Structure", "authorids": ["~Minghao_Xu1", "~Hang_Wang1", "~Bingbing_Ni3", "~Hongyu_Guo1", "~Jian_Tang1"], "authors": ["Minghao Xu", "Hang Wang", "Bingbing Ni", "Hongyu Guo", "Jian Tang"], "keywords": ["Self-supervised Representation Learning", "Graph Representation Learning", "Hierarchical Semantic Learning"], "abstract": "This paper focuses on unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks including drug and material discovery. Current methods can effectively model the local structure between different graph instances, but they fail to discover the global semantic structure of the entire dataset. In this work, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local instance-level structure, GraphLoG leverages a nonparametric strategy to learn hierarchical prototypes of the data. These prototypes capture the semantic clusters in the latent space, and the number of prototypes can automatically adapt to different feature distributions. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark datasets demonstrate the effectiveness of our approach. ", "one-sentence_summary": "This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|selfsupervised_graphlevel_representation_learning_with_local_and_global_structure", "supplementary_material": "/attachment/5d9e09603b2a9b000859921b7fe4e1ddc1ccef83.zip", "pdf": "/pdf/2fe3e8d8c91ff90b4960cc121baf1bcb727dde10.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ittVdeg0zj", "_bibtex": "@misc{\nxu2021selfsupervised,\ntitle={Self-supervised Graph-level Representation Learning with Local and Global Structure},\nauthor={Minghao Xu and Hang Wang and Bingbing Ni and Hongyu Guo and Jian Tang},\nyear={2021},\nurl={https://openreview.net/forum?id=DAaaaqPv9-q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "DAaaaqPv9-q", "replyto": "DAaaaqPv9-q", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper177/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538148708, "tmdate": 1606915799747, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper177/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper177/-/Official_Review"}}}, {"id": "w3qHnI1IXyh", "original": null, "number": 15, "cdate": 1606209282070, "ddate": null, "tcdate": 1606209282070, "tmdate": 1606209282070, "tddate": null, "forum": "DAaaaqPv9-q", "replyto": "ZJzPCNpK2He", "invitation": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment", "content": {"title": "Feedback to the response", "comment": "Thanks for the detailed response. My previous concerns are partially resolved.\n\nTo employ prototypes for the classification task, the authors design a new supervised setting in which the number of bottom-layer prototypes is set as the number of classes in the dataset. This setting, however, may not be rigorous enough. Some datasets used in the experiments only contain two classes. If the number of bottom-layer prototypes is set as 2, how can the model form a hierarchical prototype structure? Even for the datasets with multiple classes, the number of classes may not be large enough to be used as the number of the bottom-layer prototypes. \n\nAfter reading the theoretical justification of the attribute masking, I realized that the correlated graphs are generated instead of choosing from the dataset. Then my previous concern about graph matching is resolved. However, I\u2019m curious about whether minimizing the representation distance between each graph (patch) and its masked version is sufficient to form a good representation structure? In this way, it seems that only extremely similar graphs (with the same structure and only several node attribute differences) are pulled together while the distance between the majority of the graphs is not well handled. In real-world datasets like chemical molecules, graphs with the same structures may be very rare, so the distance between different graphs may not be well handled in this case. \n\nBesides, the given theoretical justification seems not related to the paper. It states that the repaired information is larger than the mutual information between the masked node and its L-hop neighbors, which implies that the amount of information that can be recovered depends on the amount of information within the masked node that is contained in its neighbors. It is necessary to justify why using attribute masking can ensure a good embedding structure (similar graphs being pulled together and dissimilar ones being pushed apart). It seems to be very difficult and would depend on the types of datasets being used. \n\nOverall, my concerns are partially resolved and I would like to raise my rating from 4 to 5."}, "signatures": ["ICLR.cc/2021/Conference/Paper177/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-supervised Graph-level Representation Learning with Local and Global Structure", "authorids": ["~Minghao_Xu1", "~Hang_Wang1", "~Bingbing_Ni3", "~Hongyu_Guo1", "~Jian_Tang1"], "authors": ["Minghao Xu", "Hang Wang", "Bingbing Ni", "Hongyu Guo", "Jian Tang"], "keywords": ["Self-supervised Representation Learning", "Graph Representation Learning", "Hierarchical Semantic Learning"], "abstract": "This paper focuses on unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks including drug and material discovery. Current methods can effectively model the local structure between different graph instances, but they fail to discover the global semantic structure of the entire dataset. In this work, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local instance-level structure, GraphLoG leverages a nonparametric strategy to learn hierarchical prototypes of the data. These prototypes capture the semantic clusters in the latent space, and the number of prototypes can automatically adapt to different feature distributions. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark datasets demonstrate the effectiveness of our approach. ", "one-sentence_summary": "This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|selfsupervised_graphlevel_representation_learning_with_local_and_global_structure", "supplementary_material": "/attachment/5d9e09603b2a9b000859921b7fe4e1ddc1ccef83.zip", "pdf": "/pdf/2fe3e8d8c91ff90b4960cc121baf1bcb727dde10.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ittVdeg0zj", "_bibtex": "@misc{\nxu2021selfsupervised,\ntitle={Self-supervised Graph-level Representation Learning with Local and Global Structure},\nauthor={Minghao Xu and Hang Wang and Bingbing Ni and Hongyu Guo and Jian Tang},\nyear={2021},\nurl={https://openreview.net/forum?id=DAaaaqPv9-q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "DAaaaqPv9-q", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper177/Authors|ICLR.cc/2021/Conference/Paper177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873789, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment"}}}, {"id": "y49jRnRy45N", "original": null, "number": 14, "cdate": 1606187853229, "ddate": null, "tcdate": 1606187853229, "tmdate": 1606187853229, "tddate": null, "forum": "DAaaaqPv9-q", "replyto": "FaFBw3mrOOB", "invitation": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment", "content": {"title": "Official Response to AnonReviewer3", "comment": "Thanks for your feedback!\n\nWe would like to clarify that the core idea of this work (local-instance and global-semantic learning) can achieve superior performance without the help of existing effective techniques:\n\n1. First, compared with previous methods for self-supervised graph representation learning (e.g. Edge Prediction [a], InfoGraph [b], Context Prediction [c], etc.), the combination of the GraphLoG model with vanilla model components (i.e. hinge-loss-based contrastive loss, K-means clustering), denoted as **GraphLoG-vanilla**, can also achieve superior performance on the biological downstream task, as shown in Table A. This phenomenon illustrates that the GraphLoG model itself can obtain decent performance gain and surpass the state-of-the-art approaches.\n\nTable A: The performance comparison among different self-supervised methods on the biological function prediction benchmark.\n\n|Method|ROC-AUC (%)|\n|:----:|:----:|\n|EdgePred [a]|$70.5\\pm0.7$|\n|InfoGraph [b]|$70.7\\pm0.5$|\n|AttrMasking [c]|$70.5\\pm0.5$|\n|ContextPred [c]|$69.9\\pm0.3$|\n|GraphPartition [d]|$71.0\\pm0.2$|\n|GraphLoG-vanilla|$\\textbf{72.2}\\pm0.4$| \n\n2. Second, we apply the idea of local-instance and global-semantic learning to the supervised setting and use the vanilla model components (i.e. hinge-loss-based contrastive loss, K-means clustering), which is a plain version of the sup-GraphLoG model in **Section 4**, denoted as **sup-GraphLoG-vanilla**. This vanilla supervised model outperforms the Graph Isomorphism Network (GIN) [e] with a clear margin on the biological function prediction benchmark, as shown in Table B.\n\nTable B: The performance comparison between two supervised models on biological function prediction benchmark.\n\n|Method|ROC-AUC (%)|\n|:----:|:----:|\n|GIN [e]|$64.8\\pm1.0$|\n|sup-GraphLoG-vanilla|$\\textbf{66.9}\\pm0.7$|\n\n\n[a] Kipf, Thomas N., and Max Welling. \"Variational graph auto-encoders.\" arXiv:1611.07308 (2016).\n\n[b] Sun, Fan-Yun, et al. \"Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization.\" ICLR, 2020.\n\n[c] Hu, Weihua, et al. \"Strategies for Pre-training Graph Neural Networks.\" ICLR, 2020.\n\n\n[d] You, Yuning, et al. \"When Does Self-Supervision Help Graph Convolutional Networks?.\" ICML, 2020.\n\n[e] Xu, Keyulu, et al. \"How powerful are graph neural networks?.\" ICLR, 2019.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper177/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-supervised Graph-level Representation Learning with Local and Global Structure", "authorids": ["~Minghao_Xu1", "~Hang_Wang1", "~Bingbing_Ni3", "~Hongyu_Guo1", "~Jian_Tang1"], "authors": ["Minghao Xu", "Hang Wang", "Bingbing Ni", "Hongyu Guo", "Jian Tang"], "keywords": ["Self-supervised Representation Learning", "Graph Representation Learning", "Hierarchical Semantic Learning"], "abstract": "This paper focuses on unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks including drug and material discovery. Current methods can effectively model the local structure between different graph instances, but they fail to discover the global semantic structure of the entire dataset. In this work, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local instance-level structure, GraphLoG leverages a nonparametric strategy to learn hierarchical prototypes of the data. These prototypes capture the semantic clusters in the latent space, and the number of prototypes can automatically adapt to different feature distributions. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark datasets demonstrate the effectiveness of our approach. ", "one-sentence_summary": "This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|selfsupervised_graphlevel_representation_learning_with_local_and_global_structure", "supplementary_material": "/attachment/5d9e09603b2a9b000859921b7fe4e1ddc1ccef83.zip", "pdf": "/pdf/2fe3e8d8c91ff90b4960cc121baf1bcb727dde10.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ittVdeg0zj", "_bibtex": "@misc{\nxu2021selfsupervised,\ntitle={Self-supervised Graph-level Representation Learning with Local and Global Structure},\nauthor={Minghao Xu and Hang Wang and Bingbing Ni and Hongyu Guo and Jian Tang},\nyear={2021},\nurl={https://openreview.net/forum?id=DAaaaqPv9-q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "DAaaaqPv9-q", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper177/Authors|ICLR.cc/2021/Conference/Paper177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873789, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment"}}}, {"id": "FaFBw3mrOOB", "original": null, "number": 13, "cdate": 1606164319073, "ddate": null, "tcdate": 1606164319073, "tmdate": 1606164319073, "tddate": null, "forum": "DAaaaqPv9-q", "replyto": "-w8buVLx4o1", "invitation": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment", "content": {"title": "the performance gains are still attributed to the combination of the three main building blocks from literature", "comment": "The Table~5 in the appendix shows that the attribute masking and PPCL and InfoNCE are crucial components for the performance gains of the proposed method. When replaced by vanilla version, the performance drops. In other words, it is by combining these existing technqiues that final performance gains are achieved, which makes the novelty of the paper less significant.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper177/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-supervised Graph-level Representation Learning with Local and Global Structure", "authorids": ["~Minghao_Xu1", "~Hang_Wang1", "~Bingbing_Ni3", "~Hongyu_Guo1", "~Jian_Tang1"], "authors": ["Minghao Xu", "Hang Wang", "Bingbing Ni", "Hongyu Guo", "Jian Tang"], "keywords": ["Self-supervised Representation Learning", "Graph Representation Learning", "Hierarchical Semantic Learning"], "abstract": "This paper focuses on unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks including drug and material discovery. Current methods can effectively model the local structure between different graph instances, but they fail to discover the global semantic structure of the entire dataset. In this work, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local instance-level structure, GraphLoG leverages a nonparametric strategy to learn hierarchical prototypes of the data. These prototypes capture the semantic clusters in the latent space, and the number of prototypes can automatically adapt to different feature distributions. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark datasets demonstrate the effectiveness of our approach. ", "one-sentence_summary": "This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|selfsupervised_graphlevel_representation_learning_with_local_and_global_structure", "supplementary_material": "/attachment/5d9e09603b2a9b000859921b7fe4e1ddc1ccef83.zip", "pdf": "/pdf/2fe3e8d8c91ff90b4960cc121baf1bcb727dde10.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ittVdeg0zj", "_bibtex": "@misc{\nxu2021selfsupervised,\ntitle={Self-supervised Graph-level Representation Learning with Local and Global Structure},\nauthor={Minghao Xu and Hang Wang and Bingbing Ni and Hongyu Guo and Jian Tang},\nyear={2021},\nurl={https://openreview.net/forum?id=DAaaaqPv9-q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "DAaaaqPv9-q", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper177/Authors|ICLR.cc/2021/Conference/Paper177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873789, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment"}}}, {"id": "3tguWHr4c8", "original": null, "number": 12, "cdate": 1606133473140, "ddate": null, "tcdate": 1606133473140, "tmdate": 1606133473140, "tddate": null, "forum": "DAaaaqPv9-q", "replyto": "AIwlhBeS8Ij", "invitation": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment", "content": {"title": "Feedback necessary", "comment": "Dear reviewer, \n\nThe authors have responded to your comments below. Could you please go over the response and give feedback to the authors sometime soon? The interactive discussion deadline is this Tuesday and you will not be able to interact with the authors after the date.\n\nThanks,\nAC"}, "signatures": ["ICLR.cc/2021/Conference/Paper177/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-supervised Graph-level Representation Learning with Local and Global Structure", "authorids": ["~Minghao_Xu1", "~Hang_Wang1", "~Bingbing_Ni3", "~Hongyu_Guo1", "~Jian_Tang1"], "authors": ["Minghao Xu", "Hang Wang", "Bingbing Ni", "Hongyu Guo", "Jian Tang"], "keywords": ["Self-supervised Representation Learning", "Graph Representation Learning", "Hierarchical Semantic Learning"], "abstract": "This paper focuses on unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks including drug and material discovery. Current methods can effectively model the local structure between different graph instances, but they fail to discover the global semantic structure of the entire dataset. In this work, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local instance-level structure, GraphLoG leverages a nonparametric strategy to learn hierarchical prototypes of the data. These prototypes capture the semantic clusters in the latent space, and the number of prototypes can automatically adapt to different feature distributions. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark datasets demonstrate the effectiveness of our approach. ", "one-sentence_summary": "This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|selfsupervised_graphlevel_representation_learning_with_local_and_global_structure", "supplementary_material": "/attachment/5d9e09603b2a9b000859921b7fe4e1ddc1ccef83.zip", "pdf": "/pdf/2fe3e8d8c91ff90b4960cc121baf1bcb727dde10.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ittVdeg0zj", "_bibtex": "@misc{\nxu2021selfsupervised,\ntitle={Self-supervised Graph-level Representation Learning with Local and Global Structure},\nauthor={Minghao Xu and Hang Wang and Bingbing Ni and Hongyu Guo and Jian Tang},\nyear={2021},\nurl={https://openreview.net/forum?id=DAaaaqPv9-q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "DAaaaqPv9-q", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper177/Authors|ICLR.cc/2021/Conference/Paper177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873789, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment"}}}, {"id": "kqaztaZiu1", "original": null, "number": 11, "cdate": 1606133452011, "ddate": null, "tcdate": 1606133452011, "tmdate": 1606133452011, "tddate": null, "forum": "DAaaaqPv9-q", "replyto": "jSgse61B9ao", "invitation": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment", "content": {"title": "Feedback necessary", "comment": "Dear reviewer, \n\nThe authors have responded to your comments below. Could you please go over the response and give feedback to the authors sometime soon? The interactive discussion deadline is this Tuesday and you will not be able to interact with the authors after the date.\n\nThanks,\nAC"}, "signatures": ["ICLR.cc/2021/Conference/Paper177/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-supervised Graph-level Representation Learning with Local and Global Structure", "authorids": ["~Minghao_Xu1", "~Hang_Wang1", "~Bingbing_Ni3", "~Hongyu_Guo1", "~Jian_Tang1"], "authors": ["Minghao Xu", "Hang Wang", "Bingbing Ni", "Hongyu Guo", "Jian Tang"], "keywords": ["Self-supervised Representation Learning", "Graph Representation Learning", "Hierarchical Semantic Learning"], "abstract": "This paper focuses on unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks including drug and material discovery. Current methods can effectively model the local structure between different graph instances, but they fail to discover the global semantic structure of the entire dataset. In this work, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local instance-level structure, GraphLoG leverages a nonparametric strategy to learn hierarchical prototypes of the data. These prototypes capture the semantic clusters in the latent space, and the number of prototypes can automatically adapt to different feature distributions. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark datasets demonstrate the effectiveness of our approach. ", "one-sentence_summary": "This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|selfsupervised_graphlevel_representation_learning_with_local_and_global_structure", "supplementary_material": "/attachment/5d9e09603b2a9b000859921b7fe4e1ddc1ccef83.zip", "pdf": "/pdf/2fe3e8d8c91ff90b4960cc121baf1bcb727dde10.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ittVdeg0zj", "_bibtex": "@misc{\nxu2021selfsupervised,\ntitle={Self-supervised Graph-level Representation Learning with Local and Global Structure},\nauthor={Minghao Xu and Hang Wang and Bingbing Ni and Hongyu Guo and Jian Tang},\nyear={2021},\nurl={https://openreview.net/forum?id=DAaaaqPv9-q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "DAaaaqPv9-q", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper177/Authors|ICLR.cc/2021/Conference/Paper177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873789, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment"}}}, {"id": "4-0FFKYXY1j", "original": null, "number": 10, "cdate": 1606133427527, "ddate": null, "tcdate": 1606133427527, "tmdate": 1606133427527, "tddate": null, "forum": "DAaaaqPv9-q", "replyto": "b4uaKv95lCI", "invitation": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment", "content": {"title": "Feedback necessary", "comment": "Dear reviewer, \n\nThe authors have responded to your comments below. Could you please go over the response and give feedback to the authors sometime soon? The interactive discussion deadline is this Tuesday and you will not be able to interact with the authors after the date.\n\nThanks,\nAC"}, "signatures": ["ICLR.cc/2021/Conference/Paper177/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-supervised Graph-level Representation Learning with Local and Global Structure", "authorids": ["~Minghao_Xu1", "~Hang_Wang1", "~Bingbing_Ni3", "~Hongyu_Guo1", "~Jian_Tang1"], "authors": ["Minghao Xu", "Hang Wang", "Bingbing Ni", "Hongyu Guo", "Jian Tang"], "keywords": ["Self-supervised Representation Learning", "Graph Representation Learning", "Hierarchical Semantic Learning"], "abstract": "This paper focuses on unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks including drug and material discovery. Current methods can effectively model the local structure between different graph instances, but they fail to discover the global semantic structure of the entire dataset. In this work, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local instance-level structure, GraphLoG leverages a nonparametric strategy to learn hierarchical prototypes of the data. These prototypes capture the semantic clusters in the latent space, and the number of prototypes can automatically adapt to different feature distributions. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark datasets demonstrate the effectiveness of our approach. ", "one-sentence_summary": "This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|selfsupervised_graphlevel_representation_learning_with_local_and_global_structure", "supplementary_material": "/attachment/5d9e09603b2a9b000859921b7fe4e1ddc1ccef83.zip", "pdf": "/pdf/2fe3e8d8c91ff90b4960cc121baf1bcb727dde10.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ittVdeg0zj", "_bibtex": "@misc{\nxu2021selfsupervised,\ntitle={Self-supervised Graph-level Representation Learning with Local and Global Structure},\nauthor={Minghao Xu and Hang Wang and Bingbing Ni and Hongyu Guo and Jian Tang},\nyear={2021},\nurl={https://openreview.net/forum?id=DAaaaqPv9-q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "DAaaaqPv9-q", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper177/Authors|ICLR.cc/2021/Conference/Paper177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873789, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment"}}}, {"id": "4gg5BOeokp8", "original": null, "number": 9, "cdate": 1606133407686, "ddate": null, "tcdate": 1606133407686, "tmdate": 1606133407686, "tddate": null, "forum": "DAaaaqPv9-q", "replyto": "Y38wFBmjJrW", "invitation": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment", "content": {"title": "Feedback necessary", "comment": "Dear reviewer, \n\nThe authors have responded to your comments below. Could you please go over the response and give feedback to the authors sometime soon? The interactive discussion deadline is this Tuesday and you will not be able to interact with the authors after the date.\n\nThanks,\nAC"}, "signatures": ["ICLR.cc/2021/Conference/Paper177/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-supervised Graph-level Representation Learning with Local and Global Structure", "authorids": ["~Minghao_Xu1", "~Hang_Wang1", "~Bingbing_Ni3", "~Hongyu_Guo1", "~Jian_Tang1"], "authors": ["Minghao Xu", "Hang Wang", "Bingbing Ni", "Hongyu Guo", "Jian Tang"], "keywords": ["Self-supervised Representation Learning", "Graph Representation Learning", "Hierarchical Semantic Learning"], "abstract": "This paper focuses on unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks including drug and material discovery. Current methods can effectively model the local structure between different graph instances, but they fail to discover the global semantic structure of the entire dataset. In this work, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local instance-level structure, GraphLoG leverages a nonparametric strategy to learn hierarchical prototypes of the data. These prototypes capture the semantic clusters in the latent space, and the number of prototypes can automatically adapt to different feature distributions. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark datasets demonstrate the effectiveness of our approach. ", "one-sentence_summary": "This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|selfsupervised_graphlevel_representation_learning_with_local_and_global_structure", "supplementary_material": "/attachment/5d9e09603b2a9b000859921b7fe4e1ddc1ccef83.zip", "pdf": "/pdf/2fe3e8d8c91ff90b4960cc121baf1bcb727dde10.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ittVdeg0zj", "_bibtex": "@misc{\nxu2021selfsupervised,\ntitle={Self-supervised Graph-level Representation Learning with Local and Global Structure},\nauthor={Minghao Xu and Hang Wang and Bingbing Ni and Hongyu Guo and Jian Tang},\nyear={2021},\nurl={https://openreview.net/forum?id=DAaaaqPv9-q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "DAaaaqPv9-q", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper177/Authors|ICLR.cc/2021/Conference/Paper177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873789, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment"}}}, {"id": "J5ddwmXC3L4", "original": null, "number": 8, "cdate": 1605887298601, "ddate": null, "tcdate": 1605887298601, "tmdate": 1606096839225, "tddate": null, "forum": "DAaaaqPv9-q", "replyto": "DAaaaqPv9-q", "invitation": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment", "content": {"title": "The end of the discussion phase approaching", "comment": "Dear Reviewers,\n\nThe authors have provided detailed responses to your comments. Could you please go over the responses from the reviewers, read the revision, and provide feedback since the authors can have interactions with you only by this Tuesday (24th)?. I sincerely thank you for your service in reviewing for ICLR. \n\nThanks, Area Chair\n\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper177/Area_Chair1"], "readers": ["ICLR.cc/2021/Conference/Paper177/Area_Chairs", "everyone", "ICLR.cc/2021/Conference/Paper177/Reviewers"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-supervised Graph-level Representation Learning with Local and Global Structure", "authorids": ["~Minghao_Xu1", "~Hang_Wang1", "~Bingbing_Ni3", "~Hongyu_Guo1", "~Jian_Tang1"], "authors": ["Minghao Xu", "Hang Wang", "Bingbing Ni", "Hongyu Guo", "Jian Tang"], "keywords": ["Self-supervised Representation Learning", "Graph Representation Learning", "Hierarchical Semantic Learning"], "abstract": "This paper focuses on unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks including drug and material discovery. Current methods can effectively model the local structure between different graph instances, but they fail to discover the global semantic structure of the entire dataset. In this work, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local instance-level structure, GraphLoG leverages a nonparametric strategy to learn hierarchical prototypes of the data. These prototypes capture the semantic clusters in the latent space, and the number of prototypes can automatically adapt to different feature distributions. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark datasets demonstrate the effectiveness of our approach. ", "one-sentence_summary": "This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|selfsupervised_graphlevel_representation_learning_with_local_and_global_structure", "supplementary_material": "/attachment/5d9e09603b2a9b000859921b7fe4e1ddc1ccef83.zip", "pdf": "/pdf/2fe3e8d8c91ff90b4960cc121baf1bcb727dde10.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ittVdeg0zj", "_bibtex": "@misc{\nxu2021selfsupervised,\ntitle={Self-supervised Graph-level Representation Learning with Local and Global Structure},\nauthor={Minghao Xu and Hang Wang and Bingbing Ni and Hongyu Guo and Jian Tang},\nyear={2021},\nurl={https://openreview.net/forum?id=DAaaaqPv9-q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "DAaaaqPv9-q", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper177/Authors|ICLR.cc/2021/Conference/Paper177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873789, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment"}}}, {"id": "FAm9-78C9-t", "original": null, "number": 6, "cdate": 1605578150882, "ddate": null, "tcdate": 1605578150882, "tmdate": 1605593578216, "tddate": null, "forum": "DAaaaqPv9-q", "replyto": "jSgse61B9ao", "invitation": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment", "content": {"title": "Official Response to AnonReviewer4", "comment": "Thanks very much for your recognition in our work! \n \nWe address your two concerns as follows: \n\nQ1: The number of prototypes determined by RPCL cannot be adjusted during training.\n\nA1: In the **Section E.3** of appendix, we design an adaptive variant of RPCL clustering (Adaptive-RPCL) which is able to adjust the number of prototypes during training. Its performance on biological downstream task is comparable with that of vanilla RPCL clustering algorithm in our method, which shows that the proposed GraphLoG model is not too sensitive to the selection of clustering algorithm.\n\nQ2: Is the performance of GraphLoG robust to different clustering outputs?\n\nA2: In the **Section E.4** of appendix, we compare the performance of six pre-trained models derived by different clustering results. It is observed that the downstream task performance of these models is comparable with each other, which demonstrates that the GraphLoG model is fairly robust to different clustering outputs.\n \n\n**In the revised paper, you can refer to the bolded sections above for the detailed experimental results.**"}, "signatures": ["ICLR.cc/2021/Conference/Paper177/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-supervised Graph-level Representation Learning with Local and Global Structure", "authorids": ["~Minghao_Xu1", "~Hang_Wang1", "~Bingbing_Ni3", "~Hongyu_Guo1", "~Jian_Tang1"], "authors": ["Minghao Xu", "Hang Wang", "Bingbing Ni", "Hongyu Guo", "Jian Tang"], "keywords": ["Self-supervised Representation Learning", "Graph Representation Learning", "Hierarchical Semantic Learning"], "abstract": "This paper focuses on unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks including drug and material discovery. Current methods can effectively model the local structure between different graph instances, but they fail to discover the global semantic structure of the entire dataset. In this work, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local instance-level structure, GraphLoG leverages a nonparametric strategy to learn hierarchical prototypes of the data. These prototypes capture the semantic clusters in the latent space, and the number of prototypes can automatically adapt to different feature distributions. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark datasets demonstrate the effectiveness of our approach. ", "one-sentence_summary": "This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|selfsupervised_graphlevel_representation_learning_with_local_and_global_structure", "supplementary_material": "/attachment/5d9e09603b2a9b000859921b7fe4e1ddc1ccef83.zip", "pdf": "/pdf/2fe3e8d8c91ff90b4960cc121baf1bcb727dde10.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ittVdeg0zj", "_bibtex": "@misc{\nxu2021selfsupervised,\ntitle={Self-supervised Graph-level Representation Learning with Local and Global Structure},\nauthor={Minghao Xu and Hang Wang and Bingbing Ni and Hongyu Guo and Jian Tang},\nyear={2021},\nurl={https://openreview.net/forum?id=DAaaaqPv9-q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "DAaaaqPv9-q", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper177/Authors|ICLR.cc/2021/Conference/Paper177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873789, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment"}}}, {"id": "-w8buVLx4o1", "original": null, "number": 7, "cdate": 1605578522347, "ddate": null, "tcdate": 1605578522347, "tmdate": 1605593113289, "tddate": null, "forum": "DAaaaqPv9-q", "replyto": "AIwlhBeS8Ij", "invitation": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment", "content": {"title": "Official Response to AnonReviewer3", "comment": "Thanks for your insightful comments and great suggestions, which definitely help us improve the quality of this work. \n \nWe respond to your concerns about the novelty of this work as follows:\n\nQ1: The combination of too many existing techniques shadows the novelty of this work.\n\nA1: Our core idea is to learn both the local-instance and global-semantic structure of a set of graphs in a self-supervised fashion. This problem, to the best of our knowledge, has not been explored by previous works, which makes the proposed GraphLoG model novel as a whole. Indeed, some existing techniques, i.e. attribute masking [a], InfoNCE loss [b] and RPCL clustering [c], have been adopted to construct the entire model. However, the additional ablation studies in the **Section E** of appendix show that these techniques (except attribute masking) can be replaced by their vanilla counterparts without too much hurt to model\u2019s performance, which demonstrates the effectiveness of local-instance and global-semantic learning, i.e. the key idea of this work.\n\nQ2: If we combine a plain GNN with hierarchical prototypes, can this model achieve superior performance?\n\nA2: Following your suggestion, we further design a supervised variant of GraphLoG, named as sup-GraphLoG, in **Section 4**. The sup-GraphLoG model establishes hierarchical prototypes on top of a plain GNN and performs graph classification by measuring the similarity between graph embeddings and prototypes. This model outperforms the plain GNN on chemical and biological benchmark datasets (shown in **Tabs. 1 and 2**), which illustrates the effectiveness of global-semantic learning under the supervised setting. \n\nIn addition, we would like to point out that the sup-GraphLoG model does not perform as well as the GraphLoG model, which demonstrates the necessity of self-supervised pre-training on massive unlabeled graphs.\n\n\n**In the revised paper, you can refer to the bolded sections above for the detailed contents related to your concerns.**\n \n \n[a] Hu, Weihua, et al. \"Strategies for Pre-training Graph Neural Networks.\" ICLR, 2020.\n\n[b] Oord, Aaron van den, Yazhe Li, and Oriol Vinyals. \"Representation learning with contrastive predictive coding.\" arXiv:1807.03748 (2018).\n\n[c] Xu, Lei, Adam Krzyzak, and Erkki Oja. \"Rival penalized competitive learning for clustering analysis, RBF net, and curve detection.\" IEEE Transactions on Neural networks, 1993."}, "signatures": ["ICLR.cc/2021/Conference/Paper177/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-supervised Graph-level Representation Learning with Local and Global Structure", "authorids": ["~Minghao_Xu1", "~Hang_Wang1", "~Bingbing_Ni3", "~Hongyu_Guo1", "~Jian_Tang1"], "authors": ["Minghao Xu", "Hang Wang", "Bingbing Ni", "Hongyu Guo", "Jian Tang"], "keywords": ["Self-supervised Representation Learning", "Graph Representation Learning", "Hierarchical Semantic Learning"], "abstract": "This paper focuses on unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks including drug and material discovery. Current methods can effectively model the local structure between different graph instances, but they fail to discover the global semantic structure of the entire dataset. In this work, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local instance-level structure, GraphLoG leverages a nonparametric strategy to learn hierarchical prototypes of the data. These prototypes capture the semantic clusters in the latent space, and the number of prototypes can automatically adapt to different feature distributions. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark datasets demonstrate the effectiveness of our approach. ", "one-sentence_summary": "This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|selfsupervised_graphlevel_representation_learning_with_local_and_global_structure", "supplementary_material": "/attachment/5d9e09603b2a9b000859921b7fe4e1ddc1ccef83.zip", "pdf": "/pdf/2fe3e8d8c91ff90b4960cc121baf1bcb727dde10.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ittVdeg0zj", "_bibtex": "@misc{\nxu2021selfsupervised,\ntitle={Self-supervised Graph-level Representation Learning with Local and Global Structure},\nauthor={Minghao Xu and Hang Wang and Bingbing Ni and Hongyu Guo and Jian Tang},\nyear={2021},\nurl={https://openreview.net/forum?id=DAaaaqPv9-q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "DAaaaqPv9-q", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper177/Authors|ICLR.cc/2021/Conference/Paper177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873789, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment"}}}, {"id": "ZJzPCNpK2He", "original": null, "number": 4, "cdate": 1605577579207, "ddate": null, "tcdate": 1605577579207, "tmdate": 1605591473356, "tddate": null, "forum": "DAaaaqPv9-q", "replyto": "Y38wFBmjJrW", "invitation": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment", "content": {"title": "Official Response to AnonReviewer2", "comment": "Thanks for your insightful reviews on this work!\n \nWe first would like to re-emphasize the novelty of this work. This paper is dedicated to self-supervised graph representation learning which preserves both the local-instance and global-semantic structure of a set of unlabeled graphs. The proposed GraphLoG model is novel as a whole, since this learning problem, to the best of our knowledge, has not been studied by previous works. During constructing the entire model, we adopt some existing techniques, i.e. attribute masking [a], InfoNCE loss [b] and RPCL clustering [c], to promote model\u2019s performance. However, these techniques can be substituted with the vanilla counterpart, e.g. InfoNCE loss -> hinge-loss-based contrastive loss, RPCL -> K-means, without too much hurt to model\u2019s effectiveness, which is analyzed by the additional ablation studies in the **Section E** of appendix. In summary, we utilize these techniques as the performance-boosting modules serving for the core idea, local-instance and global-semantic learning, instead of simply combining them together.\n \nWe respond to your questions as follows:\n\nQ1: The theoretical and experimental analysis about the reliability of attribute masking strategy should be supplemented.\n\nA1: We give a theoretical analysis about GNN\u2019s capability of repairing the information lost by attribute masking in the **Section A** of appendix, and also empirically show that the correlated graphs derived by attribute masking is more reliable in **Section E.1**.\n\nQ2: How to use hierarchical prototypes in graph classification tasks?\n\nA2: In the self-supervised model GraphLoG, since the hierarchical prototypes cannot directly correspond to the categories of downstream tasks, they are not employed during graph classification. To study this problem in-depth, we additionally design a supervised learning variant, sup-GraphLoG, in **Section 4** to verify the effectiveness of hierarchical prototypes on graph classification with explicit supervision. The sup-GraphLoG model outperforms the vanilla GNN on chemical and biological benchmark datasets (shown in **Tabs. 1 and 2**).\n\nQ3: In the global-semantic loss, are graph embedding and hierarchical prototypes optimized jointly?\n\nA3: Appreciate for this good question. In the current model, only the representation of correlated graph is updated by the global-semantic loss (Eq. 13), and hierarchical prototypes are only updated by Eqs. 11 and 12. The joint optimization of these two types of variables will be the direction of our future exploration.\n\n \n**In the revised paper, you can refer to the bolded sections above for the detailed contents related to your questions.**\n \n \n[a] Hu, Weihua, et al. \"Strategies for Pre-training Graph Neural Networks.\" ICLR, 2020.\n\n[b] Oord, Aaron van den, Yazhe Li, and Oriol Vinyals. \"Representation learning with contrastive predictive coding.\" arXiv:1807.03748 (2018).\n\n[c] Xu, Lei, Adam Krzyzak, and Erkki Oja. \"Rival penalized competitive learning for clustering analysis, RBF net, and curve detection.\" IEEE Transactions on Neural networks, 1993."}, "signatures": ["ICLR.cc/2021/Conference/Paper177/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-supervised Graph-level Representation Learning with Local and Global Structure", "authorids": ["~Minghao_Xu1", "~Hang_Wang1", "~Bingbing_Ni3", "~Hongyu_Guo1", "~Jian_Tang1"], "authors": ["Minghao Xu", "Hang Wang", "Bingbing Ni", "Hongyu Guo", "Jian Tang"], "keywords": ["Self-supervised Representation Learning", "Graph Representation Learning", "Hierarchical Semantic Learning"], "abstract": "This paper focuses on unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks including drug and material discovery. Current methods can effectively model the local structure between different graph instances, but they fail to discover the global semantic structure of the entire dataset. In this work, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local instance-level structure, GraphLoG leverages a nonparametric strategy to learn hierarchical prototypes of the data. These prototypes capture the semantic clusters in the latent space, and the number of prototypes can automatically adapt to different feature distributions. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark datasets demonstrate the effectiveness of our approach. ", "one-sentence_summary": "This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|selfsupervised_graphlevel_representation_learning_with_local_and_global_structure", "supplementary_material": "/attachment/5d9e09603b2a9b000859921b7fe4e1ddc1ccef83.zip", "pdf": "/pdf/2fe3e8d8c91ff90b4960cc121baf1bcb727dde10.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ittVdeg0zj", "_bibtex": "@misc{\nxu2021selfsupervised,\ntitle={Self-supervised Graph-level Representation Learning with Local and Global Structure},\nauthor={Minghao Xu and Hang Wang and Bingbing Ni and Hongyu Guo and Jian Tang},\nyear={2021},\nurl={https://openreview.net/forum?id=DAaaaqPv9-q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "DAaaaqPv9-q", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper177/Authors|ICLR.cc/2021/Conference/Paper177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873789, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment"}}}, {"id": "ciENTA1Mf7x", "original": null, "number": 5, "cdate": 1605577849299, "ddate": null, "tcdate": 1605577849299, "tmdate": 1605589999182, "tddate": null, "forum": "DAaaaqPv9-q", "replyto": "b4uaKv95lCI", "invitation": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment", "content": {"title": "Official Response to AnonReviewer1", "comment": "Thanks for your support to the motivation and methodology of this work!\n \nWe address your concern on the experimental verification as follows:\n\nQ1: More benchmark tasks should be added to evaluate the proposed method.\n\nA1: We additionally evaluate the proposed model on five graph classification benchmarks in the **Section D** of appendix. These five benchmark datasets involve the classification on the molecular graphs and social networks, and they are commonly used in previous self-supervised graph representation learning literature [a,b].\n\nQ2: More ablation studies should be conducted in order to better understand the proposed GraphLoG model.\n\nA2: We conduct more thorough ablation studies on the correlated graph construction, loss constraint and clustering algorithm in the **Section E** of appendix.\n\n\n**In the revised paper, you can refer to the bolded sections above for the detailed experimental results.**\n \n \n[a] Sun, Fan-Yun, et al. \"Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization.\"  ICLR, 2020.\n\n[b] Hassani, Kaveh, and Amir Hosein Khasahmadi. \"Contrastive Multi-View Representation Learning on Graphs.\" ICML, 2020."}, "signatures": ["ICLR.cc/2021/Conference/Paper177/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-supervised Graph-level Representation Learning with Local and Global Structure", "authorids": ["~Minghao_Xu1", "~Hang_Wang1", "~Bingbing_Ni3", "~Hongyu_Guo1", "~Jian_Tang1"], "authors": ["Minghao Xu", "Hang Wang", "Bingbing Ni", "Hongyu Guo", "Jian Tang"], "keywords": ["Self-supervised Representation Learning", "Graph Representation Learning", "Hierarchical Semantic Learning"], "abstract": "This paper focuses on unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks including drug and material discovery. Current methods can effectively model the local structure between different graph instances, but they fail to discover the global semantic structure of the entire dataset. In this work, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local instance-level structure, GraphLoG leverages a nonparametric strategy to learn hierarchical prototypes of the data. These prototypes capture the semantic clusters in the latent space, and the number of prototypes can automatically adapt to different feature distributions. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark datasets demonstrate the effectiveness of our approach. ", "one-sentence_summary": "This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|selfsupervised_graphlevel_representation_learning_with_local_and_global_structure", "supplementary_material": "/attachment/5d9e09603b2a9b000859921b7fe4e1ddc1ccef83.zip", "pdf": "/pdf/2fe3e8d8c91ff90b4960cc121baf1bcb727dde10.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ittVdeg0zj", "_bibtex": "@misc{\nxu2021selfsupervised,\ntitle={Self-supervised Graph-level Representation Learning with Local and Global Structure},\nauthor={Minghao Xu and Hang Wang and Bingbing Ni and Hongyu Guo and Jian Tang},\nyear={2021},\nurl={https://openreview.net/forum?id=DAaaaqPv9-q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "DAaaaqPv9-q", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper177/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper177/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper177/Authors|ICLR.cc/2021/Conference/Paper177/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923873789, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper177/-/Official_Comment"}}}, {"id": "AIwlhBeS8Ij", "original": null, "number": 1, "cdate": 1603747857272, "ddate": null, "tcdate": 1603747857272, "tmdate": 1605024746509, "tddate": null, "forum": "DAaaaqPv9-q", "replyto": "DAaaaqPv9-q", "invitation": "ICLR.cc/2021/Conference/Paper177/-/Official_Review", "content": {"title": "A combination of too many existing ideas that shadows the novelty and makes it hard to judge who should be given the credit of the empirical performance gains", "review": "This paper proposed a method for self-supervised graph-level representation learning. The main idea is to enforce both the instance level smoothness embedding constraints, and a so-called global, semantic grouping structures across all instance graphs in the training data set.  To achieve this goal, the authors have adopted a global clustering framework to encourage the embedding of the graphs belonging to the same clusters to be close to each other, and by using a hierarchically organized set of prototypes. The proposed method is applied to pre-train GNN on massive unlabeled graphs, which is then fine-tuned to downstream learning tasks.\n\nEnforcing a global clustering structure can be useful in capturing the distribution of large number of graphs in the training data set and hopefully carry the learned representations over to other tasks. However, it appears to me that the paper has combined the carefully devised ideas from too many existing work, each of which alone has shown great success in improving the learning performance. Therefore it can be difficult to judge which part of the choices really leads to the final improvement, and in particular whether it is  the local and global structure preserving part, which seems to be the core theme of the paper (with the other theme being sel-supervised learning), that can fully explain the result.\n\nIn more detail, the authors have used (1) masking strategy by Hu et al., 2019 to generate correlated graph pairs, (2) mutual information estimation technique InfoNCE to enforce the correlation between paired graphs, and (3) Rival Penalized Competitive Learning (RPCL) as the main building block for hierarchical prototype-based learning. Therefore, a natural question to ask is, if one uses plain GNN architecture of each graph and plug it in a (hierarchical) clustering framework (without self-supervised learning and RPCL), whether similar improvements in the learning performance can still be obtained? If not, then the gains are merely due to the effectiveness of these specially designed components from the literatures and not by the general idea of local and global structures. \n\nWith regard to this concern, I would suggest the authors to clarify on what is the main theme of the work and demonstrate that the empirical performance gains are truly due to a novel, focused idea they propose rather than by combining some of the  existing algorithms which have shown great impact and performance gains in their respective context. In the current form, the novelrity of the work seems less significant by introducing so many components from other works.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper177/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-supervised Graph-level Representation Learning with Local and Global Structure", "authorids": ["~Minghao_Xu1", "~Hang_Wang1", "~Bingbing_Ni3", "~Hongyu_Guo1", "~Jian_Tang1"], "authors": ["Minghao Xu", "Hang Wang", "Bingbing Ni", "Hongyu Guo", "Jian Tang"], "keywords": ["Self-supervised Representation Learning", "Graph Representation Learning", "Hierarchical Semantic Learning"], "abstract": "This paper focuses on unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks including drug and material discovery. Current methods can effectively model the local structure between different graph instances, but they fail to discover the global semantic structure of the entire dataset. In this work, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local instance-level structure, GraphLoG leverages a nonparametric strategy to learn hierarchical prototypes of the data. These prototypes capture the semantic clusters in the latent space, and the number of prototypes can automatically adapt to different feature distributions. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark datasets demonstrate the effectiveness of our approach. ", "one-sentence_summary": "This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|selfsupervised_graphlevel_representation_learning_with_local_and_global_structure", "supplementary_material": "/attachment/5d9e09603b2a9b000859921b7fe4e1ddc1ccef83.zip", "pdf": "/pdf/2fe3e8d8c91ff90b4960cc121baf1bcb727dde10.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ittVdeg0zj", "_bibtex": "@misc{\nxu2021selfsupervised,\ntitle={Self-supervised Graph-level Representation Learning with Local and Global Structure},\nauthor={Minghao Xu and Hang Wang and Bingbing Ni and Hongyu Guo and Jian Tang},\nyear={2021},\nurl={https://openreview.net/forum?id=DAaaaqPv9-q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "DAaaaqPv9-q", "replyto": "DAaaaqPv9-q", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper177/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538148708, "tmdate": 1606915799747, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper177/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper177/-/Official_Review"}}}, {"id": "b4uaKv95lCI", "original": null, "number": 3, "cdate": 1603942571846, "ddate": null, "tcdate": 1603942571846, "tmdate": 1605024746440, "tddate": null, "forum": "DAaaaqPv9-q", "replyto": "DAaaaqPv9-q", "invitation": "ICLR.cc/2021/Conference/Paper177/-/Official_Review", "content": {"title": "This paper proposes GraphLoG for self-supervised graph-level representation learning. It can learn both local-instance and global-semantic information. Experiments are conducted on chemical and biological benchmark.", "review": "The motivation and novelty of the proposed method are good. However, the validation is kind of\nweak.\nI can understand that this papers follows the validation in Hu et al (2019), however, I feel that\ntwo tasks (one on chemical benchmark and one on biological benchmark) may not be sufficient\nto give a detailed idea of the improvement of the proposed GraphLoG over other baselines. I\nthink 3-5 tasks are much better.\nFor the ablation study in Section 5.4, these ablated items are good. However, I more would like\nto see fluctuated parts in the proposed GraphLoG. One example may be: is there any different\nchoice/option for hierarchical prototype? Which one is good/bad? What is the reason. Or other\npotential and similar examples exist in the proposed GraphLoG. I think this will help us to\nunderstand GraphLoG more.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper177/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-supervised Graph-level Representation Learning with Local and Global Structure", "authorids": ["~Minghao_Xu1", "~Hang_Wang1", "~Bingbing_Ni3", "~Hongyu_Guo1", "~Jian_Tang1"], "authors": ["Minghao Xu", "Hang Wang", "Bingbing Ni", "Hongyu Guo", "Jian Tang"], "keywords": ["Self-supervised Representation Learning", "Graph Representation Learning", "Hierarchical Semantic Learning"], "abstract": "This paper focuses on unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks including drug and material discovery. Current methods can effectively model the local structure between different graph instances, but they fail to discover the global semantic structure of the entire dataset. In this work, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local instance-level structure, GraphLoG leverages a nonparametric strategy to learn hierarchical prototypes of the data. These prototypes capture the semantic clusters in the latent space, and the number of prototypes can automatically adapt to different feature distributions. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark datasets demonstrate the effectiveness of our approach. ", "one-sentence_summary": "This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|selfsupervised_graphlevel_representation_learning_with_local_and_global_structure", "supplementary_material": "/attachment/5d9e09603b2a9b000859921b7fe4e1ddc1ccef83.zip", "pdf": "/pdf/2fe3e8d8c91ff90b4960cc121baf1bcb727dde10.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ittVdeg0zj", "_bibtex": "@misc{\nxu2021selfsupervised,\ntitle={Self-supervised Graph-level Representation Learning with Local and Global Structure},\nauthor={Minghao Xu and Hang Wang and Bingbing Ni and Hongyu Guo and Jian Tang},\nyear={2021},\nurl={https://openreview.net/forum?id=DAaaaqPv9-q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "DAaaaqPv9-q", "replyto": "DAaaaqPv9-q", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper177/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538148708, "tmdate": 1606915799747, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper177/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper177/-/Official_Review"}}}, {"id": "jSgse61B9ao", "original": null, "number": 2, "cdate": 1603939702472, "ddate": null, "tcdate": 1603939702472, "tmdate": 1605024746305, "tddate": null, "forum": "DAaaaqPv9-q", "replyto": "DAaaaqPv9-q", "invitation": "ICLR.cc/2021/Conference/Paper177/-/Official_Review", "content": {"title": "An interesting work for self-supervised graph representation learning", "review": "Pros:\n- The paper proposed a novel self-supervised learning method to embed graphs to vector space. Different from previous methods, the method proposed a global-semantic learning strategy to encourage the embeddings to form a hierarchical clustering structure.  Both the embedding network and the hierarchical structure can be jointly learned.\n\n- Authors have provided extensive and convincing comparison results and numerical analysis to show the effectiveness of the method.\n\n- The paper is well-organized and clearly written. To the best of my knowledge, the proposed method is technically feasible.\n\nCons:\n- The number of prototypes is determined by RPCL and can not be adjusted in training.\u3000\n- Clustering algorithms are usually not very robust. Since the prototypes of GraphLoG is initialized by RPCL, is the performance of GraphLoG robust? ", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper177/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper177/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Self-supervised Graph-level Representation Learning with Local and Global Structure", "authorids": ["~Minghao_Xu1", "~Hang_Wang1", "~Bingbing_Ni3", "~Hongyu_Guo1", "~Jian_Tang1"], "authors": ["Minghao Xu", "Hang Wang", "Bingbing Ni", "Hongyu Guo", "Jian Tang"], "keywords": ["Self-supervised Representation Learning", "Graph Representation Learning", "Hierarchical Semantic Learning"], "abstract": "This paper focuses on unsupervised/self-supervised whole-graph representation learning, which is critical in many tasks including drug and material discovery. Current methods can effectively model the local structure between different graph instances, but they fail to discover the global semantic structure of the entire dataset. In this work, we propose a unified framework called Local-instance and Global-semantic Learning (GraphLoG) for self-supervised whole-graph representation learning. Specifically, besides preserving the local instance-level structure, GraphLoG leverages a nonparametric strategy to learn hierarchical prototypes of the data. These prototypes capture the semantic clusters in the latent space, and the number of prototypes can automatically adapt to different feature distributions. We evaluate GraphLoG by pre-training it on massive unlabeled graphs followed by fine-tuning on downstream tasks. Extensive experiments on both chemical and biological benchmark datasets demonstrate the effectiveness of our approach. ", "one-sentence_summary": "This work seeks to learn the local-instance and global-semantic structure of a set of unlabeled graphs.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xu|selfsupervised_graphlevel_representation_learning_with_local_and_global_structure", "supplementary_material": "/attachment/5d9e09603b2a9b000859921b7fe4e1ddc1ccef83.zip", "pdf": "/pdf/2fe3e8d8c91ff90b4960cc121baf1bcb727dde10.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=ittVdeg0zj", "_bibtex": "@misc{\nxu2021selfsupervised,\ntitle={Self-supervised Graph-level Representation Learning with Local and Global Structure},\nauthor={Minghao Xu and Hang Wang and Bingbing Ni and Hongyu Guo and Jian Tang},\nyear={2021},\nurl={https://openreview.net/forum?id=DAaaaqPv9-q}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "DAaaaqPv9-q", "replyto": "DAaaaqPv9-q", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper177/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538148708, "tmdate": 1606915799747, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper177/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper177/-/Official_Review"}}}], "count": 23}