{"notes": [{"id": "HJMC_iA5tm", "original": "BJeic0ucFm", "number": 402, "cdate": 1538087798046, "ddate": null, "tcdate": 1538087798046, "tmdate": 1546725108774, "tddate": null, "forum": "HJMC_iA5tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning a SAT Solver from Single-Bit Supervision", "abstract": "We present NeuroSAT, a message passing neural network that learns to solve SAT problems after only being trained as a classifier to predict satisfiability.  Although it is not competitive with state-of-the-art SAT solvers, NeuroSAT can solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. Moreover, NeuroSAT generalizes to novel distributions; after training only on random SAT problems, at test time it can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems, all on a range of distributions over small random graphs.", "keywords": ["sat", "search", "graph neural network", "theorem proving", "proof"], "authorids": ["dselsam@cs.stanford.edu", "mlamm@cs.stanford.edu", "buenz@cs.stanford.edu", "pliang@cs.stanford.edu", "leonardo@microsoft.com", "dill@cs.stanford.edu"], "authors": ["Daniel Selsam", "Matthew Lamm", "Benedikt B\\\"{u}nz", "Percy Liang", "Leonardo de Moura", "David L. Dill"], "TL;DR": "We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.", "pdf": "/pdf/868d9f7b066d73e8b692a14f5148c48d16376781.pdf", "paperhash": "selsam|learning_a_sat_solver_from_singlebit_supervision", "_bibtex": "@inproceedings{\nselsam2018learning,\ntitle={Learning a {SAT} Solver from Single-Bit Supervision},\nauthor={Daniel Selsam and Matthew Lamm and Benedikt B\\\"{u}nz and Percy Liang and Leonardo de Moura and David L. Dill},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJMC_iA5tm},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 19, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "r1gnoGlNxE", "original": null, "number": 1, "cdate": 1544975012227, "ddate": null, "tcdate": 1544975012227, "tmdate": 1545354488990, "tddate": null, "forum": "HJMC_iA5tm", "replyto": "HJMC_iA5tm", "invitation": "ICLR.cc/2019/Conference/-/Paper402/Meta_Review", "content": {"metareview": "The submission proposes a machine learning approach to directly train a prediction system for whether a boolean sentence is satisfiable.  The strengths of the paper seem to be largely in proposing an architecture for SAT problems and the analysis of the generalization performance of the resulting classifier on classes of problems not directly seen during training.\n\nAlthough the resulting system cannot be claimed to be a state of the art system, and it does not have a correctness guarantee like DPLL based approaches, the paper is a nice re-introduction of SAT in a machine learning context using deep networks.  It may be nice to mention e.g. (W. Ruml. Adaptive Tree Search. PhD thesis, Harvard University, 2002) which applied reinforcement learning techniques to SAT problems.  The empirical validation on variable sized problems, etc. is a nice contribution showing interesting generalization properties of the proposed approach.\n\nThe reviewers were unanimous in their recommendation that the paper be accepted, and the review process attracted a number of additional comments showing the broader interest of the setting.", "confidence": "5: The area chair is absolutely certain", "recommendation": "Accept (Poster)", "title": "Area chair recommendation"}, "signatures": ["ICLR.cc/2019/Conference/Paper402/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper402/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning a SAT Solver from Single-Bit Supervision", "abstract": "We present NeuroSAT, a message passing neural network that learns to solve SAT problems after only being trained as a classifier to predict satisfiability.  Although it is not competitive with state-of-the-art SAT solvers, NeuroSAT can solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. Moreover, NeuroSAT generalizes to novel distributions; after training only on random SAT problems, at test time it can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems, all on a range of distributions over small random graphs.", "keywords": ["sat", "search", "graph neural network", "theorem proving", "proof"], "authorids": ["dselsam@cs.stanford.edu", "mlamm@cs.stanford.edu", "buenz@cs.stanford.edu", "pliang@cs.stanford.edu", "leonardo@microsoft.com", "dill@cs.stanford.edu"], "authors": ["Daniel Selsam", "Matthew Lamm", "Benedikt B\\\"{u}nz", "Percy Liang", "Leonardo de Moura", "David L. Dill"], "TL;DR": "We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.", "pdf": "/pdf/868d9f7b066d73e8b692a14f5148c48d16376781.pdf", "paperhash": "selsam|learning_a_sat_solver_from_singlebit_supervision", "_bibtex": "@inproceedings{\nselsam2018learning,\ntitle={Learning a {SAT} Solver from Single-Bit Supervision},\nauthor={Daniel Selsam and Matthew Lamm and Benedikt B\\\"{u}nz and Percy Liang and Leonardo de Moura and David L. Dill},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJMC_iA5tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper402/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353230555, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJMC_iA5tm", "replyto": "HJMC_iA5tm", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper402/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper402/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper402/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353230555}}}, {"id": "r1lwc2f1C7", "original": null, "number": 10, "cdate": 1542560910661, "ddate": null, "tcdate": 1542560910661, "tmdate": 1543086264788, "tddate": null, "forum": "HJMC_iA5tm", "replyto": "r1lvKBRCT7", "invitation": "ICLR.cc/2019/Conference/-/Paper402/Official_Comment", "content": {"title": "Re: Re: Re: correlations", "comment": "Thank you for the suggestion. I think you may have overlooked the crucial note at the end of S5: \"Note: for the entire rest of the paper, \\emph{NeuroSAT} refers to the specific trained model that has only been trained on $\\SR(\\U(10, 40))$\". We need to rely on a note like this because we use the phrase \"NeuroSAT\" in this way many times.  We also include an explicit reminder of this note whenever we draw attention to the role of the training data, as in the beginning on S8: \"NeuroSAT (trained on $\\SR(\\U(10, 40))$) can find satisfying assignments but is not helpful in constructing proofs of unsatisfiability.\" We go on to say that \"We trained our architecture on [the SRC(40, u)] dataset, and we refer to the trained model as \\emph{NeuroUNSAT}.\" To address your concern, I have added another reminder at the beginning of S6, shortly before the sentence you quoted that you found confusing. Do you think it is sufficiently clear now? An alternative approach to preempting this confusion would be to make the dependence on the training distribution explicit in the notation, e.g. by referring to \\mathrm{NeuroSAT}_{\\SR(\\U(10, 40))} and \\mathrm{NeuroSAT}_{\\SRC(40, u)}. This may leave less room for confusion, but I fear it would be rather cumbersome, especially since we only consider two different training distributions in the entire paper. What do you think?"}, "signatures": ["ICLR.cc/2019/Conference/Paper402/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning a SAT Solver from Single-Bit Supervision", "abstract": "We present NeuroSAT, a message passing neural network that learns to solve SAT problems after only being trained as a classifier to predict satisfiability.  Although it is not competitive with state-of-the-art SAT solvers, NeuroSAT can solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. Moreover, NeuroSAT generalizes to novel distributions; after training only on random SAT problems, at test time it can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems, all on a range of distributions over small random graphs.", "keywords": ["sat", "search", "graph neural network", "theorem proving", "proof"], "authorids": ["dselsam@cs.stanford.edu", "mlamm@cs.stanford.edu", "buenz@cs.stanford.edu", "pliang@cs.stanford.edu", "leonardo@microsoft.com", "dill@cs.stanford.edu"], "authors": ["Daniel Selsam", "Matthew Lamm", "Benedikt B\\\"{u}nz", "Percy Liang", "Leonardo de Moura", "David L. Dill"], "TL;DR": "We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.", "pdf": "/pdf/868d9f7b066d73e8b692a14f5148c48d16376781.pdf", "paperhash": "selsam|learning_a_sat_solver_from_singlebit_supervision", "_bibtex": "@inproceedings{\nselsam2018learning,\ntitle={Learning a {SAT} Solver from Single-Bit Supervision},\nauthor={Daniel Selsam and Matthew Lamm and Benedikt B\\\"{u}nz and Percy Liang and Leonardo de Moura and David L. Dill},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJMC_iA5tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper402/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621613953, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJMC_iA5tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper402/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper402/Authors|ICLR.cc/2019/Conference/Paper402/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621613953}}}, {"id": "SklcSBbD07", "original": null, "number": 13, "cdate": 1543079234513, "ddate": null, "tcdate": 1543079234513, "tmdate": 1543085503290, "tddate": null, "forum": "HJMC_iA5tm", "replyto": "rkecACeG07", "invitation": "ICLR.cc/2019/Conference/-/Paper402/Official_Comment", "content": {"title": "Re: Testing SR(40) with more than n variables", "comment": "> What\u2019s the maximum number of classes on the data use for SR(40)?\n\nFor any n >= 2, the number of clauses m in a problem from SR(n) can be arbitrarily large. To see this, note that for any given $M$, there is some probability that we sample the clause (x_1 \\/ x_2) $M$ times in a row, in which case $m$ will be larger than $M$. The variance is not very large though.\n\n> How does the model work with formulas with less than $n$ variables or $m$ clauses?\n> How can you test on a formula with n > 40 or $m$ bigger than the training data of SR(40)?\n\nThe parameters of the model do not depend on n or m in any way. We use d to refer to the dimensionality of the literal and clause embeddings, which is a hyperparameter that does not depend on n or m. As we explain in S3, the parameters of the NeuroSAT architecture are only the following:\n\n1. L_init and C_init: vectors in R^d that for a given problem get duplicated 2n and m times respectively.\n2. L_msg and C_msg:  MLPs that map R^d to R^d, and that get applied to the embeddings of each of the 2n literals and m clauses respectively.\n3. L_update and C_update: layer-norm LSTMs whose dimensions also only depend on $d$, that get applied independently for each of the 2n literals and m clauses respectively.\n4. L_vote: an MLP that maps R^d to R, that gets applied independently to the embeddings of each of the 2n literals.\n\nThe input to the model at train and test time is any bipartite adjacency matrix $M$ over any number of literals and clauses. \n\nI added a paragraph at the end of S3 to clarify this point."}, "signatures": ["ICLR.cc/2019/Conference/Paper402/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning a SAT Solver from Single-Bit Supervision", "abstract": "We present NeuroSAT, a message passing neural network that learns to solve SAT problems after only being trained as a classifier to predict satisfiability.  Although it is not competitive with state-of-the-art SAT solvers, NeuroSAT can solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. Moreover, NeuroSAT generalizes to novel distributions; after training only on random SAT problems, at test time it can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems, all on a range of distributions over small random graphs.", "keywords": ["sat", "search", "graph neural network", "theorem proving", "proof"], "authorids": ["dselsam@cs.stanford.edu", "mlamm@cs.stanford.edu", "buenz@cs.stanford.edu", "pliang@cs.stanford.edu", "leonardo@microsoft.com", "dill@cs.stanford.edu"], "authors": ["Daniel Selsam", "Matthew Lamm", "Benedikt B\\\"{u}nz", "Percy Liang", "Leonardo de Moura", "David L. Dill"], "TL;DR": "We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.", "pdf": "/pdf/868d9f7b066d73e8b692a14f5148c48d16376781.pdf", "paperhash": "selsam|learning_a_sat_solver_from_singlebit_supervision", "_bibtex": "@inproceedings{\nselsam2018learning,\ntitle={Learning a {SAT} Solver from Single-Bit Supervision},\nauthor={Daniel Selsam and Matthew Lamm and Benedikt B\\\"{u}nz and Percy Liang and Leonardo de Moura and David L. Dill},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJMC_iA5tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper402/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621613953, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJMC_iA5tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper402/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper402/Authors|ICLR.cc/2019/Conference/Paper402/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621613953}}}, {"id": "rkecACeG07", "original": null, "number": 5, "cdate": 1542749906275, "ddate": null, "tcdate": 1542749906275, "tmdate": 1542828292352, "tddate": null, "forum": "HJMC_iA5tm", "replyto": "HJMC_iA5tm", "invitation": "ICLR.cc/2019/Conference/-/Paper402/Public_Comment", "content": {"comment": "The model described in section 3 has parameters $n$ and $m$ for the number of variables and clauses.\n\n* What\u2019s the maximum number of classes on the data use for SR(40)?\nThat would be $m$, right?\nThe paper says \"over 200 clauses on average\u201d, but it doesn\u2019t say anything about the max.\n\n* How does the model work with formulas with less than $n$ variables or $m$ clauses?\nI understand the adjacency matrix $M$ would have some zero rows and columns.\nWhat\u2019s the impact of that during testing?\n\n* How can you test on a formula with n > 40 or $m$ bigger than the training data of SR(40)?\n", "title": "Testing SR(40) with more than n variables"}, "signatures": ["~Hector_Palacios1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Hector_Palacios1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning a SAT Solver from Single-Bit Supervision", "abstract": "We present NeuroSAT, a message passing neural network that learns to solve SAT problems after only being trained as a classifier to predict satisfiability.  Although it is not competitive with state-of-the-art SAT solvers, NeuroSAT can solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. Moreover, NeuroSAT generalizes to novel distributions; after training only on random SAT problems, at test time it can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems, all on a range of distributions over small random graphs.", "keywords": ["sat", "search", "graph neural network", "theorem proving", "proof"], "authorids": ["dselsam@cs.stanford.edu", "mlamm@cs.stanford.edu", "buenz@cs.stanford.edu", "pliang@cs.stanford.edu", "leonardo@microsoft.com", "dill@cs.stanford.edu"], "authors": ["Daniel Selsam", "Matthew Lamm", "Benedikt B\\\"{u}nz", "Percy Liang", "Leonardo de Moura", "David L. Dill"], "TL;DR": "We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.", "pdf": "/pdf/868d9f7b066d73e8b692a14f5148c48d16376781.pdf", "paperhash": "selsam|learning_a_sat_solver_from_singlebit_supervision", "_bibtex": "@inproceedings{\nselsam2018learning,\ntitle={Learning a {SAT} Solver from Single-Bit Supervision},\nauthor={Daniel Selsam and Matthew Lamm and Benedikt B\\\"{u}nz and Percy Liang and Leonardo de Moura and David L. Dill},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJMC_iA5tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper402/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311848611, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "HJMC_iA5tm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311848611}}}, {"id": "r1lvKBRCT7", "original": null, "number": 9, "cdate": 1542542719249, "ddate": null, "tcdate": 1542542719249, "tmdate": 1542542719249, "tddate": null, "forum": "HJMC_iA5tm", "replyto": "SJx8VBfCpm", "invitation": "ICLR.cc/2019/Conference/-/Paper402/Official_Comment", "content": {"title": "Re: Re: correlations", "comment": "OK, thanks! This is significantly clearer and I think we\u2019re converging. I would suggest describing this explicitly in the paper. One of the points which was misleading for me is the second paragraph of S6: \u201cNeuroSAT never becomes highly confident that a problem is unsat, and it almost never guesses sat on an unsat problem\u201d. In fact this only holds for the series of experiments on SR(20). \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper402/AnonReviewer2"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper402/AnonReviewer2", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning a SAT Solver from Single-Bit Supervision", "abstract": "We present NeuroSAT, a message passing neural network that learns to solve SAT problems after only being trained as a classifier to predict satisfiability.  Although it is not competitive with state-of-the-art SAT solvers, NeuroSAT can solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. Moreover, NeuroSAT generalizes to novel distributions; after training only on random SAT problems, at test time it can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems, all on a range of distributions over small random graphs.", "keywords": ["sat", "search", "graph neural network", "theorem proving", "proof"], "authorids": ["dselsam@cs.stanford.edu", "mlamm@cs.stanford.edu", "buenz@cs.stanford.edu", "pliang@cs.stanford.edu", "leonardo@microsoft.com", "dill@cs.stanford.edu"], "authors": ["Daniel Selsam", "Matthew Lamm", "Benedikt B\\\"{u}nz", "Percy Liang", "Leonardo de Moura", "David L. Dill"], "TL;DR": "We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.", "pdf": "/pdf/868d9f7b066d73e8b692a14f5148c48d16376781.pdf", "paperhash": "selsam|learning_a_sat_solver_from_singlebit_supervision", "_bibtex": "@inproceedings{\nselsam2018learning,\ntitle={Learning a {SAT} Solver from Single-Bit Supervision},\nauthor={Daniel Selsam and Matthew Lamm and Benedikt B\\\"{u}nz and Percy Liang and Leonardo de Moura and David L. Dill},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJMC_iA5tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper402/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621613953, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJMC_iA5tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper402/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper402/Authors|ICLR.cc/2019/Conference/Paper402/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621613953}}}, {"id": "SJx8VBfCpm", "original": null, "number": 8, "cdate": 1542493485804, "ddate": null, "tcdate": 1542493485804, "tmdate": 1542493615701, "tddate": null, "forum": "HJMC_iA5tm", "replyto": "Ske_LQKQTX", "invitation": "ICLR.cc/2019/Conference/-/Paper402/Official_Comment", "content": {"title": "Re: correlations", "comment": "I am afraid that I still do not understand what you are asking, but I will try to address what I think might be a source of confusion.  After each round of message passing, each literal casts a _single_ scalar \"vote\". During training, the votes prior to round T are discarded, and then the round-T votes are averaged together and passed to the sigmoid function to estimate the probability that the problem is satisfiable. The network weights are optimized end-to-end to minimize the cross-entropy loss. When we train our architecture on SR(n), we observe empirically that these literal votes behave as we describe in S6, while when we train it on SRC(n, u), we observe empirically that the votes behave as we describe in S8. But in a given trained network, each literal still only casts a single vote at each time step.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper402/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning a SAT Solver from Single-Bit Supervision", "abstract": "We present NeuroSAT, a message passing neural network that learns to solve SAT problems after only being trained as a classifier to predict satisfiability.  Although it is not competitive with state-of-the-art SAT solvers, NeuroSAT can solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. Moreover, NeuroSAT generalizes to novel distributions; after training only on random SAT problems, at test time it can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems, all on a range of distributions over small random graphs.", "keywords": ["sat", "search", "graph neural network", "theorem proving", "proof"], "authorids": ["dselsam@cs.stanford.edu", "mlamm@cs.stanford.edu", "buenz@cs.stanford.edu", "pliang@cs.stanford.edu", "leonardo@microsoft.com", "dill@cs.stanford.edu"], "authors": ["Daniel Selsam", "Matthew Lamm", "Benedikt B\\\"{u}nz", "Percy Liang", "Leonardo de Moura", "David L. Dill"], "TL;DR": "We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.", "pdf": "/pdf/868d9f7b066d73e8b692a14f5148c48d16376781.pdf", "paperhash": "selsam|learning_a_sat_solver_from_singlebit_supervision", "_bibtex": "@inproceedings{\nselsam2018learning,\ntitle={Learning a {SAT} Solver from Single-Bit Supervision},\nauthor={Daniel Selsam and Matthew Lamm and Benedikt B\\\"{u}nz and Percy Liang and Leonardo de Moura and David L. Dill},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJMC_iA5tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper402/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621613953, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJMC_iA5tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper402/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper402/Authors|ICLR.cc/2019/Conference/Paper402/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621613953}}}, {"id": "S1e74C9XTm", "original": null, "number": 6, "cdate": 1541807658879, "ddate": null, "tcdate": 1541807658879, "tmdate": 1541866282305, "tddate": null, "forum": "HJMC_iA5tm", "replyto": "rylt7MfEhm", "invitation": "ICLR.cc/2019/Conference/-/Paper402/Official_Comment", "content": {"title": "Re: How significant is the work?", "comment": "First, some context. NeuroSAT solves SAT problems, it doesn't just predict satisfiability. We only report its classification accuracy in S5 to facilitate understanding, and in the rest of the paper we focus on the percent of satisfiable problems for which we can decode a solution.  Also, our main motivation has been scientific rather than to build a tool.  We wanted to better understand the extent to which neural networks are capable of precise, logical reasoning. As we state in S10, our work has definitively established that neural networks can learn to perform discrete search on their own without the help of hard-coded search procedures, even after only end-to-end training with minimal supervision.\n\nThe DOS2008 paper is orthogonal to our work, but let's still consider it in detail. For a given set of SAT problems, it may be arbitrarily easy to classify satisfiability (e.g. if the _sat_ and _unsat_ problems come from different domains and have different statistical properties); however, high classification accuracy may not imply beating random on subproblems of the problems in the training set, let alone imply high accuracy on (sub)problems from other domains. Such degeneracy is an obvious concern for the \"Crafted\", \"Industrial\", and \"Random\" (not to be confused with \"Random 3-SAT\") categories in DOS2008, and the authors do not provide evidence that the classifiers trained on these categories are robust.\n\nThus, for the rest of this comment we consider only their results in the \"Random 3-SAT\" category, which, although we find the wording on the bottom of page 6 to be confusing, we believe consists only of uniform random 3-SAT instances at the phase transition region that were generated using an unforced filtered method. Even for this category, for which the authors could have easily given precise semantics, they do not mention the size of the problems they used. They say that all 4,772 problems in this category are from SATLib. As of this writing, SATLib has only 3,700 uniform Random-3SAT problems in total, ranging from 20 to 250 variables, so it is not possible for us to deduce how the authors assembled their 4,772 problems or what sizes they were.\n\nThere are three numbers (for each classifier) that DOS2008 provide that we will consider in more detail: the Random 3SAT \"base\", \"all\", and \"+t\" accuracies for the class ALL (meaning unsat and sat combined). For the \"all\" and \"+t\" categories, DOS2008 use extremely sophisticated feature extractors.  One set of features requires running two existing stochastic local search algorithms, GSAT and SAPS, multiple times each on the SAT problem. Another set of features involves solving the LP relaxation of an IP representing the SAT problem. A third set of features involves running DPLL on the SAT problem with some budget. Their feature extraction process alone took about 2 seconds on average for each of the random 3-SAT problems (aside: the feature extraction process took over an hour for one of the industrial problems). Depending on the size of the random 3-SAT problems, the solvers they ran as part of this process could have easily solved the problems within the budget and encoded their conclusions in the features themselves. Thus we cannot consider the \"all\" and \"+t\" numbers informative without more information about the sizes of the problems and the budgets for each of the feature extractors.\n\nIt remains to consider the Random 3SAT \"base\" number, which is still extremely high for some of the classifiers (97.2% for decision trees).  For \"base\", they use only features 1-33, which are all syntactic properties of the SAT problem. We tried to reproduce these numbers, using sklearn to train a decision-tree classifier (default settings) and an MLP (6 50-node layers and otherwise default settings) to classify satisfiability on two different random 3-SAT distributions using exclusively these 33 features. For the first distribution, we generated 20,000 problems with 20 variables at threshold (~4.62), and for the second, we generated 10,000 problems with 50 variables at the threshold (~4.36). In each case we split the data evenly into train and test, and used Minisat to determine if the problem was satisfiable. Note that the authors only trained on fewer than 5,000 problems in total, so we are making the conditions at least as favorable for the classifier. Under these conditions, we got the following accuracies:\n\nDT, n=20, train: 100%, test: 54%\nDT, n=50, train: 100%, test: 54%\nMLP, n=20, train: 50%, test: 50%\nMLP, n=50, train: 52%, test: 51%\n\nHyperparameter tuning might yield improvements, and of course, we could be making an error in this informal experiment. Nonetheless, especially given how remarkable the unqualified claim is of 97% test-set accuracy on hard random sat with only syntactic features, and how much crucial information is missing from DOS2008, I think the burden is on the authors of DOS2008 to clarify the experimental details and to provide reproducible code.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper402/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning a SAT Solver from Single-Bit Supervision", "abstract": "We present NeuroSAT, a message passing neural network that learns to solve SAT problems after only being trained as a classifier to predict satisfiability.  Although it is not competitive with state-of-the-art SAT solvers, NeuroSAT can solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. Moreover, NeuroSAT generalizes to novel distributions; after training only on random SAT problems, at test time it can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems, all on a range of distributions over small random graphs.", "keywords": ["sat", "search", "graph neural network", "theorem proving", "proof"], "authorids": ["dselsam@cs.stanford.edu", "mlamm@cs.stanford.edu", "buenz@cs.stanford.edu", "pliang@cs.stanford.edu", "leonardo@microsoft.com", "dill@cs.stanford.edu"], "authors": ["Daniel Selsam", "Matthew Lamm", "Benedikt B\\\"{u}nz", "Percy Liang", "Leonardo de Moura", "David L. Dill"], "TL;DR": "We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.", "pdf": "/pdf/868d9f7b066d73e8b692a14f5148c48d16376781.pdf", "paperhash": "selsam|learning_a_sat_solver_from_singlebit_supervision", "_bibtex": "@inproceedings{\nselsam2018learning,\ntitle={Learning a {SAT} Solver from Single-Bit Supervision},\nauthor={Daniel Selsam and Matthew Lamm and Benedikt B\\\"{u}nz and Percy Liang and Leonardo de Moura and David L. Dill},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJMC_iA5tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper402/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621613953, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJMC_iA5tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper402/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper402/Authors|ICLR.cc/2019/Conference/Paper402/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621613953}}}, {"id": "ByeriC5Q6X", "original": null, "number": 7, "cdate": 1541807773348, "ddate": null, "tcdate": 1541807773348, "tmdate": 1541807871757, "tddate": null, "forum": "HJMC_iA5tm", "replyto": "rylt7MfEhm", "invitation": "ICLR.cc/2019/Conference/-/Paper402/Official_Comment", "content": {"title": "Re: How significant is the work? (II)", "comment": "> 2) As mentioned in the paper, for some cases, it may be possible to decode the satisfying assignments. However, this may require the graph neural network algorithm runs for many iterations. I was wondering what is the average required running time for decoding the satisfying assignments (e.g., how many seconds, ...)? Because if it takes too long time, then I would rather just use an existing off-the-shell SAT solver.\n\nWe explain the entire architecture in detail in the paper, as well as how many iterations we ran it for the different experiments. The number of seconds depends heavily on the hardware, which for neural networks is changing drastically every year. It also depends on how or whether the cost is amortized. As we explain in a comment above, we can solve a very large number of SAT problems simultaneously as a single batch (e.g. on a GPU) without any problem-specific control flow.\n\nAs for the question of whether to use NeuroSAT or an off-the-shelf solver, we stress here as we do in the paper that the trained NeuroSAT discussed in the paper is not remotely competitive with off-the-shelf SAT solvers. We strongly recommend that you just use an existing off-the-shelf SAT solver, at least for the foreseeable future.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper402/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning a SAT Solver from Single-Bit Supervision", "abstract": "We present NeuroSAT, a message passing neural network that learns to solve SAT problems after only being trained as a classifier to predict satisfiability.  Although it is not competitive with state-of-the-art SAT solvers, NeuroSAT can solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. Moreover, NeuroSAT generalizes to novel distributions; after training only on random SAT problems, at test time it can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems, all on a range of distributions over small random graphs.", "keywords": ["sat", "search", "graph neural network", "theorem proving", "proof"], "authorids": ["dselsam@cs.stanford.edu", "mlamm@cs.stanford.edu", "buenz@cs.stanford.edu", "pliang@cs.stanford.edu", "leonardo@microsoft.com", "dill@cs.stanford.edu"], "authors": ["Daniel Selsam", "Matthew Lamm", "Benedikt B\\\"{u}nz", "Percy Liang", "Leonardo de Moura", "David L. Dill"], "TL;DR": "We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.", "pdf": "/pdf/868d9f7b066d73e8b692a14f5148c48d16376781.pdf", "paperhash": "selsam|learning_a_sat_solver_from_singlebit_supervision", "_bibtex": "@inproceedings{\nselsam2018learning,\ntitle={Learning a {SAT} Solver from Single-Bit Supervision},\nauthor={Daniel Selsam and Matthew Lamm and Benedikt B\\\"{u}nz and Percy Liang and Leonardo de Moura and David L. Dill},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJMC_iA5tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper402/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621613953, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJMC_iA5tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper402/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper402/Authors|ICLR.cc/2019/Conference/Paper402/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621613953}}}, {"id": "Ske_LQKQTX", "original": null, "number": 5, "cdate": 1541800783524, "ddate": null, "tcdate": 1541800783524, "tmdate": 1541800783524, "tddate": null, "forum": "HJMC_iA5tm", "replyto": "BJxsg-S767", "invitation": "ICLR.cc/2019/Conference/-/Paper402/Official_Comment", "content": {"title": "Some comments about the authors' response", "comment": "> We graphically depict a single iteration in Figure 2, though it is very high-level. Do you have a particular middle- ground in mind, between the figure we have and the equations themselves?\n\nYes, Figure 2 is a bit too high-level and does not provide much information about the transitions. So a bit more detailed figure, showing how equations are handled would be really helpful in understanding the neural model.\n\n> Here is the description we give in the paper on the 2-clustering approach: \"2-cluster $L^{(T)}$ to get cluster centers $\\Delta_1$ and $\\Delta_2$, partition the variables according to the predicate \\( \\| x_i - \\Delta_1 \\|^2 + \\| \\flip{x_i} - \\Delta_2 \\|^2 < \\| x_i - \\Delta_2 \\|^2 + \\| \\flip{x_i} - \\Delta_1 \\|^2 \\), and then try both candidate assignments that result from mapping the partitions to truth values.\" If you clarify what you find confusing or missing from this explanation, we will try to improve the explanation in the paper.\n\nSome additional comments (maybe in the Appendix) about how this approach is implemented would be fine. Namely, how do you find the clusters? What it the algorithm here? And, finally, which assignment do you choose ( we have two candidate assignments, so which is the best)?\n\n> It is easy to generate unlimited data from these distributions. We trained on millions of problems, and tested on hundreds of thousands of them.\n\nSure. But for the sake of clarity, it would be relevant to mention these orders of magnitude.\n\n>> Namely, it seems that in the last layer of each iteration, literals are voting for SAT (red colors) with some confidence (say $\\delta$) and voting for UNSAT (blue colors) with some confidence (say $\\delta\u2019$). Are $\\delta$ and $\\delta\u2019$ correlated in the neural architecture? And, how confidences for UNSAT votes are updated?\n> I am afraid I do not understand what you are asking. Can you please clarify your use of 'correlated' and 'updated' in the last two sentences?\n \nIn Sections 3-7, the learning model is focused on finding satisfying assignments.  So, all literals are voting for SAT with some confidence which is susceptible to change over transitions, and finally, an instance is predicted as UNSAT if such confidences are too small (i.e. there is no phase transition). \n\nYet, according to Section 8, the framework can also be applied to core finding, which requires the literals to vote for UNSAT with high confidence (as illustrated in Figure 7). So, a natural question here is: do we have two kinds of votes (i.e. voting for SAT and trying to find a satisfying assignment, AND voting for UNSAT and trying to find a core)? If this is indeed the case, another question is to determine whether such votes are correlated: if one literal is voting for SAT with high-confidence, it will likely vote for UNSAT with low confidence. \n "}, "signatures": ["ICLR.cc/2019/Conference/Paper402/AnonReviewer2"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper402/AnonReviewer2", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning a SAT Solver from Single-Bit Supervision", "abstract": "We present NeuroSAT, a message passing neural network that learns to solve SAT problems after only being trained as a classifier to predict satisfiability.  Although it is not competitive with state-of-the-art SAT solvers, NeuroSAT can solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. Moreover, NeuroSAT generalizes to novel distributions; after training only on random SAT problems, at test time it can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems, all on a range of distributions over small random graphs.", "keywords": ["sat", "search", "graph neural network", "theorem proving", "proof"], "authorids": ["dselsam@cs.stanford.edu", "mlamm@cs.stanford.edu", "buenz@cs.stanford.edu", "pliang@cs.stanford.edu", "leonardo@microsoft.com", "dill@cs.stanford.edu"], "authors": ["Daniel Selsam", "Matthew Lamm", "Benedikt B\\\"{u}nz", "Percy Liang", "Leonardo de Moura", "David L. Dill"], "TL;DR": "We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.", "pdf": "/pdf/868d9f7b066d73e8b692a14f5148c48d16376781.pdf", "paperhash": "selsam|learning_a_sat_solver_from_singlebit_supervision", "_bibtex": "@inproceedings{\nselsam2018learning,\ntitle={Learning a {SAT} Solver from Single-Bit Supervision},\nauthor={Daniel Selsam and Matthew Lamm and Benedikt B\\\"{u}nz and Percy Liang and Leonardo de Moura and David L. Dill},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJMC_iA5tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper402/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621613953, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJMC_iA5tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper402/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper402/Authors|ICLR.cc/2019/Conference/Paper402/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621613953}}}, {"id": "rkeiH0Bmpm", "original": null, "number": 4, "cdate": 1541787203229, "ddate": null, "tcdate": 1541787203229, "tmdate": 1541787203229, "tddate": null, "forum": "HJMC_iA5tm", "replyto": "r1x80rJJTQ", "invitation": "ICLR.cc/2019/Conference/-/Paper402/Official_Comment", "content": {"title": "practical implications uncertain", "comment": "We agree with AR1 that the practical implications are quite hard to know. Following the sentences you quoted, we discuss encouraging signs, and close by saying \"We are cautiously optimistic that a descendent of NeuroSAT will one day lead to improvements to the state-of-the-art.\""}, "signatures": ["ICLR.cc/2019/Conference/Paper402/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning a SAT Solver from Single-Bit Supervision", "abstract": "We present NeuroSAT, a message passing neural network that learns to solve SAT problems after only being trained as a classifier to predict satisfiability.  Although it is not competitive with state-of-the-art SAT solvers, NeuroSAT can solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. Moreover, NeuroSAT generalizes to novel distributions; after training only on random SAT problems, at test time it can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems, all on a range of distributions over small random graphs.", "keywords": ["sat", "search", "graph neural network", "theorem proving", "proof"], "authorids": ["dselsam@cs.stanford.edu", "mlamm@cs.stanford.edu", "buenz@cs.stanford.edu", "pliang@cs.stanford.edu", "leonardo@microsoft.com", "dill@cs.stanford.edu"], "authors": ["Daniel Selsam", "Matthew Lamm", "Benedikt B\\\"{u}nz", "Percy Liang", "Leonardo de Moura", "David L. Dill"], "TL;DR": "We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.", "pdf": "/pdf/868d9f7b066d73e8b692a14f5148c48d16376781.pdf", "paperhash": "selsam|learning_a_sat_solver_from_singlebit_supervision", "_bibtex": "@inproceedings{\nselsam2018learning,\ntitle={Learning a {SAT} Solver from Single-Bit Supervision},\nauthor={Daniel Selsam and Matthew Lamm and Benedikt B\\\"{u}nz and Percy Liang and Leonardo de Moura and David L. Dill},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJMC_iA5tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper402/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621613953, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJMC_iA5tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper402/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper402/Authors|ICLR.cc/2019/Conference/Paper402/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621613953}}}, {"id": "B1xxGmSmpm", "original": null, "number": 3, "cdate": 1541784327693, "ddate": null, "tcdate": 1541784327693, "tmdate": 1541784327693, "tddate": null, "forum": "HJMC_iA5tm", "replyto": "H1x_vEau3m", "invitation": "ICLR.cc/2019/Conference/-/Paper402/Official_Comment", "content": {"title": "Response to AR3", "comment": "Thank you for your comments and questions.\n\n> However, the theoretical analysis isn't very sufficient. For instance, why does the change of the dataset from the original SR(n) to SRC(n,u) lead to the change of the behavior of the network from searching for a satisfying assignment indefinitely to detecting the unsatisfiable cores?\n\nFor SRC(n, u), the objective function assigns much lower cost to the parameters that detect the presence of the planted unsat cores than to the parameters that search for satisfying assignments, because unlike the latter, the former allow perfect classification of the dataset in a fixed, small number of steps. Such a simple approach is not an option on SR(n), because the cores are bigger and more diverse.\n\n> For instance, in figure 3, I am not sure whether darker value means larger value or smaller value because the authors only mentioned that white represents zero, blue negative and red positive. Also, in figure 7, I am not sure whether those black grids represent higher positive values or lower negative values.\n\nWe also write in two places that \"for several iterations, almost every literal is voting \\emph{unsat} with low confidence (\\ie light blue)\".  We updated the paper to include two more similar parenthetical notes, one for \"_sat_ with high confidence\" and \"dark red\", and one for \"_unsat_ with high confidence\" and \"dark blue\". What you saw as black is just dark blue.\n\n> What's the initialization of the two vectors the authors use for tiling operation? Does the initialization differ for different types of SAT problems?\n\nIt is just the parameters L_init and C_init that are learned by gradient descent at the same time as the other parameters are learned.  When a trained NeuroSAT is run on a SAT problem, no matter the size or origin, the same L_init and C_init are used.\n\n> How do the authors decide the number of iterations necessary for solving a particular SAT problem?\n\nSince the network usually converges once it finds a solution, one does not need to try to decode solutions after each round of message passing, and instead can run for a predetermined number of rounds and only check at the end. This is a desirable feature since it makes it easy to solve a very large number of SAT problems simultaneously as a single batch (e.g. on a GPU) without any problem-specific control flow. As for rules of thumb, Figure 5 provides data on how many iterations it took to solve what percentage of problems in SR(n) for a range of n. For the graph problems in S7.2, we simply ran NeuroSAT for (the somewhat arbitrary) 512 iterations on every problem.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper402/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning a SAT Solver from Single-Bit Supervision", "abstract": "We present NeuroSAT, a message passing neural network that learns to solve SAT problems after only being trained as a classifier to predict satisfiability.  Although it is not competitive with state-of-the-art SAT solvers, NeuroSAT can solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. Moreover, NeuroSAT generalizes to novel distributions; after training only on random SAT problems, at test time it can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems, all on a range of distributions over small random graphs.", "keywords": ["sat", "search", "graph neural network", "theorem proving", "proof"], "authorids": ["dselsam@cs.stanford.edu", "mlamm@cs.stanford.edu", "buenz@cs.stanford.edu", "pliang@cs.stanford.edu", "leonardo@microsoft.com", "dill@cs.stanford.edu"], "authors": ["Daniel Selsam", "Matthew Lamm", "Benedikt B\\\"{u}nz", "Percy Liang", "Leonardo de Moura", "David L. Dill"], "TL;DR": "We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.", "pdf": "/pdf/868d9f7b066d73e8b692a14f5148c48d16376781.pdf", "paperhash": "selsam|learning_a_sat_solver_from_singlebit_supervision", "_bibtex": "@inproceedings{\nselsam2018learning,\ntitle={Learning a {SAT} Solver from Single-Bit Supervision},\nauthor={Daniel Selsam and Matthew Lamm and Benedikt B\\\"{u}nz and Percy Liang and Leonardo de Moura and David L. Dill},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJMC_iA5tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper402/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621613953, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJMC_iA5tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper402/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper402/Authors|ICLR.cc/2019/Conference/Paper402/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621613953}}}, {"id": "BJxsg-S767", "original": null, "number": 2, "cdate": 1541783795296, "ddate": null, "tcdate": 1541783795296, "tmdate": 1541783795296, "tddate": null, "forum": "HJMC_iA5tm", "replyto": "r1eoySkthX", "invitation": "ICLR.cc/2019/Conference/-/Paper402/Official_Comment", "content": {"title": "Response to AR2", "comment": "Thank you for your comments and questions.\n\n> a brief description of the initial matrices (which encode the literal en clause embeddings) would be nice.\n\nThe initial vectors L_init and C_init are simply parameters of the model, that we learn simultaneously with the other parameters.\n\n> For the sake of clarity, I would suggest to provide a figure for depicting a transition (from iteration t-1 to iteration t) in the architecture.\n\nWe graphically depict a single iteration in Figure 2, though it is very high-level. Do you have a particular middle-ground in mind, between the figure we have and the equations themselves?\n\n> As a minor comment, it would be nice (in Section 2) to define the main parameters $n$, $m$, and $d$ used in the rest of the paper.\n\nWe updated S2 to introduce n and m. We cannot introduce d there since d only makes sense in the context of the model, which is not discussed until S3.\n\n> Concerning the experimental part of the paper, Sections 4 & 5 are well-explained but, in Section 6, the solution decoding method, inspired from PCA is a bit confusing. Specifically, we don\u2019t know how a satisfying assignment is extracted from the last layer, and this should be explained in detail. According to Figure 4 and the comments above, it seems that a clustering method (with two centroids) is advocated, but this is not clear\n\nHere is the description we give in the paper on the 2-clustering approach: \"2-cluster $L^{(T)}$ to get cluster centers $\\Delta_1$ and $\\Delta_2$, partition the variables according to the predicate \\( \\| x_i - \\Delta_1 \\|^2 + \\| \\flip{x_i} - \\Delta_2 \\|^2 < \\| x_i - \\Delta_2 \\|^2 + \\| \\flip{x_i} - \\Delta_1 \\|^2 \\), and then try both candidate assignments that result from mapping the partitions to truth values.\" If you clarify what you find confusing or missing from this explanation, we will try to improve the explanation in the paper.\n\n> In Table 1, the correlation between the accuracy on SAT instances, and the percent of SAT instances solved is not clear. Is the ratio of 70% measured on the CNF instances which have been predicted to be satisfiable? Or, is this ratio measured on the whole set of test instances?\n\nAs the caption says, in that experiment we were able to decode a satisfying assignment for 70% of the satisfiable problems. The satisfiable problems includes the subset of satisfiable problems for which the network incorrectly predicted _unsat_. To a first approximation, the 70% number we report means that we could decode solutions for approximately 96% of the problems correctly predicted to be _sat_; however, the 70% does include a few problems for which the network found a solution but nonetheless incorrectly guessed _unsat_. We expect this case to happen when the network finds the solution towards the very end of message passing, and does not have enough time to flip all the literal votes. \n\nAlso note that the percentage of satisfiable problems solved is the metric we actually care about, whereas we only care about classification accuracy for instrumental reasons.\n\n> Finally, for the results established in Table 1, how many training instances and test instances have been used?\n\nIt is easy to generate unlimited data from these distributions. We trained on millions of problems, and tested on hundreds of thousands of them.\n\n> In Sec 7.1, for SR(200) tasks, was NeuroSAT tested on the same conditions as those for SR(40) tasks? Notably, what is the input dimension $d$ of the embedding space here? (I guess that $d = 128$ is too small for such large instances).\n\nOnce trained, NeuroSAT has learned parameters whose dimensions depend on the hyperparameter $d$. It is not possible to run NeuroSAT with a larger $d$ at test time. For SR(200), we use the exact same trained NeuroSAT model as in Table 1, which was trained only on SR(U(10, 40)) and has $d$ = 128.\n\n> For the 4,888 satisfiable instances generated in Sec. 7.2, which solver have been used to determine the satisfiability of those instances (I guess it is Minisat, but this should be mentioned somewhere).\n\nYes, we used Minisat. We updated the paper to mention this, and also updated S4 to make it clear we use Minisat to generate SR(n) as well.\n\n> But the notion of \u201cconfidence\u201d should be explained in more detail in this section, and more generally, in the whole paper.\n\nWe only use the phrase \"confidence\" informally. The semantics of the literal votes is defined by the network architecture.\n\n> Namely, it seems that in the last layer of each iteration, literals are voting for SAT (red colors) with some confidence (say $\\delta$) and voting for UNSAT (blue colors) with some confidence (say $\\delta\u2019$). Are $\\delta$ and $\\delta\u2019$ correlated in the neural architecture? And, how confidences for UNSAT votes are updated?\n\nI am afraid I do not understand what you are asking. Can you please clarify your use of 'correlated' and 'updated' in the last two sentences?\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper402/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning a SAT Solver from Single-Bit Supervision", "abstract": "We present NeuroSAT, a message passing neural network that learns to solve SAT problems after only being trained as a classifier to predict satisfiability.  Although it is not competitive with state-of-the-art SAT solvers, NeuroSAT can solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. Moreover, NeuroSAT generalizes to novel distributions; after training only on random SAT problems, at test time it can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems, all on a range of distributions over small random graphs.", "keywords": ["sat", "search", "graph neural network", "theorem proving", "proof"], "authorids": ["dselsam@cs.stanford.edu", "mlamm@cs.stanford.edu", "buenz@cs.stanford.edu", "pliang@cs.stanford.edu", "leonardo@microsoft.com", "dill@cs.stanford.edu"], "authors": ["Daniel Selsam", "Matthew Lamm", "Benedikt B\\\"{u}nz", "Percy Liang", "Leonardo de Moura", "David L. Dill"], "TL;DR": "We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.", "pdf": "/pdf/868d9f7b066d73e8b692a14f5148c48d16376781.pdf", "paperhash": "selsam|learning_a_sat_solver_from_singlebit_supervision", "_bibtex": "@inproceedings{\nselsam2018learning,\ntitle={Learning a {SAT} Solver from Single-Bit Supervision},\nauthor={Daniel Selsam and Matthew Lamm and Benedikt B\\\"{u}nz and Percy Liang and Leonardo de Moura and David L. Dill},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJMC_iA5tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper402/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621613953, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJMC_iA5tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper402/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper402/Authors|ICLR.cc/2019/Conference/Paper402/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621613953}}}, {"id": "ByxJhsEmam", "original": null, "number": 1, "cdate": 1541782439302, "ddate": null, "tcdate": 1541782439302, "tmdate": 1541782439302, "tddate": null, "forum": "HJMC_iA5tm", "replyto": "B1x2lmDK3X", "invitation": "ICLR.cc/2019/Conference/-/Paper402/Official_Comment", "content": {"title": "Response to AR1", "comment": "Thank you for your comments.\n\n> One thing that was a little confusing is that why should all the literals turn to SAT (turn red) to prove SAT (as it is shown in figure 3). Is it that the neural network does not realize that it has found a SAT solution with a smaller subset of SAT literals. In other words, is it not capable of taking advantage of the problem structure.\n\nRemember that the network is only trained to make the *mean* vote of the literals large on satisfiable problems and small (i.e. large and negative) on unsatisfiable problems. Thus on satisfiable problems it has a strong incentive to make all the literals vote _sat_ instead of only half of them."}, "signatures": ["ICLR.cc/2019/Conference/Paper402/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning a SAT Solver from Single-Bit Supervision", "abstract": "We present NeuroSAT, a message passing neural network that learns to solve SAT problems after only being trained as a classifier to predict satisfiability.  Although it is not competitive with state-of-the-art SAT solvers, NeuroSAT can solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. Moreover, NeuroSAT generalizes to novel distributions; after training only on random SAT problems, at test time it can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems, all on a range of distributions over small random graphs.", "keywords": ["sat", "search", "graph neural network", "theorem proving", "proof"], "authorids": ["dselsam@cs.stanford.edu", "mlamm@cs.stanford.edu", "buenz@cs.stanford.edu", "pliang@cs.stanford.edu", "leonardo@microsoft.com", "dill@cs.stanford.edu"], "authors": ["Daniel Selsam", "Matthew Lamm", "Benedikt B\\\"{u}nz", "Percy Liang", "Leonardo de Moura", "David L. Dill"], "TL;DR": "We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.", "pdf": "/pdf/868d9f7b066d73e8b692a14f5148c48d16376781.pdf", "paperhash": "selsam|learning_a_sat_solver_from_singlebit_supervision", "_bibtex": "@inproceedings{\nselsam2018learning,\ntitle={Learning a {SAT} Solver from Single-Bit Supervision},\nauthor={Daniel Selsam and Matthew Lamm and Benedikt B\\\"{u}nz and Percy Liang and Leonardo de Moura and David L. Dill},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJMC_iA5tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper402/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621613953, "tddate": null, "super": null, "final": null, "reply": {"forum": "HJMC_iA5tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper402/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper402/Authors|ICLR.cc/2019/Conference/Paper402/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621613953}}}, {"id": "B1x2lmDK3X", "original": null, "number": 3, "cdate": 1541137139581, "ddate": null, "tcdate": 1541137139581, "tmdate": 1541534025995, "tddate": null, "forum": "HJMC_iA5tm", "replyto": "HJMC_iA5tm", "invitation": "ICLR.cc/2019/Conference/-/Paper402/Official_Review", "content": {"title": "A neural architecture and analysis of predicting satisfiability with minimal supervision", "review": "The paper describes a general neural  network architecture for predicting satisfiability. Specifically, the contributions include an encoding for SAT problems, and predicting SAT using a message passing method, where the embeddings for literals and clauses are iteratively changed until convergence.\n\nThe paper seems significant considering that it brings together SAT solving and neural network architectures. The paper is very clearly written and quite precise about its contributions. The analysis especially figures 3,4, and 7 seems to give a nice intuitive ideas as to what the neural network is trying to do. However, one weakness is that the problems are run on a specific type of SAT problem the authors have created. Of course, the authors make it clear that the objective is not really to create a. State-of-the-art solver but rather to understand what a neural network trying to do SAT solving is capable of doing. On this front, I think the paper succeeds in doing this. One thing that was a little confusing is that why should all the literals turn to SAT (turn red) to prove SAT (as it is shown in figure 3). Is it that the neural network does not realize that it has found a SAT solution with a smaller subset of SAT literals. In other words, is it not capable of taking advantage of the problem structure.\n\nIn general though, this seemed to be an interesting paper though its practical implications are quite hard to know either in the SAT community or in the neural network community.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper402/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning a SAT Solver from Single-Bit Supervision", "abstract": "We present NeuroSAT, a message passing neural network that learns to solve SAT problems after only being trained as a classifier to predict satisfiability.  Although it is not competitive with state-of-the-art SAT solvers, NeuroSAT can solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. Moreover, NeuroSAT generalizes to novel distributions; after training only on random SAT problems, at test time it can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems, all on a range of distributions over small random graphs.", "keywords": ["sat", "search", "graph neural network", "theorem proving", "proof"], "authorids": ["dselsam@cs.stanford.edu", "mlamm@cs.stanford.edu", "buenz@cs.stanford.edu", "pliang@cs.stanford.edu", "leonardo@microsoft.com", "dill@cs.stanford.edu"], "authors": ["Daniel Selsam", "Matthew Lamm", "Benedikt B\\\"{u}nz", "Percy Liang", "Leonardo de Moura", "David L. Dill"], "TL;DR": "We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.", "pdf": "/pdf/868d9f7b066d73e8b692a14f5148c48d16376781.pdf", "paperhash": "selsam|learning_a_sat_solver_from_singlebit_supervision", "_bibtex": "@inproceedings{\nselsam2018learning,\ntitle={Learning a {SAT} Solver from Single-Bit Supervision},\nauthor={Daniel Selsam and Matthew Lamm and Benedikt B\\\"{u}nz and Percy Liang and Leonardo de Moura and David L. Dill},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJMC_iA5tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper402/Official_Review", "cdate": 1542234469497, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJMC_iA5tm", "replyto": "HJMC_iA5tm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper402/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335715975, "tmdate": 1552335715975, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper402/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "r1eoySkthX", "original": null, "number": 2, "cdate": 1541104867483, "ddate": null, "tcdate": 1541104867483, "tmdate": 1541534025786, "tddate": null, "forum": "HJMC_iA5tm", "replyto": "HJMC_iA5tm", "invitation": "ICLR.cc/2019/Conference/-/Paper402/Official_Review", "content": {"title": "A promising approach to solve SAT problems with neural architectures", "review": "This paper presents the NeuroSAT architecture, which uses a deep, message passing neural net for predicting the satisfiability of CNF instances. The architecture is also able to predict a satisfiable assignment in the SAT case, and the literals involved in some minimal conflicting set of clauses (i.e. core) in the UNSAT case. The NeuroSAT architecture is based on a vector space embedding of literals and clauses, which exploits (with message passing) some important symmetries of SAT instances (permutation invariance and negation invariance). This architecture is tested on various classes of random SAT instances, involving both unstructured (RS) problems, and structured ones (e.g. graph colorings, vertex covers, dominating sets, etc.).\n\nOverall the paper is well-motivated, and the experimental results are quite convincing. Arguably, the salient characteristic of NeuroSAT is to iteratively refine the confidence of literals voting for the SAT - or UNSAT - output, using a voting scheme on the last iteration of the literal matrix. This is very interesting, and NeuroSAT might be used to help existing solvers in choosing variable orderings for tackling hard instances, or hard queries (e.g. find a core).\n\nOn the other hand, the technical description of the architecture (sec. 3) is perhaps a little vague for having a clear intuition of how the classification task - for SAT instances - is handled in the NeuroSAT architecture. Namely, a brief description of the initial matrices (which encode the literal en clause embeddings) would be nice. Some comments on the role played by the multilayer perceptron units and the normalization units would also be welcome. The two update rules in Page 3 could be explained in more detail. For the sake of clarity, I would suggest to provide a figure for depicting a transition (from iteration t-1 to iteration t) in the architecture. As a minor comment, it would be nice (in Section 2) to define the main parameters $n$, $m$, and $d$ used in the rest of the paper.\n\nConcerning the experimental part of the paper, Sections 4 & 5 are well-explained but, in Section 6,  the solution decoding method, inspired from PCA is a bit confusing. Specifically, we don\u2019t know how a satisfying assignment is extracted from the last layer, and this should be explained in detail. According to Figure 4 and the comments above, it seems that a clustering method (with two centroids) is advocated, but this is not clear. In Table 1, the correlation between the accuracy on SAT instances, and the percent of SAT instances solved is not clear. Is the ratio of 70% measured on the CNF instances which have been predicted to be satisfiable? Or, is this ratio measured on the whole set of test instances? Finally, for the results established in Table 1, how many training instances and test instances have been used?\n\nIn Section 7, some important aspects related to experiments, are missing. In Sec 7.1, for SR(200) tasks, was NeuroSAT tested on the same conditions as those for SR(40) tasks? Notably, what is the input dimension $d$ of the embedding space here? (I guess that $d = 128$ is too small for such large instances). Also, how many training and test instances have been used to plot the curves in Figure 5? For the 4,888 satisfiable instances generated in Sec. 7.2, which solver have been used to determine the satisfiability of those instances (I guess it is Minisat, but this should be mentioned somewhere). \n\nIn Section 8, I found interesting the the ability of NeuroSAT in predicting the literals that participate in an UNSAT core. Indeed the problem of finding an UNSAT core in CNF instances is computationally harder than determining the satisfiability of this instance. So, NeuroSAT might be used here to help a solver in finding a core. But the notion of \u201cconfidence\u201d should be explained in more detail in this section, and more generally, in the whole paper. Namely, it seems that in the last layer of each iteration, literals are voting for SAT (red colors) with some confidence (say $\\delta$)  and voting for UNSAT (blue colors) with some confidence (say $\\delta\u2019$). Are $\\delta$ and $\\delta\u2019$ correlated in the neural architecture? And, how confidences for UNSAT votes are updated?\n\nFinally, I found that the different benchmarks where relevant, but I would also suggest (for future work, or in the appendix) to additionally perform experiments on the well-known random 3-SAT instances ($k$ is fixed to 3). Here, it is well-known that a phase transition (on the instances, not the solver/learner) occurs at 4.26 for the clause/variable ratio. A plot displaying the performance of NeuroSAT (accuracy in predicting the label of the instance) versus the clause/variable ratio would be very helpful in assessing the robustness of NeuroSAT on the so-called \u201chard\u201d instances (which are close to 4.26). By extension, there have been a lot of recent work in generating \u201cpseudo-industrial\u201d random SAT instances, which incorporate some structure (e.g. communities) in order to mimic real-world structured SAT instances. To this point, it would be interesting to analyze the performance of NeuroSAT on such pseudo-industrial instances.\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper402/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning a SAT Solver from Single-Bit Supervision", "abstract": "We present NeuroSAT, a message passing neural network that learns to solve SAT problems after only being trained as a classifier to predict satisfiability.  Although it is not competitive with state-of-the-art SAT solvers, NeuroSAT can solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. Moreover, NeuroSAT generalizes to novel distributions; after training only on random SAT problems, at test time it can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems, all on a range of distributions over small random graphs.", "keywords": ["sat", "search", "graph neural network", "theorem proving", "proof"], "authorids": ["dselsam@cs.stanford.edu", "mlamm@cs.stanford.edu", "buenz@cs.stanford.edu", "pliang@cs.stanford.edu", "leonardo@microsoft.com", "dill@cs.stanford.edu"], "authors": ["Daniel Selsam", "Matthew Lamm", "Benedikt B\\\"{u}nz", "Percy Liang", "Leonardo de Moura", "David L. Dill"], "TL;DR": "We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.", "pdf": "/pdf/868d9f7b066d73e8b692a14f5148c48d16376781.pdf", "paperhash": "selsam|learning_a_sat_solver_from_singlebit_supervision", "_bibtex": "@inproceedings{\nselsam2018learning,\ntitle={Learning a {SAT} Solver from Single-Bit Supervision},\nauthor={Daniel Selsam and Matthew Lamm and Benedikt B\\\"{u}nz and Percy Liang and Leonardo de Moura and David L. Dill},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJMC_iA5tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper402/Official_Review", "cdate": 1542234469497, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJMC_iA5tm", "replyto": "HJMC_iA5tm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper402/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335715975, "tmdate": 1552335715975, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper402/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "H1x_vEau3m", "original": null, "number": 1, "cdate": 1541096543871, "ddate": null, "tcdate": 1541096543871, "tmdate": 1541534025537, "tddate": null, "forum": "HJMC_iA5tm", "replyto": "HJMC_iA5tm", "invitation": "ICLR.cc/2019/Conference/-/Paper402/Official_Review", "content": {"title": "review for \"Learning a SAT Solver from Single-Bit Supervision\"", "review": "This paper trains a neural network to solve the satisfiability problems. Based on the message passing neural network, it presents NeuroSAT and trains it as a classifier to predict satisfiability under a single bit of supervision. After training, NeuroSAT can solve problems that are larger and more difficult than it ever saw during training. Furthermore, the authors present a way to decode the solutions from the network's activations. Besides, for unsatisfiable problems, the paper also presents NeuroUNSAT, which learns to detect the contradictions in the form of UNSAT cores.\n\nRelevance: this paper is likely to be of interest to a large proportion of the community for several reasons. Firstly, satisfiability problems arise from a variety of domains. This paper starts with a new angle to solve the SAT problem. Secondly, it uses neural networks in the SAT problem and establishes that neural networks can learn to perform a discrete search. Thirdly, the system used in this paper may also help improve existing SAT solvers.\n\nSignificance: I think the results are significant. For the decoding satisfying assignments section, the two-dimensional PCA embeddings are very clear. And the NeuroSAT's success rate for more significant problems and different problems has shown it's generalization ability. Finally, the sequences of literal votes in NeuroUNSAT have proved its ability to detect unsatisfied cores.\n\nNovelty: NeuroSAT\u2019s approach is novel. Based on message passing neural networks, it trains a neural network to learn to solve the SAT problem. \n\nSoundness: This paper is technically sound. \n\nEvaluation: The experimental section is comprehensive. There are a variety of graphs showing the performance and ability of your architecture. However, the theoretical analysis isn't very sufficient. For instance, why does the change of the dataset from the original SR(n) to SRC(n,u) lead to the change of the behavior of the network from searching for a satisfying assignment indefinitely to detecting the unsatisfiable cores?\n\nClarity: As a whole, the paper is clear. The definition of the problem, the model structure, the data generation, the training procedure, and the evaluation are all well organized. However, there is still a few points requiring more explanation. For instance, in figure 3, I am not sure whether darker value means larger value or smaller value because the authors only mentioned that white represents zero, blue negative and red positive. Also, in figure 7, I am not sure whether those black grids represent higher positive values or lower negative values.\n\nA few questions:\n\nWhat's the initialization of the two vectors the authors use for tiling operation? Does the initialization differ for different types of SAT problems?\n\nHow do the authors decide the number of iterations necessary for solving a particular SAT problem?\n\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper402/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning a SAT Solver from Single-Bit Supervision", "abstract": "We present NeuroSAT, a message passing neural network that learns to solve SAT problems after only being trained as a classifier to predict satisfiability.  Although it is not competitive with state-of-the-art SAT solvers, NeuroSAT can solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. Moreover, NeuroSAT generalizes to novel distributions; after training only on random SAT problems, at test time it can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems, all on a range of distributions over small random graphs.", "keywords": ["sat", "search", "graph neural network", "theorem proving", "proof"], "authorids": ["dselsam@cs.stanford.edu", "mlamm@cs.stanford.edu", "buenz@cs.stanford.edu", "pliang@cs.stanford.edu", "leonardo@microsoft.com", "dill@cs.stanford.edu"], "authors": ["Daniel Selsam", "Matthew Lamm", "Benedikt B\\\"{u}nz", "Percy Liang", "Leonardo de Moura", "David L. Dill"], "TL;DR": "We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.", "pdf": "/pdf/868d9f7b066d73e8b692a14f5148c48d16376781.pdf", "paperhash": "selsam|learning_a_sat_solver_from_singlebit_supervision", "_bibtex": "@inproceedings{\nselsam2018learning,\ntitle={Learning a {SAT} Solver from Single-Bit Supervision},\nauthor={Daniel Selsam and Matthew Lamm and Benedikt B\\\"{u}nz and Percy Liang and Leonardo de Moura and David L. Dill},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJMC_iA5tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper402/Official_Review", "cdate": 1542234469497, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HJMC_iA5tm", "replyto": "HJMC_iA5tm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper402/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335715975, "tmdate": 1552335715975, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper402/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "r1x80rJJTQ", "original": null, "number": 3, "cdate": 1541498318019, "ddate": null, "tcdate": 1541498318019, "tmdate": 1541498318019, "tddate": null, "forum": "HJMC_iA5tm", "replyto": "B1x2lmDK3X", "invitation": "ICLR.cc/2019/Conference/-/Paper402/Public_Comment", "content": {"comment": "The paper (with admirable honesty) itself claims to have little to no impact on modern SAT solving. To quote, \"As we stressed early on, as an end-to-end SAT solver the trained NeuroSAT system discussed in this paper is still vastly less reliable than the state-of-the-art. We concede that we see no obvious path to beating existing SAT solvers. \"", "title": "Likely no practical implications?"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning a SAT Solver from Single-Bit Supervision", "abstract": "We present NeuroSAT, a message passing neural network that learns to solve SAT problems after only being trained as a classifier to predict satisfiability.  Although it is not competitive with state-of-the-art SAT solvers, NeuroSAT can solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. Moreover, NeuroSAT generalizes to novel distributions; after training only on random SAT problems, at test time it can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems, all on a range of distributions over small random graphs.", "keywords": ["sat", "search", "graph neural network", "theorem proving", "proof"], "authorids": ["dselsam@cs.stanford.edu", "mlamm@cs.stanford.edu", "buenz@cs.stanford.edu", "pliang@cs.stanford.edu", "leonardo@microsoft.com", "dill@cs.stanford.edu"], "authors": ["Daniel Selsam", "Matthew Lamm", "Benedikt B\\\"{u}nz", "Percy Liang", "Leonardo de Moura", "David L. Dill"], "TL;DR": "We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.", "pdf": "/pdf/868d9f7b066d73e8b692a14f5148c48d16376781.pdf", "paperhash": "selsam|learning_a_sat_solver_from_singlebit_supervision", "_bibtex": "@inproceedings{\nselsam2018learning,\ntitle={Learning a {SAT} Solver from Single-Bit Supervision},\nauthor={Daniel Selsam and Matthew Lamm and Benedikt B\\\"{u}nz and Percy Liang and Leonardo de Moura and David L. Dill},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJMC_iA5tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper402/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311848611, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "HJMC_iA5tm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311848611}}}, {"id": "rJlAYEJyT7", "original": null, "number": 2, "cdate": 1541497989742, "ddate": null, "tcdate": 1541497989742, "tmdate": 1541498003057, "tddate": null, "forum": "HJMC_iA5tm", "replyto": "rylt7MfEhm", "invitation": "ICLR.cc/2019/Conference/-/Paper402/Public_Comment", "content": {"comment": "I am curious what the authors have to say regarding this comment. ", "title": "Can the authors shed some light on this front? (Not the OP, but another interested reader)"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning a SAT Solver from Single-Bit Supervision", "abstract": "We present NeuroSAT, a message passing neural network that learns to solve SAT problems after only being trained as a classifier to predict satisfiability.  Although it is not competitive with state-of-the-art SAT solvers, NeuroSAT can solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. Moreover, NeuroSAT generalizes to novel distributions; after training only on random SAT problems, at test time it can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems, all on a range of distributions over small random graphs.", "keywords": ["sat", "search", "graph neural network", "theorem proving", "proof"], "authorids": ["dselsam@cs.stanford.edu", "mlamm@cs.stanford.edu", "buenz@cs.stanford.edu", "pliang@cs.stanford.edu", "leonardo@microsoft.com", "dill@cs.stanford.edu"], "authors": ["Daniel Selsam", "Matthew Lamm", "Benedikt B\\\"{u}nz", "Percy Liang", "Leonardo de Moura", "David L. Dill"], "TL;DR": "We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.", "pdf": "/pdf/868d9f7b066d73e8b692a14f5148c48d16376781.pdf", "paperhash": "selsam|learning_a_sat_solver_from_singlebit_supervision", "_bibtex": "@inproceedings{\nselsam2018learning,\ntitle={Learning a {SAT} Solver from Single-Bit Supervision},\nauthor={Daniel Selsam and Matthew Lamm and Benedikt B\\\"{u}nz and Percy Liang and Leonardo de Moura and David L. Dill},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJMC_iA5tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper402/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311848611, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "HJMC_iA5tm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311848611}}}, {"id": "rylt7MfEhm", "original": null, "number": 1, "cdate": 1540788768697, "ddate": null, "tcdate": 1540788768697, "tmdate": 1540788916567, "tddate": null, "forum": "HJMC_iA5tm", "replyto": "HJMC_iA5tm", "invitation": "ICLR.cc/2019/Conference/-/Paper402/Public_Comment", "content": {"comment": "I have two points:\n1) Devlin and O\u2019Sullivan (2008) examined the performance of a host of simple ML techniques for classifying satisfiability. Experimental results showed that Random Forest achieved very good performance (90+% accuracy for difficult large industrial SAT instances as well as for random 3-SAT and random k-SAT instances sourced from Satlib). However, the proposed deep learning based method achieves only 85% accuracy on randomly generated instances. This makes me question the significance of this work. The authors say that the data generation heuristic mentioned in the paper is for helping the neural network generalize better. I would be more convinced if the authors demonstrate the generalizability by evaluating the performance of NeuroSAT on real industrial instances. In conclusion, my main point is that after reading the work of Devlin and O\u2019Sullivan (2008), I don't feel this work is important or significant.\n\n2) As mentioned in the paper, for some cases, it may be possible to decode the satisfying assignments. However, this may require the graph neural network algorithm runs for many iterations. I was wondering what is the average required running time for decoding the satisfying assignments (e.g., how many seconds, ...)? Because if it takes too long time, then I would rather just use an existing off-the-shell SAT solver.\n\nReferences:\n[1] David Devlin and Barry O\u2019Sullivan. B.: Satisfiability as a classification problem. In Proc. of the 19th Irish Conf. on\nArtificial Intelligence and Cognitive Science, 2008.", "title": "How significant is the work?"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper402/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning a SAT Solver from Single-Bit Supervision", "abstract": "We present NeuroSAT, a message passing neural network that learns to solve SAT problems after only being trained as a classifier to predict satisfiability.  Although it is not competitive with state-of-the-art SAT solvers, NeuroSAT can solve problems that are substantially larger and more difficult than it ever saw during training by simply running for more iterations. Moreover, NeuroSAT generalizes to novel distributions; after training only on random SAT problems, at test time it can solve SAT problems encoding graph coloring, clique detection, dominating set, and vertex cover problems, all on a range of distributions over small random graphs.", "keywords": ["sat", "search", "graph neural network", "theorem proving", "proof"], "authorids": ["dselsam@cs.stanford.edu", "mlamm@cs.stanford.edu", "buenz@cs.stanford.edu", "pliang@cs.stanford.edu", "leonardo@microsoft.com", "dill@cs.stanford.edu"], "authors": ["Daniel Selsam", "Matthew Lamm", "Benedikt B\\\"{u}nz", "Percy Liang", "Leonardo de Moura", "David L. Dill"], "TL;DR": "We train a graph network to predict boolean satisfiability and show that it learns to search for solutions, and that the solutions it finds can be decoded from its activations.", "pdf": "/pdf/868d9f7b066d73e8b692a14f5148c48d16376781.pdf", "paperhash": "selsam|learning_a_sat_solver_from_singlebit_supervision", "_bibtex": "@inproceedings{\nselsam2018learning,\ntitle={Learning a {SAT} Solver from Single-Bit Supervision},\nauthor={Daniel Selsam and Matthew Lamm and Benedikt B\\\"{u}nz and Percy Liang and Leonardo de Moura and David L. Dill},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HJMC_iA5tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper402/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311848611, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "HJMC_iA5tm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper402/Authors", "ICLR.cc/2019/Conference/Paper402/Reviewers", "ICLR.cc/2019/Conference/Paper402/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311848611}}}], "count": 20}