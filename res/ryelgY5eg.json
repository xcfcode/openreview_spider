{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1487957638719, "tcdate": 1478295552807, "number": 469, "id": "ryelgY5eg", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "ryelgY5eg", "signatures": ["~Akshay_Balsubramani1"], "readers": ["everyone"], "content": {"title": "Optimal Binary Autoencoding with Pairwise Correlations", "abstract": "We formulate learning of a binary autoencoder as a biconvex optimization problem which learns from the pairwise correlations between encoded and decoded bits. Among all possible algorithms that use this information, ours finds the autoencoder that reconstructs its inputs with worst-case optimal loss. The optimal decoder is a single layer of artificial neurons, emerging entirely from the minimax loss minimization, and with weights learned by convex optimization. All this is reflected in competitive experimental results, demonstrating that binary autoencoding can be done efficiently by conveying information in pairwise correlations in an optimal fashion. ", "pdf": "/pdf/60c41b4b1ae5395c59d55554c2da52316ed79016.pdf", "TL;DR": "Efficient biconvex learning of binary autoencoders, using pairwise correlations between encodings and decodings, is strongly optimal.", "paperhash": "balsubramani|optimal_binary_autoencoding_with_pairwise_correlations", "authors": ["Akshay Balsubramani"], "authorids": ["abalsubr@stanford.edu"], "keywords": ["Theory", "Unsupervised Learning", "Games"], "conflicts": ["ucsd.edu", "stanford.edu"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 6, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396601780, "tcdate": 1486396601780, "number": 1, "id": "HJMp2MLOx", "invitation": "ICLR.cc/2017/conference/-/paper469/acceptance", "forum": "ryelgY5eg", "replyto": "ryelgY5eg", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "All reviewers (weakly) support the acceptance of the paper. I also think that binary neural networks model is an important direction to explore.", "decision": "Accept (Poster)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimal Binary Autoencoding with Pairwise Correlations", "abstract": "We formulate learning of a binary autoencoder as a biconvex optimization problem which learns from the pairwise correlations between encoded and decoded bits. Among all possible algorithms that use this information, ours finds the autoencoder that reconstructs its inputs with worst-case optimal loss. The optimal decoder is a single layer of artificial neurons, emerging entirely from the minimax loss minimization, and with weights learned by convex optimization. All this is reflected in competitive experimental results, demonstrating that binary autoencoding can be done efficiently by conveying information in pairwise correlations in an optimal fashion. ", "pdf": "/pdf/60c41b4b1ae5395c59d55554c2da52316ed79016.pdf", "TL;DR": "Efficient biconvex learning of binary autoencoders, using pairwise correlations between encodings and decodings, is strongly optimal.", "paperhash": "balsubramani|optimal_binary_autoencoding_with_pairwise_correlations", "authors": ["Akshay Balsubramani"], "authorids": ["abalsubr@stanford.edu"], "keywords": ["Theory", "Unsupervised Learning", "Games"], "conflicts": ["ucsd.edu", "stanford.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396602282, "id": "ICLR.cc/2017/conference/-/paper469/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "ryelgY5eg", "replyto": "ryelgY5eg", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396602282}}}, {"tddate": null, "tmdate": 1484770492402, "tcdate": 1484763459289, "number": 2, "id": "ryiHb4pIg", "invitation": "ICLR.cc/2017/conference/-/paper469/public/comment", "forum": "ryelgY5eg", "replyto": "Sy2MfVHNl", "signatures": ["~Akshay_Balsubramani1"], "readers": ["everyone"], "writers": ["~Akshay_Balsubramani1"], "content": {"title": "author response", "comment": "Thanks very much for your comments! I just wanted to address your point about denoising AEs.\n\nDAEs would not necessarily perform better on the loss minimization than AEs (after all, they are adding noise to the AE problem; I did not find a task where they empirically did better by that measure). But their well-known published results have been on classification tasks evaluated downstream on the learned features. I chose the more direct reconstruction loss comparison here, because the performance of the paper's new optimization method on its new objective function was of interest. \n\nIt is possible to instead compare using classification performance of e.g. logistic regression on the learned encodings, and the performance is again markedly better with the new approach (this is consistent with the sometimes dramatically better reconstruction performance). I have not done them for all datasets; if possible I will add them shortly. I did add a short appendix explicitly deriving the denoising autoencoding method, and posted this as a new revision. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimal Binary Autoencoding with Pairwise Correlations", "abstract": "We formulate learning of a binary autoencoder as a biconvex optimization problem which learns from the pairwise correlations between encoded and decoded bits. Among all possible algorithms that use this information, ours finds the autoencoder that reconstructs its inputs with worst-case optimal loss. The optimal decoder is a single layer of artificial neurons, emerging entirely from the minimax loss minimization, and with weights learned by convex optimization. All this is reflected in competitive experimental results, demonstrating that binary autoencoding can be done efficiently by conveying information in pairwise correlations in an optimal fashion. ", "pdf": "/pdf/60c41b4b1ae5395c59d55554c2da52316ed79016.pdf", "TL;DR": "Efficient biconvex learning of binary autoencoders, using pairwise correlations between encodings and decodings, is strongly optimal.", "paperhash": "balsubramani|optimal_binary_autoencoding_with_pairwise_correlations", "authors": ["Akshay Balsubramani"], "authorids": ["abalsubr@stanford.edu"], "keywords": ["Theory", "Unsupervised Learning", "Games"], "conflicts": ["ucsd.edu", "stanford.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287563952, "id": "ICLR.cc/2017/conference/-/paper469/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ryelgY5eg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper469/reviewers", "ICLR.cc/2017/conference/paper469/areachairs"], "cdate": 1485287563952}}}, {"tddate": null, "tmdate": 1483480082327, "tcdate": 1483479409755, "number": 1, "id": "Byc_K9tSg", "invitation": "ICLR.cc/2017/conference/-/paper469/public/comment", "forum": "ryelgY5eg", "replyto": "B1uDSibVe", "signatures": ["~Akshay_Balsubramani1"], "readers": ["everyone"], "writers": ["~Akshay_Balsubramani1"], "content": {"title": "author response", "comment": "Thanks for your constructive comments!\n\nIn response, I first want to emphasize that the paper does not posit a \"linear relation between the encoding and the data\", only linear constraints on the reconstructions in terms of the encodings. This is a very significant difference because the former is a model assumption, while the latter is a sample statistic that exists regardless of how the encodings/reconstructions are generated. Furthermore, while PCA only considers second-order statistics between visible units, the hidden units here allow us to consider higher-order correlations too, just like a vanilla autoencoder or a Boltzmann machine. Note that the encodings and decodings are allowed to be nonlinear (arbitrary!) functions of each other.\n\nSomewhat similarly, 1-bit compressed sensing is very different from our approach even at its foundations, as its central concern is with a linear measurement model (which is then quantized). That theory does not apply as generally as the new approach does (i.e. without measurement incoherence assumptions like RIP, or to general nonconvex bitwise losses). \n\nNow to answer your questions:\n- On performance of sign-thresholded PCA: I understand this suggestion as a nice baseline (although with caveats as discussed above). So I tried using regular PCA to encode data into the projections on the top H PCs, and reconstructing the data by projecting back and clipping the result to [-1,1]. I just posted the results in a new version of the paper - they are uniformly significantly worse on these datasets than a vanilla AE (and, transitively, than PC-AE). \n\n- Initializing with PCA weights gives the same performance; the biconvex objective function seems fairly easy to optimize by the algorithm I have given. (This may not be surprising since it is convex, Lipschitz, etc., though unproven).\n\n- Performance on CIFAR: It is not straightforward to me how to binarize CIFAR; the two natural ways (averaging the 3 channels and taking just a single channel) do not always result in very realistic-looking pictures. But I tried the algorithm on the former, where it gives roughly equal performance to the vanilla AE within error (though it appears to converge faster). I am working on more experiments, using the code posted on github (see paper for URL)."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimal Binary Autoencoding with Pairwise Correlations", "abstract": "We formulate learning of a binary autoencoder as a biconvex optimization problem which learns from the pairwise correlations between encoded and decoded bits. Among all possible algorithms that use this information, ours finds the autoencoder that reconstructs its inputs with worst-case optimal loss. The optimal decoder is a single layer of artificial neurons, emerging entirely from the minimax loss minimization, and with weights learned by convex optimization. All this is reflected in competitive experimental results, demonstrating that binary autoencoding can be done efficiently by conveying information in pairwise correlations in an optimal fashion. ", "pdf": "/pdf/60c41b4b1ae5395c59d55554c2da52316ed79016.pdf", "TL;DR": "Efficient biconvex learning of binary autoencoders, using pairwise correlations between encodings and decodings, is strongly optimal.", "paperhash": "balsubramani|optimal_binary_autoencoding_with_pairwise_correlations", "authors": ["Akshay Balsubramani"], "authorids": ["abalsubr@stanford.edu"], "keywords": ["Theory", "Unsupervised Learning", "Games"], "conflicts": ["ucsd.edu", "stanford.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287563952, "id": "ICLR.cc/2017/conference/-/paper469/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "ryelgY5eg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper469/reviewers", "ICLR.cc/2017/conference/paper469/areachairs"], "cdate": 1485287563952}}}, {"tddate": null, "tmdate": 1482142227584, "tcdate": 1482142227584, "number": 3, "id": "Sy2MfVHNl", "invitation": "ICLR.cc/2017/conference/-/paper469/official/review", "forum": "ryelgY5eg", "replyto": "ryelgY5eg", "signatures": ["ICLR.cc/2017/conference/paper469/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper469/AnonReviewer3"], "content": {"title": "Review", "rating": "7: Good paper, accept", "review": "The paper presents a novel look at binary auto-encoders, formulating the objective function as a min-max reconstruction error over a training set given the observed intermediate representations. The author shows that this formulation leads to a bi-convex problem that can be solved by alternating minimisation methods; this part is non-trivial and is the main contribution of the paper. Proof-of-concept experiments are performed, showing improvements for 1-hidden layer auto-encoders with respect to a vanilla approach. \n\nThe experimental section is fairly weak because the literature on auto-encoders is huge and many variants were shown to perform better than straightforward approaches without being more complicated (e.g., denoising auto-encoders). Yet, the paper presents an analysis that leads to a new learning algorithm for an old problem, and is likely worth discussing. ", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimal Binary Autoencoding with Pairwise Correlations", "abstract": "We formulate learning of a binary autoencoder as a biconvex optimization problem which learns from the pairwise correlations between encoded and decoded bits. Among all possible algorithms that use this information, ours finds the autoencoder that reconstructs its inputs with worst-case optimal loss. The optimal decoder is a single layer of artificial neurons, emerging entirely from the minimax loss minimization, and with weights learned by convex optimization. All this is reflected in competitive experimental results, demonstrating that binary autoencoding can be done efficiently by conveying information in pairwise correlations in an optimal fashion. ", "pdf": "/pdf/60c41b4b1ae5395c59d55554c2da52316ed79016.pdf", "TL;DR": "Efficient biconvex learning of binary autoencoders, using pairwise correlations between encodings and decodings, is strongly optimal.", "paperhash": "balsubramani|optimal_binary_autoencoding_with_pairwise_correlations", "authors": ["Akshay Balsubramani"], "authorids": ["abalsubr@stanford.edu"], "keywords": ["Theory", "Unsupervised Learning", "Games"], "conflicts": ["ucsd.edu", "stanford.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512575700, "id": "ICLR.cc/2017/conference/-/paper469/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper469/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper469/AnonReviewer1", "ICLR.cc/2017/conference/paper469/AnonReviewer2", "ICLR.cc/2017/conference/paper469/AnonReviewer3"], "reply": {"forum": "ryelgY5eg", "replyto": "ryelgY5eg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper469/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper469/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512575700}}}, {"tddate": null, "tmdate": 1481988073947, "tcdate": 1481988073947, "number": 2, "id": "HkMl_AzNx", "invitation": "ICLR.cc/2017/conference/-/paper469/official/review", "forum": "ryelgY5eg", "replyto": "ryelgY5eg", "signatures": ["ICLR.cc/2017/conference/paper469/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper469/AnonReviewer2"], "content": {"title": "Review", "rating": "7: Good paper, accept", "review": "The author attacks the problem of shallow binary autoencoders using a minmax game approach. The algorithm, though simple, appears to be very effective. The paper is well written and has sound analyses. Although the work does not extend to deep networks immediately, its connections with other popular minmax approaches (eg GANs) could be fruitful in the future.", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimal Binary Autoencoding with Pairwise Correlations", "abstract": "We formulate learning of a binary autoencoder as a biconvex optimization problem which learns from the pairwise correlations between encoded and decoded bits. Among all possible algorithms that use this information, ours finds the autoencoder that reconstructs its inputs with worst-case optimal loss. The optimal decoder is a single layer of artificial neurons, emerging entirely from the minimax loss minimization, and with weights learned by convex optimization. All this is reflected in competitive experimental results, demonstrating that binary autoencoding can be done efficiently by conveying information in pairwise correlations in an optimal fashion. ", "pdf": "/pdf/60c41b4b1ae5395c59d55554c2da52316ed79016.pdf", "TL;DR": "Efficient biconvex learning of binary autoencoders, using pairwise correlations between encodings and decodings, is strongly optimal.", "paperhash": "balsubramani|optimal_binary_autoencoding_with_pairwise_correlations", "authors": ["Akshay Balsubramani"], "authorids": ["abalsubr@stanford.edu"], "keywords": ["Theory", "Unsupervised Learning", "Games"], "conflicts": ["ucsd.edu", "stanford.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512575700, "id": "ICLR.cc/2017/conference/-/paper469/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper469/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper469/AnonReviewer1", "ICLR.cc/2017/conference/paper469/AnonReviewer2", "ICLR.cc/2017/conference/paper469/AnonReviewer3"], "reply": {"forum": "ryelgY5eg", "replyto": "ryelgY5eg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper469/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper469/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512575700}}}, {"tddate": null, "tmdate": 1481909599918, "tcdate": 1481909599918, "number": 1, "id": "B1uDSibVe", "invitation": "ICLR.cc/2017/conference/-/paper469/official/review", "forum": "ryelgY5eg", "replyto": "ryelgY5eg", "signatures": ["ICLR.cc/2017/conference/paper469/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper469/AnonReviewer1"], "content": {"title": "", "rating": "6: Marginally above acceptance threshold", "review": "The paper propose to find an optimal decoder for binary data using a min-max decoder on the binary hypercube given a linear constraint on the correlation between the encoder and the  data. \nThe paper gives finally that the optimal decoder as logistic of the lagragian W multiplying the encoding e.\n \nGiven the weights of the \u2018min-max\u2019decoder W the paper finds the best encoding for the data distribution considered, by minimizing that error as a function of the encoding.\n\nThe paper then alternates that optimization between the encoding and the min-max decoding, starting from random weights W.\n\n\nclarity:\n\n-The paper would be easier to follow if the real data (x in section 3 ) is differentiated from the worst case data played by the model (x in section 2). \n\n\nsignificance\n\nOverall I like the paper, however I have some doubts on what the alternating optimization optimum ends up being.  The paper ends up implementing a single layer network. The correlation constraints while convenient in the derivation, is  a bit intriguing. Since linear relation between the encoding and the data  seems to be weak modeling constraint and might be not different from what PCA would implement.\n\n- what is the performance of PCA on those tasks? one could you use a simple sign function to decode. This is related to one bit compressive sensing.\n\n- what happens if you initialize W in algorithm one with PCA weights? or weighted pca weights?\n\n- Have you tried on more complex datasets such as cifar?", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimal Binary Autoencoding with Pairwise Correlations", "abstract": "We formulate learning of a binary autoencoder as a biconvex optimization problem which learns from the pairwise correlations between encoded and decoded bits. Among all possible algorithms that use this information, ours finds the autoencoder that reconstructs its inputs with worst-case optimal loss. The optimal decoder is a single layer of artificial neurons, emerging entirely from the minimax loss minimization, and with weights learned by convex optimization. All this is reflected in competitive experimental results, demonstrating that binary autoencoding can be done efficiently by conveying information in pairwise correlations in an optimal fashion. ", "pdf": "/pdf/60c41b4b1ae5395c59d55554c2da52316ed79016.pdf", "TL;DR": "Efficient biconvex learning of binary autoencoders, using pairwise correlations between encodings and decodings, is strongly optimal.", "paperhash": "balsubramani|optimal_binary_autoencoding_with_pairwise_correlations", "authors": ["Akshay Balsubramani"], "authorids": ["abalsubr@stanford.edu"], "keywords": ["Theory", "Unsupervised Learning", "Games"], "conflicts": ["ucsd.edu", "stanford.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512575700, "id": "ICLR.cc/2017/conference/-/paper469/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper469/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper469/AnonReviewer1", "ICLR.cc/2017/conference/paper469/AnonReviewer2", "ICLR.cc/2017/conference/paper469/AnonReviewer3"], "reply": {"forum": "ryelgY5eg", "replyto": "ryelgY5eg", "writers": {"values-regex": "ICLR.cc/2017/conference/paper469/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper469/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512575700}}}], "count": 7}