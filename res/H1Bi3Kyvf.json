{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124444010, "tcdate": 1518472349317, "number": 319, "cdate": 1518472349317, "id": "H1Bi3Kyvf", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "H1Bi3Kyvf", "signatures": ["~Lawrence_A_Phillips1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Explanatory Masks for Neural Network Interpretability", "abstract": "Neural network interpretability is a vital component for applications across a wide variety of domains. One way to explain neural networks is to indicate which input data is responsible for the decision via a data mask. In this work, we present a method to produce explanation masks for pre-trained networks. Our masks identify which parts of the input are most important for accurate prediction. Masks are created by a secondary network whose goal is to create as small an explanation as possible while still preserving predictive accuracy. We demonstrate the applicability of our method for image classification with CNNs, sentiment analysis with RNNs, and chemical property prediction with mixed CNN/RNN architectures. ", "paperhash": "phillips|explanatory_masks_for_neural_network_interpretability", "keywords": ["Deep Learning", "Model Explanation", "Interpretability"], "_bibtex": "@misc{\n  phillips2018explanatory,\n  title={Explanatory Masks for Neural Network Interpretability},\n  author={Lawrence Phillips and Nathan Hodas and Garrett B. Goh},\n  year={2018},\n  url={https://openreview.net/forum?id=H1Bi3Kyvf}\n}", "authorids": ["lawrence.phillips@pnnl.gov", "nathan.hodas@pnnl.gov", "garrett.goh@pnnl.gov"], "authors": ["Lawrence Phillips", "Nathan Hodas", "Garrett B. Goh"], "TL;DR": "Network-generated input masks provide explanations for how pre-trained networks make their decisions.", "pdf": "/pdf/eeb01eb6b6e21d399a2f406e055f9b321262406a.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582934827, "tcdate": 1520310771139, "number": 1, "cdate": 1520310771139, "id": "Byjxqciuf", "invitation": "ICLR.cc/2018/Workshop/-/Paper319/Official_Review", "forum": "H1Bi3Kyvf", "replyto": "H1Bi3Kyvf", "signatures": ["ICLR.cc/2018/Workshop/Paper319/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper319/AnonReviewer1"], "content": {"title": "comparison with other network interpretability work", "rating": "4: Ok but not good enough - rejection", "review": "* Overview *\nThe paper proposes to predict the relevant parts of an input (e.g. image, text) that correlated with the output prediction. The authors train a NN to predict a mask which then they use to mask the input. The idea is simple however the authors fail to compare to similar works that deal with the same topic (see below)\n\n* Details *\nThe authors should compare and contrast their work to\na) Visualizing and understanding convolutional networks, Zeiler & Fergus, ECCV 2014\nb) Interpreting Deep Visual Representations via Network Dissection, Zhou et al, arXiv:1711.05611, 2017\n\nI would like the authors to mention whether the performance of the classifier drops after masking the input. Also, the authors should mention why to train a network from scratch rather than interpreting the weights and activations of the layers instead, which does not involve training a new NN which results in changed weights.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Explanatory Masks for Neural Network Interpretability", "abstract": "Neural network interpretability is a vital component for applications across a wide variety of domains. One way to explain neural networks is to indicate which input data is responsible for the decision via a data mask. In this work, we present a method to produce explanation masks for pre-trained networks. Our masks identify which parts of the input are most important for accurate prediction. Masks are created by a secondary network whose goal is to create as small an explanation as possible while still preserving predictive accuracy. We demonstrate the applicability of our method for image classification with CNNs, sentiment analysis with RNNs, and chemical property prediction with mixed CNN/RNN architectures. ", "paperhash": "phillips|explanatory_masks_for_neural_network_interpretability", "keywords": ["Deep Learning", "Model Explanation", "Interpretability"], "_bibtex": "@misc{\n  phillips2018explanatory,\n  title={Explanatory Masks for Neural Network Interpretability},\n  author={Lawrence Phillips and Nathan Hodas and Garrett B. Goh},\n  year={2018},\n  url={https://openreview.net/forum?id=H1Bi3Kyvf}\n}", "authorids": ["lawrence.phillips@pnnl.gov", "nathan.hodas@pnnl.gov", "garrett.goh@pnnl.gov"], "authors": ["Lawrence Phillips", "Nathan Hodas", "Garrett B. Goh"], "TL;DR": "Network-generated input masks provide explanations for how pre-trained networks make their decisions.", "pdf": "/pdf/eeb01eb6b6e21d399a2f406e055f9b321262406a.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582934637, "id": "ICLR.cc/2018/Workshop/-/Paper319/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper319/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper319/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper319/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper319/AnonReviewer2"], "reply": {"forum": "H1Bi3Kyvf", "replyto": "H1Bi3Kyvf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper319/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper319/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582934637}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582748844, "tcdate": 1520657230456, "number": 2, "cdate": 1520657230456, "id": "HJLUmybYM", "invitation": "ICLR.cc/2018/Workshop/-/Paper319/Official_Review", "forum": "H1Bi3Kyvf", "replyto": "H1Bi3Kyvf", "signatures": ["ICLR.cc/2018/Workshop/Paper319/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper319/AnonReviewer3"], "content": {"title": "Advantages of proposed method are unclear", "rating": "3: Clear rejection", "review": "The description of the proposed method lacks detail.\nThe advantages of the proposed method over explanation techniques such as Sensitivity Analysis, Guided Backprop or LRP are unclear. Qualitative and quantitative comparison with other explanation methods is lacking.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Explanatory Masks for Neural Network Interpretability", "abstract": "Neural network interpretability is a vital component for applications across a wide variety of domains. One way to explain neural networks is to indicate which input data is responsible for the decision via a data mask. In this work, we present a method to produce explanation masks for pre-trained networks. Our masks identify which parts of the input are most important for accurate prediction. Masks are created by a secondary network whose goal is to create as small an explanation as possible while still preserving predictive accuracy. We demonstrate the applicability of our method for image classification with CNNs, sentiment analysis with RNNs, and chemical property prediction with mixed CNN/RNN architectures. ", "paperhash": "phillips|explanatory_masks_for_neural_network_interpretability", "keywords": ["Deep Learning", "Model Explanation", "Interpretability"], "_bibtex": "@misc{\n  phillips2018explanatory,\n  title={Explanatory Masks for Neural Network Interpretability},\n  author={Lawrence Phillips and Nathan Hodas and Garrett B. Goh},\n  year={2018},\n  url={https://openreview.net/forum?id=H1Bi3Kyvf}\n}", "authorids": ["lawrence.phillips@pnnl.gov", "nathan.hodas@pnnl.gov", "garrett.goh@pnnl.gov"], "authors": ["Lawrence Phillips", "Nathan Hodas", "Garrett B. Goh"], "TL;DR": "Network-generated input masks provide explanations for how pre-trained networks make their decisions.", "pdf": "/pdf/eeb01eb6b6e21d399a2f406e055f9b321262406a.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582934637, "id": "ICLR.cc/2018/Workshop/-/Paper319/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper319/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper319/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper319/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper319/AnonReviewer2"], "reply": {"forum": "H1Bi3Kyvf", "replyto": "H1Bi3Kyvf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper319/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper319/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582934637}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582604108, "tcdate": 1520956459876, "number": 3, "cdate": 1520956459876, "id": "SkNEE_rYG", "invitation": "ICLR.cc/2018/Workshop/-/Paper319/Official_Review", "forum": "H1Bi3Kyvf", "replyto": "H1Bi3Kyvf", "signatures": ["ICLR.cc/2018/Workshop/Paper319/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper319/AnonReviewer2"], "content": {"title": "Simple but Interesting", "rating": "7: Good paper, accept", "review": "In this work, the authors propose a simple explanatory mask generation network which given some feature representation portion of a deep network, outputs an attention map on the input which is sparse and which highlights the regions of the image that are minimally required to predict the correct output for the now-masked input. They apply this technique in three highly different domains (image classification, sentiment analysis, and chemical solubility) and produce reasonable results in each. There is limited novelty over standard attention mechanisms however the fact that this approach produces these maps in pixel space for frozen network is sufficiently interesting. ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Explanatory Masks for Neural Network Interpretability", "abstract": "Neural network interpretability is a vital component for applications across a wide variety of domains. One way to explain neural networks is to indicate which input data is responsible for the decision via a data mask. In this work, we present a method to produce explanation masks for pre-trained networks. Our masks identify which parts of the input are most important for accurate prediction. Masks are created by a secondary network whose goal is to create as small an explanation as possible while still preserving predictive accuracy. We demonstrate the applicability of our method for image classification with CNNs, sentiment analysis with RNNs, and chemical property prediction with mixed CNN/RNN architectures. ", "paperhash": "phillips|explanatory_masks_for_neural_network_interpretability", "keywords": ["Deep Learning", "Model Explanation", "Interpretability"], "_bibtex": "@misc{\n  phillips2018explanatory,\n  title={Explanatory Masks for Neural Network Interpretability},\n  author={Lawrence Phillips and Nathan Hodas and Garrett B. Goh},\n  year={2018},\n  url={https://openreview.net/forum?id=H1Bi3Kyvf}\n}", "authorids": ["lawrence.phillips@pnnl.gov", "nathan.hodas@pnnl.gov", "garrett.goh@pnnl.gov"], "authors": ["Lawrence Phillips", "Nathan Hodas", "Garrett B. Goh"], "TL;DR": "Network-generated input masks provide explanations for how pre-trained networks make their decisions.", "pdf": "/pdf/eeb01eb6b6e21d399a2f406e055f9b321262406a.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582934637, "id": "ICLR.cc/2018/Workshop/-/Paper319/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper319/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper319/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper319/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper319/AnonReviewer2"], "reply": {"forum": "H1Bi3Kyvf", "replyto": "H1Bi3Kyvf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper319/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper319/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582934637}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573597432, "tcdate": 1521573597432, "number": 233, "cdate": 1521573597092, "id": "BJBkkyycG", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "H1Bi3Kyvf", "replyto": "H1Bi3Kyvf", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Explanatory Masks for Neural Network Interpretability", "abstract": "Neural network interpretability is a vital component for applications across a wide variety of domains. One way to explain neural networks is to indicate which input data is responsible for the decision via a data mask. In this work, we present a method to produce explanation masks for pre-trained networks. Our masks identify which parts of the input are most important for accurate prediction. Masks are created by a secondary network whose goal is to create as small an explanation as possible while still preserving predictive accuracy. We demonstrate the applicability of our method for image classification with CNNs, sentiment analysis with RNNs, and chemical property prediction with mixed CNN/RNN architectures. ", "paperhash": "phillips|explanatory_masks_for_neural_network_interpretability", "keywords": ["Deep Learning", "Model Explanation", "Interpretability"], "_bibtex": "@misc{\n  phillips2018explanatory,\n  title={Explanatory Masks for Neural Network Interpretability},\n  author={Lawrence Phillips and Nathan Hodas and Garrett B. Goh},\n  year={2018},\n  url={https://openreview.net/forum?id=H1Bi3Kyvf}\n}", "authorids": ["lawrence.phillips@pnnl.gov", "nathan.hodas@pnnl.gov", "garrett.goh@pnnl.gov"], "authors": ["Lawrence Phillips", "Nathan Hodas", "Garrett B. Goh"], "TL;DR": "Network-generated input masks provide explanations for how pre-trained networks make their decisions.", "pdf": "/pdf/eeb01eb6b6e21d399a2f406e055f9b321262406a.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}