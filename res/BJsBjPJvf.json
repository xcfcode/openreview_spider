{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124461831, "tcdate": 1518463810928, "number": 228, "cdate": 1518463810928, "id": "BJsBjPJvf", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "BJsBjPJvf", "signatures": ["~Andreea_Bobu1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Adapting to Continuously Shifting Domains", "abstract": "Domain adaptation typically focuses on adapting a model from a single source domain to a target domain. However, in practice, this paradigm of adapting from one source to one target is limiting, as different aspects of the real world such as illumination and weather conditions vary continuously and cannot be effectively captured by two static domains. Approaches that attempt to tackle this problem by adapting from a single source to many different target domains simultaneously are consistently unable to learn across all domain shifts. Instead, we propose an adaptation method that exploits the continuity between gradually varying domains by adapting in sequence from the source to the most similar target domain. By incrementally adapting while simultaneously efficiently regularizing against prior examples, we obtain a single strong model capable of recognition within all observed domains.", "paperhash": "bobu|adapting_to_continuously_shifting_domains", "keywords": ["domain adaptation", "unsupervised learning", "computer vision", "deep learning"], "_bibtex": "@misc{\n  bobu2018adapting,\n  title={Adapting to Continuously Shifting Domains},\n  author={Andreea Bobu and Eric Tzeng and Judy Hoffman and Trevor Darrell},\n  year={2018},\n  url={https://openreview.net/forum?id=BJsBjPJvf}\n}", "authorids": ["abobu@eecs.berkeley.edu", "etzeng@eecs.berkeley.edu", "jhoffman@eecs.berkeley.edu", "trevor@eecs.berkeley.edu"], "authors": ["Andreea Bobu", "Eric Tzeng", "Judy Hoffman", "Trevor Darrell"], "TL;DR": "We propose a flexible framework for continuous unsupervised domain adaptation that enables a single model to adapt across multiple domain shifts while maintaining consistent performance on all domains.", "pdf": "/pdf/b815f872542565692b45c66b9260dc0f7a864161.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582937147, "tcdate": 1520292346392, "number": 1, "cdate": 1520292346392, "id": "SkGZz8idz", "invitation": "ICLR.cc/2018/Workshop/-/Paper228/Official_Review", "forum": "BJsBjPJvf", "replyto": "BJsBjPJvf", "signatures": ["ICLR.cc/2018/Workshop/Paper228/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper228/AnonReviewer2"], "content": {"title": "Good paper, accept", "rating": "7: Good paper, accept", "review": "This paper proposed to tackle a continuous domain adaptation problem by an interesting replaying scheme. Unlike the existing source-target adaptation or multi-source domain adaptation, this paper considers the scenario that the target domains continuously shift over time. With no doubt this is a very challenging problem, the proposed solution is reasonable and gives rise to convincing results in the experiments. The replaying scheme is a nice regularization to prevent the adaptation from negative transfer, a desirable property when the target domains drift away slowly. \n\nEquation (4) is a little confusing since the math notations are not conventional. The authors may consider improve it to make the math language match that in the text. An extended version with more details of the implementation and experiments could be appreciated.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adapting to Continuously Shifting Domains", "abstract": "Domain adaptation typically focuses on adapting a model from a single source domain to a target domain. However, in practice, this paradigm of adapting from one source to one target is limiting, as different aspects of the real world such as illumination and weather conditions vary continuously and cannot be effectively captured by two static domains. Approaches that attempt to tackle this problem by adapting from a single source to many different target domains simultaneously are consistently unable to learn across all domain shifts. Instead, we propose an adaptation method that exploits the continuity between gradually varying domains by adapting in sequence from the source to the most similar target domain. By incrementally adapting while simultaneously efficiently regularizing against prior examples, we obtain a single strong model capable of recognition within all observed domains.", "paperhash": "bobu|adapting_to_continuously_shifting_domains", "keywords": ["domain adaptation", "unsupervised learning", "computer vision", "deep learning"], "_bibtex": "@misc{\n  bobu2018adapting,\n  title={Adapting to Continuously Shifting Domains},\n  author={Andreea Bobu and Eric Tzeng and Judy Hoffman and Trevor Darrell},\n  year={2018},\n  url={https://openreview.net/forum?id=BJsBjPJvf}\n}", "authorids": ["abobu@eecs.berkeley.edu", "etzeng@eecs.berkeley.edu", "jhoffman@eecs.berkeley.edu", "trevor@eecs.berkeley.edu"], "authors": ["Andreea Bobu", "Eric Tzeng", "Judy Hoffman", "Trevor Darrell"], "TL;DR": "We propose a flexible framework for continuous unsupervised domain adaptation that enables a single model to adapt across multiple domain shifts while maintaining consistent performance on all domains.", "pdf": "/pdf/b815f872542565692b45c66b9260dc0f7a864161.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582936956, "id": "ICLR.cc/2018/Workshop/-/Paper228/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper228/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper228/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper228/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper228/AnonReviewer3"], "reply": {"forum": "BJsBjPJvf", "replyto": "BJsBjPJvf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper228/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper228/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582936956}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582907173, "tcdate": 1520448986088, "number": 2, "cdate": 1520448986088, "id": "B1My8naOf", "invitation": "ICLR.cc/2018/Workshop/-/Paper228/Official_Review", "forum": "BJsBjPJvf", "replyto": "BJsBjPJvf", "signatures": ["ICLR.cc/2018/Workshop/Paper228/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper228/AnonReviewer1"], "content": {"title": "Interesting idea for continuous domain adaptation. The paper lacks of some discussion, justifications, precisions and evaluation, but it is understandable in a short workshop paper.", "rating": "8: Top 50% of accepted papers, clear accept", "review": "Summary:\nThis paper adresses the problem of continuous transfer learning where the objective is to continuously adapt a model learned from a source task where supervised learning data are available,\nto a sequence of target tasks with no labeled data in the training set. \nThe authors propose a model that aims at moving closer the target data of each task to the source data with respect to a divergence measure, which is relatively classic. The originality here is that they add a supervised classification term in the objective function aiming at classifying correctly a small dataset of instances from previous tasks with their predicted labels (sof labels). In other words, for a target task t, they try try to learn a projection of M_t to minimizing the divergence between data, such that the classifier learned from source data is still able to find the predicted labels of previously seen examples with respect to the new projection M_t.\nAn experimental study based on the MNIST digits dataset is provided.\n\nAs far as I know, the idea to incorporate soft-labeled instances of previous tasks is a continuous of continuous adaptation is new and the method shows interesting results on a particular tasks. Some discussions and precisions are missing  but it is understandable in a short workshop paper.\n\nIn the experimental setup, we do not know how the hyper parameters are tuned/fixed  (lambda, alpha), nor how the other baselines were used. So it is unclear if the results are very specific to the studied task or not. An evaluation on another data would have been informative.\n\nThe addition of soft-labels can lead to negative transfer if the first predictions are incorrect. So a good adaptation seems to depend on the ordering to tasks. The fact that the tasks arrive according to the increasing degree of rotation would undoubtedly help.\nA discussion on hypothesis where the approach can work or can fail would be interesting as well.\n\nPositive points:\n-Interesting idea to deal with continuous learning\n-paper reports very good results\n-simple idea\n\nNegative points:\n-the risk of negative transfer can be high, this point is not discussed\n-The choice of the soft-labeled data seems purely heuristic, tuning the tradeoff parameter is unclear\n-method evaluated on one particular task", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adapting to Continuously Shifting Domains", "abstract": "Domain adaptation typically focuses on adapting a model from a single source domain to a target domain. However, in practice, this paradigm of adapting from one source to one target is limiting, as different aspects of the real world such as illumination and weather conditions vary continuously and cannot be effectively captured by two static domains. Approaches that attempt to tackle this problem by adapting from a single source to many different target domains simultaneously are consistently unable to learn across all domain shifts. Instead, we propose an adaptation method that exploits the continuity between gradually varying domains by adapting in sequence from the source to the most similar target domain. By incrementally adapting while simultaneously efficiently regularizing against prior examples, we obtain a single strong model capable of recognition within all observed domains.", "paperhash": "bobu|adapting_to_continuously_shifting_domains", "keywords": ["domain adaptation", "unsupervised learning", "computer vision", "deep learning"], "_bibtex": "@misc{\n  bobu2018adapting,\n  title={Adapting to Continuously Shifting Domains},\n  author={Andreea Bobu and Eric Tzeng and Judy Hoffman and Trevor Darrell},\n  year={2018},\n  url={https://openreview.net/forum?id=BJsBjPJvf}\n}", "authorids": ["abobu@eecs.berkeley.edu", "etzeng@eecs.berkeley.edu", "jhoffman@eecs.berkeley.edu", "trevor@eecs.berkeley.edu"], "authors": ["Andreea Bobu", "Eric Tzeng", "Judy Hoffman", "Trevor Darrell"], "TL;DR": "We propose a flexible framework for continuous unsupervised domain adaptation that enables a single model to adapt across multiple domain shifts while maintaining consistent performance on all domains.", "pdf": "/pdf/b815f872542565692b45c66b9260dc0f7a864161.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582936956, "id": "ICLR.cc/2018/Workshop/-/Paper228/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper228/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper228/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper228/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper228/AnonReviewer3"], "reply": {"forum": "BJsBjPJvf", "replyto": "BJsBjPJvf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper228/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper228/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582936956}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582819432, "tcdate": 1520612588807, "number": 3, "cdate": 1520612588807, "id": "B1rlSVlKM", "invitation": "ICLR.cc/2018/Workshop/-/Paper228/Official_Review", "forum": "BJsBjPJvf", "replyto": "BJsBjPJvf", "signatures": ["ICLR.cc/2018/Workshop/Paper228/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper228/AnonReviewer3"], "content": {"title": "A simple and effective method for tackling an important problem", "rating": "7: Good paper, accept", "review": "The paper presents a training methodology in a domain adaptation scenario where the learner is provided with a labeled source sample and unlabeled target samples at different time intervals, as the target domain is {varying,drifting,shifting} over time. \n\nThe proposed sequential learning algorithm is inspired by existing domain adversarial approaches: at every timestamp, it learns a representation that reduces the \"distance\" between the corresponding target sample and the source sample, but also reuses a small subsample of self-labeled target samples from previous timestamps (to enforce prediction consistency).\n\nIf I were reviewing a conference paper, I would ask some questions on algorithm design and parameter tuning choices. But I think the work fit well in a workshop track, as it provides a simple but effective methodology to handle the problem of shifting domain, which occurs in many real-life applications. I stress the word \"methodology\" as these ideas can be straightforwardly reused in various learning algorithms.\n\nThe paper is well written and succeed in presenting a complete work in three pages. That being said, I feel strange about the fact that the bibliography cites only arXiv references, even when the works have been published in journals and conferences (i.e., has been peer reviewed!)\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adapting to Continuously Shifting Domains", "abstract": "Domain adaptation typically focuses on adapting a model from a single source domain to a target domain. However, in practice, this paradigm of adapting from one source to one target is limiting, as different aspects of the real world such as illumination and weather conditions vary continuously and cannot be effectively captured by two static domains. Approaches that attempt to tackle this problem by adapting from a single source to many different target domains simultaneously are consistently unable to learn across all domain shifts. Instead, we propose an adaptation method that exploits the continuity between gradually varying domains by adapting in sequence from the source to the most similar target domain. By incrementally adapting while simultaneously efficiently regularizing against prior examples, we obtain a single strong model capable of recognition within all observed domains.", "paperhash": "bobu|adapting_to_continuously_shifting_domains", "keywords": ["domain adaptation", "unsupervised learning", "computer vision", "deep learning"], "_bibtex": "@misc{\n  bobu2018adapting,\n  title={Adapting to Continuously Shifting Domains},\n  author={Andreea Bobu and Eric Tzeng and Judy Hoffman and Trevor Darrell},\n  year={2018},\n  url={https://openreview.net/forum?id=BJsBjPJvf}\n}", "authorids": ["abobu@eecs.berkeley.edu", "etzeng@eecs.berkeley.edu", "jhoffman@eecs.berkeley.edu", "trevor@eecs.berkeley.edu"], "authors": ["Andreea Bobu", "Eric Tzeng", "Judy Hoffman", "Trevor Darrell"], "TL;DR": "We propose a flexible framework for continuous unsupervised domain adaptation that enables a single model to adapt across multiple domain shifts while maintaining consistent performance on all domains.", "pdf": "/pdf/b815f872542565692b45c66b9260dc0f7a864161.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582936956, "id": "ICLR.cc/2018/Workshop/-/Paper228/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper228/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper228/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper228/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper228/AnonReviewer3"], "reply": {"forum": "BJsBjPJvf", "replyto": "BJsBjPJvf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper228/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper228/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582936956}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573548893, "tcdate": 1521573548893, "number": 25, "cdate": 1521573548542, "id": "BJr2RCRYf", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "BJsBjPJvf", "replyto": "BJsBjPJvf", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adapting to Continuously Shifting Domains", "abstract": "Domain adaptation typically focuses on adapting a model from a single source domain to a target domain. However, in practice, this paradigm of adapting from one source to one target is limiting, as different aspects of the real world such as illumination and weather conditions vary continuously and cannot be effectively captured by two static domains. Approaches that attempt to tackle this problem by adapting from a single source to many different target domains simultaneously are consistently unable to learn across all domain shifts. Instead, we propose an adaptation method that exploits the continuity between gradually varying domains by adapting in sequence from the source to the most similar target domain. By incrementally adapting while simultaneously efficiently regularizing against prior examples, we obtain a single strong model capable of recognition within all observed domains.", "paperhash": "bobu|adapting_to_continuously_shifting_domains", "keywords": ["domain adaptation", "unsupervised learning", "computer vision", "deep learning"], "_bibtex": "@misc{\n  bobu2018adapting,\n  title={Adapting to Continuously Shifting Domains},\n  author={Andreea Bobu and Eric Tzeng and Judy Hoffman and Trevor Darrell},\n  year={2018},\n  url={https://openreview.net/forum?id=BJsBjPJvf}\n}", "authorids": ["abobu@eecs.berkeley.edu", "etzeng@eecs.berkeley.edu", "jhoffman@eecs.berkeley.edu", "trevor@eecs.berkeley.edu"], "authors": ["Andreea Bobu", "Eric Tzeng", "Judy Hoffman", "Trevor Darrell"], "TL;DR": "We propose a flexible framework for continuous unsupervised domain adaptation that enables a single model to adapt across multiple domain shifts while maintaining consistent performance on all domains.", "pdf": "/pdf/b815f872542565692b45c66b9260dc0f7a864161.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}