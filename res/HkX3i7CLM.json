{"notes": [{"tddate": null, "ddate": null, "original": null, "tmdate": 1521573615233, "tcdate": 1521573615233, "number": 302, "cdate": 1521573614887, "id": "HkDxyJ1qz", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "HkX3i7CLM", "replyto": "HkX3i7CLM", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "This paper was invited to the workshop track based on reviews at the main conference."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Deep Models: Critical Points and Local Openness", "abstract": "In this paper we present a unifying framework to study the local/global optima equivalence of the optimization problems arising from training non-convex deep models. Using the local openness property of the underlying training models,  we provide simple sufficient conditions under which any local optimum of the resulting optimization problem is  globally optimal. We first completely characterize the local openness of matrix multiplication mapping in its range. Then we use our characterization to: 1) show that every local optimum of two layer linear networks is globally optimal.  Unlike many existing results, our result requires no assumption  on the target data matrix Y, and input data matrix X. 2) Develop almost complete characterization of the local/global optima equivalence of multi-layer linear neural networks. 3) Show global/local optima equivalence of non-linear deep models having certain pyramidal structure. Unlike some existing works, our result requires no assumption on the differentiability of the activation functions. \n", "pdf": "/pdf/666ae61126bdb69b09930052a4603b60b6b6c008.pdf", "paperhash": "nouiehed|learning_deep_models_critical_points_and_local_openness", "_bibtex": "@misc{\nnouiehed2018learning,\ntitle={Learning Deep Models: Critical Points and Local Openness},\nauthor={Maher Nouiehed and Meisam Razaviyayn},\nyear={2018},\nurl={https://openreview.net/forum?id=ByxLBMZCb},\n}", "authorids": ["nouiehed@usc.edu", "razaviya@usc.edu"], "keywords": ["Non-convex Optimization", "Local/Global Equivalence", "Training Deep Models", "Local Open Mappings"], "authors": ["Maher Nouiehed", "Meisam Razaviyayn"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1518730163476, "tcdate": 1518381995541, "number": 74, "cdate": 1518381995541, "id": "HkX3i7CLM", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "HkX3i7CLM", "original": "ByxLBMZCb", "signatures": ["~Maher_Nouiehed1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Learning Deep Models: Critical Points and Local Openness", "abstract": "In this paper we present a unifying framework to study the local/global optima equivalence of the optimization problems arising from training non-convex deep models. Using the local openness property of the underlying training models,  we provide simple sufficient conditions under which any local optimum of the resulting optimization problem is  globally optimal. We first completely characterize the local openness of matrix multiplication mapping in its range. Then we use our characterization to: 1) show that every local optimum of two layer linear networks is globally optimal.  Unlike many existing results, our result requires no assumption  on the target data matrix Y, and input data matrix X. 2) Develop almost complete characterization of the local/global optima equivalence of multi-layer linear neural networks. 3) Show global/local optima equivalence of non-linear deep models having certain pyramidal structure. Unlike some existing works, our result requires no assumption on the differentiability of the activation functions. \n", "pdf": "/pdf/666ae61126bdb69b09930052a4603b60b6b6c008.pdf", "paperhash": "nouiehed|learning_deep_models_critical_points_and_local_openness", "_bibtex": "@misc{\nnouiehed2018learning,\ntitle={Learning Deep Models: Critical Points and Local Openness},\nauthor={Maher Nouiehed and Meisam Razaviyayn},\nyear={2018},\nurl={https://openreview.net/forum?id=ByxLBMZCb},\n}", "authorids": ["nouiehed@usc.edu", "razaviya@usc.edu"], "keywords": ["Non-convex Optimization", "Local/Global Equivalence", "Training Deep Models", "Local Open Mappings"], "authors": ["Maher Nouiehed", "Meisam Razaviyayn"]}, "nonreaders": [], "details": {"replyCount": 1, "writable": false, "overwriting": [], "revisions": false, "tags": [], "original": {"tddate": null, "ddate": null, "tmdate": 1518730163476, "tcdate": 1509135688027, "number": 834, "cdate": 1518730163466, "id": "ByxLBMZCb", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "ByxLBMZCb", "original": "BkyLrfZ0Z", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "Learning Deep Models: Critical Points and Local Openness", "abstract": "With the increasing interest in deeper understanding of  the loss surface of many non-convex deep models, this paper presents a unifying framework to study the local/global optima equivalence of the optimization problems arising from training of such non-convex models.  Using the \"local openness\" property of the underlying training models,  we provide simple sufficient conditions under which any local optimum of the resulting optimization problem is  globally optimal. We first completely characterize the local openness of matrix multiplication mapping in its range. Then we use our characterization to: 1) show that every local optimum of two layer linear networks is globally optimal.  Unlike many existing results in the literature, our result requires no assumption  on the target data matrix Y, and input data matrix X. 2) develop almost complete characterization of the local/global optima equivalence of multi-layer linear neural networks. We provide various counterexamples to show the necessity of each of our assumptions. 3) show global/local optima equivalence of non-linear deep models having certain pyramidal structure. Unlike some existing works, our result requires no assumption on the differentiability of the activation functions and can go beyond \"full-rank\" cases. \n", "pdf": "/pdf/ce69c62df1c25edd5102db6c590a30bc67ccd7fe.pdf", "paperhash": "nouiehed|learning_deep_models_critical_points_and_local_openness", "_bibtex": "@misc{\nnouiehed2018learning,\ntitle={Learning Deep Models: Critical Points and Local Openness},\nauthor={Maher Nouiehed and Meisam Razaviyayn},\nyear={2018},\nurl={https://openreview.net/forum?id=ByxLBMZCb},\n}", "authorids": ["nouiehed@usc.edu", "razaviya@usc.edu"], "keywords": ["Training Deep Models", "Non-convex Optimization", "Local and Global Equivalence", "Local Openness"], "authors": ["Maher Nouiehed", "Meisam Razaviyayn"]}, "nonreaders": []}, "originalWritable": false, "originalInvitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}, "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}], "count": 2}