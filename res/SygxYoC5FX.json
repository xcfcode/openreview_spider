{"notes": [{"id": "SygxYoC5FX", "original": "HklImKqcFm", "number": 413, "cdate": 1538087799939, "ddate": null, "tcdate": 1538087799939, "tmdate": 1545355422133, "tddate": null, "forum": "SygxYoC5FX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "BIGSAGE: unsupervised inductive representation learning of graph via bi-attended sampling and global-biased aggregating", "abstract": "Different kinds of representation learning techniques on graph have shown significant effect in downstream machine learning tasks. Recently, in order to inductively learn representations for graph structures that is unobservable during training, a general framework with sampling and aggregating (GraphSAGE) was proposed by Hamilton and Ying and had been proved more efficient than transductive methods on fileds like transfer learning or evolving dataset. However, GraphSAGE is uncapable of selective neighbor sampling and lack of memory of known nodes that've been trained. To address these problems, we present an unsupervised method that samples neighborhood information attended by co-occurring structures and optimizes a trainable global bias as a representation expectation for each node in the given graph. Experiments show that our approach outperforms the state-of-the-art inductive and unsupervised methods for representation learning on graphs.", "keywords": ["network embedding", "unsupervised learning", "inductive learning"], "authorids": ["luox35@mail2.sysu.edu.cn", "zhuohank@mail.sysu.edu.cn"], "authors": ["Xin Luo", "Hankz Hankui Zhuo"], "TL;DR": "For unsupervised and inductive network embedding, we propose a novel approach to explore most relevant neighbors and preserve previously learnt knowledge of nodes by utilizing bi-attention architecture and introducing global bias, respectively", "pdf": "/pdf/f7a58568ddb09df2b9eaf3d9b412cede79872a03.pdf", "paperhash": "luo|bigsage_unsupervised_inductive_representation_learning_of_graph_via_biattended_sampling_and_globalbiased_aggregating", "_bibtex": "@misc{\nluo2019bigsage,\ntitle={{BIGSAGE}: unsupervised inductive representation learning of graph via bi-attended sampling and global-biased aggregating},\nauthor={Xin Luo and Hankz Hankui Zhuo},\nyear={2019},\nurl={https://openreview.net/forum?id=SygxYoC5FX},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "HkxD_SCMg4", "original": null, "number": 1, "cdate": 1544901998914, "ddate": null, "tcdate": 1544901998914, "tmdate": 1545354493271, "tddate": null, "forum": "SygxYoC5FX", "replyto": "SygxYoC5FX", "invitation": "ICLR.cc/2019/Conference/-/Paper413/Meta_Review", "content": {"metareview": "AR2 is concerned about the marginal novelty, weak experiments and very high complexity of the algorithm. AR3 is concerned about lack of theoretical analysis and parameter setting. AR4 is concerned that the proposed method is useful in very\nrestricted settings and the paper is incremental.\n\nUnfortunately, with strong critique from reviewers regarding the novelty, complexity, poor presentation and restricted setting, this draft cannot be accepted by ICLR.", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "Novelty, complexity and poor presentation are all of concern."}, "signatures": ["ICLR.cc/2019/Conference/Paper413/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper413/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BIGSAGE: unsupervised inductive representation learning of graph via bi-attended sampling and global-biased aggregating", "abstract": "Different kinds of representation learning techniques on graph have shown significant effect in downstream machine learning tasks. Recently, in order to inductively learn representations for graph structures that is unobservable during training, a general framework with sampling and aggregating (GraphSAGE) was proposed by Hamilton and Ying and had been proved more efficient than transductive methods on fileds like transfer learning or evolving dataset. However, GraphSAGE is uncapable of selective neighbor sampling and lack of memory of known nodes that've been trained. To address these problems, we present an unsupervised method that samples neighborhood information attended by co-occurring structures and optimizes a trainable global bias as a representation expectation for each node in the given graph. Experiments show that our approach outperforms the state-of-the-art inductive and unsupervised methods for representation learning on graphs.", "keywords": ["network embedding", "unsupervised learning", "inductive learning"], "authorids": ["luox35@mail2.sysu.edu.cn", "zhuohank@mail.sysu.edu.cn"], "authors": ["Xin Luo", "Hankz Hankui Zhuo"], "TL;DR": "For unsupervised and inductive network embedding, we propose a novel approach to explore most relevant neighbors and preserve previously learnt knowledge of nodes by utilizing bi-attention architecture and introducing global bias, respectively", "pdf": "/pdf/f7a58568ddb09df2b9eaf3d9b412cede79872a03.pdf", "paperhash": "luo|bigsage_unsupervised_inductive_representation_learning_of_graph_via_biattended_sampling_and_globalbiased_aggregating", "_bibtex": "@misc{\nluo2019bigsage,\ntitle={{BIGSAGE}: unsupervised inductive representation learning of graph via bi-attended sampling and global-biased aggregating},\nauthor={Xin Luo and Hankz Hankui Zhuo},\nyear={2019},\nurl={https://openreview.net/forum?id=SygxYoC5FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper413/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353225117, "tddate": null, "super": null, "final": null, "reply": {"forum": "SygxYoC5FX", "replyto": "SygxYoC5FX", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper413/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper413/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper413/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353225117}}}, {"id": "HyeZ0Llep7", "original": null, "number": 3, "cdate": 1541568201446, "ddate": null, "tcdate": 1541568201446, "tmdate": 1541568201446, "tddate": null, "forum": "SygxYoC5FX", "replyto": "SygxYoC5FX", "invitation": "ICLR.cc/2019/Conference/-/Paper413/Official_Review", "content": {"title": "An increment of GraphSAGE with restricted applications", "review": "This paper modifies the GraphSAGE on unsupervised inductive node embedding.\nThe authors propose to use the bi-attention architecture to sample\ninteresting nodes (instead of the uniform sampler in GraphSAGE), and to use a\nglobal embedding bias matrix in the local aggregating functions. The method\nshowed improvements over GraphSAGE and other baselines on unsupervised\ngraph embeddings.\n\nThe proposition makes sense and the performance improvements are expected.\n\nA major comment, however, is that that the proposed method is useful in very\nrestricted settings, and it is not clear how to generalize to\nother applications which GraphSAGE can be applied on.\nThe overall technical contribution is incremental and\nmay not have enough novelty to be published in ICLR.\n\nThe technical representation is very poor, unorganized and not self-contained.\nThe paper cannot pass the threshold merely based on the way it is presented.\n\nIn the algorithms, please give the output besides the input. After the\nalgorithms, please remark on the computational and memory cost.\n\nIn algorithm 1, what is this function BIATT()? \nAfter algorithm 1, please describe this function as well as SAGE(). \n\nIn the beginning of section 3, please describe the meaning of the\nglobal bias matrix. In algorithm 1, if B is zero-initialized, why\ndoes one need it as input?\n\nSome of the equations are poor formatted (e.g. reduce_sum in page 5).\nPlease try to use rigorous mathematical formulations instead of \"pseudo equations\".\nFor example, re-write \"One_hot(i)\". In section 3.2, explain A_{gg}, etc.\nuse $\\langle \\rangle$ instead of $\\alpha$.\n\nThere are many typos.", "rating": "2: Strong rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper413/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BIGSAGE: unsupervised inductive representation learning of graph via bi-attended sampling and global-biased aggregating", "abstract": "Different kinds of representation learning techniques on graph have shown significant effect in downstream machine learning tasks. Recently, in order to inductively learn representations for graph structures that is unobservable during training, a general framework with sampling and aggregating (GraphSAGE) was proposed by Hamilton and Ying and had been proved more efficient than transductive methods on fileds like transfer learning or evolving dataset. However, GraphSAGE is uncapable of selective neighbor sampling and lack of memory of known nodes that've been trained. To address these problems, we present an unsupervised method that samples neighborhood information attended by co-occurring structures and optimizes a trainable global bias as a representation expectation for each node in the given graph. Experiments show that our approach outperforms the state-of-the-art inductive and unsupervised methods for representation learning on graphs.", "keywords": ["network embedding", "unsupervised learning", "inductive learning"], "authorids": ["luox35@mail2.sysu.edu.cn", "zhuohank@mail.sysu.edu.cn"], "authors": ["Xin Luo", "Hankz Hankui Zhuo"], "TL;DR": "For unsupervised and inductive network embedding, we propose a novel approach to explore most relevant neighbors and preserve previously learnt knowledge of nodes by utilizing bi-attention architecture and introducing global bias, respectively", "pdf": "/pdf/f7a58568ddb09df2b9eaf3d9b412cede79872a03.pdf", "paperhash": "luo|bigsage_unsupervised_inductive_representation_learning_of_graph_via_biattended_sampling_and_globalbiased_aggregating", "_bibtex": "@misc{\nluo2019bigsage,\ntitle={{BIGSAGE}: unsupervised inductive representation learning of graph via bi-attended sampling and global-biased aggregating},\nauthor={Xin Luo and Hankz Hankui Zhuo},\nyear={2019},\nurl={https://openreview.net/forum?id=SygxYoC5FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper413/Official_Review", "cdate": 1542234466984, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SygxYoC5FX", "replyto": "SygxYoC5FX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper413/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335718653, "tmdate": 1552335718653, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper413/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "ByxStr6L3X", "original": null, "number": 2, "cdate": 1540965757063, "ddate": null, "tcdate": 1540965757063, "tmdate": 1541534016550, "tddate": null, "forum": "SygxYoC5FX", "replyto": "SygxYoC5FX", "invitation": "ICLR.cc/2019/Conference/-/Paper413/Official_Review", "content": {"title": "Overall quality is not high.", "review": "This paper proposes a new representation learning method for graphs.\n\nQuality:\nThe quality of the paper is not high due to vague presentation of the proposed method (see clarity).\nMoreover, there is no theoretical analysis and empirical evaluation is not thorough (see significance).\n\nClarity:\nThis paper is not clearly written and many parts are unclear.\n- In Introduction, what are \"the first issue\" and \"the second issue\"?\n- There are many grammatical mistakes (such as missing articles and the third-person singular -s) and mistakes of mathematical notations.\n- Too many symbols are not mathematically defined and it is hard to understand the paper. The current version is not appropriate for publication.\n\nOriginality:\nThe proposed method is a minor extension of the existing method GraphSAGE. Hence the originality is not high.\n\nSignificance:\n- There is no theoretical analysis of the proposed method. Hence the significance is not high.\n  In particular, the advantage of the proposed method compared to the existing approach (GraphSAGE) should be theoretically analyzed.\n- How to set parameters in practice? The performance of the proposed method will be greatly affected by parameter setting.\n  In experiments, the sensitivity of the proposed method with respect to parameter changes should be analyzed.  \n\nPros:\n- The relevant problem is studied.\nCons:\n- Presentation is not good.\n- Theoretical analysis is not given.\n- Empirical analysis is not thorough.\n\nOther comments:\n- P.3, L.5 in Sec.3: \"G = {V, E, X}\" should be \"G = (V, E, X)\"\n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper413/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BIGSAGE: unsupervised inductive representation learning of graph via bi-attended sampling and global-biased aggregating", "abstract": "Different kinds of representation learning techniques on graph have shown significant effect in downstream machine learning tasks. Recently, in order to inductively learn representations for graph structures that is unobservable during training, a general framework with sampling and aggregating (GraphSAGE) was proposed by Hamilton and Ying and had been proved more efficient than transductive methods on fileds like transfer learning or evolving dataset. However, GraphSAGE is uncapable of selective neighbor sampling and lack of memory of known nodes that've been trained. To address these problems, we present an unsupervised method that samples neighborhood information attended by co-occurring structures and optimizes a trainable global bias as a representation expectation for each node in the given graph. Experiments show that our approach outperforms the state-of-the-art inductive and unsupervised methods for representation learning on graphs.", "keywords": ["network embedding", "unsupervised learning", "inductive learning"], "authorids": ["luox35@mail2.sysu.edu.cn", "zhuohank@mail.sysu.edu.cn"], "authors": ["Xin Luo", "Hankz Hankui Zhuo"], "TL;DR": "For unsupervised and inductive network embedding, we propose a novel approach to explore most relevant neighbors and preserve previously learnt knowledge of nodes by utilizing bi-attention architecture and introducing global bias, respectively", "pdf": "/pdf/f7a58568ddb09df2b9eaf3d9b412cede79872a03.pdf", "paperhash": "luo|bigsage_unsupervised_inductive_representation_learning_of_graph_via_biattended_sampling_and_globalbiased_aggregating", "_bibtex": "@misc{\nluo2019bigsage,\ntitle={{BIGSAGE}: unsupervised inductive representation learning of graph via bi-attended sampling and global-biased aggregating},\nauthor={Xin Luo and Hankz Hankui Zhuo},\nyear={2019},\nurl={https://openreview.net/forum?id=SygxYoC5FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper413/Official_Review", "cdate": 1542234466984, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SygxYoC5FX", "replyto": "SygxYoC5FX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper413/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335718653, "tmdate": 1552335718653, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper413/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "r1e8qsZWhm", "original": null, "number": 1, "cdate": 1540590478240, "ddate": null, "tcdate": 1540590478240, "tmdate": 1541534016343, "tddate": null, "forum": "SygxYoC5FX", "replyto": "SygxYoC5FX", "invitation": "ICLR.cc/2019/Conference/-/Paper413/Official_Review", "content": {"title": "Novelty of the paper seems to be marginal", "review": "This paper studied learning unsupervised inductive node embeddings with an attention mechanism. For each positive edge, multiple different sets of neighborhoods are sampled for both the source and target nodes, and the similarity between the neighborhood are used as the attention functions. Experimental results prove the effectiveness of the proposed approach over GraphSAGE on a few networks. \n\nStrength:\n- learning unsupervised inductive node embeddings is an important problem\n- the proposed method seems to work\n\nWeakness:\n- the novelty of the proposed method seems to be very marginal\n- the experiments are quite weak\n- the complexity of the algorithm seems to be very high\n\nDetails:\n- the complexity of the algorithm seems to be very high seem for each pair of nodes, multiple sets of neighborhoods must be sampled for each node.\n- there are also other approaches for inductive unsupervised node embeddings, for example, the varitional graph autoencoder method (Kipf et al. 2017).\n- I am wondering how the proposed method performs comparing with the methods of only selecting the nodes which form triangles with the given positive edges. \n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper413/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "BIGSAGE: unsupervised inductive representation learning of graph via bi-attended sampling and global-biased aggregating", "abstract": "Different kinds of representation learning techniques on graph have shown significant effect in downstream machine learning tasks. Recently, in order to inductively learn representations for graph structures that is unobservable during training, a general framework with sampling and aggregating (GraphSAGE) was proposed by Hamilton and Ying and had been proved more efficient than transductive methods on fileds like transfer learning or evolving dataset. However, GraphSAGE is uncapable of selective neighbor sampling and lack of memory of known nodes that've been trained. To address these problems, we present an unsupervised method that samples neighborhood information attended by co-occurring structures and optimizes a trainable global bias as a representation expectation for each node in the given graph. Experiments show that our approach outperforms the state-of-the-art inductive and unsupervised methods for representation learning on graphs.", "keywords": ["network embedding", "unsupervised learning", "inductive learning"], "authorids": ["luox35@mail2.sysu.edu.cn", "zhuohank@mail.sysu.edu.cn"], "authors": ["Xin Luo", "Hankz Hankui Zhuo"], "TL;DR": "For unsupervised and inductive network embedding, we propose a novel approach to explore most relevant neighbors and preserve previously learnt knowledge of nodes by utilizing bi-attention architecture and introducing global bias, respectively", "pdf": "/pdf/f7a58568ddb09df2b9eaf3d9b412cede79872a03.pdf", "paperhash": "luo|bigsage_unsupervised_inductive_representation_learning_of_graph_via_biattended_sampling_and_globalbiased_aggregating", "_bibtex": "@misc{\nluo2019bigsage,\ntitle={{BIGSAGE}: unsupervised inductive representation learning of graph via bi-attended sampling and global-biased aggregating},\nauthor={Xin Luo and Hankz Hankui Zhuo},\nyear={2019},\nurl={https://openreview.net/forum?id=SygxYoC5FX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper413/Official_Review", "cdate": 1542234466984, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SygxYoC5FX", "replyto": "SygxYoC5FX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper413/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335718653, "tmdate": 1552335718653, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper413/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 5}