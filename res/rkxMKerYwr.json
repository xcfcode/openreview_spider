{"notes": [{"id": "rkxMKerYwr", "original": "HyeW3TeFwB", "number": 2426, "cdate": 1569439865792, "ddate": null, "tcdate": 1569439865792, "tmdate": 1577168233742, "tddate": null, "forum": "rkxMKerYwr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["secaojiezhang@mail.scut.edu.cn", "sejinchengli@mail.scut.edu.cn", "huxp@lzu.edu.cn", "peilinzhao@hotmail.com", "mingkuitan@scut.edu.cn"], "title": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "authors": ["Jiezhang Cao", "Jincheng Li", "Xiping Hu", "Peilin Zhao", "Mingkui Tan"], "TL;DR": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "abstract": "Deep neural networks (DNNs) have achieved unprecedented practical success in many applications.\nHowever, how to interpret DNNs is still an open problem.\nIn particular, what do hidden layers behave is not clearly understood. \nIn this paper, relying on a teacher-student paradigm, we seek to understand the layer behaviors of DNNs by ``monitoring\" both across-layer and single-layer distribution evolution to some target distribution in the training. Here, the ``across-layer\" and ``single-layer\" considers the layer behavior \\emph{along the depth} and  a specific layer \\emph{along training epochs}, respectively. \nRelying on optimal transport theory, we employ the Wasserstein distance ($W$-distance)  to measure the divergence between the layer distribution and the target distribution. \nTheoretically, we prove that i) the $W$-distance of across layers to the target distribution tends to decrease along the depth. ii) the $W$-distance of a specific layer to the target distribution tends to decrease along training iterations. iii) \nHowever, a deep layer is not always better than a shallow layer for some samples. Moreover, our results helps to analyze the stability of layer distributions and explains why auxiliary losses helps the training of DNNs. Extensive experiments on real-world datasets justify our theoretical findings.", "keywords": ["Interpretability of DNNs", "Wasserstein distance", "Layer behavior"], "pdf": "/pdf/d2481371910de3ba11f5d9c21852e539fd2b4715.pdf", "paperhash": "cao|towards_interpreting_deep_neural_networks_via_understanding_layer_behaviors", "original_pdf": "/attachment/f1239b7877efd927e7061f0b4a749a746dc6d08b.pdf", "_bibtex": "@misc{\ncao2020towards,\ntitle={Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors},\nauthor={Jiezhang Cao and Jincheng Li and Xiping Hu and Peilin Zhao and Mingkui Tan},\nyear={2020},\nurl={https://openreview.net/forum?id=rkxMKerYwr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 12, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "5IzGXvslrr", "original": null, "number": 1, "cdate": 1576798748846, "ddate": null, "tcdate": 1576798748846, "tmdate": 1576800887127, "tddate": null, "forum": "rkxMKerYwr", "replyto": "rkxMKerYwr", "invitation": "ICLR.cc/2020/Conference/Paper2426/-/Decision", "content": {"decision": "Reject", "comment": "This paper studies the transfer of representations learned by deep neural networks across various datasets and tasks when the network is pre-trained on some dataset and subsequently fine-tuned on the target dataset. On the theoretical side the authors analyse two-layer fully connected networks. In an extensive empirical evaluation the authors argue that an appropriately pre-trained networks enable better loss landscapes (improved Lipschitzness). Understanding the transferability of representations is an important problem and the reviewers appreciated some aspects of the extensive empirical evaluation and the initial theoretical investigation. However, we feel that the manuscript needs a major revision and that there is not enough empirical evidence to support the stated conclusions. As a result, I will recommend rejecting this paper in the current form. Nevertheless, as the problem is extremely important I encourage the authors to improve the clarity and provide more convincing arguments towards the stated conclusions by addressing the issues raised during the discussion phase.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["secaojiezhang@mail.scut.edu.cn", "sejinchengli@mail.scut.edu.cn", "huxp@lzu.edu.cn", "peilinzhao@hotmail.com", "mingkuitan@scut.edu.cn"], "title": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "authors": ["Jiezhang Cao", "Jincheng Li", "Xiping Hu", "Peilin Zhao", "Mingkui Tan"], "TL;DR": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "abstract": "Deep neural networks (DNNs) have achieved unprecedented practical success in many applications.\nHowever, how to interpret DNNs is still an open problem.\nIn particular, what do hidden layers behave is not clearly understood. \nIn this paper, relying on a teacher-student paradigm, we seek to understand the layer behaviors of DNNs by ``monitoring\" both across-layer and single-layer distribution evolution to some target distribution in the training. Here, the ``across-layer\" and ``single-layer\" considers the layer behavior \\emph{along the depth} and  a specific layer \\emph{along training epochs}, respectively. \nRelying on optimal transport theory, we employ the Wasserstein distance ($W$-distance)  to measure the divergence between the layer distribution and the target distribution. \nTheoretically, we prove that i) the $W$-distance of across layers to the target distribution tends to decrease along the depth. ii) the $W$-distance of a specific layer to the target distribution tends to decrease along training iterations. iii) \nHowever, a deep layer is not always better than a shallow layer for some samples. Moreover, our results helps to analyze the stability of layer distributions and explains why auxiliary losses helps the training of DNNs. Extensive experiments on real-world datasets justify our theoretical findings.", "keywords": ["Interpretability of DNNs", "Wasserstein distance", "Layer behavior"], "pdf": "/pdf/d2481371910de3ba11f5d9c21852e539fd2b4715.pdf", "paperhash": "cao|towards_interpreting_deep_neural_networks_via_understanding_layer_behaviors", "original_pdf": "/attachment/f1239b7877efd927e7061f0b4a749a746dc6d08b.pdf", "_bibtex": "@misc{\ncao2020towards,\ntitle={Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors},\nauthor={Jiezhang Cao and Jincheng Li and Xiping Hu and Peilin Zhao and Mingkui Tan},\nyear={2020},\nurl={https://openreview.net/forum?id=rkxMKerYwr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "rkxMKerYwr", "replyto": "rkxMKerYwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795716287, "tmdate": 1576800266397, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2426/-/Decision"}}}, {"id": "B1lfD3Ahtr", "original": null, "number": 1, "cdate": 1571773530048, "ddate": null, "tcdate": 1571773530048, "tmdate": 1574343802264, "tddate": null, "forum": "rkxMKerYwr", "replyto": "rkxMKerYwr", "invitation": "ICLR.cc/2020/Conference/Paper2426/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #3", "review": "This paper seeks to understand both across-layer and single-layer behavior within neural networks (i.e. layer behavior along the depth of a network, and behavior of a single layer along training epochs). Therefore, they resort to the optimal transport framework to compare predicted and target distributions. Theoretically, they show that the Wasserstein distance between predicted and target distributions is decreasing along the depth and for a single layer, along training iterations. They also give intuition on how this analysis can help the learning process in practice.\n\nThis paper gives an interesting contribution to the in-depth analysis of neural networks. However, some elements remain unclear:\n\n1.\tThe setting of multi-label classification does not really motivate the use of measures.\n2.\tIt is unclear why the use of teacher/student networks are pertinent or necessary.\n3.\tThere is no detail on the regularization strength of the Wasserstein distance, or what p (in definition 1) is chosen either in the experiments or in the theorems.\n4.\tI believe it is understated that all \\tilde{f}_i have the same input and output domains (as well as h=h_i in figure 1a), which is restrictive and should have been made clearer. \n\n- Post rebuttal: I thank the authors for their response. On this basis, I am maintaining my weak reject rating.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper2426/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2426/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["secaojiezhang@mail.scut.edu.cn", "sejinchengli@mail.scut.edu.cn", "huxp@lzu.edu.cn", "peilinzhao@hotmail.com", "mingkuitan@scut.edu.cn"], "title": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "authors": ["Jiezhang Cao", "Jincheng Li", "Xiping Hu", "Peilin Zhao", "Mingkui Tan"], "TL;DR": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "abstract": "Deep neural networks (DNNs) have achieved unprecedented practical success in many applications.\nHowever, how to interpret DNNs is still an open problem.\nIn particular, what do hidden layers behave is not clearly understood. \nIn this paper, relying on a teacher-student paradigm, we seek to understand the layer behaviors of DNNs by ``monitoring\" both across-layer and single-layer distribution evolution to some target distribution in the training. Here, the ``across-layer\" and ``single-layer\" considers the layer behavior \\emph{along the depth} and  a specific layer \\emph{along training epochs}, respectively. \nRelying on optimal transport theory, we employ the Wasserstein distance ($W$-distance)  to measure the divergence between the layer distribution and the target distribution. \nTheoretically, we prove that i) the $W$-distance of across layers to the target distribution tends to decrease along the depth. ii) the $W$-distance of a specific layer to the target distribution tends to decrease along training iterations. iii) \nHowever, a deep layer is not always better than a shallow layer for some samples. Moreover, our results helps to analyze the stability of layer distributions and explains why auxiliary losses helps the training of DNNs. Extensive experiments on real-world datasets justify our theoretical findings.", "keywords": ["Interpretability of DNNs", "Wasserstein distance", "Layer behavior"], "pdf": "/pdf/d2481371910de3ba11f5d9c21852e539fd2b4715.pdf", "paperhash": "cao|towards_interpreting_deep_neural_networks_via_understanding_layer_behaviors", "original_pdf": "/attachment/f1239b7877efd927e7061f0b4a749a746dc6d08b.pdf", "_bibtex": "@misc{\ncao2020towards,\ntitle={Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors},\nauthor={Jiezhang Cao and Jincheng Li and Xiping Hu and Peilin Zhao and Mingkui Tan},\nyear={2020},\nurl={https://openreview.net/forum?id=rkxMKerYwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkxMKerYwr", "replyto": "rkxMKerYwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2426/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2426/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575875647651, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2426/Reviewers"], "noninvitees": [], "tcdate": 1570237722984, "tmdate": 1575875647664, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2426/-/Official_Review"}}}, {"id": "BJeibrI5iH", "original": null, "number": 4, "cdate": 1573704963148, "ddate": null, "tcdate": 1573704963148, "tmdate": 1573705631616, "tddate": null, "forum": "rkxMKerYwr", "replyto": "BJe8i8JLqB", "invitation": "ICLR.cc/2020/Conference/Paper2426/-/Official_Comment", "content": {"title": "Response to Reviewer #2", "comment": "Thank you for your constructive comments.\n\nQ1. Advantage of the proposed method over information bottleneck and main contributions of our paper\n\nExisting studies [1, 2] using information bottleneck methods mainly analyze the dynamics of across different layers. However, it is hard for these methods to analyze the dynamics of a specific layer through different iterations. In contrast, our proposed method is able to analyze both single-layer and across-layer behaviors. \n\nWe highlight the main contributions as follows:\n\n1. We propose a unified teacher-student analysis method to explore both across-layer and single-layer behaviors.\ni) Across-layer behaviors: The W-distance between the distribution of any layer and the target distribution decreases along the depth of a DNN.\nii) Single-layer behaviors: For a specific layer, the W-distance between the distribution in an iteration and the target distribution decreases across the training iterations when introducing a loss in the layer.\niii) We prove that a deep layer is not always better than a shallow layer for some samples (see Figure 5).\n\n2. We have provided extensive experiments to justify these findings. \n \n\nQ2. Definition of the label distribution\n\nAs defined in [3], the label distribution can be defined as a probability distribution to cover a certain number of labels, representing the degree to which each label describes the instance, as shown in Figure 1 (c) of the revised paper. Because the label distribution is a probability distribution, its sum is equal to 1. The revised paper provides more intuitive examples to explain the definition of label distribution.\n\nDue to the convexity of cross-entropy loss, we derive the optimal label distribution for given features of every layer [4]. In this sense, the label distribution reflects the actual distribution of feature maps in a specific layer.\n\nReference: \n[1] Naftali Tishby et al. Deep learning and the information bottleneck principle. IEEE ITW, 2015.\n[2] Seojin Bang et al. Explaining a black-box using deep variational information bottleneck approach. arxiv, 2019.\n[3] Xin Geng. Label Distribution Learning. KDD, 2016.\n[4] Guillaume Alain, Yoshua Bengio. Understanding intermediate layers using linear classifier probes. arxiv, 2018.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2426/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2426/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["secaojiezhang@mail.scut.edu.cn", "sejinchengli@mail.scut.edu.cn", "huxp@lzu.edu.cn", "peilinzhao@hotmail.com", "mingkuitan@scut.edu.cn"], "title": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "authors": ["Jiezhang Cao", "Jincheng Li", "Xiping Hu", "Peilin Zhao", "Mingkui Tan"], "TL;DR": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "abstract": "Deep neural networks (DNNs) have achieved unprecedented practical success in many applications.\nHowever, how to interpret DNNs is still an open problem.\nIn particular, what do hidden layers behave is not clearly understood. \nIn this paper, relying on a teacher-student paradigm, we seek to understand the layer behaviors of DNNs by ``monitoring\" both across-layer and single-layer distribution evolution to some target distribution in the training. Here, the ``across-layer\" and ``single-layer\" considers the layer behavior \\emph{along the depth} and  a specific layer \\emph{along training epochs}, respectively. \nRelying on optimal transport theory, we employ the Wasserstein distance ($W$-distance)  to measure the divergence between the layer distribution and the target distribution. \nTheoretically, we prove that i) the $W$-distance of across layers to the target distribution tends to decrease along the depth. ii) the $W$-distance of a specific layer to the target distribution tends to decrease along training iterations. iii) \nHowever, a deep layer is not always better than a shallow layer for some samples. Moreover, our results helps to analyze the stability of layer distributions and explains why auxiliary losses helps the training of DNNs. Extensive experiments on real-world datasets justify our theoretical findings.", "keywords": ["Interpretability of DNNs", "Wasserstein distance", "Layer behavior"], "pdf": "/pdf/d2481371910de3ba11f5d9c21852e539fd2b4715.pdf", "paperhash": "cao|towards_interpreting_deep_neural_networks_via_understanding_layer_behaviors", "original_pdf": "/attachment/f1239b7877efd927e7061f0b4a749a746dc6d08b.pdf", "_bibtex": "@misc{\ncao2020towards,\ntitle={Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors},\nauthor={Jiezhang Cao and Jincheng Li and Xiping Hu and Peilin Zhao and Mingkui Tan},\nyear={2020},\nurl={https://openreview.net/forum?id=rkxMKerYwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkxMKerYwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2426/Authors", "ICLR.cc/2020/Conference/Paper2426/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2426/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2426/Reviewers", "ICLR.cc/2020/Conference/Paper2426/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2426/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2426/Authors|ICLR.cc/2020/Conference/Paper2426/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504141537, "tmdate": 1576860553750, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2426/Authors", "ICLR.cc/2020/Conference/Paper2426/Reviewers", "ICLR.cc/2020/Conference/Paper2426/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2426/-/Official_Comment"}}}, {"id": "ByxCO489sH", "original": null, "number": 3, "cdate": 1573704821639, "ddate": null, "tcdate": 1573704821639, "tmdate": 1573705543584, "tddate": null, "forum": "rkxMKerYwr", "replyto": "rkxMKerYwr", "invitation": "ICLR.cc/2020/Conference/Paper2426/-/Official_Comment", "content": {"title": "Response to AC and all reviewers", "comment": "\nDear AC and reviewers,\n\nThank you very much for your constructive comments. In this paper, we propose a unified teacher-student analysis method to analyze both across-layer and single-layer behaviors of neural networks. Moreover, our theoretical findings help to improve the classification performance of multi-label learning tasks (see Table 1). We believe our results would provide a different view of understanding and interpreting neural networks.\n\nWe have updated a revised version of the paper. The changes have been highlighted as follows:\n\n1. We highlight the contributions of our paper on page 2.\n2. We discuss some studies using information bottleneck methods in related work.\n3. We define the label distribution in Figure 1 (c) and Section 3, and provide more intuitive examples in Figure 16 in Section I of Supplementary materials.\n4. We conduct thorough repeated experiments to verify the consistency of performance in Figure 9 in Section F of Supplementary materials.\n5. We explain the reasonability and necessity for the setting of multi-label classification in Section 4.\n6. We explain the importance and necessity for the teacher-student networks in Section 5.\n7. We give more details of $f_i$ and $\\tilde{f}_i$, and clarify Figure 1 (a) in the revised paper.\n\nThank you very much for your consideration.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2426/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2426/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["secaojiezhang@mail.scut.edu.cn", "sejinchengli@mail.scut.edu.cn", "huxp@lzu.edu.cn", "peilinzhao@hotmail.com", "mingkuitan@scut.edu.cn"], "title": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "authors": ["Jiezhang Cao", "Jincheng Li", "Xiping Hu", "Peilin Zhao", "Mingkui Tan"], "TL;DR": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "abstract": "Deep neural networks (DNNs) have achieved unprecedented practical success in many applications.\nHowever, how to interpret DNNs is still an open problem.\nIn particular, what do hidden layers behave is not clearly understood. \nIn this paper, relying on a teacher-student paradigm, we seek to understand the layer behaviors of DNNs by ``monitoring\" both across-layer and single-layer distribution evolution to some target distribution in the training. Here, the ``across-layer\" and ``single-layer\" considers the layer behavior \\emph{along the depth} and  a specific layer \\emph{along training epochs}, respectively. \nRelying on optimal transport theory, we employ the Wasserstein distance ($W$-distance)  to measure the divergence between the layer distribution and the target distribution. \nTheoretically, we prove that i) the $W$-distance of across layers to the target distribution tends to decrease along the depth. ii) the $W$-distance of a specific layer to the target distribution tends to decrease along training iterations. iii) \nHowever, a deep layer is not always better than a shallow layer for some samples. Moreover, our results helps to analyze the stability of layer distributions and explains why auxiliary losses helps the training of DNNs. Extensive experiments on real-world datasets justify our theoretical findings.", "keywords": ["Interpretability of DNNs", "Wasserstein distance", "Layer behavior"], "pdf": "/pdf/d2481371910de3ba11f5d9c21852e539fd2b4715.pdf", "paperhash": "cao|towards_interpreting_deep_neural_networks_via_understanding_layer_behaviors", "original_pdf": "/attachment/f1239b7877efd927e7061f0b4a749a746dc6d08b.pdf", "_bibtex": "@misc{\ncao2020towards,\ntitle={Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors},\nauthor={Jiezhang Cao and Jincheng Li and Xiping Hu and Peilin Zhao and Mingkui Tan},\nyear={2020},\nurl={https://openreview.net/forum?id=rkxMKerYwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkxMKerYwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2426/Authors", "ICLR.cc/2020/Conference/Paper2426/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2426/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2426/Reviewers", "ICLR.cc/2020/Conference/Paper2426/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2426/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2426/Authors|ICLR.cc/2020/Conference/Paper2426/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504141537, "tmdate": 1576860553750, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2426/Authors", "ICLR.cc/2020/Conference/Paper2426/Reviewers", "ICLR.cc/2020/Conference/Paper2426/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2426/-/Official_Comment"}}}, {"id": "rkgKoLL9jH", "original": null, "number": 6, "cdate": 1573705376521, "ddate": null, "tcdate": 1573705376521, "tmdate": 1573705494295, "tddate": null, "forum": "rkxMKerYwr", "replyto": "B1lfD3Ahtr", "invitation": "ICLR.cc/2020/Conference/Paper2426/-/Official_Comment", "content": {"title": "Response to Reviewer #3", "comment": "Thank you for your valuable comments. We have carefully considered the four concerns and made the paper clearer in the revised paper. We sincerely hope you would be satisfied with the clarifications below.\n\nQ1. Concern on multi-label classification and Wasserstein distance\n\nThe setting of multi-label classification does motivate the use of Wasserstein distance. First, using Wasserstein distance is able to improve the performance of multi-label classification [5, 6]. Second, deep neural networks on the multi-label classification task still lack strong theoretical understanding. With the help of optimal transport theory, we are able to use Wasserstein distance to interpret deep neural networks via understanding layer behaviors.\n\nQ2. Necessity of teacher-student networks\n\nWe exploit the teacher-student framework to build our analysis as it is a flexible framework to analyze and understand neural networks [7, 8, 9]. Specifically, in our one-layer behavior analysis, this framework helps to understand the dynamics of a student network from the teacher network. In our multi-layer behavior analysis, this framework helps to study the ability of the student network to express distributions of the teacher network (Barron function). Therefore, the teacher-student analysis framework is important and necessary in our paper to understand deep neural networks. We believe our analysis framework would provide a different view of understanding and interpreting neural networks.\n\nQ3.\tMore details of the regularization strength and p of Wasserstein distance\n\nRegularization strength of the Wasserstein distance: When the regularization strength $\\alpha$ is large enough, the entropic Wasserstein distance in Eqn. (17) coincides with the Wasserstein distance in Eqn. (2) [10]. In practice, we set $\\alpha=0.01$ to achieve balanced results. In addition, we choose $p=2$ in the experiments and all theoretical analysis.\n\nQ4.\tMore details of $\\tilde{f}_i, f_i$ and their domains\n\nIn the second paragraph of Section 3, for all functions $\\tilde{f}_i, i=1, \u2026, L$, they have different input and output domains. In contrast, for all functions $f_i, i=1, \u2026, L$, they have the same input domain and the same output domain, because it feeds the same input and then outputs the label distribution to close to the ground-truth. We clarify Figure 1 (a) and make them clearer in the revised paper.\n\n\nReference:\n[5] Charlie Frogner et al. Learning with a wasserstein loss. NeurIPS, 2015.\n[6] Peng Zhao et al. Label distribution learning by optimal transport. IJCAI. 2018.\n[7] Yuandong Tian. An analytical formula of population gradient for two-layered ReLU network and its applications in convergence and critical point analysis. ICML, 2016.\n[8] Simon S. Du et al. When is a convolutional filter easy to learn? ICLR, 2018.\n[9] Qiuyi Zhang et al. Electron-proton dynamics in deep learning. arxiv, 2017.\n[10] Marco Cuturi. Sinkhorn Distances: lightspeed computation of optimal transport, NeurIPS, 2013.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2426/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2426/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["secaojiezhang@mail.scut.edu.cn", "sejinchengli@mail.scut.edu.cn", "huxp@lzu.edu.cn", "peilinzhao@hotmail.com", "mingkuitan@scut.edu.cn"], "title": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "authors": ["Jiezhang Cao", "Jincheng Li", "Xiping Hu", "Peilin Zhao", "Mingkui Tan"], "TL;DR": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "abstract": "Deep neural networks (DNNs) have achieved unprecedented practical success in many applications.\nHowever, how to interpret DNNs is still an open problem.\nIn particular, what do hidden layers behave is not clearly understood. \nIn this paper, relying on a teacher-student paradigm, we seek to understand the layer behaviors of DNNs by ``monitoring\" both across-layer and single-layer distribution evolution to some target distribution in the training. Here, the ``across-layer\" and ``single-layer\" considers the layer behavior \\emph{along the depth} and  a specific layer \\emph{along training epochs}, respectively. \nRelying on optimal transport theory, we employ the Wasserstein distance ($W$-distance)  to measure the divergence between the layer distribution and the target distribution. \nTheoretically, we prove that i) the $W$-distance of across layers to the target distribution tends to decrease along the depth. ii) the $W$-distance of a specific layer to the target distribution tends to decrease along training iterations. iii) \nHowever, a deep layer is not always better than a shallow layer for some samples. Moreover, our results helps to analyze the stability of layer distributions and explains why auxiliary losses helps the training of DNNs. Extensive experiments on real-world datasets justify our theoretical findings.", "keywords": ["Interpretability of DNNs", "Wasserstein distance", "Layer behavior"], "pdf": "/pdf/d2481371910de3ba11f5d9c21852e539fd2b4715.pdf", "paperhash": "cao|towards_interpreting_deep_neural_networks_via_understanding_layer_behaviors", "original_pdf": "/attachment/f1239b7877efd927e7061f0b4a749a746dc6d08b.pdf", "_bibtex": "@misc{\ncao2020towards,\ntitle={Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors},\nauthor={Jiezhang Cao and Jincheng Li and Xiping Hu and Peilin Zhao and Mingkui Tan},\nyear={2020},\nurl={https://openreview.net/forum?id=rkxMKerYwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkxMKerYwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2426/Authors", "ICLR.cc/2020/Conference/Paper2426/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2426/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2426/Reviewers", "ICLR.cc/2020/Conference/Paper2426/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2426/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2426/Authors|ICLR.cc/2020/Conference/Paper2426/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504141537, "tmdate": 1576860553750, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2426/Authors", "ICLR.cc/2020/Conference/Paper2426/Reviewers", "ICLR.cc/2020/Conference/Paper2426/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2426/-/Official_Comment"}}}, {"id": "r1eMoS85iS", "original": null, "number": 5, "cdate": 1573705113529, "ddate": null, "tcdate": 1573705113529, "tmdate": 1573705113529, "tddate": null, "forum": "rkxMKerYwr", "replyto": "HkxW9dLptr", "invitation": "ICLR.cc/2020/Conference/Paper2426/-/Official_Comment", "content": {"title": "Response to Reviewer #1", "comment": "Thank you for your valuable comments. We conduct thorough repeated experiments in the revised paper, and we sincerely hope you would be satisfied with our following response on your concern over the consistency of experimental results.\n\nQ1. Consistency of experimental results\n\nThe experimental results are consistent with repeated experiments, which are shown in Figure 9 in Section F of Supplementary materials. In this experiment, we shuffle the data and then conduct three experiments with different partitioning. From Figure 9, different experiments consistently have the same decreasing tendency through the depth of a neural network. \n\nHere we would like to highlight our main contributions as below:\n\n1. We propose a unified teacher-student analysis method to explore both across-layer and single-layer behaviors.\ni) Across-layer behaviors: The W-distance between the distribution of any layer and the target distribution decreases along the depth of a DNN.\nii) Single-layer behaviors: For a specific layer, the W-distance between the distribution in an iteration and the target distribution decreases across the training iterations when introducing a loss in the layer.\niii) We prove that a deep layer is not always better than a shallow layer for some samples (see Figure 5).\n\n2. We have provided extensive experiments to justify these findings. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2426/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2426/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["secaojiezhang@mail.scut.edu.cn", "sejinchengli@mail.scut.edu.cn", "huxp@lzu.edu.cn", "peilinzhao@hotmail.com", "mingkuitan@scut.edu.cn"], "title": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "authors": ["Jiezhang Cao", "Jincheng Li", "Xiping Hu", "Peilin Zhao", "Mingkui Tan"], "TL;DR": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "abstract": "Deep neural networks (DNNs) have achieved unprecedented practical success in many applications.\nHowever, how to interpret DNNs is still an open problem.\nIn particular, what do hidden layers behave is not clearly understood. \nIn this paper, relying on a teacher-student paradigm, we seek to understand the layer behaviors of DNNs by ``monitoring\" both across-layer and single-layer distribution evolution to some target distribution in the training. Here, the ``across-layer\" and ``single-layer\" considers the layer behavior \\emph{along the depth} and  a specific layer \\emph{along training epochs}, respectively. \nRelying on optimal transport theory, we employ the Wasserstein distance ($W$-distance)  to measure the divergence between the layer distribution and the target distribution. \nTheoretically, we prove that i) the $W$-distance of across layers to the target distribution tends to decrease along the depth. ii) the $W$-distance of a specific layer to the target distribution tends to decrease along training iterations. iii) \nHowever, a deep layer is not always better than a shallow layer for some samples. Moreover, our results helps to analyze the stability of layer distributions and explains why auxiliary losses helps the training of DNNs. Extensive experiments on real-world datasets justify our theoretical findings.", "keywords": ["Interpretability of DNNs", "Wasserstein distance", "Layer behavior"], "pdf": "/pdf/d2481371910de3ba11f5d9c21852e539fd2b4715.pdf", "paperhash": "cao|towards_interpreting_deep_neural_networks_via_understanding_layer_behaviors", "original_pdf": "/attachment/f1239b7877efd927e7061f0b4a749a746dc6d08b.pdf", "_bibtex": "@misc{\ncao2020towards,\ntitle={Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors},\nauthor={Jiezhang Cao and Jincheng Li and Xiping Hu and Peilin Zhao and Mingkui Tan},\nyear={2020},\nurl={https://openreview.net/forum?id=rkxMKerYwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkxMKerYwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2426/Authors", "ICLR.cc/2020/Conference/Paper2426/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2426/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2426/Reviewers", "ICLR.cc/2020/Conference/Paper2426/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2426/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2426/Authors|ICLR.cc/2020/Conference/Paper2426/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504141537, "tmdate": 1576860553750, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2426/Authors", "ICLR.cc/2020/Conference/Paper2426/Reviewers", "ICLR.cc/2020/Conference/Paper2426/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2426/-/Official_Comment"}}}, {"id": "HkxW9dLptr", "original": null, "number": 2, "cdate": 1571805320773, "ddate": null, "tcdate": 1571805320773, "tmdate": 1572972339673, "tddate": null, "forum": "rkxMKerYwr", "replyto": "rkxMKerYwr", "invitation": "ICLR.cc/2020/Conference/Paper2426/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors intuitively, and then analytically, explain the behavior in the hidden layers of deep convolutional networks and show how the behavior can be used to improve performance by \"early exiting.\"\n\nI give this paper a weak reject. I believe this paper does well by connecting the intuitive explanation with the proofs, and then by confirming their results through experimentation. I also applaud the authors for their rigorous explanation of the hyper-parameters and experimentation methods. However, from what I can tell, there was no cross-fold validation or even repeat trials with different partitioning to see whether the differences in performance were just random perturbations or a consistent effect. The increase in accuracy isn't large enough across experiments to allay my concerns.\n\nI think the authors have some very compelling work here, but the lack of a large difference in accuracy combined with insufficient testing methodology causes me to reject this paper... but only barely. I can be convinced otherwise with a compelling set of arguments."}, "signatures": ["ICLR.cc/2020/Conference/Paper2426/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2426/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["secaojiezhang@mail.scut.edu.cn", "sejinchengli@mail.scut.edu.cn", "huxp@lzu.edu.cn", "peilinzhao@hotmail.com", "mingkuitan@scut.edu.cn"], "title": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "authors": ["Jiezhang Cao", "Jincheng Li", "Xiping Hu", "Peilin Zhao", "Mingkui Tan"], "TL;DR": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "abstract": "Deep neural networks (DNNs) have achieved unprecedented practical success in many applications.\nHowever, how to interpret DNNs is still an open problem.\nIn particular, what do hidden layers behave is not clearly understood. \nIn this paper, relying on a teacher-student paradigm, we seek to understand the layer behaviors of DNNs by ``monitoring\" both across-layer and single-layer distribution evolution to some target distribution in the training. Here, the ``across-layer\" and ``single-layer\" considers the layer behavior \\emph{along the depth} and  a specific layer \\emph{along training epochs}, respectively. \nRelying on optimal transport theory, we employ the Wasserstein distance ($W$-distance)  to measure the divergence between the layer distribution and the target distribution. \nTheoretically, we prove that i) the $W$-distance of across layers to the target distribution tends to decrease along the depth. ii) the $W$-distance of a specific layer to the target distribution tends to decrease along training iterations. iii) \nHowever, a deep layer is not always better than a shallow layer for some samples. Moreover, our results helps to analyze the stability of layer distributions and explains why auxiliary losses helps the training of DNNs. Extensive experiments on real-world datasets justify our theoretical findings.", "keywords": ["Interpretability of DNNs", "Wasserstein distance", "Layer behavior"], "pdf": "/pdf/d2481371910de3ba11f5d9c21852e539fd2b4715.pdf", "paperhash": "cao|towards_interpreting_deep_neural_networks_via_understanding_layer_behaviors", "original_pdf": "/attachment/f1239b7877efd927e7061f0b4a749a746dc6d08b.pdf", "_bibtex": "@misc{\ncao2020towards,\ntitle={Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors},\nauthor={Jiezhang Cao and Jincheng Li and Xiping Hu and Peilin Zhao and Mingkui Tan},\nyear={2020},\nurl={https://openreview.net/forum?id=rkxMKerYwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkxMKerYwr", "replyto": "rkxMKerYwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2426/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2426/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575875647651, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2426/Reviewers"], "noninvitees": [], "tcdate": 1570237722984, "tmdate": 1575875647664, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2426/-/Official_Review"}}}, {"id": "BJe8i8JLqB", "original": null, "number": 3, "cdate": 1572365982234, "ddate": null, "tcdate": 1572365982234, "tmdate": 1572972339625, "tddate": null, "forum": "rkxMKerYwr", "replyto": "rkxMKerYwr", "invitation": "ICLR.cc/2020/Conference/Paper2426/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents a method to compute the distance of distribution of two layers in neural networks by using the label distribution mapping (e.g., Frogner et al., 2015). With the tool, authors could see how individual layers could related each other across-layer (along the depth) and single layer (training epoch). \n\nI believe that the contributions of this paper are week in analyzing individual layers across-layer since there are many extensive studies are conducted on information bottleneck methods with mutual information. I believe that those methods are better to analyze the dynamics of learning even without the additional label distribution mapping.\n\nHowever, authors of this paper presents a way to utilize the label distribution mapping to compare the distance of individual layers when an input image come as shown in Figure 5 which I believe the main contribution of this paper. \n\nThe (somehow artificial and ambiguous) term, label distribution is used several places before it is defined. Even in Section 3, the label distribution mapping is not clearly explained except for the description of FC+softmax. Thus, it would be better to clarify the definition. Also, it is not clear that the label distribution reflect the actual distribution of (nodes or feature maps) in a specific layer. It would be good to spend more space and resources (e.g., image and/or running examples) to explain the definition of label distribution."}, "signatures": ["ICLR.cc/2020/Conference/Paper2426/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2426/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["secaojiezhang@mail.scut.edu.cn", "sejinchengli@mail.scut.edu.cn", "huxp@lzu.edu.cn", "peilinzhao@hotmail.com", "mingkuitan@scut.edu.cn"], "title": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "authors": ["Jiezhang Cao", "Jincheng Li", "Xiping Hu", "Peilin Zhao", "Mingkui Tan"], "TL;DR": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "abstract": "Deep neural networks (DNNs) have achieved unprecedented practical success in many applications.\nHowever, how to interpret DNNs is still an open problem.\nIn particular, what do hidden layers behave is not clearly understood. \nIn this paper, relying on a teacher-student paradigm, we seek to understand the layer behaviors of DNNs by ``monitoring\" both across-layer and single-layer distribution evolution to some target distribution in the training. Here, the ``across-layer\" and ``single-layer\" considers the layer behavior \\emph{along the depth} and  a specific layer \\emph{along training epochs}, respectively. \nRelying on optimal transport theory, we employ the Wasserstein distance ($W$-distance)  to measure the divergence between the layer distribution and the target distribution. \nTheoretically, we prove that i) the $W$-distance of across layers to the target distribution tends to decrease along the depth. ii) the $W$-distance of a specific layer to the target distribution tends to decrease along training iterations. iii) \nHowever, a deep layer is not always better than a shallow layer for some samples. Moreover, our results helps to analyze the stability of layer distributions and explains why auxiliary losses helps the training of DNNs. Extensive experiments on real-world datasets justify our theoretical findings.", "keywords": ["Interpretability of DNNs", "Wasserstein distance", "Layer behavior"], "pdf": "/pdf/d2481371910de3ba11f5d9c21852e539fd2b4715.pdf", "paperhash": "cao|towards_interpreting_deep_neural_networks_via_understanding_layer_behaviors", "original_pdf": "/attachment/f1239b7877efd927e7061f0b4a749a746dc6d08b.pdf", "_bibtex": "@misc{\ncao2020towards,\ntitle={Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors},\nauthor={Jiezhang Cao and Jincheng Li and Xiping Hu and Peilin Zhao and Mingkui Tan},\nyear={2020},\nurl={https://openreview.net/forum?id=rkxMKerYwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkxMKerYwr", "replyto": "rkxMKerYwr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2426/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2426/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575875647651, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2426/Reviewers"], "noninvitees": [], "tcdate": 1570237722984, "tmdate": 1575875647664, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2426/-/Official_Review"}}}, {"id": "H1eDnHP7_r", "original": null, "number": 1, "cdate": 1570104751007, "ddate": null, "tcdate": 1570104751007, "tmdate": 1570104751007, "tddate": null, "forum": "rkxMKerYwr", "replyto": "B1lIWeW3wH", "invitation": "ICLR.cc/2020/Conference/Paper2426/-/Official_Comment", "content": {"comment": "Thanks for your helpful comments. LISA (Gupta et al, 2018) is a great work to explain deep neural networks by understanding the layer-wise semantic accumulation behavior. We will discuss and cite this work in the related work.", "title": "Discussions of the related work"}, "signatures": ["ICLR.cc/2020/Conference/Paper2426/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2426/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["secaojiezhang@mail.scut.edu.cn", "sejinchengli@mail.scut.edu.cn", "huxp@lzu.edu.cn", "peilinzhao@hotmail.com", "mingkuitan@scut.edu.cn"], "title": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "authors": ["Jiezhang Cao", "Jincheng Li", "Xiping Hu", "Peilin Zhao", "Mingkui Tan"], "TL;DR": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "abstract": "Deep neural networks (DNNs) have achieved unprecedented practical success in many applications.\nHowever, how to interpret DNNs is still an open problem.\nIn particular, what do hidden layers behave is not clearly understood. \nIn this paper, relying on a teacher-student paradigm, we seek to understand the layer behaviors of DNNs by ``monitoring\" both across-layer and single-layer distribution evolution to some target distribution in the training. Here, the ``across-layer\" and ``single-layer\" considers the layer behavior \\emph{along the depth} and  a specific layer \\emph{along training epochs}, respectively. \nRelying on optimal transport theory, we employ the Wasserstein distance ($W$-distance)  to measure the divergence between the layer distribution and the target distribution. \nTheoretically, we prove that i) the $W$-distance of across layers to the target distribution tends to decrease along the depth. ii) the $W$-distance of a specific layer to the target distribution tends to decrease along training iterations. iii) \nHowever, a deep layer is not always better than a shallow layer for some samples. Moreover, our results helps to analyze the stability of layer distributions and explains why auxiliary losses helps the training of DNNs. Extensive experiments on real-world datasets justify our theoretical findings.", "keywords": ["Interpretability of DNNs", "Wasserstein distance", "Layer behavior"], "pdf": "/pdf/d2481371910de3ba11f5d9c21852e539fd2b4715.pdf", "paperhash": "cao|towards_interpreting_deep_neural_networks_via_understanding_layer_behaviors", "original_pdf": "/attachment/f1239b7877efd927e7061f0b4a749a746dc6d08b.pdf", "_bibtex": "@misc{\ncao2020towards,\ntitle={Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors},\nauthor={Jiezhang Cao and Jincheng Li and Xiping Hu and Peilin Zhao and Mingkui Tan},\nyear={2020},\nurl={https://openreview.net/forum?id=rkxMKerYwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkxMKerYwr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2426/Authors", "ICLR.cc/2020/Conference/Paper2426/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2426/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2426/Reviewers", "ICLR.cc/2020/Conference/Paper2426/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2426/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2426/Authors|ICLR.cc/2020/Conference/Paper2426/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504141537, "tmdate": 1576860553750, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2426/Authors", "ICLR.cc/2020/Conference/Paper2426/Reviewers", "ICLR.cc/2020/Conference/Paper2426/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2426/-/Official_Comment"}}}, {"id": "Sye009qhwr", "original": null, "number": 3, "cdate": 1569659606011, "ddate": null, "tcdate": 1569659606011, "tmdate": 1569659673016, "tddate": null, "forum": "rkxMKerYwr", "replyto": "rkgUEKZ2PB", "invitation": "ICLR.cc/2020/Conference/Paper2426/-/Public_Comment", "content": {"comment": "Appreciate your question about relatedness. I understand the following connection of this work vs [1], though the latter is explanation-based method to study behavior of neural networks. \n\nAt test time, [1] studies the layer-wise semantic accumulation behavior, how a semantic is built given a sequence of words and propagated across hidden layers of RNN. Moreover, it detects  and extracts salient textual patterns in building semantics. It is based on simply analyzing the label distribution at each of the hidden layers in a sequence classification task and studies the confidence of RNN for the target class, spanning across recurrent layers and thus, in accumulating semantics across hidden layers. \n\nHowever, this work explores how label distribution propagates from one layer to another in order to understand behaviors of different hidden layers in DNN.  \n\n", "title": "Semantic Propagation in hidden layers "}, "signatures": ["~pankaj_gupta1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~pankaj_gupta1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["secaojiezhang@mail.scut.edu.cn", "sejinchengli@mail.scut.edu.cn", "huxp@lzu.edu.cn", "peilinzhao@hotmail.com", "mingkuitan@scut.edu.cn"], "title": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "authors": ["Jiezhang Cao", "Jincheng Li", "Xiping Hu", "Peilin Zhao", "Mingkui Tan"], "TL;DR": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "abstract": "Deep neural networks (DNNs) have achieved unprecedented practical success in many applications.\nHowever, how to interpret DNNs is still an open problem.\nIn particular, what do hidden layers behave is not clearly understood. \nIn this paper, relying on a teacher-student paradigm, we seek to understand the layer behaviors of DNNs by ``monitoring\" both across-layer and single-layer distribution evolution to some target distribution in the training. Here, the ``across-layer\" and ``single-layer\" considers the layer behavior \\emph{along the depth} and  a specific layer \\emph{along training epochs}, respectively. \nRelying on optimal transport theory, we employ the Wasserstein distance ($W$-distance)  to measure the divergence between the layer distribution and the target distribution. \nTheoretically, we prove that i) the $W$-distance of across layers to the target distribution tends to decrease along the depth. ii) the $W$-distance of a specific layer to the target distribution tends to decrease along training iterations. iii) \nHowever, a deep layer is not always better than a shallow layer for some samples. Moreover, our results helps to analyze the stability of layer distributions and explains why auxiliary losses helps the training of DNNs. Extensive experiments on real-world datasets justify our theoretical findings.", "keywords": ["Interpretability of DNNs", "Wasserstein distance", "Layer behavior"], "pdf": "/pdf/d2481371910de3ba11f5d9c21852e539fd2b4715.pdf", "paperhash": "cao|towards_interpreting_deep_neural_networks_via_understanding_layer_behaviors", "original_pdf": "/attachment/f1239b7877efd927e7061f0b4a749a746dc6d08b.pdf", "_bibtex": "@misc{\ncao2020towards,\ntitle={Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors},\nauthor={Jiezhang Cao and Jincheng Li and Xiping Hu and Peilin Zhao and Mingkui Tan},\nyear={2020},\nurl={https://openreview.net/forum?id=rkxMKerYwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkxMKerYwr", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504180456, "tmdate": 1576860586912, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper2426/Authors", "ICLR.cc/2020/Conference/Paper2426/Reviewers", "ICLR.cc/2020/Conference/Paper2426/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2426/-/Public_Comment"}}}, {"id": "B1lIWeW3wH", "original": null, "number": 1, "cdate": 1569619966277, "ddate": null, "tcdate": 1569619966277, "tmdate": 1569655949997, "tddate": null, "forum": "rkxMKerYwr", "replyto": "rkxMKerYwr", "invitation": "ICLR.cc/2020/Conference/Paper2426/-/Public_Comment", "content": {"comment": "Please also include the following work in your related works section. It understands neural networks (especially RNNs) in explaining their judgements and semantic accumulation behavior.\n\nPankaj Gupta, Hinrich Sch\u00fctze. LISA: Explaining Recurrent Neural Network Judgments via Layer-wIse Semantic Accumulation and Example to Pattern Transformation. In BlackboxNLP@EMNLP 2018. ", "title": "Nice work. Include additional Reference "}, "signatures": ["~pankaj_gupta1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~pankaj_gupta1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["secaojiezhang@mail.scut.edu.cn", "sejinchengli@mail.scut.edu.cn", "huxp@lzu.edu.cn", "peilinzhao@hotmail.com", "mingkuitan@scut.edu.cn"], "title": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "authors": ["Jiezhang Cao", "Jincheng Li", "Xiping Hu", "Peilin Zhao", "Mingkui Tan"], "TL;DR": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "abstract": "Deep neural networks (DNNs) have achieved unprecedented practical success in many applications.\nHowever, how to interpret DNNs is still an open problem.\nIn particular, what do hidden layers behave is not clearly understood. \nIn this paper, relying on a teacher-student paradigm, we seek to understand the layer behaviors of DNNs by ``monitoring\" both across-layer and single-layer distribution evolution to some target distribution in the training. Here, the ``across-layer\" and ``single-layer\" considers the layer behavior \\emph{along the depth} and  a specific layer \\emph{along training epochs}, respectively. \nRelying on optimal transport theory, we employ the Wasserstein distance ($W$-distance)  to measure the divergence between the layer distribution and the target distribution. \nTheoretically, we prove that i) the $W$-distance of across layers to the target distribution tends to decrease along the depth. ii) the $W$-distance of a specific layer to the target distribution tends to decrease along training iterations. iii) \nHowever, a deep layer is not always better than a shallow layer for some samples. Moreover, our results helps to analyze the stability of layer distributions and explains why auxiliary losses helps the training of DNNs. Extensive experiments on real-world datasets justify our theoretical findings.", "keywords": ["Interpretability of DNNs", "Wasserstein distance", "Layer behavior"], "pdf": "/pdf/d2481371910de3ba11f5d9c21852e539fd2b4715.pdf", "paperhash": "cao|towards_interpreting_deep_neural_networks_via_understanding_layer_behaviors", "original_pdf": "/attachment/f1239b7877efd927e7061f0b4a749a746dc6d08b.pdf", "_bibtex": "@misc{\ncao2020towards,\ntitle={Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors},\nauthor={Jiezhang Cao and Jincheng Li and Xiping Hu and Peilin Zhao and Mingkui Tan},\nyear={2020},\nurl={https://openreview.net/forum?id=rkxMKerYwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkxMKerYwr", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504180456, "tmdate": 1576860586912, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper2426/Authors", "ICLR.cc/2020/Conference/Paper2426/Reviewers", "ICLR.cc/2020/Conference/Paper2426/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2426/-/Public_Comment"}}}, {"id": "rkgUEKZ2PB", "original": null, "number": 2, "cdate": 1569622317946, "ddate": null, "tcdate": 1569622317946, "tmdate": 1569622317946, "tddate": null, "forum": "rkxMKerYwr", "replyto": "B1lIWeW3wH", "invitation": "ICLR.cc/2020/Conference/Paper2426/-/Public_Comment", "content": {"comment": "The submitted paper targets at understanding across-layer behavior during the learning process of DNNs. And the mentioned paper is about interpreting the predictions of RNNs. Why they are related? ", "title": "I do not think there is a connection between the two works."}, "signatures": ["~Cantona_ViVian1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Cantona_ViVian1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["secaojiezhang@mail.scut.edu.cn", "sejinchengli@mail.scut.edu.cn", "huxp@lzu.edu.cn", "peilinzhao@hotmail.com", "mingkuitan@scut.edu.cn"], "title": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "authors": ["Jiezhang Cao", "Jincheng Li", "Xiping Hu", "Peilin Zhao", "Mingkui Tan"], "TL;DR": "Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors", "abstract": "Deep neural networks (DNNs) have achieved unprecedented practical success in many applications.\nHowever, how to interpret DNNs is still an open problem.\nIn particular, what do hidden layers behave is not clearly understood. \nIn this paper, relying on a teacher-student paradigm, we seek to understand the layer behaviors of DNNs by ``monitoring\" both across-layer and single-layer distribution evolution to some target distribution in the training. Here, the ``across-layer\" and ``single-layer\" considers the layer behavior \\emph{along the depth} and  a specific layer \\emph{along training epochs}, respectively. \nRelying on optimal transport theory, we employ the Wasserstein distance ($W$-distance)  to measure the divergence between the layer distribution and the target distribution. \nTheoretically, we prove that i) the $W$-distance of across layers to the target distribution tends to decrease along the depth. ii) the $W$-distance of a specific layer to the target distribution tends to decrease along training iterations. iii) \nHowever, a deep layer is not always better than a shallow layer for some samples. Moreover, our results helps to analyze the stability of layer distributions and explains why auxiliary losses helps the training of DNNs. Extensive experiments on real-world datasets justify our theoretical findings.", "keywords": ["Interpretability of DNNs", "Wasserstein distance", "Layer behavior"], "pdf": "/pdf/d2481371910de3ba11f5d9c21852e539fd2b4715.pdf", "paperhash": "cao|towards_interpreting_deep_neural_networks_via_understanding_layer_behaviors", "original_pdf": "/attachment/f1239b7877efd927e7061f0b4a749a746dc6d08b.pdf", "_bibtex": "@misc{\ncao2020towards,\ntitle={Towards Interpreting Deep Neural Networks via Understanding Layer Behaviors},\nauthor={Jiezhang Cao and Jincheng Li and Xiping Hu and Peilin Zhao and Mingkui Tan},\nyear={2020},\nurl={https://openreview.net/forum?id=rkxMKerYwr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkxMKerYwr", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504180456, "tmdate": 1576860586912, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper2426/Authors", "ICLR.cc/2020/Conference/Paper2426/Reviewers", "ICLR.cc/2020/Conference/Paper2426/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2426/-/Public_Comment"}}}], "count": 13}