{"notes": [{"id": "BJeKh3VYDH", "original": "SJg8P3DGwB", "number": 198, "cdate": 1569438897348, "ddate": null, "tcdate": 1569438897348, "tmdate": 1583912027431, "tddate": null, "forum": "BJeKh3VYDH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds", "authors": ["Lukas Prantl", "Nuttapong Chentanez", "Stefan Jeschke", "Nils Thuerey"], "authorids": ["lukas.prantl@tum.de", "nuttapong26@gmail.com", "jeschke@stefan-jeschke.com", "nils.thuerey@tum.de"], "keywords": ["point clouds", "spatio-temporal representations", "Lagrangian data", "temporal coherence", "super-resolution", "denoising"], "TL;DR": "We propose a generative neural network approach for temporally coherent point clouds.", "abstract": "Point clouds, as a form of Lagrangian representation, allow for powerful and flexible applications in a large number of computational disciplines. We propose a novel deep-learning method to learn stable and temporally coherent feature spaces for points clouds that change over time. We identify a set of inherent problems with these approaches: without knowledge of the time dimension, the inferred solutions can exhibit strong flickering, and easy solutions to suppress this flickering can result in undesirable local minima that manifest themselves as halo structures. We propose a novel temporal loss function that takes into account higher time derivatives of the point positions, and encourages mingling, i.e., to prevent the aforementioned halos. We combine these techniques in a super-resolution method with a truncation approach to flexibly adapt the size of the generated positions. We show that our method works for large, deforming point sets from different sources to demonstrate the flexibility of our approach.", "pdf": "/pdf/585439c3aa3f3d0fa87a24893c86c5384ee58d27.pdf", "paperhash": "prantl|tranquil_clouds_neural_networks_for_learning_temporally_coherent_features_in_point_clouds", "_bibtex": "@inproceedings{\nPrantl2020Tranquil,\ntitle={Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds},\nauthor={Lukas Prantl and Nuttapong Chentanez and Stefan Jeschke and Nils Thuerey},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeKh3VYDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/bace279991894089e1918c8ba21c381dadcdf4fb.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "J3iKVKxIu", "original": null, "number": 1, "cdate": 1576798690028, "ddate": null, "tcdate": 1576798690028, "tmdate": 1576800945139, "tddate": null, "forum": "BJeKh3VYDH", "replyto": "BJeKh3VYDH", "invitation": "ICLR.cc/2020/Conference/Paper198/-/Decision", "content": {"decision": "Accept (Spotlight)", "comment": "This paper provides an improved method for deep learning on point clouds.  Reviewers are unanimous that this paper is acceptable, and the AC concurs. ", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds", "authors": ["Lukas Prantl", "Nuttapong Chentanez", "Stefan Jeschke", "Nils Thuerey"], "authorids": ["lukas.prantl@tum.de", "nuttapong26@gmail.com", "jeschke@stefan-jeschke.com", "nils.thuerey@tum.de"], "keywords": ["point clouds", "spatio-temporal representations", "Lagrangian data", "temporal coherence", "super-resolution", "denoising"], "TL;DR": "We propose a generative neural network approach for temporally coherent point clouds.", "abstract": "Point clouds, as a form of Lagrangian representation, allow for powerful and flexible applications in a large number of computational disciplines. We propose a novel deep-learning method to learn stable and temporally coherent feature spaces for points clouds that change over time. We identify a set of inherent problems with these approaches: without knowledge of the time dimension, the inferred solutions can exhibit strong flickering, and easy solutions to suppress this flickering can result in undesirable local minima that manifest themselves as halo structures. We propose a novel temporal loss function that takes into account higher time derivatives of the point positions, and encourages mingling, i.e., to prevent the aforementioned halos. We combine these techniques in a super-resolution method with a truncation approach to flexibly adapt the size of the generated positions. We show that our method works for large, deforming point sets from different sources to demonstrate the flexibility of our approach.", "pdf": "/pdf/585439c3aa3f3d0fa87a24893c86c5384ee58d27.pdf", "paperhash": "prantl|tranquil_clouds_neural_networks_for_learning_temporally_coherent_features_in_point_clouds", "_bibtex": "@inproceedings{\nPrantl2020Tranquil,\ntitle={Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds},\nauthor={Lukas Prantl and Nuttapong Chentanez and Stefan Jeschke and Nils Thuerey},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeKh3VYDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/bace279991894089e1918c8ba21c381dadcdf4fb.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "BJeKh3VYDH", "replyto": "BJeKh3VYDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795715160, "tmdate": 1576800265011, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper198/-/Decision"}}}, {"id": "HJl_VsdKsB", "original": null, "number": 4, "cdate": 1573649199963, "ddate": null, "tcdate": 1573649199963, "tmdate": 1573649199963, "tddate": null, "forum": "BJeKh3VYDH", "replyto": "H1emRfD0tr", "invitation": "ICLR.cc/2020/Conference/Paper198/-/Official_Comment", "content": {"title": "Thanks for your review. ", "comment": "We thank you for the positive assessment and feedback. Below are our responses to the concerns mentioned in your review. We will upload a revised version of our submission that extends the evaluation with respect to inputs with dense correspondences.\n\nRegarding the qualitative results we provide:\n\n- Each of our three scenarios contains between 60 and 200 frames. In total we show outputs for 420 frames with up to half a million particles. Thus the animations contain a much larger range of input configurations than most previous works. They also contain a wide range of temporal configurations that highlight the stability of our generative model. We have tested our method in other settings, and the performance of these 400+ frames is representative. Furthermore, the network used for all 3D tests was trained only once, which illustrates how well our network generalizes. \n\nIt is also worth noting that due to the patch-based nature of our approach, the input data correlates only partially. While the changes look simple to our eyes, the network has to deal with many non-trivial temporal changes in the inputs (the isolated patch examples in our videos illustrate this). If the reviewers agree that additional examples are would strengthen the submission, we\u2019d be happy to apply our network to additional input sequences.\n\nQuantitative results in our submission:\n\n- Thank you for this interesting suggestion. We performed an evaluation based on your comments: we use an animated mesh as a basis to compute ground truth reference points over time, and project the generated point positions onto the mesh. In this way we can establish a correlation between the generated point clouds, and calculate how much the change in position of the points corresponds to the ground-truth velocity and acceleration. Additionally, we also evaluate the point density, which is a good indicator of temporal stability, as it should be as uniform as possible. \n\nVelocity and acceleration are computed via the 1st and 2nd derivative of the predicted positions to the ground-truth position. These derivatives are especially important to highlight discontinuous motions and other temporal instabilities. For the density evaluation we also consider the variance of the 1st and 2nd derivative of the particle density. The variance highlights especially well how much the particle distributions vary over time.\n\nWe list the resulting measurements averaged over 100 frames in the following table for a version of our network without temporal loss (\u201cw/o\u201d) and with our full temporal loss formulation (\u201cwith\u201d):\n\n                            w/o          with\nVelocity            |   0.043   |   0.024\nAcceleration    |   0.078   |   0.043\n\nAnd for the variances of density derivatives:\n\n                                    w/o            with\nVar. of 1st Deriv.  |  0.01600  |   0.00013\nVar. of 2nd Deriv. |  0.03800  |   0.00017\n\nThus, in both cases, our temporal loss formulation leads to substantial improvements in terms of accuracy and stability. This evaluation shows how well our algorithm approximates the ground-truth velocity, and that it generates very uniform and stable point clouds. We will include these results in our revised paper (as Figure 9). \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper198/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper198/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds", "authors": ["Lukas Prantl", "Nuttapong Chentanez", "Stefan Jeschke", "Nils Thuerey"], "authorids": ["lukas.prantl@tum.de", "nuttapong26@gmail.com", "jeschke@stefan-jeschke.com", "nils.thuerey@tum.de"], "keywords": ["point clouds", "spatio-temporal representations", "Lagrangian data", "temporal coherence", "super-resolution", "denoising"], "TL;DR": "We propose a generative neural network approach for temporally coherent point clouds.", "abstract": "Point clouds, as a form of Lagrangian representation, allow for powerful and flexible applications in a large number of computational disciplines. We propose a novel deep-learning method to learn stable and temporally coherent feature spaces for points clouds that change over time. We identify a set of inherent problems with these approaches: without knowledge of the time dimension, the inferred solutions can exhibit strong flickering, and easy solutions to suppress this flickering can result in undesirable local minima that manifest themselves as halo structures. We propose a novel temporal loss function that takes into account higher time derivatives of the point positions, and encourages mingling, i.e., to prevent the aforementioned halos. We combine these techniques in a super-resolution method with a truncation approach to flexibly adapt the size of the generated positions. We show that our method works for large, deforming point sets from different sources to demonstrate the flexibility of our approach.", "pdf": "/pdf/585439c3aa3f3d0fa87a24893c86c5384ee58d27.pdf", "paperhash": "prantl|tranquil_clouds_neural_networks_for_learning_temporally_coherent_features_in_point_clouds", "_bibtex": "@inproceedings{\nPrantl2020Tranquil,\ntitle={Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds},\nauthor={Lukas Prantl and Nuttapong Chentanez and Stefan Jeschke and Nils Thuerey},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeKh3VYDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/bace279991894089e1918c8ba21c381dadcdf4fb.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJeKh3VYDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper198/Authors", "ICLR.cc/2020/Conference/Paper198/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper198/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper198/Reviewers", "ICLR.cc/2020/Conference/Paper198/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper198/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper198/Authors|ICLR.cc/2020/Conference/Paper198/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504174916, "tmdate": 1576860540107, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper198/Authors", "ICLR.cc/2020/Conference/Paper198/Reviewers", "ICLR.cc/2020/Conference/Paper198/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper198/-/Official_Comment"}}}, {"id": "SJefiq_tjB", "original": null, "number": 3, "cdate": 1573649050101, "ddate": null, "tcdate": 1573649050101, "tmdate": 1573649050101, "tddate": null, "forum": "BJeKh3VYDH", "replyto": "SJlE85gmcS", "invitation": "ICLR.cc/2020/Conference/Paper198/-/Official_Comment", "content": {"title": "Thanks for your review. ", "comment": "We thank you for the positive comments and assessment of our work."}, "signatures": ["ICLR.cc/2020/Conference/Paper198/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper198/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds", "authors": ["Lukas Prantl", "Nuttapong Chentanez", "Stefan Jeschke", "Nils Thuerey"], "authorids": ["lukas.prantl@tum.de", "nuttapong26@gmail.com", "jeschke@stefan-jeschke.com", "nils.thuerey@tum.de"], "keywords": ["point clouds", "spatio-temporal representations", "Lagrangian data", "temporal coherence", "super-resolution", "denoising"], "TL;DR": "We propose a generative neural network approach for temporally coherent point clouds.", "abstract": "Point clouds, as a form of Lagrangian representation, allow for powerful and flexible applications in a large number of computational disciplines. We propose a novel deep-learning method to learn stable and temporally coherent feature spaces for points clouds that change over time. We identify a set of inherent problems with these approaches: without knowledge of the time dimension, the inferred solutions can exhibit strong flickering, and easy solutions to suppress this flickering can result in undesirable local minima that manifest themselves as halo structures. We propose a novel temporal loss function that takes into account higher time derivatives of the point positions, and encourages mingling, i.e., to prevent the aforementioned halos. We combine these techniques in a super-resolution method with a truncation approach to flexibly adapt the size of the generated positions. We show that our method works for large, deforming point sets from different sources to demonstrate the flexibility of our approach.", "pdf": "/pdf/585439c3aa3f3d0fa87a24893c86c5384ee58d27.pdf", "paperhash": "prantl|tranquil_clouds_neural_networks_for_learning_temporally_coherent_features_in_point_clouds", "_bibtex": "@inproceedings{\nPrantl2020Tranquil,\ntitle={Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds},\nauthor={Lukas Prantl and Nuttapong Chentanez and Stefan Jeschke and Nils Thuerey},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeKh3VYDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/bace279991894089e1918c8ba21c381dadcdf4fb.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJeKh3VYDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper198/Authors", "ICLR.cc/2020/Conference/Paper198/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper198/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper198/Reviewers", "ICLR.cc/2020/Conference/Paper198/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper198/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper198/Authors|ICLR.cc/2020/Conference/Paper198/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504174916, "tmdate": 1576860540107, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper198/Authors", "ICLR.cc/2020/Conference/Paper198/Reviewers", "ICLR.cc/2020/Conference/Paper198/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper198/-/Official_Comment"}}}, {"id": "H1eNK5dFoS", "original": null, "number": 2, "cdate": 1573649020195, "ddate": null, "tcdate": 1573649020195, "tmdate": 1573649020195, "tddate": null, "forum": "BJeKh3VYDH", "replyto": "BkeSwCWwqB", "invitation": "ICLR.cc/2020/Conference/Paper198/-/Official_Comment", "content": {"title": "Thanks for your review.", "comment": "We thank you for the positive review and feedback. Below are our responses to the concerns mentioned in your review.\n\nSlow input movement:\n- When generating point clouds without temporal constraints, one of the biggest problems is a high frequency jittering that occurs due to accumulated small scale inference errors. Especially with very small movements these jittering artifacts are very noticeable. Thus a temporal constraint is also relevant for an almost static input.\n\nOther point-based algorithms:\n- That's a very interesting thought. In theory, our method can be used with other point-based methods. Only the training process would need to be updated, while the method for inference could stay the same. We will add this as a discussion to our document.\n\nDifferent choices of weighting terms:\n- A larger temporal loss factor leads to central clusters of points. The effects of the different ratios within the temporal loss (velocity and acceleration) are shown in the provided video starting from 0:26. There one can clearly see how the additional acceleration loss term prevents flickering.\n\nWith an increased upsampling factor the memory utilization and the training time increases considerably, especially for the volumetric data. As we primarily target temporal stability, we did not evaluate larger upsampling factors so far (smaller ones would be less problematic).\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper198/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper198/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds", "authors": ["Lukas Prantl", "Nuttapong Chentanez", "Stefan Jeschke", "Nils Thuerey"], "authorids": ["lukas.prantl@tum.de", "nuttapong26@gmail.com", "jeschke@stefan-jeschke.com", "nils.thuerey@tum.de"], "keywords": ["point clouds", "spatio-temporal representations", "Lagrangian data", "temporal coherence", "super-resolution", "denoising"], "TL;DR": "We propose a generative neural network approach for temporally coherent point clouds.", "abstract": "Point clouds, as a form of Lagrangian representation, allow for powerful and flexible applications in a large number of computational disciplines. We propose a novel deep-learning method to learn stable and temporally coherent feature spaces for points clouds that change over time. We identify a set of inherent problems with these approaches: without knowledge of the time dimension, the inferred solutions can exhibit strong flickering, and easy solutions to suppress this flickering can result in undesirable local minima that manifest themselves as halo structures. We propose a novel temporal loss function that takes into account higher time derivatives of the point positions, and encourages mingling, i.e., to prevent the aforementioned halos. We combine these techniques in a super-resolution method with a truncation approach to flexibly adapt the size of the generated positions. We show that our method works for large, deforming point sets from different sources to demonstrate the flexibility of our approach.", "pdf": "/pdf/585439c3aa3f3d0fa87a24893c86c5384ee58d27.pdf", "paperhash": "prantl|tranquil_clouds_neural_networks_for_learning_temporally_coherent_features_in_point_clouds", "_bibtex": "@inproceedings{\nPrantl2020Tranquil,\ntitle={Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds},\nauthor={Lukas Prantl and Nuttapong Chentanez and Stefan Jeschke and Nils Thuerey},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeKh3VYDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/bace279991894089e1918c8ba21c381dadcdf4fb.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJeKh3VYDH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper198/Authors", "ICLR.cc/2020/Conference/Paper198/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper198/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper198/Reviewers", "ICLR.cc/2020/Conference/Paper198/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper198/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper198/Authors|ICLR.cc/2020/Conference/Paper198/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504174916, "tmdate": 1576860540107, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper198/Authors", "ICLR.cc/2020/Conference/Paper198/Reviewers", "ICLR.cc/2020/Conference/Paper198/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper198/-/Official_Comment"}}}, {"id": "H1emRfD0tr", "original": null, "number": 1, "cdate": 1571873482897, "ddate": null, "tcdate": 1571873482897, "tmdate": 1572972626374, "tddate": null, "forum": "BJeKh3VYDH", "replyto": "BJeKh3VYDH", "invitation": "ICLR.cc/2020/Conference/Paper198/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary:\nThis paper proposed a deep network for point cloud sequence super-resolution/upsampling. Building on the basis of pointNet and PU-net, the main contribution of the paper is identifying the problem of temporal incoherence in the process of upsampling a point cloud shape representation as well as a training loss to encourage temporal coherence. In the cases showed in the paper, the proposed method seems effective comparing to previous work which is not done on sequence data. My main concern about the work is that the experimental evaluation is limited.\n\nStrengths:\nInteresting problem and novel idea.\nThe proposed method is technically sound. From the provided results, the newly introduced training loss seems effective: the result sequences are visually more plausible and smooth.\nWeaknesses:\nQualitative results are limited and in most cases seemingly simple. In the paper as well as the companion video, there are very few examples provided. The scale of the evaluation demonstration is not convincing enough for the readers that this work could be generalized to more complicated testing scenarios.\nQuantitative results are also limited. Since the method is handling the coherence of shape deformation over time, it would be much more convincing and helpful to introduce a dense-correspondence evaluation as a benchmark. For example, one can create ground-truth correspondence from parametric morphable models and evaluate the coherence of the sequence by comparing the generated results with the ground truth.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper198/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper198/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds", "authors": ["Lukas Prantl", "Nuttapong Chentanez", "Stefan Jeschke", "Nils Thuerey"], "authorids": ["lukas.prantl@tum.de", "nuttapong26@gmail.com", "jeschke@stefan-jeschke.com", "nils.thuerey@tum.de"], "keywords": ["point clouds", "spatio-temporal representations", "Lagrangian data", "temporal coherence", "super-resolution", "denoising"], "TL;DR": "We propose a generative neural network approach for temporally coherent point clouds.", "abstract": "Point clouds, as a form of Lagrangian representation, allow for powerful and flexible applications in a large number of computational disciplines. We propose a novel deep-learning method to learn stable and temporally coherent feature spaces for points clouds that change over time. We identify a set of inherent problems with these approaches: without knowledge of the time dimension, the inferred solutions can exhibit strong flickering, and easy solutions to suppress this flickering can result in undesirable local minima that manifest themselves as halo structures. We propose a novel temporal loss function that takes into account higher time derivatives of the point positions, and encourages mingling, i.e., to prevent the aforementioned halos. We combine these techniques in a super-resolution method with a truncation approach to flexibly adapt the size of the generated positions. We show that our method works for large, deforming point sets from different sources to demonstrate the flexibility of our approach.", "pdf": "/pdf/585439c3aa3f3d0fa87a24893c86c5384ee58d27.pdf", "paperhash": "prantl|tranquil_clouds_neural_networks_for_learning_temporally_coherent_features_in_point_clouds", "_bibtex": "@inproceedings{\nPrantl2020Tranquil,\ntitle={Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds},\nauthor={Lukas Prantl and Nuttapong Chentanez and Stefan Jeschke and Nils Thuerey},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeKh3VYDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/bace279991894089e1918c8ba21c381dadcdf4fb.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJeKh3VYDH", "replyto": "BJeKh3VYDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper198/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper198/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575920797499, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper198/Reviewers"], "noninvitees": [], "tcdate": 1570237755611, "tmdate": 1575920797514, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper198/-/Official_Review"}}}, {"id": "SJlE85gmcS", "original": null, "number": 2, "cdate": 1572174411816, "ddate": null, "tcdate": 1572174411816, "tmdate": 1572972626331, "tddate": null, "forum": "BJeKh3VYDH", "replyto": "BJeKh3VYDH", "invitation": "ICLR.cc/2020/Conference/Paper198/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper addresses the task of learning temporally stable features for point clouds with an application to upsampling point clouds. Learning point-based descriptors has been a major topic of research in the recent vision and graphics meetings, where approaches have been proposed focusing semantic labeling, geometry-oriented tasks (e.g. normal estimation), and point-based graphics. However, as the paper states, and to the best of my knowledge, no methods have been proposed to learn features in fourth dimension in a temporally stable way. Thus, the very topic of research is significantly novel and promising. \n\nThe authors consider a combination of loss functions and train a neural point-based network to learn the features. To stabilize training, the authors carefully study the effect of a series of loss functions, including well-known EMD, losses ensuring slow changes in positions, velocities, and accelerations, as well as a mingling loss to ensure a more uniform spatial point distribution on the output shape. The studied losses are very logical to implement as one aims to ensure that the output should satisfy a temporally smooth motion pattern. \n\nThe experimental results provide a clear view of the proposed approach and demonstrate that combining the studied objectives function with a known point-based learning approach leads to a temporally stable feature representation per-point. An ablation study further helps to validate the proposed approaches step-by-step.\n\nTo sum up, I believe paper should clearly be accepted, as (1) the work addresses a novel point-based learning task, (2) the research methodology is convincingly presented, and (3) the results provide a clear demonstration of the feasibility of the proposed task.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper198/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper198/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds", "authors": ["Lukas Prantl", "Nuttapong Chentanez", "Stefan Jeschke", "Nils Thuerey"], "authorids": ["lukas.prantl@tum.de", "nuttapong26@gmail.com", "jeschke@stefan-jeschke.com", "nils.thuerey@tum.de"], "keywords": ["point clouds", "spatio-temporal representations", "Lagrangian data", "temporal coherence", "super-resolution", "denoising"], "TL;DR": "We propose a generative neural network approach for temporally coherent point clouds.", "abstract": "Point clouds, as a form of Lagrangian representation, allow for powerful and flexible applications in a large number of computational disciplines. We propose a novel deep-learning method to learn stable and temporally coherent feature spaces for points clouds that change over time. We identify a set of inherent problems with these approaches: without knowledge of the time dimension, the inferred solutions can exhibit strong flickering, and easy solutions to suppress this flickering can result in undesirable local minima that manifest themselves as halo structures. We propose a novel temporal loss function that takes into account higher time derivatives of the point positions, and encourages mingling, i.e., to prevent the aforementioned halos. We combine these techniques in a super-resolution method with a truncation approach to flexibly adapt the size of the generated positions. We show that our method works for large, deforming point sets from different sources to demonstrate the flexibility of our approach.", "pdf": "/pdf/585439c3aa3f3d0fa87a24893c86c5384ee58d27.pdf", "paperhash": "prantl|tranquil_clouds_neural_networks_for_learning_temporally_coherent_features_in_point_clouds", "_bibtex": "@inproceedings{\nPrantl2020Tranquil,\ntitle={Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds},\nauthor={Lukas Prantl and Nuttapong Chentanez and Stefan Jeschke and Nils Thuerey},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeKh3VYDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/bace279991894089e1918c8ba21c381dadcdf4fb.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJeKh3VYDH", "replyto": "BJeKh3VYDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper198/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper198/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575920797499, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper198/Reviewers"], "noninvitees": [], "tcdate": 1570237755611, "tmdate": 1575920797514, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper198/-/Official_Review"}}}, {"id": "BkeSwCWwqB", "original": null, "number": 3, "cdate": 1572441692760, "ddate": null, "tcdate": 1572441692760, "tmdate": 1572972626288, "tddate": null, "forum": "BJeKh3VYDH", "replyto": "BJeKh3VYDH", "invitation": "ICLR.cc/2020/Conference/Paper198/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper tries to learn temporally stable representations for point-based data sets and focus on varying size and dynamic point sets, and demonstrate its usefulness in the context of super-resolution. To deal with a difficult target that dynamically moves and deforms over time with variable input and output size, they take a novel temporal loss function for temporally coherent point set generation and siamese network setup for temporal loss calculation. Their novel temporal loss is based on EMD to minimize differences between an estimated point cloud and a desired super-resolution point cloud. The discussion and evolution on multiple loss functions are mostly well done. Except spatial loss is considered, taking the ground truth acceleration and estimated velocity into account is beneficial to this task. Their main contribution is taking permutation invariant loss terms and a siamese training setup and generator architecture, enabling improved output variance by allowing for dynamic adjustments of the output size, and identifying a specialized form of mode collapse for temporal point networks. \nThey perform an empirical study of their temporal loss function on the generated data set and apply the proposed method to some complex 3D models to conclude the superior performance of temporal loss formulation in contrast to previous work.\n \nOverall, this paper has some significant points on point cloud super-resolution, with the caveat for some clarifications on the theory and experiments. Given these clarifications in an author response, I would be willing to increase the score.\n \nWhen the input moves slowly enough, the point cloud can be considered static. Can the proposed temporal loss outperform other works under this condition? \n \nOnly one previous work PU-Net based on PointNet++ is compared in the paper, I would like to see more discussion on applying the proposed temporal loss with other point-based algorithms.\n \nI am very curious about the effect on different choices of weighting terms hyperparameters in temporal loss and predefined upsampling factor r.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper198/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper198/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds", "authors": ["Lukas Prantl", "Nuttapong Chentanez", "Stefan Jeschke", "Nils Thuerey"], "authorids": ["lukas.prantl@tum.de", "nuttapong26@gmail.com", "jeschke@stefan-jeschke.com", "nils.thuerey@tum.de"], "keywords": ["point clouds", "spatio-temporal representations", "Lagrangian data", "temporal coherence", "super-resolution", "denoising"], "TL;DR": "We propose a generative neural network approach for temporally coherent point clouds.", "abstract": "Point clouds, as a form of Lagrangian representation, allow for powerful and flexible applications in a large number of computational disciplines. We propose a novel deep-learning method to learn stable and temporally coherent feature spaces for points clouds that change over time. We identify a set of inherent problems with these approaches: without knowledge of the time dimension, the inferred solutions can exhibit strong flickering, and easy solutions to suppress this flickering can result in undesirable local minima that manifest themselves as halo structures. We propose a novel temporal loss function that takes into account higher time derivatives of the point positions, and encourages mingling, i.e., to prevent the aforementioned halos. We combine these techniques in a super-resolution method with a truncation approach to flexibly adapt the size of the generated positions. We show that our method works for large, deforming point sets from different sources to demonstrate the flexibility of our approach.", "pdf": "/pdf/585439c3aa3f3d0fa87a24893c86c5384ee58d27.pdf", "paperhash": "prantl|tranquil_clouds_neural_networks_for_learning_temporally_coherent_features_in_point_clouds", "_bibtex": "@inproceedings{\nPrantl2020Tranquil,\ntitle={Tranquil Clouds: Neural Networks for Learning Temporally Coherent Features in Point Clouds},\nauthor={Lukas Prantl and Nuttapong Chentanez and Stefan Jeschke and Nils Thuerey},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=BJeKh3VYDH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/bace279991894089e1918c8ba21c381dadcdf4fb.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJeKh3VYDH", "replyto": "BJeKh3VYDH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper198/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper198/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575920797499, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper198/Reviewers"], "noninvitees": [], "tcdate": 1570237755611, "tmdate": 1575920797514, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper198/-/Official_Review"}}}], "count": 8}