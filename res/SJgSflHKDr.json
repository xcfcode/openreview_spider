{"notes": [{"id": "SJgSflHKDr", "original": "ByxrGzxtvr", "number": 2171, "cdate": 1569439756624, "ddate": null, "tcdate": 1569439756624, "tmdate": 1577168293036, "tddate": null, "forum": "SJgSflHKDr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["jzilly@ethz.ch", "hzilly@ethz.ch", "richtero@ethz.ch", "wattenhofer@ethz.ch", "acensi@ethz.ch", "emilio.frazzoli@idsc.mavt.ethz.ch"], "title": "The Frechet Distance of training and test distribution predicts the generalization gap", "authors": ["Julian Zilly", "Hannes Zilly", "Oliver Richter", "Roger Wattenhofer", "Andrea Censi", "Emilio Frazzoli"], "pdf": "/pdf/09cc6c1edd3ef4dd318eee08de43fafed57765ef.pdf", "TL;DR": "The Frechet Distance between train and test distribution correlates with the change in performance for functions that are not invariant to the shift.", "abstract": "Learning theory tells us that more data is better when minimizing the generalization error of identically distributed training and test sets. However, when training and test distribution differ, this distribution shift can have a significant effect. With a novel perspective on function transfer learning, we are able to lower bound the change of performance when transferring from training to test set with the Wasserstein distance between the embedded training and test set distribution. We find that there is a trade-off affecting performance between how invariant a function is to changes in training and test distribution and how large this shift in distribution is. Empirically across several data domains, we substantiate this viewpoint by showing that test performance correlates strongly with the distance in data distributions between training and test set. Complementary to the popular belief that more data is always better, our results highlight the utility of also choosing a training data distribution that is close to the test data distribution when the learned function is not invariant to such changes.", "keywords": ["Generalization", "Transfer learning", "Frechet distance", "Optimal transport", "Domain adaptation", "Distribution shift", "Invariance"], "paperhash": "zilly|the_frechet_distance_of_training_and_test_distribution_predicts_the_generalization_gap", "original_pdf": "/attachment/af29a582acb9e84e43cdb90ded0af57501a80ce1.pdf", "_bibtex": "@misc{\nzilly2020the,\ntitle={The Frechet Distance of training and test distribution predicts the generalization gap},\nauthor={Julian Zilly and Hannes Zilly and Oliver Richter and Roger Wattenhofer and Andrea Censi and Emilio Frazzoli},\nyear={2020},\nurl={https://openreview.net/forum?id=SJgSflHKDr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "Mrprk-YZZ6", "original": null, "number": 1, "cdate": 1576798742331, "ddate": null, "tcdate": 1576798742331, "tmdate": 1576800893888, "tddate": null, "forum": "SJgSflHKDr", "replyto": "SJgSflHKDr", "invitation": "ICLR.cc/2020/Conference/Paper2171/-/Decision", "content": {"decision": "Reject", "comment": "The authors discuss how to predict generalization gaps. Reviews are mixed, putting the submission in the lower half of this year's submissions. I also would have liked to see a comparison with other divergence metrics, for example, L1, MMD, H-distance, discrepancy distance, and learned representations (e.g., BERT, Laser, etc., for language). Without this, the empirical evaluation of FD is a bit weak. Also, the obvious next step would be trying to minimize FD in the context of domain adaptation, and the question is if this shouldn't already be part of your paper? Suggestions: The Amazon reviews are time-stamped, enabling you to run experiments with drift over time. See [0] for an example. \n\n[0] https://www.aclweb.org/anthology/W18-6210/", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["jzilly@ethz.ch", "hzilly@ethz.ch", "richtero@ethz.ch", "wattenhofer@ethz.ch", "acensi@ethz.ch", "emilio.frazzoli@idsc.mavt.ethz.ch"], "title": "The Frechet Distance of training and test distribution predicts the generalization gap", "authors": ["Julian Zilly", "Hannes Zilly", "Oliver Richter", "Roger Wattenhofer", "Andrea Censi", "Emilio Frazzoli"], "pdf": "/pdf/09cc6c1edd3ef4dd318eee08de43fafed57765ef.pdf", "TL;DR": "The Frechet Distance between train and test distribution correlates with the change in performance for functions that are not invariant to the shift.", "abstract": "Learning theory tells us that more data is better when minimizing the generalization error of identically distributed training and test sets. However, when training and test distribution differ, this distribution shift can have a significant effect. With a novel perspective on function transfer learning, we are able to lower bound the change of performance when transferring from training to test set with the Wasserstein distance between the embedded training and test set distribution. We find that there is a trade-off affecting performance between how invariant a function is to changes in training and test distribution and how large this shift in distribution is. Empirically across several data domains, we substantiate this viewpoint by showing that test performance correlates strongly with the distance in data distributions between training and test set. Complementary to the popular belief that more data is always better, our results highlight the utility of also choosing a training data distribution that is close to the test data distribution when the learned function is not invariant to such changes.", "keywords": ["Generalization", "Transfer learning", "Frechet distance", "Optimal transport", "Domain adaptation", "Distribution shift", "Invariance"], "paperhash": "zilly|the_frechet_distance_of_training_and_test_distribution_predicts_the_generalization_gap", "original_pdf": "/attachment/af29a582acb9e84e43cdb90ded0af57501a80ce1.pdf", "_bibtex": "@misc{\nzilly2020the,\ntitle={The Frechet Distance of training and test distribution predicts the generalization gap},\nauthor={Julian Zilly and Hannes Zilly and Oliver Richter and Roger Wattenhofer and Andrea Censi and Emilio Frazzoli},\nyear={2020},\nurl={https://openreview.net/forum?id=SJgSflHKDr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "SJgSflHKDr", "replyto": "SJgSflHKDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795715055, "tmdate": 1576800264888, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2171/-/Decision"}}}, {"id": "H1euOzraKS", "original": null, "number": 1, "cdate": 1571799664291, "ddate": null, "tcdate": 1571799664291, "tmdate": 1572972373844, "tddate": null, "forum": "SJgSflHKDr", "replyto": "SJgSflHKDr", "invitation": "ICLR.cc/2020/Conference/Paper2171/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors consider the relation between Frechet distance of training and test distribution and the generalization gap. The authors derive the lower bound for the difference of loss function w.r.t. training and test set by the Wasserstein distance between embedding training and test set distribution. Empirically, the authors illustrate a strong correlation between test performance and the distance in distributions between training and test set.\n\nThe motivation to find the relation between generalization gap and the Frechet distance of training and test distribution is sound. However, I am not sure that the lower bound as in Equation (1) is enough. I am curious that one can derive the upper bound for the relation or not. The finding about choosing a training data distribution should be close to the test data distribution seems quite trivial in some sense. I am not clear about its important since it is quite popular that the distribution shift affects the performance and many learning approach assumes same distribution for training and test data. Overall I feel that the contribution may be quite weak, and I lean on the negative side.\n\nBelow are some of my concerns:\n\n1) About the lower-bound in Equation (1), it seems unclear to me that when the W_2(p1, p2) = 0, we can inference any information about the test performance (It seems quite trivial for this case, the left hand side time is greater than or equal 0?) In my opinion, the upper-bound is more important which one can inference much information about the difference of generalization gap.\n\n2) In the proof of Theorem 1, it is quite hard to follow with the current notation, for the integral in (i), (ii) as well as in the proof using the intermediate value theorem, which variables are used? I am confused which one is variable, which one is constants in those integrals.\n\n3) In page 5, at the interpretation (1), for W2(p1, p2) = 0, the learned function fits training distribution perfectly and is not ill-conditioned ==> why one can deduce that the test distribution is fit perfectly? What we have in Theorem 1 is the lower-bound only?\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2171/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2171/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["jzilly@ethz.ch", "hzilly@ethz.ch", "richtero@ethz.ch", "wattenhofer@ethz.ch", "acensi@ethz.ch", "emilio.frazzoli@idsc.mavt.ethz.ch"], "title": "The Frechet Distance of training and test distribution predicts the generalization gap", "authors": ["Julian Zilly", "Hannes Zilly", "Oliver Richter", "Roger Wattenhofer", "Andrea Censi", "Emilio Frazzoli"], "pdf": "/pdf/09cc6c1edd3ef4dd318eee08de43fafed57765ef.pdf", "TL;DR": "The Frechet Distance between train and test distribution correlates with the change in performance for functions that are not invariant to the shift.", "abstract": "Learning theory tells us that more data is better when minimizing the generalization error of identically distributed training and test sets. However, when training and test distribution differ, this distribution shift can have a significant effect. With a novel perspective on function transfer learning, we are able to lower bound the change of performance when transferring from training to test set with the Wasserstein distance between the embedded training and test set distribution. We find that there is a trade-off affecting performance between how invariant a function is to changes in training and test distribution and how large this shift in distribution is. Empirically across several data domains, we substantiate this viewpoint by showing that test performance correlates strongly with the distance in data distributions between training and test set. Complementary to the popular belief that more data is always better, our results highlight the utility of also choosing a training data distribution that is close to the test data distribution when the learned function is not invariant to such changes.", "keywords": ["Generalization", "Transfer learning", "Frechet distance", "Optimal transport", "Domain adaptation", "Distribution shift", "Invariance"], "paperhash": "zilly|the_frechet_distance_of_training_and_test_distribution_predicts_the_generalization_gap", "original_pdf": "/attachment/af29a582acb9e84e43cdb90ded0af57501a80ce1.pdf", "_bibtex": "@misc{\nzilly2020the,\ntitle={The Frechet Distance of training and test distribution predicts the generalization gap},\nauthor={Julian Zilly and Hannes Zilly and Oliver Richter and Roger Wattenhofer and Andrea Censi and Emilio Frazzoli},\nyear={2020},\nurl={https://openreview.net/forum?id=SJgSflHKDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJgSflHKDr", "replyto": "SJgSflHKDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2171/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2171/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575628379263, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2171/Reviewers"], "noninvitees": [], "tcdate": 1570237726682, "tmdate": 1575628379279, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2171/-/Official_Review"}}}, {"id": "ryx1DuaTKr", "original": null, "number": 2, "cdate": 1571833942564, "ddate": null, "tcdate": 1571833942564, "tmdate": 1572972373797, "tddate": null, "forum": "SJgSflHKDr", "replyto": "SJgSflHKDr", "invitation": "ICLR.cc/2020/Conference/Paper2171/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The authors propose to relate the performance of a classifier under distribution shift using a quantity called Frechet distance. It is common belief that the further apart the training and test distributions are, the more difficult it is to transfer a learned classifier. They give simple bounds via gradient norm/Lipschitz constants and distribution distance in Theorem 1. The authors try to capture it with Frechet distance, but I struggle to understand what is new in this work. \n\nFirst, there are a lot of assumptions in the computation of the Frechet distance: \n  1. The authors use the embeddings given by the neural networks instead of the raw data since density estimation is hard. This makes the distance model-dependent \n  2. The authors assume the embeddings are normally distributed in their computation, which have not been justified. \n\nMost importantly, they do not relate the Frechet distance to the lower bound in Theorem 1. There is no estimation on how the learned changes across distributions in the gradient norm term. This makes the evaluation nothing more than a confirmation of the general idea that the closer the distribution, the better the transfer. The lower bound is not used in any quantitative manner. \n\nThe authors should make the connection of the bound and its computation clear, with proper connections to the experiments. The current paper looks like separate theoretical and experimental results that do not tie together. \n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2171/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2171/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["jzilly@ethz.ch", "hzilly@ethz.ch", "richtero@ethz.ch", "wattenhofer@ethz.ch", "acensi@ethz.ch", "emilio.frazzoli@idsc.mavt.ethz.ch"], "title": "The Frechet Distance of training and test distribution predicts the generalization gap", "authors": ["Julian Zilly", "Hannes Zilly", "Oliver Richter", "Roger Wattenhofer", "Andrea Censi", "Emilio Frazzoli"], "pdf": "/pdf/09cc6c1edd3ef4dd318eee08de43fafed57765ef.pdf", "TL;DR": "The Frechet Distance between train and test distribution correlates with the change in performance for functions that are not invariant to the shift.", "abstract": "Learning theory tells us that more data is better when minimizing the generalization error of identically distributed training and test sets. However, when training and test distribution differ, this distribution shift can have a significant effect. With a novel perspective on function transfer learning, we are able to lower bound the change of performance when transferring from training to test set with the Wasserstein distance between the embedded training and test set distribution. We find that there is a trade-off affecting performance between how invariant a function is to changes in training and test distribution and how large this shift in distribution is. Empirically across several data domains, we substantiate this viewpoint by showing that test performance correlates strongly with the distance in data distributions between training and test set. Complementary to the popular belief that more data is always better, our results highlight the utility of also choosing a training data distribution that is close to the test data distribution when the learned function is not invariant to such changes.", "keywords": ["Generalization", "Transfer learning", "Frechet distance", "Optimal transport", "Domain adaptation", "Distribution shift", "Invariance"], "paperhash": "zilly|the_frechet_distance_of_training_and_test_distribution_predicts_the_generalization_gap", "original_pdf": "/attachment/af29a582acb9e84e43cdb90ded0af57501a80ce1.pdf", "_bibtex": "@misc{\nzilly2020the,\ntitle={The Frechet Distance of training and test distribution predicts the generalization gap},\nauthor={Julian Zilly and Hannes Zilly and Oliver Richter and Roger Wattenhofer and Andrea Censi and Emilio Frazzoli},\nyear={2020},\nurl={https://openreview.net/forum?id=SJgSflHKDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJgSflHKDr", "replyto": "SJgSflHKDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2171/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2171/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575628379263, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2171/Reviewers"], "noninvitees": [], "tcdate": 1570237726682, "tmdate": 1575628379279, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2171/-/Official_Review"}}}, {"id": "B1goCQ9J9B", "original": null, "number": 3, "cdate": 1571951571384, "ddate": null, "tcdate": 1571951571384, "tmdate": 1572972373751, "tddate": null, "forum": "SJgSflHKDr", "replyto": "SJgSflHKDr", "invitation": "ICLR.cc/2020/Conference/Paper2171/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper considers the problem of how the mismatch between distributions of training data and test data would affect the generalization gap in machine learning tasks. This phenomenon has been observed many times in previous literature and has gathered significant attention in the machine learning community.\n\nThe paper took a step in relating the change in the performance of the learned function to the Frechet distance (FD), also known as 2-Wasserstein distance, between the input and output distributions and proved that the former is lower bounded by the latter multiplied by a term related to the sensitivity of learning algorithm to distribution shift. The paper also provides empirical evidence that the testing error is correlated with the FD between input and output distributions based on tasks including text classification, image classification, and speech separation.\n\nI find the idea of the paper interesting but the content not convincing enough. The theory proved in the paper does not provide additional quantitive insight beyond intuition. Specifically, the term about the sensitivity of the algorithm is not justified enough in the paper. The experiments provide some evidence but not convincing, especially for the part about image classification.\n\nI also find the statement about the generalization gap a bit misleading. Generally, the generalization gap refers to the gap between the expected error and the empirical error.  But the experiments are mostly presenting the performance on the test data. \n\nOverall, I don't think the paper meets the standard for publication at ICLR."}, "signatures": ["ICLR.cc/2020/Conference/Paper2171/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2171/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["jzilly@ethz.ch", "hzilly@ethz.ch", "richtero@ethz.ch", "wattenhofer@ethz.ch", "acensi@ethz.ch", "emilio.frazzoli@idsc.mavt.ethz.ch"], "title": "The Frechet Distance of training and test distribution predicts the generalization gap", "authors": ["Julian Zilly", "Hannes Zilly", "Oliver Richter", "Roger Wattenhofer", "Andrea Censi", "Emilio Frazzoli"], "pdf": "/pdf/09cc6c1edd3ef4dd318eee08de43fafed57765ef.pdf", "TL;DR": "The Frechet Distance between train and test distribution correlates with the change in performance for functions that are not invariant to the shift.", "abstract": "Learning theory tells us that more data is better when minimizing the generalization error of identically distributed training and test sets. However, when training and test distribution differ, this distribution shift can have a significant effect. With a novel perspective on function transfer learning, we are able to lower bound the change of performance when transferring from training to test set with the Wasserstein distance between the embedded training and test set distribution. We find that there is a trade-off affecting performance between how invariant a function is to changes in training and test distribution and how large this shift in distribution is. Empirically across several data domains, we substantiate this viewpoint by showing that test performance correlates strongly with the distance in data distributions between training and test set. Complementary to the popular belief that more data is always better, our results highlight the utility of also choosing a training data distribution that is close to the test data distribution when the learned function is not invariant to such changes.", "keywords": ["Generalization", "Transfer learning", "Frechet distance", "Optimal transport", "Domain adaptation", "Distribution shift", "Invariance"], "paperhash": "zilly|the_frechet_distance_of_training_and_test_distribution_predicts_the_generalization_gap", "original_pdf": "/attachment/af29a582acb9e84e43cdb90ded0af57501a80ce1.pdf", "_bibtex": "@misc{\nzilly2020the,\ntitle={The Frechet Distance of training and test distribution predicts the generalization gap},\nauthor={Julian Zilly and Hannes Zilly and Oliver Richter and Roger Wattenhofer and Andrea Censi and Emilio Frazzoli},\nyear={2020},\nurl={https://openreview.net/forum?id=SJgSflHKDr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJgSflHKDr", "replyto": "SJgSflHKDr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2171/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2171/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575628379263, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2171/Reviewers"], "noninvitees": [], "tcdate": 1570237726682, "tmdate": 1575628379279, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2171/-/Official_Review"}}}], "count": 5}