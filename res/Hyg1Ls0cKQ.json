{"notes": [{"id": "Hyg1Ls0cKQ", "original": "SJgZ9V2Kt7", "number": 140, "cdate": 1538087751284, "ddate": null, "tcdate": 1538087751284, "tmdate": 1545355423383, "tddate": null, "forum": "Hyg1Ls0cKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning Latent Semantic Representation from Pre-defined Generative Model", "abstract": "Learning representations of data is an important issue in machine learning. Though GAN has led to significant improvements in the data representations, it still has several problems such as unstable training, hidden manifold of data, and huge computational overhead. GAN tends to produce the data simply without any information about the manifold of the data, which hinders from controlling desired features to generate. Moreover, most of GAN\u2019s have a large size of manifold, resulting in poor scalability. In this paper, we propose a novel GAN to control the latent semantic representation, called LSC-GAN, which allows us to produce desired data to generate and learns a representation of the data efficiently. Unlike the conventional GAN models with hidden distribution of latent space, we define the distributions explicitly in advance that are trained to generate the data based on the corresponding features by inputting the latent variables that follow the distribution. As the larger scale of latent space caused by deploying various distributions in one latent space makes training unstable while maintaining the dimension of latent space, we need to separate the process of defining the distributions explicitly and operation of generation. We prove that a VAE is proper for the former and modify a loss function of VAE to map the data into the pre-defined latent space so as to locate the reconstructed data as close to the input data according to its characteristics. Moreover, we add the KL divergence to the loss function of LSC-GAN to include this process. The decoder of VAE, which generates the data with the corresponding features from the pre-defined latent space, is used as the generator of the LSC-GAN. Several experiments on the CelebA dataset are conducted to verify the usefulness of the proposed method to generate desired data stably and efficiently, achieving a high compression ratio that can hold about 24 pixels of information in each dimension of latent space. Besides, our model learns the reverse of features such as not laughing (rather frowning) only with data of ordinary and smiling facial expression.", "keywords": ["Latent space", "Generative adversarial network", "variational autoencoder", "conditioned generation"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "authors": ["Jin-Young Kim", "Sung-Bae Cho"], "TL;DR": "We propose a generative model that not only produces data with desired features from the pre-defined latent space but also fully understands the features of the data to create characteristics that are not in the dataset.", "pdf": "/pdf/35c7239a229fd9030f0d906a93428001abde9917.pdf", "paperhash": "kim|learning_latent_semantic_representation_from_predefined_generative_model", "_bibtex": "@misc{\nkim2019learning,\ntitle={Learning Latent Semantic Representation from Pre-defined Generative Model},\nauthor={Jin-Young Kim and Sung-Bae Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=Hyg1Ls0cKQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "BygW9T-XlN", "original": null, "number": 1, "cdate": 1544916360575, "ddate": null, "tcdate": 1544916360575, "tmdate": 1545354492129, "tddate": null, "forum": "Hyg1Ls0cKQ", "replyto": "Hyg1Ls0cKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper140/Meta_Review", "content": {"metareview": "Reviewers have expressed concerns about clarity/writing of the paper and technical novelty, which the authors haven't responded to. The paper is not suitable for publication at ICLR.", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "Concerns about clarity and writing of the paper"}, "signatures": ["ICLR.cc/2019/Conference/Paper140/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper140/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Latent Semantic Representation from Pre-defined Generative Model", "abstract": "Learning representations of data is an important issue in machine learning. Though GAN has led to significant improvements in the data representations, it still has several problems such as unstable training, hidden manifold of data, and huge computational overhead. GAN tends to produce the data simply without any information about the manifold of the data, which hinders from controlling desired features to generate. Moreover, most of GAN\u2019s have a large size of manifold, resulting in poor scalability. In this paper, we propose a novel GAN to control the latent semantic representation, called LSC-GAN, which allows us to produce desired data to generate and learns a representation of the data efficiently. Unlike the conventional GAN models with hidden distribution of latent space, we define the distributions explicitly in advance that are trained to generate the data based on the corresponding features by inputting the latent variables that follow the distribution. As the larger scale of latent space caused by deploying various distributions in one latent space makes training unstable while maintaining the dimension of latent space, we need to separate the process of defining the distributions explicitly and operation of generation. We prove that a VAE is proper for the former and modify a loss function of VAE to map the data into the pre-defined latent space so as to locate the reconstructed data as close to the input data according to its characteristics. Moreover, we add the KL divergence to the loss function of LSC-GAN to include this process. The decoder of VAE, which generates the data with the corresponding features from the pre-defined latent space, is used as the generator of the LSC-GAN. Several experiments on the CelebA dataset are conducted to verify the usefulness of the proposed method to generate desired data stably and efficiently, achieving a high compression ratio that can hold about 24 pixels of information in each dimension of latent space. Besides, our model learns the reverse of features such as not laughing (rather frowning) only with data of ordinary and smiling facial expression.", "keywords": ["Latent space", "Generative adversarial network", "variational autoencoder", "conditioned generation"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "authors": ["Jin-Young Kim", "Sung-Bae Cho"], "TL;DR": "We propose a generative model that not only produces data with desired features from the pre-defined latent space but also fully understands the features of the data to create characteristics that are not in the dataset.", "pdf": "/pdf/35c7239a229fd9030f0d906a93428001abde9917.pdf", "paperhash": "kim|learning_latent_semantic_representation_from_predefined_generative_model", "_bibtex": "@misc{\nkim2019learning,\ntitle={Learning Latent Semantic Representation from Pre-defined Generative Model},\nauthor={Jin-Young Kim and Sung-Bae Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=Hyg1Ls0cKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper140/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353323886, "tddate": null, "super": null, "final": null, "reply": {"forum": "Hyg1Ls0cKQ", "replyto": "Hyg1Ls0cKQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper140/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper140/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper140/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353323886}}}, {"id": "ryl2cEYo37", "original": null, "number": 3, "cdate": 1541276819908, "ddate": null, "tcdate": 1541276819908, "tmdate": 1541534249085, "tddate": null, "forum": "Hyg1Ls0cKQ", "replyto": "Hyg1Ls0cKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper140/Official_Review", "content": {"title": "I think it's an interesting approach to an interesting problem.  I am not familiar with other SOTA results, but visually the results are not that compelling. The explanation of the method should be clarified.", "review": "* Pros\n- addresses an interesting problem\n- gives a nice approach to the problem\n- attempts to give some theoretical justification for the approach\n\n* Cons\n- I generally understand the approach, but details were not clear to me (specifics given below)\n- Sections 3.2.1 and 3.2.2 (the theoretical section), I found particuarly hard to follow.\n- The visual results are not particularly compelling, tbhough I suppose the panel liked them better than the competitor methods (Table 1).  For example \"inverse pale skin\" and \"pale skin\" in figure 5 do not convince me that the model understands skin. The skin and background seem to be changing colors together.  Might be worth including examples of the competitor approaches to show that they are even worse.\n\n* Comments and Questions\n- Throughout, you seem to assume binary-valued features, without ever explicitly stating this.  Would be helpful to state explicitly.\n- Would be useful to specify the codomain of the discriminator D(x) -- from the objective function, seems to be a value in (0,1).\n- In Section 3.2, you say: \"Besides, we add the encoder for LSC-VAE into LSC-GAN to make sure that the generated data actually have the desired features.  The encoder projects back to latent space so as to be trained to minimize the difference between latent space where data is generated and the space where the compressed data is projected.\"  This seems like a fundamental change to training, much more than just initializing a GAN with a VAE-GAN. I think this should be elaborated on.  For example, what happens if you don't include the term with the encoder in (5).  Moreover, what goes wrong if you just try to train everything jointly using (5) without the VAE-GAN initialization step?\n- I have a very difficult time understanding 3.2.1, both the text and the equations.  e.g. what are the z_i's in (8)?  In 3.2.1, you say \"we pre-train G with the decoder of LSC-VAE\" -- this \"pretraining\" is what you refer to as initialization previously, I think?  Which seems also what section 3.1 is about?\n- I think some clarification would be nice in Section 3.2.2.  The conclusion of the section is that the \"proposed learning process is valid and efficient.\"       What do you mean by \"valid\" and \"efficient\"?  Perhaps you can explain that a bit more in words at the beginning of the section.  It's not entirely clear where your theory section connects to the objective function in (5). I don't really follow your argument for LSC_VAE being a good initializer in this section. In what sense is theorem 2 demonstrating \"efficiency\"?  \n- In Theorem 1, you write p_data \\approx p_G.  I guess p_data is some unknown data generating distribution, rather than the empirical distribution of a training set?   I've also never seen \\approx 0 used in formal mathematical statements and proofs especially when we're talking about \\approx 0 at infinitely many points.  Can this be elaborated on?  \n- In the end of section 3 intro paragraph you say \"The decoder of LSC-VAE is used in the generator (G) of LSC-GAN in the second phase.\" By \"used\" do you mean used as the initialization of the generator G, when we switch to the LSC_GAN training?  Seems like it, but could be made more clear.\n- In Section 3, second paragraph, you say \"In the first phase, LSC-VAE is trained to project data into a specific location of latent space according to its features\".  It's not clear whether or not this \"projection step\" (which I guess is also called encoding step or the inference step depending on the context?) uses the explicit feature values in this step, or can only use the input (e.g. the image).  I really have the same question for the decoder/generator: does it explicitly use the feature values, or does it depend only on the latent variables?  My guess is that in both cases the feature values are not depended on directly, but I think this could be made more clear, one way or the other.\n- how did results vary when you deviate from using 20 latent dimension per feature?\n- You say \"As shown in Fig. 4, the change between images is natural so that we can say that the latent space of LSC-GAN is a manifold.\" --- maybe a linear manifold?\n- Footnote 2 on page 4: This is confusing.  You are [basically arbitrarily] defining the conditional distribution on the latent space for any feature setting.  How can any particular distribution be \"correct\".\n- In the equations in (5), you're taking expectations over z_i, but don't you need to have an expectation over i (the feature assigments) as well?  Do you use the same feature distributions as you have in the training data?  Should be clarified.\n- Also, in (5), the expectation over z_i applies to the first term, as well as the z_i in G(z_i) in the second KL divergence term, right?  \n- In VAE the encoder typically produces the parameters of the Q distribution on the latent space.  What distribution does Q have and how are you parameterizing it?  Indendent Gaussians on each coordinate, each with its own mean and standard deviation?  or what? If you are allowing the encoder to take the feature values as input (which I don't think you are, but am not entirely sure of), does the encoder have to learn the means for each feature setting, or are you explicitly building those feature-based offsets into the encoder?\n", "rating": "5: Marginally below acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2019/Conference/Paper140/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Latent Semantic Representation from Pre-defined Generative Model", "abstract": "Learning representations of data is an important issue in machine learning. Though GAN has led to significant improvements in the data representations, it still has several problems such as unstable training, hidden manifold of data, and huge computational overhead. GAN tends to produce the data simply without any information about the manifold of the data, which hinders from controlling desired features to generate. Moreover, most of GAN\u2019s have a large size of manifold, resulting in poor scalability. In this paper, we propose a novel GAN to control the latent semantic representation, called LSC-GAN, which allows us to produce desired data to generate and learns a representation of the data efficiently. Unlike the conventional GAN models with hidden distribution of latent space, we define the distributions explicitly in advance that are trained to generate the data based on the corresponding features by inputting the latent variables that follow the distribution. As the larger scale of latent space caused by deploying various distributions in one latent space makes training unstable while maintaining the dimension of latent space, we need to separate the process of defining the distributions explicitly and operation of generation. We prove that a VAE is proper for the former and modify a loss function of VAE to map the data into the pre-defined latent space so as to locate the reconstructed data as close to the input data according to its characteristics. Moreover, we add the KL divergence to the loss function of LSC-GAN to include this process. The decoder of VAE, which generates the data with the corresponding features from the pre-defined latent space, is used as the generator of the LSC-GAN. Several experiments on the CelebA dataset are conducted to verify the usefulness of the proposed method to generate desired data stably and efficiently, achieving a high compression ratio that can hold about 24 pixels of information in each dimension of latent space. Besides, our model learns the reverse of features such as not laughing (rather frowning) only with data of ordinary and smiling facial expression.", "keywords": ["Latent space", "Generative adversarial network", "variational autoencoder", "conditioned generation"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "authors": ["Jin-Young Kim", "Sung-Bae Cho"], "TL;DR": "We propose a generative model that not only produces data with desired features from the pre-defined latent space but also fully understands the features of the data to create characteristics that are not in the dataset.", "pdf": "/pdf/35c7239a229fd9030f0d906a93428001abde9917.pdf", "paperhash": "kim|learning_latent_semantic_representation_from_predefined_generative_model", "_bibtex": "@misc{\nkim2019learning,\ntitle={Learning Latent Semantic Representation from Pre-defined Generative Model},\nauthor={Jin-Young Kim and Sung-Bae Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=Hyg1Ls0cKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper140/Official_Review", "cdate": 1542234529403, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "Hyg1Ls0cKQ", "replyto": "Hyg1Ls0cKQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper140/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335657680, "tmdate": 1552335657680, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper140/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "B1ebp4G527", "original": null, "number": 2, "cdate": 1541182649498, "ddate": null, "tcdate": 1541182649498, "tmdate": 1541534248848, "tddate": null, "forum": "Hyg1Ls0cKQ", "replyto": "Hyg1Ls0cKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper140/Official_Review", "content": {"title": "Poorly written draft with minimal technical novelty", "review": "The paper proposes a generative model that combines VAE and GAN. The main idea of the paper is to replace the standard normal distribution used in VAE with a normal distribution centered at a feature representation of the input image. In other words, the prior distribution is data adaptive. The paper compares the proposed generative model to DCGAN and EBGAN for image generation quality using the CelebA dataset and reports better human preference score.\n\nOverall, the paper is poorly written with incorrect technical descriptions and vague expositions.  The two baselines (DCGAN and EBGAN) are also quite out-dated. Beating these two baselines are insignificant, particularly there are GAN methods that  can generate high quality images without an encoder. For example, the Progressive GAN by Terro et. al. (ICLR 2018), SNGAN by Miyato et. al.(ICLR 2018), and GAN with zero-center gradient penalty by Mescheder et. al. (ICML 2018). The paper also fails to give a literature overview of effort in combining VAE and GAN. For example, Zhiting et. al. ICLR 2018 and Liu et. al. NIPS 2017.\n\nTechnical errors\n\n- In the related works section, the paper states that VAEs and GANs are both based on maximum likelihood. This statement is incorrect as GANs are based on distribution matching. \n\nVague exposition\n\n- In Section 2, the paper states that \"Larsen et al. (2015) used both VAE and GAN in one generative model. As they just mixed two models and did not analyzed a latent space, so that the manifold of data was hidden to us.\" Isn't the data manifold in this case a multivariate Gaussian distribution. The paper fails to explain what it means by the sentence.\n\n- In Section 3.1, the paper states that \"Since any supervision is not in training process, the manifold constructed is hidden to us.\" Again, the reviewer fails to understand what the paper means.\n\n- In Section 3.2.1, the paper states that \"it is not efficient to pre-train the G , because it depends on the parameters of the D.\" This sentence is confusing. Isn't pretraining just meaning using a pretrained decoder weight to initialize G?\n\n\n\n\n\n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper140/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Latent Semantic Representation from Pre-defined Generative Model", "abstract": "Learning representations of data is an important issue in machine learning. Though GAN has led to significant improvements in the data representations, it still has several problems such as unstable training, hidden manifold of data, and huge computational overhead. GAN tends to produce the data simply without any information about the manifold of the data, which hinders from controlling desired features to generate. Moreover, most of GAN\u2019s have a large size of manifold, resulting in poor scalability. In this paper, we propose a novel GAN to control the latent semantic representation, called LSC-GAN, which allows us to produce desired data to generate and learns a representation of the data efficiently. Unlike the conventional GAN models with hidden distribution of latent space, we define the distributions explicitly in advance that are trained to generate the data based on the corresponding features by inputting the latent variables that follow the distribution. As the larger scale of latent space caused by deploying various distributions in one latent space makes training unstable while maintaining the dimension of latent space, we need to separate the process of defining the distributions explicitly and operation of generation. We prove that a VAE is proper for the former and modify a loss function of VAE to map the data into the pre-defined latent space so as to locate the reconstructed data as close to the input data according to its characteristics. Moreover, we add the KL divergence to the loss function of LSC-GAN to include this process. The decoder of VAE, which generates the data with the corresponding features from the pre-defined latent space, is used as the generator of the LSC-GAN. Several experiments on the CelebA dataset are conducted to verify the usefulness of the proposed method to generate desired data stably and efficiently, achieving a high compression ratio that can hold about 24 pixels of information in each dimension of latent space. Besides, our model learns the reverse of features such as not laughing (rather frowning) only with data of ordinary and smiling facial expression.", "keywords": ["Latent space", "Generative adversarial network", "variational autoencoder", "conditioned generation"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "authors": ["Jin-Young Kim", "Sung-Bae Cho"], "TL;DR": "We propose a generative model that not only produces data with desired features from the pre-defined latent space but also fully understands the features of the data to create characteristics that are not in the dataset.", "pdf": "/pdf/35c7239a229fd9030f0d906a93428001abde9917.pdf", "paperhash": "kim|learning_latent_semantic_representation_from_predefined_generative_model", "_bibtex": "@misc{\nkim2019learning,\ntitle={Learning Latent Semantic Representation from Pre-defined Generative Model},\nauthor={Jin-Young Kim and Sung-Bae Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=Hyg1Ls0cKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper140/Official_Review", "cdate": 1542234529403, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "Hyg1Ls0cKQ", "replyto": "Hyg1Ls0cKQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper140/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335657680, "tmdate": 1552335657680, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper140/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HyxqHRUt2Q", "original": null, "number": 1, "cdate": 1541135938366, "ddate": null, "tcdate": 1541135938366, "tmdate": 1541534248649, "tddate": null, "forum": "Hyg1Ls0cKQ", "replyto": "Hyg1Ls0cKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper140/Official_Review", "content": {"title": "Really confusing", "review": "This paper proposes to learn a manifold of deep generative models using a pre-trained VAE. To generate samples with desired features, this paper proposes to learn an embedding of each feature in the hidden space using VAE. Then the learned hidden space is used to train a GAN.\n\nHowever, the method in this paper and main contributions are not clearly represented. I can hardly understand the motivation of this paper. In the introduction part, this paper mentions \u201clarge scale of latent space\u201d lots of times, but does not make it clear that why a large latent space hinders the deep generative models. In Fig.1, it demonstrates that for some manifold, L2 distance cannot be applied directly. However, for most DGMs, the hidden space is defined in Euclid Space, and L2 distance is a valid distance for them. \n\nIn Sec. 3, the method is not presented clearly and the notation is confusing. In Sec. 3.2.1, Eqn (8) is not an objective function and it is confusing how to optimize the generator using it. In Sec. 3.2.2, the notation is really confusing and I can hardly understand the proof the Theorem 2.\n\nThe experimental results are not solid where no well-known metrics, such as Inception Score, FID, are used to evaluate the generated samples. For compression rate, the size of bottleneck has not been mentioned above, and the experimental setting of each baseline is not ignored which makes the experimental results incomparable.\n\nOverall, this paper is not a qualified paper for ICLR.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper140/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning Latent Semantic Representation from Pre-defined Generative Model", "abstract": "Learning representations of data is an important issue in machine learning. Though GAN has led to significant improvements in the data representations, it still has several problems such as unstable training, hidden manifold of data, and huge computational overhead. GAN tends to produce the data simply without any information about the manifold of the data, which hinders from controlling desired features to generate. Moreover, most of GAN\u2019s have a large size of manifold, resulting in poor scalability. In this paper, we propose a novel GAN to control the latent semantic representation, called LSC-GAN, which allows us to produce desired data to generate and learns a representation of the data efficiently. Unlike the conventional GAN models with hidden distribution of latent space, we define the distributions explicitly in advance that are trained to generate the data based on the corresponding features by inputting the latent variables that follow the distribution. As the larger scale of latent space caused by deploying various distributions in one latent space makes training unstable while maintaining the dimension of latent space, we need to separate the process of defining the distributions explicitly and operation of generation. We prove that a VAE is proper for the former and modify a loss function of VAE to map the data into the pre-defined latent space so as to locate the reconstructed data as close to the input data according to its characteristics. Moreover, we add the KL divergence to the loss function of LSC-GAN to include this process. The decoder of VAE, which generates the data with the corresponding features from the pre-defined latent space, is used as the generator of the LSC-GAN. Several experiments on the CelebA dataset are conducted to verify the usefulness of the proposed method to generate desired data stably and efficiently, achieving a high compression ratio that can hold about 24 pixels of information in each dimension of latent space. Besides, our model learns the reverse of features such as not laughing (rather frowning) only with data of ordinary and smiling facial expression.", "keywords": ["Latent space", "Generative adversarial network", "variational autoencoder", "conditioned generation"], "authorids": ["seago0828@yonsei.ac.kr", "sbcho@yonsei.ac.kr"], "authors": ["Jin-Young Kim", "Sung-Bae Cho"], "TL;DR": "We propose a generative model that not only produces data with desired features from the pre-defined latent space but also fully understands the features of the data to create characteristics that are not in the dataset.", "pdf": "/pdf/35c7239a229fd9030f0d906a93428001abde9917.pdf", "paperhash": "kim|learning_latent_semantic_representation_from_predefined_generative_model", "_bibtex": "@misc{\nkim2019learning,\ntitle={Learning Latent Semantic Representation from Pre-defined Generative Model},\nauthor={Jin-Young Kim and Sung-Bae Cho},\nyear={2019},\nurl={https://openreview.net/forum?id=Hyg1Ls0cKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper140/Official_Review", "cdate": 1542234529403, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "Hyg1Ls0cKQ", "replyto": "Hyg1Ls0cKQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper140/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335657680, "tmdate": 1552335657680, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper140/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 5}