{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124469706, "tcdate": 1518457921137, "number": 180, "cdate": 1518457921137, "id": "BytSNIyvM", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "BytSNIyvM", "signatures": ["~Ivan_Lobov1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "SpectralWords: Spectral Embeddings Approach to Word Similarity Task for Large Vocabularies", "abstract": "In this paper we show how recent advances in spectral clustering using Bethe Hessian operator can be used to learn dense word representations. We propose an algorithm SpectralWords that achieves comparable to the state-of-the-art performance on word similarity tasks for medium-size vocabularies and can be superior for datasets with larger vocabularies.", "paperhash": "lobov|spectralwords_spectral_embeddings_approach_to_word_similarity_task_for_large_vocabularies", "keywords": ["spectral clustering", "distributed representation", "embeddings", "word similarities"], "_bibtex": "@misc{\n  lobov2018spectralwords:,\n  title={SpectralWords: Spectral Embeddings Approach to Word Similarity Task for Large Vocabularies},\n  author={Ivan Lobov},\n  year={2018},\n  url={https://openreview.net/forum?id=BytSNIyvM}\n}", "authorids": ["i.lobov@criteo.com"], "authors": ["Ivan Lobov"], "TL;DR": "Beating Skip-gram and SVD (on PPMI) on word similarity tasks with large vocabularies by using spectral-based approach.", "pdf": "/pdf/fcc927a48b79cea970b17feefc9664b6dd88466d.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582979369, "tcdate": 1519839686968, "number": 1, "cdate": 1519839686968, "id": "HJ1RtDVuf", "invitation": "ICLR.cc/2018/Workshop/-/Paper180/Official_Review", "forum": "BytSNIyvM", "replyto": "BytSNIyvM", "signatures": ["ICLR.cc/2018/Workshop/Paper180/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper180/AnonReviewer1"], "content": {"title": "Nice insight, method and results", "rating": "7: Good paper, accept", "review": "This work provides a novel approach to inducing semantic similarity from co-occurrence matrices (harvested from text corpora). The method is based on a recent improved spectral clustering algorithm. \n\nPros\n- The paper is very well written\n- The method is clearly explained\n- The choice of experiments and comparisons is good for understanding the differences between other approaches\n\nCons\n- The high-level intuition (if there is one) behind the spectral technique (and why it improves similarity) is not made clear.\n- It is not clear whether code is made available for this method (highly recommended), or how easy it is to apply.\n\n ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SpectralWords: Spectral Embeddings Approach to Word Similarity Task for Large Vocabularies", "abstract": "In this paper we show how recent advances in spectral clustering using Bethe Hessian operator can be used to learn dense word representations. We propose an algorithm SpectralWords that achieves comparable to the state-of-the-art performance on word similarity tasks for medium-size vocabularies and can be superior for datasets with larger vocabularies.", "paperhash": "lobov|spectralwords_spectral_embeddings_approach_to_word_similarity_task_for_large_vocabularies", "keywords": ["spectral clustering", "distributed representation", "embeddings", "word similarities"], "_bibtex": "@misc{\n  lobov2018spectralwords:,\n  title={SpectralWords: Spectral Embeddings Approach to Word Similarity Task for Large Vocabularies},\n  author={Ivan Lobov},\n  year={2018},\n  url={https://openreview.net/forum?id=BytSNIyvM}\n}", "authorids": ["i.lobov@criteo.com"], "authors": ["Ivan Lobov"], "TL;DR": "Beating Skip-gram and SVD (on PPMI) on word similarity tasks with large vocabularies by using spectral-based approach.", "pdf": "/pdf/fcc927a48b79cea970b17feefc9664b6dd88466d.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582979175, "id": "ICLR.cc/2018/Workshop/-/Paper180/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper180/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper180/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper180/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper180/AnonReviewer2"], "reply": {"forum": "BytSNIyvM", "replyto": "BytSNIyvM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper180/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper180/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582979175}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582921330, "tcdate": 1520370706466, "number": 2, "cdate": 1520370706466, "id": "S15MVFhdM", "invitation": "ICLR.cc/2018/Workshop/-/Paper180/Official_Review", "forum": "BytSNIyvM", "replyto": "BytSNIyvM", "signatures": ["ICLR.cc/2018/Workshop/Paper180/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper180/AnonReviewer3"], "content": {"title": "application of Bethe Hessian to learning word embeddings", "rating": "5: Marginally below acceptance threshold", "review": "The paper applies the Bethe Hessian (Saade et al., 2014) to learning word embededings. The technique is interesting and has connections to the non-backtracking walk on the graph, but it is not the contribution of the paper. The paper designs a way to use the Bethe Hessian operator very similar to many co-occurrence factorization methods.\n\nWhile the technique is shown to produce competitive performance on word similiarity tasks, this result, unfortunately, has few practical implications as there is a plethora of word embeddings techniques that can be used to achieve the same level of performance (some easier to use than others). \n\nPerhaps the work may benefit from focusing on the technique aspects of the approach, for instance analyzing the properties of the method. One missing reference that is closely relavant to the work is the long line of spectral word embedding methods using canonical correlation analysis: for example, see Stratos et al. (2015, 2014) and Dhillon et al. (2011). ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SpectralWords: Spectral Embeddings Approach to Word Similarity Task for Large Vocabularies", "abstract": "In this paper we show how recent advances in spectral clustering using Bethe Hessian operator can be used to learn dense word representations. We propose an algorithm SpectralWords that achieves comparable to the state-of-the-art performance on word similarity tasks for medium-size vocabularies and can be superior for datasets with larger vocabularies.", "paperhash": "lobov|spectralwords_spectral_embeddings_approach_to_word_similarity_task_for_large_vocabularies", "keywords": ["spectral clustering", "distributed representation", "embeddings", "word similarities"], "_bibtex": "@misc{\n  lobov2018spectralwords:,\n  title={SpectralWords: Spectral Embeddings Approach to Word Similarity Task for Large Vocabularies},\n  author={Ivan Lobov},\n  year={2018},\n  url={https://openreview.net/forum?id=BytSNIyvM}\n}", "authorids": ["i.lobov@criteo.com"], "authors": ["Ivan Lobov"], "TL;DR": "Beating Skip-gram and SVD (on PPMI) on word similarity tasks with large vocabularies by using spectral-based approach.", "pdf": "/pdf/fcc927a48b79cea970b17feefc9664b6dd88466d.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582979175, "id": "ICLR.cc/2018/Workshop/-/Paper180/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper180/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper180/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper180/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper180/AnonReviewer2"], "reply": {"forum": "BytSNIyvM", "replyto": "BytSNIyvM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper180/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper180/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582979175}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582703965, "tcdate": 1520697020457, "number": 3, "cdate": 1520697020457, "id": "HkVT0_WYf", "invitation": "ICLR.cc/2018/Workshop/-/Paper180/Official_Review", "forum": "BytSNIyvM", "replyto": "BytSNIyvM", "signatures": ["ICLR.cc/2018/Workshop/Paper180/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper180/AnonReviewer2"], "content": {"title": "Well written and ", "rating": "8: Top 50% of accepted papers, clear accept", "review": "In the present paper, the authors extend a spectral method for clustering  to learn dense word representations, an algorithm they name SpectralWords. They show, through extensive experiments, that their approach achieves comparable or superior to the state-of-the-art performance.\n\nThis short paper looks like is a straightforward accept yo me: the method is interesting, it uses an innovative approach, and has good performance on data sets. The paper is short, yet well written and the litterature is well covered.\n\n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SpectralWords: Spectral Embeddings Approach to Word Similarity Task for Large Vocabularies", "abstract": "In this paper we show how recent advances in spectral clustering using Bethe Hessian operator can be used to learn dense word representations. We propose an algorithm SpectralWords that achieves comparable to the state-of-the-art performance on word similarity tasks for medium-size vocabularies and can be superior for datasets with larger vocabularies.", "paperhash": "lobov|spectralwords_spectral_embeddings_approach_to_word_similarity_task_for_large_vocabularies", "keywords": ["spectral clustering", "distributed representation", "embeddings", "word similarities"], "_bibtex": "@misc{\n  lobov2018spectralwords:,\n  title={SpectralWords: Spectral Embeddings Approach to Word Similarity Task for Large Vocabularies},\n  author={Ivan Lobov},\n  year={2018},\n  url={https://openreview.net/forum?id=BytSNIyvM}\n}", "authorids": ["i.lobov@criteo.com"], "authors": ["Ivan Lobov"], "TL;DR": "Beating Skip-gram and SVD (on PPMI) on word similarity tasks with large vocabularies by using spectral-based approach.", "pdf": "/pdf/fcc927a48b79cea970b17feefc9664b6dd88466d.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582979175, "id": "ICLR.cc/2018/Workshop/-/Paper180/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper180/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper180/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper180/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper180/AnonReviewer2"], "reply": {"forum": "BytSNIyvM", "replyto": "BytSNIyvM", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper180/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper180/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582979175}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573556520, "tcdate": 1521573556520, "number": 59, "cdate": 1521573556177, "id": "By3200RFf", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "BytSNIyvM", "replyto": "BytSNIyvM", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "SpectralWords: Spectral Embeddings Approach to Word Similarity Task for Large Vocabularies", "abstract": "In this paper we show how recent advances in spectral clustering using Bethe Hessian operator can be used to learn dense word representations. We propose an algorithm SpectralWords that achieves comparable to the state-of-the-art performance on word similarity tasks for medium-size vocabularies and can be superior for datasets with larger vocabularies.", "paperhash": "lobov|spectralwords_spectral_embeddings_approach_to_word_similarity_task_for_large_vocabularies", "keywords": ["spectral clustering", "distributed representation", "embeddings", "word similarities"], "_bibtex": "@misc{\n  lobov2018spectralwords:,\n  title={SpectralWords: Spectral Embeddings Approach to Word Similarity Task for Large Vocabularies},\n  author={Ivan Lobov},\n  year={2018},\n  url={https://openreview.net/forum?id=BytSNIyvM}\n}", "authorids": ["i.lobov@criteo.com"], "authors": ["Ivan Lobov"], "TL;DR": "Beating Skip-gram and SVD (on PPMI) on word similarity tasks with large vocabularies by using spectral-based approach.", "pdf": "/pdf/fcc927a48b79cea970b17feefc9664b6dd88466d.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}