{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124294528, "tcdate": 1518047772534, "number": 33, "cdate": 1518047772534, "id": "rJEXGGKLf", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "rJEXGGKLf", "signatures": ["~Ryan_Szeto1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "A Dataset To Evaluate The Representations Learned By Video Prediction Models", "abstract": "We present a parameterized synthetic dataset called Moving Symbols to support the objective study of video prediction networks. Using several instantiations of the dataset in which variation is explicitly controlled, we highlight issues in an existing state-of-the-art approach and propose the use of a performance metric with greater semantic meaning to improve experimental interpretability. Our dataset provides canonical test cases that will help the community better understand, and eventually improve, the representations learned by such networks in the future. Code is available at https://github.com/rszeto/moving-symbols.", "paperhash": "szeto|a_dataset_to_evaluate_the_representations_learned_by_video_prediction_models", "keywords": ["video prediction", "self-supervised learning", "dataset", "model interpretability"], "_bibtex": "@misc{\n  szeto2018a,\n  title={A Dataset To Evaluate The Representations Learned By Video Prediction Models},\n  author={Ryan Szeto and Simon Stent and German Ros and Jason J. Corso},\n  year={2018},\n  url={https://openreview.net/forum?id=rJEXGGKLf}\n}", "authorids": ["szetor@umich.edu", "simon.stent@tri.global", "german.ros@tri.global", "jjcorso@umich.edu"], "authors": ["Ryan Szeto", "Simon Stent", "German Ros", "Jason J. Corso"], "TL;DR": "We propose a new dataset to better understand the shortcomings of existing video prediction networks.", "pdf": "/pdf/c3e3234cc81a0132d7ca53abd6810412bbb2f2e8.pdf"}, "nonreaders": [], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "tmdate": 1522359151348, "tcdate": 1522359008297, "number": 1, "cdate": 1522359008297, "id": "H1u1sR55f", "invitation": "ICLR.cc/2018/Workshop/-/Paper33/Official_Comment", "forum": "rJEXGGKLf", "replyto": "rJFsIcjtM", "signatures": ["ICLR.cc/2018/Workshop/Paper33/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper33/Authors"], "content": {"title": "Authors' Response to AnonReviewer1", "comment": "Thank you for your comments. We appreciate that you have considered our method to be better suited for evaluating the generalization capabilities of video prediction algorithms than prior work. Please find our responses to your comments below.\n\n1. Regarding the \"comparison-friendly\" dataset hyperparameters, we note that the parameters used to generate the data for our experiments are included in our GitHub code. If the dataset is adopted by other researchers, we encourage them to submit pull requests for their own parameter configurations so that other authors can make direct comparisons.\n\n2. With regard to varying the scale of symbols over time, this is a feature supported in our code; however, we omitted our experiments on this behavior due to space constraints.\n\n3. \"To make this even more general, other geometric transformations can be considered\u2026\": We agree that supporting other geometric transformations would further improve our understanding; skewing and distorted symbols can be incorporated in future work. As the goal of our dataset is to evaluate the extent to which video prediction models capture the underlying content- and motion-defining parameters that are shared between a training set and a held-out set, adding any visual transformation that exists within that other dataset would be justified."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Dataset To Evaluate The Representations Learned By Video Prediction Models", "abstract": "We present a parameterized synthetic dataset called Moving Symbols to support the objective study of video prediction networks. Using several instantiations of the dataset in which variation is explicitly controlled, we highlight issues in an existing state-of-the-art approach and propose the use of a performance metric with greater semantic meaning to improve experimental interpretability. Our dataset provides canonical test cases that will help the community better understand, and eventually improve, the representations learned by such networks in the future. Code is available at https://github.com/rszeto/moving-symbols.", "paperhash": "szeto|a_dataset_to_evaluate_the_representations_learned_by_video_prediction_models", "keywords": ["video prediction", "self-supervised learning", "dataset", "model interpretability"], "_bibtex": "@misc{\n  szeto2018a,\n  title={A Dataset To Evaluate The Representations Learned By Video Prediction Models},\n  author={Ryan Szeto and Simon Stent and German Ros and Jason J. Corso},\n  year={2018},\n  url={https://openreview.net/forum?id=rJEXGGKLf}\n}", "authorids": ["szetor@umich.edu", "simon.stent@tri.global", "german.ros@tri.global", "jjcorso@umich.edu"], "authors": ["Ryan Szeto", "Simon Stent", "German Ros", "Jason J. Corso"], "TL;DR": "We propose a new dataset to better understand the shortcomings of existing video prediction networks.", "pdf": "/pdf/c3e3234cc81a0132d7ca53abd6810412bbb2f2e8.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1519222450311, "id": "ICLR.cc/2018/Workshop/-/Paper33/Official_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "rJEXGGKLf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper33/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper33/Authors|ICLR.cc/2018/Workshop/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper33/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper33/Authors|ICLR.cc/2018/Workshop/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Workshop/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Workshop/Paper33/Reviewers", "ICLR.cc/2018/Workshop/Paper33/Authors", "ICLR.cc/2018/Workshop/Program_Chairs"], "cdate": 1519222450311}}, "tauthor": "szetor@umich.edu"}, {"tddate": null, "ddate": null, "tmdate": 1522359138581, "tcdate": 1522359138581, "number": 3, "cdate": 1522359138581, "id": "ByjDj0q5f", "invitation": "ICLR.cc/2018/Workshop/-/Paper33/Official_Comment", "forum": "rJEXGGKLf", "replyto": "ByMsgnh_G", "signatures": ["ICLR.cc/2018/Workshop/Paper33/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper33/Authors"], "content": {"title": "Authors' Response to AnonReviewer2", "comment": "Thank you for your comments. Addressing your concern with limiting our analysis to a single existing method, we focused our analysis on the best-performing video prediction method whose code is publicly available (to the best of our knowledge) due to space constraints. However, we agree that comparing several state-of-the-art models would strengthen our conclusions. We welcome authors of new video prediction models to evaluate and objectively compare the performance of their models on versions of our dataset with published parameters."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Dataset To Evaluate The Representations Learned By Video Prediction Models", "abstract": "We present a parameterized synthetic dataset called Moving Symbols to support the objective study of video prediction networks. Using several instantiations of the dataset in which variation is explicitly controlled, we highlight issues in an existing state-of-the-art approach and propose the use of a performance metric with greater semantic meaning to improve experimental interpretability. Our dataset provides canonical test cases that will help the community better understand, and eventually improve, the representations learned by such networks in the future. Code is available at https://github.com/rszeto/moving-symbols.", "paperhash": "szeto|a_dataset_to_evaluate_the_representations_learned_by_video_prediction_models", "keywords": ["video prediction", "self-supervised learning", "dataset", "model interpretability"], "_bibtex": "@misc{\n  szeto2018a,\n  title={A Dataset To Evaluate The Representations Learned By Video Prediction Models},\n  author={Ryan Szeto and Simon Stent and German Ros and Jason J. Corso},\n  year={2018},\n  url={https://openreview.net/forum?id=rJEXGGKLf}\n}", "authorids": ["szetor@umich.edu", "simon.stent@tri.global", "german.ros@tri.global", "jjcorso@umich.edu"], "authors": ["Ryan Szeto", "Simon Stent", "German Ros", "Jason J. Corso"], "TL;DR": "We propose a new dataset to better understand the shortcomings of existing video prediction networks.", "pdf": "/pdf/c3e3234cc81a0132d7ca53abd6810412bbb2f2e8.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1519222450311, "id": "ICLR.cc/2018/Workshop/-/Paper33/Official_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "rJEXGGKLf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper33/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper33/Authors|ICLR.cc/2018/Workshop/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper33/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper33/Authors|ICLR.cc/2018/Workshop/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Workshop/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Workshop/Paper33/Reviewers", "ICLR.cc/2018/Workshop/Paper33/Authors", "ICLR.cc/2018/Workshop/Program_Chairs"], "cdate": 1519222450311}}, "tauthor": "szetor@umich.edu"}, {"tddate": null, "ddate": null, "tmdate": 1522359108527, "tcdate": 1522359108527, "number": 2, "cdate": 1522359108527, "id": "rknHiA55z", "invitation": "ICLR.cc/2018/Workshop/-/Paper33/Official_Comment", "forum": "rJEXGGKLf", "replyto": "BJDpcfGYz", "signatures": ["ICLR.cc/2018/Workshop/Paper33/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper33/Authors"], "content": {"title": "Authors' Response to AnonReviewer3", "comment": "Thank you for your comments; we are happy that you find our dataset very valuable. Addressing your comment about justifying generalizability --- specifically that \"it is not clear that a learning algorithm or even the human brain can or should generalize to much novel motion profiles or appearances\" --- we agree but, as mentioned in the introduction, real-video datasets used for video prediction do exhibit (to varying extent) novel motion profiles or appearances between training and testing (e.g. training on a video of a professional baseball pitcher and testing on a video of an amateur pitcher in casual clothing). As our dataset allows researchers to control this domain gap, it is a step towards better quantification and understanding of the generalizability problem. It also allows us as a community to ask how we should modify existing learning algorithms to more efficiently adapt to unseen domains that they struggle to immediately generalize to."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Dataset To Evaluate The Representations Learned By Video Prediction Models", "abstract": "We present a parameterized synthetic dataset called Moving Symbols to support the objective study of video prediction networks. Using several instantiations of the dataset in which variation is explicitly controlled, we highlight issues in an existing state-of-the-art approach and propose the use of a performance metric with greater semantic meaning to improve experimental interpretability. Our dataset provides canonical test cases that will help the community better understand, and eventually improve, the representations learned by such networks in the future. Code is available at https://github.com/rszeto/moving-symbols.", "paperhash": "szeto|a_dataset_to_evaluate_the_representations_learned_by_video_prediction_models", "keywords": ["video prediction", "self-supervised learning", "dataset", "model interpretability"], "_bibtex": "@misc{\n  szeto2018a,\n  title={A Dataset To Evaluate The Representations Learned By Video Prediction Models},\n  author={Ryan Szeto and Simon Stent and German Ros and Jason J. Corso},\n  year={2018},\n  url={https://openreview.net/forum?id=rJEXGGKLf}\n}", "authorids": ["szetor@umich.edu", "simon.stent@tri.global", "german.ros@tri.global", "jjcorso@umich.edu"], "authors": ["Ryan Szeto", "Simon Stent", "German Ros", "Jason J. Corso"], "TL;DR": "We propose a new dataset to better understand the shortcomings of existing video prediction networks.", "pdf": "/pdf/c3e3234cc81a0132d7ca53abd6810412bbb2f2e8.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1519222450311, "id": "ICLR.cc/2018/Workshop/-/Paper33/Official_Comment", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "rJEXGGKLf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper33/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper33/Authors|ICLR.cc/2018/Workshop/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper33/AnonReviewer[0-9]+|ICLR.cc/2018/Workshop/Paper33/Authors|ICLR.cc/2018/Workshop/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Workshop/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Workshop/Paper33/Reviewers", "ICLR.cc/2018/Workshop/Paper33/Authors", "ICLR.cc/2018/Workshop/Program_Chairs"], "cdate": 1519222450311}}, "tauthor": "szetor@umich.edu"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582918474, "tcdate": 1520382106501, "number": 1, "cdate": 1520382106501, "id": "ByMsgnh_G", "invitation": "ICLR.cc/2018/Workshop/-/Paper33/Official_Review", "forum": "rJEXGGKLf", "replyto": "rJEXGGKLf", "signatures": ["ICLR.cc/2018/Workshop/Paper33/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper33/AnonReviewer2"], "content": {"title": "A  means to allow for systematic evaluation of video-based methods", "rating": "9: Top 15% of accepted papers, strong accept", "review": " \n==========================================\nSummary\n==========================================\n \nThe paper proposes Moving Symbols, a means to generate synthetic video datasets with the capability of controlling changes on apperance and motion of objects occurring in the video. The main goal of the proposed dataset is to allow systematic experimentation of video prediction methods.\n\n----------------\nNovelty\n----------------\n\nEven though the proposed dataset is an extension of the Moving MNIST dataset (Srivastava et al., ICML'15), its contribution increases the benchmarking capabilities of the dataset.\n\n----------------\nClarity\n----------------\n\nThe paper is clear and its content is easy to follow.\n\n----------------\nSignificance\n----------------\n\nThe proposed dataset is a timely addition to recent interest on video prediction.\nIn addition, it allows for the systematic evaluation of these methods.\n\n----------------\nQuality\n----------------\n\nThe manuscript displays good quality. Contributions are properly motivated, the evaluation protocol is clear and observations made on the evaluation are adequately discussed.\n\n\n==========================================\nPROs:\n- Clear and easy to follow.\n- Need of the proposed dataset is properly motivated.\n- Observations of the conducted experiments are adequately discussed.\n- Evaluation code is made available.\n\n\nCONS:\n- Even though the evaluation is appropriate, it is limited to a single existing method, i.e. MCNet (Villegas et al. ICLR'17).\n==========================================\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Dataset To Evaluate The Representations Learned By Video Prediction Models", "abstract": "We present a parameterized synthetic dataset called Moving Symbols to support the objective study of video prediction networks. Using several instantiations of the dataset in which variation is explicitly controlled, we highlight issues in an existing state-of-the-art approach and propose the use of a performance metric with greater semantic meaning to improve experimental interpretability. Our dataset provides canonical test cases that will help the community better understand, and eventually improve, the representations learned by such networks in the future. Code is available at https://github.com/rszeto/moving-symbols.", "paperhash": "szeto|a_dataset_to_evaluate_the_representations_learned_by_video_prediction_models", "keywords": ["video prediction", "self-supervised learning", "dataset", "model interpretability"], "_bibtex": "@misc{\n  szeto2018a,\n  title={A Dataset To Evaluate The Representations Learned By Video Prediction Models},\n  author={Ryan Szeto and Simon Stent and German Ros and Jason J. Corso},\n  year={2018},\n  url={https://openreview.net/forum?id=rJEXGGKLf}\n}", "authorids": ["szetor@umich.edu", "simon.stent@tri.global", "german.ros@tri.global", "jjcorso@umich.edu"], "authors": ["Ryan Szeto", "Simon Stent", "German Ros", "Jason J. Corso"], "TL;DR": "We propose a new dataset to better understand the shortcomings of existing video prediction networks.", "pdf": "/pdf/c3e3234cc81a0132d7ca53abd6810412bbb2f2e8.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582918257, "id": "ICLR.cc/2018/Workshop/-/Paper33/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper33/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper33/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper33/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper33/AnonReviewer1"], "reply": {"forum": "rJEXGGKLf", "replyto": "rJEXGGKLf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper33/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper33/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582918257}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582672094, "tcdate": 1520736958701, "number": 2, "cdate": 1520736958701, "id": "BJDpcfGYz", "invitation": "ICLR.cc/2018/Workshop/-/Paper33/Official_Review", "forum": "rJEXGGKLf", "replyto": "rJEXGGKLf", "signatures": ["ICLR.cc/2018/Workshop/Paper33/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper33/AnonReviewer3"], "content": {"title": "a dataset with controllable amount of train/test motion-content differences for video prediction ", "rating": "7: Good paper, accept", "review": "A dataset is introduced where appearance and motion statistics are varied in a controllable manner between train and test time, and various splits are proposed to test capabilities of current video prediction methods to generalize to novel motion or appearance profiles between train and test.\nThe dataset is tested on the model of Villegas et al 2017.\nThe conclusion is it does not generalize to novel content or motion profiles.\nThough controlling such train/test dissimilarity statistics seems like a great idea, it is not clear that a learning algorithm or even the human brain can or should generalize to much novel motion profiles or appearances. This though is a different discussion. i find the dataset very valuable for evaluation purposes.\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Dataset To Evaluate The Representations Learned By Video Prediction Models", "abstract": "We present a parameterized synthetic dataset called Moving Symbols to support the objective study of video prediction networks. Using several instantiations of the dataset in which variation is explicitly controlled, we highlight issues in an existing state-of-the-art approach and propose the use of a performance metric with greater semantic meaning to improve experimental interpretability. Our dataset provides canonical test cases that will help the community better understand, and eventually improve, the representations learned by such networks in the future. Code is available at https://github.com/rszeto/moving-symbols.", "paperhash": "szeto|a_dataset_to_evaluate_the_representations_learned_by_video_prediction_models", "keywords": ["video prediction", "self-supervised learning", "dataset", "model interpretability"], "_bibtex": "@misc{\n  szeto2018a,\n  title={A Dataset To Evaluate The Representations Learned By Video Prediction Models},\n  author={Ryan Szeto and Simon Stent and German Ros and Jason J. Corso},\n  year={2018},\n  url={https://openreview.net/forum?id=rJEXGGKLf}\n}", "authorids": ["szetor@umich.edu", "simon.stent@tri.global", "german.ros@tri.global", "jjcorso@umich.edu"], "authors": ["Ryan Szeto", "Simon Stent", "German Ros", "Jason J. Corso"], "TL;DR": "We propose a new dataset to better understand the shortcomings of existing video prediction networks.", "pdf": "/pdf/c3e3234cc81a0132d7ca53abd6810412bbb2f2e8.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582918257, "id": "ICLR.cc/2018/Workshop/-/Paper33/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper33/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper33/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper33/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper33/AnonReviewer1"], "reply": {"forum": "rJEXGGKLf", "replyto": "rJEXGGKLf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper33/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper33/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582918257}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582581670, "tcdate": 1521358496792, "number": 3, "cdate": 1521358496792, "id": "rJFsIcjtM", "invitation": "ICLR.cc/2018/Workshop/-/Paper33/Official_Review", "forum": "rJEXGGKLf", "replyto": "rJEXGGKLf", "signatures": ["ICLR.cc/2018/Workshop/Paper33/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper33/AnonReviewer1"], "content": {"title": "Review", "rating": "7: Good paper, accept", "review": "This paper proposes a new dataset, which can be seen as a variation (in spirit at least) of the Moving MNIST dataset (Srivastava et al., 2015). Specifically, instead of having the same data classes in both training and test set, the proposed dataset has different ones (e.g., MNIST like in training, Omniglot like in test). The reason is that by having the same \"semantic\" distributions in both training and test sets, it's harder to judge whether the semantics themselves influence the learning of dynamics of objects over time. What is more, different from Moving MNIST, where the  image source files and speed of dynamics are hard coded, in this  paper they are sampled on the fly.\n\nThe dataset is an interesting contribution, and there is not much to say to make it better. I would note that sampling on the fly is better to evaluate the generalization capabilities of the algorithms. However, at the same time it makes comparisons between different methods from different papers somewhat arbitrary. It would be good if the authors offered also \"comparison-friendly\" dataset hyperparameters, so that new papers can compare with previous methods on equal grounds. Another variation that could also be considered is the scale of symbols, e.g., their size can vary over time. To make this more general, other geometric transformations can be considered, such as skewing, or even symbol morphings? Of course, in the end each variation should serve a purpose, namely what type of dynamics are tested here?", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Dataset To Evaluate The Representations Learned By Video Prediction Models", "abstract": "We present a parameterized synthetic dataset called Moving Symbols to support the objective study of video prediction networks. Using several instantiations of the dataset in which variation is explicitly controlled, we highlight issues in an existing state-of-the-art approach and propose the use of a performance metric with greater semantic meaning to improve experimental interpretability. Our dataset provides canonical test cases that will help the community better understand, and eventually improve, the representations learned by such networks in the future. Code is available at https://github.com/rszeto/moving-symbols.", "paperhash": "szeto|a_dataset_to_evaluate_the_representations_learned_by_video_prediction_models", "keywords": ["video prediction", "self-supervised learning", "dataset", "model interpretability"], "_bibtex": "@misc{\n  szeto2018a,\n  title={A Dataset To Evaluate The Representations Learned By Video Prediction Models},\n  author={Ryan Szeto and Simon Stent and German Ros and Jason J. Corso},\n  year={2018},\n  url={https://openreview.net/forum?id=rJEXGGKLf}\n}", "authorids": ["szetor@umich.edu", "simon.stent@tri.global", "german.ros@tri.global", "jjcorso@umich.edu"], "authors": ["Ryan Szeto", "Simon Stent", "German Ros", "Jason J. Corso"], "TL;DR": "We propose a new dataset to better understand the shortcomings of existing video prediction networks.", "pdf": "/pdf/c3e3234cc81a0132d7ca53abd6810412bbb2f2e8.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582918257, "id": "ICLR.cc/2018/Workshop/-/Paper33/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper33/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper33/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper33/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper33/AnonReviewer1"], "reply": {"forum": "rJEXGGKLf", "replyto": "rJEXGGKLf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper33/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper33/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582918257}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573547189, "tcdate": 1521573547189, "number": 18, "cdate": 1521573546846, "id": "r1Q30ACtG", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "rJEXGGKLf", "replyto": "rJEXGGKLf", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Dataset To Evaluate The Representations Learned By Video Prediction Models", "abstract": "We present a parameterized synthetic dataset called Moving Symbols to support the objective study of video prediction networks. Using several instantiations of the dataset in which variation is explicitly controlled, we highlight issues in an existing state-of-the-art approach and propose the use of a performance metric with greater semantic meaning to improve experimental interpretability. Our dataset provides canonical test cases that will help the community better understand, and eventually improve, the representations learned by such networks in the future. Code is available at https://github.com/rszeto/moving-symbols.", "paperhash": "szeto|a_dataset_to_evaluate_the_representations_learned_by_video_prediction_models", "keywords": ["video prediction", "self-supervised learning", "dataset", "model interpretability"], "_bibtex": "@misc{\n  szeto2018a,\n  title={A Dataset To Evaluate The Representations Learned By Video Prediction Models},\n  author={Ryan Szeto and Simon Stent and German Ros and Jason J. Corso},\n  year={2018},\n  url={https://openreview.net/forum?id=rJEXGGKLf}\n}", "authorids": ["szetor@umich.edu", "simon.stent@tri.global", "german.ros@tri.global", "jjcorso@umich.edu"], "authors": ["Ryan Szeto", "Simon Stent", "German Ros", "Jason J. Corso"], "TL;DR": "We propose a new dataset to better understand the shortcomings of existing video prediction networks.", "pdf": "/pdf/c3e3234cc81a0132d7ca53abd6810412bbb2f2e8.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 8}