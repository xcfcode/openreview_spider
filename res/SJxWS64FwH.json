{"notes": [{"id": "SJxWS64FwH", "original": "rJlKKNHvPS", "number": 512, "cdate": 1569439032827, "ddate": null, "tcdate": 1569439032827, "tmdate": 1583912045010, "tddate": null, "forum": "SJxWS64FwH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["john.zarka@ens.fr", "louis.thiry@ens.fr", "tomas.angles@ens.fr", "stephane.mallat@ens.fr"], "title": "Deep Network Classification by Scattering and Homotopy Dictionary Learning", "authors": ["John Zarka", "Louis Thiry", "Tomas Angles", "Stephane Mallat"], "pdf": "/pdf/e6235a059a0929ea35206c487924a1f355bb8c7d.pdf", "TL;DR": "A scattering transform followed by supervised dictionary learning reaches a higher accuracy than AlexNet on ImageNet.", "abstract": "We introduce a sparse scattering deep convolutional neural network, which provides a simple model to analyze properties of deep representation learning for classification. Learning a single dictionary matrix with a classifier yields a higher classification accuracy than AlexNet over the ImageNet 2012 dataset. The network first applies a scattering transform that linearizes variabilities due to geometric transformations such as translations and small deformations.\nA sparse $\\ell^1$ dictionary coding reduces intra-class variability while preserving class separation through projections over unions of linear spaces. It is implemented in a deep convolutional network with a homotopy algorithm having an exponential convergence. A convergence proof is given in a general framework that includes ALISTA. Classification results are analyzed on ImageNet.", "keywords": ["dictionary learning", "scattering transform", "sparse coding", "imagenet"], "paperhash": "zarka|deep_network_classification_by_scattering_and_homotopy_dictionary_learning", "_bibtex": "@inproceedings{\nZarka2020Deep,\ntitle={Deep Network Classification by Scattering and Homotopy Dictionary Learning},\nauthor={John Zarka and Louis Thiry and Tomas Angles and Stephane Mallat},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJxWS64FwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/29c8b04d248189e8466780ebd914005d9beb4aa5.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "iwUlSHLUzz", "original": null, "number": 1, "cdate": 1576798698553, "ddate": null, "tcdate": 1576798698553, "tmdate": 1576800937259, "tddate": null, "forum": "SJxWS64FwH", "replyto": "SJxWS64FwH", "invitation": "ICLR.cc/2020/Conference/Paper512/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "After the rebuttal period the ratings on this paper increased and it now has a strong assessment across reviewers. The AC recommends acceptance.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["john.zarka@ens.fr", "louis.thiry@ens.fr", "tomas.angles@ens.fr", "stephane.mallat@ens.fr"], "title": "Deep Network Classification by Scattering and Homotopy Dictionary Learning", "authors": ["John Zarka", "Louis Thiry", "Tomas Angles", "Stephane Mallat"], "pdf": "/pdf/e6235a059a0929ea35206c487924a1f355bb8c7d.pdf", "TL;DR": "A scattering transform followed by supervised dictionary learning reaches a higher accuracy than AlexNet on ImageNet.", "abstract": "We introduce a sparse scattering deep convolutional neural network, which provides a simple model to analyze properties of deep representation learning for classification. Learning a single dictionary matrix with a classifier yields a higher classification accuracy than AlexNet over the ImageNet 2012 dataset. The network first applies a scattering transform that linearizes variabilities due to geometric transformations such as translations and small deformations.\nA sparse $\\ell^1$ dictionary coding reduces intra-class variability while preserving class separation through projections over unions of linear spaces. It is implemented in a deep convolutional network with a homotopy algorithm having an exponential convergence. A convergence proof is given in a general framework that includes ALISTA. Classification results are analyzed on ImageNet.", "keywords": ["dictionary learning", "scattering transform", "sparse coding", "imagenet"], "paperhash": "zarka|deep_network_classification_by_scattering_and_homotopy_dictionary_learning", "_bibtex": "@inproceedings{\nZarka2020Deep,\ntitle={Deep Network Classification by Scattering and Homotopy Dictionary Learning},\nauthor={John Zarka and Louis Thiry and Tomas Angles and Stephane Mallat},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJxWS64FwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/29c8b04d248189e8466780ebd914005d9beb4aa5.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "SJxWS64FwH", "replyto": "SJxWS64FwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795714479, "tmdate": 1576800264202, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper512/-/Decision"}}}, {"id": "HJl5HgCpFB", "original": null, "number": 2, "cdate": 1571835970028, "ddate": null, "tcdate": 1571835970028, "tmdate": 1574691371901, "tddate": null, "forum": "SJxWS64FwH", "replyto": "SJxWS64FwH", "invitation": "ICLR.cc/2020/Conference/Paper512/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "8: Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #3", "review": "\n## Summary\n\nThe paper proposes an interpretable architecture for image classification based on a scattering transform and sparse dictionary learning approach. The scattering transform acts as a pre-trained interpretable feature extractor that does not require data. A sparse dictionary on top of this representation (the scattering coefficients) is learnt to minimize the classification error. The authors cast the dictionary learning as a classical CNN learning approach and implement an efficient solution via homotopy learning (given that some assumptions are fulfilled). The scattering transform approach is not new (as the authors mention in the paper, it was published in Oyallon et al., 2019). The main novelty comes from applying a previously published dictionary learning approach (as the authors mention in the paper, it was published in Jiao et al., 2017) on top to boost the performance. As a second contribution, the authors extend the exponential convergence proof of ISTC (Jiao et al., 2017) and ALISTA (Liu et al., 2019). In the experiments, they show that the proposed architecture, despite its simplicity, outperform AlexNet in the ImageNet classification problem.\n \n## Comments\n\nThe paper is well written and the exposition is clear. The main motivation of the paper is to propose an interpretable architecture with similar performance to black box deep learning architectures. To do so, the authors put together:\n\n- A scattering transform feature extractor: Unlike I am missing something, this is exactly what was previously proposed in (Oyallon et al., 2019). \n- A dictionary learning on top: This seems to be the biggest novelty of the paper. This component allows to boost the performance of the previously proposed architecture. However, this approach has been previously explored in the literature (Mahdizadehaghdam et al. 2018), the authors just apply it on top the extracted features. The justification of the paper lies in that previous dictionary learning approaches did not scale (convergence too slow), and so the authors use a different method recently published in (Jiao et al., 2017). \n\nThis allow the authors to apply the method to bigger datasets ImageNet, and keep the performance above AlexNet. \n\nGeneralizing the convergence results of ALISTA and ISTC is a nice contribution. However, my main concern is with respect the novelty of the rest of the paper. The authors do not propose a substantially different approach, rather they apply the same approach (an scalable  dictionary learning method already published in Jiao et al., 2017) on top of some extracted features (scattering coefficients)  to a different datasets. The problem with accepting the paper is that changing the dataset/dictionary learning method/features to compare with, you get a different paper, and so, in my opinion, the impact of this publication is limited.\n \nAlso, given that the paper main point is the interpretability of the proposed method wrt to black-box deep learning methods, I think the authors should include recent references to the active field of interpretability in the deep neural network community.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper512/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper512/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["john.zarka@ens.fr", "louis.thiry@ens.fr", "tomas.angles@ens.fr", "stephane.mallat@ens.fr"], "title": "Deep Network Classification by Scattering and Homotopy Dictionary Learning", "authors": ["John Zarka", "Louis Thiry", "Tomas Angles", "Stephane Mallat"], "pdf": "/pdf/e6235a059a0929ea35206c487924a1f355bb8c7d.pdf", "TL;DR": "A scattering transform followed by supervised dictionary learning reaches a higher accuracy than AlexNet on ImageNet.", "abstract": "We introduce a sparse scattering deep convolutional neural network, which provides a simple model to analyze properties of deep representation learning for classification. Learning a single dictionary matrix with a classifier yields a higher classification accuracy than AlexNet over the ImageNet 2012 dataset. The network first applies a scattering transform that linearizes variabilities due to geometric transformations such as translations and small deformations.\nA sparse $\\ell^1$ dictionary coding reduces intra-class variability while preserving class separation through projections over unions of linear spaces. It is implemented in a deep convolutional network with a homotopy algorithm having an exponential convergence. A convergence proof is given in a general framework that includes ALISTA. Classification results are analyzed on ImageNet.", "keywords": ["dictionary learning", "scattering transform", "sparse coding", "imagenet"], "paperhash": "zarka|deep_network_classification_by_scattering_and_homotopy_dictionary_learning", "_bibtex": "@inproceedings{\nZarka2020Deep,\ntitle={Deep Network Classification by Scattering and Homotopy Dictionary Learning},\nauthor={John Zarka and Louis Thiry and Tomas Angles and Stephane Mallat},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJxWS64FwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/29c8b04d248189e8466780ebd914005d9beb4aa5.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJxWS64FwH", "replyto": "SJxWS64FwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper512/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper512/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575217740268, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper512/Reviewers"], "noninvitees": [], "tcdate": 1570237751067, "tmdate": 1575217740281, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper512/-/Official_Review"}}}, {"id": "rJg3_X7osS", "original": null, "number": 4, "cdate": 1573757812196, "ddate": null, "tcdate": 1573757812196, "tmdate": 1573822700385, "tddate": null, "forum": "SJxWS64FwH", "replyto": "HJl5HgCpFB", "invitation": "ICLR.cc/2020/Conference/Paper512/-/Official_Comment", "content": {"title": "Answer to review #3", "comment": "First of all, thank you very much for your review. Please find below answers to your comments.\n\nReviewer: The scattering transform approach is not new (Oyallon et al. 2019). The main novelty comes from applying a previously published dictionary learning approach on top to boost the performance [...] - A scattering transform feature extractor: Unlike I am missing something, this is exactly what was previously proposed in (Oyallon et al., 2019).\n\nWe modified the introduction to clarify this confusion. The scattering transform is a predefined representation (no learning) published in 2013 (Bruna et al.) (cited). Since then, several papers (which are cited) have obtained state-of-the-art results with a scattering among all predefined and unsupervised learning representations. It also performs nearly as well as learned deep networks on relatively simple image datasets (MNIST, CIFAR). Oyallon et al., 2019, did not introduce the scattering transform but have shown that an important classification gap is observed on ImageNet, which can be bridged by adding a CNN on top of scattering. However, Oyallon paper does not provide an explanation.\n\nUnderstanding this gap is about understanding the nature of the information learned by deep neural networks for image classification. The goal of this paper is to address this problem through a model which is as simple as possible. The paper indeed shows that learning a single sparse coding dictionary matrix is sufficient to reach AlexNet performance and bridge the gap. The learned dictionary matrix captures the discriminative information needed to reach a high performance. This is the main novelty of the paper. It provides a simplified mathematical model of CNN for image classification.\n\n\nReviewer: [...] and so the authors use a different method recently published in (Jiao et al., 2017). This allow the authors to apply the method to bigger datasets ImageNet, and keep the performance above AlexNet. Generalizing the convergence results of ALISTA and ISTC is a nice contribution. However, my main concern is with respect the novelty of the rest of the paper. The authors do not propose a substantially different approach, rather they apply the same approach (an scalable dictionary learning method already published in Jiao et al., 2017) on top of some extracted features (scattering coefficients) to a different datasets.\n\nWe have rewritten Section 3.1 to address this misunderstanding. The ISTC and ALISTA algorithms, as well as ISTA or FISTA are algorithms which find the minimum of a sparse coding loss for a given dictionary D. This is very different from dictionary learning, which is a much more complex non-convex problem that optimizes the dictionary D. Our contribution is a dictionary learning algorithm, which incorporates a generalized ISTC into a deep network in order to optimize the dictionary D through stochastic gradient descent.\n\nSection 3.1 now explains the principles of sparse coding and dictionary learning for classification and clearly differentiates the two problems. Section 3.2 is devoted to sparse coding algorithms only. The goal is to reduce the number of network layers for computational efficiency. We show that by using ISTC algorithms we obtain a more efficient dictionary learning algorithm in a deep neural network.\n\n\nReviewer: - A dictionary learning on top: This seems to be the biggest novelty [\u2026] However, this approach has been previously explored in the literature (Mahdizadehaghdam et al. 2018) [...] The justification of the paper lies in that previous dictionary learning approaches did not scale (convergence too slow). [...] The problem with accepting the paper is that changing the dataset/dictionary learning method/features to compare with, you get a different paper, and so, in my opinion, the impact of this publication is limited.\n\nWe do not agree with this conclusion. We now explain more clearly in the introduction that all previously dictionary learning approaches, including Mahdizadehaghdam et al., 2018, consist of cascading *many dictionaries* and involve the learning of many intermediate matrices. There is no indication that these operators actually compute sparse $\\ell^1$ codes. As a result they are mathematically not understood and so complex that they could not be applied to ImageNet.\n\nThe introduction explains that this is the first paper which shows that one can reach deep network performance by learning a *single dictionary matrix D* from a predefined representation (scattering transform) and we prove that it actually performs a sparse $\\ell^1$ coding. This provides a simple learning model that scales to large datasets, which we believe can have a high impact.\n\n\nReviewer: The authors should include recent references to the active field of interpretability\n\nTo be more precise and avoid confusion between mathematical analysis and interpretability, we have replaced \u201cmathematical interpretability\u201d by \u201cmathematical understanding\u201d.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper512/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper512/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["john.zarka@ens.fr", "louis.thiry@ens.fr", "tomas.angles@ens.fr", "stephane.mallat@ens.fr"], "title": "Deep Network Classification by Scattering and Homotopy Dictionary Learning", "authors": ["John Zarka", "Louis Thiry", "Tomas Angles", "Stephane Mallat"], "pdf": "/pdf/e6235a059a0929ea35206c487924a1f355bb8c7d.pdf", "TL;DR": "A scattering transform followed by supervised dictionary learning reaches a higher accuracy than AlexNet on ImageNet.", "abstract": "We introduce a sparse scattering deep convolutional neural network, which provides a simple model to analyze properties of deep representation learning for classification. Learning a single dictionary matrix with a classifier yields a higher classification accuracy than AlexNet over the ImageNet 2012 dataset. The network first applies a scattering transform that linearizes variabilities due to geometric transformations such as translations and small deformations.\nA sparse $\\ell^1$ dictionary coding reduces intra-class variability while preserving class separation through projections over unions of linear spaces. It is implemented in a deep convolutional network with a homotopy algorithm having an exponential convergence. A convergence proof is given in a general framework that includes ALISTA. Classification results are analyzed on ImageNet.", "keywords": ["dictionary learning", "scattering transform", "sparse coding", "imagenet"], "paperhash": "zarka|deep_network_classification_by_scattering_and_homotopy_dictionary_learning", "_bibtex": "@inproceedings{\nZarka2020Deep,\ntitle={Deep Network Classification by Scattering and Homotopy Dictionary Learning},\nauthor={John Zarka and Louis Thiry and Tomas Angles and Stephane Mallat},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJxWS64FwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/29c8b04d248189e8466780ebd914005d9beb4aa5.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJxWS64FwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper512/Authors", "ICLR.cc/2020/Conference/Paper512/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper512/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper512/Reviewers", "ICLR.cc/2020/Conference/Paper512/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper512/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper512/Authors|ICLR.cc/2020/Conference/Paper512/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504170328, "tmdate": 1576860561062, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper512/Authors", "ICLR.cc/2020/Conference/Paper512/Reviewers", "ICLR.cc/2020/Conference/Paper512/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper512/-/Official_Comment"}}}, {"id": "ryla7UXjsB", "original": null, "number": 5, "cdate": 1573758500888, "ddate": null, "tcdate": 1573758500888, "tmdate": 1573819019175, "tddate": null, "forum": "SJxWS64FwH", "replyto": "SkgtJzcntH", "invitation": "ICLR.cc/2020/Conference/Paper512/-/Official_Comment", "content": {"title": "Answer to review #1", "comment": "First of all, thank you very much for your review. Notations have been adjusted according to the reviewer\u2019s suggestions. Please find below answers to your comments.\n\nReviewer: The last paragraph in Section 3.1 does not explain the algorithm clearly. The confusing part is how to update the dictionary parameters. [...] I believe that this is the crux of the methodological/conceptual contribution and requires proper explanation with proper illustration of the forward-backward pass. [...] Just below Figure 2, I fail to follow how the number of layers N relates to the iterative algorithm? Does it mean that you would actually have blocks per each \\alpha_n for some N indices (this again refers to previous comment on clarity)?\n\nWe rewrote Section 3.1 to address this point. Section 3 now clearly separates the sparse coding from the dictionary learning stage. We explain that the sparse coding is implemented as a deep network calculation. The dictionary learning is then performed by minimizing the classification loss with stochastic gradient descent. The number of layers in the network is equal to the number of iterations used to approximate the sparse code: we clarify it in the caption of Figure 2. We explain now that during training, the forward pass approximates the sparse code with respect to the current dictionary, and the backward pass updates the dictionary through a stochastic gradient descent step.\n\n\nReviewer: In Section 3.2 (homotopy iterated thresholding and ALISTA), there is a matrix W which comes ad-hoc. There should be some motivation and gentle introduction. At the moment, it is completely justified to ask why one needs this matrix (W) and why the approach would not work without Proposition 3.1.\n\nThe reviewer is right. We now explain the role of this auxiliary matrix to accelerate the convergence of LISTA and ALISTA. Theorem 3.1 gives a general framework to study the role of such matrices, by giving a sufficient condition for exponential convergence. In Section 4 we consider the case where W=D which corresponds to the original ISTC algorithm, and a general case where W is freely optimized."}, "signatures": ["ICLR.cc/2020/Conference/Paper512/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper512/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["john.zarka@ens.fr", "louis.thiry@ens.fr", "tomas.angles@ens.fr", "stephane.mallat@ens.fr"], "title": "Deep Network Classification by Scattering and Homotopy Dictionary Learning", "authors": ["John Zarka", "Louis Thiry", "Tomas Angles", "Stephane Mallat"], "pdf": "/pdf/e6235a059a0929ea35206c487924a1f355bb8c7d.pdf", "TL;DR": "A scattering transform followed by supervised dictionary learning reaches a higher accuracy than AlexNet on ImageNet.", "abstract": "We introduce a sparse scattering deep convolutional neural network, which provides a simple model to analyze properties of deep representation learning for classification. Learning a single dictionary matrix with a classifier yields a higher classification accuracy than AlexNet over the ImageNet 2012 dataset. The network first applies a scattering transform that linearizes variabilities due to geometric transformations such as translations and small deformations.\nA sparse $\\ell^1$ dictionary coding reduces intra-class variability while preserving class separation through projections over unions of linear spaces. It is implemented in a deep convolutional network with a homotopy algorithm having an exponential convergence. A convergence proof is given in a general framework that includes ALISTA. Classification results are analyzed on ImageNet.", "keywords": ["dictionary learning", "scattering transform", "sparse coding", "imagenet"], "paperhash": "zarka|deep_network_classification_by_scattering_and_homotopy_dictionary_learning", "_bibtex": "@inproceedings{\nZarka2020Deep,\ntitle={Deep Network Classification by Scattering and Homotopy Dictionary Learning},\nauthor={John Zarka and Louis Thiry and Tomas Angles and Stephane Mallat},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJxWS64FwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/29c8b04d248189e8466780ebd914005d9beb4aa5.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJxWS64FwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper512/Authors", "ICLR.cc/2020/Conference/Paper512/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper512/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper512/Reviewers", "ICLR.cc/2020/Conference/Paper512/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper512/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper512/Authors|ICLR.cc/2020/Conference/Paper512/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504170328, "tmdate": 1576860561062, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper512/Authors", "ICLR.cc/2020/Conference/Paper512/Reviewers", "ICLR.cc/2020/Conference/Paper512/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper512/-/Official_Comment"}}}, {"id": "ByeTcFMiiH", "original": null, "number": 3, "cdate": 1573755284597, "ddate": null, "tcdate": 1573755284597, "tmdate": 1573757943205, "tddate": null, "forum": "SJxWS64FwH", "replyto": "SkeHSjoe9H", "invitation": "ICLR.cc/2020/Conference/Paper512/-/Official_Comment", "content": {"title": "Answer to review #2", "comment": "First of all, thank you very much for your review. Please find below answers to your comments.\n\nReviewer: I think that it would be interesting to add an ablation showing the change in performance by changing N (the number of iterations in the ISTC net).\n\nThis is now included in the text of Section 4.1. Reducing the number of iterations to N=8 preserves the accuracy but the sparse code does not converge to an $\\ell^1$ sparse code and thus can not be interpreted. For N = 14 or 16 the convergence accuracy is nearly the same with marginal convergence improvements.\n\n\nReviewer: Also, it would make sense to run FISTA or ISTA unrolls to see if the benefits of the faster convergence also affect classification performance.\n\nFigure 4, left shows that the sparse code produced by ISTC (W = D) converges to the same sparse code produced by ISTA/FISTA, but ISTA/FISTA require many more iterations. We tried to apply ISTA unrolled with N=12 iterations using the same dictionary learning procedure as for ISTC. It provides a classification accuracy of 79.5% which is above AlexNet but it provides a poor approximation of an $\\ell^1$ sparse code, as shown in Figure 4.\n\n\nReviewer: It would be good to add to Table 1 the number of trainable parameters of each variant.\n\nWe have now incorporated the number of trainable parameters to compute the sparse scattering representation, in Section 4.1, depending upon the configuration. This is incorporated in the text with a comparison with AlexNet.\n\n\nReviewer: I find it a bit confusing to refer to the setting in which W is learned as ALISTA, as to me ALISTA implies using analytical W. This is clear later in the text (and makes sense from a computational standpoint). Would be good to clarify it early in the text.\n\nTo clarify all this, we define a general ISTC algorithm for an arbitrary W. For W which minimizes the mutual coherence we get ALISTA. We explain that Section 4.1 considers the case of an arbitrary W which does not correspond to ALISTA.\n\n\nReviewer: Finally the paper presents a proof of exponential convergence for ALISTA in the noisy case. While this is an interesting result, it is not very closely linked to the main focus of the work.\n\nWe now explain more clearly that Theorem 3.1 gives a sufficient condition for exponential convergence of the general ISTC algorithm, which is used in all experiments of Section 4. If W has a minimum mutual convergence with D then we get a convergence result for ALISTA in the noisy case. This result also considerably simplifies ALISTA proof and shows that it is a homotopy algorithm. However, we agree with the reviewer that it is not used in the numerics so we have removed this from the introduction, to concentrate on the main focus of the work.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper512/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper512/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["john.zarka@ens.fr", "louis.thiry@ens.fr", "tomas.angles@ens.fr", "stephane.mallat@ens.fr"], "title": "Deep Network Classification by Scattering and Homotopy Dictionary Learning", "authors": ["John Zarka", "Louis Thiry", "Tomas Angles", "Stephane Mallat"], "pdf": "/pdf/e6235a059a0929ea35206c487924a1f355bb8c7d.pdf", "TL;DR": "A scattering transform followed by supervised dictionary learning reaches a higher accuracy than AlexNet on ImageNet.", "abstract": "We introduce a sparse scattering deep convolutional neural network, which provides a simple model to analyze properties of deep representation learning for classification. Learning a single dictionary matrix with a classifier yields a higher classification accuracy than AlexNet over the ImageNet 2012 dataset. The network first applies a scattering transform that linearizes variabilities due to geometric transformations such as translations and small deformations.\nA sparse $\\ell^1$ dictionary coding reduces intra-class variability while preserving class separation through projections over unions of linear spaces. It is implemented in a deep convolutional network with a homotopy algorithm having an exponential convergence. A convergence proof is given in a general framework that includes ALISTA. Classification results are analyzed on ImageNet.", "keywords": ["dictionary learning", "scattering transform", "sparse coding", "imagenet"], "paperhash": "zarka|deep_network_classification_by_scattering_and_homotopy_dictionary_learning", "_bibtex": "@inproceedings{\nZarka2020Deep,\ntitle={Deep Network Classification by Scattering and Homotopy Dictionary Learning},\nauthor={John Zarka and Louis Thiry and Tomas Angles and Stephane Mallat},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJxWS64FwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/29c8b04d248189e8466780ebd914005d9beb4aa5.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJxWS64FwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper512/Authors", "ICLR.cc/2020/Conference/Paper512/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper512/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper512/Reviewers", "ICLR.cc/2020/Conference/Paper512/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper512/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper512/Authors|ICLR.cc/2020/Conference/Paper512/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504170328, "tmdate": 1576860561062, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper512/Authors", "ICLR.cc/2020/Conference/Paper512/Reviewers", "ICLR.cc/2020/Conference/Paper512/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper512/-/Official_Comment"}}}, {"id": "rJxLcUzssB", "original": null, "number": 2, "cdate": 1573754509868, "ddate": null, "tcdate": 1573754509868, "tmdate": 1573754509868, "tddate": null, "forum": "SJxWS64FwH", "replyto": "SJxWS64FwH", "invitation": "ICLR.cc/2020/Conference/Paper512/-/Official_Comment", "content": {"title": "Some general clarifications", "comment": "We are very grateful to all the reviewers for their comments which were important for us to improve the paper. We have modified the introduction to clarify the goal and contributions of the paper, especially for Reviewer #3.\n\nWe partly rewrote Section 3.1 to better differentiate sparse coding problems from dictionary learning following remarks of Reviewer #1 and #3. We also tried to better highlight the specificities of different sparse coding algorithms in Section 3.2 to address remarks of all reviewers. To clarify the role of W, we describe the ISTC algorithm for a general W and explain how it relates to the original ISTC and ALISTA for different values of W, and the role of W.\n\nFor simplicity, we have restricted the sparse codes to positive codes, so that the network is implemented with ReLU and a bias as in standard CNNs. It also improved classification accuracies by about 0.5%. The Section 4 was adapted to these modifications."}, "signatures": ["ICLR.cc/2020/Conference/Paper512/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper512/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["john.zarka@ens.fr", "louis.thiry@ens.fr", "tomas.angles@ens.fr", "stephane.mallat@ens.fr"], "title": "Deep Network Classification by Scattering and Homotopy Dictionary Learning", "authors": ["John Zarka", "Louis Thiry", "Tomas Angles", "Stephane Mallat"], "pdf": "/pdf/e6235a059a0929ea35206c487924a1f355bb8c7d.pdf", "TL;DR": "A scattering transform followed by supervised dictionary learning reaches a higher accuracy than AlexNet on ImageNet.", "abstract": "We introduce a sparse scattering deep convolutional neural network, which provides a simple model to analyze properties of deep representation learning for classification. Learning a single dictionary matrix with a classifier yields a higher classification accuracy than AlexNet over the ImageNet 2012 dataset. The network first applies a scattering transform that linearizes variabilities due to geometric transformations such as translations and small deformations.\nA sparse $\\ell^1$ dictionary coding reduces intra-class variability while preserving class separation through projections over unions of linear spaces. It is implemented in a deep convolutional network with a homotopy algorithm having an exponential convergence. A convergence proof is given in a general framework that includes ALISTA. Classification results are analyzed on ImageNet.", "keywords": ["dictionary learning", "scattering transform", "sparse coding", "imagenet"], "paperhash": "zarka|deep_network_classification_by_scattering_and_homotopy_dictionary_learning", "_bibtex": "@inproceedings{\nZarka2020Deep,\ntitle={Deep Network Classification by Scattering and Homotopy Dictionary Learning},\nauthor={John Zarka and Louis Thiry and Tomas Angles and Stephane Mallat},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJxWS64FwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/29c8b04d248189e8466780ebd914005d9beb4aa5.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SJxWS64FwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper512/Authors", "ICLR.cc/2020/Conference/Paper512/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper512/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper512/Reviewers", "ICLR.cc/2020/Conference/Paper512/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper512/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper512/Authors|ICLR.cc/2020/Conference/Paper512/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504170328, "tmdate": 1576860561062, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper512/Authors", "ICLR.cc/2020/Conference/Paper512/Reviewers", "ICLR.cc/2020/Conference/Paper512/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper512/-/Official_Comment"}}}, {"id": "SkgtJzcntH", "original": null, "number": 1, "cdate": 1571754465276, "ddate": null, "tcdate": 1571754465276, "tmdate": 1572972586215, "tddate": null, "forum": "SJxWS64FwH", "replyto": "SJxWS64FwH", "invitation": "ICLR.cc/2020/Conference/Paper512/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The work considers a new architecture for artificial neural networks to be used in image classification tasks. The network combines several promising previous research directions into an interesting approach (to the best of my knowledge, the architecture is novel). \n\nIn the first step, the input representation (i.e., image) is processed using deep scattering spectrum. This is an operator proposed by Mallat (2012) and it is known for extracting robust features with properties such as translation invariance and Lipschitz continuity of the operator mapping. As a result, such a representation is likely to be more stable to perturbations and noise in the inputs.\nThe scattering operator of the second and higher orders tends to produce a large number of coefficients. Such a representation is, in general, sparse with many of the higher order coefficients equal to zero. To lower the dimension of the scattering representation, the architecture employs a linear projection operator. For example, one can take principal component analysis and project to a sub-space retaining most of the variation present in the data.\nThe first two blocks (scattering and linear projection) are unsupervised and, thus, kept fixed during learning. \n\nThe third block in the architecture aims at finding a sparse coding dictionary that will take into account instances and labels. It builds a dictionary using a convolutional neural network and finds sparse coding using previous work on dictionary learning (e.g., Donoho & Elad, 2006: Marial et al., 2011; Jiao et al., 2017 etc). The algorithm works by computing the sparse encoding vector (see Eq. 1) in the forward pass and updating the convolutional parameters as well as sparsity controlling hyperparameter in the backward step. To speed up the convergence, the authors rely on homotopy iterated thresholding illustrated in Figure 2.\n\nThe approach is evaluated on ImageNet and empirical results demonstrate that the removal of the sparse encoding block amounts to a significant performance degradation. The results also establish a minor improvement in the accuracy as a result of adding a linear projection matrix (i.e., principal component analysis applied to scattering coefficients). Overall, the network shows promising performance on ImageNet by doing better than AlexNet. The result is not yet 'competitive' with ResNets but it might be worth to pursue this direction of research in the future.\n\nThe work is properly structured with well organized materials from previous work. The clarity, however, could be improved in several places. In particular, the last paragraph in Section 3.1 does not explain the algorithm clearly. The confusing part is how to update the dictionary (i.e., convolutional network) parameters. One might infer from the current materials that first the problem in Eq. (1) is solved to find \\alpha and that solution is fixed. Then, for that setting of the sparse encoding vector one will train the network parameters. Section 3.2 then givens an iterative procedure in Eq. (3) and Figure 2, which suggest that in a forward pass the dictionary representation is computed using some setting of parameters and \\alpha is updated per Eq. (3). Following this, the gradient of the convolutional parameters is computed (\\alpha_{n + 1} is differentiated, which means that the gradient depends on other \\alpha iterates). I believe that this is the crux of the methodological/conceptual contribution and requires proper explanation with proper illustration of the forward-backward pass.\n\nIn Section 3.2 (homotopy iterated thresholding and ALISTA), there is a matrix W which comes ad-hoc. There should be some motivation and gentle introduction. At the moment, it is completely justified to ask why one needs this matrix and why the approach would not work without Proposition 3.1. Please add some discussion and make sure things are properly motivated and gently introduced. This will also place the theoretical contribution in the proper context and strengthen the work.\n\nJust below Figure 2, I fail to follow how the number of layers N relates to the iterative algorithm? Does it mean that you would actually have blocks per each \\alpha_n for some N indices (this again refers to previous comment on clarity)?\n\nCan you please use \\ell_1 or l_1 notation for sparse dictionary coding. The current symbol reads as 1 to the power of 1 and it is very confusing (never seen it before in the context of sparse encodings)."}, "signatures": ["ICLR.cc/2020/Conference/Paper512/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper512/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["john.zarka@ens.fr", "louis.thiry@ens.fr", "tomas.angles@ens.fr", "stephane.mallat@ens.fr"], "title": "Deep Network Classification by Scattering and Homotopy Dictionary Learning", "authors": ["John Zarka", "Louis Thiry", "Tomas Angles", "Stephane Mallat"], "pdf": "/pdf/e6235a059a0929ea35206c487924a1f355bb8c7d.pdf", "TL;DR": "A scattering transform followed by supervised dictionary learning reaches a higher accuracy than AlexNet on ImageNet.", "abstract": "We introduce a sparse scattering deep convolutional neural network, which provides a simple model to analyze properties of deep representation learning for classification. Learning a single dictionary matrix with a classifier yields a higher classification accuracy than AlexNet over the ImageNet 2012 dataset. The network first applies a scattering transform that linearizes variabilities due to geometric transformations such as translations and small deformations.\nA sparse $\\ell^1$ dictionary coding reduces intra-class variability while preserving class separation through projections over unions of linear spaces. It is implemented in a deep convolutional network with a homotopy algorithm having an exponential convergence. A convergence proof is given in a general framework that includes ALISTA. Classification results are analyzed on ImageNet.", "keywords": ["dictionary learning", "scattering transform", "sparse coding", "imagenet"], "paperhash": "zarka|deep_network_classification_by_scattering_and_homotopy_dictionary_learning", "_bibtex": "@inproceedings{\nZarka2020Deep,\ntitle={Deep Network Classification by Scattering and Homotopy Dictionary Learning},\nauthor={John Zarka and Louis Thiry and Tomas Angles and Stephane Mallat},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJxWS64FwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/29c8b04d248189e8466780ebd914005d9beb4aa5.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJxWS64FwH", "replyto": "SJxWS64FwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper512/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper512/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575217740268, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper512/Reviewers"], "noninvitees": [], "tcdate": 1570237751067, "tmdate": 1575217740281, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper512/-/Official_Review"}}}, {"id": "SkeHSjoe9H", "original": null, "number": 3, "cdate": 1572023101022, "ddate": null, "tcdate": 1572023101022, "tmdate": 1572972586078, "tddate": null, "forum": "SJxWS64FwH", "replyto": "SJxWS64FwH", "invitation": "ICLR.cc/2020/Conference/Paper512/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper proposes a network architecture composed of three interpretable components followed by a simple MLP classifier. It first applies a scattering transform followed by a learned linear projection (to reduce dimensionality). A sparse representation of these coefficients is then obtained using dictionary learning. The projection, dictionary and MLP classifier are jointly trained to minimize the classification loss. Results show that the model outperforms AlexNet on the Imagenet benchmark.\n\nThe paper is well written. The main contribution of the work is to present an architecture with composed of mathematically interpretable components achieving very high empirical performance. I find that these results are very significant. \n\nThe second contribution is to propose a dictionary learning algorithm that uses ISTC and can be trained with gradient descent.  I think that it would be interesting to add an ablation showing the change in performance by changing N (the number of iterations in the ISTC net). Also, it would make sense to run FISTA or ISTA unrolls to see if the benefits of the faster convergence also affect classification performance.\n\nIt would be good to add to Table 1 the number of trainable parameters of each variant.\n\nI find it a bit confusing to refer to the setting in which W is learned as ALISTA, as to me ALISTA implies using analytical W. This is clear later in the text (and makes sense from a computational standpoint). Would be good to clarify it early in the text.\n\nFinally the paper presents a proof of exponential convergence for ALISTA in the noisy case. While this is an interesting result, it is not very closely linked to the main focus of the work. \n"}, "signatures": ["ICLR.cc/2020/Conference/Paper512/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper512/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["john.zarka@ens.fr", "louis.thiry@ens.fr", "tomas.angles@ens.fr", "stephane.mallat@ens.fr"], "title": "Deep Network Classification by Scattering and Homotopy Dictionary Learning", "authors": ["John Zarka", "Louis Thiry", "Tomas Angles", "Stephane Mallat"], "pdf": "/pdf/e6235a059a0929ea35206c487924a1f355bb8c7d.pdf", "TL;DR": "A scattering transform followed by supervised dictionary learning reaches a higher accuracy than AlexNet on ImageNet.", "abstract": "We introduce a sparse scattering deep convolutional neural network, which provides a simple model to analyze properties of deep representation learning for classification. Learning a single dictionary matrix with a classifier yields a higher classification accuracy than AlexNet over the ImageNet 2012 dataset. The network first applies a scattering transform that linearizes variabilities due to geometric transformations such as translations and small deformations.\nA sparse $\\ell^1$ dictionary coding reduces intra-class variability while preserving class separation through projections over unions of linear spaces. It is implemented in a deep convolutional network with a homotopy algorithm having an exponential convergence. A convergence proof is given in a general framework that includes ALISTA. Classification results are analyzed on ImageNet.", "keywords": ["dictionary learning", "scattering transform", "sparse coding", "imagenet"], "paperhash": "zarka|deep_network_classification_by_scattering_and_homotopy_dictionary_learning", "_bibtex": "@inproceedings{\nZarka2020Deep,\ntitle={Deep Network Classification by Scattering and Homotopy Dictionary Learning},\nauthor={John Zarka and Louis Thiry and Tomas Angles and Stephane Mallat},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SJxWS64FwH}\n}", "full_presentation_video": "", "original_pdf": "/attachment/29c8b04d248189e8466780ebd914005d9beb4aa5.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJxWS64FwH", "replyto": "SJxWS64FwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper512/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper512/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575217740268, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper512/Reviewers"], "noninvitees": [], "tcdate": 1570237751067, "tmdate": 1575217740281, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper512/-/Official_Review"}}}], "count": 9}