{"notes": [{"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1458218526308, "tcdate": 1458218526308, "id": "YW9k53A8qILknpQqIK3N", "invitation": "ICLR.cc/2016/workshop/-/paper/78/review/12", "forum": "gZ9OMgQWoIAPowrRUAN6", "replyto": "gZ9OMgQWoIAPowrRUAN6", "signatures": ["ICLR.cc/2016/workshop/paper/78/reviewer/12"], "readers": ["everyone"], "writers": ["ICLR.cc/2016/workshop/paper/78/reviewer/12"], "content": {"title": "Good empirical exploration of seq2seq applied to sentence-summarization", "rating": "7: Good paper, accept", "review": "Overall, this paper considers a fairly straightforward application of the seq2seq model to abstractive sentence summarization, with most novel work only hinted at or mostly ignored (almost surely due to the short page limit, but it would be very interesting to pursue in a longer paper). The empirical results are carefully described, and based on the authors' response, seem to be comparable to those of Rush et al., and overall therefore represent a significant boost in accuracy over the Rush model.  \n\nSome finer points:\n\nUsing the Large Vocabulary \"Trick\" speeds up training but hurts the abstractive ability of the model. Since the latter is the core focus of this model, it seems worth it to fix this issue. A sampling approach to the full softmax should represent a better solution than the LVT heuristic or the heuristic of extending the target vocabulary with 1-nearest neighbours.\n\nIn the words-lvt2k-(2|5)sent model, it is not clear why using 2 sentences is more accurate than 1, but using 5 sentences is less accurate than 2 (do you reverse the input in the encoder?). It would be beneficial to investigate the reason for this by visualizing and analyzing the attention heat maps for the 2 vs 5 sentence models.\n\nIt was nice to see that the authors did also consider a more novel hierarchical model based on Li et al. 2015, but it is unfortunate that this approach did not seem to yield better results. Could it be that this approach could actually benefit from using more than two sentences? It's not clear whether this was tried.\n\nIt would be useful to see the \"src-copy rate\" of the gold training data to be able to meaningfully interpret that metric.\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Sequence-to-Sequence RNNs for Text Summarization", "abstract": "In this work, we cast text summarization as a sequence-to-sequence problem and apply the attentional encoder-decoder RNN that has been shown to be successful for Machine Translation.\nOur experiments show that the proposed architecture significantly outperforms the state-of-the art model of Rush et. al. (2015), on the Gigaword dataset without any additional tuning. We also propose additional extensions to the standard architecture, which we show contribute to further improvement in performance. ", "pdf": "/pdf/gZ9OMgQWoIAPowrRUAN6.pdf", "paperhash": "nallapati|sequencetosequence_rnns_for_text_summarization", "conflicts": ["us.ibm.com"], "authors": ["Ramesh Nallapati", "Bing Xiang", "Bowen Zhou"], "authorids": ["nallapati@us.ibm.com", "bingxia@us.ibm.com", "zhou@us.ibm.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456579946523, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456579946523, "id": "ICLR.cc/2016/workshop/-/paper/78/review/12", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "gZ9OMgQWoIAPowrRUAN6", "replyto": "gZ9OMgQWoIAPowrRUAN6", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/78/reviewer/12", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1458138090619, "tcdate": 1458138090619, "id": "4QygZK2KPFBYD9yOFqj8", "invitation": "ICLR.cc/2016/workshop/-/paper/78/comment", "forum": "gZ9OMgQWoIAPowrRUAN6", "replyto": "YW94VGrx7TLknpQqIKZm", "signatures": ["~Ramesh_M_Nallapati1"], "readers": ["everyone"], "writers": ["~Ramesh_M_Nallapati1"], "content": {"title": "Response to reviewer 11's  review", "comment": "Our test set sample actually did come from the same test set as that of Rush et al, but it is indeed true that the samples themselves are not identical. The reason is that the authors of that paper have not publicly released their test sample. Regarding your other comment on Rouge recall, we did compare our full-length Rouge Recall numbers to those of Rush et al in rows 11, 12 and 13 of Table 1 in the submitted version (we confirmed with the authors of Rush et al before submission that this is exactly the metric used by them on Gigaword corpus, and not the limited-length Recall that they used on DUC corpus). We also reported our numbers on Full-length Rouge-F1 out of our extra effort to be fair, since full-length recall tends to favor longer summaries and we didn't want to gain an unfair advantage just in case our summaries were longer than theirs. Please note that on Recall only, our model is in fact even better than theirs.\n \nAfter the submission, we also followed up our communication with Rush et al authors, and obtained their exact test sample and did additional experiments to do precise apples-to-apples comparison on both recall and F1, and it is indeed confirmed that our proposed models clearly outperform theirs on both counts. Please refer to the updated version downloadable from https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnxyYW1lc2huYWxsYXBhdGl8Z3g6MTE5NjdkZGY2NDM3Y2FkMQ for more details on these experiments, but we are also printing the comparison on the same test-set sample below for your convenience:\n\nFull length Recall:\n              Rouge1         Rouge2         Rouge-L\nRush et al:   31.47          12.73          28.54\nOur model:    34.85          17.20          32.74\n\nFull length F1:\n              Rouge1         Rouge2         Rouge-L\nRush et al:   29.78          11.89          26.97\nOur model:    32.76          16.17          30.73\n\nSincerely,\nRamesh Nallapati, Bing Xiang and Bowen Zhou.\n      "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Sequence-to-Sequence RNNs for Text Summarization", "abstract": "In this work, we cast text summarization as a sequence-to-sequence problem and apply the attentional encoder-decoder RNN that has been shown to be successful for Machine Translation.\nOur experiments show that the proposed architecture significantly outperforms the state-of-the art model of Rush et. al. (2015), on the Gigaword dataset without any additional tuning. We also propose additional extensions to the standard architecture, which we show contribute to further improvement in performance. ", "pdf": "/pdf/gZ9OMgQWoIAPowrRUAN6.pdf", "paperhash": "nallapati|sequencetosequence_rnns_for_text_summarization", "conflicts": ["us.ibm.com"], "authors": ["Ramesh Nallapati", "Bing Xiang", "Bowen Zhou"], "authorids": ["nallapati@us.ibm.com", "bingxia@us.ibm.com", "zhou@us.ibm.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "tmdate": null, "cdate": 1455770818438, "ddate": null, "super": null, "final": null, "tcdate": 1455770818438, "id": "ICLR.cc/2016/workshop/-/paper/78/comment", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "readers": ["everyone"], "reply": {"pdf": null, "replyto": null, "writers": {"values-regex": "~.*"}, "forum": "gZ9OMgQWoIAPowrRUAN6", "signatures": {"values-regex": "~.*", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "invitees": ["~", "ICLR.cc/2016/workshop/paper/78/reviewer/10"], "nonreaders": [], "noninvitees": []}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1458064654382, "tcdate": 1458064654382, "id": "YW94VGrx7TLknpQqIKZm", "invitation": "ICLR.cc/2016/workshop/-/paper/78/review/11", "forum": "gZ9OMgQWoIAPowrRUAN6", "replyto": "gZ9OMgQWoIAPowrRUAN6", "signatures": ["ICLR.cc/2016/workshop/paper/78/reviewer/11"], "readers": ["everyone"], "writers": ["ICLR.cc/2016/workshop/paper/78/reviewer/11"], "content": {"title": "Comparison to previous work not possible", "rating": "5: Marginally below acceptance threshold", "review": "It's interesting to see that embedding additional annotations such as part-of-speech and NER tags helps the performance.\nHowever, the evaluation in the paper makes it impossible to compare to previous work. They use the same training data but use a different test set. Why not use the same test set? \nAlso, the standard metric for summarization is Rouge recall  (see the DUC challenge) but the authors chose F1. They also quote previous work but Rush et al. used recall - so it does not sound right to put both results in the same table.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Sequence-to-Sequence RNNs for Text Summarization", "abstract": "In this work, we cast text summarization as a sequence-to-sequence problem and apply the attentional encoder-decoder RNN that has been shown to be successful for Machine Translation.\nOur experiments show that the proposed architecture significantly outperforms the state-of-the art model of Rush et. al. (2015), on the Gigaword dataset without any additional tuning. We also propose additional extensions to the standard architecture, which we show contribute to further improvement in performance. ", "pdf": "/pdf/gZ9OMgQWoIAPowrRUAN6.pdf", "paperhash": "nallapati|sequencetosequence_rnns_for_text_summarization", "conflicts": ["us.ibm.com"], "authors": ["Ramesh Nallapati", "Bing Xiang", "Bowen Zhou"], "authorids": ["nallapati@us.ibm.com", "bingxia@us.ibm.com", "zhou@us.ibm.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456579947096, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456579947096, "id": "ICLR.cc/2016/workshop/-/paper/78/review/11", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "gZ9OMgQWoIAPowrRUAN6", "replyto": "gZ9OMgQWoIAPowrRUAN6", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/78/reviewer/11", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "replyto": null, "ddate": null, "cdate": null, "tmdate": 1455770816091, "tcdate": 1455770816091, "id": "gZ9OMgQWoIAPowrRUAN6", "invitation": "ICLR.cc/2016/workshop/-/submission", "forum": "gZ9OMgQWoIAPowrRUAN6", "signatures": ["~Ramesh_M_Nallapati1"], "readers": ["everyone"], "writers": ["~Ramesh_M_Nallapati1"], "content": {"CMT_id": "", "title": "Sequence-to-Sequence RNNs for Text Summarization", "abstract": "In this work, we cast text summarization as a sequence-to-sequence problem and apply the attentional encoder-decoder RNN that has been shown to be successful for Machine Translation.\nOur experiments show that the proposed architecture significantly outperforms the state-of-the art model of Rush et. al. (2015), on the Gigaword dataset without any additional tuning. We also propose additional extensions to the standard architecture, which we show contribute to further improvement in performance. ", "pdf": "/pdf/gZ9OMgQWoIAPowrRUAN6.pdf", "paperhash": "nallapati|sequencetosequence_rnns_for_text_summarization", "conflicts": ["us.ibm.com"], "authors": ["Ramesh Nallapati", "Bing Xiang", "Bowen Zhou"], "authorids": ["nallapati@us.ibm.com", "bingxia@us.ibm.com", "zhou@us.ibm.com"]}, "nonreaders": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1454464564200, "ddate": null, "super": null, "final": null, "duedate": 1455833700000, "tcdate": 1454464564200, "id": "ICLR.cc/2016/workshop/-/submission", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "readers": ["everyone"], "reply": {"pdf": null, "forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"order": 4, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv.", "value-regex": "upload|http://arxiv.org/pdf/.+"}, "title": {"order": 3, "description": "Title of paper.", "value-regex": ".{0,500}"}, "abstract": {"order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"order": 1, "description": "Comma separated list of author names, as they appear in the paper.", "value-regex": "[^,\\n]+(,[^,\\n]+)*"}, "author_emails": {"order": 2, "description": "Comma separated list of author email addresses, in the same order as above.", "value-regex": "[^,\\n]+(,[^,\\n]+)*"}, "conflicts": {"order": 100, "description": "Semi-colon separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.).", "value-regex": "^([a-zA-Z0-9][a-zA-Z0-9-_]{0,61}[a-zA-Z0-9]{0,1}\\.([a-zA-Z]{1,6}|[a-zA-Z0-9-]{1,30}\\.[a-zA-Z]{2,3}))+(;[a-zA-Z0-9][a-zA-Z0-9-_]{0,61}[a-zA-Z0-9]{0,1}\\.([a-zA-Z]{1,6}|[a-zA-Z0-9-]{1,30}\\.[a-zA-Z]{2,3}))*$"}, "CMT_id": {"order": 5, "value-regex": ".*", "description": "If the paper is a resubmission from the ICLR 2016 Conference Track, enter its CMT ID; otherwise, leave blank."}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "expdate": 1463609700000}}}], "count": 4}