{"notes": [{"id": "rkx3-04FwB", "original": "ryxDLvE_DH", "number": 980, "cdate": 1569439235971, "ddate": null, "tcdate": 1569439235971, "tmdate": 1577168241681, "tddate": null, "forum": "rkx3-04FwB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["johnpalowitch@gmail.com", "bperozzi@acm.org"], "title": "MONET: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit", "authors": ["John Palowitch", "Bryan Perozzi"], "pdf": "/pdf/ca4f13a67f969d7f1835d82c72c48c403525bedc.pdf", "TL;DR": "Introduces a novel graph neural network method for debiasing graph embeddings from metadata and embedding the metadata effect.", "abstract": "Are Graph Neural Networks (GNNs) fair? In many real world graphs, the formation of edges is related to certain node attributes (e.g. gender, community, reputation). In this case, any GNN using these edges will be biased by this information, as it is encoded in the structure of the adjacency matrix itself.  In this paper, we show that when metadata is correlated with the formation of node neighborhoods, unsupervised node embedding dimensions learn this metadata. This bias implies an inability to control for important covariates in real-world applications, such as recommendation systems. \n\nTo solve these issues, we introduce the Metadata-Orthogonal Node Embedding Training (MONET) unit, a general model for debiasing embeddings of nodes in a graph. MONET achieves this by ensuring that the node embeddings are trained on a hyperplane orthogonal to that of the node metadata. This effectively organizes unstructured embedding dimensions into an interpretable topology-only, metadata-only division with no linear interactions. We illustrate the effectiveness of MONET though our experiments on a variety of real world graphs, which shows that our method can learn and remove the effect of arbitrary covariates in tasks such as preventing the leakage of political party affiliation in a blog network, and thwarting the gaming of embedding-based recommendation systems.", "keywords": ["Graph Embeddings", "Representation Learning"], "paperhash": "palowitch|monet_debiasing_graph_embeddings_via_the_metadataorthogonal_training_unit", "original_pdf": "/attachment/4f137657ceb118d5033f7a4de34f70789cedc640.pdf", "_bibtex": "@misc{\npalowitch2020monet,\ntitle={{\\{}MONET{\\}}: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit},\nauthor={John Palowitch and Bryan Perozzi},\nyear={2020},\nurl={https://openreview.net/forum?id=rkx3-04FwB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "knvcLk5Usn", "original": null, "number": 1, "cdate": 1576798711356, "ddate": null, "tcdate": 1576798711356, "tmdate": 1576800925005, "tddate": null, "forum": "rkx3-04FwB", "replyto": "rkx3-04FwB", "invitation": "ICLR.cc/2020/Conference/Paper980/-/Decision", "content": {"decision": "Reject", "comment": "This work presents a method for debiasing graph embeddings. The main concerns for the work were originally identified by Reviewer 3, who pointed out that the method is only capable of linear debiasing. Authors responded by updating the manuscript in several places to mention this limitation as well as adding Table 3 to the Appendix showing that SVM's with non-linear kernels are still able to identify bias in the embeddings. Reviewers agreed that this addition improved the manuscript, however some reviewers still had concerns about the revised manuscript. This AC has several recommendations for improving the paper. First additional revision is needed to better address the limitations of linear debiasing, for example Table 1 still reads \"MONET is successful in removing all metadata information from the topology embeddings \u2013 the links in the graph are no longer an effective predictor of political party\".  Statements like this are a bit misleading, as the embeddings will still be biased with respect to a non-linear classifiers (as evident by Table 3). Additionally, updating Table 1 and related experiments to measure embedding bias with respect to non-linear classifiers would help clarify the limitations for perspective readers. Second, the paper should be updated to address remaining concerns that the linear debiasing assumption limits the applicability of the method. One could either discuss or demonstrate additional applications of the method that work even with the linear assumption, extend MONET so it can improve model bias with respect to non-linear classifiers, or show that MONET still outperforms baselines when the non-linear assumption is violated.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["johnpalowitch@gmail.com", "bperozzi@acm.org"], "title": "MONET: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit", "authors": ["John Palowitch", "Bryan Perozzi"], "pdf": "/pdf/ca4f13a67f969d7f1835d82c72c48c403525bedc.pdf", "TL;DR": "Introduces a novel graph neural network method for debiasing graph embeddings from metadata and embedding the metadata effect.", "abstract": "Are Graph Neural Networks (GNNs) fair? In many real world graphs, the formation of edges is related to certain node attributes (e.g. gender, community, reputation). In this case, any GNN using these edges will be biased by this information, as it is encoded in the structure of the adjacency matrix itself.  In this paper, we show that when metadata is correlated with the formation of node neighborhoods, unsupervised node embedding dimensions learn this metadata. This bias implies an inability to control for important covariates in real-world applications, such as recommendation systems. \n\nTo solve these issues, we introduce the Metadata-Orthogonal Node Embedding Training (MONET) unit, a general model for debiasing embeddings of nodes in a graph. MONET achieves this by ensuring that the node embeddings are trained on a hyperplane orthogonal to that of the node metadata. This effectively organizes unstructured embedding dimensions into an interpretable topology-only, metadata-only division with no linear interactions. We illustrate the effectiveness of MONET though our experiments on a variety of real world graphs, which shows that our method can learn and remove the effect of arbitrary covariates in tasks such as preventing the leakage of political party affiliation in a blog network, and thwarting the gaming of embedding-based recommendation systems.", "keywords": ["Graph Embeddings", "Representation Learning"], "paperhash": "palowitch|monet_debiasing_graph_embeddings_via_the_metadataorthogonal_training_unit", "original_pdf": "/attachment/4f137657ceb118d5033f7a4de34f70789cedc640.pdf", "_bibtex": "@misc{\npalowitch2020monet,\ntitle={{\\{}MONET{\\}}: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit},\nauthor={John Palowitch and Bryan Perozzi},\nyear={2020},\nurl={https://openreview.net/forum?id=rkx3-04FwB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "rkx3-04FwB", "replyto": "rkx3-04FwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795703672, "tmdate": 1576800251094, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper980/-/Decision"}}}, {"id": "Bye6Jh_TFB", "original": null, "number": 1, "cdate": 1571814373435, "ddate": null, "tcdate": 1571814373435, "tmdate": 1574711687227, "tddate": null, "forum": "rkx3-04FwB", "replyto": "rkx3-04FwB", "invitation": "ICLR.cc/2020/Conference/Paper980/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #1", "review": "Summary: The paper introduces a GNN model (MONET) for debiasing graph embeddings, by enforcing orthogonality between the embedding spaces of the graph topology & the graph metadata. They show that unsupervised learning induces bias from important graph metadata, when the metadata is correlated with the node edges. They show experimental results on real world graphs (political blogs network & graph-based recommendation systems), where MONET can debias  graph embeddings and prevent metadata leakage.\n\nDecision: Accept\n\nReasons for the decision: The paper is clearly written, well-motivated, and well-organized. The proposed algorithm and analysis seem insightful & novel, and the experimental results (showing that MONET can debias metadata from topology) are convincing.\n\nAdditional Feedback:\n\n1) It would be helpful to show results on at least one other graph embedding model other than GloVe, to empirically substantiate the claim that MONET is \u201cbroadly generalizable\u201d.\n\n2) In Section 3.4 [Algorithmic Complexity], it would be helpful to compare the wall clock time of MONET vs. the baselines (DeepWalk, GloVe), to give a better sense of how expensive the SVD calculation is.\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper980/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper980/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["johnpalowitch@gmail.com", "bperozzi@acm.org"], "title": "MONET: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit", "authors": ["John Palowitch", "Bryan Perozzi"], "pdf": "/pdf/ca4f13a67f969d7f1835d82c72c48c403525bedc.pdf", "TL;DR": "Introduces a novel graph neural network method for debiasing graph embeddings from metadata and embedding the metadata effect.", "abstract": "Are Graph Neural Networks (GNNs) fair? In many real world graphs, the formation of edges is related to certain node attributes (e.g. gender, community, reputation). In this case, any GNN using these edges will be biased by this information, as it is encoded in the structure of the adjacency matrix itself.  In this paper, we show that when metadata is correlated with the formation of node neighborhoods, unsupervised node embedding dimensions learn this metadata. This bias implies an inability to control for important covariates in real-world applications, such as recommendation systems. \n\nTo solve these issues, we introduce the Metadata-Orthogonal Node Embedding Training (MONET) unit, a general model for debiasing embeddings of nodes in a graph. MONET achieves this by ensuring that the node embeddings are trained on a hyperplane orthogonal to that of the node metadata. This effectively organizes unstructured embedding dimensions into an interpretable topology-only, metadata-only division with no linear interactions. We illustrate the effectiveness of MONET though our experiments on a variety of real world graphs, which shows that our method can learn and remove the effect of arbitrary covariates in tasks such as preventing the leakage of political party affiliation in a blog network, and thwarting the gaming of embedding-based recommendation systems.", "keywords": ["Graph Embeddings", "Representation Learning"], "paperhash": "palowitch|monet_debiasing_graph_embeddings_via_the_metadataorthogonal_training_unit", "original_pdf": "/attachment/4f137657ceb118d5033f7a4de34f70789cedc640.pdf", "_bibtex": "@misc{\npalowitch2020monet,\ntitle={{\\{}MONET{\\}}: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit},\nauthor={John Palowitch and Bryan Perozzi},\nyear={2020},\nurl={https://openreview.net/forum?id=rkx3-04FwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkx3-04FwB", "replyto": "rkx3-04FwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper980/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper980/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575489917831, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper980/Reviewers"], "noninvitees": [], "tcdate": 1570237744146, "tmdate": 1575489917842, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper980/-/Official_Review"}}}, {"id": "S1lWDbG0FH", "original": null, "number": 2, "cdate": 1571852632871, "ddate": null, "tcdate": 1571852632871, "tmdate": 1574464779596, "tddate": null, "forum": "rkx3-04FwB", "replyto": "rkx3-04FwB", "invitation": "ICLR.cc/2020/Conference/Paper980/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #2", "review": "The paper presents an approach to debiasing graph embeddings from known, given node attributes/metadata.\nSpecifically, the paper proposes to learn an embedding that is orthogonal to given node attributes, ensuring that there is no *linear* function which can extract the node attributes from the learned embedding.\n\n\nStrength:\n-\tThe paper addresses an interesting and relevant problem on debiasing graph embeddings.\n-\tThe paper presents a, to my knowledge, novel approach, to avoid the leakage of meta-data in the embedding, effectively debiasing it from this information (although some discussion of prior should be addressed, see below)\n-\tThe paper shows that the approach is effective compared to two baselines on two datasets (although some aspects of the experiments can be improved, see below)\n\nWeaknesses:\n1.\tExperimental evaluation:\n1.1.\tThe paper only evaluates on the training set. Specifically, in experiment 1, the paper learns an embedding and supervises it to be orthogonal to given labels; this is good, but it also somewhat expected that this could be learned when tested on the same dataset. An important question is, if the model actually learned a generalizable embedding or just overfit to the training set. If the learned embedding is applied to new data, is it still not possible to extract political affiliation from it?\nI would suggest splitting the dataset in two part: One part to train the debiased embedding and one to train and test the Linear SVM.\n1.2.\tIt would be great if the authors describe better and quantify how they ensure in experiment 1 that the learned embedding of the MONET model is measured, and how this compares to the three baselines (e.g. a random or constant embedding would also be perfectly debiased).\n1.3.\tWhile the paper clearly states that the approach is restricted to linear relationships, it would be interesting to look at non-linear classifiers and see how well this works in practice, also in comparison to the baselines.\n1.4.\tFigure 3(c) visualizes that \n2.\tRelated work:\n2.1.\tThe comparison to related work could be improved. Specifically, a discussion relating this work to adversarial training, e.g. as in domain confusion networks [A] or in [5].\n2.2.\tThe authors argue that [5] is independent/concurrent work. I agree with the authors that [5] is sufficiently different to this work, but it should be discussed thoroughly as it has been published at ICML 2019. Unfortunately, the authors also miss to include in the references that it has been published at ICML 2019.\n\n\nWhile the paper explores an interesting direction and approach, there are several concerns which speak against acceptance (see Weaknesses above); however, I believe they can be a addressed/clarified in a further revision.\n\n\nReferences:\n[A] Tzeng et al, Adversarial Discriminative Domain Adaptation, CVPR 2017\n\n\n=== Post author response\nI thank the authors for their response and additions as well as clarifications.\n\nI agree to other reviewers, that the limitation to linear de-biasing is a concern for the paper, but the authors have clarified it now in the abstract an other locations; the additional experiments with and RBF kernel have shown that  indeed the formulation only does mainly do linear decorrelation. \n\nTable 3 could be further clarified (what is the goal? 50% accuracy, i.e. chance level?) and made more similar to Table 1, or ideally merged with it. \n\nIt is also a bit unfortunate that all this additions are in supplement and not merged in the main paper.\n\nOverall I still lean more towards accept.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper980/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper980/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["johnpalowitch@gmail.com", "bperozzi@acm.org"], "title": "MONET: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit", "authors": ["John Palowitch", "Bryan Perozzi"], "pdf": "/pdf/ca4f13a67f969d7f1835d82c72c48c403525bedc.pdf", "TL;DR": "Introduces a novel graph neural network method for debiasing graph embeddings from metadata and embedding the metadata effect.", "abstract": "Are Graph Neural Networks (GNNs) fair? In many real world graphs, the formation of edges is related to certain node attributes (e.g. gender, community, reputation). In this case, any GNN using these edges will be biased by this information, as it is encoded in the structure of the adjacency matrix itself.  In this paper, we show that when metadata is correlated with the formation of node neighborhoods, unsupervised node embedding dimensions learn this metadata. This bias implies an inability to control for important covariates in real-world applications, such as recommendation systems. \n\nTo solve these issues, we introduce the Metadata-Orthogonal Node Embedding Training (MONET) unit, a general model for debiasing embeddings of nodes in a graph. MONET achieves this by ensuring that the node embeddings are trained on a hyperplane orthogonal to that of the node metadata. This effectively organizes unstructured embedding dimensions into an interpretable topology-only, metadata-only division with no linear interactions. We illustrate the effectiveness of MONET though our experiments on a variety of real world graphs, which shows that our method can learn and remove the effect of arbitrary covariates in tasks such as preventing the leakage of political party affiliation in a blog network, and thwarting the gaming of embedding-based recommendation systems.", "keywords": ["Graph Embeddings", "Representation Learning"], "paperhash": "palowitch|monet_debiasing_graph_embeddings_via_the_metadataorthogonal_training_unit", "original_pdf": "/attachment/4f137657ceb118d5033f7a4de34f70789cedc640.pdf", "_bibtex": "@misc{\npalowitch2020monet,\ntitle={{\\{}MONET{\\}}: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit},\nauthor={John Palowitch and Bryan Perozzi},\nyear={2020},\nurl={https://openreview.net/forum?id=rkx3-04FwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkx3-04FwB", "replyto": "rkx3-04FwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper980/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper980/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575489917831, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper980/Reviewers"], "noninvitees": [], "tcdate": 1570237744146, "tmdate": 1575489917842, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper980/-/Official_Review"}}}, {"id": "ryerBa9nsB", "original": null, "number": 7, "cdate": 1573854525156, "ddate": null, "tcdate": 1573854525156, "tmdate": 1573854525156, "tddate": null, "forum": "rkx3-04FwB", "replyto": "Bye6Jh_TFB", "invitation": "ICLR.cc/2020/Conference/Paper980/-/Official_Comment", "content": {"title": "Author Response 2: addition of MONET-DeepWalk implementation", "comment": "Fortunately, we were able to complete the implementation of MONET into the DeepWalk loss. Results from the new method MONET_D are now compared in the experiments, and the implementation is explained fully in  the Appendix. \nThe code we will release includes implementations of both MONET_G and MONET_D."}, "signatures": ["ICLR.cc/2020/Conference/Paper980/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper980/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["johnpalowitch@gmail.com", "bperozzi@acm.org"], "title": "MONET: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit", "authors": ["John Palowitch", "Bryan Perozzi"], "pdf": "/pdf/ca4f13a67f969d7f1835d82c72c48c403525bedc.pdf", "TL;DR": "Introduces a novel graph neural network method for debiasing graph embeddings from metadata and embedding the metadata effect.", "abstract": "Are Graph Neural Networks (GNNs) fair? In many real world graphs, the formation of edges is related to certain node attributes (e.g. gender, community, reputation). In this case, any GNN using these edges will be biased by this information, as it is encoded in the structure of the adjacency matrix itself.  In this paper, we show that when metadata is correlated with the formation of node neighborhoods, unsupervised node embedding dimensions learn this metadata. This bias implies an inability to control for important covariates in real-world applications, such as recommendation systems. \n\nTo solve these issues, we introduce the Metadata-Orthogonal Node Embedding Training (MONET) unit, a general model for debiasing embeddings of nodes in a graph. MONET achieves this by ensuring that the node embeddings are trained on a hyperplane orthogonal to that of the node metadata. This effectively organizes unstructured embedding dimensions into an interpretable topology-only, metadata-only division with no linear interactions. We illustrate the effectiveness of MONET though our experiments on a variety of real world graphs, which shows that our method can learn and remove the effect of arbitrary covariates in tasks such as preventing the leakage of political party affiliation in a blog network, and thwarting the gaming of embedding-based recommendation systems.", "keywords": ["Graph Embeddings", "Representation Learning"], "paperhash": "palowitch|monet_debiasing_graph_embeddings_via_the_metadataorthogonal_training_unit", "original_pdf": "/attachment/4f137657ceb118d5033f7a4de34f70789cedc640.pdf", "_bibtex": "@misc{\npalowitch2020monet,\ntitle={{\\{}MONET{\\}}: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit},\nauthor={John Palowitch and Bryan Perozzi},\nyear={2020},\nurl={https://openreview.net/forum?id=rkx3-04FwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkx3-04FwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper980/Authors", "ICLR.cc/2020/Conference/Paper980/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper980/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper980/Reviewers", "ICLR.cc/2020/Conference/Paper980/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper980/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper980/Authors|ICLR.cc/2020/Conference/Paper980/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504163143, "tmdate": 1576860550522, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper980/Authors", "ICLR.cc/2020/Conference/Paper980/Reviewers", "ICLR.cc/2020/Conference/Paper980/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper980/-/Official_Comment"}}}, {"id": "BkeWkT93jB", "original": null, "number": 6, "cdate": 1573854424563, "ddate": null, "tcdate": 1573854424563, "tmdate": 1573854424563, "tddate": null, "forum": "rkx3-04FwB", "replyto": "Bke4vIkIcr", "invitation": "ICLR.cc/2020/Conference/Paper980/-/Official_Comment", "content": {"title": "Author Response 2: addition of adversarial baseline", "comment": "Fortunately, we were able to implement an attribute adversary into our GloVe model using the framework in [1]. All references to adversarial learning work you gave (and others mentioned by other reviewers) are extremely relevant, and aim to solve closely related problems. We discuss them in our related work section. However, none of the associated models apply directly to our problem, unless one makes significant modifications (verging on novel work). Therefore we decided to directly adapt a fundamental adversarial learner (from [1]) to our GloVe trainer. To our knowledge, this is actually a novel (though naive and preliminary) incorporation of adversarial learning in unsupervised GNNs. While by no means a mature and complete approach to the problem, we believe it helps shed light on how a comparable adversarial approach would work as an alternative to MONET. The option to use the adversarial loss will be available in the code we are open sourcing as a reference implementation of the ideas discussed in the paper.\n\nSince our last update we have added a paragraph about the connection to adversarial networks in our Methods section (S 3.4). We now describe our adversarial baseline in the beginning of the experiments section and more fully in the Appendix. Note that the shilling experiment involves real-valued attributes, which requires a different type of adversarial network than that needed for the political blogs experiment. We consider the development of multiple adversaries in our unsupervised setting beyond the scope of this paper, so we use the adversary baseline only for the first experiment.\n\n\n[1] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. In Advances in neural information processing systems, pages 2672\u20132680, 2014."}, "signatures": ["ICLR.cc/2020/Conference/Paper980/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper980/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["johnpalowitch@gmail.com", "bperozzi@acm.org"], "title": "MONET: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit", "authors": ["John Palowitch", "Bryan Perozzi"], "pdf": "/pdf/ca4f13a67f969d7f1835d82c72c48c403525bedc.pdf", "TL;DR": "Introduces a novel graph neural network method for debiasing graph embeddings from metadata and embedding the metadata effect.", "abstract": "Are Graph Neural Networks (GNNs) fair? In many real world graphs, the formation of edges is related to certain node attributes (e.g. gender, community, reputation). In this case, any GNN using these edges will be biased by this information, as it is encoded in the structure of the adjacency matrix itself.  In this paper, we show that when metadata is correlated with the formation of node neighborhoods, unsupervised node embedding dimensions learn this metadata. This bias implies an inability to control for important covariates in real-world applications, such as recommendation systems. \n\nTo solve these issues, we introduce the Metadata-Orthogonal Node Embedding Training (MONET) unit, a general model for debiasing embeddings of nodes in a graph. MONET achieves this by ensuring that the node embeddings are trained on a hyperplane orthogonal to that of the node metadata. This effectively organizes unstructured embedding dimensions into an interpretable topology-only, metadata-only division with no linear interactions. We illustrate the effectiveness of MONET though our experiments on a variety of real world graphs, which shows that our method can learn and remove the effect of arbitrary covariates in tasks such as preventing the leakage of political party affiliation in a blog network, and thwarting the gaming of embedding-based recommendation systems.", "keywords": ["Graph Embeddings", "Representation Learning"], "paperhash": "palowitch|monet_debiasing_graph_embeddings_via_the_metadataorthogonal_training_unit", "original_pdf": "/attachment/4f137657ceb118d5033f7a4de34f70789cedc640.pdf", "_bibtex": "@misc{\npalowitch2020monet,\ntitle={{\\{}MONET{\\}}: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit},\nauthor={John Palowitch and Bryan Perozzi},\nyear={2020},\nurl={https://openreview.net/forum?id=rkx3-04FwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkx3-04FwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper980/Authors", "ICLR.cc/2020/Conference/Paper980/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper980/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper980/Reviewers", "ICLR.cc/2020/Conference/Paper980/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper980/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper980/Authors|ICLR.cc/2020/Conference/Paper980/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504163143, "tmdate": 1576860550522, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper980/Authors", "ICLR.cc/2020/Conference/Paper980/Reviewers", "ICLR.cc/2020/Conference/Paper980/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper980/-/Official_Comment"}}}, {"id": "rJec8hGtiB", "original": null, "number": 4, "cdate": 1573624913971, "ddate": null, "tcdate": 1573624913971, "tmdate": 1573624913971, "tddate": null, "forum": "rkx3-04FwB", "replyto": "Bye6Jh_TFB", "invitation": "ICLR.cc/2020/Conference/Paper980/-/Official_Comment", "content": {"title": "Author Response 1", "comment": "We appreciate the suggestions. In the Appendix, we now display the wall clock time for all methods involved in the political blogs experiment. We added a reference to that table in Section 3.4.\n\nRegarding results from another graph embedding model with MONET, we are currently working on an implementation of DeepWalk with MONET, which we hope to have completed by the end of the discussion period. Note that we have described the MONET version of DeepWalk in Section 3.1 (Equation 3)."}, "signatures": ["ICLR.cc/2020/Conference/Paper980/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper980/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["johnpalowitch@gmail.com", "bperozzi@acm.org"], "title": "MONET: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit", "authors": ["John Palowitch", "Bryan Perozzi"], "pdf": "/pdf/ca4f13a67f969d7f1835d82c72c48c403525bedc.pdf", "TL;DR": "Introduces a novel graph neural network method for debiasing graph embeddings from metadata and embedding the metadata effect.", "abstract": "Are Graph Neural Networks (GNNs) fair? In many real world graphs, the formation of edges is related to certain node attributes (e.g. gender, community, reputation). In this case, any GNN using these edges will be biased by this information, as it is encoded in the structure of the adjacency matrix itself.  In this paper, we show that when metadata is correlated with the formation of node neighborhoods, unsupervised node embedding dimensions learn this metadata. This bias implies an inability to control for important covariates in real-world applications, such as recommendation systems. \n\nTo solve these issues, we introduce the Metadata-Orthogonal Node Embedding Training (MONET) unit, a general model for debiasing embeddings of nodes in a graph. MONET achieves this by ensuring that the node embeddings are trained on a hyperplane orthogonal to that of the node metadata. This effectively organizes unstructured embedding dimensions into an interpretable topology-only, metadata-only division with no linear interactions. We illustrate the effectiveness of MONET though our experiments on a variety of real world graphs, which shows that our method can learn and remove the effect of arbitrary covariates in tasks such as preventing the leakage of political party affiliation in a blog network, and thwarting the gaming of embedding-based recommendation systems.", "keywords": ["Graph Embeddings", "Representation Learning"], "paperhash": "palowitch|monet_debiasing_graph_embeddings_via_the_metadataorthogonal_training_unit", "original_pdf": "/attachment/4f137657ceb118d5033f7a4de34f70789cedc640.pdf", "_bibtex": "@misc{\npalowitch2020monet,\ntitle={{\\{}MONET{\\}}: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit},\nauthor={John Palowitch and Bryan Perozzi},\nyear={2020},\nurl={https://openreview.net/forum?id=rkx3-04FwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkx3-04FwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper980/Authors", "ICLR.cc/2020/Conference/Paper980/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper980/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper980/Reviewers", "ICLR.cc/2020/Conference/Paper980/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper980/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper980/Authors|ICLR.cc/2020/Conference/Paper980/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504163143, "tmdate": 1576860550522, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper980/Authors", "ICLR.cc/2020/Conference/Paper980/Reviewers", "ICLR.cc/2020/Conference/Paper980/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper980/-/Official_Comment"}}}, {"id": "B1gzMsfFsS", "original": null, "number": 3, "cdate": 1573624586220, "ddate": null, "tcdate": 1573624586220, "tmdate": 1573624586220, "tddate": null, "forum": "rkx3-04FwB", "replyto": "S1lWDbG0FH", "invitation": "ICLR.cc/2020/Conference/Paper980/-/Official_Comment", "content": {"title": "Author Response 1", "comment": "We appreciate the comments and interesting considerations. To examine whether MONET can learn a \"generalizable embedding\", we split the graph into two parts, and train a MONET model on the first part. We then use the metadata transformation from that restricted MONET model to debias the usual DeepWalk embeddings of those nodes. In the Appendix, we show that this process is able to debias the held-out data effectively, evaluating at a full range of sizes for the held-out set.\n\nThe issue of embedding quality after debiasing is a good question. We have added the \"Embedding Distance Correlation to GloVe\" metric to the political blogs experiment (now shown in the Appendix). This measures the correlation of pairwise embedding distances between GloVe and the various other methods. We have also added a random embeddings baseline to that experiment. We find that MONET embedding distances are significantly more correlated to GloVe distances than the random baseline, and that the random baseline is actually significantly biased, on average (randomly generated embeddings are never perfectly linearly separated from any given sensitive attribute).\n\nOn the political blogs data, we have also added political affiliation classification results using a non-linear SVM (using an RBF kernel), in response to your question about the application of non-linear classifiers. We find that, while MONET is still less biased than the baselines, the gap diminishes drastically, and the classifier performs quite well even on MONET embeddings. \nWe think that researching a non-linear correction in the style of MONET is an exciting area for future work.\n\nWe have now properly cited Bose and Hamilton (2019), and added a substantial discussion of related work from the field of adversarial learning."}, "signatures": ["ICLR.cc/2020/Conference/Paper980/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper980/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["johnpalowitch@gmail.com", "bperozzi@acm.org"], "title": "MONET: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit", "authors": ["John Palowitch", "Bryan Perozzi"], "pdf": "/pdf/ca4f13a67f969d7f1835d82c72c48c403525bedc.pdf", "TL;DR": "Introduces a novel graph neural network method for debiasing graph embeddings from metadata and embedding the metadata effect.", "abstract": "Are Graph Neural Networks (GNNs) fair? In many real world graphs, the formation of edges is related to certain node attributes (e.g. gender, community, reputation). In this case, any GNN using these edges will be biased by this information, as it is encoded in the structure of the adjacency matrix itself.  In this paper, we show that when metadata is correlated with the formation of node neighborhoods, unsupervised node embedding dimensions learn this metadata. This bias implies an inability to control for important covariates in real-world applications, such as recommendation systems. \n\nTo solve these issues, we introduce the Metadata-Orthogonal Node Embedding Training (MONET) unit, a general model for debiasing embeddings of nodes in a graph. MONET achieves this by ensuring that the node embeddings are trained on a hyperplane orthogonal to that of the node metadata. This effectively organizes unstructured embedding dimensions into an interpretable topology-only, metadata-only division with no linear interactions. We illustrate the effectiveness of MONET though our experiments on a variety of real world graphs, which shows that our method can learn and remove the effect of arbitrary covariates in tasks such as preventing the leakage of political party affiliation in a blog network, and thwarting the gaming of embedding-based recommendation systems.", "keywords": ["Graph Embeddings", "Representation Learning"], "paperhash": "palowitch|monet_debiasing_graph_embeddings_via_the_metadataorthogonal_training_unit", "original_pdf": "/attachment/4f137657ceb118d5033f7a4de34f70789cedc640.pdf", "_bibtex": "@misc{\npalowitch2020monet,\ntitle={{\\{}MONET{\\}}: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit},\nauthor={John Palowitch and Bryan Perozzi},\nyear={2020},\nurl={https://openreview.net/forum?id=rkx3-04FwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkx3-04FwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper980/Authors", "ICLR.cc/2020/Conference/Paper980/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper980/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper980/Reviewers", "ICLR.cc/2020/Conference/Paper980/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper980/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper980/Authors|ICLR.cc/2020/Conference/Paper980/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504163143, "tmdate": 1576860550522, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper980/Authors", "ICLR.cc/2020/Conference/Paper980/Reviewers", "ICLR.cc/2020/Conference/Paper980/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper980/-/Official_Comment"}}}, {"id": "SkgQ3qfFiB", "original": null, "number": 2, "cdate": 1573624491275, "ddate": null, "tcdate": 1573624491275, "tmdate": 1573624491275, "tddate": null, "forum": "rkx3-04FwB", "replyto": "Bke4vIkIcr", "invitation": "ICLR.cc/2020/Conference/Paper980/-/Official_Comment", "content": {"title": "Author Response 1", "comment": "We appreciate the careful criticisms and the deep understanding of our work. We have made sure to clearly state the linear nature of MONET debiasing in the abstract, in our list of contributions in the introduction, and in our conclusion. We have also changed statements about the \"independence\" of metadata and topology embeddings to \"decorrelated\". We agree, as you wrote, that MONET is a partial solution to the problem of complete debiasing of unsupervised graph embeddings. That being said, we argue that MONET remains a useful first step in this area. As we show in the shilling attack experiment, MONET substantially reduces bias when embeddings are used for simple nearest-neighbor lookups, which is a common application in graph-based recommender systems. We have added a discussion about this to our conclusion.\n\nAdditionally, in response to your suggestions and those of the second reviewer, we have added results from a non-linear SVM applied to political blog embeddings, showing that indeed non-linear classifiers still work well on MONET-debiased embeddings. We added a reference to these metrics in the main text.\nWe look forward to investigating non-linear corrections in the style of MONET in our future work in the area.\n\nWe like your suggestion to compare against adversarial or information bottleneck baselines.  We looked into the code bases for the references you listed (and others), but couldn't find any off-the-shelf implementations for unsupervised debiasing that were directly applicable to our problem.  Are you aware of any?\n\nIn lieu of a reusable baseline, we have started adapting a couple existing methods that seemed close ([1], [2]).  Unfortunately this has gone slowly - the adversarial methods have been non-trivial to adapt to our setting, and cumbersome to train.  We can add the current results to the manuscript, but we would prefer to wait and tune the baselines further. (We will complete this ASAP, but likely not before the rebuttal period is over.)\n\n\n[1] A. J. Bose and W. L. Hamilton.  Compositional fairness constraints for graph embeddings. Proceedings of the 36th International Conference on Machine Learning, 2019.\n\n[2] B. H. Zhang, B. Lemoine, and M. Mitchell.   Mitigating unwanted biases with adversarial learning. In Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society, pages335\u2013340. ACM, 2018."}, "signatures": ["ICLR.cc/2020/Conference/Paper980/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper980/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["johnpalowitch@gmail.com", "bperozzi@acm.org"], "title": "MONET: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit", "authors": ["John Palowitch", "Bryan Perozzi"], "pdf": "/pdf/ca4f13a67f969d7f1835d82c72c48c403525bedc.pdf", "TL;DR": "Introduces a novel graph neural network method for debiasing graph embeddings from metadata and embedding the metadata effect.", "abstract": "Are Graph Neural Networks (GNNs) fair? In many real world graphs, the formation of edges is related to certain node attributes (e.g. gender, community, reputation). In this case, any GNN using these edges will be biased by this information, as it is encoded in the structure of the adjacency matrix itself.  In this paper, we show that when metadata is correlated with the formation of node neighborhoods, unsupervised node embedding dimensions learn this metadata. This bias implies an inability to control for important covariates in real-world applications, such as recommendation systems. \n\nTo solve these issues, we introduce the Metadata-Orthogonal Node Embedding Training (MONET) unit, a general model for debiasing embeddings of nodes in a graph. MONET achieves this by ensuring that the node embeddings are trained on a hyperplane orthogonal to that of the node metadata. This effectively organizes unstructured embedding dimensions into an interpretable topology-only, metadata-only division with no linear interactions. We illustrate the effectiveness of MONET though our experiments on a variety of real world graphs, which shows that our method can learn and remove the effect of arbitrary covariates in tasks such as preventing the leakage of political party affiliation in a blog network, and thwarting the gaming of embedding-based recommendation systems.", "keywords": ["Graph Embeddings", "Representation Learning"], "paperhash": "palowitch|monet_debiasing_graph_embeddings_via_the_metadataorthogonal_training_unit", "original_pdf": "/attachment/4f137657ceb118d5033f7a4de34f70789cedc640.pdf", "_bibtex": "@misc{\npalowitch2020monet,\ntitle={{\\{}MONET{\\}}: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit},\nauthor={John Palowitch and Bryan Perozzi},\nyear={2020},\nurl={https://openreview.net/forum?id=rkx3-04FwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "rkx3-04FwB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper980/Authors", "ICLR.cc/2020/Conference/Paper980/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper980/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper980/Reviewers", "ICLR.cc/2020/Conference/Paper980/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper980/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper980/Authors|ICLR.cc/2020/Conference/Paper980/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504163143, "tmdate": 1576860550522, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper980/Authors", "ICLR.cc/2020/Conference/Paper980/Reviewers", "ICLR.cc/2020/Conference/Paper980/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper980/-/Official_Comment"}}}, {"id": "Bke4vIkIcr", "original": null, "number": 3, "cdate": 1572365915785, "ddate": null, "tcdate": 1572365915785, "tmdate": 1572972527682, "tddate": null, "forum": "rkx3-04FwB", "replyto": "rkx3-04FwB", "invitation": "ICLR.cc/2020/Conference/Paper980/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "TLDR: split node embeddings into medatadata and graph structure, force them to be orthogonal.\n\nThe paper proposes to split node embeddings in a graph into two parts:\n1. graph structure embeddings: Es\n2. known node metadata embeddings: Em\nTo prevent Es from containing information about Em, the authors propose a scheme which puts Es into the Nullspace of Em through repeated SVD factorizations. This prevents linear classifiers that operate on Es to reliably predict information in Em.\n\nThe weakness of the paper stems from the proposed definition of debiasing. Just like two random variables can be dependent, but have a linear correlation coefficient of 0, in the proposed method the two embeddings may be linearly unrelated, but have a strong non-linear relationship.\n\nThis is an important caveat that should be highlighted in the papers' abstract, not burried deep on p4, under Theorem 2. \n\nIn fact, looking at Fig 3c information about party affiliation follows a XOR-like pattern in the PCA space. This means that a linear classifier will fail (indeed the linear SVM in Table 1 fails), but a non-linear one should work OK. Thus, contrary to the abstract, the proposed method doesn't remove the effect of arbitrary covariates, but removes a LINEAR dependence. \n\nThus the paper proposes to solve an important problem and proposes a partial solution, but overstates the results in the abstract and hides the true efficiency of the method.\n\nAction items ot correct the paper:\n- be more honest about the true result. Decorrelation does not imply independence.\n- redo Table 1 with strong non-linear classifiers such a Gaussian SVM or Random Forest to show how much is not filtered out by your linear decorrelation method\n\nFinally, contrast with the adversarial information removal [1] and  the information bottleneck [2], both of which also promise to remove non-linear dependencies. It may happen that the you method works better, even though it only guarantees no linear dependencies.\n\n[1] https://arxiv.org/abs/1505.07818\n[2] D. Moyer, S. Gao, R. Brekelmans, A. Galstyan, and G. Ver Steeg, \u201cInvariant Representations without Adversarial Training,\u201d in Advances in Neural Information Processing Systems 31, 2018\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper980/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper980/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["johnpalowitch@gmail.com", "bperozzi@acm.org"], "title": "MONET: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit", "authors": ["John Palowitch", "Bryan Perozzi"], "pdf": "/pdf/ca4f13a67f969d7f1835d82c72c48c403525bedc.pdf", "TL;DR": "Introduces a novel graph neural network method for debiasing graph embeddings from metadata and embedding the metadata effect.", "abstract": "Are Graph Neural Networks (GNNs) fair? In many real world graphs, the formation of edges is related to certain node attributes (e.g. gender, community, reputation). In this case, any GNN using these edges will be biased by this information, as it is encoded in the structure of the adjacency matrix itself.  In this paper, we show that when metadata is correlated with the formation of node neighborhoods, unsupervised node embedding dimensions learn this metadata. This bias implies an inability to control for important covariates in real-world applications, such as recommendation systems. \n\nTo solve these issues, we introduce the Metadata-Orthogonal Node Embedding Training (MONET) unit, a general model for debiasing embeddings of nodes in a graph. MONET achieves this by ensuring that the node embeddings are trained on a hyperplane orthogonal to that of the node metadata. This effectively organizes unstructured embedding dimensions into an interpretable topology-only, metadata-only division with no linear interactions. We illustrate the effectiveness of MONET though our experiments on a variety of real world graphs, which shows that our method can learn and remove the effect of arbitrary covariates in tasks such as preventing the leakage of political party affiliation in a blog network, and thwarting the gaming of embedding-based recommendation systems.", "keywords": ["Graph Embeddings", "Representation Learning"], "paperhash": "palowitch|monet_debiasing_graph_embeddings_via_the_metadataorthogonal_training_unit", "original_pdf": "/attachment/4f137657ceb118d5033f7a4de34f70789cedc640.pdf", "_bibtex": "@misc{\npalowitch2020monet,\ntitle={{\\{}MONET{\\}}: Debiasing Graph Embeddings via the Metadata-Orthogonal Training Unit},\nauthor={John Palowitch and Bryan Perozzi},\nyear={2020},\nurl={https://openreview.net/forum?id=rkx3-04FwB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "rkx3-04FwB", "replyto": "rkx3-04FwB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper980/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper980/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575489917831, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper980/Reviewers"], "noninvitees": [], "tcdate": 1570237744146, "tmdate": 1575489917842, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper980/-/Official_Review"}}}], "count": 10}