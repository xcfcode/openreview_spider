{"notes": [{"id": "HJxWl0NKPB", "original": "ryl9Rf7uwr", "number": 919, "cdate": 1569439209239, "ddate": null, "tcdate": 1569439209239, "tmdate": 1577168213196, "tddate": null, "forum": "HJxWl0NKPB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Combining MixMatch and Active Learning for Better Accuracy with Fewer Labels", "authors": ["Shuang Song", "David Berthelot", "Afshin Rostamizadeh"], "authorids": ["shuangsong@google.com", "dberth@google.com", "rostami@google.com"], "keywords": ["active learning", "semi-supervised learning"], "TL;DR": "We combine MixMatch and active learning to obtain better accuracy with fewer labels and we follow this by a cost analysis comparing labeling data vs adding unlabeled data.. ", "abstract": "We propose using active learning based techniques to further improve the state-of-the-art semi-supervised learning MixMatch algorithm. We provide a thorough empirical evaluation of several active-learning and baseline methods, which successfully demonstrate a significant improvement on the benchmark CIFAR-10, CIFAR-100, and SVHN datasets (as much as 1.5% in absolute accuracy). \nWe also provide an empirical analysis of the cost trade-off between incrementally gathering more labeled versus unlabeled data. This analysis can be used to measure the relative value of labeled/unlabeled data at different points of the learning curve, where we find that although the incremental value of labeled data can be as much as 20x that of unlabeled, it quickly diminishes to less than 3x once more than 2,000 labeled example are observed.", "pdf": "/pdf/bf54be9e85eacea1c4b4cda9947859365afacf08.pdf", "paperhash": "song|combining_mixmatch_and_active_learning_for_better_accuracy_with_fewer_labels", "original_pdf": "/attachment/839f873a397082e4efb370a8462c0300c8235eb5.pdf", "_bibtex": "@misc{\nsong2020combining,\ntitle={Combining MixMatch and Active Learning for Better Accuracy with Fewer Labels},\nauthor={Shuang Song and David Berthelot and Afshin Rostamizadeh},\nyear={2020},\nurl={https://openreview.net/forum?id=HJxWl0NKPB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "mUBpUzTcGf", "original": null, "number": 1, "cdate": 1576798709729, "ddate": null, "tcdate": 1576798709729, "tmdate": 1576800926590, "tddate": null, "forum": "HJxWl0NKPB", "replyto": "HJxWl0NKPB", "invitation": "ICLR.cc/2020/Conference/Paper919/-/Decision", "content": {"decision": "Reject", "comment": "This paper extends state of the art semi-supervised learning techniques (i.e., MixMatch) to collect new data adaptively and studies the benefit of getting new labels versus adding more unlabeled data. Active learning is incorporated in a natural and simple (albeit, unsurprising) way and the experiments are convincing that this approach has merit.\n\nWhile the approach works, reviewers were concerned about the novelty of the combination given that its somewhat obvious and straightforward to accomplish. Reviewers were also concerned that the space of both semi-supervised learning algorithms and active learning algorithms was not sufficiently exhaustively studied. As one reviewer points out: neither of these ideas are new or particular to deep learning.\n\nDue to lack of novelty, this paper is not suited for a top tier conference. ", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Combining MixMatch and Active Learning for Better Accuracy with Fewer Labels", "authors": ["Shuang Song", "David Berthelot", "Afshin Rostamizadeh"], "authorids": ["shuangsong@google.com", "dberth@google.com", "rostami@google.com"], "keywords": ["active learning", "semi-supervised learning"], "TL;DR": "We combine MixMatch and active learning to obtain better accuracy with fewer labels and we follow this by a cost analysis comparing labeling data vs adding unlabeled data.. ", "abstract": "We propose using active learning based techniques to further improve the state-of-the-art semi-supervised learning MixMatch algorithm. We provide a thorough empirical evaluation of several active-learning and baseline methods, which successfully demonstrate a significant improvement on the benchmark CIFAR-10, CIFAR-100, and SVHN datasets (as much as 1.5% in absolute accuracy). \nWe also provide an empirical analysis of the cost trade-off between incrementally gathering more labeled versus unlabeled data. This analysis can be used to measure the relative value of labeled/unlabeled data at different points of the learning curve, where we find that although the incremental value of labeled data can be as much as 20x that of unlabeled, it quickly diminishes to less than 3x once more than 2,000 labeled example are observed.", "pdf": "/pdf/bf54be9e85eacea1c4b4cda9947859365afacf08.pdf", "paperhash": "song|combining_mixmatch_and_active_learning_for_better_accuracy_with_fewer_labels", "original_pdf": "/attachment/839f873a397082e4efb370a8462c0300c8235eb5.pdf", "_bibtex": "@misc{\nsong2020combining,\ntitle={Combining MixMatch and Active Learning for Better Accuracy with Fewer Labels},\nauthor={Shuang Song and David Berthelot and Afshin Rostamizadeh},\nyear={2020},\nurl={https://openreview.net/forum?id=HJxWl0NKPB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "HJxWl0NKPB", "replyto": "HJxWl0NKPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795713886, "tmdate": 1576800263606, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper919/-/Decision"}}}, {"id": "BkeRfPx2Kr", "original": null, "number": 2, "cdate": 1571714838081, "ddate": null, "tcdate": 1571714838081, "tmdate": 1574722107043, "tddate": null, "forum": "HJxWl0NKPB", "replyto": "HJxWl0NKPB", "invitation": "ICLR.cc/2020/Conference/Paper919/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #1", "review": "Summarize the paper:\n\nThis paper proposes a method that can deal with an active-learning scenario for the recently proposed semi-supervised learning method: MixMatch.  More specifically, the proposed method considers uncertainty measures to choose samples and a diversification step to ensure diversity within the sampled batch.  For uncertainty measures, the paper considers the simple maximum confidence and the gap between two most likely classes.  Additional augmentation techniques inspired from MixMatch are used.  For diversification, a clustering method and an information density method are considered.  Furthermore, the paper proposes a cost analysis model to compare labeled and unlabeled samples.  Experiments demonstrate the behavior of the proposed method.\n\n\nPros of the paper:\n\n- The experimental results seem to be strong and encouraging.\n- The discussions on the cost of labeled and unlabeled samples seems to be an important contribution for semi-supervised active learning.\n- The motivation and direction of the paper is simple and easy to follow: Take the state-of-the-art semi-supervised learning algorithm and propose an active-learning version of it.\n- It is not a straightforward combination of MixMatch and active learning, and there are some specialized techniques such as \u201caug\u201d used in the design of the proposed algorithm.\n\n\nCons of the paper:\n\n- Only uncertainty based sampling methods are considered, but is this enough?  There seems to be no other papers that deal with active semi-supervised learning for a deep learning context, so it might be important to really explore the many sampling methods (e.g., from survey of Settles 2009).\n\n- A more minor comment: The same issue goes for the semi-supervised learning side.  MixMatch is the state of the art in terms of accuracy for image domains, but it is an ensemble of several semi-supervised learning methods, and have strong assumptions, e.g., smoothness assumption, small distribution overlap, etc.  This will mean the proposed method will also have those strong assumptions and limits the method\u2019s applicability.\n\n- In experiments, it would be better to have figures that are usually used in active learning experiments, where the x-axis is the remaining budget and y-axis is the performance measure.\n\n\nAdditional comments:\n\nActive learning methods gives labels to unlabeled samples in different epochs until the budget is used up, but it would be interesting to give the final labeled and unlabeled dataset after budget is used up as a fixed dataset, and then train the traditional passive MixMatch with this.  Then we can really compare the original MixMatch and active MixMatch.  If the proposed method still works better,  then the proposed method might be meaningful not only as an active learning method but also as a curriculum learning method.\n\n********************\nI would like to thank the authors for answering my questions and updating the paper, but would like to keep my score due to the 2nd point of the cons.  A minor comment on the second point of the author response:  The sharpening step in MixMatch can be regarded as an entropy minimization procedure, which I think is based on the assumption of low distribution overlap.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper919/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper919/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Combining MixMatch and Active Learning for Better Accuracy with Fewer Labels", "authors": ["Shuang Song", "David Berthelot", "Afshin Rostamizadeh"], "authorids": ["shuangsong@google.com", "dberth@google.com", "rostami@google.com"], "keywords": ["active learning", "semi-supervised learning"], "TL;DR": "We combine MixMatch and active learning to obtain better accuracy with fewer labels and we follow this by a cost analysis comparing labeling data vs adding unlabeled data.. ", "abstract": "We propose using active learning based techniques to further improve the state-of-the-art semi-supervised learning MixMatch algorithm. We provide a thorough empirical evaluation of several active-learning and baseline methods, which successfully demonstrate a significant improvement on the benchmark CIFAR-10, CIFAR-100, and SVHN datasets (as much as 1.5% in absolute accuracy). \nWe also provide an empirical analysis of the cost trade-off between incrementally gathering more labeled versus unlabeled data. This analysis can be used to measure the relative value of labeled/unlabeled data at different points of the learning curve, where we find that although the incremental value of labeled data can be as much as 20x that of unlabeled, it quickly diminishes to less than 3x once more than 2,000 labeled example are observed.", "pdf": "/pdf/bf54be9e85eacea1c4b4cda9947859365afacf08.pdf", "paperhash": "song|combining_mixmatch_and_active_learning_for_better_accuracy_with_fewer_labels", "original_pdf": "/attachment/839f873a397082e4efb370a8462c0300c8235eb5.pdf", "_bibtex": "@misc{\nsong2020combining,\ntitle={Combining MixMatch and Active Learning for Better Accuracy with Fewer Labels},\nauthor={Shuang Song and David Berthelot and Afshin Rostamizadeh},\nyear={2020},\nurl={https://openreview.net/forum?id=HJxWl0NKPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HJxWl0NKPB", "replyto": "HJxWl0NKPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper919/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper919/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574722376000, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper919/Reviewers"], "noninvitees": [], "tcdate": 1570237745050, "tmdate": 1574723084627, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper919/-/Official_Review"}}}, {"id": "BJxdRYEjjH", "original": null, "number": 2, "cdate": 1573763536511, "ddate": null, "tcdate": 1573763536511, "tmdate": 1573763764113, "tddate": null, "forum": "HJxWl0NKPB", "replyto": "HyeIXNKTYH", "invitation": "ICLR.cc/2020/Conference/Paper919/-/Official_Comment", "content": {"title": "Response to Review #2", "comment": "Thank you very much for the careful reading and feedback. Here are our answers and clarifications.\n\n1. Novelty concern\nWe make two points to help answer this concern. Even if the two methods (MixMatch and uncertainty based AL) are themselves not novel, their combination is and the fact that they result in state-of-the-art performance, we believe, is a worthwhile discovery. Secondly, we do note that the combination is not entirely straightforward: for example, we borrowed the idea of using multiple augmentations from MixMatch when we compute the confidence scores of unlabeled samples (namely \u201caug\u201d). An \u201ceasy\u201d sample should mean that the current model can predict confidently on multiple augmentations of it, and these predictions are consistent. This can potentially improve the stability of our confidence estimation. Empirically, we can also see this method helps.\n\n2. SSL baselies other than MixMatch.\nWe have added references to several other SSL methods to the beginning of Section 3. Furthermore we have added the following empirical evaluations:\n\nWe run four other SSL methods on CIFAR-10 in the passive setting and report the mean and standard deviation over 5 repeated runs are summarized here, together with that for MixMatch.\n\n\t\t\t      500\t\t        1000\t\t  2000\t\t    4000\nMeanTeacher     61.95\u00b16.80       81.57\u00b12.49       87.28\u00b10.84       89.37\u00b10.14 \nVAT         \t     73.69\u00b12.34     \t81.12\u00b10.76       85.88\u00b10.47       88.56\u00b10.24      \t\nPiModel     \t     56.67\u00b11.63     \t68.77\u00b10.82       77.29\u00b10.39\t    84.23\u00b10.80\nPseudoLabel      57.56\u00b11.03     \t68.96\u00b11.66       77.94\u00b10.55       83.84\u00b10.28     \t  \t\nMixMatch\t     90.58\u00b10.83        91.61\u00b10.54\t  93.20\u00b10.11\t    93.70\u00b10.16\n\nWe chose MixMatch to augment with active learning since its SSL performance is significantly superior. The MixMatch work[1] confirms the performance of MixMatch compared to other SSL methods, showing that MixMatch outperforms other SSL methods by a large margin in different datasets.\nWe added the performance measurements of the above SSL methods in the appendix (Table 5) to justify the choice of MixMatch, and we added a brief summary of popular SSL methods in Section 3.\n[1] Berthelot, David, et al. \"Mixmatch: A holistic approach to semi-supervised learning.\" arXiv preprint arXiv:1905.02249 (2019).\n\n3. Cost ratio less than 0.\nThe cost ratio can be less than zero when the difference |U_{i,j}| - |U_{i+1, k}| < 0, which can for example occur when adding labeled data actually causes a drop in accuracy. This occurs in Table 10 when the number of unlabeled points is small. This is likely due to the fact that MixMatch algorithm has been tuned to work best in the regime when |U| >> |L|.\n\n4. Improvement on CIFAR-100 not statistically significant.\nIndeed, the improvement due to MMA is smaller on CIFAR-100 compared to other datasets. This is likely related to the general observation that active learning provides less of a benefit as a task become more difficult. For example see: \n\nMussmann, Stephen, and Percy Liang. \"On the Relationship between Data Efficiency and Error for Uncertainty Sampling.\" International Conference on Machine Learning. 2018.\n\nFinding additional techniques to complement active learning in these cases is an interesting direction, however, is outside the scope of this investigation.\n\nWe did not run on ImageNet due to computational constraints at the time of writing and the lack of availability of MixMatch parameters for this dataset. SSL publications only recently started to study ImageNet (in the last 6 months).\n\n\n5. Training time comparison.\nIn general, the cost of the AL algorithm is dwarfed by the training time of the machine learning model which, in real-world applications, is itself dwarfed by the time it takes to gather labels for queried points. Thus, the additional cost introduced by active learning is generally insignificant. However, to give an idea, we measured the time (in seconds) it takes per active learning iteration to decide which unlabeled samples to query with three AL methods for CIFAR-10 (w/ 49750 unlabeled samples to choose from), CIFAR-100 (w/ 47500 unlabeled) and SVHN (w/ 73007 unlabeled). As can be seen in the table, the time for deciding the unlabeled data to query is usually less than 5 minutes. Compared to the model training time, which, for a passive MixMatch to be trained until convergence, is ~15h for CIFAR-10, ~24h for CIFAR-100 and ~8h for SVHN, the time for this decision process is not significant. \n\n\t\t        diff2-direct\tdiff2-kmean\tdiff2-id\nCIFAR-10\t5.78\u00b11.56\t20.67\u00b16.69\t100.06\u00b118.20\nCIFAR-100\t21.62\u00b12.47\t81.92\u00b118.63\t175.06\u00b122.60\nSVHN\t\t13.04\u00b11.00\t37.84\u00b114.75\t191.87\u00b122.95\n\nHope these address your concerns."}, "signatures": ["ICLR.cc/2020/Conference/Paper919/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper919/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Combining MixMatch and Active Learning for Better Accuracy with Fewer Labels", "authors": ["Shuang Song", "David Berthelot", "Afshin Rostamizadeh"], "authorids": ["shuangsong@google.com", "dberth@google.com", "rostami@google.com"], "keywords": ["active learning", "semi-supervised learning"], "TL;DR": "We combine MixMatch and active learning to obtain better accuracy with fewer labels and we follow this by a cost analysis comparing labeling data vs adding unlabeled data.. ", "abstract": "We propose using active learning based techniques to further improve the state-of-the-art semi-supervised learning MixMatch algorithm. We provide a thorough empirical evaluation of several active-learning and baseline methods, which successfully demonstrate a significant improvement on the benchmark CIFAR-10, CIFAR-100, and SVHN datasets (as much as 1.5% in absolute accuracy). \nWe also provide an empirical analysis of the cost trade-off between incrementally gathering more labeled versus unlabeled data. This analysis can be used to measure the relative value of labeled/unlabeled data at different points of the learning curve, where we find that although the incremental value of labeled data can be as much as 20x that of unlabeled, it quickly diminishes to less than 3x once more than 2,000 labeled example are observed.", "pdf": "/pdf/bf54be9e85eacea1c4b4cda9947859365afacf08.pdf", "paperhash": "song|combining_mixmatch_and_active_learning_for_better_accuracy_with_fewer_labels", "original_pdf": "/attachment/839f873a397082e4efb370a8462c0300c8235eb5.pdf", "_bibtex": "@misc{\nsong2020combining,\ntitle={Combining MixMatch and Active Learning for Better Accuracy with Fewer Labels},\nauthor={Shuang Song and David Berthelot and Afshin Rostamizadeh},\nyear={2020},\nurl={https://openreview.net/forum?id=HJxWl0NKPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJxWl0NKPB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper919/Authors", "ICLR.cc/2020/Conference/Paper919/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper919/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper919/Reviewers", "ICLR.cc/2020/Conference/Paper919/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper919/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper919/Authors|ICLR.cc/2020/Conference/Paper919/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504164163, "tmdate": 1576860561834, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper919/Authors", "ICLR.cc/2020/Conference/Paper919/Reviewers", "ICLR.cc/2020/Conference/Paper919/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper919/-/Official_Comment"}}}, {"id": "BygzUcNisS", "original": null, "number": 3, "cdate": 1573763658427, "ddate": null, "tcdate": 1573763658427, "tmdate": 1573763658427, "tddate": null, "forum": "HJxWl0NKPB", "replyto": "BJedOIhjKH", "invitation": "ICLR.cc/2020/Conference/Paper919/-/Official_Comment", "content": {"title": "Response to Review #3", "comment": "Thank you very much for the careful reading and feedback. Here are our answers and clarifications.\n\n- MixMatch is the only SSL method evaluated.\nPlease see response to Reviewer #2's question 2.\n\n- Question regarding checkpoints.\nThank you very much for the careful reading and we apologize for the typo! Each checkpoint is saved every **2^10=1024** iterations (not every 2^16=65536 iterations). \n\nWe use two parameters: the initial training duration before growing (262144=2^18 you quoted in your question) and the number of training steps between each repeated growth (32768=2^15 from your question).\nThese numbers were chosen empirically to balance the convergence of the model and training time. The choice of power of 2 follows from the practice in the MixMatch work (https://github.com/google-research/mixmatch).\n\n- Universal statement at the end of the abstract.\nIndeed, we make these observations for our experiments; we will make this clear.\n\n- Section 3 title.\nWe have modified this section to include discussion of other approaches as well.\n\n- Difference between MixMatch and MMA with random selection.\nMMA with random selection and MixMatch only differ in that MMA trains with an iteratively growing subset of (uniformly randomly selected) training data, while MixMatch trains on the entire training set at once. Thus, it is not surprising that the two methods perform similarly, although it is worthwhile to conduct the experiment since the two methods may converge differently given the non-convex nature of the training problem.\n\n- Performance on CIFAR-100 with smaller batch size.\nWe ran a new set of experiment on CIFAR-100, with 2500 randomly selected samples initially and smaller batch size of 100 sampled label queries each time. We summarized the results here and also in the appendix (Table 7). Although some methods show improvement, they are within the standard deviation.\n                                4000 \t\t5000 \t\t8000 \t\t10000\nrandom \t\t        66.84\u00b10.43 \t68.72\u00b10.34 \t72.18\u00b10.31 \t73.70\u00b10.41 \ndiff2-direct \t\t67.47\u00b10.29 \t69.25\u00b10.27 \t72.79\u00b10.26 \t74.68\u00b10.33 \ndiff2.aug-direct \t67.46\u00b10.43\t69.35\u00b10.37 \t72.91\u00b10.25 \t74.50\u00b10.35 \ndiff2.aug-kmean\t67.64\u00b10.61 \t67.78\u00b13.79 \t73.07\u00b10.20 \t74.82\u00b10.26 \ndiff2-kmean\t\t67.89\u00b10.27 \t69.83\u00b10.45 \t73.10\u00b10.33 \t74.80\u00b10.13 \ndiff2-id\t   \t  \t68.06\u00b10.58\t70.18\u00b10.52\t73.90\u00b10.21\t75.26\u00b10.23\ndiff2.aug-id\t\t68.00\u00b10.76\t70.04\u00b10.41\t73.70\u00b10.30\t75.45\u00b10.27\n\nHope these address your concerns.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper919/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper919/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Combining MixMatch and Active Learning for Better Accuracy with Fewer Labels", "authors": ["Shuang Song", "David Berthelot", "Afshin Rostamizadeh"], "authorids": ["shuangsong@google.com", "dberth@google.com", "rostami@google.com"], "keywords": ["active learning", "semi-supervised learning"], "TL;DR": "We combine MixMatch and active learning to obtain better accuracy with fewer labels and we follow this by a cost analysis comparing labeling data vs adding unlabeled data.. ", "abstract": "We propose using active learning based techniques to further improve the state-of-the-art semi-supervised learning MixMatch algorithm. We provide a thorough empirical evaluation of several active-learning and baseline methods, which successfully demonstrate a significant improvement on the benchmark CIFAR-10, CIFAR-100, and SVHN datasets (as much as 1.5% in absolute accuracy). \nWe also provide an empirical analysis of the cost trade-off between incrementally gathering more labeled versus unlabeled data. This analysis can be used to measure the relative value of labeled/unlabeled data at different points of the learning curve, where we find that although the incremental value of labeled data can be as much as 20x that of unlabeled, it quickly diminishes to less than 3x once more than 2,000 labeled example are observed.", "pdf": "/pdf/bf54be9e85eacea1c4b4cda9947859365afacf08.pdf", "paperhash": "song|combining_mixmatch_and_active_learning_for_better_accuracy_with_fewer_labels", "original_pdf": "/attachment/839f873a397082e4efb370a8462c0300c8235eb5.pdf", "_bibtex": "@misc{\nsong2020combining,\ntitle={Combining MixMatch and Active Learning for Better Accuracy with Fewer Labels},\nauthor={Shuang Song and David Berthelot and Afshin Rostamizadeh},\nyear={2020},\nurl={https://openreview.net/forum?id=HJxWl0NKPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJxWl0NKPB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper919/Authors", "ICLR.cc/2020/Conference/Paper919/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper919/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper919/Reviewers", "ICLR.cc/2020/Conference/Paper919/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper919/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper919/Authors|ICLR.cc/2020/Conference/Paper919/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504164163, "tmdate": 1576860561834, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper919/Authors", "ICLR.cc/2020/Conference/Paper919/Reviewers", "ICLR.cc/2020/Conference/Paper919/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper919/-/Official_Comment"}}}, {"id": "Hke7au4ssB", "original": null, "number": 1, "cdate": 1573763259436, "ddate": null, "tcdate": 1573763259436, "tmdate": 1573763259436, "tddate": null, "forum": "HJxWl0NKPB", "replyto": "BkeRfPx2Kr", "invitation": "ICLR.cc/2020/Conference/Paper919/-/Official_Comment", "content": {"title": "Response to Review #1", "comment": "Thank you very much for the careful reading and feedback! Here are our answers and clarifications.\n\n- \"Only uncertainty based sampling methods are considered\u2026\"\nAlthough many other AL algorithms exist (such as those found in Settles 2009), we find that they are not easily adapted to the setting of complex neural networks which are costly to train. We have added an explanation at the end of Section 4.2.\n\n- \"[MMA] will also have those strong assumptions\u2026\"\nThe proposed method inherits the properties of the SSL algorithm being used. MixMatch mostly relies on consistency regularization and as far as we know does not make claims about distribution overlap.\n\n- \"[Plot the figure so that] the x-axis is the remaining budget and y-axis is the performance measure\"\nFigure 1 (now Figure 2 in the revision) is plotted in what we find is a common fashion (accuracy vs. # labeled examples). Is the main comment that you would prefer to see the same plot but with the x-axis reversed (i.e., budget remaining rather than budget consumed)? This can easily be done the camera ready version.\n\nHope these address your concerns."}, "signatures": ["ICLR.cc/2020/Conference/Paper919/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper919/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Combining MixMatch and Active Learning for Better Accuracy with Fewer Labels", "authors": ["Shuang Song", "David Berthelot", "Afshin Rostamizadeh"], "authorids": ["shuangsong@google.com", "dberth@google.com", "rostami@google.com"], "keywords": ["active learning", "semi-supervised learning"], "TL;DR": "We combine MixMatch and active learning to obtain better accuracy with fewer labels and we follow this by a cost analysis comparing labeling data vs adding unlabeled data.. ", "abstract": "We propose using active learning based techniques to further improve the state-of-the-art semi-supervised learning MixMatch algorithm. We provide a thorough empirical evaluation of several active-learning and baseline methods, which successfully demonstrate a significant improvement on the benchmark CIFAR-10, CIFAR-100, and SVHN datasets (as much as 1.5% in absolute accuracy). \nWe also provide an empirical analysis of the cost trade-off between incrementally gathering more labeled versus unlabeled data. This analysis can be used to measure the relative value of labeled/unlabeled data at different points of the learning curve, where we find that although the incremental value of labeled data can be as much as 20x that of unlabeled, it quickly diminishes to less than 3x once more than 2,000 labeled example are observed.", "pdf": "/pdf/bf54be9e85eacea1c4b4cda9947859365afacf08.pdf", "paperhash": "song|combining_mixmatch_and_active_learning_for_better_accuracy_with_fewer_labels", "original_pdf": "/attachment/839f873a397082e4efb370a8462c0300c8235eb5.pdf", "_bibtex": "@misc{\nsong2020combining,\ntitle={Combining MixMatch and Active Learning for Better Accuracy with Fewer Labels},\nauthor={Shuang Song and David Berthelot and Afshin Rostamizadeh},\nyear={2020},\nurl={https://openreview.net/forum?id=HJxWl0NKPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HJxWl0NKPB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper919/Authors", "ICLR.cc/2020/Conference/Paper919/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper919/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper919/Reviewers", "ICLR.cc/2020/Conference/Paper919/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper919/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper919/Authors|ICLR.cc/2020/Conference/Paper919/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504164163, "tmdate": 1576860561834, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper919/Authors", "ICLR.cc/2020/Conference/Paper919/Reviewers", "ICLR.cc/2020/Conference/Paper919/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper919/-/Official_Comment"}}}, {"id": "BJedOIhjKH", "original": null, "number": 1, "cdate": 1571698287968, "ddate": null, "tcdate": 1571698287968, "tmdate": 1572972535649, "tddate": null, "forum": "HJxWl0NKPB", "replyto": "HJxWl0NKPB", "invitation": "ICLR.cc/2020/Conference/Paper919/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper takes a look at using active learning techniques instead of random sampling for the \n\"state-of-the-art\" semi-supervised learning (SSL) method MixMatch. At least for this one SSL algorithm, the authors give a strong argument that active learning helps MixMatch (4x label efficiency in some cases) and highlight the active learning algorithms that work best. An additionally interesting point is the value of labeled vs unlabeled data in this setting. For these reasons, I argue for acceptance of this paper. However, I have some reservations which are given below, that perhaps the authors can clarify.  \n\n\nThings that would have improved my score:\n\n - This paper relies on MixMatch very heavily as the sole semi-supervised technique. It would be nice to see more of an argument for this choice of a relatively recent paper that hasn't stood the test of time.\n\n - I am confused why the authors \"report the median of the last 20 checkpoints' accuracy where a checkpoint is computed every 65,536 training iterations\". As we see later, the authors train after each batch of selected examples for 32,768 iterations which is half of the time between checkpoints. Can the authors comment on this choice?\n\n\nMinor comments:\n\n - The end of the abstract makes it sound like like the conclusions are universal (\"quickly diminishes to less than 3x once more than 2000 labeled example are observed\"). I would be surprised if the authors meant this as a universal statement since no theory is provided and the experiments are on similar datasets.\n\n - I don't understand why section 3 is not simply titled \"MixMatch\" since the paper doesn't really touch any other \"modern SSL\" methods.\n\n - In the experiments section, 262144 and 32768 iterations seem to come from nowhere. Only later did I realize that these were powers of 2. Can this be clarified?\n\n - What's the difference between MixMatch and MMA with random selection? Shouldn't these perform the same (which they seem to anyways)?\n\n - I really like that this paper assesses the label efficiency of their algorithm, rather than merely reporting raw accuracy numbers which aren't as meaningful.\n\n - I wonder if MMA seems to not give as big gains on CIFAR-100 because the batch size is 10x larger. Generally, I've found that active learning (especially uncertainty sampling methods) work best with smaller batch sizes and I'm not sure I agree with the reasoning that more classes mean one should select larger batch sizes.\n\n\n\n\n\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper919/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper919/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Combining MixMatch and Active Learning for Better Accuracy with Fewer Labels", "authors": ["Shuang Song", "David Berthelot", "Afshin Rostamizadeh"], "authorids": ["shuangsong@google.com", "dberth@google.com", "rostami@google.com"], "keywords": ["active learning", "semi-supervised learning"], "TL;DR": "We combine MixMatch and active learning to obtain better accuracy with fewer labels and we follow this by a cost analysis comparing labeling data vs adding unlabeled data.. ", "abstract": "We propose using active learning based techniques to further improve the state-of-the-art semi-supervised learning MixMatch algorithm. We provide a thorough empirical evaluation of several active-learning and baseline methods, which successfully demonstrate a significant improvement on the benchmark CIFAR-10, CIFAR-100, and SVHN datasets (as much as 1.5% in absolute accuracy). \nWe also provide an empirical analysis of the cost trade-off between incrementally gathering more labeled versus unlabeled data. This analysis can be used to measure the relative value of labeled/unlabeled data at different points of the learning curve, where we find that although the incremental value of labeled data can be as much as 20x that of unlabeled, it quickly diminishes to less than 3x once more than 2,000 labeled example are observed.", "pdf": "/pdf/bf54be9e85eacea1c4b4cda9947859365afacf08.pdf", "paperhash": "song|combining_mixmatch_and_active_learning_for_better_accuracy_with_fewer_labels", "original_pdf": "/attachment/839f873a397082e4efb370a8462c0300c8235eb5.pdf", "_bibtex": "@misc{\nsong2020combining,\ntitle={Combining MixMatch and Active Learning for Better Accuracy with Fewer Labels},\nauthor={Shuang Song and David Berthelot and Afshin Rostamizadeh},\nyear={2020},\nurl={https://openreview.net/forum?id=HJxWl0NKPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HJxWl0NKPB", "replyto": "HJxWl0NKPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper919/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper919/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574722376000, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper919/Reviewers"], "noninvitees": [], "tcdate": 1570237745050, "tmdate": 1574723084627, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper919/-/Official_Review"}}}, {"id": "HyeIXNKTYH", "original": null, "number": 3, "cdate": 1571816477865, "ddate": null, "tcdate": 1571816477865, "tmdate": 1572972535576, "tddate": null, "forum": "HJxWl0NKPB", "replyto": "HJxWl0NKPB", "invitation": "ICLR.cc/2020/Conference/Paper919/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The paper proposes to combine active learning techniques with MixMatch for semi-supervised learning. First, they review active learning and semi-supervised learning, especially MixMatch. Instead of traditional semi-supervised learning with a fixed set of labeled examples, they incrementally grow the labeled set as the training process goes on. They consider several different choices in active learning strategies: uncertainty measure and diversification. Diversification methods are used to balance the samples in different classes and ensure diversity. The cost analysis of adding labeled vs unlabeled data looks interesting. They perform an empirical evaluation on image benchmarks and improve over MixMatch.\n\nOverall, the paper is clearly written and easy to follow. However,  I cannot recommend acceptance because\n\n1. Novelty concern. The combination of two existing techniques seems not novel enough.\n\n2. Missing important baselines in related work and experiments. In the related work on semi-supervised learning (Section 3), the authors only review MixMatch but neglect other literature, e.g.[1,2,3,4]. And semi-supervised learning has a long history and it is not restricted to recent deep learning-based approaches. A thorough review can make the approach well-placed in the literature. In experiments, the authors only compare with MixMatch. I suggest that the authors include the missing literature in the next version.\n\n3. The cost analysis is the most interesting to me. However, Figure 2(b) in Section 5.3 is weird. How can the ratio less than 0? According to the definition in Section 4.3, $L_i \\subset L_{i+1}$ and $|L_{i+1}| > |L_i|$ and similar case for $U_{i,j}$, the cost ratio should not be less than 0. I'm also confused by the explanation in Section 5.3.\n\n4. From Figure 1(b) and Table 2, we can see that on CIFAR-100, the improvement of the proposed MMA is not statistically significant, especially when the label budget is low. But on a simpler dataset CIFAR-10, MMA performs better. How does MMA perform on a more challenging task with more classes, e.g. ImageNet?\n\n5. Training time comparison. At the expense of spending more time on selecting uncertain examples and techniques like k-means clustering, MMA is slightly better than MixMatch. A comparison of training time and complexity would be better to convince me.\n\n\n\n***\nMinor:\npage 4 \u201cStarting with from a fixed pool of n unlabeled sample\u201d\npage 4 \u201cA corollary question is how do various accuracy targets relate to each other?\u201d \npage 5 \u201cWhile there are there additional active learning\u201d\npage 5 \u201c Let\u2019s define cl and cu as the cost of respectively obtaining a new labeled sample and a new unlabeled sample.\u201d --> costs\n\n\n\n***\nReferences\n[1] Temporal Ensembling for Semi-Supervised Learning, ICLR 2017.\n[2] Smooth Neighbors on Teacher Graphs for Semi-supervised Learning, CVPR 2018.\n[3] Realistic Evaluation of Semi-supervised Learning Algorithms, NeurIPS 2018.\n[4] There Are Many Consistent Explanations of Unlabeled Data: Why You Should Average, ICLR 2019.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper919/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper919/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Combining MixMatch and Active Learning for Better Accuracy with Fewer Labels", "authors": ["Shuang Song", "David Berthelot", "Afshin Rostamizadeh"], "authorids": ["shuangsong@google.com", "dberth@google.com", "rostami@google.com"], "keywords": ["active learning", "semi-supervised learning"], "TL;DR": "We combine MixMatch and active learning to obtain better accuracy with fewer labels and we follow this by a cost analysis comparing labeling data vs adding unlabeled data.. ", "abstract": "We propose using active learning based techniques to further improve the state-of-the-art semi-supervised learning MixMatch algorithm. We provide a thorough empirical evaluation of several active-learning and baseline methods, which successfully demonstrate a significant improvement on the benchmark CIFAR-10, CIFAR-100, and SVHN datasets (as much as 1.5% in absolute accuracy). \nWe also provide an empirical analysis of the cost trade-off between incrementally gathering more labeled versus unlabeled data. This analysis can be used to measure the relative value of labeled/unlabeled data at different points of the learning curve, where we find that although the incremental value of labeled data can be as much as 20x that of unlabeled, it quickly diminishes to less than 3x once more than 2,000 labeled example are observed.", "pdf": "/pdf/bf54be9e85eacea1c4b4cda9947859365afacf08.pdf", "paperhash": "song|combining_mixmatch_and_active_learning_for_better_accuracy_with_fewer_labels", "original_pdf": "/attachment/839f873a397082e4efb370a8462c0300c8235eb5.pdf", "_bibtex": "@misc{\nsong2020combining,\ntitle={Combining MixMatch and Active Learning for Better Accuracy with Fewer Labels},\nauthor={Shuang Song and David Berthelot and Afshin Rostamizadeh},\nyear={2020},\nurl={https://openreview.net/forum?id=HJxWl0NKPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HJxWl0NKPB", "replyto": "HJxWl0NKPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper919/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper919/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574722376000, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper919/Reviewers"], "noninvitees": [], "tcdate": 1570237745050, "tmdate": 1574723084627, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper919/-/Official_Review"}}}], "count": 8}