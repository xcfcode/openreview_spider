{"notes": [{"id": "S1el9TEKPB", "original": "Skx2rDawwB", "number": 694, "cdate": 1569439112186, "ddate": null, "tcdate": 1569439112186, "tmdate": 1577168216434, "tddate": null, "forum": "S1el9TEKPB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Sparsity Meets Robustness: Channel Pruning for the Feynman-Kac Formalism Principled Robust Deep Neural Nets", "authors": ["Thu Dinh*", "Bao Wang*", "Andrea L. Bertozzi", "Stanley J. Osher", "Jack Xin"], "authorids": ["thud2@uci.edu", "wangbaonj@gmail.com", "bertozzi@math.ucla.edu", "sjo@math.ucla.edu", "jxin@math.uci.edu"], "keywords": ["Sparse Network", "Model Compression", "Adversarial Training"], "TL;DR": "We focus on a co-design of efficient DNN compression algorithms and sparse neural architectures for robust and accurate deep learning. Such a co-design enables us to advance the goal of accommodating both sparsity and robustness.", "abstract": "Deep neural nets (DNNs) compression is crucial for adaptation to mobile devices. Though many successful algorithms exist to compress naturally trained DNNs, developing efficient and stable compression algorithms for robustly trained DNNs remains widely open. In this paper, we focus on a co-design of efficient DNN compression algorithms and sparse neural architectures for robust and accurate deep learning. Such a co-design enables us to advance the goal of accommodating both sparsity and robustness. With this objective in mind, we leverage the relaxed augmented Lagrangian based algorithms to prune the weights of adversarially trained DNNs, at both structured and unstructured levels. Using a Feynman-Kac formalism principled robust and sparse DNNs, we can at least double the channel sparsity of the adversarially trained ResNet20 for CIFAR10 classification, meanwhile, improve the natural accuracy by 8.69\\% and the robust accuracy under the benchmark 20 iterations of IFGSM attack by 5.42\\%.", "pdf": "/pdf/89f2e45791b7387212fdc0017bcece7b43d2870c.pdf", "paperhash": "dinh|sparsity_meets_robustness_channel_pruning_for_the_feynmankac_formalism_principled_robust_deep_neural_nets", "original_pdf": "/attachment/d718a986fae7cc36211a72c47c78179ebaedf2ff.pdf", "_bibtex": "@misc{\ndinh*2020sparsity,\ntitle={Sparsity Meets Robustness: Channel Pruning for the Feynman-Kac Formalism Principled Robust Deep Neural Nets},\nauthor={Thu Dinh* and Bao Wang* and Andrea L. Bertozzi and Stanley J. Osher and Jack Xin},\nyear={2020},\nurl={https://openreview.net/forum?id=S1el9TEKPB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "ElJH0lSuMT", "original": null, "number": 1, "cdate": 1576798703486, "ddate": null, "tcdate": 1576798703486, "tmdate": 1576800932550, "tddate": null, "forum": "S1el9TEKPB", "replyto": "S1el9TEKPB", "invitation": "ICLR.cc/2020/Conference/Paper694/-/Decision", "content": {"decision": "Reject", "comment": "The paper is rejected based on unanimous reviews.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sparsity Meets Robustness: Channel Pruning for the Feynman-Kac Formalism Principled Robust Deep Neural Nets", "authors": ["Thu Dinh*", "Bao Wang*", "Andrea L. Bertozzi", "Stanley J. Osher", "Jack Xin"], "authorids": ["thud2@uci.edu", "wangbaonj@gmail.com", "bertozzi@math.ucla.edu", "sjo@math.ucla.edu", "jxin@math.uci.edu"], "keywords": ["Sparse Network", "Model Compression", "Adversarial Training"], "TL;DR": "We focus on a co-design of efficient DNN compression algorithms and sparse neural architectures for robust and accurate deep learning. Such a co-design enables us to advance the goal of accommodating both sparsity and robustness.", "abstract": "Deep neural nets (DNNs) compression is crucial for adaptation to mobile devices. Though many successful algorithms exist to compress naturally trained DNNs, developing efficient and stable compression algorithms for robustly trained DNNs remains widely open. In this paper, we focus on a co-design of efficient DNN compression algorithms and sparse neural architectures for robust and accurate deep learning. Such a co-design enables us to advance the goal of accommodating both sparsity and robustness. With this objective in mind, we leverage the relaxed augmented Lagrangian based algorithms to prune the weights of adversarially trained DNNs, at both structured and unstructured levels. Using a Feynman-Kac formalism principled robust and sparse DNNs, we can at least double the channel sparsity of the adversarially trained ResNet20 for CIFAR10 classification, meanwhile, improve the natural accuracy by 8.69\\% and the robust accuracy under the benchmark 20 iterations of IFGSM attack by 5.42\\%.", "pdf": "/pdf/89f2e45791b7387212fdc0017bcece7b43d2870c.pdf", "paperhash": "dinh|sparsity_meets_robustness_channel_pruning_for_the_feynmankac_formalism_principled_robust_deep_neural_nets", "original_pdf": "/attachment/d718a986fae7cc36211a72c47c78179ebaedf2ff.pdf", "_bibtex": "@misc{\ndinh*2020sparsity,\ntitle={Sparsity Meets Robustness: Channel Pruning for the Feynman-Kac Formalism Principled Robust Deep Neural Nets},\nauthor={Thu Dinh* and Bao Wang* and Andrea L. Bertozzi and Stanley J. Osher and Jack Xin},\nyear={2020},\nurl={https://openreview.net/forum?id=S1el9TEKPB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "S1el9TEKPB", "replyto": "S1el9TEKPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795719226, "tmdate": 1576800269838, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper694/-/Decision"}}}, {"id": "S1gNquq_sH", "original": null, "number": 2, "cdate": 1573591179994, "ddate": null, "tcdate": 1573591179994, "tmdate": 1573605590735, "tddate": null, "forum": "S1el9TEKPB", "replyto": "SJloP0M1cr", "invitation": "ICLR.cc/2020/Conference/Paper694/-/Official_Comment", "content": {"title": "Reply to review #1", "comment": "Thank you for your valuable feedback and thoughtful reviews. Below we address your concerns about our paper.\n\nQ1. The paper has limited novelty. It has already been shown in the original EnResNet paper [1] that EnResNet is more robust to adversarial attacks. Thus the only additional contribution of this paper is the observation that EnResnet is more sparse than standard ResNet, and combination of EnResnet with sparsification methods. Overall, while the paper provides an interesting observation, it has limited contributions due to lack of novelty. Further, inadequate experimental validation makes it difficult to see if the claims made in the paper are actually true. Thus I believe that this paper requires substantial improvements in order to be accepted to top-tier publication venues such as ICLR.\nAnswer: The adversarially trained EnResNet is observed to be more robust in [1]. The novelty of our work is twofold: First, based on the property of the convection-diffusion equation, we observed that the weights of the adversarially trained EnResNet are much sparser than the baseline ResNet. Second, we proposed a relaxed augmented Lagrangian based algorithm to efficiently prune the weights at both structured and unstructured level. The relaxed augmented Lagrangian method is more efficient than the standard ADMM approach for pruning the weights of deep neural nets. Moreover, the pruning algorithm provably converges in the adversarial setting. Both the sparsity observation and the relaxed augmented Lagrangian based algorithm for structured and unstructured pruning are novel.\n\nIn our paper, we conducted extensive experiments on both CIFAR10 and CIFAR100 to verify the robustness and sparsity of the proposed framework. In the revised manuscript, we have also added more results on adversarial attacks.\n\nQ2. The paper is not well justified on why one should use sparsifying techniques such as RVSM, RGSM with the Feynman-Kac formula principled EnResnet. The authors state that this enables sparsity to meet robustness; however, in all experimental results, the robustness actually decreases with the increase in sparsity which is opposite to the claims made in the paper. \nAnswer: In this paper, we have two objectives in mind. First, we perform the neural net architecture redesign to improve their sparsity. Second, on top of the new architecture, we develop efficient sparsification algorithms to prune the neural net at both structured and unstructured sparsity levels. We leveraged both RVSM and RGSM to achieve the second goal. In our paper, sparsity meets robustness means that  we are developing algorithms to improve both robustness and sparsity on top of the baseline deep neural nets. We do not mean that improving sparsity will improve robustness.\n\nQ3. The authors only report robustness on white-box gradient-based attacks. Thus it is not clear whether the method will generalize to black-box/gradient-free attack approaches such as NAttack.\nAnswer: We list the results on the black-box adversarial attack below, where we use the base model to classify the adversarial examples crafted by attacking the target model. All models are PGD adversarially trained with $\\beta=1$, $\\lambda_1=0.1$, and $\\lambda_2=1e-5$.\n-----------------------------------------------------------------------------------------------------------------------------------------\nBased Model            Target Model       $IFGSM^{10}$  $IFGSM^{20}$  $IFGSM^{50}$   $IFGSM^{100}$ \n-----------------------------------------------------------------------------------------------------------------------------------------\nEn$_5$ResNet20    ResNet20                   61.63             60.65                 60.67                    60.59\nEn$_2$ResNet20    ResNet20                   58.51             56.99                 56.79                    57.01\n    ResNet20         En$_2$ResNet20          57.50             53.54                 53.51                    53.37\n    ResNet20         En$_5$ResNet20          58.14             53.97                 53.87                    53.65\n-----------------------------------------------------------------------------------------------------------------------------------------\n\nIn the revised manuscript, we have also added results on NAttack (with the default parameters in the attackbox: https://github.com/cmhcbb/attackbox) in Table 2. Below is a partial list of the results of the three models mentioned above. \n-----------------------------------------------------------\nModel                       Accuracy (NAttack)\n----------------------------------------------------------\nResNet20                   43.84\nEn$_2$ResNet20          46.77\nEn$_5$ResNet20          48.23\n----------------------------------------------------------\n\nWe see that the sparsified EnResNets are also more robust to both black-box IFGSM attack and NAttack than the baseline ResNet."}, "signatures": ["ICLR.cc/2020/Conference/Paper694/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper694/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sparsity Meets Robustness: Channel Pruning for the Feynman-Kac Formalism Principled Robust Deep Neural Nets", "authors": ["Thu Dinh*", "Bao Wang*", "Andrea L. Bertozzi", "Stanley J. Osher", "Jack Xin"], "authorids": ["thud2@uci.edu", "wangbaonj@gmail.com", "bertozzi@math.ucla.edu", "sjo@math.ucla.edu", "jxin@math.uci.edu"], "keywords": ["Sparse Network", "Model Compression", "Adversarial Training"], "TL;DR": "We focus on a co-design of efficient DNN compression algorithms and sparse neural architectures for robust and accurate deep learning. Such a co-design enables us to advance the goal of accommodating both sparsity and robustness.", "abstract": "Deep neural nets (DNNs) compression is crucial for adaptation to mobile devices. Though many successful algorithms exist to compress naturally trained DNNs, developing efficient and stable compression algorithms for robustly trained DNNs remains widely open. In this paper, we focus on a co-design of efficient DNN compression algorithms and sparse neural architectures for robust and accurate deep learning. Such a co-design enables us to advance the goal of accommodating both sparsity and robustness. With this objective in mind, we leverage the relaxed augmented Lagrangian based algorithms to prune the weights of adversarially trained DNNs, at both structured and unstructured levels. Using a Feynman-Kac formalism principled robust and sparse DNNs, we can at least double the channel sparsity of the adversarially trained ResNet20 for CIFAR10 classification, meanwhile, improve the natural accuracy by 8.69\\% and the robust accuracy under the benchmark 20 iterations of IFGSM attack by 5.42\\%.", "pdf": "/pdf/89f2e45791b7387212fdc0017bcece7b43d2870c.pdf", "paperhash": "dinh|sparsity_meets_robustness_channel_pruning_for_the_feynmankac_formalism_principled_robust_deep_neural_nets", "original_pdf": "/attachment/d718a986fae7cc36211a72c47c78179ebaedf2ff.pdf", "_bibtex": "@misc{\ndinh*2020sparsity,\ntitle={Sparsity Meets Robustness: Channel Pruning for the Feynman-Kac Formalism Principled Robust Deep Neural Nets},\nauthor={Thu Dinh* and Bao Wang* and Andrea L. Bertozzi and Stanley J. Osher and Jack Xin},\nyear={2020},\nurl={https://openreview.net/forum?id=S1el9TEKPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1el9TEKPB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper694/Authors", "ICLR.cc/2020/Conference/Paper694/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper694/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper694/Reviewers", "ICLR.cc/2020/Conference/Paper694/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper694/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper694/Authors|ICLR.cc/2020/Conference/Paper694/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504167640, "tmdate": 1576860560584, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper694/Authors", "ICLR.cc/2020/Conference/Paper694/Reviewers", "ICLR.cc/2020/Conference/Paper694/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper694/-/Official_Comment"}}}, {"id": "HygV-Fc_sr", "original": null, "number": 4, "cdate": 1573591292507, "ddate": null, "tcdate": 1573591292507, "tmdate": 1573591292507, "tddate": null, "forum": "S1el9TEKPB", "replyto": "BkxlcbZ0KH", "invitation": "ICLR.cc/2020/Conference/Paper694/-/Official_Comment", "content": {"title": "Reply to review #3", "comment": "Thank you for your valuable feedback and thoughtful reviews. Below we address your concerns about our paper.\n\nQ1. The main contribution of paper is to adapt the RVSM/RGSM algorithms to the AT of DNNs to sparsify the deep model. However, both RVSM and RGSM have already been used as sparsification algorithms for DNNs, and the Feynman-Kac formalism principled DNNs has also been investigated for the purpose of sparsification, thus the contribution is largely reduced and the novelty appear to be limited.\nAnswer: The authors of EnResNet just used the fact that the ensemble of the adversarially trained \nnoise injected ResNet can improve both natural and robust accuracy on top of the baseline ResNet. The novelty of our work is twofold: First, based on the property of the convection-diffusion equation, we observed that the weights of the adversarially trained EnResNet are much sparser than the baseline ResNet. Second, we proposed a relaxed augmented Lagrangian based algorithm to efficiently prune the weights at both structured and unstructured level. The relaxed augmented Lagrangian method is more efficient than the standard ADMM approach for pruning the weights of deep neural nets. Moreover, the pruning algorithm provably converges in the adversarial setting. Both the sparsity observation and the relaxed augmented Lagrangian based algorithm for structured and unstructured pruning are novel.\n\n\nQ2. For the experiments, the effectiveness of RVSM/RGSM are verified on the variants of ResNet and EnResNet, and there are insufficient comparisons with other cutting-edge compression/sparsification methods to show the advantage of the proposed method.\nAnswer: In this paper, we compared the proposed RVSM/RGSM with ADMM type structured/unstructured pruning algorithms that are also Lagrangian based and used recently by other researchers. We shall compare with other sparsification methods in future work, however, we already made the first major step forward in achieving considerable sparsity for robust networks. Moreover, RVSM/RGSM is simple and efficient, easy to implement and enjoys a solid theoretical foundation without any ad hoc modification. \n\n\n\nQ3. The author claims that ADMM produce a lot of small weights that cannot be regarded as zero since the norm is larger than 1e-15. Is the \u20181e-15\u2019 threshold too small to regard a value as zero?\n\nAnswer: A small threshold value 1e-15 is meaningful in that the individual weight values in a channel with norm above such threshold may still exceed machine precision and have a non-negligible effect on accuracy. In the case of 64 bit, the value for machine precision is approximately 2.22e-16. Thus 1.e-15 is a reasonable threshold. One can use a larger threshold, yet it remains true that ADMM does not zero out as many weights (channels) as RVSM (RGSM). \n\n================================================\nWe hope we have answered your questions about our work, and we would appreciate more constructive feedback from you."}, "signatures": ["ICLR.cc/2020/Conference/Paper694/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper694/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sparsity Meets Robustness: Channel Pruning for the Feynman-Kac Formalism Principled Robust Deep Neural Nets", "authors": ["Thu Dinh*", "Bao Wang*", "Andrea L. Bertozzi", "Stanley J. Osher", "Jack Xin"], "authorids": ["thud2@uci.edu", "wangbaonj@gmail.com", "bertozzi@math.ucla.edu", "sjo@math.ucla.edu", "jxin@math.uci.edu"], "keywords": ["Sparse Network", "Model Compression", "Adversarial Training"], "TL;DR": "We focus on a co-design of efficient DNN compression algorithms and sparse neural architectures for robust and accurate deep learning. Such a co-design enables us to advance the goal of accommodating both sparsity and robustness.", "abstract": "Deep neural nets (DNNs) compression is crucial for adaptation to mobile devices. Though many successful algorithms exist to compress naturally trained DNNs, developing efficient and stable compression algorithms for robustly trained DNNs remains widely open. In this paper, we focus on a co-design of efficient DNN compression algorithms and sparse neural architectures for robust and accurate deep learning. Such a co-design enables us to advance the goal of accommodating both sparsity and robustness. With this objective in mind, we leverage the relaxed augmented Lagrangian based algorithms to prune the weights of adversarially trained DNNs, at both structured and unstructured levels. Using a Feynman-Kac formalism principled robust and sparse DNNs, we can at least double the channel sparsity of the adversarially trained ResNet20 for CIFAR10 classification, meanwhile, improve the natural accuracy by 8.69\\% and the robust accuracy under the benchmark 20 iterations of IFGSM attack by 5.42\\%.", "pdf": "/pdf/89f2e45791b7387212fdc0017bcece7b43d2870c.pdf", "paperhash": "dinh|sparsity_meets_robustness_channel_pruning_for_the_feynmankac_formalism_principled_robust_deep_neural_nets", "original_pdf": "/attachment/d718a986fae7cc36211a72c47c78179ebaedf2ff.pdf", "_bibtex": "@misc{\ndinh*2020sparsity,\ntitle={Sparsity Meets Robustness: Channel Pruning for the Feynman-Kac Formalism Principled Robust Deep Neural Nets},\nauthor={Thu Dinh* and Bao Wang* and Andrea L. Bertozzi and Stanley J. Osher and Jack Xin},\nyear={2020},\nurl={https://openreview.net/forum?id=S1el9TEKPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1el9TEKPB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper694/Authors", "ICLR.cc/2020/Conference/Paper694/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper694/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper694/Reviewers", "ICLR.cc/2020/Conference/Paper694/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper694/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper694/Authors|ICLR.cc/2020/Conference/Paper694/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504167640, "tmdate": 1576860560584, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper694/Authors", "ICLR.cc/2020/Conference/Paper694/Reviewers", "ICLR.cc/2020/Conference/Paper694/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper694/-/Official_Comment"}}}, {"id": "r1lOpO9diB", "original": null, "number": 3, "cdate": 1573591231729, "ddate": null, "tcdate": 1573591231729, "tmdate": 1573591231729, "tddate": null, "forum": "S1el9TEKPB", "replyto": "S1gNquq_sH", "invitation": "ICLR.cc/2020/Conference/Paper694/-/Official_Comment", "content": {"title": "Reply to review #1 -- Continued", "comment": "Q4. Why didn\u2019t you report the accuracy on the clean examples? This is important in showing that the method generalizes well to clean examples while maintaining robustness.\nAnswer: We call the accuracy on the clean examples as natural accuracy, denoted as $A_1$, in our paper, we followed the name adopted by other researchers. As you expected, our proposed framework not only remarkably improves robustness but also improves their natural accuracy, as shown in Tables 1, 2, 3, and Figure 4.\n\nQ5. Why use only 20 iterations to evaluate the attack? Will the model maintain its robustness with the increase in the iteration and epsilon? \nAnswer: 20 iterations IFGSM attack is the commonly used attack to evaluate the robustness of machine learning models. Below we list the accuracy of different models under IFGSM with the different number of iterations. All models are trained with $\\beta=1$, $\\lambda_1=0.1$, and $\\lambda_2=1e-5$.\n----------------------------------------------------------------------------------------------------------------\n       Model            $IFGSM^{10}$  $IFGSM^{20}$  $IFGSM^{50}$   $IFGSM^{100}$ \n----------------------------------------------------------------------------------------------------------------\n    ResNet20                48.14             47.14                 46.50                    46.46\nEn$_2$ResNet20        54.46             49.58                 48.65                    48.47\nEn$_5$ResNet20        56.92             51.35                 50.32                    50.19\n----------------------------------------------------------------------------------------------------------------\nIt shows that  the robust accuracy of the sparsified EnResNets is significantly higher than ResNet.\n\n\nQ6. Figures are not referenced anywhere in the text.\nAnswer: We referenced the figures in the text. Mostly, we call Fig.~(figure number). Also, we discussed all the figures in the main text.\n\nQ7. It would be better to put the results on CIFAR100 in the main paper rather than in the appendix.\nAnswer: As you suggested, we have moved the results on CIFAR100 to the main paper.\n\nQ8. Page 2, \u201clower cases\u201d  -> \u201clower case\u201d.  Page 2, \u201cRelated Works\u201d -> \u201cRelated work\u201d, it\u2019s better to have it as a separate section.\nAnswer: As you suggested, we have made the related work part to be a separate section in the revised manuscript and fixed the typos.\n\n================================================\nWe hope we have answered your questions about our work, and we would appreciate more constructive feedback from you."}, "signatures": ["ICLR.cc/2020/Conference/Paper694/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper694/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sparsity Meets Robustness: Channel Pruning for the Feynman-Kac Formalism Principled Robust Deep Neural Nets", "authors": ["Thu Dinh*", "Bao Wang*", "Andrea L. Bertozzi", "Stanley J. Osher", "Jack Xin"], "authorids": ["thud2@uci.edu", "wangbaonj@gmail.com", "bertozzi@math.ucla.edu", "sjo@math.ucla.edu", "jxin@math.uci.edu"], "keywords": ["Sparse Network", "Model Compression", "Adversarial Training"], "TL;DR": "We focus on a co-design of efficient DNN compression algorithms and sparse neural architectures for robust and accurate deep learning. Such a co-design enables us to advance the goal of accommodating both sparsity and robustness.", "abstract": "Deep neural nets (DNNs) compression is crucial for adaptation to mobile devices. Though many successful algorithms exist to compress naturally trained DNNs, developing efficient and stable compression algorithms for robustly trained DNNs remains widely open. In this paper, we focus on a co-design of efficient DNN compression algorithms and sparse neural architectures for robust and accurate deep learning. Such a co-design enables us to advance the goal of accommodating both sparsity and robustness. With this objective in mind, we leverage the relaxed augmented Lagrangian based algorithms to prune the weights of adversarially trained DNNs, at both structured and unstructured levels. Using a Feynman-Kac formalism principled robust and sparse DNNs, we can at least double the channel sparsity of the adversarially trained ResNet20 for CIFAR10 classification, meanwhile, improve the natural accuracy by 8.69\\% and the robust accuracy under the benchmark 20 iterations of IFGSM attack by 5.42\\%.", "pdf": "/pdf/89f2e45791b7387212fdc0017bcece7b43d2870c.pdf", "paperhash": "dinh|sparsity_meets_robustness_channel_pruning_for_the_feynmankac_formalism_principled_robust_deep_neural_nets", "original_pdf": "/attachment/d718a986fae7cc36211a72c47c78179ebaedf2ff.pdf", "_bibtex": "@misc{\ndinh*2020sparsity,\ntitle={Sparsity Meets Robustness: Channel Pruning for the Feynman-Kac Formalism Principled Robust Deep Neural Nets},\nauthor={Thu Dinh* and Bao Wang* and Andrea L. Bertozzi and Stanley J. Osher and Jack Xin},\nyear={2020},\nurl={https://openreview.net/forum?id=S1el9TEKPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1el9TEKPB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper694/Authors", "ICLR.cc/2020/Conference/Paper694/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper694/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper694/Reviewers", "ICLR.cc/2020/Conference/Paper694/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper694/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper694/Authors|ICLR.cc/2020/Conference/Paper694/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504167640, "tmdate": 1576860560584, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper694/Authors", "ICLR.cc/2020/Conference/Paper694/Reviewers", "ICLR.cc/2020/Conference/Paper694/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper694/-/Official_Comment"}}}, {"id": "rklrNd5diH", "original": null, "number": 1, "cdate": 1573591085053, "ddate": null, "tcdate": 1573591085053, "tmdate": 1573591085053, "tddate": null, "forum": "S1el9TEKPB", "replyto": "HklqNcvkqB", "invitation": "ICLR.cc/2020/Conference/Paper694/-/Official_Comment", "content": {"title": "Reply to review #2", "comment": "Thank you for your valuable feedback and thoughtful reviews. Below we address your concerns about our paper.\n\nQ1. In my opinion, the introduction messes unstructured and structured. Weight sparsification is associated with structured while I do believe is unstructured. \nAnswer: In our submission, we focused on the channel-pruning, which is structured pruning. For comparison, we also reported the results on the unstructured pruning \u2014 weight sparsification. We have made this more clear in the revised manuscript.\n\nQ2. Related work does not seem very comprehensive. The paper claims novelty on using RGSM to improve performance. How is this different from the formulation used in \"Learning the Number of Neurons in Deep Networks, Alvarez and Salzmann NIPS 2016\".\nAnswer: Alvarez and Salzmann NIPS 2016 is a proximal gradient descent method on group lasso and L1 penalty, while RGSM involves a relaxed variable to explore the loss landscape and sparsify weights. In our paper, RGSM is applied to group L0 (L0) for structure (un-structured) sparsity, which is more effective in realizing sparsity and maintaining accuracy in gradient descent training than using group L1 (L1). To the best of our  knowledge, this is the first time that the L0 penalty is studied in the setting of adversarial learning.\n\nQ3. One thing that got my attention is the threshold for pruning weights (1e-15). I think that is not a fair value. There are related works suggesting no loss in accuracy if the threshold is ~1e-5 (y. Sparse convolutional neural networks CVPR2015). I do believe the numbers would change drastically. \nAnswer: The threshold of 1e-15 comes from the observation that the weights in a channel with norm less than 1e-15 is essentially under machine precision and have no effects on accuracy when set to zero. \nHence, the threshold should be small to keep a good robust accuracy.  We tested ResNet-20 on CIFAR10 with channel norm threshold increased to 1e-5, and found that RVSM has 28% (133 vs. 171) more sparsity than ADMM with comparable or better accuracy.\n\nQ4. The comparison between ADMM and the proximal is unfair if using that threshold. The proximal has an implicit thresholding Eq. 6. \nAnswer: Step 2 of ADMM (u update of eq. (3) ) can also be written as a proximal operation with implicit thresholding. Hence the comparison is fair. The difference is that ADMM has an extra multiplier, while RVSM/RGSM does not.\n\nQ5. What is the goal for the ensembles of the small networks? where are the numbers?\nAnswer: The goal of the ensemble of noise injected small ResNet is to improve the sparsity and robustness on top of the baseline ResNet. This is one of the crucial components of our proposed framework. We denoted the ensemble of ResNet as En$_x$ResNet, where the subscript x indicates the number of ResNet.\n\nQ6. In sparsity and robustness, there are some works missing (as a typo). \nAnswer: They are fixed in the revised manuscript.\n\nQ7. On the method, there are two parts where I am confused. What is the aim for including all-around Eq. 4? The same with the theoretical guarantees. \nAnswer: Eq 4 shows the Lagrangian function being minimized by our algorithm. The theoretical results provide a mathematical foundation of our algorithm and its convergence based on Eq 4. \n\n================================================\nWe hope we have answered your questions about our work, and we would appreciate more constructive feedback from you."}, "signatures": ["ICLR.cc/2020/Conference/Paper694/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper694/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sparsity Meets Robustness: Channel Pruning for the Feynman-Kac Formalism Principled Robust Deep Neural Nets", "authors": ["Thu Dinh*", "Bao Wang*", "Andrea L. Bertozzi", "Stanley J. Osher", "Jack Xin"], "authorids": ["thud2@uci.edu", "wangbaonj@gmail.com", "bertozzi@math.ucla.edu", "sjo@math.ucla.edu", "jxin@math.uci.edu"], "keywords": ["Sparse Network", "Model Compression", "Adversarial Training"], "TL;DR": "We focus on a co-design of efficient DNN compression algorithms and sparse neural architectures for robust and accurate deep learning. Such a co-design enables us to advance the goal of accommodating both sparsity and robustness.", "abstract": "Deep neural nets (DNNs) compression is crucial for adaptation to mobile devices. Though many successful algorithms exist to compress naturally trained DNNs, developing efficient and stable compression algorithms for robustly trained DNNs remains widely open. In this paper, we focus on a co-design of efficient DNN compression algorithms and sparse neural architectures for robust and accurate deep learning. Such a co-design enables us to advance the goal of accommodating both sparsity and robustness. With this objective in mind, we leverage the relaxed augmented Lagrangian based algorithms to prune the weights of adversarially trained DNNs, at both structured and unstructured levels. Using a Feynman-Kac formalism principled robust and sparse DNNs, we can at least double the channel sparsity of the adversarially trained ResNet20 for CIFAR10 classification, meanwhile, improve the natural accuracy by 8.69\\% and the robust accuracy under the benchmark 20 iterations of IFGSM attack by 5.42\\%.", "pdf": "/pdf/89f2e45791b7387212fdc0017bcece7b43d2870c.pdf", "paperhash": "dinh|sparsity_meets_robustness_channel_pruning_for_the_feynmankac_formalism_principled_robust_deep_neural_nets", "original_pdf": "/attachment/d718a986fae7cc36211a72c47c78179ebaedf2ff.pdf", "_bibtex": "@misc{\ndinh*2020sparsity,\ntitle={Sparsity Meets Robustness: Channel Pruning for the Feynman-Kac Formalism Principled Robust Deep Neural Nets},\nauthor={Thu Dinh* and Bao Wang* and Andrea L. Bertozzi and Stanley J. Osher and Jack Xin},\nyear={2020},\nurl={https://openreview.net/forum?id=S1el9TEKPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "S1el9TEKPB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper694/Authors", "ICLR.cc/2020/Conference/Paper694/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper694/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper694/Reviewers", "ICLR.cc/2020/Conference/Paper694/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper694/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper694/Authors|ICLR.cc/2020/Conference/Paper694/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504167640, "tmdate": 1576860560584, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper694/Authors", "ICLR.cc/2020/Conference/Paper694/Reviewers", "ICLR.cc/2020/Conference/Paper694/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper694/-/Official_Comment"}}}, {"id": "BkxlcbZ0KH", "original": null, "number": 1, "cdate": 1571848584297, "ddate": null, "tcdate": 1571848584297, "tmdate": 1572972563858, "tddate": null, "forum": "S1el9TEKPB", "replyto": "S1el9TEKPB", "invitation": "ICLR.cc/2020/Conference/Paper694/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "Summary:\nThis paper focuses on the study of sparse neural architectures and efficient DNN compression algorithms for the robust and accurate deep learning. The authors apply relaxed augmented Lagrangian based sparsification algorithms to perform both unstructured and channel pruning for the AT DNNs. By combing with the sparsity merit of EnResNet, their sparsification algorithms further boost the sparsity limit of the AT DNNs, leading to much better robustness and accuracy. Their approach demonstrates superior natural and robust accuracies under several benchmark attacks.\n\nStrengths:\n1 The authors practically apply the RVSM/RGSM algorithms to the AT using robust PGD training, resulting in significantly enhanced sparsity of DNNs, and achieving promising robust accuracies against various adversarial attacks.   \n2 The authors provide the theoretical analysis showing the convergence of the RVSM algorithm.\n\nWeaknesses:\n1 The main contribution of paper is to adapt the RVSM/RGSM algorithms to the AT of DNNs to sparsify the deep model. However, both RVSM and RGSM have already been used as sparsification algorithms for DNNs, and the Feynman-Kac formalism principled DNNs has also been investigated for the purpose of sparsification, thus the contribution is largely reduced and the novelty appear to be limited.\n\n2 For the experiments, the effectiveness of RVSM/RGSM are verified on the variants of ResNet and EnResNet, and there are insufficient comparisons with other cutting-edge compression/sparsification methods to show the advantage of the proposed method.\n\nQuestion:\n1 The author claim that ADMM produce a lot of small weights that cannot be regarded as zero since the norm is large than 1e-15. Is the \u20181e-15\u2019 threshold too small to regard a value as zero?"}, "signatures": ["ICLR.cc/2020/Conference/Paper694/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper694/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sparsity Meets Robustness: Channel Pruning for the Feynman-Kac Formalism Principled Robust Deep Neural Nets", "authors": ["Thu Dinh*", "Bao Wang*", "Andrea L. Bertozzi", "Stanley J. Osher", "Jack Xin"], "authorids": ["thud2@uci.edu", "wangbaonj@gmail.com", "bertozzi@math.ucla.edu", "sjo@math.ucla.edu", "jxin@math.uci.edu"], "keywords": ["Sparse Network", "Model Compression", "Adversarial Training"], "TL;DR": "We focus on a co-design of efficient DNN compression algorithms and sparse neural architectures for robust and accurate deep learning. Such a co-design enables us to advance the goal of accommodating both sparsity and robustness.", "abstract": "Deep neural nets (DNNs) compression is crucial for adaptation to mobile devices. Though many successful algorithms exist to compress naturally trained DNNs, developing efficient and stable compression algorithms for robustly trained DNNs remains widely open. In this paper, we focus on a co-design of efficient DNN compression algorithms and sparse neural architectures for robust and accurate deep learning. Such a co-design enables us to advance the goal of accommodating both sparsity and robustness. With this objective in mind, we leverage the relaxed augmented Lagrangian based algorithms to prune the weights of adversarially trained DNNs, at both structured and unstructured levels. Using a Feynman-Kac formalism principled robust and sparse DNNs, we can at least double the channel sparsity of the adversarially trained ResNet20 for CIFAR10 classification, meanwhile, improve the natural accuracy by 8.69\\% and the robust accuracy under the benchmark 20 iterations of IFGSM attack by 5.42\\%.", "pdf": "/pdf/89f2e45791b7387212fdc0017bcece7b43d2870c.pdf", "paperhash": "dinh|sparsity_meets_robustness_channel_pruning_for_the_feynmankac_formalism_principled_robust_deep_neural_nets", "original_pdf": "/attachment/d718a986fae7cc36211a72c47c78179ebaedf2ff.pdf", "_bibtex": "@misc{\ndinh*2020sparsity,\ntitle={Sparsity Meets Robustness: Channel Pruning for the Feynman-Kac Formalism Principled Robust Deep Neural Nets},\nauthor={Thu Dinh* and Bao Wang* and Andrea L. Bertozzi and Stanley J. Osher and Jack Xin},\nyear={2020},\nurl={https://openreview.net/forum?id=S1el9TEKPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "S1el9TEKPB", "replyto": "S1el9TEKPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper694/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper694/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575633969259, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper694/Reviewers"], "noninvitees": [], "tcdate": 1570237748438, "tmdate": 1575633969280, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper694/-/Official_Review"}}}, {"id": "SJloP0M1cr", "original": null, "number": 2, "cdate": 1571921506669, "ddate": null, "tcdate": 1571921506669, "tmdate": 1572972563814, "tddate": null, "forum": "S1el9TEKPB", "replyto": "S1el9TEKPB", "invitation": "ICLR.cc/2020/Conference/Paper694/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "Summary: This paper presents an observation that Feynman-Kac formalism principled ResNet ensemble [1] yields sparser network weights compared to those of standard Resnet.  Based on this observation, the authors combine the ensemble model with Lagrangian based sparsification methods to obtain sparse and robust models. \n\nPros:\n- Obtaining sparse and robust networks is an important and challenging problem that could be of interest to a large audience.\n- The paper provides an interesting observation that EnResNet [1] yields sparser network weights compared to standard ResNet, and further leverage it to obtain sparse and robust models. \n\nCons:\n- The paper has limited novelty. It has already been shown in the original EnResNet paper [1] that EnResNet is more robust to adversarial attacks. Thus the only additional contribution of this paper is the observation that EnResnet is more sparse than standard ResNet, and combination of EnResnet with sparsification methods.  \n- The paper is not well justified on why one should use sparsifying techniques such as RVSM, RGSM with the Feynman-Kac formula principled EnResnet. The authors state that this enables sparsity to meet robustness; however, in all experimental results, the robustness actually decreases with the increase in sparsity which is opposite to the claims made in the paper. \n- The authors only report robustness on white-box gradient-based attacks. Thus it is not clear whether the method will generalize to black-box/gradient-free attack approaches such as NAttack [2].\n\nMinor comments:\n\n- Why didn\u2019t you report the accuracy on the clean examples? This is important in showing that the method generalizes well to clean examples while maintaining robustness.\n- Why use only 20 iterations to evaluate the attack? Will the model maintain its robustness with the increase in the iteration and epsilon? \n- Figures are not referenced anywhere in the text.\n- It would be better to put the results on CIFAR100 in the main paper rather than in the appendix.\n- Page 2, \u201clower cases\u201d  -> \u201clower case\u201d.\n- Page 2, \u201cRelated Works\u201d -> \u201cRelated work\u201d, it\u2019s better to have it as a separate section.\n\nOverall, while the paper provides an interesting observation, it has limited contributions due to lack of novelty. Further, inadequate experimental validation makes it difficult to see if the claims made in the paper are actually true. Thus I believe that this paper requires substantial improvements in order to be accepted to top-tier publication venues such as ICLR.\n\nReferences:\n[1] Bao et al. 2018, https://arxiv.org/abs/1811.10745 \n[2] Yadong et al. 2019, https://arxiv.org/abs/1905.00441"}, "signatures": ["ICLR.cc/2020/Conference/Paper694/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper694/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sparsity Meets Robustness: Channel Pruning for the Feynman-Kac Formalism Principled Robust Deep Neural Nets", "authors": ["Thu Dinh*", "Bao Wang*", "Andrea L. Bertozzi", "Stanley J. Osher", "Jack Xin"], "authorids": ["thud2@uci.edu", "wangbaonj@gmail.com", "bertozzi@math.ucla.edu", "sjo@math.ucla.edu", "jxin@math.uci.edu"], "keywords": ["Sparse Network", "Model Compression", "Adversarial Training"], "TL;DR": "We focus on a co-design of efficient DNN compression algorithms and sparse neural architectures for robust and accurate deep learning. Such a co-design enables us to advance the goal of accommodating both sparsity and robustness.", "abstract": "Deep neural nets (DNNs) compression is crucial for adaptation to mobile devices. Though many successful algorithms exist to compress naturally trained DNNs, developing efficient and stable compression algorithms for robustly trained DNNs remains widely open. In this paper, we focus on a co-design of efficient DNN compression algorithms and sparse neural architectures for robust and accurate deep learning. Such a co-design enables us to advance the goal of accommodating both sparsity and robustness. With this objective in mind, we leverage the relaxed augmented Lagrangian based algorithms to prune the weights of adversarially trained DNNs, at both structured and unstructured levels. Using a Feynman-Kac formalism principled robust and sparse DNNs, we can at least double the channel sparsity of the adversarially trained ResNet20 for CIFAR10 classification, meanwhile, improve the natural accuracy by 8.69\\% and the robust accuracy under the benchmark 20 iterations of IFGSM attack by 5.42\\%.", "pdf": "/pdf/89f2e45791b7387212fdc0017bcece7b43d2870c.pdf", "paperhash": "dinh|sparsity_meets_robustness_channel_pruning_for_the_feynmankac_formalism_principled_robust_deep_neural_nets", "original_pdf": "/attachment/d718a986fae7cc36211a72c47c78179ebaedf2ff.pdf", "_bibtex": "@misc{\ndinh*2020sparsity,\ntitle={Sparsity Meets Robustness: Channel Pruning for the Feynman-Kac Formalism Principled Robust Deep Neural Nets},\nauthor={Thu Dinh* and Bao Wang* and Andrea L. Bertozzi and Stanley J. Osher and Jack Xin},\nyear={2020},\nurl={https://openreview.net/forum?id=S1el9TEKPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "S1el9TEKPB", "replyto": "S1el9TEKPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper694/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper694/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575633969259, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper694/Reviewers"], "noninvitees": [], "tcdate": 1570237748438, "tmdate": 1575633969280, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper694/-/Official_Review"}}}, {"id": "HklqNcvkqB", "original": null, "number": 3, "cdate": 1571940913663, "ddate": null, "tcdate": 1571940913663, "tmdate": 1572972563772, "tddate": null, "forum": "S1el9TEKPB", "replyto": "S1el9TEKPB", "invitation": "ICLR.cc/2020/Conference/Paper694/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper presents an algorithm to train neural networks combining sparsity and adversarial training. \nOn the sparsity inducing regularization, the paper proposes using proximal methods. \n\nOn the positive side:\n- The goal is of interest when it comes to real-world applications.  \n- There is an interesting analysis of the weights and how pruning / AT affects them. \n\n\nOn the negative side:\n\n- In my opinion, the introduction messes unstructured and structured. Weight sparsification is associated with structured while I do believe is unstructured. \n\n\n- Related work does not seem very comprehensive. The paper claims novelty on using RGSM to improve performance. How is this different from the formulation used in \"Learning the Number of Neurons in Deep Networks, Alvarez and Salzmann NIPS 2016\".\n\n\n\nExperimental settings:\n- One thing that got my attention is the threshold for pruning weights (1e-15). I think that is not a fair value. There are related works suggesting no loss in accuracy if the threshold is ~1e-5 (y. Sparse convolutional neural networks CVPR2015). I do believe the numbers would change drastically. \n\n- The comparison between ADMM and the proximal is unfair if using that threshold. The proximal has an implicit thresholding Eq. 6. \n\n- What is the goal for the ensembles of the small networks? where are the numbers?\n\n\nMinor stuff:\n- In sparsity and robustness, there are some works missing (as a typo). \n- On the method, there are two parts where I am confused. What is the aim for including all-around Eq. 4? The same with the theoretical guarantees. "}, "signatures": ["ICLR.cc/2020/Conference/Paper694/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper694/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Sparsity Meets Robustness: Channel Pruning for the Feynman-Kac Formalism Principled Robust Deep Neural Nets", "authors": ["Thu Dinh*", "Bao Wang*", "Andrea L. Bertozzi", "Stanley J. Osher", "Jack Xin"], "authorids": ["thud2@uci.edu", "wangbaonj@gmail.com", "bertozzi@math.ucla.edu", "sjo@math.ucla.edu", "jxin@math.uci.edu"], "keywords": ["Sparse Network", "Model Compression", "Adversarial Training"], "TL;DR": "We focus on a co-design of efficient DNN compression algorithms and sparse neural architectures for robust and accurate deep learning. Such a co-design enables us to advance the goal of accommodating both sparsity and robustness.", "abstract": "Deep neural nets (DNNs) compression is crucial for adaptation to mobile devices. Though many successful algorithms exist to compress naturally trained DNNs, developing efficient and stable compression algorithms for robustly trained DNNs remains widely open. In this paper, we focus on a co-design of efficient DNN compression algorithms and sparse neural architectures for robust and accurate deep learning. Such a co-design enables us to advance the goal of accommodating both sparsity and robustness. With this objective in mind, we leverage the relaxed augmented Lagrangian based algorithms to prune the weights of adversarially trained DNNs, at both structured and unstructured levels. Using a Feynman-Kac formalism principled robust and sparse DNNs, we can at least double the channel sparsity of the adversarially trained ResNet20 for CIFAR10 classification, meanwhile, improve the natural accuracy by 8.69\\% and the robust accuracy under the benchmark 20 iterations of IFGSM attack by 5.42\\%.", "pdf": "/pdf/89f2e45791b7387212fdc0017bcece7b43d2870c.pdf", "paperhash": "dinh|sparsity_meets_robustness_channel_pruning_for_the_feynmankac_formalism_principled_robust_deep_neural_nets", "original_pdf": "/attachment/d718a986fae7cc36211a72c47c78179ebaedf2ff.pdf", "_bibtex": "@misc{\ndinh*2020sparsity,\ntitle={Sparsity Meets Robustness: Channel Pruning for the Feynman-Kac Formalism Principled Robust Deep Neural Nets},\nauthor={Thu Dinh* and Bao Wang* and Andrea L. Bertozzi and Stanley J. Osher and Jack Xin},\nyear={2020},\nurl={https://openreview.net/forum?id=S1el9TEKPB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "S1el9TEKPB", "replyto": "S1el9TEKPB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper694/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper694/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575633969259, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper694/Reviewers"], "noninvitees": [], "tcdate": 1570237748438, "tmdate": 1575633969280, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper694/-/Official_Review"}}}], "count": 9}