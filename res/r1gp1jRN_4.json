{"notes": [{"id": "r1gp1jRN_4", "original": "B1xlMXDmu4", "number": 42, "cdate": 1553423076662, "ddate": null, "tcdate": 1553423076662, "tmdate": 1562082116361, "tddate": null, "forum": "r1gp1jRN_4", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "Unifying semi-supervised and robust learning by mixup", "authors": ["Ryuichiro Hataya", "Hideki Nakayama"], "authorids": ["hataya@nlab.ci.i.u-tokyo.ac.jp", "nakayama@nlab.ci.i.u-tokyo.ac.jp"], "keywords": ["label noise", "semi-supervised learning", "robust leaning under to noisy label"], "TL;DR": "We propose to compare semi-supervised and robust learning to noisy label under a shared setting", "abstract": "Supervised deep learning methods require cleanly labeled large-scale datasets, but collecting such data is difficult and sometimes impossible. There exist two popular frameworks to alleviate this problem: semi-supervised learning and robust learning to label noise. Although these frameworks relax the restriction of supervised learning, they are studied independently. Hence, the training scheme that is suitable when only small cleanly-labeled data are available remains unknown. In this study, we consider learning from bi-quality data as a generalization of these studies, in which a small portion of data is cleanly labeled, and the rest is corrupt. Under this framework, we compare recent algorithms for semi-supervised and robust learning. The results suggest that semi-supervised learning outperforms robust learning with noisy labels. We also propose a training strategy for mixing mixup techniques to learn from such bi-quality data effectively.", "pdf": "/pdf/986512271a3ffade897bde41e3772231371b6d00.pdf", "paperhash": "hataya|unifying_semisupervised_and_robust_learning_by_mixup"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "OpenReview.net"}, {"id": "H1xNccu5OE", "original": null, "number": 1, "cdate": 1553791627897, "ddate": null, "tcdate": 1553791627897, "tmdate": 1555512029875, "tddate": null, "forum": "r1gp1jRN_4", "replyto": "r1gp1jRN_4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper42/Official_Review", "content": {"title": "Great workshop paper, but many areas to improve algorithm", "review": "Major comments and summary: \n\n  Overall, I strongly recommend this paper as a workshop paper, but I think it needs more work to become a great conference paper.  The problem is well-motivated and seems very important to me.  My biggest issue is that I feel like one could go much \"further\" with this idea - and it shows empirically - the only improvement from using the noisy labels is to go from 89% -> 90%, which I would say is only a small improvement.  If this problem gets solved I think you should be closer to 95% on CIFAR10.  \n\nI have a few ideas on how to make the algorithm better: \n  -On the noisily labeled data points $D_U$, replace the (noisy) label y_i with a soft-label which reflects the underlying noise process.  For example if you're told that y = 1, but the noise process corrupts to a new random label with 50% chance, then make the new soft-label [0.5/9, 0.5, 0.5/9, 0.5/9, ...].  This is like changing the label randomly each time you see the example but it will have much less variance!  This is just for the L_robust loss.  \n  -Alternatively, what if you replace L_robust with a partial likelihood which reflects what q is?  For example, if each data point is corrupted with 50% chance - then just try to encourage the probability of that point to be >=50%.  Don't try to push the probability on that label up to 100% (in practice this would look like a hinge loss - I think).  \n  -Is \"L\" loss cross-entropy or mean squared error?  For semi-supervised consistency loss I think it helps to use mean squared error instead of cross entropy (cross-entropy is very harsh if the prediction and the label strongly disagree when the label is confident).  \n\nOther Comments: \n\n  -I think the bi-quality data setting is extremely interesting.  However, the introduction could perhaps benefit from giving some more concrete examples of bi-quality data.  I think model-based RL could be one interesting example (the model gives very noise rollouts and the environment gives high-quality rollouts).  \n\n  -The paper motivates the algorithm by saying that the value of q might be unknown.  However, even if q were known, would it be trivial to fuse SSL and RLL?  There would still be a tradeoff between how much to trust the labels from the untrustworthy set and how much to rely on the trustworthy data.  \n\n  -Explicit hyperparameter to mix between the robust objective the semi-supervised objective.  Would it be too hard to learn this hyperparameter?  \n\n  -Is the value of \"q\" and the noise corruption process known?  It doesn't seem to be used in the algorithm block.  If q or the corruption process were known, would you have a way of using it.  \n\n\nPaper reading notes: \n-Deep learning requires labeled data which is both large and clean.  \n\n-This paper proposes to study the robust learning and SSL learning problems jointly - in that we assume that we have \"bi-quality data\" - where a small number of examples are cleanly labeled and a large amount of data has noisy labels.  \n\n-Using just robust learning on all the data performs worse than SSL.  \n\n-Paper proposes to combine SSL and RLL.  \n\n-D_T is the trusted data (clean, labels always correct).  D_U is the untrusted data (labels are sometimes wrong).  \n\n-P refers to the fraction of the total data which is trusted.  \n\n-Also have a score q, such that q=0 means the labels are totally random and q=1 means the labels are perfectly clean.  \n\n-From this perspective SSL corresponds to the q=0 case (where the untrusted data has no label information).  \n\n\nMinor comments: \n\n  -Would be good to also cite this newer paper focusing on mixup and SSL (only published recently, but spells the SSL stuff out more clearly): https://arxiv.org/pdf/1903.03825.pdf\n\n  -\"To realize this goal, whose quality might be 0, we propose...\" -> this line doesn't make sense to me.  Typo?  \n\n  -Please put more space into the algorithm 1 block.  ", "rating": "5: Top 15% of accepted papers, strong accept", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper42/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper42/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unifying semi-supervised and robust learning by mixup", "authors": ["Ryuichiro Hataya", "Hideki Nakayama"], "authorids": ["hataya@nlab.ci.i.u-tokyo.ac.jp", "nakayama@nlab.ci.i.u-tokyo.ac.jp"], "keywords": ["label noise", "semi-supervised learning", "robust leaning under to noisy label"], "TL;DR": "We propose to compare semi-supervised and robust learning to noisy label under a shared setting", "abstract": "Supervised deep learning methods require cleanly labeled large-scale datasets, but collecting such data is difficult and sometimes impossible. There exist two popular frameworks to alleviate this problem: semi-supervised learning and robust learning to label noise. Although these frameworks relax the restriction of supervised learning, they are studied independently. Hence, the training scheme that is suitable when only small cleanly-labeled data are available remains unknown. In this study, we consider learning from bi-quality data as a generalization of these studies, in which a small portion of data is cleanly labeled, and the rest is corrupt. Under this framework, we compare recent algorithms for semi-supervised and robust learning. The results suggest that semi-supervised learning outperforms robust learning with noisy labels. We also propose a training strategy for mixing mixup techniques to learn from such bi-quality data effectively.", "pdf": "/pdf/986512271a3ffade897bde41e3772231371b6d00.pdf", "paperhash": "hataya|unifying_semisupervised_and_robust_learning_by_mixup"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper42/Official_Review", "cdate": 1553713414832, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "r1gp1jRN_4", "replyto": "r1gp1jRN_4", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper42/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper42/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713414832, "tmdate": 1555511824994, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper42/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "B1l2Qw2DFV", "original": null, "number": 2, "cdate": 1554659107686, "ddate": null, "tcdate": 1554659107686, "tmdate": 1555512018684, "tddate": null, "forum": "r1gp1jRN_4", "replyto": "r1gp1jRN_4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper42/Official_Review", "content": {"title": "A simple approach for handling noisy labels, coupled with promising results", "review": "The authors start by introducing a formal setting that includes the semi-supervised and the robust learning tasks as special cases and they then proceed by proposing a strategy based on mixup [1] for training a model in this unified setting.\n\nMy general impression from this work is firmly positive. The manuscript is clearly written, the experimental setup covers adequately alternative methods and the description of the experiments includes the most important details. The results presented, while in my opinion do not allow drawing definite conclusions, they are at least promising. In more detail, I see the following prons and cons:\n\nProns:\n\n1. Clearly written manuscript. Related work is properly presented, the proposed unifying framework is easy to understand and the experiments are described in adequate detail.\n\n2. The proposed learning approach in this unified setting is elegant and, to the best of my knowledge, original.\n\n3. The proposed method is compared adequately with alternative state-of-the-art ones and with reasonable baselines. The comparison of these state-of-the-art methods with each other in this specific setting is interesting on its own right, too.\n\n4. This works falls nicely within the scope of the workshop.\n\nCons:\n\n1. In the reported experiments the proposed method had a performance which is very close to that of an alternative method (90% as oppose to 89% of [2]) while the difference when q=0 with when q=0.6 is also close (88% and 90% respectively). Given how close these numbers are, I would have preferred if the experiments had been repeated for more trials (say 3) and/or some statistical tests had been performed (even though it is my understanding that this is not standard practice in the conference) in order to gain some insight on the statistical significance of these differences.\n\n2. Of course one can always suggest more experiments,  but still I think it would be interesting to see if/how the results change if some other CNN architecture is used.\n\n\n[1] Zhang, Hongyi, et al. \"mixup: Beyond empirical risk minimization.\" arXiv preprint arXiv:1710.09412 (2017).\n\n[2] Verma, Vikas, et al. \"Manifold Mixup: Learning Better Representations by Interpolating Hidden States.\" (2018).\n", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper42/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper42/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unifying semi-supervised and robust learning by mixup", "authors": ["Ryuichiro Hataya", "Hideki Nakayama"], "authorids": ["hataya@nlab.ci.i.u-tokyo.ac.jp", "nakayama@nlab.ci.i.u-tokyo.ac.jp"], "keywords": ["label noise", "semi-supervised learning", "robust leaning under to noisy label"], "TL;DR": "We propose to compare semi-supervised and robust learning to noisy label under a shared setting", "abstract": "Supervised deep learning methods require cleanly labeled large-scale datasets, but collecting such data is difficult and sometimes impossible. There exist two popular frameworks to alleviate this problem: semi-supervised learning and robust learning to label noise. Although these frameworks relax the restriction of supervised learning, they are studied independently. Hence, the training scheme that is suitable when only small cleanly-labeled data are available remains unknown. In this study, we consider learning from bi-quality data as a generalization of these studies, in which a small portion of data is cleanly labeled, and the rest is corrupt. Under this framework, we compare recent algorithms for semi-supervised and robust learning. The results suggest that semi-supervised learning outperforms robust learning with noisy labels. We also propose a training strategy for mixing mixup techniques to learn from such bi-quality data effectively.", "pdf": "/pdf/986512271a3ffade897bde41e3772231371b6d00.pdf", "paperhash": "hataya|unifying_semisupervised_and_robust_learning_by_mixup"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper42/Official_Review", "cdate": 1553713414832, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "r1gp1jRN_4", "replyto": "r1gp1jRN_4", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper42/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper42/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713414832, "tmdate": 1555511824994, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper42/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "B1gtJDkYF4", "original": null, "number": 1, "cdate": 1554736864547, "ddate": null, "tcdate": 1554736864547, "tmdate": 1555510986944, "tddate": null, "forum": "r1gp1jRN_4", "replyto": "r1gp1jRN_4", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper42/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Unifying semi-supervised and robust learning by mixup", "authors": ["Ryuichiro Hataya", "Hideki Nakayama"], "authorids": ["hataya@nlab.ci.i.u-tokyo.ac.jp", "nakayama@nlab.ci.i.u-tokyo.ac.jp"], "keywords": ["label noise", "semi-supervised learning", "robust leaning under to noisy label"], "TL;DR": "We propose to compare semi-supervised and robust learning to noisy label under a shared setting", "abstract": "Supervised deep learning methods require cleanly labeled large-scale datasets, but collecting such data is difficult and sometimes impossible. There exist two popular frameworks to alleviate this problem: semi-supervised learning and robust learning to label noise. Although these frameworks relax the restriction of supervised learning, they are studied independently. Hence, the training scheme that is suitable when only small cleanly-labeled data are available remains unknown. In this study, we consider learning from bi-quality data as a generalization of these studies, in which a small portion of data is cleanly labeled, and the rest is corrupt. Under this framework, we compare recent algorithms for semi-supervised and robust learning. The results suggest that semi-supervised learning outperforms robust learning with noisy labels. We also propose a training strategy for mixing mixup techniques to learn from such bi-quality data effectively.", "pdf": "/pdf/986512271a3ffade897bde41e3772231371b6d00.pdf", "paperhash": "hataya|unifying_semisupervised_and_robust_learning_by_mixup"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper42/Decision", "cdate": 1554736076298, "reply": {"forum": "r1gp1jRN_4", "replyto": "r1gp1jRN_4", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736076298, "tmdate": 1555510962563, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 4}