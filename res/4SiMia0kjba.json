{"notes": [{"id": "4SiMia0kjba", "original": "mljNZkk7i0", "number": 1578, "cdate": 1601308174917, "ddate": null, "tcdate": 1601308174917, "tmdate": 1614985711265, "tddate": null, "forum": "4SiMia0kjba", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets", "authorids": ["~Shixiang_Wan1", "~Shikai_Luo1", "~Hongtu_Zhu2"], "authors": ["Shixiang Wan", "Shikai Luo", "Hongtu Zhu"], "keywords": ["Spatio-temporal Prediction", "Causal Inference", "Efficient Transformers", "Two-sided Markets"], "abstract": "Achieving accurate spatio-temporal predictions in large-scale systems is extremely valuable in many real-world applications, such as weather forecasts, retail forecasting, and urban traffic forecasting. So far, most existing methods for multi-horizon, multi-task and multi-target predictions select important predicting variables via their correlations with responses, and thus it is highly possible that many forecasting models generated from those methods are not causal, leading to poor interpretability. The aim of this paper is to develop a collaborative causal spatio-temporal fusion transformer, named CausalTrans, to establish the collaborative causal effects of predictors on multiple forecasting targets, such as supply and demand in ride-sharing platforms. Specifically, we integrate the causal attention with the Conditional Average Treatment Effect (CATE) estimation method for causal inference. Moreover, we propose a novel and fast multi-head attention evolved from Taylor expansion instead of softmax, reducing time complexity from $O(\\mathcal{V}^2)$ to $O(\\mathcal{V})$, where $\\mathcal{V}$ is the number of nodes in a graph. We further design a spatial graph fusion mechanism to significantly reduce the parameters' scale. We conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various model components, and the time efficiency of our CausalTrans. As shown in these experiments, our CausalTrans framework can achieve up to 15$\\%$ error reduction compared with various baseline methods. ", "one-sentence_summary": "We develop a novel causal transformer with causal inference and efficient taylor attention to address large scale spatio-temporal predictions. Our method achieves up to 15% error reduction compared with various baseline methods. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wan|causal_probabilistic_spatiotemporal_fusion_transformers_in_twosided_ridehailing_markets", "pdf": "/pdf/2e1d95eab956d7894f701146a590095527edb2b9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=i9kbk52UWw", "_bibtex": "@misc{\nwan2021causal,\ntitle={Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets},\nauthor={Shixiang Wan and Shikai Luo and Hongtu Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=4SiMia0kjba}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 16, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "Fnmvsgx3pG", "original": null, "number": 1, "cdate": 1610040431551, "ddate": null, "tcdate": 1610040431551, "tmdate": 1610474031613, "tddate": null, "forum": "4SiMia0kjba", "replyto": "4SiMia0kjba", "invitation": "ICLR.cc/2021/Conference/Paper1578/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The paper presents a spatial-temporal prediction framework with causal effects of predictors for better interpretability. The idea is interesting and the touch on modeling causal relations could be useful in practical applications. The paper receives mixed ratings and therefore there has been extensive discussion. We agree that while the paper has some merits, it falls short on the following aspects: \n\n1, One central issue pointed out by all reviewers is the evaluation. For example, the contribution on efficient attention was not compared to any previous work; most of the baselines do no have access to the spatial information, which makes the comparison unfair. The authors did add two more baselines with access to spatial information. However, there are not enough details and discussions to make the results convincing; In addition, other stronger baselines should be added. \n\n2. The notation and technical presentation was extremely lacking in the submitted version, the amount of unintroduced notations. Even in their core contribution equations had major issues with norm and vectors mixed together (see the difference between the corrected equation in the Taylor equation and the one in the original submission)\n\nAfter the discussion, all reviewers agree that the paper fails to provide a fair and convincing evaluation, and the ratings will be adjusted to reflect the discussion. We hope that the reviews can help the authors improve the draft for a stronger submission in the future. "}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets", "authorids": ["~Shixiang_Wan1", "~Shikai_Luo1", "~Hongtu_Zhu2"], "authors": ["Shixiang Wan", "Shikai Luo", "Hongtu Zhu"], "keywords": ["Spatio-temporal Prediction", "Causal Inference", "Efficient Transformers", "Two-sided Markets"], "abstract": "Achieving accurate spatio-temporal predictions in large-scale systems is extremely valuable in many real-world applications, such as weather forecasts, retail forecasting, and urban traffic forecasting. So far, most existing methods for multi-horizon, multi-task and multi-target predictions select important predicting variables via their correlations with responses, and thus it is highly possible that many forecasting models generated from those methods are not causal, leading to poor interpretability. The aim of this paper is to develop a collaborative causal spatio-temporal fusion transformer, named CausalTrans, to establish the collaborative causal effects of predictors on multiple forecasting targets, such as supply and demand in ride-sharing platforms. Specifically, we integrate the causal attention with the Conditional Average Treatment Effect (CATE) estimation method for causal inference. Moreover, we propose a novel and fast multi-head attention evolved from Taylor expansion instead of softmax, reducing time complexity from $O(\\mathcal{V}^2)$ to $O(\\mathcal{V})$, where $\\mathcal{V}$ is the number of nodes in a graph. We further design a spatial graph fusion mechanism to significantly reduce the parameters' scale. We conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various model components, and the time efficiency of our CausalTrans. As shown in these experiments, our CausalTrans framework can achieve up to 15$\\%$ error reduction compared with various baseline methods. ", "one-sentence_summary": "We develop a novel causal transformer with causal inference and efficient taylor attention to address large scale spatio-temporal predictions. Our method achieves up to 15% error reduction compared with various baseline methods. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wan|causal_probabilistic_spatiotemporal_fusion_transformers_in_twosided_ridehailing_markets", "pdf": "/pdf/2e1d95eab956d7894f701146a590095527edb2b9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=i9kbk52UWw", "_bibtex": "@misc{\nwan2021causal,\ntitle={Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets},\nauthor={Shixiang Wan and Shikai Luo and Hongtu Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=4SiMia0kjba}\n}"}, "tags": [], "invitation": {"reply": {"forum": "4SiMia0kjba", "replyto": "4SiMia0kjba", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040431538, "tmdate": 1610474031598, "id": "ICLR.cc/2021/Conference/Paper1578/-/Decision"}}}, {"id": "E6gZWHZNzad", "original": null, "number": 2, "cdate": 1603916752535, "ddate": null, "tcdate": 1603916752535, "tmdate": 1608386090747, "tddate": null, "forum": "4SiMia0kjba", "replyto": "4SiMia0kjba", "invitation": "ICLR.cc/2021/Conference/Paper1578/-/Official_Review", "content": {"title": "Spatio-temporal fusion transformers for predicting supply and demand in two-sided markets.", "review": "The authors propose an interpretable spatio-temporal fusion transformer for predicting supply and demand in ride-haling platforms.  More generally, the authors claim that their approach extends to other two-sided markets such as electric grids, retail etc by showing empirical results of their approach using data from these markets.  The paper is well-written and easy to follow. \n\nThe assumption that the supply is always conditioned on the demand x_v(, t + \\tau_max) is too strong.  Is there a smoother of this assumption where the demand is dependent on a moving window over the past and future supply?  The experimental results show the efficacy of the proposed ML architecture.  However, one result that will greatly help the conclusions are results that clearly show the interpretability of the predictions, given that the authors state this as one of the main differences of their proposed solution.\n\nThe use of higher-order Taylor terms to approximate the attention procedure is interesting but the time complexity reductions are obvious and therefore does not meet the novelty bar for an ICLR submission.\n\nOther suggestions - make the use of the word 'collaborative' in the model more clear.  The significance of the results is not completely clear and how the interpretability is helping understanding of the results.  Adding clarifications will help in the exposition.\n\nI still have some concerns regarding the paper. The lack of baseline comparisons with spatio-temporal data (as also observed by fellow reviewers). My other concern also remains - from the authors' response, it is not clear how once can clearly attribute explainability of the results from their analysis of the model.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1578/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets", "authorids": ["~Shixiang_Wan1", "~Shikai_Luo1", "~Hongtu_Zhu2"], "authors": ["Shixiang Wan", "Shikai Luo", "Hongtu Zhu"], "keywords": ["Spatio-temporal Prediction", "Causal Inference", "Efficient Transformers", "Two-sided Markets"], "abstract": "Achieving accurate spatio-temporal predictions in large-scale systems is extremely valuable in many real-world applications, such as weather forecasts, retail forecasting, and urban traffic forecasting. So far, most existing methods for multi-horizon, multi-task and multi-target predictions select important predicting variables via their correlations with responses, and thus it is highly possible that many forecasting models generated from those methods are not causal, leading to poor interpretability. The aim of this paper is to develop a collaborative causal spatio-temporal fusion transformer, named CausalTrans, to establish the collaborative causal effects of predictors on multiple forecasting targets, such as supply and demand in ride-sharing platforms. Specifically, we integrate the causal attention with the Conditional Average Treatment Effect (CATE) estimation method for causal inference. Moreover, we propose a novel and fast multi-head attention evolved from Taylor expansion instead of softmax, reducing time complexity from $O(\\mathcal{V}^2)$ to $O(\\mathcal{V})$, where $\\mathcal{V}$ is the number of nodes in a graph. We further design a spatial graph fusion mechanism to significantly reduce the parameters' scale. We conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various model components, and the time efficiency of our CausalTrans. As shown in these experiments, our CausalTrans framework can achieve up to 15$\\%$ error reduction compared with various baseline methods. ", "one-sentence_summary": "We develop a novel causal transformer with causal inference and efficient taylor attention to address large scale spatio-temporal predictions. Our method achieves up to 15% error reduction compared with various baseline methods. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wan|causal_probabilistic_spatiotemporal_fusion_transformers_in_twosided_ridehailing_markets", "pdf": "/pdf/2e1d95eab956d7894f701146a590095527edb2b9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=i9kbk52UWw", "_bibtex": "@misc{\nwan2021causal,\ntitle={Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets},\nauthor={Shixiang Wan and Shikai Luo and Hongtu Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=4SiMia0kjba}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "4SiMia0kjba", "replyto": "4SiMia0kjba", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1578/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538115539, "tmdate": 1606915781335, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1578/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1578/-/Official_Review"}}}, {"id": "gBbjE3A22EE", "original": null, "number": 8, "cdate": 1606114494879, "ddate": null, "tcdate": 1606114494879, "tmdate": 1606155356686, "tddate": null, "forum": "4SiMia0kjba", "replyto": "4SiMia0kjba", "invitation": "ICLR.cc/2021/Conference/Paper1578/-/Official_Comment", "content": {"title": "Summary of revision", "comment": "We uploaded revisions of the submission in which\n\n1. We add sentences to explain equation (1) and (2) in section 3.1. (done)\n2. We move probabilistic forecasting in appendix to section 3.2. (done)\n3. We add sentences to explain the motivation of using Taylor linear attention and correct equation (6) and (7) in section 3.4. (done)\n4. We add experiments and analysis about two baselines ST-MGCN and DMVST in section 4.2, and we also check the comparison results in table 2 and table 3. (done)\n5. We show experimental optimal hyperparameters in appendix B. (done)\n6. We add ablation analysis on Traffic dataset in appendix C.2. (done)\n7. We add ablation analysis about hyperparameter $k$ of spatial fusion in appendix C.2. (done)\n8. We discuss a series of linear attention studies in appendix D. (done)"}, "signatures": ["ICLR.cc/2021/Conference/Paper1578/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets", "authorids": ["~Shixiang_Wan1", "~Shikai_Luo1", "~Hongtu_Zhu2"], "authors": ["Shixiang Wan", "Shikai Luo", "Hongtu Zhu"], "keywords": ["Spatio-temporal Prediction", "Causal Inference", "Efficient Transformers", "Two-sided Markets"], "abstract": "Achieving accurate spatio-temporal predictions in large-scale systems is extremely valuable in many real-world applications, such as weather forecasts, retail forecasting, and urban traffic forecasting. So far, most existing methods for multi-horizon, multi-task and multi-target predictions select important predicting variables via their correlations with responses, and thus it is highly possible that many forecasting models generated from those methods are not causal, leading to poor interpretability. The aim of this paper is to develop a collaborative causal spatio-temporal fusion transformer, named CausalTrans, to establish the collaborative causal effects of predictors on multiple forecasting targets, such as supply and demand in ride-sharing platforms. Specifically, we integrate the causal attention with the Conditional Average Treatment Effect (CATE) estimation method for causal inference. Moreover, we propose a novel and fast multi-head attention evolved from Taylor expansion instead of softmax, reducing time complexity from $O(\\mathcal{V}^2)$ to $O(\\mathcal{V})$, where $\\mathcal{V}$ is the number of nodes in a graph. We further design a spatial graph fusion mechanism to significantly reduce the parameters' scale. We conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various model components, and the time efficiency of our CausalTrans. As shown in these experiments, our CausalTrans framework can achieve up to 15$\\%$ error reduction compared with various baseline methods. ", "one-sentence_summary": "We develop a novel causal transformer with causal inference and efficient taylor attention to address large scale spatio-temporal predictions. Our method achieves up to 15% error reduction compared with various baseline methods. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wan|causal_probabilistic_spatiotemporal_fusion_transformers_in_twosided_ridehailing_markets", "pdf": "/pdf/2e1d95eab956d7894f701146a590095527edb2b9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=i9kbk52UWw", "_bibtex": "@misc{\nwan2021causal,\ntitle={Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets},\nauthor={Shixiang Wan and Shikai Luo and Hongtu Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=4SiMia0kjba}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "4SiMia0kjba", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1578/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1578/Authors|ICLR.cc/2021/Conference/Paper1578/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858148, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1578/-/Official_Comment"}}}, {"id": "vXh4QTzMv9-", "original": null, "number": 12, "cdate": 1606155200633, "ddate": null, "tcdate": 1606155200633, "tmdate": 1606155251439, "tddate": null, "forum": "4SiMia0kjba", "replyto": "VGCzN4r15aw", "invitation": "ICLR.cc/2021/Conference/Paper1578/-/Official_Comment", "content": {"title": "Thanks for your useful comments again.", "comment": "Thanks for your useful comments again. Before deadline of final submission, we would continue to improve more details and make this work easy to read.\n\n* We are grateful to find that efficient attention is an interesting and useful research field. We would try our best to compare prior work about this issue.\n\n* We completely agree that a large number of methods have been proposed for spatio-temporal forecasting, and we promise that we will add more experiments of SOTA spatial baselines. **Additionally, we would appreciate it if you could recommend several typical SOTA spatial baselines.** The maximum benefit of our method is still up-to 15% in Table 3, as we split Table 2 in first version into Table 2 and Table 3. The main hyperparameters of baselines are consistent with their original papers.\n\n* We agree with your comment. Based on equation (1) and (2), we first predict demand $x_v(t+1:t+\\tau_{max})$, then predict supply $y_v(t+1:t+\\tau_{max})$ given $x_v(t+1:t+\\tau_{max})$ and other covariates. Forecasting order of both demand and supply reflects the causal relationship between them. Compared with joint effect (e,g. CRPS-sum), quantile risk losses (i.e., $R_{50}$ and $R_{90}$) are enough to evaluate the final performance and is fair to compare with SOTA peer-work."}, "signatures": ["ICLR.cc/2021/Conference/Paper1578/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets", "authorids": ["~Shixiang_Wan1", "~Shikai_Luo1", "~Hongtu_Zhu2"], "authors": ["Shixiang Wan", "Shikai Luo", "Hongtu Zhu"], "keywords": ["Spatio-temporal Prediction", "Causal Inference", "Efficient Transformers", "Two-sided Markets"], "abstract": "Achieving accurate spatio-temporal predictions in large-scale systems is extremely valuable in many real-world applications, such as weather forecasts, retail forecasting, and urban traffic forecasting. So far, most existing methods for multi-horizon, multi-task and multi-target predictions select important predicting variables via their correlations with responses, and thus it is highly possible that many forecasting models generated from those methods are not causal, leading to poor interpretability. The aim of this paper is to develop a collaborative causal spatio-temporal fusion transformer, named CausalTrans, to establish the collaborative causal effects of predictors on multiple forecasting targets, such as supply and demand in ride-sharing platforms. Specifically, we integrate the causal attention with the Conditional Average Treatment Effect (CATE) estimation method for causal inference. Moreover, we propose a novel and fast multi-head attention evolved from Taylor expansion instead of softmax, reducing time complexity from $O(\\mathcal{V}^2)$ to $O(\\mathcal{V})$, where $\\mathcal{V}$ is the number of nodes in a graph. We further design a spatial graph fusion mechanism to significantly reduce the parameters' scale. We conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various model components, and the time efficiency of our CausalTrans. As shown in these experiments, our CausalTrans framework can achieve up to 15$\\%$ error reduction compared with various baseline methods. ", "one-sentence_summary": "We develop a novel causal transformer with causal inference and efficient taylor attention to address large scale spatio-temporal predictions. Our method achieves up to 15% error reduction compared with various baseline methods. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wan|causal_probabilistic_spatiotemporal_fusion_transformers_in_twosided_ridehailing_markets", "pdf": "/pdf/2e1d95eab956d7894f701146a590095527edb2b9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=i9kbk52UWw", "_bibtex": "@misc{\nwan2021causal,\ntitle={Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets},\nauthor={Shixiang Wan and Shikai Luo and Hongtu Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=4SiMia0kjba}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "4SiMia0kjba", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1578/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1578/Authors|ICLR.cc/2021/Conference/Paper1578/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858148, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1578/-/Official_Comment"}}}, {"id": "_E7aYBncwb", "original": null, "number": 3, "cdate": 1605847579533, "ddate": null, "tcdate": 1605847579533, "tmdate": 1606129634814, "tddate": null, "forum": "4SiMia0kjba", "replyto": "VlTvPc0dGnc", "invitation": "ICLR.cc/2021/Conference/Paper1578/-/Official_Comment", "content": {"title": "Thank you very much for insightful comments! We will add some ablation analysis in Appendix to address your comments.", "comment": "1. \"The ablation analysis shows that spatial fusion shows tiny improvement (+0.3% on average). I\u2019d like the author to elaborate more on the reason. If there are hyperparameters for the spatial fusion, please do some ablation analysis in this regard.\"  \nResponse: Thanks a lot! We feel that spatial fusion aggregates adjacent hexagonal grids, leading to reducing statistical noises in both demand and supply. For instance, in some cases, the boundary (usually around 800 meters) of adjacent grids separates large demand hotpots (e.g., large shopping malls), resulting in some noise when counting supply and demand. Spatial fusion can reduce the influence of such noise, while improving the probabilistic forecasting performance. According to the ablation analysis in Appendix C.2, the longer forecasting time (e.g., 7 days versus 1 day), the more significant gain by using spatial fusion. We consider the use of spatial fusion as a trick for enhancing the robustness of forecasting. The hyperparameter of spatial fusion is $\\mathcal{K}$ used in the kmeans method. In this paper, we set $\\mathcal{K} \\in ${3, 4, 5}. To address your comments, we will add some ablation analysis in Appendix.  \n\n2. \"From experiments the fast attention improves computation a lot with only 0.2% performance dropped in multi-horizon methods. Is it the same in multi-horizon methods?\"  \nResponse: Thanks! It is an interesting discussion. We feel that, if attention feature maps (i.e. $Q$, $K$ and $V$ in original attention) can meet the positive definite and normalization conditions, and one focuses on short-term dependence, then the linear attention used here is useful for this aspect. The linear attention replaces softmax with the multiplication of feature maps, but such multiplication during the training is unstable with enforcing the positive definite and normalization conditions for feature maps. For our ride-hailing dataset, the positive definite condition is valid ($Q$, $K$ and $V$ are positive) and the L2 normalization is employed, so our training process is stable. In addition, almost all attentions with the linear complexity level (e.g., Sparse Attention proposed by OpenAI, Linformer proposed by Facebook, etc.) follow the same idea of \"mainly retaining the attentions in short context and forcing most of attentions to zero\". Moreover, linear attention in our work also focus on the short-term dependence such that the long-term dependence is ignored.  \n\n3. \"From table 1 the results show that, in case of Electricity, the proposed method can\u2019t outperform the state-of-the-art (TFT) due to lack of covariates and spatial information. I\u2019d like to see the ablation analysis (like table 3) in case of Traffic, showing that in case of the iterative method, the performance can be gained by each submodule.\"  \nResponse: We will add a series of ablation experiments in case of Traffic.\n\n4. \"Lack of experimental details. For example, learning rate/strategy, batch size, optimizer, architecture settings...etc. If the author(s) plan not to release the code in the future, it\u2019s better to list the experimental details in the appendix, for reproducing the performance.\"  \nResponse: We will include the detailed hyperparameters of the experiments (learning rate with decay strategies, optimizers, structure settings, etc.), training environment settings, training time and other details in Appendix. Moreover, we plan to release our source code later due to obtaining an open source license from our cooperation. "}, "signatures": ["ICLR.cc/2021/Conference/Paper1578/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets", "authorids": ["~Shixiang_Wan1", "~Shikai_Luo1", "~Hongtu_Zhu2"], "authors": ["Shixiang Wan", "Shikai Luo", "Hongtu Zhu"], "keywords": ["Spatio-temporal Prediction", "Causal Inference", "Efficient Transformers", "Two-sided Markets"], "abstract": "Achieving accurate spatio-temporal predictions in large-scale systems is extremely valuable in many real-world applications, such as weather forecasts, retail forecasting, and urban traffic forecasting. So far, most existing methods for multi-horizon, multi-task and multi-target predictions select important predicting variables via their correlations with responses, and thus it is highly possible that many forecasting models generated from those methods are not causal, leading to poor interpretability. The aim of this paper is to develop a collaborative causal spatio-temporal fusion transformer, named CausalTrans, to establish the collaborative causal effects of predictors on multiple forecasting targets, such as supply and demand in ride-sharing platforms. Specifically, we integrate the causal attention with the Conditional Average Treatment Effect (CATE) estimation method for causal inference. Moreover, we propose a novel and fast multi-head attention evolved from Taylor expansion instead of softmax, reducing time complexity from $O(\\mathcal{V}^2)$ to $O(\\mathcal{V})$, where $\\mathcal{V}$ is the number of nodes in a graph. We further design a spatial graph fusion mechanism to significantly reduce the parameters' scale. We conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various model components, and the time efficiency of our CausalTrans. As shown in these experiments, our CausalTrans framework can achieve up to 15$\\%$ error reduction compared with various baseline methods. ", "one-sentence_summary": "We develop a novel causal transformer with causal inference and efficient taylor attention to address large scale spatio-temporal predictions. Our method achieves up to 15% error reduction compared with various baseline methods. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wan|causal_probabilistic_spatiotemporal_fusion_transformers_in_twosided_ridehailing_markets", "pdf": "/pdf/2e1d95eab956d7894f701146a590095527edb2b9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=i9kbk52UWw", "_bibtex": "@misc{\nwan2021causal,\ntitle={Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets},\nauthor={Shixiang Wan and Shikai Luo and Hongtu Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=4SiMia0kjba}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "4SiMia0kjba", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1578/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1578/Authors|ICLR.cc/2021/Conference/Paper1578/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858148, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1578/-/Official_Comment"}}}, {"id": "ufB9NSy4aPG", "original": null, "number": 11, "cdate": 1606127522338, "ddate": null, "tcdate": 1606127522338, "tmdate": 1606127522338, "tddate": null, "forum": "4SiMia0kjba", "replyto": "NHOzh4FH32F", "invitation": "ICLR.cc/2021/Conference/Paper1578/-/Official_Comment", "content": {"title": "Thanks for your references", "comment": "Thanks for your references. We plan to do some experiments about existing linear attention methods to address this issue. "}, "signatures": ["ICLR.cc/2021/Conference/Paper1578/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets", "authorids": ["~Shixiang_Wan1", "~Shikai_Luo1", "~Hongtu_Zhu2"], "authors": ["Shixiang Wan", "Shikai Luo", "Hongtu Zhu"], "keywords": ["Spatio-temporal Prediction", "Causal Inference", "Efficient Transformers", "Two-sided Markets"], "abstract": "Achieving accurate spatio-temporal predictions in large-scale systems is extremely valuable in many real-world applications, such as weather forecasts, retail forecasting, and urban traffic forecasting. So far, most existing methods for multi-horizon, multi-task and multi-target predictions select important predicting variables via their correlations with responses, and thus it is highly possible that many forecasting models generated from those methods are not causal, leading to poor interpretability. The aim of this paper is to develop a collaborative causal spatio-temporal fusion transformer, named CausalTrans, to establish the collaborative causal effects of predictors on multiple forecasting targets, such as supply and demand in ride-sharing platforms. Specifically, we integrate the causal attention with the Conditional Average Treatment Effect (CATE) estimation method for causal inference. Moreover, we propose a novel and fast multi-head attention evolved from Taylor expansion instead of softmax, reducing time complexity from $O(\\mathcal{V}^2)$ to $O(\\mathcal{V})$, where $\\mathcal{V}$ is the number of nodes in a graph. We further design a spatial graph fusion mechanism to significantly reduce the parameters' scale. We conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various model components, and the time efficiency of our CausalTrans. As shown in these experiments, our CausalTrans framework can achieve up to 15$\\%$ error reduction compared with various baseline methods. ", "one-sentence_summary": "We develop a novel causal transformer with causal inference and efficient taylor attention to address large scale spatio-temporal predictions. Our method achieves up to 15% error reduction compared with various baseline methods. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wan|causal_probabilistic_spatiotemporal_fusion_transformers_in_twosided_ridehailing_markets", "pdf": "/pdf/2e1d95eab956d7894f701146a590095527edb2b9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=i9kbk52UWw", "_bibtex": "@misc{\nwan2021causal,\ntitle={Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets},\nauthor={Shixiang Wan and Shikai Luo and Hongtu Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=4SiMia0kjba}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "4SiMia0kjba", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1578/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1578/Authors|ICLR.cc/2021/Conference/Paper1578/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858148, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1578/-/Official_Comment"}}}, {"id": "VGCzN4r15aw", "original": null, "number": 10, "cdate": 1606125226025, "ddate": null, "tcdate": 1606125226025, "tmdate": 1606125226025, "tddate": null, "forum": "4SiMia0kjba", "replyto": "cnjsn5gtG-k", "invitation": "ICLR.cc/2021/Conference/Paper1578/-/Official_Comment", "content": {"title": "answer", "comment": "Thank you very much for your detailed answer. However, I still have concerns regarding accepting the paper:\n\n- it is better now that are you are discussing prior work on efficient attention but there is no comparison in your experiments, past-work are only mentioned in the appendix (and unfortunately they were not discussed at all for the first version which is problematic given that efficient attention is a main contribution claim of the paper)\n\n- spatial-temporal baselines: I am glad that you added two baselines that have access to spatial information however the current comparison is still lacking in this aspect. A large number of methods have been proposed for spatio-temporal forecasting and your paper only compares with two. The benefit of the method already shrank from up-to 15% to up-to 9% (this should be updated in the abstract). The comparison here should be more extensive and proper details should be given on those baselines, it is unclear how much the claim improvement will shrink in light of those comparisons. \n\n- regarding my point about \"lack of relevant metrics\", I meant to highlight that you are only measuring error as if supply and demand were independent but they are clearly correlated (and you model predict correlated samples since the prediction of $y_v$ takes $x_v$ as input). Hence, it makes sense to have an error metric that measures this joint effect, CRPS-sum would be one possible example. This point is less problematic that the previous above though.\n\nFinally, regarding the technical clarity, I am glad that many typos were fixed but the changes are substantial (there were many technical issues in the submitted version) and I believe should be evaluated as another round of review."}, "signatures": ["ICLR.cc/2021/Conference/Paper1578/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets", "authorids": ["~Shixiang_Wan1", "~Shikai_Luo1", "~Hongtu_Zhu2"], "authors": ["Shixiang Wan", "Shikai Luo", "Hongtu Zhu"], "keywords": ["Spatio-temporal Prediction", "Causal Inference", "Efficient Transformers", "Two-sided Markets"], "abstract": "Achieving accurate spatio-temporal predictions in large-scale systems is extremely valuable in many real-world applications, such as weather forecasts, retail forecasting, and urban traffic forecasting. So far, most existing methods for multi-horizon, multi-task and multi-target predictions select important predicting variables via their correlations with responses, and thus it is highly possible that many forecasting models generated from those methods are not causal, leading to poor interpretability. The aim of this paper is to develop a collaborative causal spatio-temporal fusion transformer, named CausalTrans, to establish the collaborative causal effects of predictors on multiple forecasting targets, such as supply and demand in ride-sharing platforms. Specifically, we integrate the causal attention with the Conditional Average Treatment Effect (CATE) estimation method for causal inference. Moreover, we propose a novel and fast multi-head attention evolved from Taylor expansion instead of softmax, reducing time complexity from $O(\\mathcal{V}^2)$ to $O(\\mathcal{V})$, where $\\mathcal{V}$ is the number of nodes in a graph. We further design a spatial graph fusion mechanism to significantly reduce the parameters' scale. We conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various model components, and the time efficiency of our CausalTrans. As shown in these experiments, our CausalTrans framework can achieve up to 15$\\%$ error reduction compared with various baseline methods. ", "one-sentence_summary": "We develop a novel causal transformer with causal inference and efficient taylor attention to address large scale spatio-temporal predictions. Our method achieves up to 15% error reduction compared with various baseline methods. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wan|causal_probabilistic_spatiotemporal_fusion_transformers_in_twosided_ridehailing_markets", "pdf": "/pdf/2e1d95eab956d7894f701146a590095527edb2b9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=i9kbk52UWw", "_bibtex": "@misc{\nwan2021causal,\ntitle={Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets},\nauthor={Shixiang Wan and Shikai Luo and Hongtu Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=4SiMia0kjba}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "4SiMia0kjba", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1578/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1578/Authors|ICLR.cc/2021/Conference/Paper1578/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858148, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1578/-/Official_Comment"}}}, {"id": "NHOzh4FH32F", "original": null, "number": 9, "cdate": 1606124266983, "ddate": null, "tcdate": 1606124266983, "tmdate": 1606124266983, "tddate": null, "forum": "4SiMia0kjba", "replyto": "fXJWCXuNYC7", "invitation": "ICLR.cc/2021/Conference/Paper1578/-/Official_Comment", "content": {"title": "missing references", "comment": "I am sorry that references were not pasted correctly in my review, I have updated them."}, "signatures": ["ICLR.cc/2021/Conference/Paper1578/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets", "authorids": ["~Shixiang_Wan1", "~Shikai_Luo1", "~Hongtu_Zhu2"], "authors": ["Shixiang Wan", "Shikai Luo", "Hongtu Zhu"], "keywords": ["Spatio-temporal Prediction", "Causal Inference", "Efficient Transformers", "Two-sided Markets"], "abstract": "Achieving accurate spatio-temporal predictions in large-scale systems is extremely valuable in many real-world applications, such as weather forecasts, retail forecasting, and urban traffic forecasting. So far, most existing methods for multi-horizon, multi-task and multi-target predictions select important predicting variables via their correlations with responses, and thus it is highly possible that many forecasting models generated from those methods are not causal, leading to poor interpretability. The aim of this paper is to develop a collaborative causal spatio-temporal fusion transformer, named CausalTrans, to establish the collaborative causal effects of predictors on multiple forecasting targets, such as supply and demand in ride-sharing platforms. Specifically, we integrate the causal attention with the Conditional Average Treatment Effect (CATE) estimation method for causal inference. Moreover, we propose a novel and fast multi-head attention evolved from Taylor expansion instead of softmax, reducing time complexity from $O(\\mathcal{V}^2)$ to $O(\\mathcal{V})$, where $\\mathcal{V}$ is the number of nodes in a graph. We further design a spatial graph fusion mechanism to significantly reduce the parameters' scale. We conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various model components, and the time efficiency of our CausalTrans. As shown in these experiments, our CausalTrans framework can achieve up to 15$\\%$ error reduction compared with various baseline methods. ", "one-sentence_summary": "We develop a novel causal transformer with causal inference and efficient taylor attention to address large scale spatio-temporal predictions. Our method achieves up to 15% error reduction compared with various baseline methods. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wan|causal_probabilistic_spatiotemporal_fusion_transformers_in_twosided_ridehailing_markets", "pdf": "/pdf/2e1d95eab956d7894f701146a590095527edb2b9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=i9kbk52UWw", "_bibtex": "@misc{\nwan2021causal,\ntitle={Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets},\nauthor={Shixiang Wan and Shikai Luo and Hongtu Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=4SiMia0kjba}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "4SiMia0kjba", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1578/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1578/Authors|ICLR.cc/2021/Conference/Paper1578/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858148, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1578/-/Official_Comment"}}}, {"id": "nCqPm9Qsi7", "original": null, "number": 1, "cdate": 1603795621015, "ddate": null, "tcdate": 1603795621015, "tmdate": 1606124230656, "tddate": null, "forum": "4SiMia0kjba", "replyto": "4SiMia0kjba", "invitation": "ICLR.cc/2021/Conference/Paper1578/-/Official_Review", "content": {"title": "Recommendation to Reject", "review": "The paper is interested with multivariate probabilistic forecasting applied in the context of ride-hailing forecast.\nThe goal is to be able to handle the spatial aspect, causal effects of external covariates (e.g. the causal impact of rain, Christmas on supply/demand) and dependency between supply and demand. To this end, the authors propose a causal attention mechanism\t(to not just detect correlation with covariates) and a custom transformer architecture where the quadratic attention cost is avoided. Experiments are performed on public and private datasets against a set of (mostly) univariate baselines.\n\nStrong points:\n+ highly-relevant problem\n+ novel consideration of handling causality instead of simple covariate correlation in this context\n\nWeak points:\n- very hard to read, many details missing and notation are not introduced\n- lack of relevant baselines (e.g. baselines using spatial information)\n- lack of relevant metrics to illustrate the benefit of the contribution\n- missing related work discussion for efficient attention computation\n\nI recommend a reject for this paper.\n\nWhile the problem presented by the paper is highly relevant for the community, the paper has several issues that makes it not ready for publication. The first issue comes in the clarity of the description and in particular section 3.3 where many terms and notation are not introduced at all making the paper very hard to read (see detailed comments). \n\nExperiments are also problematic as many details were unclear (see detailed comments) and would be far from being reproducible. But the most problematic bit is in its design: key aspects introduced in the paper are not asserted in the experiments.1) While the method claims ~5% error improvement on the ride-hailing benchmark, only one baseline have access to spatial information while numerous methods have been proposed to handle spatio-temporal forecast, only one baseline (TFT) is provided with spatial information (with no detail). 2) Since you are interested in the probabilistic forecast of the joint demand/supply targets (collaborative), your experimental setup should consider a joint metric (CRPS-sum for instance [1,2]) rather than the average of R50/R90 metrics of demand/supply targets which is \"blind\" to correlation between the two demand and supply targets.\n\nFinally, I had issue with the Taylor expansion as its description was not clear (see detailed comments) but also I found description of related work missing in this aspect. Attention cost has been decreased to $N\\sqrt{N}$, $N\\log{N}$ and $N$ respectively in [3, 4, 5], this discussion is clearly missing to relate your contribution.\n\n# Additional questions to the author\n- 3.1 at no point in the paper you say explicitly what is the loss that you are minimizing, this makes it harder to read. I would recommend to specify in 3.1 directly that you minimize NLE with poisson distribution (which is what I understood) and specify also clearly how predictions are made.\n- 3.3 the beginning of the section mix model description and related work\n- 3.3 Eq. (3) has two unintroduced notation, what is the \\bar? what is \"batch\"?\n- 3.3 Eq. (6) is so confusing, you are mixing norms and vectors (unintroduced), $T$ is not explicitly introduced, there is no clear explanation why the approximation holds also (e.g. why a^T W would be small)\n- 4.2 DeepState is *not* an auto-regressive model, it belongs to the second category.\n- 4.3: \"CausalTrans outperforms all other competing methods primarily due to the use of the causal estimator DML and spatial information\". This is very problematic as you dont compare with methods designed to handle spatial information. \n\n# Additional feedback (not part of the decision assessment)\n- 3.1 eq (1) (2) makes an assumption that only demand impacts supply: it would be good to discuss it at least. One could imagine where it breaks.\n- 3.1 weather features: you should precise whether they are known in advance\n- 3.3 The section will be easier to read if you indicate variable dimensions\n\nFinally, I would recommend to use a public dataset rather than the private one for your benchmark (e.g. NY taxi dataset or Uber), you also have covariates such as date or weather forecast and this would make your work comparable and reproducible in the future.\n\n\n\n[1] High-dimensional multivariate forecasting with low-rank Gaussian Copula Processes http://papers.nips.cc/paper/8907-high-dimensional-multivariate-forecasting-with-low-rank-gaussian-copula-processes\n\n[2] Multi-variate Probabilistic Time Series Forecasting via Conditioned Normalizing Flows https://arxiv.org/abs/2002.06103\n\n[3] Generating Long Sequences with Sparse Transformers https://arxiv.org/pdf/1904.10509.pdf\n\n[4] Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention https://arxiv.org/abs/2006.16236\n\n[5] Reformer: The Efficient Transformer https://arxiv.org/abs/2001.04451\n\n", "rating": "2: Strong rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper1578/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets", "authorids": ["~Shixiang_Wan1", "~Shikai_Luo1", "~Hongtu_Zhu2"], "authors": ["Shixiang Wan", "Shikai Luo", "Hongtu Zhu"], "keywords": ["Spatio-temporal Prediction", "Causal Inference", "Efficient Transformers", "Two-sided Markets"], "abstract": "Achieving accurate spatio-temporal predictions in large-scale systems is extremely valuable in many real-world applications, such as weather forecasts, retail forecasting, and urban traffic forecasting. So far, most existing methods for multi-horizon, multi-task and multi-target predictions select important predicting variables via their correlations with responses, and thus it is highly possible that many forecasting models generated from those methods are not causal, leading to poor interpretability. The aim of this paper is to develop a collaborative causal spatio-temporal fusion transformer, named CausalTrans, to establish the collaborative causal effects of predictors on multiple forecasting targets, such as supply and demand in ride-sharing platforms. Specifically, we integrate the causal attention with the Conditional Average Treatment Effect (CATE) estimation method for causal inference. Moreover, we propose a novel and fast multi-head attention evolved from Taylor expansion instead of softmax, reducing time complexity from $O(\\mathcal{V}^2)$ to $O(\\mathcal{V})$, where $\\mathcal{V}$ is the number of nodes in a graph. We further design a spatial graph fusion mechanism to significantly reduce the parameters' scale. We conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various model components, and the time efficiency of our CausalTrans. As shown in these experiments, our CausalTrans framework can achieve up to 15$\\%$ error reduction compared with various baseline methods. ", "one-sentence_summary": "We develop a novel causal transformer with causal inference and efficient taylor attention to address large scale spatio-temporal predictions. Our method achieves up to 15% error reduction compared with various baseline methods. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wan|causal_probabilistic_spatiotemporal_fusion_transformers_in_twosided_ridehailing_markets", "pdf": "/pdf/2e1d95eab956d7894f701146a590095527edb2b9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=i9kbk52UWw", "_bibtex": "@misc{\nwan2021causal,\ntitle={Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets},\nauthor={Shixiang Wan and Shikai Luo and Hongtu Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=4SiMia0kjba}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "4SiMia0kjba", "replyto": "4SiMia0kjba", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1578/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538115539, "tmdate": 1606915781335, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1578/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1578/-/Official_Review"}}}, {"id": "eOqS8ijd4n2", "original": null, "number": 5, "cdate": 1605891188703, "ddate": null, "tcdate": 1605891188703, "tmdate": 1605891393234, "tddate": null, "forum": "4SiMia0kjba", "replyto": "nCqPm9Qsi7", "invitation": "ICLR.cc/2021/Conference/Paper1578/-/Official_Comment", "content": {"title": "Thank you very much for many insightful comments, and we plan to add more spatial baselines and discussion about linear attention.", "comment": "11. \"3.3 Eq. (6) is so confusing, you are mixing norms and vectors (unintroduced), is not explicitly introduced, there is no clear explanation why the approximation holds also (e.g. why a^T W would be small)\"  \nResponse: Thanks a lot for pointing out our mistake. Equation (6) should be corrected as: $\\exp(a^TW) \\approx \\mathcal{T}(a^TW) = 1 + \\left(\\frac{a}{||a||_2}\\right)^T \\left(\\frac{W}{||W||_2}\\right)$\u3002Analogous to the self-attention in original Transformer, the approximate mean and variance of $\\frac{QK^T}{\\sqrt{d_k}}$ are 0 and 1, respectively, so $a^TW$ here are limited to small values. We introduce $L_2$ normalization to ensure small $a^TW$ and $1 + a^TW \\geq 0$, as mentioned in equation (6) above.\n\n12. \"4.2 DeepState is not an auto-regressive model, it belongs to the second category.\"  \nResponse: We tend to classify DeepState as an iterative step-by-step forecasting method (i.e., the first category), which is consistent with categories in TFT paper [1].  \n[1]. Lim, Bryan, et al. \"Temporal fusion transformers for interpretable multi-horizon time series forecasting.\" arXiv preprint arXiv:1912.09363 (2019).\n\n13. \"4.3: \"CausalTrans outperforms all other competing methods primarily due to the use of the causal estimator DML and spatial information\". This is very problematic as you don't compare with methods designed to handle spatial information.\"  \nResponse: As mentioned in the second comment above, we plan to add more spatial baselines as competitors.\n\n14. \"3.1 eq (1) (2) makes an assumption that only demand impacts supply: it would be good to discuss it at least. One could imagine where it breaks.\"  \nResponse: Thanks a lot! Equation (1) and (2) are primarily based on our understanding of business. The first one is that the demand $x$ may depend on historical supply $y$ that happens several weeks (or even longer) ago. But in the last several weeks (training period), for customers, their demands may be primarily influenced by their own historical patterns and their recent request completion rates. The second one is that the demand may rise when supply is not enough for demand and demand may accumulate.  \nIn short, we feel that the distribution of demand is primarily determined by its historical distribution since the forecast period that we consider in the ride-sharing business is a short-term range (usually 1~7 days). Regarding to the first comment, we usually include historical request completion rate as an external covariate in $z$ to explain it better. The second one usually happens during the rush hour and lasts for 1-2 hours, leading to 2-4 outlying observations due to the temporal resolution being 30 minutes. Moreover, we have included the historical and current demands to predict the future demands such that the proposed equations work reasonably well. To address this issue better, we plan to introduce the request completion rate and integrate it with existing external covariates.  \n\n15. \"3.1 weather features: you should precise whether they are known in advance\"  \nResponse: The future weather features (i.e. the weather forecast) are known conditions.\n\n16. \"3.3 The section will be easier to read if you indicate variable dimensions\"  \nResponse: Thanks a lot! We consider to add more details about variable dimensions in Appendix.\n\n17. \"...I would recommend to use a public dataset rather than the private one for your benchmark...\"  \nResponse: Thanks for your kindly suggestion. At the beginning of this work, we consider that the scale of public dataset is limited, and proposed algorithms may be easier to learn special tricks (or patterns) due to lose good generalization. Serval methods (e.g. N-Beats [1]) that performed almost best on public datasets (e.g. M4 competition [2]), but performed very bad on our large-scale dataset. For reproducibility, we plan to release source code later after obtaining an open source license from our cooperation.   \n[1]. Oreshkin, Boris N., et al. \"N-BEATS: Neural basis expansion analysis for interpretable time series forecasting.\" arXiv preprint arXiv:1905.10437 (2019).  \n[2]. https://www.kaggle.com/yogesh94/m4-forecasting-competition-dataset"}, "signatures": ["ICLR.cc/2021/Conference/Paper1578/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets", "authorids": ["~Shixiang_Wan1", "~Shikai_Luo1", "~Hongtu_Zhu2"], "authors": ["Shixiang Wan", "Shikai Luo", "Hongtu Zhu"], "keywords": ["Spatio-temporal Prediction", "Causal Inference", "Efficient Transformers", "Two-sided Markets"], "abstract": "Achieving accurate spatio-temporal predictions in large-scale systems is extremely valuable in many real-world applications, such as weather forecasts, retail forecasting, and urban traffic forecasting. So far, most existing methods for multi-horizon, multi-task and multi-target predictions select important predicting variables via their correlations with responses, and thus it is highly possible that many forecasting models generated from those methods are not causal, leading to poor interpretability. The aim of this paper is to develop a collaborative causal spatio-temporal fusion transformer, named CausalTrans, to establish the collaborative causal effects of predictors on multiple forecasting targets, such as supply and demand in ride-sharing platforms. Specifically, we integrate the causal attention with the Conditional Average Treatment Effect (CATE) estimation method for causal inference. Moreover, we propose a novel and fast multi-head attention evolved from Taylor expansion instead of softmax, reducing time complexity from $O(\\mathcal{V}^2)$ to $O(\\mathcal{V})$, where $\\mathcal{V}$ is the number of nodes in a graph. We further design a spatial graph fusion mechanism to significantly reduce the parameters' scale. We conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various model components, and the time efficiency of our CausalTrans. As shown in these experiments, our CausalTrans framework can achieve up to 15$\\%$ error reduction compared with various baseline methods. ", "one-sentence_summary": "We develop a novel causal transformer with causal inference and efficient taylor attention to address large scale spatio-temporal predictions. Our method achieves up to 15% error reduction compared with various baseline methods. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wan|causal_probabilistic_spatiotemporal_fusion_transformers_in_twosided_ridehailing_markets", "pdf": "/pdf/2e1d95eab956d7894f701146a590095527edb2b9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=i9kbk52UWw", "_bibtex": "@misc{\nwan2021causal,\ntitle={Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets},\nauthor={Shixiang Wan and Shikai Luo and Hongtu Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=4SiMia0kjba}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "4SiMia0kjba", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1578/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1578/Authors|ICLR.cc/2021/Conference/Paper1578/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858148, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1578/-/Official_Comment"}}}, {"id": "cnjsn5gtG-k", "original": null, "number": 7, "cdate": 1605891368486, "ddate": null, "tcdate": 1605891368486, "tmdate": 1605891368486, "tddate": null, "forum": "4SiMia0kjba", "replyto": "nCqPm9Qsi7", "invitation": "ICLR.cc/2021/Conference/Paper1578/-/Official_Comment", "content": {"title": "Thank you very much for many insightful comments, and we plan to add more spatial baselines and discussion about linear attention.", "comment": "1. \"very hard to read, many details missing and notation are not introduced\"  \nResponse: We are sorry for the lack of necessary details and notation descriptions, and we will revise a new version with more details.\n\n2. \"lack of relevant baselines (e.g. baselines using spatial information)\"  \nResponse: We agree with your comment. Actually, our work does not focus on making full use of spatial information to greatly reduce forecasting error, but leveraging spatial information to improve training efficiency. However, to address your comment, we plan to do a series of experiments on spatial baselines  (e.g. ST-MGCN [1] and DMVST [2]).  \n[1]. Geng, Xu, et al. \"Spatiotemporal multi-graph convolution network for ride-hailing demand forecasting.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 33. 2019.  \n[2]. Yao, Huaxiu, et al. \"Deep multi-view spatial-temporal network for taxi demand prediction.\" In Thirty-Second AAAI Conference on Artificial Intelligence. 2018.\n\n3. \"lack of relevant metrics to illustrate the benefit of the contribution\"  \nResponse: Maybe we have some different perspectives about your comment. In Appendix A, we have described Risk-q $\\mathcal{R}_q$ as the metric of probabilistic forecasting, which is consistent with a series of compared SOTA studies (DeepAR, MQRNN, TFT, etc.).\n\n4. \"missing related work discussion for efficient attention computation\"  \nResponse: Thanks a lot! We will include the related work about attention acceleration in Section 3. A simple comparison will be discussed in the 7th response.\n\n5. \"1) While the method claims ~5% error improvement on the ride-hailing benchmark, only one baseline have access to spatial information while numerous methods have been proposed to handle spatio-temporal forecast, only one baseline (TFT) is provided with spatial information (with no detail). \"  \n Response: As mentioned in the second comment above, we plan to add more spatial baselines as competitors.\n\n6. \"2) Since you are interested in the probabilistic forecast of the joint demand/supply targets (collaborative), your experimental setup should consider a joint metric (CRPS-sum for instance [1,2]) rather than the average of R50/R90 metrics of demand/supply targets which is \"blind\" to correlation be\"  \nResponse: Our collaborative supply and demand forecasting refers to the causal relationship (i.e., equation (1) and (2) ) but not continuous ranked probability score sum (CRPS-sum) between demand and supply. CRPS-sum is a popular metric for probability forecasting, but it is not what we actually need. Under the collaborative/causal supply and demand framework, we only need quantile probabilistic distribution to forecast responses, which is consistent with a series of compared SOTA studies (DeepAR, MQRNN, TFT, etc.) and aligned with our business situations. "}, "signatures": ["ICLR.cc/2021/Conference/Paper1578/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets", "authorids": ["~Shixiang_Wan1", "~Shikai_Luo1", "~Hongtu_Zhu2"], "authors": ["Shixiang Wan", "Shikai Luo", "Hongtu Zhu"], "keywords": ["Spatio-temporal Prediction", "Causal Inference", "Efficient Transformers", "Two-sided Markets"], "abstract": "Achieving accurate spatio-temporal predictions in large-scale systems is extremely valuable in many real-world applications, such as weather forecasts, retail forecasting, and urban traffic forecasting. So far, most existing methods for multi-horizon, multi-task and multi-target predictions select important predicting variables via their correlations with responses, and thus it is highly possible that many forecasting models generated from those methods are not causal, leading to poor interpretability. The aim of this paper is to develop a collaborative causal spatio-temporal fusion transformer, named CausalTrans, to establish the collaborative causal effects of predictors on multiple forecasting targets, such as supply and demand in ride-sharing platforms. Specifically, we integrate the causal attention with the Conditional Average Treatment Effect (CATE) estimation method for causal inference. Moreover, we propose a novel and fast multi-head attention evolved from Taylor expansion instead of softmax, reducing time complexity from $O(\\mathcal{V}^2)$ to $O(\\mathcal{V})$, where $\\mathcal{V}$ is the number of nodes in a graph. We further design a spatial graph fusion mechanism to significantly reduce the parameters' scale. We conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various model components, and the time efficiency of our CausalTrans. As shown in these experiments, our CausalTrans framework can achieve up to 15$\\%$ error reduction compared with various baseline methods. ", "one-sentence_summary": "We develop a novel causal transformer with causal inference and efficient taylor attention to address large scale spatio-temporal predictions. Our method achieves up to 15% error reduction compared with various baseline methods. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wan|causal_probabilistic_spatiotemporal_fusion_transformers_in_twosided_ridehailing_markets", "pdf": "/pdf/2e1d95eab956d7894f701146a590095527edb2b9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=i9kbk52UWw", "_bibtex": "@misc{\nwan2021causal,\ntitle={Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets},\nauthor={Shixiang Wan and Shikai Luo and Hongtu Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=4SiMia0kjba}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "4SiMia0kjba", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1578/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1578/Authors|ICLR.cc/2021/Conference/Paper1578/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858148, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1578/-/Official_Comment"}}}, {"id": "fXJWCXuNYC7", "original": null, "number": 6, "cdate": 1605891244680, "ddate": null, "tcdate": 1605891244680, "tmdate": 1605891244680, "tddate": null, "forum": "4SiMia0kjba", "replyto": "nCqPm9Qsi7", "invitation": "ICLR.cc/2021/Conference/Paper1578/-/Official_Comment", "content": {"title": "Thank you very much for many insightful comments, and we plan to add more spatial baselines and discussion about linear attention.", "comment": "\n7. \"Finally, I had issue with the Taylor expansion as its description was not clear (see detailed comments) but also I found description of related work missing in this aspect. Attention cost has been decreased to $N\\sqrt{N}$, $N\\log{N}$ and $N$ respectively in [3, 4, 5], this discussion is clearly missing to relate your contribution.\"  \nResponse: Thanks for your insightful comment. It should be noted that we cannot find the references \"[3, 4, 5]\" you quoted above. We try to compare several latest studies about linear attention acceleration and add this discussion in Section 3 later.  \nThe current attention acceleration methods can be roughly clarified into two groups. The first one is to construct kernel functions to approximate softmax. Katharopoulos et al. [1] constructs a kernel function with basis function $\\varphi(x)=\\phi(x)=elu(x)+1$. Shen et al. [2] replaces the calculation order of softmax, which is equivalent to the basis function $\\phi(x)=softmax(x)$ and $\\varphi(x)=e^x$.  \nThe second one is to modify attention's definition. For example, the time complexity of OpenAI's Sparse Attention [3] is close to linear, but its attention  hyperparameters are very hard to be initialized and actual efficiency is hard to ensure. The time complexity of Reformer [4] is $O(nlog(n))$. It uses LSH (Locality Sensitive Hashing) to find the maximum attention values quickly and then constructs a reversible FFN (Feedforward Network) to replace the original FFN and redesign back propagation process to reduce GPU memory usage. However, Reformer is difficult to implement and debug. Facebook\u2019s Linformer [5] uses two additional matrices $E$ and $V$ to project $K$ and $V$, respectively, in order to get $Attention(Q,K,V)=softmax(Q(EK)^T )FV$. But the MLM experiment in Linformer needn't extract long-term dependence and cannot verify its linear time complexity. Moreover, many latest pooling methods (e.g., PoWER-BERT [6] and Funnel-Transformer [7]) are proposed to shorten feature maps but still difficult to implement and understand.  \n[1]. Katharopoulos, Angelos, et al. \"Transformers are rnns: Fast autoregressive transformers with linear attention.\" arXiv preprint arXiv:2006.16236 (2020).  \n[2]. Shen, Zhuoran, et al. \"Efficient Attention: Attention with Linear Complexities.\" arXiv preprint arXiv:1812.01243 (2018).  \n[3]. Child, Rewon, et al. \"Generating long sequences with sparse transformers.\" arXiv preprint arXiv:1904.10509 (2019).  \n[4]. Kitaev, Nikita, \u0141ukasz Kaiser, and Anselm Levskaya. \"Reformer: The efficient transformer.\" arXiv preprint arXiv:2001.04451 (2020).  \n[5]. Wang, Sinong, et al. \"Linformer: Self-Attention with Linear Complexity.\" arXiv preprint arXiv:2006.04768 (2020).  \n[6]. Goyal, Saurabh, et al. \"PoWER-BERT: Accelerating BERT inference for Classification Tasks.\" arXiv preprint arXiv:2001.08950 (2020).  \n[7]. Dai, Zihang, et al. \"Funnel-Transformer: Filtering out Sequential Redundancy for Efficient Language Processing.\" arXiv preprint arXiv:2006.03236 (2020).  \n\n8. \"3.1 at no point in the paper you say explicitly what is the loss that you are minimizing, this makes it harder to read. I would recommend to specify in 3.1 directly that you minimize NLE with poisson distribution (which is what I understood) and specify also clearly how predictions are made.\"  \nResponse: We employ quantile loss (with poisson distribution or not) to learn probabilistic distribution that introduced in Subsection 3.2 and Appendix A. We will move this part from appendix A to Subsection 3.1 to address your comment.\n\n9. \"3.3 the beginning of the section mix model description and related work\"  \nResponse: The related work in Section 2 is all about probabilistic forecasting, but the beginning of the Subsection 3.3 is to explain the reasons that we employ \"GAT\" and \"Transformer\" as basic algorithms. We consider that they do not mix model description, otherwise readers may confuse that \"why you choose GAT and Transformer\".\n\n10. 3.3 Eq. (3) has two unintroduced notation, what is the \\bar? what is \"batch\"?  \nResponse: $\\overline{[\\cdot]}_{Batch}$ is the mean operator on the batch mode. We will add this notation in Subsection 3.3, and carefully verify other notations."}, "signatures": ["ICLR.cc/2021/Conference/Paper1578/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets", "authorids": ["~Shixiang_Wan1", "~Shikai_Luo1", "~Hongtu_Zhu2"], "authors": ["Shixiang Wan", "Shikai Luo", "Hongtu Zhu"], "keywords": ["Spatio-temporal Prediction", "Causal Inference", "Efficient Transformers", "Two-sided Markets"], "abstract": "Achieving accurate spatio-temporal predictions in large-scale systems is extremely valuable in many real-world applications, such as weather forecasts, retail forecasting, and urban traffic forecasting. So far, most existing methods for multi-horizon, multi-task and multi-target predictions select important predicting variables via their correlations with responses, and thus it is highly possible that many forecasting models generated from those methods are not causal, leading to poor interpretability. The aim of this paper is to develop a collaborative causal spatio-temporal fusion transformer, named CausalTrans, to establish the collaborative causal effects of predictors on multiple forecasting targets, such as supply and demand in ride-sharing platforms. Specifically, we integrate the causal attention with the Conditional Average Treatment Effect (CATE) estimation method for causal inference. Moreover, we propose a novel and fast multi-head attention evolved from Taylor expansion instead of softmax, reducing time complexity from $O(\\mathcal{V}^2)$ to $O(\\mathcal{V})$, where $\\mathcal{V}$ is the number of nodes in a graph. We further design a spatial graph fusion mechanism to significantly reduce the parameters' scale. We conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various model components, and the time efficiency of our CausalTrans. As shown in these experiments, our CausalTrans framework can achieve up to 15$\\%$ error reduction compared with various baseline methods. ", "one-sentence_summary": "We develop a novel causal transformer with causal inference and efficient taylor attention to address large scale spatio-temporal predictions. Our method achieves up to 15% error reduction compared with various baseline methods. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wan|causal_probabilistic_spatiotemporal_fusion_transformers_in_twosided_ridehailing_markets", "pdf": "/pdf/2e1d95eab956d7894f701146a590095527edb2b9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=i9kbk52UWw", "_bibtex": "@misc{\nwan2021causal,\ntitle={Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets},\nauthor={Shixiang Wan and Shikai Luo and Hongtu Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=4SiMia0kjba}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "4SiMia0kjba", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1578/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1578/Authors|ICLR.cc/2021/Conference/Paper1578/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858148, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1578/-/Official_Comment"}}}, {"id": "GXk-mmXPME7", "original": null, "number": 4, "cdate": 1605847855495, "ddate": null, "tcdate": 1605847855495, "tmdate": 1605847855495, "tddate": null, "forum": "4SiMia0kjba", "replyto": "E6gZWHZNzad", "invitation": "ICLR.cc/2021/Conference/Paper1578/-/Official_Comment", "content": {"title": "Thank you very much for insightful comments! We consider to add more descriptions about causal model ideas. ", "comment": "1. \"The assumption that the supply is always conditioned on the demand $x_v(, t + \\tau_{max})$ is too strong. Is there a smoother of this assumption where the demand is dependent on a moving window over the past and future supply? \"   \nResponse: Thanks a lot for your insightful comments! In practice, we choose different sliding windows to limit training time range. Specially, the sliding window is the past two weeks when forecast period is one day, and the sliding window is the past four weeks when forecast period is seven days. We will emphasize these settings in subsection 3.1, and the detailed experimental details will be listed in Appendix.  \nIn addition, we agree that the demand $x$ may depend on historical supply $y$ that happens several weeks (or even longer) ago. But in the last several weeks (i.e. training period), for customers, their demands may be primarily influenced by their own historical patterns and their recent request completion rates. Regarding to your question, we usually include historical request completion rate as an external covariate in $z$ to address demand forecasting perfectly. Moreover, we have included the historical and current demands to predict the future demands such that the proposed equations work reasonably well. Furthermore, we plan to introduce the request completion rate and integrate it with existing external covariates $z$. \n\n2. \"Other suggestions - make the use of the word 'collaborative' in the model more clear. The significance of the results is not completely clear and how the interpretability is helping understanding of the results. Adding clarifications will help in the exposition.\"  \nResponse: Thanks for your kindly suggestions. We will add further explanations about 'collaborative' in subsection 3.1 and more worthy details, such as discussion about causal attention and descriptions about experimental hyperparameters."}, "signatures": ["ICLR.cc/2021/Conference/Paper1578/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets", "authorids": ["~Shixiang_Wan1", "~Shikai_Luo1", "~Hongtu_Zhu2"], "authors": ["Shixiang Wan", "Shikai Luo", "Hongtu Zhu"], "keywords": ["Spatio-temporal Prediction", "Causal Inference", "Efficient Transformers", "Two-sided Markets"], "abstract": "Achieving accurate spatio-temporal predictions in large-scale systems is extremely valuable in many real-world applications, such as weather forecasts, retail forecasting, and urban traffic forecasting. So far, most existing methods for multi-horizon, multi-task and multi-target predictions select important predicting variables via their correlations with responses, and thus it is highly possible that many forecasting models generated from those methods are not causal, leading to poor interpretability. The aim of this paper is to develop a collaborative causal spatio-temporal fusion transformer, named CausalTrans, to establish the collaborative causal effects of predictors on multiple forecasting targets, such as supply and demand in ride-sharing platforms. Specifically, we integrate the causal attention with the Conditional Average Treatment Effect (CATE) estimation method for causal inference. Moreover, we propose a novel and fast multi-head attention evolved from Taylor expansion instead of softmax, reducing time complexity from $O(\\mathcal{V}^2)$ to $O(\\mathcal{V})$, where $\\mathcal{V}$ is the number of nodes in a graph. We further design a spatial graph fusion mechanism to significantly reduce the parameters' scale. We conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various model components, and the time efficiency of our CausalTrans. As shown in these experiments, our CausalTrans framework can achieve up to 15$\\%$ error reduction compared with various baseline methods. ", "one-sentence_summary": "We develop a novel causal transformer with causal inference and efficient taylor attention to address large scale spatio-temporal predictions. Our method achieves up to 15% error reduction compared with various baseline methods. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wan|causal_probabilistic_spatiotemporal_fusion_transformers_in_twosided_ridehailing_markets", "pdf": "/pdf/2e1d95eab956d7894f701146a590095527edb2b9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=i9kbk52UWw", "_bibtex": "@misc{\nwan2021causal,\ntitle={Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets},\nauthor={Shixiang Wan and Shikai Luo and Hongtu Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=4SiMia0kjba}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "4SiMia0kjba", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1578/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1578/Authors|ICLR.cc/2021/Conference/Paper1578/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858148, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1578/-/Official_Comment"}}}, {"id": "M8MWOwEFPWS", "original": null, "number": 2, "cdate": 1605847154949, "ddate": null, "tcdate": 1605847154949, "tmdate": 1605847154949, "tddate": null, "forum": "4SiMia0kjba", "replyto": "sxbDM_LiZ2q", "invitation": "ICLR.cc/2021/Conference/Paper1578/-/Official_Comment", "content": {"title": "Thank you very much for all insightful comments! We plan to add more explanation and model details.", "comment": "1. \"Both equations (1) and (2) are based on the authors' assumptions. Do such assumptions have any support (either from previous literature or from the data)? In my opinion, some of the assumptions do not make sense, for example, one assumption is that $x_v(t + 1)$ is primarily affected by historical demands in $x_v(: t)$ and external covariates in $z$ without historical supply $y$. However, if the historical supply y is not enough, then the demand may raise because more and more demand accumulates.\"  \nResponse: Thanks a lot for your insightful comments! These two equations are primarily based on our understanding of business. We completely agree with your two major comments. The first one is that the demand $x$ may depend on historical supply $y$ that happens several weeks (or even longer) ago. But in the last several weeks (training period), for customers, their demands may be primarily influenced by their own historical patterns and their recent request completion rates. The second one is that the demand may rise when supply is not enough for demand and demand may accumulate.  \nIn short, we feel that the distribution of demand is primarily determined by its historical distribution since the forecast period that we consider in the ride-sharing business is a short-term range (usually 1~7 days). Regarding to the first comment, we usually include historical request completion rate as an external covariate in $z$ to explain it better. The second one usually happens during the rush hour and lasts for 1-2 hours, leading to 2-4 outlying observations due to the temporal resolution being 30 minutes. Moreover, we have included the historical and current demands to predict the future demands such that the proposed equations work reasonably well. To address your comments, we plan to introduce the request completion rate and integrate it with existing external covariates.  \n\n2. \"It seems that the authors' proposed approximate Taylor expansion attention can be used for attention models or even softmax functions in any scenarios. Does it have any limitations? For example, some of the coefficients are very large so that the higher-order Taylor terms cannot be overlooked. Please explain why such problems do not exist in the spatial-temporal prediction scenario in this paper.\"  \nResponse: Thank you so much for insightful comments! The linear attention designed in this paper essentially replaces softmax with the multiplication of feature maps (i.e. $Q$, $K$ and $V$ in original attention). However, such multiplication is unstable during the training. To address this issue, we need to ensure the positive definitive and normalization of feature maps. The feature maps in our ride-hailing dataset are positive definite ($Q$, $K$ and $V$ are positive), and L2 normalization is employed to ensure stable training processes. Additionally, almost all current linear complexity level attentions (e.g., Sparse Attention proposed by OpenAI, Linformer proposed by Facebook, etc.) follow the idea of \"mainly retaining the attentions in short context and forcing most of attentions to zero\". Linear attention in our work also mainly focus on the short-term dependence, since the long-term dependence that has little impact is ignored. To sum up, if the feature maps satisfy the positive definitive and normalization conditions, and we focuses on short-term dependence, then the linear attention method is a good option."}, "signatures": ["ICLR.cc/2021/Conference/Paper1578/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets", "authorids": ["~Shixiang_Wan1", "~Shikai_Luo1", "~Hongtu_Zhu2"], "authors": ["Shixiang Wan", "Shikai Luo", "Hongtu Zhu"], "keywords": ["Spatio-temporal Prediction", "Causal Inference", "Efficient Transformers", "Two-sided Markets"], "abstract": "Achieving accurate spatio-temporal predictions in large-scale systems is extremely valuable in many real-world applications, such as weather forecasts, retail forecasting, and urban traffic forecasting. So far, most existing methods for multi-horizon, multi-task and multi-target predictions select important predicting variables via their correlations with responses, and thus it is highly possible that many forecasting models generated from those methods are not causal, leading to poor interpretability. The aim of this paper is to develop a collaborative causal spatio-temporal fusion transformer, named CausalTrans, to establish the collaborative causal effects of predictors on multiple forecasting targets, such as supply and demand in ride-sharing platforms. Specifically, we integrate the causal attention with the Conditional Average Treatment Effect (CATE) estimation method for causal inference. Moreover, we propose a novel and fast multi-head attention evolved from Taylor expansion instead of softmax, reducing time complexity from $O(\\mathcal{V}^2)$ to $O(\\mathcal{V})$, where $\\mathcal{V}$ is the number of nodes in a graph. We further design a spatial graph fusion mechanism to significantly reduce the parameters' scale. We conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various model components, and the time efficiency of our CausalTrans. As shown in these experiments, our CausalTrans framework can achieve up to 15$\\%$ error reduction compared with various baseline methods. ", "one-sentence_summary": "We develop a novel causal transformer with causal inference and efficient taylor attention to address large scale spatio-temporal predictions. Our method achieves up to 15% error reduction compared with various baseline methods. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wan|causal_probabilistic_spatiotemporal_fusion_transformers_in_twosided_ridehailing_markets", "pdf": "/pdf/2e1d95eab956d7894f701146a590095527edb2b9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=i9kbk52UWw", "_bibtex": "@misc{\nwan2021causal,\ntitle={Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets},\nauthor={Shixiang Wan and Shikai Luo and Hongtu Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=4SiMia0kjba}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "4SiMia0kjba", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1578/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1578/Authors|ICLR.cc/2021/Conference/Paper1578/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923858148, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1578/-/Official_Comment"}}}, {"id": "VlTvPc0dGnc", "original": null, "number": 3, "cdate": 1603939387604, "ddate": null, "tcdate": 1603939387604, "tmdate": 1605024410545, "tddate": null, "forum": "4SiMia0kjba", "replyto": "4SiMia0kjba", "invitation": "ICLR.cc/2021/Conference/Paper1578/-/Official_Review", "content": {"title": "Causal attention improves performance a lot.", "review": "This paper proposes a Transformer-like framework, named CausalTrans, to tackle the demand and supply problem in the ride-hailing market. The problem is formulated by training two probabilistic models which forecasts collaborative demand and supply, by given historical observations and dynamic covariates. The paper leveragesTransformer encoder-decoder architecture, and proposes submodule (Fast S.F., C.A. and T.A.) for different functionalities. Many experiments and ablation analysis are constructed to show that the proposed method outperforms state-of-the-art. The paper also provides good visualization regarding the casual attention model, facilitating to understand the proposed idea.\n\n+ overall the paper is well organized and easy to read.\n+ the proposed architecture is with merit: Fast S.F. with an approximate Taylor\u2019s expansioninstead of using softmax function, showing lower computational cost with little performance dropped; C.A. is proposed to deal with HTE problem in large-scale spatio-temporal forecasting problems, where a DML algorithm is also proposed to learn the C.A. model.\n+ the experimental results are comprehensive and promising.\n\nStill, I have some questions:\n- The ablation analysis shows that spatial fusion shows tiny improvement (+0.3% on average). I\u2019d like the author to elaborate more on the reason. If there are hyperparameters for the spatial fusion, please do some ablation analysis in this regard.\n\n- From experiments the fast attention improves computation a lot with only 0.2% performance dropped in multi-horizon methods. Is it the same in multi-horizon methods? \n\n- From table 1 the results show that, in case of Electricity, the proposed method can\u2019t outperform the state-of-the-art (TFT) due to lack of covariates and spatial information. I\u2019d like to see the ablation analysis (like table 3) in case of Traffic, showing that in case of the iterative method, the performance can be gained by each submodule.\n\n- Lack of experimental details. For example, learning rate/strategy, batch size, optimizer, architecture settings...etc. If the author(s) plan not to release the code in the future, it\u2019s better to list the experimental details in the appendix, for reproducing the performance. \n\nOverall I think that the proposed causal attention is valuable. By adapting the C.A. to the transformer architecture, the proposed method is comparable to state-of-the-art. Moreover, sufficient experiments demonstrate the proposed method can achieve decnet performance in the demand-supply problem. If the paper can better clarify the points mentioned above, I\u2019ll vote for positive.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1578/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets", "authorids": ["~Shixiang_Wan1", "~Shikai_Luo1", "~Hongtu_Zhu2"], "authors": ["Shixiang Wan", "Shikai Luo", "Hongtu Zhu"], "keywords": ["Spatio-temporal Prediction", "Causal Inference", "Efficient Transformers", "Two-sided Markets"], "abstract": "Achieving accurate spatio-temporal predictions in large-scale systems is extremely valuable in many real-world applications, such as weather forecasts, retail forecasting, and urban traffic forecasting. So far, most existing methods for multi-horizon, multi-task and multi-target predictions select important predicting variables via their correlations with responses, and thus it is highly possible that many forecasting models generated from those methods are not causal, leading to poor interpretability. The aim of this paper is to develop a collaborative causal spatio-temporal fusion transformer, named CausalTrans, to establish the collaborative causal effects of predictors on multiple forecasting targets, such as supply and demand in ride-sharing platforms. Specifically, we integrate the causal attention with the Conditional Average Treatment Effect (CATE) estimation method for causal inference. Moreover, we propose a novel and fast multi-head attention evolved from Taylor expansion instead of softmax, reducing time complexity from $O(\\mathcal{V}^2)$ to $O(\\mathcal{V})$, where $\\mathcal{V}$ is the number of nodes in a graph. We further design a spatial graph fusion mechanism to significantly reduce the parameters' scale. We conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various model components, and the time efficiency of our CausalTrans. As shown in these experiments, our CausalTrans framework can achieve up to 15$\\%$ error reduction compared with various baseline methods. ", "one-sentence_summary": "We develop a novel causal transformer with causal inference and efficient taylor attention to address large scale spatio-temporal predictions. Our method achieves up to 15% error reduction compared with various baseline methods. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wan|causal_probabilistic_spatiotemporal_fusion_transformers_in_twosided_ridehailing_markets", "pdf": "/pdf/2e1d95eab956d7894f701146a590095527edb2b9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=i9kbk52UWw", "_bibtex": "@misc{\nwan2021causal,\ntitle={Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets},\nauthor={Shixiang Wan and Shikai Luo and Hongtu Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=4SiMia0kjba}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "4SiMia0kjba", "replyto": "4SiMia0kjba", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1578/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538115539, "tmdate": 1606915781335, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1578/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1578/-/Official_Review"}}}, {"id": "sxbDM_LiZ2q", "original": null, "number": 4, "cdate": 1604671867109, "ddate": null, "tcdate": 1604671867109, "tmdate": 1605024410480, "tddate": null, "forum": "4SiMia0kjba", "replyto": "4SiMia0kjba", "invitation": "ICLR.cc/2021/Conference/Paper1578/-/Official_Review", "content": {"title": "Interesting paper, but some designs need more explanation.", "review": "\nThis paper proposes a new framework of casual spatial-temporal prediction with high interpretability. Specifically, it first proposes a casual transformer including fast spatial graph fusion, casual attention, and temporal attention units. The authors conduct extensive experiments from different domains (electricity, traffic, etc.) and show the effectiveness, efficiency, and interpretability of their proposed method. \n\nStrength:\n\n+ The authors propose to reduce the complexity of the computation of the attention module. \n\n+ The authors first propose a causal attention method for HTE in large-scale spatio-temporal prediction problems.\n\n+ The experiments on datasets from various domains are adequate, which can support the authors' claim. \n\nWeakness: \n\n- Both equations (1) and (2) are based on the authors' assumptions. Do such assumptions have any support (either from previous literature or from the data)? In my opinion, some of the assumptions do not make sense, for example, one assumption is that $x_v(t + 1)$ is primarily affected by historical demands in $x_v(: t)$ and external covariates in $z$ without historical supply $y$. However, if the historical supply y is not enough, then the demand may raise because more and more demand accumulates. \n\n- It seems that the authors' proposed approximate Taylor's expansion attention can be used for attention models or even softmax functions in any scenarios. Does it have any limitations? For example, some of the coefficients are very large so that the higher-order Taylor terms cannot be overlooked. Please explain why such problems do not exist in the spatial-temporal prediction scenario in this paper. ", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2021/Conference/Paper1578/AnonReviewer5"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1578/AnonReviewer5"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets", "authorids": ["~Shixiang_Wan1", "~Shikai_Luo1", "~Hongtu_Zhu2"], "authors": ["Shixiang Wan", "Shikai Luo", "Hongtu Zhu"], "keywords": ["Spatio-temporal Prediction", "Causal Inference", "Efficient Transformers", "Two-sided Markets"], "abstract": "Achieving accurate spatio-temporal predictions in large-scale systems is extremely valuable in many real-world applications, such as weather forecasts, retail forecasting, and urban traffic forecasting. So far, most existing methods for multi-horizon, multi-task and multi-target predictions select important predicting variables via their correlations with responses, and thus it is highly possible that many forecasting models generated from those methods are not causal, leading to poor interpretability. The aim of this paper is to develop a collaborative causal spatio-temporal fusion transformer, named CausalTrans, to establish the collaborative causal effects of predictors on multiple forecasting targets, such as supply and demand in ride-sharing platforms. Specifically, we integrate the causal attention with the Conditional Average Treatment Effect (CATE) estimation method for causal inference. Moreover, we propose a novel and fast multi-head attention evolved from Taylor expansion instead of softmax, reducing time complexity from $O(\\mathcal{V}^2)$ to $O(\\mathcal{V})$, where $\\mathcal{V}$ is the number of nodes in a graph. We further design a spatial graph fusion mechanism to significantly reduce the parameters' scale. We conduct a wide range of experiments to demonstrate the interpretability of causal attention, the effectiveness of various model components, and the time efficiency of our CausalTrans. As shown in these experiments, our CausalTrans framework can achieve up to 15$\\%$ error reduction compared with various baseline methods. ", "one-sentence_summary": "We develop a novel causal transformer with causal inference and efficient taylor attention to address large scale spatio-temporal predictions. Our method achieves up to 15% error reduction compared with various baseline methods. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "wan|causal_probabilistic_spatiotemporal_fusion_transformers_in_twosided_ridehailing_markets", "pdf": "/pdf/2e1d95eab956d7894f701146a590095527edb2b9.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=i9kbk52UWw", "_bibtex": "@misc{\nwan2021causal,\ntitle={Causal Probabilistic Spatio-temporal Fusion Transformers in Two-sided Ride-Hailing Markets},\nauthor={Shixiang Wan and Shikai Luo and Hongtu Zhu},\nyear={2021},\nurl={https://openreview.net/forum?id=4SiMia0kjba}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "4SiMia0kjba", "replyto": "4SiMia0kjba", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1578/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538115539, "tmdate": 1606915781335, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1578/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1578/-/Official_Review"}}}], "count": 17}