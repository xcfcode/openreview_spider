{"notes": [{"id": "HyxPx3R9tm", "original": "rkgyNUnct7", "number": 1083, "cdate": 1538087918820, "ddate": null, "tcdate": 1538087918820, "tmdate": 1546040846592, "tddate": null, "forum": "HyxPx3R9tm", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow", "abstract": "Adversarial learning methods have been proposed for a wide range of applications, but the training of adversarial models can be notoriously unstable. Effectively balancing the performance of the generator and discriminator is critical, since a discriminator that achieves very high accuracy will produce relatively uninformative gradients. In this work, we propose a simple and general technique to constrain information flow in the discriminator by means of an information bottleneck. By enforcing a constraint on the mutual information between the observations and the discriminator's internal representation, we can effectively modulate the discriminator's accuracy and maintain useful and informative gradients. We demonstrate that our proposed variational discriminator bottleneck (VDB) leads to significant improvements across three distinct application areas for adversarial learning algorithms. Our primary evaluation studies the applicability of the VDB to imitation learning of dynamic continuous control skills, such as running. We show that our method can learn such skills directly from raw video demonstrations, substantially outperforming prior adversarial imitation learning methods. The VDB can also be combined with adversarial inverse reinforcement learning to learn parsimonious reward functions that can be transferred and re-optimized in new settings. Finally, we demonstrate that VDB can train GANs more effectively for image generation, improving upon a number of prior stabilization methods.", "keywords": ["reinforcement learning", "generative adversarial networks", "imitation learning", "inverse reinforcement learning", "information bottleneck"], "authorids": ["jasonpeng142@hotmail.com", "kanazawa@eecs.berkeley.edu", "sdt@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"], "authors": ["Xue Bin Peng", "Angjoo Kanazawa", "Sam Toyer", "Pieter Abbeel", "Sergey Levine"], "TL;DR": "Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.", "pdf": "/pdf/261cf4489cfd0c898a97a5bc000b29c20ac68ba2.pdf", "paperhash": "peng|variational_discriminator_bottleneck_improving_imitation_learning_inverse_rl_and_gans_by_constraining_information_flow", "_bibtex": "@inproceedings{\npeng2018variational,\ntitle={Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse {RL}, and {GAN}s by Constraining Information Flow},\nauthor={Xue Bin Peng and Angjoo Kanazawa and Sam Toyer and Pieter Abbeel and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HyxPx3R9tm},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "HJewlYGWgV", "original": null, "number": 1, "cdate": 1544788207388, "ddate": null, "tcdate": 1544788207388, "tmdate": 1545354473075, "tddate": null, "forum": "HyxPx3R9tm", "replyto": "HyxPx3R9tm", "invitation": "ICLR.cc/2019/Conference/-/Paper1083/Meta_Review", "content": {"metareview": "The paper proposes a simple and general technique based on the information bottleneck to constrain the information flow in the discriminator of adversarial models. It helps to train by maintaining informative gradients. While the information bottleneck is not novel, its application in adversarial learning to my knowledge is, and the empirical evaluation demonstrates impressive performance on a broad range of applications. Therefore, the paper should clearly be accepted.\n", "confidence": "5: The area chair is absolutely certain", "recommendation": "Accept (Poster)", "title": "Intuitive idea that leads to impressive results! "}, "signatures": ["ICLR.cc/2019/Conference/Paper1083/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1083/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow", "abstract": "Adversarial learning methods have been proposed for a wide range of applications, but the training of adversarial models can be notoriously unstable. Effectively balancing the performance of the generator and discriminator is critical, since a discriminator that achieves very high accuracy will produce relatively uninformative gradients. In this work, we propose a simple and general technique to constrain information flow in the discriminator by means of an information bottleneck. By enforcing a constraint on the mutual information between the observations and the discriminator's internal representation, we can effectively modulate the discriminator's accuracy and maintain useful and informative gradients. We demonstrate that our proposed variational discriminator bottleneck (VDB) leads to significant improvements across three distinct application areas for adversarial learning algorithms. Our primary evaluation studies the applicability of the VDB to imitation learning of dynamic continuous control skills, such as running. We show that our method can learn such skills directly from raw video demonstrations, substantially outperforming prior adversarial imitation learning methods. The VDB can also be combined with adversarial inverse reinforcement learning to learn parsimonious reward functions that can be transferred and re-optimized in new settings. Finally, we demonstrate that VDB can train GANs more effectively for image generation, improving upon a number of prior stabilization methods.", "keywords": ["reinforcement learning", "generative adversarial networks", "imitation learning", "inverse reinforcement learning", "information bottleneck"], "authorids": ["jasonpeng142@hotmail.com", "kanazawa@eecs.berkeley.edu", "sdt@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"], "authors": ["Xue Bin Peng", "Angjoo Kanazawa", "Sam Toyer", "Pieter Abbeel", "Sergey Levine"], "TL;DR": "Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.", "pdf": "/pdf/261cf4489cfd0c898a97a5bc000b29c20ac68ba2.pdf", "paperhash": "peng|variational_discriminator_bottleneck_improving_imitation_learning_inverse_rl_and_gans_by_constraining_information_flow", "_bibtex": "@inproceedings{\npeng2018variational,\ntitle={Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse {RL}, and {GAN}s by Constraining Information Flow},\nauthor={Xue Bin Peng and Angjoo Kanazawa and Sam Toyer and Pieter Abbeel and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HyxPx3R9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1083/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352972602, "tddate": null, "super": null, "final": null, "reply": {"forum": "HyxPx3R9tm", "replyto": "HyxPx3R9tm", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1083/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1083/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1083/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352972602}}}, {"id": "S1ljRntcT7", "original": null, "number": 4, "cdate": 1542261970978, "ddate": null, "tcdate": 1542261970978, "tmdate": 1542261970978, "tddate": null, "forum": "HyxPx3R9tm", "replyto": "rJx9PNrv3X", "invitation": "ICLR.cc/2019/Conference/-/Paper1083/Official_Comment", "content": {"title": "Reply to AnonReviewer1", "comment": "Thank you for the insight and feedback. We have included additional experiments to further compare with previous techniques, along with some additional clarifications.\n\nRe: additional citations\nThank you for the pointers, we have included the additional citations.\n\nRe: GP for other task\nWe have conducted additional motion imitation experiments with GAIL - GP and VAIL - GP [Figure 4, Table 1]. We also added experiments incorporating GP for the inverse RL tasks [Figure 7]. As in image generation, GP does indeed significantly improve the performance of GAIL. However, VAIL still performs better on most of the tasks, and VAIL - GP achieves the best performance overall.\n\nRe: content of batches used to compute KL divergence\nWe have added additional information to the paper to clarify the content of each batch [Section 4 above equation 11]. Each batch of data used to compute the expected KL contains an equal number of real and fake samples. The encoder maps each input sample to an individual distribution in Z. The KL divergence is computed separately for the distribution of each input, and then averaged across the batch, as opposed to computing the KL divergence across samples within a batch. Therefore, if the real and fake distributions are mapped to different parts of the manifold, it should result in a large KL.\n\nRe: saliency maps\nWe have added a colormap to Figure 5. The colors on the saliency map represent the magnitude of the discriminator\u2019s gradient with respect to each pixel and color channel in the input image. The gradients are visualized for each color channel, which results in the different colors. The same procedure is used to compute the gradients for GAIL.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1083/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1083/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1083/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow", "abstract": "Adversarial learning methods have been proposed for a wide range of applications, but the training of adversarial models can be notoriously unstable. Effectively balancing the performance of the generator and discriminator is critical, since a discriminator that achieves very high accuracy will produce relatively uninformative gradients. In this work, we propose a simple and general technique to constrain information flow in the discriminator by means of an information bottleneck. By enforcing a constraint on the mutual information between the observations and the discriminator's internal representation, we can effectively modulate the discriminator's accuracy and maintain useful and informative gradients. We demonstrate that our proposed variational discriminator bottleneck (VDB) leads to significant improvements across three distinct application areas for adversarial learning algorithms. Our primary evaluation studies the applicability of the VDB to imitation learning of dynamic continuous control skills, such as running. We show that our method can learn such skills directly from raw video demonstrations, substantially outperforming prior adversarial imitation learning methods. The VDB can also be combined with adversarial inverse reinforcement learning to learn parsimonious reward functions that can be transferred and re-optimized in new settings. Finally, we demonstrate that VDB can train GANs more effectively for image generation, improving upon a number of prior stabilization methods.", "keywords": ["reinforcement learning", "generative adversarial networks", "imitation learning", "inverse reinforcement learning", "information bottleneck"], "authorids": ["jasonpeng142@hotmail.com", "kanazawa@eecs.berkeley.edu", "sdt@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"], "authors": ["Xue Bin Peng", "Angjoo Kanazawa", "Sam Toyer", "Pieter Abbeel", "Sergey Levine"], "TL;DR": "Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.", "pdf": "/pdf/261cf4489cfd0c898a97a5bc000b29c20ac68ba2.pdf", "paperhash": "peng|variational_discriminator_bottleneck_improving_imitation_learning_inverse_rl_and_gans_by_constraining_information_flow", "_bibtex": "@inproceedings{\npeng2018variational,\ntitle={Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse {RL}, and {GAN}s by Constraining Information Flow},\nauthor={Xue Bin Peng and Angjoo Kanazawa and Sam Toyer and Pieter Abbeel and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HyxPx3R9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1083/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621619773, "tddate": null, "super": null, "final": null, "reply": {"forum": "HyxPx3R9tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1083/Authors", "ICLR.cc/2019/Conference/Paper1083/Reviewers", "ICLR.cc/2019/Conference/Paper1083/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1083/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1083/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1083/Authors|ICLR.cc/2019/Conference/Paper1083/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1083/Reviewers", "ICLR.cc/2019/Conference/Paper1083/Authors", "ICLR.cc/2019/Conference/Paper1083/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621619773}}}, {"id": "BJeNdhYq67", "original": null, "number": 3, "cdate": 1542261868103, "ddate": null, "tcdate": 1542261868103, "tmdate": 1542261868103, "tddate": null, "forum": "HyxPx3R9tm", "replyto": "Bkx6mnnK3Q", "invitation": "ICLR.cc/2019/Conference/-/Paper1083/Official_Comment", "content": {"title": "Reply to AnonReviewer2", "comment": "Thank you for the insight and feedback, we have included new experiments in the paper, along with some additional clarifications.\n\nRe: Adapt beta based on gradient magnitudes\nYes, it might be possible to formulate a similar constraint for adaptively updating beta according to the gradient magnitudes. A constraint on the gradient norm can be added, then a Lagrangian can be constructed in a similar manner to yield an adaptive update for beta."}, "signatures": ["ICLR.cc/2019/Conference/Paper1083/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1083/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1083/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow", "abstract": "Adversarial learning methods have been proposed for a wide range of applications, but the training of adversarial models can be notoriously unstable. Effectively balancing the performance of the generator and discriminator is critical, since a discriminator that achieves very high accuracy will produce relatively uninformative gradients. In this work, we propose a simple and general technique to constrain information flow in the discriminator by means of an information bottleneck. By enforcing a constraint on the mutual information between the observations and the discriminator's internal representation, we can effectively modulate the discriminator's accuracy and maintain useful and informative gradients. We demonstrate that our proposed variational discriminator bottleneck (VDB) leads to significant improvements across three distinct application areas for adversarial learning algorithms. Our primary evaluation studies the applicability of the VDB to imitation learning of dynamic continuous control skills, such as running. We show that our method can learn such skills directly from raw video demonstrations, substantially outperforming prior adversarial imitation learning methods. The VDB can also be combined with adversarial inverse reinforcement learning to learn parsimonious reward functions that can be transferred and re-optimized in new settings. Finally, we demonstrate that VDB can train GANs more effectively for image generation, improving upon a number of prior stabilization methods.", "keywords": ["reinforcement learning", "generative adversarial networks", "imitation learning", "inverse reinforcement learning", "information bottleneck"], "authorids": ["jasonpeng142@hotmail.com", "kanazawa@eecs.berkeley.edu", "sdt@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"], "authors": ["Xue Bin Peng", "Angjoo Kanazawa", "Sam Toyer", "Pieter Abbeel", "Sergey Levine"], "TL;DR": "Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.", "pdf": "/pdf/261cf4489cfd0c898a97a5bc000b29c20ac68ba2.pdf", "paperhash": "peng|variational_discriminator_bottleneck_improving_imitation_learning_inverse_rl_and_gans_by_constraining_information_flow", "_bibtex": "@inproceedings{\npeng2018variational,\ntitle={Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse {RL}, and {GAN}s by Constraining Information Flow},\nauthor={Xue Bin Peng and Angjoo Kanazawa and Sam Toyer and Pieter Abbeel and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HyxPx3R9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1083/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621619773, "tddate": null, "super": null, "final": null, "reply": {"forum": "HyxPx3R9tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1083/Authors", "ICLR.cc/2019/Conference/Paper1083/Reviewers", "ICLR.cc/2019/Conference/Paper1083/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1083/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1083/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1083/Authors|ICLR.cc/2019/Conference/Paper1083/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1083/Reviewers", "ICLR.cc/2019/Conference/Paper1083/Authors", "ICLR.cc/2019/Conference/Paper1083/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621619773}}}, {"id": "B1eIr2t5Tm", "original": null, "number": 2, "cdate": 1542261821707, "ddate": null, "tcdate": 1542261821707, "tmdate": 1542261821707, "tddate": null, "forum": "HyxPx3R9tm", "replyto": "Byl41tz9nX", "invitation": "ICLR.cc/2019/Conference/-/Paper1083/Official_Comment", "content": {"title": "Reply to AnonReviewer3", "comment": "Thank you for the insight and suggestions. We have added additional experiments and clarifications to the paper that aim to address each of your concerns -- we would really appreciate it if you could revisit your review in light of these additions and clarifications.\n\nRe: GP for other tasks\nWe have conducted additional motion imitation experiments with GAIL - GP and VAIL - GP [Figure 4, Table 1]. We also added experiments incorporating GP for the inverse RL tasks [Figure 7]. As in image generation, GP does indeed significantly improve the performance of GAIL. However, VAIL still performs better on most of the tasks, and VAIL - GP achieves the best performance overall.\n\nRe: How are VGAN and GP combined\nWe have added an additional section [Appendix B] that provides more information on how VDB and GP is combined. We use the reparameterization trick, as is done in VAEs, to backprop through the encoder to compute the gradient of the discriminator with respect to the inputs. There is a manually specified coefficient that weights the GP term in the objective, and we use the same value for the coefficient as [Mescheder et al., 2018] for image generation.\n\nRe: Combining VGAN and GP enhances performance\nThe VDB and GP are complementary techniques since the VDB helps to prevent vanishing gradients and GP prevents exploding gradients. Therefore both methods regularize the gradients, but under different criteria.\n\nRe: Spectral norm\nWe have included additional image generation experiments with spectral normalization [Figure 8]. Spectral normalization does show significant improvement over the vanilla GAN on CIFAR-10 (FID: 23.9), but our method still achieves a better score (FID: 18.1). The original spectral normalization paper [Miyato et al., 2018] reported an FID of 21.7 on CIFAR-10.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1083/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1083/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1083/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow", "abstract": "Adversarial learning methods have been proposed for a wide range of applications, but the training of adversarial models can be notoriously unstable. Effectively balancing the performance of the generator and discriminator is critical, since a discriminator that achieves very high accuracy will produce relatively uninformative gradients. In this work, we propose a simple and general technique to constrain information flow in the discriminator by means of an information bottleneck. By enforcing a constraint on the mutual information between the observations and the discriminator's internal representation, we can effectively modulate the discriminator's accuracy and maintain useful and informative gradients. We demonstrate that our proposed variational discriminator bottleneck (VDB) leads to significant improvements across three distinct application areas for adversarial learning algorithms. Our primary evaluation studies the applicability of the VDB to imitation learning of dynamic continuous control skills, such as running. We show that our method can learn such skills directly from raw video demonstrations, substantially outperforming prior adversarial imitation learning methods. The VDB can also be combined with adversarial inverse reinforcement learning to learn parsimonious reward functions that can be transferred and re-optimized in new settings. Finally, we demonstrate that VDB can train GANs more effectively for image generation, improving upon a number of prior stabilization methods.", "keywords": ["reinforcement learning", "generative adversarial networks", "imitation learning", "inverse reinforcement learning", "information bottleneck"], "authorids": ["jasonpeng142@hotmail.com", "kanazawa@eecs.berkeley.edu", "sdt@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"], "authors": ["Xue Bin Peng", "Angjoo Kanazawa", "Sam Toyer", "Pieter Abbeel", "Sergey Levine"], "TL;DR": "Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.", "pdf": "/pdf/261cf4489cfd0c898a97a5bc000b29c20ac68ba2.pdf", "paperhash": "peng|variational_discriminator_bottleneck_improving_imitation_learning_inverse_rl_and_gans_by_constraining_information_flow", "_bibtex": "@inproceedings{\npeng2018variational,\ntitle={Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse {RL}, and {GAN}s by Constraining Information Flow},\nauthor={Xue Bin Peng and Angjoo Kanazawa and Sam Toyer and Pieter Abbeel and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HyxPx3R9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1083/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621619773, "tddate": null, "super": null, "final": null, "reply": {"forum": "HyxPx3R9tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1083/Authors", "ICLR.cc/2019/Conference/Paper1083/Reviewers", "ICLR.cc/2019/Conference/Paper1083/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1083/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1083/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1083/Authors|ICLR.cc/2019/Conference/Paper1083/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1083/Reviewers", "ICLR.cc/2019/Conference/Paper1083/Authors", "ICLR.cc/2019/Conference/Paper1083/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621619773}}}, {"id": "ByxhshHL6Q", "original": null, "number": 4, "cdate": 1541983395776, "ddate": null, "tcdate": 1541983395776, "tmdate": 1541983507557, "tddate": null, "forum": "HyxPx3R9tm", "replyto": "BJxmQSxU6Q", "invitation": "ICLR.cc/2019/Conference/-/Paper1083/Public_Comment", "content": {"comment": "Thanks for your response clarifying one part of the comment. \n\nWith respect to all the \"We never claimed ...\", the writing did not have factually false claims. However, isn't it normal to interpret that a statement like \"previous approaches used larger batch sizes and multiple GPUs and our approach did not\" is intended to \"sound\" as a contribution in comparison to prior work? 24 is larger than 8. 256 is also larger than 8. 2048 is also larger than 8. But it's not the same \"larger\". One is doable with a single V100. Another is doable with 32 V100s. Third is doable only on TPU. Wouldn't it make sense to say \"We used smaller batch size (8 instead of 24 as in Mescheder et al) on a single V100 and trained for fewer iterations because of resource constraints. We also generate at full resolution directly as in Mescheder et al instead of progressive growing done in Karras et al\"? Thanks for agreeing to refine the writing. \n\n", "title": "Response to Clarification"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow", "abstract": "Adversarial learning methods have been proposed for a wide range of applications, but the training of adversarial models can be notoriously unstable. Effectively balancing the performance of the generator and discriminator is critical, since a discriminator that achieves very high accuracy will produce relatively uninformative gradients. In this work, we propose a simple and general technique to constrain information flow in the discriminator by means of an information bottleneck. By enforcing a constraint on the mutual information between the observations and the discriminator's internal representation, we can effectively modulate the discriminator's accuracy and maintain useful and informative gradients. We demonstrate that our proposed variational discriminator bottleneck (VDB) leads to significant improvements across three distinct application areas for adversarial learning algorithms. Our primary evaluation studies the applicability of the VDB to imitation learning of dynamic continuous control skills, such as running. We show that our method can learn such skills directly from raw video demonstrations, substantially outperforming prior adversarial imitation learning methods. The VDB can also be combined with adversarial inverse reinforcement learning to learn parsimonious reward functions that can be transferred and re-optimized in new settings. Finally, we demonstrate that VDB can train GANs more effectively for image generation, improving upon a number of prior stabilization methods.", "keywords": ["reinforcement learning", "generative adversarial networks", "imitation learning", "inverse reinforcement learning", "information bottleneck"], "authorids": ["jasonpeng142@hotmail.com", "kanazawa@eecs.berkeley.edu", "sdt@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"], "authors": ["Xue Bin Peng", "Angjoo Kanazawa", "Sam Toyer", "Pieter Abbeel", "Sergey Levine"], "TL;DR": "Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.", "pdf": "/pdf/261cf4489cfd0c898a97a5bc000b29c20ac68ba2.pdf", "paperhash": "peng|variational_discriminator_bottleneck_improving_imitation_learning_inverse_rl_and_gans_by_constraining_information_flow", "_bibtex": "@inproceedings{\npeng2018variational,\ntitle={Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse {RL}, and {GAN}s by Constraining Information Flow},\nauthor={Xue Bin Peng and Angjoo Kanazawa and Sam Toyer and Pieter Abbeel and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HyxPx3R9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1083/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311683001, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "HyxPx3R9tm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1083/Authors", "ICLR.cc/2019/Conference/Paper1083/Reviewers", "ICLR.cc/2019/Conference/Paper1083/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1083/Authors", "ICLR.cc/2019/Conference/Paper1083/Reviewers", "ICLR.cc/2019/Conference/Paper1083/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311683001}}}, {"id": "BJxmQSxU6Q", "original": null, "number": 1, "cdate": 1541960986827, "ddate": null, "tcdate": 1541960986827, "tmdate": 1541963192678, "tddate": null, "forum": "HyxPx3R9tm", "replyto": "SylvFMGra7", "invitation": "ICLR.cc/2019/Conference/-/Paper1083/Official_Comment", "content": {"title": "Clarification", "comment": "Thank you for your comment. \n\nThe authors of the paper are not active on reddit and we do not have control over what reddit users post about our paper.\n\nWe used a batch size of 8 in our work, and we mention this in the paper for completeness, and since this is a bit different from Meschederer et al., who used a batch size of 24 with 4 GPUs. We do not state that the batch size from Meschederer et al. is \u201cextremely large\u201d in our paper, we state that it is \"larger\" than 8, which is factually true (it\u2019s not clear how to state this in any other way\u2026). We did not claim that the smaller batch size of 8 is a contribution of our work, and we did not claim that our paper is the first to train high-resolution GANs without progressive growing of resolution. We do have results for a network trained for 300k iterations and we will add these results to the paper.\n\nWe will refine the wording for the image generation experiments to further avoid these misinterpretations."}, "signatures": ["ICLR.cc/2019/Conference/Paper1083/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1083/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1083/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow", "abstract": "Adversarial learning methods have been proposed for a wide range of applications, but the training of adversarial models can be notoriously unstable. Effectively balancing the performance of the generator and discriminator is critical, since a discriminator that achieves very high accuracy will produce relatively uninformative gradients. In this work, we propose a simple and general technique to constrain information flow in the discriminator by means of an information bottleneck. By enforcing a constraint on the mutual information between the observations and the discriminator's internal representation, we can effectively modulate the discriminator's accuracy and maintain useful and informative gradients. We demonstrate that our proposed variational discriminator bottleneck (VDB) leads to significant improvements across three distinct application areas for adversarial learning algorithms. Our primary evaluation studies the applicability of the VDB to imitation learning of dynamic continuous control skills, such as running. We show that our method can learn such skills directly from raw video demonstrations, substantially outperforming prior adversarial imitation learning methods. The VDB can also be combined with adversarial inverse reinforcement learning to learn parsimonious reward functions that can be transferred and re-optimized in new settings. Finally, we demonstrate that VDB can train GANs more effectively for image generation, improving upon a number of prior stabilization methods.", "keywords": ["reinforcement learning", "generative adversarial networks", "imitation learning", "inverse reinforcement learning", "information bottleneck"], "authorids": ["jasonpeng142@hotmail.com", "kanazawa@eecs.berkeley.edu", "sdt@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"], "authors": ["Xue Bin Peng", "Angjoo Kanazawa", "Sam Toyer", "Pieter Abbeel", "Sergey Levine"], "TL;DR": "Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.", "pdf": "/pdf/261cf4489cfd0c898a97a5bc000b29c20ac68ba2.pdf", "paperhash": "peng|variational_discriminator_bottleneck_improving_imitation_learning_inverse_rl_and_gans_by_constraining_information_flow", "_bibtex": "@inproceedings{\npeng2018variational,\ntitle={Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse {RL}, and {GAN}s by Constraining Information Flow},\nauthor={Xue Bin Peng and Angjoo Kanazawa and Sam Toyer and Pieter Abbeel and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HyxPx3R9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1083/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621619773, "tddate": null, "super": null, "final": null, "reply": {"forum": "HyxPx3R9tm", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1083/Authors", "ICLR.cc/2019/Conference/Paper1083/Reviewers", "ICLR.cc/2019/Conference/Paper1083/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1083/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1083/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1083/Authors|ICLR.cc/2019/Conference/Paper1083/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1083/Reviewers", "ICLR.cc/2019/Conference/Paper1083/Authors", "ICLR.cc/2019/Conference/Paper1083/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621619773}}}, {"id": "SylvFMGra7", "original": null, "number": 3, "cdate": 1541902975396, "ddate": null, "tcdate": 1541902975396, "tmdate": 1541904252684, "tddate": null, "forum": "HyxPx3R9tm", "replyto": "HyxPx3R9tm", "invitation": "ICLR.cc/2019/Conference/-/Paper1083/Public_Comment", "content": {"comment": "\"CelebAHQ: VGAN can also be trained on on CelebAHQ Karras et al. (2018) at 1024 by 1024 resolution directly, without progressive growing (Karras et al., 2018). We use Ic = 0.1 and train with VGAN-GP. We train on a single Tesla V100, which fits a batch size of 8 in our experiments. Previous approaches (Karras et al., 2018; Mescheder et al., 2018) use a larger batch size and train over multiple GPUs. While previous approaches have trained this for 300k iterations or more, our results are shown at 100k iterations.\"\n\nEven though the authors don't intend to, this statement is likely to be misinterpreted that VGAN is the first GAN paper to show high resolution GAN samples without progressive growing of resolution or large batch sizes. \n\nThe batch size used in Mescheder et al is 24 while the authors use 8. Why would you call 24 \"large\" and 8 \"small\"? Secondly, 100k iterations is sufficient to start seeing good samples with most GAN architectures when the architecture uses residual connections and more iterations are needed to get more modes and sharper samples. You have shown a total of 8 samples. It is hard to say whether or not they were carefully picked. \n\nAs evidence for why this is likely to be misleading, I am quoting a comment from reddit: \"Also of note: training 1024px image GANs without extremely large minibatches, progressive growing, or self-attention, just a fairly vanilla-sounding CNN and their discriminator penalization.\" Not providing the link because that breaks the anonymity of the paper. \n\nNeither is it claimed or shown by the authors that Mescheder et al's model wouldn't produce good samples with a lower batch size or fewer (100K) iterations. The benefit to get it working for large resolution comes from the careful architecture designed by Mescheder et al and not from the bottleneck. \n\nTwo more issues with the claims made in the CIFAR-10 FID metrics section: (a) \"VGAN is competitive with WGAN-GP and GP\": The gap between VGAN and WGAN-GP is higher than WGAN-GP and VGAN-GP.  But the improvement over WGAN-GP is considered \"significant\" whereas the other gap is considered \"competitive\"?  (b) Is there any reason to show the metrics at the end of 750K iterations specifically? The plot shows that WGAN-GP training curve has a bigger negative slope at the cutoff point (750k) while VGAN-GP has flattened by then. It is worth showing the readers what happens when you train even a bit more, ie 1 million iterations when the difference isn't even that significant. Even though \"VDB and GP are complementary techniques\" morally, empirical conclusions may often not turn out to be the case. \n", "title": "GAN experiments writing indicating incorrect interpretations?"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow", "abstract": "Adversarial learning methods have been proposed for a wide range of applications, but the training of adversarial models can be notoriously unstable. Effectively balancing the performance of the generator and discriminator is critical, since a discriminator that achieves very high accuracy will produce relatively uninformative gradients. In this work, we propose a simple and general technique to constrain information flow in the discriminator by means of an information bottleneck. By enforcing a constraint on the mutual information between the observations and the discriminator's internal representation, we can effectively modulate the discriminator's accuracy and maintain useful and informative gradients. We demonstrate that our proposed variational discriminator bottleneck (VDB) leads to significant improvements across three distinct application areas for adversarial learning algorithms. Our primary evaluation studies the applicability of the VDB to imitation learning of dynamic continuous control skills, such as running. We show that our method can learn such skills directly from raw video demonstrations, substantially outperforming prior adversarial imitation learning methods. The VDB can also be combined with adversarial inverse reinforcement learning to learn parsimonious reward functions that can be transferred and re-optimized in new settings. Finally, we demonstrate that VDB can train GANs more effectively for image generation, improving upon a number of prior stabilization methods.", "keywords": ["reinforcement learning", "generative adversarial networks", "imitation learning", "inverse reinforcement learning", "information bottleneck"], "authorids": ["jasonpeng142@hotmail.com", "kanazawa@eecs.berkeley.edu", "sdt@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"], "authors": ["Xue Bin Peng", "Angjoo Kanazawa", "Sam Toyer", "Pieter Abbeel", "Sergey Levine"], "TL;DR": "Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.", "pdf": "/pdf/261cf4489cfd0c898a97a5bc000b29c20ac68ba2.pdf", "paperhash": "peng|variational_discriminator_bottleneck_improving_imitation_learning_inverse_rl_and_gans_by_constraining_information_flow", "_bibtex": "@inproceedings{\npeng2018variational,\ntitle={Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse {RL}, and {GAN}s by Constraining Information Flow},\nauthor={Xue Bin Peng and Angjoo Kanazawa and Sam Toyer and Pieter Abbeel and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HyxPx3R9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1083/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311683001, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "HyxPx3R9tm", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1083/Authors", "ICLR.cc/2019/Conference/Paper1083/Reviewers", "ICLR.cc/2019/Conference/Paper1083/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1083/Authors", "ICLR.cc/2019/Conference/Paper1083/Reviewers", "ICLR.cc/2019/Conference/Paper1083/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311683001}}}, {"id": "Byl41tz9nX", "original": null, "number": 3, "cdate": 1541183707927, "ddate": null, "tcdate": 1541183707927, "tmdate": 1541533438078, "tddate": null, "forum": "HyxPx3R9tm", "replyto": "HyxPx3R9tm", "invitation": "ICLR.cc/2019/Conference/-/Paper1083/Official_Review", "content": {"title": "a constraint on the discriminator of GAN model to maintain informative gradients", "review": "This paper proposed a constraint on the discriminator of GAN model to maintain informative gradients. It is completed by control the mutual information between the observations and the discriminator\u2019s internal representation to be no bigger than a predefined value.  The idea is interesting and the discussions of applications in different areas are useful. However, I still have some concerns about the work:\n1.\tin the experiments about image generation, it seems that the proposed method does not enhance the performance obviously when compared to GP and WGAN-GP, Why the combination of VGAN and GP can enhance the performance greatly(How do they complementary to each other), what about the performance when combine VGAN with WGAN-GP?\n2.\tHow do you combine VGAN and GP, is there any parameter to balance their effect?\n3.\tThe author stated on page 2 that \u201cthe  proposed information bottleneck encourages the discriminator to ignore irrelevant cues, which then allows the generator to focus on improving the most discerning differences between real and fake samples\u201d, a proof on theory or experiments should be used to illustrate this state.\n4.\tIs it possible to apply GP and WGAN-GP to the Motion imitation or adversarial inverse reinforcement learning problems? If so, will it perform better than VGAN?\n5.\tHow about VGAN compares with Spectral norm GAN?\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1083/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow", "abstract": "Adversarial learning methods have been proposed for a wide range of applications, but the training of adversarial models can be notoriously unstable. Effectively balancing the performance of the generator and discriminator is critical, since a discriminator that achieves very high accuracy will produce relatively uninformative gradients. In this work, we propose a simple and general technique to constrain information flow in the discriminator by means of an information bottleneck. By enforcing a constraint on the mutual information between the observations and the discriminator's internal representation, we can effectively modulate the discriminator's accuracy and maintain useful and informative gradients. We demonstrate that our proposed variational discriminator bottleneck (VDB) leads to significant improvements across three distinct application areas for adversarial learning algorithms. Our primary evaluation studies the applicability of the VDB to imitation learning of dynamic continuous control skills, such as running. We show that our method can learn such skills directly from raw video demonstrations, substantially outperforming prior adversarial imitation learning methods. The VDB can also be combined with adversarial inverse reinforcement learning to learn parsimonious reward functions that can be transferred and re-optimized in new settings. Finally, we demonstrate that VDB can train GANs more effectively for image generation, improving upon a number of prior stabilization methods.", "keywords": ["reinforcement learning", "generative adversarial networks", "imitation learning", "inverse reinforcement learning", "information bottleneck"], "authorids": ["jasonpeng142@hotmail.com", "kanazawa@eecs.berkeley.edu", "sdt@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"], "authors": ["Xue Bin Peng", "Angjoo Kanazawa", "Sam Toyer", "Pieter Abbeel", "Sergey Levine"], "TL;DR": "Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.", "pdf": "/pdf/261cf4489cfd0c898a97a5bc000b29c20ac68ba2.pdf", "paperhash": "peng|variational_discriminator_bottleneck_improving_imitation_learning_inverse_rl_and_gans_by_constraining_information_flow", "_bibtex": "@inproceedings{\npeng2018variational,\ntitle={Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse {RL}, and {GAN}s by Constraining Information Flow},\nauthor={Xue Bin Peng and Angjoo Kanazawa and Sam Toyer and Pieter Abbeel and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HyxPx3R9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1083/Official_Review", "cdate": 1542234310187, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HyxPx3R9tm", "replyto": "HyxPx3R9tm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1083/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335868898, "tmdate": 1552335868898, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1083/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "Bkx6mnnK3Q", "original": null, "number": 2, "cdate": 1541159973060, "ddate": null, "tcdate": 1541159973060, "tmdate": 1541533437813, "tddate": null, "forum": "HyxPx3R9tm", "replyto": "HyxPx3R9tm", "invitation": "ICLR.cc/2019/Conference/-/Paper1083/Official_Review", "content": {"title": "Inovative technique, Impressive results", "review": "The paper \"Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow\" tackles the problem of discriminator over-fitting in adversarial learning. Balancing the generator and the discriminator is difficult in generative adversarial techniques, as a too good discriminator prevents the generator to converge toward effective distributions. The idea is to introduce an information constraint on a intermediate layer, called information bottleneck, which limits the content of this layer to the most discriminative features of the input. Based on this limited representation of the input, the disciminator is constrained to longer tailed-distributions, maintaining some uncertainty on simulated data distributions. Results show that the proposal outperforms previous researches on discriminator over-fitting, such as noise adding in the discriminator inputs. \n\nWhile the use of information bottleneck is not novel, its application in adversarial learning looks inovative and the results are impressive in a broad range of applications. The paper is well-written and easy to follow, though I find that it would be nice to give more insights on the intuition about information bottleneck in the preliminary section to make the paper self-contained (I had to read the previous work from Alemi et al (2016) to realize what information bottleneck can bring). My only question is about the setting of the constaint Ic: wouldn't it be possible to consider an adaptative version which could consider the amount of zeros gradients returned to the generator ? ", "rating": "10: Top 5% of accepted papers, seminal paper", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1083/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow", "abstract": "Adversarial learning methods have been proposed for a wide range of applications, but the training of adversarial models can be notoriously unstable. Effectively balancing the performance of the generator and discriminator is critical, since a discriminator that achieves very high accuracy will produce relatively uninformative gradients. In this work, we propose a simple and general technique to constrain information flow in the discriminator by means of an information bottleneck. By enforcing a constraint on the mutual information between the observations and the discriminator's internal representation, we can effectively modulate the discriminator's accuracy and maintain useful and informative gradients. We demonstrate that our proposed variational discriminator bottleneck (VDB) leads to significant improvements across three distinct application areas for adversarial learning algorithms. Our primary evaluation studies the applicability of the VDB to imitation learning of dynamic continuous control skills, such as running. We show that our method can learn such skills directly from raw video demonstrations, substantially outperforming prior adversarial imitation learning methods. The VDB can also be combined with adversarial inverse reinforcement learning to learn parsimonious reward functions that can be transferred and re-optimized in new settings. Finally, we demonstrate that VDB can train GANs more effectively for image generation, improving upon a number of prior stabilization methods.", "keywords": ["reinforcement learning", "generative adversarial networks", "imitation learning", "inverse reinforcement learning", "information bottleneck"], "authorids": ["jasonpeng142@hotmail.com", "kanazawa@eecs.berkeley.edu", "sdt@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"], "authors": ["Xue Bin Peng", "Angjoo Kanazawa", "Sam Toyer", "Pieter Abbeel", "Sergey Levine"], "TL;DR": "Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.", "pdf": "/pdf/261cf4489cfd0c898a97a5bc000b29c20ac68ba2.pdf", "paperhash": "peng|variational_discriminator_bottleneck_improving_imitation_learning_inverse_rl_and_gans_by_constraining_information_flow", "_bibtex": "@inproceedings{\npeng2018variational,\ntitle={Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse {RL}, and {GAN}s by Constraining Information Flow},\nauthor={Xue Bin Peng and Angjoo Kanazawa and Sam Toyer and Pieter Abbeel and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HyxPx3R9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1083/Official_Review", "cdate": 1542234310187, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HyxPx3R9tm", "replyto": "HyxPx3R9tm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1083/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335868898, "tmdate": 1552335868898, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1083/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rJx9PNrv3X", "original": null, "number": 1, "cdate": 1540998241794, "ddate": null, "tcdate": 1540998241794, "tmdate": 1541533437598, "tddate": null, "forum": "HyxPx3R9tm", "replyto": "HyxPx3R9tm", "invitation": "ICLR.cc/2019/Conference/-/Paper1083/Official_Review", "content": {"title": "Good showcase of the application and benefits of the VIB in GANs, minor corrections suggested.", "review": "Summary:\nThe authors propose to apply the Deep Variational Information Bottleneck (VIB) method of [1] on discriminator networks in various adversarial-learning-based scenarios. They propose a way to adaptively update the value for the b\u00eata hyper-parameter to respect the constraint on I(X,Z). Their technique is shown to stabilize/allow training when P_g and P_data do not overlap, similarly to WGAN and gradient-penalty based approaches, by essentially pushing their representation distributions (p_z) to overlap with the mutual information bottleneck. It can also be considered as an adaptive version of instance noise, which serves the same goal. The method is evaluated on different adversarial learning setup (imitation learning, inverse reinforcement learning and GANs), where it compares positively to most related methods. Best results for \u2018classical\u2019 adversarial learning for image generation are however obtained when combining the proposed VIB with gradient penalty (which outperforms by itself the VGAN in this case).\n\n\nPros :\n- This paper brings a good amount of evidence of the benefits to use the VIB formulation to adversarial learning by first showing the effect of such approach on a toy example, and then applying it to more complex scenarios, where it also boosts performance. The numerous experiments and analyses have great value and are a necessity as this paper mostly applies the VIB to new learning challenges. \n\n- The proposition of a principled way of adaptively varying the value of B\u00eata to actually respect more closely the constraint I(X,Z) < I_c, which to my knowledge [1] does not perform, is definitely appealing and seems to work better than fixed B\u00eatas and does also bring the KL divergence to the desired I_c.\n\n- The technique is fairly simple to implement and can be combined with other stabilization techniques such as gradient penalties on the discriminator.\n\n\nCons:\n\n- In my view, the novelty of the approach is somewhat limited, as it seems like a straightforward application of the VIB from [1] for discriminators in adversarial learning, with the difference of using an adaptive B\u00eata.\n\n- I think the B\u00eata-VAE [2] paper is definitely related to this paper and to the paper on which it is based [1] and should thus be cited as the authors use a similar regularization technique, albeit from a different perspective, that restricts I(X,Z) in an auto-encoding task.\n\n- I think the content of batches used to regularize E(z|x) w.r.t. to the KL divergence should be clarified, as the description of p^tilde \u201cbeing a mixture of the target distribution and the generator\u201d (Section 4) can let the implementation details be ambiguous. I think batches containing samples from both distributions can cause problems as the expectation of the KL divergence on a batch can be low even if the samples from both distributions are projected into different parts of the manifold. This makes me think batches are separated? Either way, this should be more clearly stated in the text.\n\n- The last results for  the \u2018traditional\u2019 GAN+VIB show that in this case, gradient penalty (GP) alone outperforms the proposed VGAN, and that both can be combined for best results. I thus wonder if the results in all other experiments could show similar trends if GP had been tested in these cases as well. In the imitation learning task, authors compare with instance noise, but not with GP, which for me are both related to VIB in what they try to accomplish. Was GP tested in Imitation Learning/Inverse RL ? Was it better? Could it still be combined with VIB for better results? \n\n- In the saliency map of Figure 5, I\u2019m unclear as to what the colors represent (especially on the GAIL side). I doubt that this is simply due to the colormap used, but this colormap should be presented.\n\nOverall, I think this is an interesting and relevant paper that I am very likely to suggest to peers working on adversarial learning, and should therefore be presented. I think the limited novelty is counterbalanced by the quality of empirical analysis. Some clarity issues and missing citations should be easy to correct. I appreciate the comparison and combination with a competitive method (Gradient Penalty) in Section 5.3, but I wish similar results were present in the other experiments, in order to inform readers if, in these cases as well, combining VIB with GP leads to the best performance.\n\n[1] Deep Variational Information Bottleneck, (Alemi et al. 2017)\n[2] beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework (Higgins et al. 2017)\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1083/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow", "abstract": "Adversarial learning methods have been proposed for a wide range of applications, but the training of adversarial models can be notoriously unstable. Effectively balancing the performance of the generator and discriminator is critical, since a discriminator that achieves very high accuracy will produce relatively uninformative gradients. In this work, we propose a simple and general technique to constrain information flow in the discriminator by means of an information bottleneck. By enforcing a constraint on the mutual information between the observations and the discriminator's internal representation, we can effectively modulate the discriminator's accuracy and maintain useful and informative gradients. We demonstrate that our proposed variational discriminator bottleneck (VDB) leads to significant improvements across three distinct application areas for adversarial learning algorithms. Our primary evaluation studies the applicability of the VDB to imitation learning of dynamic continuous control skills, such as running. We show that our method can learn such skills directly from raw video demonstrations, substantially outperforming prior adversarial imitation learning methods. The VDB can also be combined with adversarial inverse reinforcement learning to learn parsimonious reward functions that can be transferred and re-optimized in new settings. Finally, we demonstrate that VDB can train GANs more effectively for image generation, improving upon a number of prior stabilization methods.", "keywords": ["reinforcement learning", "generative adversarial networks", "imitation learning", "inverse reinforcement learning", "information bottleneck"], "authorids": ["jasonpeng142@hotmail.com", "kanazawa@eecs.berkeley.edu", "sdt@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"], "authors": ["Xue Bin Peng", "Angjoo Kanazawa", "Sam Toyer", "Pieter Abbeel", "Sergey Levine"], "TL;DR": "Regularizing adversarial learning with an information bottleneck, applied to imitation learning, inverse reinforcement learning, and generative adversarial networks.", "pdf": "/pdf/261cf4489cfd0c898a97a5bc000b29c20ac68ba2.pdf", "paperhash": "peng|variational_discriminator_bottleneck_improving_imitation_learning_inverse_rl_and_gans_by_constraining_information_flow", "_bibtex": "@inproceedings{\npeng2018variational,\ntitle={Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse {RL}, and {GAN}s by Constraining Information Flow},\nauthor={Xue Bin Peng and Angjoo Kanazawa and Sam Toyer and Pieter Abbeel and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=HyxPx3R9tm},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1083/Official_Review", "cdate": 1542234310187, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "HyxPx3R9tm", "replyto": "HyxPx3R9tm", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1083/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335868898, "tmdate": 1552335868898, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1083/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 11}