{"notes": [{"tddate": null, "ddate": null, "tmdate": 1518730178083, "tcdate": 1509117272930, "number": 433, "cdate": 1518730178072, "id": "H1Ww66x0-", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "H1Ww66x0-", "original": "r1RLppe0b", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "Lifelong Learning with Output Kernels", "abstract": "Lifelong learning poses considerable challenges in terms of effectiveness (minimizing prediction errors for all tasks) and overall computational tractability for real-time performance.  This paper addresses continuous lifelong multitask learning by jointly re-estimating the inter-task relations (\\textit{output} kernel) and the per-task model parameters at each round, assuming data arrives in a streaming fashion. We propose a novel algorithm called  \\textit{Online Output Kernel Learning Algorithm} (OOKLA) for lifelong learning setting. To avoid the memory explosion, we propose a robust budget-limited versions of the proposed algorithm that efficiently utilize the relationship between the tasks to bound the total number of representative examples in the support set.  In addition, we propose a two-stage budgeted scheme for efficiently tackling the task-specific budget constraints in lifelong learning. Our empirical results over three datasets indicate superior AUC performance for OOKLA and its budget-limited cousins over strong baselines.", "pdf": "/pdf/c2b029ef0ced524aba05fd0da3c6d32f48c9fefc.pdf", "TL;DR": "a novel approach for online lifelong learning using output kernels.", "paperhash": "murugesan|lifelong_learning_with_output_kernels", "_bibtex": "@misc{\nmurugesan2018lifelong,\ntitle={Lifelong Learning with Output Kernels},\nauthor={Keerthiram Murugesan and Jaime Carbonell},\nyear={2018},\nurl={https://openreview.net/forum?id=H1Ww66x0-},\n}", "keywords": ["multitask learning", "lifelong learning", "online learning"], "authors": ["Keerthiram Murugesan", "Jaime Carbonell"], "authorids": ["kmuruges@cs.cmu.edu", "jgc@cs.cmu.edu"]}, "nonreaders": [], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}}, "tauthor": "ICLR.cc/2018/Conference"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1517260088369, "tcdate": 1517249750039, "number": 472, "cdate": 1517249750024, "id": "HJCCN1Trz", "invitation": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "forum": "H1Ww66x0-", "replyto": "H1Ww66x0-", "signatures": ["ICLR.cc/2018/Conference/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Conference Acceptance Decision", "comment": "The output kernel idea for lifelong learning is interesting, but insufficiently developed in the current draft."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Lifelong Learning with Output Kernels", "abstract": "Lifelong learning poses considerable challenges in terms of effectiveness (minimizing prediction errors for all tasks) and overall computational tractability for real-time performance.  This paper addresses continuous lifelong multitask learning by jointly re-estimating the inter-task relations (\\textit{output} kernel) and the per-task model parameters at each round, assuming data arrives in a streaming fashion. We propose a novel algorithm called  \\textit{Online Output Kernel Learning Algorithm} (OOKLA) for lifelong learning setting. To avoid the memory explosion, we propose a robust budget-limited versions of the proposed algorithm that efficiently utilize the relationship between the tasks to bound the total number of representative examples in the support set.  In addition, we propose a two-stage budgeted scheme for efficiently tackling the task-specific budget constraints in lifelong learning. Our empirical results over three datasets indicate superior AUC performance for OOKLA and its budget-limited cousins over strong baselines.", "pdf": "/pdf/c2b029ef0ced524aba05fd0da3c6d32f48c9fefc.pdf", "TL;DR": "a novel approach for online lifelong learning using output kernels.", "paperhash": "murugesan|lifelong_learning_with_output_kernels", "_bibtex": "@misc{\nmurugesan2018lifelong,\ntitle={Lifelong Learning with Output Kernels},\nauthor={Keerthiram Murugesan and Jaime Carbonell},\nyear={2018},\nurl={https://openreview.net/forum?id=H1Ww66x0-},\n}", "keywords": ["multitask learning", "lifelong learning", "online learning"], "authors": ["Keerthiram Murugesan", "Jaime Carbonell"], "authorids": ["kmuruges@cs.cmu.edu", "jgc@cs.cmu.edu"]}, "tags": [], "invitation": {"id": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "rdate": null, "ddate": null, "expdate": 1541175629000, "duedate": null, "tmdate": 1541177635767, "tddate": null, "super": null, "final": null, "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": {"values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Conference/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Conference Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": [], "noninvitees": [], "writers": ["ICLR.cc/2018/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1541177635767}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642448318, "tcdate": 1511350296791, "number": 1, "cdate": 1511350296791, "id": "SyZQxkmxG", "invitation": "ICLR.cc/2018/Conference/-/Paper433/Official_Review", "forum": "H1Ww66x0-", "replyto": "H1Ww66x0-", "signatures": ["ICLR.cc/2018/Conference/Paper433/AnonReviewer2"], "readers": ["everyone"], "content": {"title": "This paper addresses the problem of lifelong multitask learning and proposes an efficient updating rule to learning the inter-task relationship and a new budget maintenance scheme to overcome the out of memory issue.  Experiments are conducted to demonstrate the effectiveness of the proposed method in the limited budget situation. ", "rating": "3: Clear rejection", "review": "CONTRIBUTION\nThe main contribution of the paper is not clearly stated.  To the reviewer, It seems \u201clife-long learning\u201d is the same as \u201conline learning\u201d.  However, the whole paper does not define what \u201clife-long learning\u201d is.\nThe limited budget scheme is well established in the literature. \n1. J. Hu, H. Yang, I. King, M. R. Lyu, and A. M.-C. So. Kernelized online imbalanced learning with fixed budgets. In AAAI, Austin Texas, USA, Jan. 25-30 2015. \u2028\n2. Y. Engel, S. Mannor, and R. Meir. The kernel recursive least-squares algorithm. IEEE Transactions on Signal Processing, 52(8):2275\u20132285, 2004.\nIt is not clear what the new proposal in the paper.\n\nWRITING QUALITY\nThe paper is not well written in a good shape. Many meanings of the equations are not stated clearly, e.g., $phi$ in eq. (7). Furthermore, the equation in algorithm 2 is not well formatted. \n\nDETAILED COMMENTS\n1. The mapping function $phi$ appears in Eq. (1) without definition.\n2. The last equation in pp. 3 defines the decision function f by an inner product. In the equation, the notation x_t and i_t is not clearly defined.  More seriously, a comma is missed in the definition of the inner product.\n3. Some equations are labeled but never referenced, e.g., Eq. (4).\n4. The physical meaning of Eq.(7) is unclear.  However, this equation is the key proposal of the paper.   For example, what is the output of the Eq. (7)? What is the main objective of Eq. (7)?  Moreover, what support vectors should be removed by optimizing Eq. (7)?  One main issue is that the notation $phi$ is not clearly defined.   The computation of f-y_r\\phi(s_r) makes it hard to understand.  Especially,  the dimension of $phi$ in Eq.(7) is unknown. \n\nABOUT EXPERIMENTS\n1.\tIt is unclear how to tune the hyperparameters.\n2.\tIn Table 1, the results only report the standard deviation of AUC. No standard deviations of nSV and Time are reported.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Lifelong Learning with Output Kernels", "abstract": "Lifelong learning poses considerable challenges in terms of effectiveness (minimizing prediction errors for all tasks) and overall computational tractability for real-time performance.  This paper addresses continuous lifelong multitask learning by jointly re-estimating the inter-task relations (\\textit{output} kernel) and the per-task model parameters at each round, assuming data arrives in a streaming fashion. We propose a novel algorithm called  \\textit{Online Output Kernel Learning Algorithm} (OOKLA) for lifelong learning setting. To avoid the memory explosion, we propose a robust budget-limited versions of the proposed algorithm that efficiently utilize the relationship between the tasks to bound the total number of representative examples in the support set.  In addition, we propose a two-stage budgeted scheme for efficiently tackling the task-specific budget constraints in lifelong learning. Our empirical results over three datasets indicate superior AUC performance for OOKLA and its budget-limited cousins over strong baselines.", "pdf": "/pdf/c2b029ef0ced524aba05fd0da3c6d32f48c9fefc.pdf", "TL;DR": "a novel approach for online lifelong learning using output kernels.", "paperhash": "murugesan|lifelong_learning_with_output_kernels", "_bibtex": "@misc{\nmurugesan2018lifelong,\ntitle={Lifelong Learning with Output Kernels},\nauthor={Keerthiram Murugesan and Jaime Carbonell},\nyear={2018},\nurl={https://openreview.net/forum?id=H1Ww66x0-},\n}", "keywords": ["multitask learning", "lifelong learning", "online learning"], "authors": ["Keerthiram Murugesan", "Jaime Carbonell"], "authorids": ["kmuruges@cs.cmu.edu", "jgc@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642448229, "id": "ICLR.cc/2018/Conference/-/Paper433/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper433/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper433/AnonReviewer2", "ICLR.cc/2018/Conference/Paper433/AnonReviewer1", "ICLR.cc/2018/Conference/Paper433/AnonReviewer3"], "reply": {"forum": "H1Ww66x0-", "replyto": "H1Ww66x0-", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper433/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642448229}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642448283, "tcdate": 1511609516818, "number": 2, "cdate": 1511609516818, "id": "SySnNRUxz", "invitation": "ICLR.cc/2018/Conference/-/Paper433/Official_Review", "forum": "H1Ww66x0-", "replyto": "H1Ww66x0-", "signatures": ["ICLR.cc/2018/Conference/Paper433/AnonReviewer1"], "readers": ["everyone"], "content": {"title": "A lifelong mutlitask learning scheme with online kernel learning, with low technical novelty ", "rating": "2: Strong rejection", "review": "Summary: The paper proposed a two-dimensional approach to lifelong learning, in the context of multi-task learning. It receives instances in an online setting, where both the prediction model and the relationship between the tasks are learnt using a online kernel based approach. It also proposed to use budgeting techniques to overcome computational costs. In general, the paper is poorly written, with many notation mistakes and inconsistencies. The idea does not seem to be novel, technical novelty is low, and the execution in experiments does not seem to be reliable. \n\nQuality: No obvious mistakes in the proposed method, but has very low novelty (as most methods follows existing studies in especially for online kernel learning). Many mistakes in the presentation and experiments.  \n\nOriginality: The ideas do not seem to be novel, and are mostly (trivially) using existing work as different components of the proposed technique. \n\nClarity: The paper makes many mistakes, and is difficult to read. [N] is elsewhere denoted as \\mathbb{N}. The main equation of Algorithm 2 merges into Algorithm 3. Many claims are made without justification (e.g. 2.2. \u201cCavallanti 2012 is not suitable for lifelong learning\u201d\u2026 why?; \u201csimple removal scheme \u2026 highest confidence\u201d \u2013 what is the meaning of highest confidence?), etc. The removal strategy is not at all well explained \u2013 the objective function details and solving it are not discussed. \n\nSignificance: There is no theoretical guarantee on the performance, despite the author\u2019s claiming this as a goal in the introduction itself (\u201cgoal of lifelong learner \u2026 computation\u201d). The experiments are not reliable. Perceptron obtains a better performance than PA algorithms \u2013 which is very odd. Moreover, many of the multi-task baselines obtain a worse performance than a simple perceptron (which does not account for multi-task relationships). \n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Lifelong Learning with Output Kernels", "abstract": "Lifelong learning poses considerable challenges in terms of effectiveness (minimizing prediction errors for all tasks) and overall computational tractability for real-time performance.  This paper addresses continuous lifelong multitask learning by jointly re-estimating the inter-task relations (\\textit{output} kernel) and the per-task model parameters at each round, assuming data arrives in a streaming fashion. We propose a novel algorithm called  \\textit{Online Output Kernel Learning Algorithm} (OOKLA) for lifelong learning setting. To avoid the memory explosion, we propose a robust budget-limited versions of the proposed algorithm that efficiently utilize the relationship between the tasks to bound the total number of representative examples in the support set.  In addition, we propose a two-stage budgeted scheme for efficiently tackling the task-specific budget constraints in lifelong learning. Our empirical results over three datasets indicate superior AUC performance for OOKLA and its budget-limited cousins over strong baselines.", "pdf": "/pdf/c2b029ef0ced524aba05fd0da3c6d32f48c9fefc.pdf", "TL;DR": "a novel approach for online lifelong learning using output kernels.", "paperhash": "murugesan|lifelong_learning_with_output_kernels", "_bibtex": "@misc{\nmurugesan2018lifelong,\ntitle={Lifelong Learning with Output Kernels},\nauthor={Keerthiram Murugesan and Jaime Carbonell},\nyear={2018},\nurl={https://openreview.net/forum?id=H1Ww66x0-},\n}", "keywords": ["multitask learning", "lifelong learning", "online learning"], "authors": ["Keerthiram Murugesan", "Jaime Carbonell"], "authorids": ["kmuruges@cs.cmu.edu", "jgc@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642448229, "id": "ICLR.cc/2018/Conference/-/Paper433/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper433/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper433/AnonReviewer2", "ICLR.cc/2018/Conference/Paper433/AnonReviewer1", "ICLR.cc/2018/Conference/Paper433/AnonReviewer3"], "reply": {"forum": "H1Ww66x0-", "replyto": "H1Ww66x0-", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper433/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642448229}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642448245, "tcdate": 1511827767596, "number": 3, "cdate": 1511827767596, "id": "rklBKmcgG", "invitation": "ICLR.cc/2018/Conference/-/Paper433/Official_Review", "forum": "H1Ww66x0-", "replyto": "H1Ww66x0-", "signatures": ["ICLR.cc/2018/Conference/Paper433/AnonReviewer3"], "readers": ["everyone"], "content": {"title": "The paper in an online budgeted version of an existing lifelong learning algorithm. The methodological contribution is minor and the experiments are not well designed.", "rating": "4: Ok but not good enough - rejection", "review": "The paper proposes a budgeted online kernel algorithm for multi-task learning. The main contribution of the paper is an online update of the output kernel, which measures similarity between pairs of tasks. The paper also proposes a removal strategy that bounds the number of support vectors in the kernel machine. The proposed algorithm is tested on 3 data sets and compared with several baselines.\n  Positives:\n- the output kernel update is well justified\n- experimental results are encouraging\n  Negatives:\n- the methodological contribution of the paper is minimal\n- the proposed approach to maintain the budget is simplistic\n- no theoretical analysis of the proposed algorithm is provided\n- there are issues with the experiments: the choice of data sets is questionable (all data sets are very small so there is not need for online learning or budgeting; newsgroups is a multi-class problem, so we would want to see comparisons with some good multi-class algorithms; spam data set might be too small), it is not clear what were hyperparameters in different algorithms and how they were selected, the budgeted baselines used in the experiments  are not state of the art (forgetron and random removal are known to perform poorly in practice, projectron usually works much better), it is not clear how a practitioner would decide whether to use update (2) or(3)", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Lifelong Learning with Output Kernels", "abstract": "Lifelong learning poses considerable challenges in terms of effectiveness (minimizing prediction errors for all tasks) and overall computational tractability for real-time performance.  This paper addresses continuous lifelong multitask learning by jointly re-estimating the inter-task relations (\\textit{output} kernel) and the per-task model parameters at each round, assuming data arrives in a streaming fashion. We propose a novel algorithm called  \\textit{Online Output Kernel Learning Algorithm} (OOKLA) for lifelong learning setting. To avoid the memory explosion, we propose a robust budget-limited versions of the proposed algorithm that efficiently utilize the relationship between the tasks to bound the total number of representative examples in the support set.  In addition, we propose a two-stage budgeted scheme for efficiently tackling the task-specific budget constraints in lifelong learning. Our empirical results over three datasets indicate superior AUC performance for OOKLA and its budget-limited cousins over strong baselines.", "pdf": "/pdf/c2b029ef0ced524aba05fd0da3c6d32f48c9fefc.pdf", "TL;DR": "a novel approach for online lifelong learning using output kernels.", "paperhash": "murugesan|lifelong_learning_with_output_kernels", "_bibtex": "@misc{\nmurugesan2018lifelong,\ntitle={Lifelong Learning with Output Kernels},\nauthor={Keerthiram Murugesan and Jaime Carbonell},\nyear={2018},\nurl={https://openreview.net/forum?id=H1Ww66x0-},\n}", "keywords": ["multitask learning", "lifelong learning", "online learning"], "authors": ["Keerthiram Murugesan", "Jaime Carbonell"], "authorids": ["kmuruges@cs.cmu.edu", "jgc@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642448229, "id": "ICLR.cc/2018/Conference/-/Paper433/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper433/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper433/AnonReviewer2", "ICLR.cc/2018/Conference/Paper433/AnonReviewer1", "ICLR.cc/2018/Conference/Paper433/AnonReviewer3"], "reply": {"forum": "H1Ww66x0-", "replyto": "H1Ww66x0-", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper433/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642448229}}}, {"tddate": null, "ddate": null, "tmdate": 1515216748829, "tcdate": 1515216748829, "number": 4, "cdate": 1515216748829, "id": "SJBuJy0Xz", "invitation": "ICLR.cc/2018/Conference/-/Paper433/Official_Comment", "forum": "H1Ww66x0-", "replyto": "H1Ww66x0-", "signatures": ["ICLR.cc/2018/Conference/Paper433/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper433/Authors"], "content": {"title": "Major Clarification Points", "comment": "We thank all the reviewers for the helpful comments, which we will take into account in our revision.  We give our major clarifications points here.\n\n \u201cMinimal contribution\u201d:\nIn essence, our paper has three main contributions:\n1) proposing simple update rules for learning task relationship \nUnlike in (Jawanpuria 2015), we proposed simple sequential updates for learning task relationship matrix in addition to satisfying its positive semi-definite constraint at each iteration.  These update equations are unique to online lifelong learning setting and doesn\u2019t require access to the entire input kernel matrix. The proposed algorithm can easily scales to large datasets with many tasks.\n\n2) incorporating task relationship in the budgeted scheme \nOur proposed scheme consists of a simple removal step that utilizes the task relationship.  Unlike in the previous work, we remove an example from the support set S by considering both the similarity between the examples (via confidence of the models) and the relationship between the tasks with less runtime per removal step. The proposed method empirically outperforms (both in terms of AUC and Time taken) other multitask budgeted learning schemes.\n\n3) two-stage budgeted approach for lifelong learning\nTo the best of our knowledge, our paper proposed the first practical budgeted scheme for lifelong multitask learning. The two-stage budgeted scheme allows us to use expensive budgeted schemes with best retention policy such as Projectron on task-specific budget T_k instead of S. \n\nWe will clarify these points along with additional details on update equations and budgeted removal step.\n\n\u201cSmaller datasets\u201d\nAll the datasets in our experiments are widely accepted benchmarks in online multi-task and lifelong learning evaluations (See Pentina 2016, Murugesan 2016).  We chose these 3 datasets for two main reasons: 1) for a fair comparison with the current online multi-task learning methods such as OSMTL, OMTRL, etc. 2) to consider different type of tasks that one may encounter in many practical applications such as spam detection, sentiment analysis, etc. \n\nWe plan to include additional experiments on datasets with large number of tasks in the revised version.\n\n\u201cHyper-parameters\u201d\nWe tuned all the hyper-parameters via 5-fold cross validation. We will include additional details on the hyper-parameters of the baselines for clarity.\n\n\u201cTheoretical analysis\u201d\nWe are currently working on the theoretical bounds for the proposed lifelong learning approach. We will derive the generalization bounds for lifelong learning setting with respect to some unknown task-generating probability distribution.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Lifelong Learning with Output Kernels", "abstract": "Lifelong learning poses considerable challenges in terms of effectiveness (minimizing prediction errors for all tasks) and overall computational tractability for real-time performance.  This paper addresses continuous lifelong multitask learning by jointly re-estimating the inter-task relations (\\textit{output} kernel) and the per-task model parameters at each round, assuming data arrives in a streaming fashion. We propose a novel algorithm called  \\textit{Online Output Kernel Learning Algorithm} (OOKLA) for lifelong learning setting. To avoid the memory explosion, we propose a robust budget-limited versions of the proposed algorithm that efficiently utilize the relationship between the tasks to bound the total number of representative examples in the support set.  In addition, we propose a two-stage budgeted scheme for efficiently tackling the task-specific budget constraints in lifelong learning. Our empirical results over three datasets indicate superior AUC performance for OOKLA and its budget-limited cousins over strong baselines.", "pdf": "/pdf/c2b029ef0ced524aba05fd0da3c6d32f48c9fefc.pdf", "TL;DR": "a novel approach for online lifelong learning using output kernels.", "paperhash": "murugesan|lifelong_learning_with_output_kernels", "_bibtex": "@misc{\nmurugesan2018lifelong,\ntitle={Lifelong Learning with Output Kernels},\nauthor={Keerthiram Murugesan and Jaime Carbonell},\nyear={2018},\nurl={https://openreview.net/forum?id=H1Ww66x0-},\n}", "keywords": ["multitask learning", "lifelong learning", "online learning"], "authors": ["Keerthiram Murugesan", "Jaime Carbonell"], "authorids": ["kmuruges@cs.cmu.edu", "jgc@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825733720, "id": "ICLR.cc/2018/Conference/-/Paper433/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "H1Ww66x0-", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper433/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper433/Authors|ICLR.cc/2018/Conference/Paper433/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper433/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper433/Authors|ICLR.cc/2018/Conference/Paper433/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper433/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper433/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper433/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper433/Reviewers", "ICLR.cc/2018/Conference/Paper433/Authors", "ICLR.cc/2018/Conference/Paper433/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825733720}}}, {"tddate": null, "ddate": null, "tmdate": 1515214866759, "tcdate": 1515202526383, "number": 3, "cdate": 1515202526383, "id": "S1Ikdi67G", "invitation": "ICLR.cc/2018/Conference/-/Paper433/Official_Comment", "forum": "H1Ww66x0-", "replyto": "SyZQxkmxG", "signatures": ["ICLR.cc/2018/Conference/Paper433/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper433/Authors"], "content": {"title": "@AnonReviewer2", "comment": "\u201cDifference between online multitask learning and lifelong learning\u201d\nAs mentioned in Page 2 Paragraph 3, the key difference is that the online multitask learning, unlike in the lifelong learning, may require that the number of tasks be specified beforehand. Most existing online multitask learning algorithms utilize this additional knowledge for learning the task relationship such as FOML, OMTRL, OSMTL, etc.\n\n\u201cReferences for budgeted schemes\u201d\nThank you for the additional references. The budget schemes from Hu et al. use the similarity between the examples for removal, on the other hand, our proposed budget schemes consider both the similarity between the examples and the relationship between the tasks to identify an example to remove.  The sparsification procedure considered in Engel et al.  will suffer from scalability issues similar to the Multitask Projectron as discussed in the paper.\n\n\\phi(.) is the feature function used in kernel learning. We will make this clear with all other clarifications in our revised version.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Lifelong Learning with Output Kernels", "abstract": "Lifelong learning poses considerable challenges in terms of effectiveness (minimizing prediction errors for all tasks) and overall computational tractability for real-time performance.  This paper addresses continuous lifelong multitask learning by jointly re-estimating the inter-task relations (\\textit{output} kernel) and the per-task model parameters at each round, assuming data arrives in a streaming fashion. We propose a novel algorithm called  \\textit{Online Output Kernel Learning Algorithm} (OOKLA) for lifelong learning setting. To avoid the memory explosion, we propose a robust budget-limited versions of the proposed algorithm that efficiently utilize the relationship between the tasks to bound the total number of representative examples in the support set.  In addition, we propose a two-stage budgeted scheme for efficiently tackling the task-specific budget constraints in lifelong learning. Our empirical results over three datasets indicate superior AUC performance for OOKLA and its budget-limited cousins over strong baselines.", "pdf": "/pdf/c2b029ef0ced524aba05fd0da3c6d32f48c9fefc.pdf", "TL;DR": "a novel approach for online lifelong learning using output kernels.", "paperhash": "murugesan|lifelong_learning_with_output_kernels", "_bibtex": "@misc{\nmurugesan2018lifelong,\ntitle={Lifelong Learning with Output Kernels},\nauthor={Keerthiram Murugesan and Jaime Carbonell},\nyear={2018},\nurl={https://openreview.net/forum?id=H1Ww66x0-},\n}", "keywords": ["multitask learning", "lifelong learning", "online learning"], "authors": ["Keerthiram Murugesan", "Jaime Carbonell"], "authorids": ["kmuruges@cs.cmu.edu", "jgc@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825733720, "id": "ICLR.cc/2018/Conference/-/Paper433/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "H1Ww66x0-", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper433/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper433/Authors|ICLR.cc/2018/Conference/Paper433/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper433/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper433/Authors|ICLR.cc/2018/Conference/Paper433/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper433/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper433/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper433/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper433/Reviewers", "ICLR.cc/2018/Conference/Paper433/Authors", "ICLR.cc/2018/Conference/Paper433/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825733720}}}, {"tddate": null, "ddate": null, "tmdate": 1515202478918, "tcdate": 1515202478918, "number": 2, "cdate": 1515202478918, "id": "Skv3vop7M", "invitation": "ICLR.cc/2018/Conference/-/Paper433/Official_Comment", "forum": "H1Ww66x0-", "replyto": "SySnNRUxz", "signatures": ["ICLR.cc/2018/Conference/Paper433/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper433/Authors"], "content": {"title": "@AnonReviewer1", "comment": "\u201cCavallanti 2012 is impractical for lifelong learning\u201d\nThe multitask variants of the budgeted schemes in Cavallanti 2012 assumes that the relationship between the tasks are known a priori. In addition to the unknown number of tasks, they don\u2019t scale to lifelong learning setting since the tasks arrive sequentially.  \n\n\u201cConfidence in removal step\u201d\nThe confidence is measured using the margin i.e., how far an example x_r is from the margin after removing it from S. \n\n\u201cmultitask baselines worse than perceptron\u201d\nPerceptron in Table 1 shows the results for single-task setting where it builds one models for all the tasks, whereas PA shows the results for independent task learning where it learns independent model for each task. \n\nSince Perceptron, FOML and OSMTL cannot learn the negative correlation between the tasks, the results of Perceptron, FOML and OSMTL are similar in newsgroup datasets.  Note that the results for Perceptron is comparable to that of FOML and OSMTL as it sets \\Omega_{ij}=1 for all i,j.  In case of sentiment dataset, we can see that FOML and OSMTL outperform Perceptron as they consider the task relationship. We will fix this in the revised version.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Lifelong Learning with Output Kernels", "abstract": "Lifelong learning poses considerable challenges in terms of effectiveness (minimizing prediction errors for all tasks) and overall computational tractability for real-time performance.  This paper addresses continuous lifelong multitask learning by jointly re-estimating the inter-task relations (\\textit{output} kernel) and the per-task model parameters at each round, assuming data arrives in a streaming fashion. We propose a novel algorithm called  \\textit{Online Output Kernel Learning Algorithm} (OOKLA) for lifelong learning setting. To avoid the memory explosion, we propose a robust budget-limited versions of the proposed algorithm that efficiently utilize the relationship between the tasks to bound the total number of representative examples in the support set.  In addition, we propose a two-stage budgeted scheme for efficiently tackling the task-specific budget constraints in lifelong learning. Our empirical results over three datasets indicate superior AUC performance for OOKLA and its budget-limited cousins over strong baselines.", "pdf": "/pdf/c2b029ef0ced524aba05fd0da3c6d32f48c9fefc.pdf", "TL;DR": "a novel approach for online lifelong learning using output kernels.", "paperhash": "murugesan|lifelong_learning_with_output_kernels", "_bibtex": "@misc{\nmurugesan2018lifelong,\ntitle={Lifelong Learning with Output Kernels},\nauthor={Keerthiram Murugesan and Jaime Carbonell},\nyear={2018},\nurl={https://openreview.net/forum?id=H1Ww66x0-},\n}", "keywords": ["multitask learning", "lifelong learning", "online learning"], "authors": ["Keerthiram Murugesan", "Jaime Carbonell"], "authorids": ["kmuruges@cs.cmu.edu", "jgc@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825733720, "id": "ICLR.cc/2018/Conference/-/Paper433/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "H1Ww66x0-", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper433/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper433/Authors|ICLR.cc/2018/Conference/Paper433/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper433/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper433/Authors|ICLR.cc/2018/Conference/Paper433/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper433/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper433/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper433/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper433/Reviewers", "ICLR.cc/2018/Conference/Paper433/Authors", "ICLR.cc/2018/Conference/Paper433/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825733720}}}, {"tddate": null, "ddate": null, "tmdate": 1515202422302, "tcdate": 1515202422302, "number": 1, "cdate": 1515202422302, "id": "SJ0_PiTXM", "invitation": "ICLR.cc/2018/Conference/-/Paper433/Official_Comment", "forum": "H1Ww66x0-", "replyto": "rklBKmcgG", "signatures": ["ICLR.cc/2018/Conference/Paper433/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper433/Authors"], "content": {"title": "@AnonReviewer3", "comment": "\u201call data sets are very small so\u201d \n*) \u201cthere is no need for online learning\u201d\nOur focus in this paper is on the scenario where training examples are insufficient for each single task.  In other words, we are interested in a lifelong learning setting where we see large number of tasks with limited set of labeled examples per task. \n\n*) \u201cor budgeting\u201d\nThe budget/support set S contains examples from all the tasks. Even though the number of examples per task is small, the tasks arrive sequentially (with unknown horizon). The new examples are added to S over several rounds. Without any bound on the size of S, we will face the memory explosion problem as discussed in the Introduction section.\n\n\u201cnewsgroups is a multi-class problem\u201d\nWe use newsgroup dataset to demonstrate the effectiveness of the proposed algorithm to learn the (positive, negative, no) correlation between the tasks with our simple update rules. In this experiment, each task identifies the subject group (comp and talk.politics) rather than the class.\n\n\u201cbudgeted baselines are not state-of-the-art\u201d\nOur baselines in Table 2 are specific to multitask and lifelong learning setting that considers relationship between the tasks for removal step (See Cavallanti 2012). In addition, Projectron has one of the best retention policies for budgeted learning algorithms. \n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Lifelong Learning with Output Kernels", "abstract": "Lifelong learning poses considerable challenges in terms of effectiveness (minimizing prediction errors for all tasks) and overall computational tractability for real-time performance.  This paper addresses continuous lifelong multitask learning by jointly re-estimating the inter-task relations (\\textit{output} kernel) and the per-task model parameters at each round, assuming data arrives in a streaming fashion. We propose a novel algorithm called  \\textit{Online Output Kernel Learning Algorithm} (OOKLA) for lifelong learning setting. To avoid the memory explosion, we propose a robust budget-limited versions of the proposed algorithm that efficiently utilize the relationship between the tasks to bound the total number of representative examples in the support set.  In addition, we propose a two-stage budgeted scheme for efficiently tackling the task-specific budget constraints in lifelong learning. Our empirical results over three datasets indicate superior AUC performance for OOKLA and its budget-limited cousins over strong baselines.", "pdf": "/pdf/c2b029ef0ced524aba05fd0da3c6d32f48c9fefc.pdf", "TL;DR": "a novel approach for online lifelong learning using output kernels.", "paperhash": "murugesan|lifelong_learning_with_output_kernels", "_bibtex": "@misc{\nmurugesan2018lifelong,\ntitle={Lifelong Learning with Output Kernels},\nauthor={Keerthiram Murugesan and Jaime Carbonell},\nyear={2018},\nurl={https://openreview.net/forum?id=H1Ww66x0-},\n}", "keywords": ["multitask learning", "lifelong learning", "online learning"], "authors": ["Keerthiram Murugesan", "Jaime Carbonell"], "authorids": ["kmuruges@cs.cmu.edu", "jgc@cs.cmu.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825733720, "id": "ICLR.cc/2018/Conference/-/Paper433/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "H1Ww66x0-", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper433/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper433/Authors|ICLR.cc/2018/Conference/Paper433/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper433/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper433/Authors|ICLR.cc/2018/Conference/Paper433/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper433/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper433/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper433/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper433/Reviewers", "ICLR.cc/2018/Conference/Paper433/Authors", "ICLR.cc/2018/Conference/Paper433/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825733720}}}], "count": 9}