{"notes": [{"id": "SJlYznBEtS", "original": null, "number": 9, "cdate": 1571212305128, "ddate": null, "tcdate": 1571212305128, "tmdate": 1571212305128, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "H1ewdiR5tQ", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Public_Comment", "content": {"comment": "Compared with GCN,  this paper replaced the non-localized and non-sparse graph Fourier bases with the so-called \"graph wavelet bases\" ,  leveraging the sparseness and locality of graph wavelet bases to improve the efficiency of GCN. However, I have some questions about the definition of the graph wavelet transform in this paper. \n\nFirst, in section 2.3, you defined $\\phi_s$ as the graph wavelet bases, and the kernel is $g(s\\lambda)=e^{s\\lambda}$ . However,  it is certainly not the graph wavelet bases defined in  Hammond et al (2011), where $g$ is required to meet some conditions, e.g $g$ is a band-pass filter. Obviously $g(s\\lambda)=e^{s\\lambda}$ can not meet these requirements.\n\nSecond, you call  $\\hat{x}=\\phi_s^{-1}x$ as graph wavelet transform, but actually it is not. As defined in  Hammond et al (2011), if $\\phi_s$ is the graph wavelet bases, then $\\hat{x}=<\\phi_s, x>=\\phi_s^*x$ is the graph wavelet transform.  Furthermore, I am more confusing about relationship between the graph wavelet transform and inverse graph wavelet transform defined in this paper (Eq.(4).).\n\nCould you explain these for me? ", "title": "Questions about the definition of the graph wavelet transform in this paper!"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311857652, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "H1ewdiR5tQ", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311857652}}}, {"id": "rkx68SByEV", "original": null, "number": 7, "cdate": 1548862805327, "ddate": null, "tcdate": 1548862805327, "tmdate": 1548862805327, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "B1lazXHDXV", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Public_Comment", "content": {"comment": "I saw the code release. Linked it in the readme of the repository.", "title": "Thank you for the code release."}, "signatures": ["~Benedek_Rozemberczki1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Benedek_Rozemberczki1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311857652, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "H1ewdiR5tQ", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311857652}}}, {"id": "B1lazXHDXV", "original": null, "number": 27, "cdate": 1548337940756, "ddate": null, "tcdate": 1548337940756, "tmdate": 1548337940756, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "ryxZNpEDQV", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "content": {"title": "Thank you for your comment", "comment": "Thank you for your feedback and reproduce!\n\nI implemented my code via tensorflow. In my code, I set the elements which are lower than a given threshold to zero, which is stated in the paper. Also, the datasets are divided as GCN (https://github.com/tkipf/gcn). I will organize and release my code in Github as soon as possible, and update the link of Github here."}, "signatures": ["ICLR.cc/2019/Conference/Paper363/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621604510, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1ewdiR5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper363/Authors|ICLR.cc/2019/Conference/Paper363/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621604510}}}, {"id": "ryxZNpEDQV", "original": null, "number": 6, "cdate": 1548336424771, "ddate": null, "tcdate": 1548336424771, "tmdate": 1548336424771, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "H1ewdiR5tQ", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Public_Comment", "content": {"comment": "I attempted to reproduce the results. The accuracy scores are lower than reported, even with a larger training set. What was your exact approach to defining/creating a wavelet filter?\n\nhttps://github.com/benedekrozemberczki/GraphWaveletNeuralNetwork", "title": "Attempt to reproduce results."}, "signatures": ["~Benedek_Rozemberczki1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Benedek_Rozemberczki1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311857652, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "H1ewdiR5tQ", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311857652}}}, {"id": "H1ewdiR5tQ", "original": "HkeuD5y9Ym", "number": 363, "cdate": 1538087791005, "ddate": null, "tcdate": 1538087791005, "tmdate": 1547117314839, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 33, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "SygtJlSZxN", "original": null, "number": 1, "cdate": 1544798176522, "ddate": null, "tcdate": 1544798176522, "tmdate": 1545354526218, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "H1ewdiR5tQ", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Meta_Review", "content": {"metareview": "AR1 and AR3 have found this paper interesting in terms of replacing the spectral operations in GCN by wavelet operations. However, AR4 was more critical about the poor complexity of the proposed method compared to approximations in Hammond et al. AR4 was also right to find the proposed work similar to Chebyshev approximations in ChebNet and to highlight that the proposed approach is only marginally better than GCN. On balance, all reviewers find some merit in this work thus AC advocates an accept. The authors are asked to keep the contents of the final draft as agreed with AR4 (and other reviewers) during rebuttal without making any further theoretical changes/brushing over various new claims/ideas unsolicited by the reviewers (otherwise such changes would require passing the draft again through reviewers).", "confidence": "5: The area chair is absolutely certain", "recommendation": "Accept (Poster)", "title": "some novelty"}, "signatures": ["ICLR.cc/2019/Conference/Paper363/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper363/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353242982, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1ewdiR5tQ", "replyto": "H1ewdiR5tQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper363/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper363/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper363/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353242982}}}, {"id": "rke3djBHJE", "original": null, "number": 24, "cdate": 1544014707802, "ddate": null, "tcdate": 1544014707802, "tmdate": 1544014707802, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "BkeGhSLykN", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "content": {"title": "Thanks for your comment", "comment": "Thank you for your comment! This paper seems interesting, i.e., any feature generated by the network is\napproximately invariant to permutations and stable to graph manipulations.  We will pay attention to it and add it as our related work if necessary."}, "signatures": ["ICLR.cc/2019/Conference/Paper363/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621604510, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1ewdiR5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper363/Authors|ICLR.cc/2019/Conference/Paper363/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621604510}}}, {"id": "B1lZ8H4Ch7", "original": null, "number": 2, "cdate": 1541453128937, "ddate": null, "tcdate": 1541453128937, "tmdate": 1543955656149, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "H1ewdiR5tQ", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Review", "content": {"title": "Long-awaited combination of Graph wavelets and NNs", "review": "This paper proposes to learn graph wavelet kernels through a neural network. This idea is interesting, even if it is not a real surprise, given the interesting features graph wavelets, and the explosion of proposals for graph neural networks. Yet, the paper is interesting, pretty complete, and the proposed algorithm is shown to be relatively effective. \n\nA few more detailed comments:\n\n- one for the key motivations the work, namely to avoid eigen-decompositions, is also solved in a different way by methods using Chebyshev approximations (e.g., Khasanova - ICML 2017). The introduction should be clarified accordingly. \n- retaining the flexibility of convolution kernel (on page 2): what do the authors mean here?\n- the graph wavelet nn in 2.4 is certainly an interesting combination of known elements - yet, it is not very clear how the network is trained/optimized at this stage. \n- the section 3 is a bit confusing: are the proposed elements, contributions of the paper, or only ideas with future work?\n- the idea of detaching feature transformation from convolution is interesting: it would be even better to quantify or discuss the penalty, if any, induced by this design choice. \n- the results are generally fine and convincing, even if they are not super-impressive. ' GWNN is comfortably ahead of Spectral CNN. ' is probably an over-statement however...\n- the discussion about interpretability is interesting, and very trendy. However, what the authors discuss is mere localisation and sparsity - this is one way to 'interpret' interpretability of features, but that discussion should be rephrased in a more mild sense then. \n\nGenerally, the ideas in this paper are interesting, even not surprising. The text should be clarified at places, and the paper looks a bit superficial on many aspects (see above). With good revision, it could lead to an interesting paper, and most likely to interesting discussions at ICLR.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper363/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Review", "cdate": 1542234478345, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "H1ewdiR5tQ", "replyto": "H1ewdiR5tQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335707414, "tmdate": 1552335707414, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HJxnVQ_Gk4", "original": null, "number": 21, "cdate": 1543828275886, "ddate": null, "tcdate": 1543828275886, "tmdate": 1543828275886, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "SJgbLEF0RQ", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "content": {"title": "Thank you for your response", "comment": "Thank you very much for your efforts on reviewing the paper and the response. Your review comments are valuable for improving and strengthening our paper. We are delightful to see that our revisions are acknowledged by you. \n\nRegards,\nThe authors\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper363/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621604510, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1ewdiR5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper363/Authors|ICLR.cc/2019/Conference/Paper363/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621604510}}}, {"id": "H1lVuGuMk4", "original": null, "number": 20, "cdate": 1543828075921, "ddate": null, "tcdate": 1543828075921, "tmdate": 1543828075921, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "ryg5qifzkV", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "content": {"title": "Reply to Reviewer4", "comment": "We appreciate you so much for the pertinent comments. With the two-round rebuttals and revisions, we are inspired that we have established a mutual understanding with you about the paper.\n\nConsidering that you still have some concerns, we would like to highlight our major improvements after revisions:\n\n- Informative analysis about hyper-parameter sensitivity.\nFigure 5 is added as a thorough analysis about the effect of the hyper-parameter on the performance of the proposed method. As shown in Figure 5, the proposed method is not sensitive to hyper-parameters.\n\n- Clarification about computational complexity.\nPrompted by your suggestions, we clarified the computational complexity of the graph wavelets and graph convolution via graph wavelets. Indeed, with Hammond\u2019s approximation (Appendix D), the computational complexity scales up to O(|E|) rather than being of quadratic complexity as concerned in your original review. \n\n- Good presentation quality. \nWe carefully revised the paper, clarifying several misleading statements in the original version. Moreover, we added detailed description about the implementation of the proposed method (Sec. 2.4). \n\nWe also agree that our method has several limitations, e.g., higher computational cost than GCN. However, these limitations don\u2019t deteriorate our major contribution, i.e., we offer a localized graph convolution via replacing graph Fourier transform with graph wavelet transform, and such a work is useful, at least promising, to help us design appropriate graph convolution via finding good spectral basis with localization property and good interpretability.\n\nIn sum, we are delighted to see that the technical novelty and presentation quality are acknowledged. With the aforementioned improvements, we believe the current version of this paper deserves a higher score than the original version.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper363/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621604510, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1ewdiR5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper363/Authors|ICLR.cc/2019/Conference/Paper363/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621604510}}}, {"id": "ryg5qifzkV", "original": null, "number": 19, "cdate": 1543805842229, "ddate": null, "tcdate": 1543805842229, "tmdate": 1543805842229, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "HyedjpicA7", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "content": {"title": "Further reply", "comment": "I would like to thank the authors for the detailed reply and the revision efforts. After reading the rebuttals, I think the authors have established a mutual understanding with me of the strength and weakness of the paper. Our difference is more on \"whether the strength is great enough\" and \"whether these weaknesses are OK\" for giving the paper a pass.\n\nAfter careful consideration and re-scan through the paper, I still would like to keep my score. I understand that the authors have made revisions that should be acknowledged as these revisions have improved the presentation.  However, these revisions and discussions have also confirmed the weakness as pointed out in my original review.\n\nLet me summarize my review as follows\nPro\n- technical novelty\n- presentation quality\nCon\n- computational and implementation difficulty\n- marginal improvement over GCN\n\nI would encourage the authors to develop this method into the next stage. Based on the novelty, I believe it deserves to be published in a good venue as ICLR after some further developments."}, "signatures": ["ICLR.cc/2019/Conference/Paper363/AnonReviewer4"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper363/AnonReviewer4", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621604510, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1ewdiR5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper363/Authors|ICLR.cc/2019/Conference/Paper363/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621604510}}}, {"id": "BkeGhSLykN", "original": null, "number": 5, "cdate": 1543624106145, "ddate": null, "tcdate": 1543624106145, "tmdate": 1543624106145, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "H1ewdiR5tQ", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Public_Comment", "content": {"comment": "This is an interesting study. In particular, training wavelets on graphs is very useful. It is interesting to compare with https://arxiv.org/abs/1804.00099. The latter work also uses Hammond's wavelets, but instead of training the wavelets it uses them to construct a scattering transform. It can be regarded as a graph network with fixed parameters. It is proved to have properties such as invariance to permutation and stability to signal and graph manipulation. ", "title": "Interesting study using graph wavelets"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": [], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311857652, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "H1ewdiR5tQ", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311857652}}}, {"id": "r1gNgBRO3X", "original": null, "number": 1, "cdate": 1541100780009, "ddate": null, "tcdate": 1541100780009, "tmdate": 1543570520808, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "H1ewdiR5tQ", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Review", "content": {"title": "Interesting approach", "review": "This is an empirical paper that proposes to design wavelets on graphs, that can be integrated to neural networks on graphs. It permits to reducing the number of parameters of the \u00ab convolution \u00bb and exploits the sparsity of sparse weighted graphs for computations. I think it\u2019s an interesting work.\n\nThe perspective I enjoy in using wavelets is that they typically provide a good trade-off in localization in the spectral and graph domains. For instance, large eigenvalues of the laplacian could be potentially captured in a more stable way. This type of work might be a first step.\n\nPros :\n- good numerical results\n- nice incorporation of structure via wavelets\nCons :\n- Sometimes the paper is not really clear\n\nI have severals comments:\n\n1/ (1) \u00ab Some subsequent works devote to making spectral methods spectrum-free\u2026 avoiding high computational cost \u00bb. I think also those types of representations can be potentially unstable. That\u2019s a second reason.\n\n2/ I\u2019m not sure to understand the point (1) of the fourth paragraph of the introduction. (1.)\u00ab graph wavelet does not depend on the eigen decomposition of Laplacian matrix \u00bb. Does it mean numerically ? This sentence is not clear, because even numerically, it can be done in a dependent way to this matrix. However, if it is implied that the fastest algorithm can be obtained without eigen-decomposition of the Laplacian Matrix, in a cheap way, then I agree and a small rephrasing could be nice.\n\n3/ Please remove all the sentences that are supposed to be an introduction for a section, i.e. the sentences between 2 and 2.1 (\u00ab We use graph\u2026 \u00bb) and 3 and 3.1 (\u00ab In many research\u2026 \u00bb). They are poorly written and do not help the reader.\n\n5/ .(2.2) \u201cHowever, such a polynomial approximation also limits the flexibility to define appropriate convolution on graph\u201d I\u2019m not sure to understand. In the paper you refer to, the set of filters span the polynomial of degree less than n, of a diagonalizable matrix of size nxn. Thus, lagrange polynomial basis could be used to interpolate any desired values? Does it signify learning non-diagonal(in the appropriate basis) matrix?\n\n6/ (2.3) $s$ how is this parameter chosen, crossvalidation? Is it adjusted such that the singular values of $\\psi_s$ have a certain decay? Why is $s$ constant across layers? How is the spectrum of psi_s? Is it well conditionned? A huge difference with (Hammond et al,2011) is that they use a collection of wavelets. Did you consider this kind of approach ? Is there a loss of information in some cases?(like if $\\psi_s$ has a fast decay)\n\n7/ (2.3) \u201cThe matrix $\\psi_s$ and $\\psi_s^{-1}$ are both sparse\u201d. This is a critical affirmation which is not in general true. It is possibly sparse if the weighted laplacian graph is sparse as well, as explained by the remark after theorem 5.5 of page 16 of (Hammond et al, 2011). However, I do agree this typically happens in the application you present. \n\n8/ The (c) of Figure 1 is missing.(in my version at least)\n\n9/ In section 5.3, why not trying to compare the number of parameters with other papers? I think also more results, with maybe a bit higher performances, could be reported, such as: GraphSGAN, GAT. But that\u2019s fine to me.\n\n10/ Appendix A, isn\u2019t it a simple rephrasing of (Hammond et al, 2011)?\n\n11/ How do you compare in term of interpretability with [1]?\n\n12/ Just as a suggestion and/or a comment: it seems similar to approaches such as lifting schemes(which basically builds wavelets on graphs/manifolds), except that there is no learning involved. (e.g. [2]) I think there could be great connexions.\n\n\n[1] Relational inductive biases, deep learning, and graph networks, Battaglia et al 2011?\n[2] THE LIFTING SCHEME: A CONSTRUCTION OF SECOND GENERATION WAVELETS, Wim Sweldgens", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper363/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Review", "cdate": 1542234478345, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "H1ewdiR5tQ", "replyto": "H1ewdiR5tQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335707414, "tmdate": 1552335707414, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SJgbLEF0RQ", "original": null, "number": 16, "cdate": 1543570504771, "ddate": null, "tcdate": 1543570504771, "tmdate": 1543570504771, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "BJg_QmL8Rm", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "content": {"title": "-", "comment": "Thank you for your answer. I updated my score as promised.\n\nRegards,"}, "signatures": ["ICLR.cc/2019/Conference/Paper363/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper363/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621604510, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1ewdiR5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper363/Authors|ICLR.cc/2019/Conference/Paper363/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621604510}}}, {"id": "HyedjpicA7", "original": null, "number": 14, "cdate": 1543318944276, "ddate": null, "tcdate": 1543318944276, "tmdate": 1543319030346, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "SJxDst0O0X", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "content": {"title": "Response to Reviewer4 (2/2)", "comment": "Q3: Experimentally, WAVELET has around 1% improvement over GCN's originally reported results, which is a fair baseline. Actually, GCN's performance can be a bit better than the reported results. For example, on the Pubmed dataset, its transductive classification accuracy can reach 79.2%, which is better than the proposed method. Moreover, as other reviewers/researchers have pointed out, the inductive results are missing.\n\nA3: Thank you for letting us to know that GCN can achieve better result (i.e., 79.2%) on Pubmed with well-tuned parameters. Indeed, GCN is also not the state-of-the-art methods for transductive node classification task. Several spatial methods like GAT achieve better results than GCN. We didn\u2019t compare with GAT in this paper, because we focus on the line of spectral methods.\n\nIn other words, we don\u2019t aim to design state-of-the-art method for graph-based semi-supervised learning task, e.g., node classification. We aim to demonstrate that graph wavelet transform is better than graph Fourier transform for designing spectral graph convolution. As shown in Table 3, the proposed GWNN method using graph wavelet transform remarkably (achieving 10% improvement on Cora and Citeseer, and 5% improvement on Pubmed) outperforms the Spectral CNN method using graph Fourier transform. \n\nFor the comparison with GCN, we want to clarify the connection and difference between our method and GCN. Both our method and GCN aim to improve spectral methods via design localized graph convolution. GCN, as a simplified version of ChebyNet, expresses the spectral graph convolution in spatial domain, acting as spatial-like method (Monti et al., 2017). Our method resorts to using graph wavelet as a new set of bases, directly designing localized spectral graph convolution. We compare with GCN on the transductive node classification task, just showing that these two methods have comparable results.\n\nFinally, spectral methods are inappropriate for the inductive classification task. Indeed, before GraphSAGE and GAT, almost all methods are not evaluated on inductive task. We follow the practice of spectral methods and evaluate our methods on the transductive classification task. \n\nQ4: In the sparsity comparison, one should also compare with the sparsity of the graph Laplacian matrix, so as to have an idea on the computational overhead of using the proposed approach.\n\nA4: We fully understand your concern about the computational cost of the proposed method. We acknowledge that the sparsity of the graph wavelet matrix depends on the sparsity of the Laplacian matrix and the hyper-parameter $s$. For clarity, we added the sparsity comparison between the two matrices in Appendix E.\n\nFor the computational overhead, it is not necessary to explicitly obtain the graph wavelet matrix for graph wavelet transform. Instead, following the Chebyshev approximation in Eq. (17) in Appendix D, the computational complexity of graph wavelet transform is O(m*|E|)."}, "signatures": ["ICLR.cc/2019/Conference/Paper363/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621604510, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1ewdiR5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper363/Authors|ICLR.cc/2019/Conference/Paper363/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621604510}}}, {"id": "S1gYRpj9A7", "original": null, "number": 15, "cdate": 1543318992606, "ddate": null, "tcdate": 1543318992606, "tmdate": 1543318992606, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "SJxDst0O0X", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "content": {"title": "Response to Reviewer4 (1/2)", "comment": "Thank you for your efforts on reviewing our paper and the response. We are sorry that our hard-working response fails to meet your requirement. Here, we offer more response and revise the paper with some supplements. \n\nQ1: Hammond et al (2011)'s O(|E|) approximation of \\phi_s and \\phi_s^{-1} are still missing.\n\nA1: We acknowledge that it would be much self-contained for the paper to include the technical details of the approximation of \\phi_s and \\phi_s^{-1}. Considering that the approximation algorithm isn\u2019t proposed by this paper, in the previous version, we only give the main results (e.g., complexity analysis) of the approximation with the reference to Hammond et al (2011). Prompted by your request, we included the technical details of the approximation of \\phi_s and \\phi_s^{-1} as Appendix D in the new version.\n\nQ2: It is true that the proposed GWNN has some computational issues and is surely more expensive than GCN (that's why you need Hammond et al's approximation) and has more hyper-parameters resulting from Hammond's polynomial approximation as well as the heat kernel. I am not convinced that the authors have fully acknowledged this point in their response.\n\nA2: Thank you for the pertinent comments. We also acknowledge that the proposed method still has some limitations, e.g., the computational issues and additional hyper-parameters as you pointed out, although we have attempted to combat these issues via approximation and detaching feature transformation from graph convolution. Yet, the major contribution, i.e., offering a localized graph convolution via replacing graph Fourier transform with graph wavelet transform, is not deteriorated by these issues. In particular, such a work is useful, at least promising, to help us design appropriate graph convolution via finding good spectral basis with localization property and good interpretability. This distinguishes our method from ChebyNet and GCN, which express the graph convolution defined via graph Fourier transform in vertex domain. In the revised version, we acknowledged these issues and added Appendix B and E to discuss the hyper-parameter and the computational cost.\n\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper363/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621604510, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1ewdiR5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper363/Authors|ICLR.cc/2019/Conference/Paper363/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621604510}}}, {"id": "SJxDst0O0X", "original": null, "number": 13, "cdate": 1543199134838, "ddate": null, "tcdate": 1543199134838, "tmdate": 1543199175030, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "SJl0RLrgC7", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "content": {"title": "Reply to rebuttal", "comment": "Thank you very much for the detailed clarification and revision on parameter sensitivity (the added Figure 5 is very informative).\n\nI will keep my original scores based on\n\n- Hammond et al (2011)'s O(|E|) approximation of \\phi_s and \\phi_s^{-1} are still missing.\n\n- It is true that the proposed GWNN has some computational issues and is surely more expensive than GCN (that's why you need Hammond et al's approximation) and has more hyperparameters resulting from Hammond's polynomial approximation as well as the heat kernel. I am not convinced that the authors have fully acknowledge this point in their response.\n\n- Experimentally, WAVELET has around 1% improvement over GCN's originally reported results, which is a fair baseline. Actually, GCN's performance can be a bit better than the reported results. For example, on the Pubmed dataset, its transductive classification accuracy can reach 79.2%, which is better than the proposed method. Moreover, as other reviewers/researchers have pointed out, the inductive results are missing.\n\n- In the sparsity comparison, one should also compare with the sparsity of the graph Laplacian matrix, so as to have an idea on the computational overhead of using the proposed approach.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper363/AnonReviewer4"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper363/AnonReviewer4", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621604510, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1ewdiR5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper363/Authors|ICLR.cc/2019/Conference/Paper363/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621604510}}}, {"id": "BJg_QmL8Rm", "original": null, "number": 12, "cdate": 1543033632095, "ddate": null, "tcdate": 1543033632095, "tmdate": 1543033632095, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "SJgloxU4CQ", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "content": {"title": "Thanks for your quick response", "comment": "We appreciate you so much for the quick response, and we are delighted to see your approval of our revision to this paper.\n\nPrompted by your suggestion, we added Appendix C to compare the parameter complexity of our method with other methods. In this paper, as the second major contribution, we propose detaching feature transformation from graph convolution,  reducing the parameter complexity remarkably, e.g., from $O(n*p*q)$ to $O(n+p*q)$ for Spectral CNN and our GWNN. Such a practice offers us an efficient implementation of GWNN, making it applicable to large scale real world networks. Moreover, with the reduction of parameter complexity, GWNN is particularly appropriate for the scenario of semi-supervised learning where labeled data is limited. For example, for the graph-based supervised learning task, i.e., node classification on Cora and Citeseer, GWNN with smaller parameter complexity achieves better performance than ChebyNet. \n\nThank you very much for all your comments, which are valuable for improving and strengthening our paper."}, "signatures": ["ICLR.cc/2019/Conference/Paper363/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621604510, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1ewdiR5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper363/Authors|ICLR.cc/2019/Conference/Paper363/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621604510}}}, {"id": "SJgloxU4CQ", "original": null, "number": 11, "cdate": 1542901912153, "ddate": null, "tcdate": 1542901912153, "tmdate": 1542901912153, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "BkeYvdreR7", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "content": {"title": "Thanks for the clarifications", "comment": "Dear authors,\n\nThank you for your clarifications and revisions. Maybe one question related to Q9: do you have a rough idea of the number of parameters w.r.t. other methods? (I do not think I saw this in the revised version of the paper)\n\nI'd be happy to raise my score to 7 after this.\nBest,\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper363/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper363/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621604510, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1ewdiR5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper363/Authors|ICLR.cc/2019/Conference/Paper363/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621604510}}}, {"id": "rygjzdBlA7", "original": null, "number": 8, "cdate": 1542637586599, "ddate": null, "tcdate": 1542637586599, "tmdate": 1542677886173, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "B1lZ8H4Ch7", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "content": {"title": "Response to Reviewer3", "comment": "Thank you for the pertinent comments and accurately summarizing the major contributions of this paper. According to your constructive suggestions, we carefully revised our paper with much improvement. We now offer point-by-point response.\n\nQ1: one for the key motivations the work, namely to avoid eigen-decompositions, is also solved in a different way by methods using Chebyshev approximations (e.g., Khasanova - ICML 2017). The introduction should be clarified accordingly. \n\nA1: We revised the statements relevant to this point, and cited the paper (i.e., Khasanova, ICML 2017) in the introduction part. \n\nQ2: retaining the flexibility of convolution kernel (on page 2): what do the authors mean here?\n\nA2: We apologize for the misleading statement. What we mean is that the convolution kernel of ChebyNet is not flexible. Specifically, ChebyNet offers a $K$-order polynomial parameterization to graph convolution kernel. A smaller $K$ causes high approximation bias, while a larger $K$ results in non-localized convolution kernel. Therefore, ChebyNet has limited flexibility to define graph convolution kernel. In the revised version, we clarified this point in the last paragraph in Section 2.2.\n\nQ3: the graph wavelet nn in 2.4 is certainly an interesting combination of known elements - yet, it is not very clear how the network is trained/optimized at this stage. \n\nA3: Thank you for pointing out this issue. Prompted by your suggestion, we revised Section 2.4: (1) We offered detailed description about the architecture of graph wavelet neural network; (2) We added the loss function when training graph wavelet neural networks on semi-supervised node classification task.\n\nQ4: the section 3 is a bit confusing: are the proposed elements, contributions of the paper, or only ideas with future work?\n\nA4: We apologize for the confusing organization of sections. Indeed, Section 3 is the second contribution of this paper, i.e., reducing the parameter complexity by detaching feature transformation from graph convolution. It is particularly important for training graph wavelet neural networks. For clarity, we reorganized the sections of this paper: combing the original Section 3 into Section 2 as a subsection, i.e., Section 2.5.\n\nQ5: the idea of detaching feature transformation from convolution is interesting: it would be even better to quantify or discuss the penalty, if any, induced by this design choice. \n\nA5: We are delighted to see that this idea is identified and approved. Detaching feature transformation from convolution, we remarkably reduce the number of parameters. This practice is particularly important for scenarios where labeled data is limited, e.g., graph-based semi-supervised learning task considered in this paper.\n\nOne potential penalty of this practice is that the modeling capacity is reduced. To quantify the penalty, in Section 4.4, we compared the influence of detaching feature transformation from convolution to the performance of graph-based semi-supervised node classification. Results demonstrate that detaching feature transformation from convolution achieves comparable (sometimes better) performance, with the number of parameters remarkably reduced. \n\nQ6: the results are generally fine and convincing, even if they are not super-impressive. ' GWNN is comfortably ahead of Spectral CNN. ' is probably an over-statement.\n\nA6: For experimental evaluation, we compare the proposed GWNN with existing spectral methods, Spectral CNN, ChebyNet, GCN and some spatial methods like MoNet. The major contribution of this paper is to improve spectral methods, using graph wavelets rather than eigenvectors of Laplacian as bases. Thus, we focus on the comparison with spectral methods. By the sentence ' GWNN is comfortably ahead of Spectral CNN ', we mean GWNN using graph wavelet transform is ahead of the Spectral CNN using Fourier transform, i.e., GWNN (the last row in Table 3) and Spectral CNN (the ninth row in Table 3). Indeed, GWNN is better than Spectral CNN by 10% improvement on Cora and Citeseer and 5% improvement on Pubmed.\n\nQ7: the discussion about interpretability is interesting, and very trendy. However, what the authors discuss is mere localisation and sparsity - this is one way to 'interpret' interpretability of features, but that discussion should be rephrased in a more mild sense then. \n\nA7: Thank you for the inspiring comments. We revised the discussion about interpretability (Section 4.7), trying to ease the understanding of the interpretability of graph wavelets and graph convolution via graph wavelet transform.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper363/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621604510, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1ewdiR5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper363/Authors|ICLR.cc/2019/Conference/Paper363/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621604510}}}, {"id": "H1gdhOBxAm", "original": null, "number": 10, "cdate": 1542637744399, "ddate": null, "tcdate": 1542637744399, "tmdate": 1542637744399, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "r1gNgBRO3X", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "content": {"title": "Response to Reviewer1 (1/2)", "comment": "Thank you for your positive comments and the accurate summary of our contributions. Prompted by your constructive suggestions, we carefully revised the paper and improved the clarity of the presentation. Next we offer point-by-point response. \n\nQ1: (1) \u00ab Some subsequent works devote to making spectral methods spectrum-free\u2026 avoiding high computational cost \u00bb. I think also those types of representations can be potentially unstable. That\u2019s a second reason.\n\nA1: We revised this sentence in the new version, highlighting that the chief goal of spectrum-free methods is to achieve locality in spatial domain.\n\nQ2: I\u2019m not sure to understand the point (1) of the fourth paragraph of the introduction. (1.)\u00ab graph wavelet does not depend on the eigen decomposition of Laplacian matrix \u00bb. Does it mean numerically ? This sentence is not clear, because even numerically, it can be done in a dependent way to this matrix. However, if it is implied that the fastest algorithm can be obtained without eigen-decomposition of the Laplacian Matrix, in a cheap way, then I agree and a small rephrasing could be nice.\n\nA2: We apologize for not clarifying this point at the outset. To be sure, as you pointed out, graph wavelets are \u201cnumerically\u201d, not intrinsically, independent on eigen-decomposition of Lapacian matrix. For clarity, we replaced the sentence \u201cgraph wavelet does not depend on the eigen-decompostition of Laplacian matrix\u201d with a new sentence \u201cgraph wavelets can be obtained via a fast algorithm without requiring the eigen-decomposition of Laplacian matrix\u201d.\n\nQ3: Please remove all the sentences that are supposed to be an introduction for a section, i.e. the sentences between 2 and 2.1 (\u00ab We use graph\u2026 \u00bb) and 3 and 3.1 (\u00ab In many research\u2026 \u00bb). They are poorly written and do not help the reader.\n\nA3: Thank you for the suggestions. We removed these sentences in the revised version.\n\nQ5: .(2.2) \u201cHowever, such a polynomial approximation also limits the flexibility to define appropriate convolution on graph\u201d I\u2019m not sure to understand. In the paper you refer to, the set of filters span the polynomial of degree less than n, of a diagonalizable matrix of size nxn. Thus, lagrange polynomial basis could be used to interpolate any desired values? Does it signify learning non-diagonal(in the appropriate basis) matrix?\n\nA5: We apologize for the misleading statement. Indeed, a polynomial parameterization with order $n$ is capable to represent any diagonal matrix, i.e., graph convolution kernel in spectral domain. What we mean by \u201cthe inflexibility of such polynomial parameterization\u201d is: a smaller order causes approximation bias and a larger order results in non-localized convolution kernel. In the revised version, we clarified this point in the last paragraph in Section 2.2.\n\nQ6: (2.3) $s$ how is this parameter chosen, crossvalidation? Is it adjusted such that the singular values of $\\psi_s$ have a certain decay? Why is $s$ constant across layers? How is the spectrum of psi_s? Is it well conditionned? A huge difference with (Hammond et al,2011) is that they use a collection of wavelets. Did you consider this kind of approach ? Is there a loss of information in some cases?(like if $\\psi_s$ has a fast decay)\n\nA6: The parameter $s$ is a hyper-parameter in our method, and its value is chosen using cross-validation. We use a constant $s$ across layers in this paper. We agree with you that it is a really interesting idea to use different $s$ across layers, i.e., using wavelets with varying locality across layers. Different form previous methods that use a collection of wavelets, we use the wavelets associated with a constant scaling parameter $s$. We agree that it is promising to use a collection of wavelets and leave it as future work. In our paper, the larger the $s$ is, the faster decay the $\\psi_s$ has, moreover, the range of neighboring node is large, which may result in the loss of localization. Finally, in the revised version, we included detailed discussion in Appendix B to demonstrate the influence of the value of $s$ on the performance of our method.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper363/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621604510, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1ewdiR5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper363/Authors|ICLR.cc/2019/Conference/Paper363/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621604510}}}, {"id": "BkeYvdreR7", "original": null, "number": 9, "cdate": 1542637665468, "ddate": null, "tcdate": 1542637665468, "tmdate": 1542637665468, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "r1gNgBRO3X", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "content": {"title": "Response to Reviewer1 (2/2)", "comment": "Q7: (2.3) \u201cThe matrix $\\psi_s$ and $\\psi_s^{-1}$ are both sparse\u201d. This is a critical affirmation which is not in general true. It is possibly sparse if the weighted laplacian graph is sparse as well, as explained by the remark after theorem 5.5 of page 16 of (Hammond et al, 2011). However, I do agree this typically happens in the application you present. \n\nA7: Thank you for drawing our attention to this point. Indeed, the sparsity of the matrix $\\psi_s$ and $\\psi_s^{-1}$ is related to the sparsity of the Laplacian matrix. Generally, real world networks are sparse with the number of edges much less than the square of the number of nodes. In these cases, the matrix $\\psi_s$ and $\\psi_s^{-1}$ are both sparse. Prompted by your comments, we revised the statement to offer an accurate claim. \n\nQ8: The (c) of Figure 1 is missing.(in my version at least)\n\nA8: We corrected the caption of Figure 1 in the revised version.\n\nQ9: In section 5.3, why not trying to compare the number of parameters with other papers? I think also more results, with maybe a bit higher performances, could be reported, such as: GraphSGAN, GAT. But that\u2019s fine to me.\n\nA9: We agree that it is always better to compare with more methods. Yet, the major contribution is about improving spectral methods by using graph wavelets instead of eigenvectors as a set of bases. Therefore, we focus on the comparison with spectral methods. We particularly appreciate your understanding. \n\nQ10: Appendix A, isn\u2019t it a simple rephrasing of (Hammond et al, 2011)?\n\nA10: Hammond et al. (2011) described the locality of graph wavelets. Instead, in Appendix A, we demonstrate that the graph convolution via graph wavelets is localized, i.e., the nodes used to update target node are its neighboring nodes. We clarified this point in the revised version.\n\nQ11: How do you compare in term of interpretability with [1]?\n\nA11: We agree that the meaning of \u201cinterpretability\u201d is diverse in the literature. In this paper, we use \u201cinterpretability\u201d to offer some intuitive understanding for the wavelet transform, compared with the Fourier transform. In [1], the proposed graph neural network, defining a flexible network via graph block, offers the interpretability as the correlation among nodes in spatial domain.\n\nQ12: Just as a suggestion and/or a comment: it seems similar to approaches such as lifting schemes (which basically builds wavelets on graphs/manifolds), except that there is no learning involved. (e.g. [2]) I think there could be great connexions.\n\nA12: The paper you mentioned presents a simple construction of wavelets that could be adapted to graphs without learning process. We cited this paper as related work in the revised version.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper363/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621604510, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1ewdiR5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper363/Authors|ICLR.cc/2019/Conference/Paper363/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621604510}}}, {"id": "SJl0RLrgC7", "original": null, "number": 6, "cdate": 1542637270309, "ddate": null, "tcdate": 1542637270309, "tmdate": 1542637484277, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "HkgPJe2k6Q", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "content": {"title": "Response to Reviewer4 (2/2)", "comment": "Q2: Experimentally, the improvement over GCN is marginal. Taking into account the implementation difficulty and complexity, the proposed method is more like a proof-of-concept instead of being of practical use. The authors are suggested to make the empirical study more comprehensive, by including node classification in an inductive setting, and/or including link prediction experiments. \n\nA2: In this paper, we focus on spectral methods for graph convolution. The standard spectral method, i.e., the Spectral CNN, is not localized, limiting its performance. To achieve localization, GCN and ChebyNet are proposed to express the graph convolution defined via graph Fourier transform in vertex domain. Here, we propose a new formulation of graph convolution, i.e., defining graph convolution via graph wavelet transform, achieving localization in both spectral and spatial domain. \n\nExperimental results demonstrate that the proposed GWNN method using graph wavelet transform remarkably (achieving 10% improvement on Cora and Citeseer, and 5% improvement on Pubmed [Table 3]) outperforms the Spectral CNN method using graph Fourier transform. Meanwhile, GWNN also outperforms GCN and ChebyNet. \n\nWe fully agree that it is always better to validate a new method on more scenarios and tasks. Here, following the common practice to evaluate spectral methods (e.g., GCN and ChebyNet) for graph CNN, we validate our method on the widely-used playground, i.e., node classification task on three benchmark datasets. \n\nQ3: The hyper-parameters (scale of the heat kernel) and t (threshold to zero the \\phi_s matrix) has to be tuned for each data set. This is not the ideal case because these parameters may not be easy to tune for real data sets, making the method difficult to use. The authors should at least give some recipes on how to tune these parameters.\n\nA3: The hyper-parameter $s$ is used to modulate the range of neighborhood and the smoothness of graph wavelets. The hyper-parameter $t$ is used only for computational consideration. We use cross-validation to determine the value of the hyper-parameter $s$ and $t$, following the common practice of machine learning community. To offer more intuition, we add the analysis about the impact of hyper-parameters on the accuracy of graph-based semi-supervised learning in Appendix B, and demonstrate our recipes to tune hyper-parameters.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper363/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621604510, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1ewdiR5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper363/Authors|ICLR.cc/2019/Conference/Paper363/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621604510}}}, {"id": "B1eMDDBe0X", "original": null, "number": 7, "cdate": 1542637402381, "ddate": null, "tcdate": 1542637402381, "tmdate": 1542637452350, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "HkgPJe2k6Q", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "content": {"title": "Response to Reviewer4 (1/2)", "comment": "Thank you for the positive comments. We are delighted to see that the technical novelty of the proposed method is approved. Inspired by the pertinent comments, we carefully revised the paper, clarifying some misleading statements and highlighting the main contributions. \n\nQ1: By the vanilla implementation without any approximations, the multiplication with \\phi_s and \\phi_s^{-1} has quadratic complexity, and to compute these two matrices is of cubic complexity. This is not acceptable for large graphs. In section 3.2, the authors mentioned that Hammond et al (2011) have an approximation of \\phi_s and \\phi_s^{-1} with the complexity of O(|E|). However, this important technical detail is disappointingly missing in the main text. I have further concerns about whether the good properties listed in section 2.3 are preserved by this approximation, which is not discussed in the paper. \n\nEven with such an approximation, the matrix multiplication still has quadratic complexity. To reduce this complexity needs some non-trivial developments. I suggest the author(s) dive into the expression of \\phi_s and write the convolution in the vertex domain and seek possibilities for a linear approximation.\n\nA1: We apologize for not clarifying these issues at the outset. We appreciate you for pointing out these issues. Prompted by your comments, we carefully revised Sec 2.3 to ease the understanding of the property of graph wavelets. Here, we clarify three main points: \n\n(1) The complexity of the multiplication with \\phi_s and \\phi_s^{-1} is not quadratic. Indeed, the complexity depends on the sparsity of the two matrices \\phi_s and \\phi_s^{-1}. For real world networks, the number of edges is much less than the square of the number of nodes. As a result, as proved in Lemma 5.5 in Hammond et al (2011), both \\phi_s and \\phi_s^{-1} are sparse. Table 4 also shows the empirical results about the sparsity of \\phi_s^{-1}: on the dataset Cora, more than 97% elements in \\phi_s^{-1} are zero.\n\n(2) The computation of the two matrices is completed using a polynomial approximation, Sec. 6 in Hammond et al (2011). Such an approximation is a polynomial function of Laplacian matrix, only involving the matrix-vector multiplication. Since the sparsity of the Laplacian matrix scales up to O(|E|), the computation of \\phi_s and \\phi_s^{-1} is of the complexity O(K*|E|), where |E| is the number of edges and K is the order of polynomial approximation. This point is clarified in Sec. 2.3.\n\n(3) All the properties listed in Section 2.3 are satisfied when \\phi_s and \\phi_s^{-1} are computed in an approximated way: (a) The first property (i.e., high efficiency) is naturally satisfied; (b) The second property (i.e., high sparseness of \\phi_s and \\phi_s^{-1}) is satisfied, since the approximated \\phi_s and \\phi_s^{-1} are always more sparse than the original ones; (c) The third property (i.e., localization property) is satisfied. As shown in Appendix A, the localization property is a result of the sparseness of graph wavelets; (d) The forth property (i.e., flexible neighborhood) is satisfied. Indeed, the flexibility is achieved by adjusting the value of the scaling parameter $s$.\n\nIn addition, we agree it is a really interesting idea to write the convolution in the vertex domain and seek possibilities for a linear approximation. Indeed, we are attempting to use heat kernel to achieve this purpose. Here, we leave it as future work. \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper363/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621604510, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1ewdiR5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper363/Authors|ICLR.cc/2019/Conference/Paper363/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621604510}}}, {"id": "Bkeje8BeRm", "original": null, "number": 5, "cdate": 1542637042666, "ddate": null, "tcdate": 1542637042666, "tmdate": 1542637042666, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "H1ewdiR5tQ", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "content": {"title": "Summary of revisions made to the paper", "comment": "We thank the reviewers and other researchers for their comprehensive and thoughtful comments. According to these comments, we carefully revised our paper, improving both the quality and clarity of our paper. We hope that reviewers will find the revised paper suitable for acceptance.\n\nA summary of the changes made to our paper is listed as follows:\n\n-\tIn Section 2.2, we added a detailed discussion about why ChebyNet has limited flexibility to define convolution kernel. This revision clarifies the confusion about the \u201cthe flexibility of convolution kernel\u201d (Reviewer 1 and Reviewer 3). \n\n-\tIn Section 2.4, we added the architecture of the proposed graph wavelet neural network and the loss function when training graph wavelet neural networks on semi-supervised node classification task.\n\n-\tWe combined Section 3 in the original version into Section 2.5 in the revised version (Reviewer 3).\n\n-\tWe added an experiment (Appendix B) to show the impact of hyper-parameters on the accuracy of node classification, and demonstrate our recipes to tune hyper-parameters (Reviewer 1 and Reviewer 4).\n\n-\tWe rephrased some misleading statements to improve the clarity of the paper.\n\n-\tWe added some references, prompted by the suggestions from reviewers and public comments.\n\nWe submitted a revised version including the aforementioned revisions. Thank you for all the efforts that help us improve the paper."}, "signatures": ["ICLR.cc/2019/Conference/Paper363/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621604510, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1ewdiR5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper363/Authors|ICLR.cc/2019/Conference/Paper363/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621604510}}}, {"id": "HkgPJe2k6Q", "original": null, "number": 3, "cdate": 1541550046736, "ddate": null, "tcdate": 1541550046736, "tmdate": 1541550046736, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "H1ewdiR5tQ", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Review", "content": {"title": "Promising but need further development", "review": "This paper proposed a new formulation of graph convolution, that is based on\ngraph wavelet transform. The convolution network is expressed in eq.(4)\nwith \\psi_s given by eq.(1). This new formulation is exciting in that\nit has numerous advantages comparing to spectral graph convolutions\nsuch as the sparsity of \\psi_s (see the items listed in section 2.3).\nThe method showed marginal improvement (<1%) on node classification\ntasks of citation networks.\n\nOverall, I am convinced with the technical novelty and that the method\ncan be promising. However, in its current form, there are several\nmajor weaknesses, hinting that this work needs further developments before\npublication.\n\n1. By the vanilla implementation without any approximations, the multiplication\nwith \\phi_s and \\phi_s^{-1} has quadratic complexity, and to compute these two\nmatrices is of cubic complexity. \nThis is not acceptable for large graphs. In section 3.2, the authors\nmentioned that Hammond et al (2011) have an approximation of\n\\phi_s and \\phi_s^{-1} with the complexity of O(|E|).\nHowever, this important technical detail is disappointingly missing\nin the main text. I have further concerns about whether the good\nproperties listed in section 2.3 are preserved by this approximation,\nwhich is not discussed in the paper.\n\nEven with such an approximation, the matrix multiplication still\nhas quadratic complexity. To reduce this complexity needs some non-trivial\ndevelopments. I suggest the author(s) dive into the expression of\n\\phi_s and write the convolution in the vertex domain and seek possibilities\nfor a linear approximation.\n\n2. Experimentally, the improvement over GCN is marginal. Taking into account\nthe implementation difficulty and complexity, the\nproposed method is more like a proof-of-concept instead of\nbeing of practical use. The authors are suggested to make the\nempirical study more comprehensive, by including node classification\nin an inductive setting, and/or including link prediction experiments. \n\n3. The hyper-parameters (scale of the heat kernel) and t (threshold\nto zero the \\phi_s matrix) has to be tuned for each data set.\nThis is not the ideal case because these parameters may not be easy\nto tune for real data sets, making the method difficult to use.\nThe authors should at least give some recipes on how to tune these parameters.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper363/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Review", "cdate": 1542234478345, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "H1ewdiR5tQ", "replyto": "H1ewdiR5tQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335707414, "tmdate": 1552335707414, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SkgXWWFx9X", "original": null, "number": 4, "cdate": 1538457850791, "ddate": null, "tcdate": 1538457850791, "tmdate": 1538457850791, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "Sye2KXfec7", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "content": {"title": "Response to baselines and benchmarks", "comment": "Thank you for the comprehensive and pertinent comments. We also appreciate you for listing several recent advances, and we will include these works in related works or as baseline methods. \n\u00a0\nFirst, for the difference between \u201cspectral\u201d and \u201cspatial\u201d methods, we basically agree with you that their distinction is somewhat artificial. To our understanding, the major distinction lies in the way the convolution is defined rather than whether Fourier transform or wavelet transform, i.e., transforming graph signal from vertex domain to spectral domain, is explicitly leveraged. Indeed, many spectral methods are spectrum-free, e.g., Chebyshev networks and GCN. In this paper, we separately describe the two types of methods just to put our graph wavelet neural network in an appropriate literature, i.e., moving in line with spectral methods. \n\u00a0\nWe also fully agree that it is a promising research direction to design anisotropic spectral filters on graphs, following the successful practice on manifolds. \n\u00a0\nSecond, we are glad to see that you have a local spectral CNN approach based on the graph Windowed Fourier Transform. We believe that this is an interesting work, given that Windowed Fourier transform is localized in vertex domain, compared with Fourier transform. This is also why we want to use wavelet transform to replace Fourier transform.\n\nThird, a new benchmark dataset is really an interesting topic and urgent demand for the GNN research community, through our present work is still evaluated on the three traditional benchmark datasets, i.e., Cora, Citeseer and Pubmed. To our understanding, the current benchmark works well to distinguish good methods/models from bad ones, yet they are not sufficient to distinguish better methods/models from good ones. We also look forward to seeing the emergence of new benchmark. The other issue we want to spell out is that a new benchmark dataset is highly dependent on new task or scenario, e.g., the current benchmark is basically designed for graph semi-supervised classification task and the underlying assumption is the graph smoothness, i.e., connected nodes are likely to share the same label. We believe that a new task or a more heterogeneous scenario will be valuable to promote the development of this research community. \n\u00a0\nIn sum, thank you for the comments and inspiring discussion again. "}, "signatures": ["ICLR.cc/2019/Conference/Paper363/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621604510, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1ewdiR5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper363/Authors|ICLR.cc/2019/Conference/Paper363/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621604510}}}, {"id": "Sye2KXfec7", "original": null, "number": 4, "cdate": 1538429827655, "ddate": null, "tcdate": 1538429827655, "tmdate": 1538429827655, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "H1ewdiR5tQ", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Public_Comment", "content": {"comment": "I think this is an interesting work, and I would like to follow up on the previous exchange of comments. \n\nFirst, I would like to note that the distinction between \"spectral\" and \"spatial\" approaches is rather artificial, as at the end methods like Chebyshev networks or the present paper do not do explicit Fourier transform and boil down to applying local spatial operators (e.g. Laplacian and its powers). \n\nHowever, if by \"spectral\" methods one refer to those based on Laplacian-type operators, I would suggest comparing to the following baselines: [1] uses rational functions instead of polynomials (it achieves 81.9% on the standard Cora split). One of the key deficiencies of the Laplacian is that it is locally permutation-invariant (on a plane, this is manifested as rotation symmetry). Thus, any Laplacian-based filters are isotropic. It is possible to create anisotropic spectral filters on manifolds, but general graphs are more complicated. I am only aware of [2] that uses graph motifs (motivated by the work of Benson et al.) to create an analogy of anisotropic diffusion on graphs. This is especially useful for treating directed graphs (as a matter of fact, the original Cora citation graph is directed), which are somewhat problematic to treat with spectral techniques due to the asymmetry of the Laplacian matrix. \n\nAmong \"spatial\" methods, besides GAT you might want to check [3], which alternates convolutions on vertices and edges (using the formalism of line graphs), generalizing the graph attention mechanism proposed in GAT and leading to better performance, though not very significantly (achieving 83.3% on Cora and 72.6% on Pubmed). Also, [4] is an interesting approach based on graph shift operators (in general, the works of Jose Moura on graph signal processing are unjustly not cited in this community). \n\n\nSecond, in the context of shape analysis we developed a local spectral CNN approach based on the graph Windowed Fourier Transform [5], which bears some resemblance to your paper (though never tested it on general graphs).\n\n\nThird, I would add my 50 cents to Marc's comment regarding benchmarks: I also think Cora and Pubmed are \"too easy\". Even worse, they might provide a misleading idea about how different methods perform on \"real data\". From my experience, most of GCNN approaches work well on graphs with underlying assumption of homophilic relations (\"positive connections\"). This in particular true for geometric data sampled from some high-dimensional manifolds. Laplacian-based methods are very appropriate in these settings. It seems that Cora/Pubmed citation networks fall into this category. However, more challenging datasets (such as interactomes in system biology) might have more complicated heterogenous relations between nodes on which algorithms working well on Cora perform poorly. What is also blatantly missing are interesting datasets with rich edge features. It seems to be sufficient critical mass of works on graph deep learning to motivate the creation of more challenging benchmarks.  \n\n\n1. CayleyNets: Graph convolutional neural networks with complex rational spectral filters\", arXiv:1705.07664\n\n2. MotifNet: a motif-based Graph Convolutional Network for directed graphs\", arXiv:1802.01572\n\n3. Dual-Primal Graph Convolutional Networks, arXiv:1806.00770.\n\n4. ON GRAPH CONVOLUTION FOR GRAPH CNNS, DSW 2018\n \n5. Learning class-specific descriptors for deformable shapes using localized spectral convolutional networks\", Computer Graphics Forum 34(5):13-23, 2015\n\n6. Learning shape correspondence with anisotropic convolutional neural networks, NIPS 2016.\n", "title": "baselines and benchmarks"}, "signatures": ["~Michael_Bronstein1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["~Michael_Bronstein1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311857652, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "H1ewdiR5tQ", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311857652}}}, {"id": "rJxXMC2ycm", "original": null, "number": 3, "cdate": 1538407946711, "ddate": null, "tcdate": 1538407946711, "tmdate": 1538407946711, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "HJlW-sd1cX", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "content": {"title": "Our opinions about datasets and methods", "comment": "Thank you for your comment! It\u2019s interesting to have a discussion on the datasets. \n\nUp to now, GNN has got a lot of attention, and many researchers are making contributions to this hotspot. We agree that harder benchmarks could benefit the development of GNN. However, it\u2019s still a long way to give an appropriate definition of the relation between nodes no matter what the benchmarks. Before the emergence of a more convincing dataset, we have to validate the proposed models on these widely adopted ones. And experiments on the three datasets help us to analyze the relative merits of different models to some degree.\n\nIn our opinion, conducting experiments is just a way to validate the merits and effectiveness of a new proposed model. And it's more valuable to have a theoretical exploration in addition to achieving better performance on the datasets. These related works mentioned in the paper provide different ideas and promote the development of GNN. As mentioned in the paper, one of our main contributions is to point out the value of wavelet and localized basis.\n\nI agree that we need to pay attention to harder benchmarks. Our group also focuses on social network analysis. And we are trying to generalize our method to social networks, and validate the effectiveness of different models with related benchmarks. Also, we will pay attention to the datasets and works that you mentioned.\n\nThanks again for your comment!\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper363/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621604510, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1ewdiR5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper363/Authors|ICLR.cc/2019/Conference/Paper363/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621604510}}}, {"id": "ByeP59nkcm", "original": null, "number": 2, "cdate": 1538407054876, "ddate": null, "tcdate": 1538407054876, "tmdate": 1538407054876, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "ryeVsqwy9X", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "content": {"title": "Thanks for your comment", "comment": "Thanks for your comment and approval of our baseline!\nGAT has become a popular work, and there are many variants of GAT. Although our work is a spectral method, we still get inspiration from the attention mechanism. Also, we will pay attention to GraphSGAN. \nThank you very much!"}, "signatures": ["ICLR.cc/2019/Conference/Paper363/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621604510, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1ewdiR5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper363/Authors|ICLR.cc/2019/Conference/Paper363/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621604510}}}, {"id": "HJlW-sd1cX", "original": null, "number": 3, "cdate": 1538390776708, "ddate": null, "tcdate": 1538390776708, "tmdate": 1538390776708, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "ryeVsqwy9X", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Public_Comment", "content": {"comment": "Disclosure: I'm one of the authors on the GGNN/GPNN papers, and I don't want to comment on the merits of the presented approach here, but on problems with graph learning experiments overall.\n\nHaving done some experiments with GNN variants on the Cora/Citeseer/Pubmed, I fear they are not useful indicators of the usefulness of new ideas anymore. The results reported by recent work are all very near to each other, and differences seem to be mostly noise. For example, GPNN reports 79.3% acc on Pubmed and 81.8% on Cora, but only 69.7% on Citeseer. These GPNN results are averaged over a number of runs with different seeds, but the variance is substantial compared to the differences between published models. Concretely, I believe that a few rounds of optimizing the 'SEED' hyperparameter would be most likely sufficient to get any of the models published in the last year to have the best results.\n\nWhat I'm saying here has nothing to do with the merits of any of the papers on graphs submitted to ICLR'19, and I'm not calling for error bars on the results here. Instead, I think we had enough progress that we /all/ need to move on to harder benchmarks, though I'm not sure what these should be. The chemical properties from the Gilmer et al. paper may be a good fit (and the data is easily accessible and reference implementations exist), but they are all very small graphs. Our graph data from the Allamanis et al. ICLR'18 paper has been released and contains larger graphs, but the dataset is painfully large to work with and there's many non-graph things to play with. ", "title": "Value of experiments on CORA/Citeseer/Pubmed datasets"}, "signatures": ["~Marc_Brockschmidt1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["~Marc_Brockschmidt1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311857652, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "H1ewdiR5tQ", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311857652}}}, {"id": "ryeVsqwy9X", "original": null, "number": 2, "cdate": 1538386588221, "ddate": null, "tcdate": 1538386588221, "tmdate": 1538386786800, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "BJlx-8Dk57", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Public_Comment", "content": {"comment": "Disclosure: I'm the author of GATs, and I'm not the original comment poster from above.\n\nBecause the purpose of this paper seems to be to propose a fully-spectral method, I agree that the main comparison should be with spectral methods, or at least methods that depend on observing some aspects of the Laplace matrix (i.e. Chebyshev networks, GCNs and the original formulation of MoNet).\n\nTo the best of my knowledge, the state-of-the-art (at least on Citeseer, which seems to be the most flexible dataset to improve on out of the three) is currently held by GraphSGAN (Ding et al., CIKM 2018), and it might be useful to report this result instead (but this would only be for contextual purposes, in my opinion).", "title": "Supervised state-of-the-art"}, "signatures": ["~Petar_Veli\u010dkovi\u01071"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["~Petar_Veli\u010dkovi\u01071", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311857652, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "H1ewdiR5tQ", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311857652}}}, {"id": "BJlx-8Dk57", "original": null, "number": 1, "cdate": 1538385400156, "ddate": null, "tcdate": 1538385400156, "tmdate": 1538385400156, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "BylQV6LAFX", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "content": {"title": "Thank you for your feedback", "comment": "Thank you for your comment! I would like to explain it from two perspectives:\nMotivation: Due to the inspiration of Spectral CNN (Bruna et.al., 2014), many works attempt to implement convolutional neural networks on graphs. However, as far as I know, there are few spectral methods leveraging the convolution theorem to design convolution operator after GCN (Kipf&Welling, 2016). It's true that GAT is more flexible than spectral methods, it applies attention mechanism to calculate relations between nodes. However, the shared parameters in GAT are linear transformation matrix W when calculating attention instead of convolution kernels (filters). We hope to propose a better spectral method based on the convolutional theorem. GWNN is our first attempt which holds the flexibility of kernel and locality in vertex domain. \nResults: We think we achieve comparable results on two datasets. The accuracy of GAT on Cora is 83.0%, and that of our work is 82.8%. On Pubmed, GAT scores 79.0% while our work scores 79.1%. It's true that GAT performs better than ours on Citeseer. We think it could be caused by the fact that the network of Citeseer is sparser than the other two datasets, which has 3327 nodes and 4732 edges. And due to the way of GAT which calculates the relations between nodes based on representation in hidden layer, adjacency matrix is only regarded as a mask. Instead, we leverage the wavelet which depends on the structure of network. Thus, our model doesn't achieve a better results on Citeseer.\nThanks again for your comment! We will include GAT as our baseline and give a discussion in a revised version of our paper.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper363/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621604510, "tddate": null, "super": null, "final": null, "reply": {"forum": "H1ewdiR5tQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper363/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper363/Authors|ICLR.cc/2019/Conference/Paper363/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621604510}}}, {"id": "BylQV6LAFX", "original": null, "number": 1, "cdate": 1538317610816, "ddate": null, "tcdate": 1538317610816, "tmdate": 1538317701875, "tddate": null, "forum": "H1ewdiR5tQ", "replyto": "H1ewdiR5tQ", "invitation": "ICLR.cc/2019/Conference/-/Paper363/Public_Comment", "content": {"comment": "You should include the experimental results of GAT which are better than yours and then explain why your results are lower.", "title": "Not report the results of graph attention network (GAT)"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper363/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Wavelet Neural Network", "abstract": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcomings of previous spectral graph CNN methods that depend on graph Fourier transform. Different from graph Fourier transform, graph wavelet transform can be obtained via a fast algorithm without requiring matrix eigendecomposition with high computational cost. Moreover, graph wavelets are sparse and localized in vertex domain, offering high efficiency and good interpretability for graph convolution. The proposed GWNN significantly outperforms previous spectral graph CNNs in the task of graph-based semi-supervised classification on three benchmark datasets: Cora, Citeseer and Pubmed.", "keywords": ["graph convolution", "graph wavelet transform", "graph Fourier transform", "semi-supervised learning"], "authorids": ["xubingbing@ict.ac.cn", "shenhuawei@ict.ac.cn", "caoqi@ict.ac.cn", "qiuyunqi@ict.ac.cn", "cxq@ict.ac.cn"], "authors": ["Bingbing Xu", "Huawei Shen", "Qi Cao", "Yunqi Qiu", "Xueqi Cheng"], "TL;DR": "We present graph wavelet neural network (GWNN), a novel graph convolutional neural network (CNN), leveraging graph wavelet transform to address the shortcoming of previous spectral graph CNN methods that depend on graph Fourier transform.", "pdf": "/pdf/3298c2f91e55e505a6cb5cc98588ba2b5a76ad5a.pdf", "paperhash": "xu|graph_wavelet_neural_network", "_bibtex": "@inproceedings{\nxu2018graph,\ntitle={Graph Wavelet Neural Network},\nauthor={Bingbing Xu and Huawei Shen and Qi Cao and Yunqi Qiu and Xueqi Cheng},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=H1ewdiR5tQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper363/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311857652, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "H1ewdiR5tQ", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper363/Authors", "ICLR.cc/2019/Conference/Paper363/Reviewers", "ICLR.cc/2019/Conference/Paper363/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311857652}}}], "count": 34}