{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124294320, "tcdate": 1517344363823, "number": 10, "cdate": 1517344363823, "id": "Sk4_LURHf", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "Sk4_LURHf", "signatures": ["~Yingzhen_Yang1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "3D-FilterMap: A Compact Architecture for Deep Convolutional Neural Networks", "abstract": "We present a novel and compact architecture for deep Convolutional Neural Networks (CNNs) in this paper, termed $3$D-FilterMap Convolutional Neural Networks ($3$D-FM-CNNs). The convolution layer of $3$D-FM-CNN learns a compact representation of the filters, named $3$D-FilterMap, instead of a set of independent filters in the conventional convolution layer. The filters are extracted from the $3$D-FilterMap as overlapping $3$D submatrics with weight sharing among nearby filters, and these filters are convolved with the input to generate the output of the convolution layer for $3$D-FM-CNN. Due to the weight sharing scheme, the parameter size of the $3$D-FilterMap is much smaller than that of the filters to be learned in the conventional convolution layer when $3$D-FilterMap generates the same number of filters. Our work is fundamentally different from the network compression literature that reduces the size of a learned large network in the sense that a small network is directly learned from scratch. Experimental results demonstrate that $3$D-FM-CNN enjoys a small parameter space by learning compact $3$D-FilterMaps, while achieving performance compared to that of the baseline CNNs which learn the same number of filters as that generated by the corresponding $3$D-FilterMap.", "paperhash": "yang|3dfiltermap_a_compact_architecture_for_deep_convolutional_neural_networks", "keywords": ["Compact Architecture", "3D-FilterMap", "Weight Sharing", "Convolutional Neural Networks"], "_bibtex": "@misc{\n  yang20183d-filtermap:,\n  title={3D-FilterMap: A Compact Architecture for Deep Convolutional Neural Networks},\n  author={Yingzhen Yang and Jianchao Yang and Ning Xu and Wei Han and Nebojsa Jojic and Thomas S. Huang},\n  year={2018},\n  url={https://openreview.net/forum?id=Sk4_LURHf}\n}", "authorids": ["superyyzg@gmail.com", "jianchao.yang@snap.com", "ning.xu@snap.com", "weihan3@illinois.edu", "jojic@microsoft.com", "t-huang1@illinois.edu"], "authors": ["Yingzhen Yang", "Jianchao Yang", "Ning Xu", "Wei Han", "Nebojsa Jojic", "Thomas S. Huang"], "TL;DR": "We present a novel and compact architecture for deep Convolutional Neural Networks in this paper, termed $3$D-FilterMap Convolutional Neural Networks ($3$D-FM-CNNs).", "pdf": "/pdf/bcd73db8263673e3fa0ebfc356a5f129bd57c225.pdf"}, "nonreaders": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582914181, "tcdate": 1520432467006, "number": 1, "cdate": 1520432467006, "id": "B1i8HdpOf", "invitation": "ICLR.cc/2018/Workshop/-/Paper10/Official_Review", "forum": "Sk4_LURHf", "replyto": "Sk4_LURHf", "signatures": ["ICLR.cc/2018/Workshop/Paper10/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper10/AnonReviewer3"], "content": {"title": "Review", "rating": "6: Marginally above acceptance threshold", "review": "This paper proposes a filter sharing methods for a convolutional layer in neural networks. Instead of learning several independent filters, the proposed method uses a larger 3D tensor as the parameter of the convolutional layer. Sliding window scheme is used along the 3 dimensions to crop sub-tensors, and each tensor is taken as a convolutional filter. \n\nPros:\n\nThe idea of geometric filter sharing is interesting. It provides a simple way to reduce the number of parameters without changing the network architecture and training strategy. \n\nThe experimental results show that the proposed method can reduce the number of parameters significantly with a minor performance loss. \n\nCons:\n\nThe number of output channels for a convolutional layer is not arbitrary in the proposed methods. It must be the multiplication of the numbers of cells in all 3 axes.\n\nThe proposed method cannot reduce the computational complexity. Given the existence way to shrink both the number of parameters and computation cost, it is not very clear how significant the proposed method is in practice,\n\nThe paper made interesting observations, but it will be great to have more insights on why sharing the filters in the proposed way is reasonable. \n\nPresentations:\n1. The abstract is not easy to follow. Several undefined terminologies pop up, and the main idea of the paper is not clearly highlighted. \n2. It seems more common to say 3D tensor rather than 3D matrices. \n\nOverall, the paper is interesting, and it has the potential to be extended to a long paper. ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "3D-FilterMap: A Compact Architecture for Deep Convolutional Neural Networks", "abstract": "We present a novel and compact architecture for deep Convolutional Neural Networks (CNNs) in this paper, termed $3$D-FilterMap Convolutional Neural Networks ($3$D-FM-CNNs). The convolution layer of $3$D-FM-CNN learns a compact representation of the filters, named $3$D-FilterMap, instead of a set of independent filters in the conventional convolution layer. The filters are extracted from the $3$D-FilterMap as overlapping $3$D submatrics with weight sharing among nearby filters, and these filters are convolved with the input to generate the output of the convolution layer for $3$D-FM-CNN. Due to the weight sharing scheme, the parameter size of the $3$D-FilterMap is much smaller than that of the filters to be learned in the conventional convolution layer when $3$D-FilterMap generates the same number of filters. Our work is fundamentally different from the network compression literature that reduces the size of a learned large network in the sense that a small network is directly learned from scratch. Experimental results demonstrate that $3$D-FM-CNN enjoys a small parameter space by learning compact $3$D-FilterMaps, while achieving performance compared to that of the baseline CNNs which learn the same number of filters as that generated by the corresponding $3$D-FilterMap.", "paperhash": "yang|3dfiltermap_a_compact_architecture_for_deep_convolutional_neural_networks", "keywords": ["Compact Architecture", "3D-FilterMap", "Weight Sharing", "Convolutional Neural Networks"], "_bibtex": "@misc{\n  yang20183d-filtermap:,\n  title={3D-FilterMap: A Compact Architecture for Deep Convolutional Neural Networks},\n  author={Yingzhen Yang and Jianchao Yang and Ning Xu and Wei Han and Nebojsa Jojic and Thomas S. Huang},\n  year={2018},\n  url={https://openreview.net/forum?id=Sk4_LURHf}\n}", "authorids": ["superyyzg@gmail.com", "jianchao.yang@snap.com", "ning.xu@snap.com", "weihan3@illinois.edu", "jojic@microsoft.com", "t-huang1@illinois.edu"], "authors": ["Yingzhen Yang", "Jianchao Yang", "Ning Xu", "Wei Han", "Nebojsa Jojic", "Thomas S. Huang"], "TL;DR": "We present a novel and compact architecture for deep Convolutional Neural Networks in this paper, termed $3$D-FilterMap Convolutional Neural Networks ($3$D-FM-CNNs).", "pdf": "/pdf/bcd73db8263673e3fa0ebfc356a5f129bd57c225.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582913957, "id": "ICLR.cc/2018/Workshop/-/Paper10/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper10/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper10/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper10/AnonReviewer2"], "reply": {"forum": "Sk4_LURHf", "replyto": "Sk4_LURHf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper10/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper10/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582913957}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582815276, "tcdate": 1520615878427, "number": 2, "cdate": 1520615878427, "id": "BJCp-HeYf", "invitation": "ICLR.cc/2018/Workshop/-/Paper10/Official_Review", "forum": "Sk4_LURHf", "replyto": "Sk4_LURHf", "signatures": ["ICLR.cc/2018/Workshop/Paper10/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper10/AnonReviewer2"], "content": {"title": "Good paper, novel approach", "rating": "7: Good paper, accept", "review": "This paper presents the approach of 3D-FilterMap, an alternative architecture to standard CNNs where the weights of the learned filters are shared locally instead of being independent. Experiments on CIFAR-10 are presented and results show that the proposed approach yields comparable performance with standard architectures with less parameters. \n\nPros:\n- The main idea of the paper is very interesting. Learning compact shared filters in the CNN instead of independent ones is a novel and substantial contribution, which could have an impact on the current efforts to reduce neural network size. \n- The experiments are convincing, the results are promising and validate the approach.\n\nCons:\n- The paper is sometimes not easy to follow, with some clarity and formatting issues.\n\nMinor comments:\n- The second paragraph of Section 2 uses the word \"3D-FF-CNN\" seven times in a five sentences paragraph, the authors should improve the writing. \n- The equations embedded in the text in Section 2 make it difficult to follow. \n- The dataset used in Section 3 should be more clearly written (maybe in a small paragraph). \n\nOverall, this paper presents a novel and promising approach for learning compact CNNs, I recommend acceptance.\n\nI am looking forward to a full version of this work, with experiments on larger dataset and specially an analysis on the filters: it should be interesting to compared the learned filters between the proposed approach and the standard CNNs.  \n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "3D-FilterMap: A Compact Architecture for Deep Convolutional Neural Networks", "abstract": "We present a novel and compact architecture for deep Convolutional Neural Networks (CNNs) in this paper, termed $3$D-FilterMap Convolutional Neural Networks ($3$D-FM-CNNs). The convolution layer of $3$D-FM-CNN learns a compact representation of the filters, named $3$D-FilterMap, instead of a set of independent filters in the conventional convolution layer. The filters are extracted from the $3$D-FilterMap as overlapping $3$D submatrics with weight sharing among nearby filters, and these filters are convolved with the input to generate the output of the convolution layer for $3$D-FM-CNN. Due to the weight sharing scheme, the parameter size of the $3$D-FilterMap is much smaller than that of the filters to be learned in the conventional convolution layer when $3$D-FilterMap generates the same number of filters. Our work is fundamentally different from the network compression literature that reduces the size of a learned large network in the sense that a small network is directly learned from scratch. Experimental results demonstrate that $3$D-FM-CNN enjoys a small parameter space by learning compact $3$D-FilterMaps, while achieving performance compared to that of the baseline CNNs which learn the same number of filters as that generated by the corresponding $3$D-FilterMap.", "paperhash": "yang|3dfiltermap_a_compact_architecture_for_deep_convolutional_neural_networks", "keywords": ["Compact Architecture", "3D-FilterMap", "Weight Sharing", "Convolutional Neural Networks"], "_bibtex": "@misc{\n  yang20183d-filtermap:,\n  title={3D-FilterMap: A Compact Architecture for Deep Convolutional Neural Networks},\n  author={Yingzhen Yang and Jianchao Yang and Ning Xu and Wei Han and Nebojsa Jojic and Thomas S. Huang},\n  year={2018},\n  url={https://openreview.net/forum?id=Sk4_LURHf}\n}", "authorids": ["superyyzg@gmail.com", "jianchao.yang@snap.com", "ning.xu@snap.com", "weihan3@illinois.edu", "jojic@microsoft.com", "t-huang1@illinois.edu"], "authors": ["Yingzhen Yang", "Jianchao Yang", "Ning Xu", "Wei Han", "Nebojsa Jojic", "Thomas S. Huang"], "TL;DR": "We present a novel and compact architecture for deep Convolutional Neural Networks in this paper, termed $3$D-FilterMap Convolutional Neural Networks ($3$D-FM-CNNs).", "pdf": "/pdf/bcd73db8263673e3fa0ebfc356a5f129bd57c225.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582913957, "id": "ICLR.cc/2018/Workshop/-/Paper10/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper10/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper10/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper10/AnonReviewer2"], "reply": {"forum": "Sk4_LURHf", "replyto": "Sk4_LURHf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper10/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper10/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582913957}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573560260, "tcdate": 1521573560260, "number": 76, "cdate": 1521573559929, "id": "H1gpCCRFG", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "Sk4_LURHf", "replyto": "Sk4_LURHf", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "3D-FilterMap: A Compact Architecture for Deep Convolutional Neural Networks", "abstract": "We present a novel and compact architecture for deep Convolutional Neural Networks (CNNs) in this paper, termed $3$D-FilterMap Convolutional Neural Networks ($3$D-FM-CNNs). The convolution layer of $3$D-FM-CNN learns a compact representation of the filters, named $3$D-FilterMap, instead of a set of independent filters in the conventional convolution layer. The filters are extracted from the $3$D-FilterMap as overlapping $3$D submatrics with weight sharing among nearby filters, and these filters are convolved with the input to generate the output of the convolution layer for $3$D-FM-CNN. Due to the weight sharing scheme, the parameter size of the $3$D-FilterMap is much smaller than that of the filters to be learned in the conventional convolution layer when $3$D-FilterMap generates the same number of filters. Our work is fundamentally different from the network compression literature that reduces the size of a learned large network in the sense that a small network is directly learned from scratch. Experimental results demonstrate that $3$D-FM-CNN enjoys a small parameter space by learning compact $3$D-FilterMaps, while achieving performance compared to that of the baseline CNNs which learn the same number of filters as that generated by the corresponding $3$D-FilterMap.", "paperhash": "yang|3dfiltermap_a_compact_architecture_for_deep_convolutional_neural_networks", "keywords": ["Compact Architecture", "3D-FilterMap", "Weight Sharing", "Convolutional Neural Networks"], "_bibtex": "@misc{\n  yang20183d-filtermap:,\n  title={3D-FilterMap: A Compact Architecture for Deep Convolutional Neural Networks},\n  author={Yingzhen Yang and Jianchao Yang and Ning Xu and Wei Han and Nebojsa Jojic and Thomas S. Huang},\n  year={2018},\n  url={https://openreview.net/forum?id=Sk4_LURHf}\n}", "authorids": ["superyyzg@gmail.com", "jianchao.yang@snap.com", "ning.xu@snap.com", "weihan3@illinois.edu", "jojic@microsoft.com", "t-huang1@illinois.edu"], "authors": ["Yingzhen Yang", "Jianchao Yang", "Ning Xu", "Wei Han", "Nebojsa Jojic", "Thomas S. Huang"], "TL;DR": "We present a novel and compact architecture for deep Convolutional Neural Networks in this paper, termed $3$D-FilterMap Convolutional Neural Networks ($3$D-FM-CNNs).", "pdf": "/pdf/bcd73db8263673e3fa0ebfc356a5f129bd57c225.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 4}