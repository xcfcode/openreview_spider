{"notes": [{"id": "H1emfT4twB", "original": "S1g4hb5UDS", "number": 407, "cdate": 1569438987304, "ddate": null, "tcdate": 1569438987304, "tmdate": 1583912030646, "tddate": null, "forum": "H1emfT4twB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"abstract": "In this paper, we explore meta-learning for few-shot text classification. Meta-learning has shown strong performance in computer vision, where low-level patterns are transferable across learning tasks. However, directly applying this approach to text is challenging--lexical features highly informative for one task may be insignificant for another. Thus, rather than learning solely from words, our model also leverages their distributional signatures, which encode pertinent word occurrence patterns. Our model is trained within a meta-learning framework to map these signatures into attention scores, which are then used to weight the lexical representations of words. We demonstrate that our model consistently outperforms prototypical networks learned on lexical knowledge (Snell et al., 2017) in both few-shot text classification and relation classification by a significant margin across six benchmark datasets (20.0% on average in 1-shot classification).", "title": "Few-shot Text Classification with Distributional Signatures", "code": "https://github.com/YujiaBao/Distributional-Signatures", "keywords": ["text classification", "meta learning", "few shot learning"], "authors": ["Yujia Bao", "Menghua Wu", "Shiyu Chang", "Regina Barzilay"], "TL;DR": "Meta-learning methods used for vision, directly applied to NLP, perform worse than nearest neighbors on new classes; we can do better with distributional signatures.", "authorids": ["yujia@csail.mit.edu", "rmwu@mit.edu", "shiyu.chang@ibm.com", "regina@csail.mit.edu"], "pdf": "/pdf/4fa31bfd21e94185de50157b87f30279d335676f.pdf", "paperhash": "bao|fewshot_text_classification_with_distributional_signatures", "_bibtex": "@inproceedings{\nBao2020Few-shot,\ntitle={Few-shot Text Classification with Distributional Signatures},\nauthor={Yujia Bao and Menghua Wu and Shiyu Chang and Regina Barzilay},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1emfT4twB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/a90b4b7b3d3a5baa79570d60c725c959d431870d.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "PqqcEiCKne", "original": null, "number": 1, "cdate": 1576798695546, "ddate": null, "tcdate": 1576798695546, "tmdate": 1576800940045, "tddate": null, "forum": "H1emfT4twB", "replyto": "H1emfT4twB", "invitation": "ICLR.cc/2020/Conference/Paper407/-/Decision", "content": {"decision": "Accept (Poster)", "comment": "This paper proposes a meta-learning approach for few-shot text classification. The main idea is to use an attention mechanism over the distributional signatures of the inputs to weight word importance. Experiments on text classification datasets show that the proposed method improves over baselines in 1-shot and 5-shot settings.\n\nThe paper addresses an important problem of learning from a few labeled examples. The proposed approach makes sense and the results clearly show the strength of the proposed approach.\n\nR1 had some questions regarding the proposed method and experimental details. I believe this have been addressed by the authors in their rebuttal.\n\nR2 suggested that the authors clarified their experimental setup with respect to prior work and improved the clarity of their paper. The authors have made some adjustments based on this feedback, including adding new sections in the appendix.\n\nR3 had concerns regarding the contribution of the approach and whether it trades variance for bias. The authors have addressed most of these concerns and R3 has updated their review accordingly.\n\nI think all the reviewers gave valuable feedbacks that have been incorporated by the authors to improve their paper. While the overall scores remain low, I believe that they would have been increased had R1 and R2 reassessed the revised submission. I recommend to accept this paper.\n", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "In this paper, we explore meta-learning for few-shot text classification. Meta-learning has shown strong performance in computer vision, where low-level patterns are transferable across learning tasks. However, directly applying this approach to text is challenging--lexical features highly informative for one task may be insignificant for another. Thus, rather than learning solely from words, our model also leverages their distributional signatures, which encode pertinent word occurrence patterns. Our model is trained within a meta-learning framework to map these signatures into attention scores, which are then used to weight the lexical representations of words. We demonstrate that our model consistently outperforms prototypical networks learned on lexical knowledge (Snell et al., 2017) in both few-shot text classification and relation classification by a significant margin across six benchmark datasets (20.0% on average in 1-shot classification).", "title": "Few-shot Text Classification with Distributional Signatures", "code": "https://github.com/YujiaBao/Distributional-Signatures", "keywords": ["text classification", "meta learning", "few shot learning"], "authors": ["Yujia Bao", "Menghua Wu", "Shiyu Chang", "Regina Barzilay"], "TL;DR": "Meta-learning methods used for vision, directly applied to NLP, perform worse than nearest neighbors on new classes; we can do better with distributional signatures.", "authorids": ["yujia@csail.mit.edu", "rmwu@mit.edu", "shiyu.chang@ibm.com", "regina@csail.mit.edu"], "pdf": "/pdf/4fa31bfd21e94185de50157b87f30279d335676f.pdf", "paperhash": "bao|fewshot_text_classification_with_distributional_signatures", "_bibtex": "@inproceedings{\nBao2020Few-shot,\ntitle={Few-shot Text Classification with Distributional Signatures},\nauthor={Yujia Bao and Menghua Wu and Shiyu Chang and Regina Barzilay},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1emfT4twB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/a90b4b7b3d3a5baa79570d60c725c959d431870d.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "H1emfT4twB", "replyto": "H1emfT4twB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795722980, "tmdate": 1576800274384, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper407/-/Decision"}}}, {"id": "rklewo2-9r", "original": null, "number": 3, "cdate": 1572092759564, "ddate": null, "tcdate": 1572092759564, "tmdate": 1575449304060, "tddate": null, "forum": "H1emfT4twB", "replyto": "H1emfT4twB", "invitation": "ICLR.cc/2020/Conference/Paper407/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #3", "review": "UPDATE: Based on the extensive improvements by the authors, I have updated my rating. However, I still have doubts about the potential of this approach to reach practically useful levels of accuracy.\n\nThis paper introduces a simple method to weight pretrained lexical features for use in meta learning of few-shot text classification. The method boils down to weighting word inut features, in the form of pretrained word-embeddings, by attention computed from inverse document frequency and class local mutual information. The idea is that this measure of feature informativeness transfers between tasks, whereas lexical features themselves are highly task-specific. The approach is well motivated and is empirically shown to outperform existing approaches to few-shot text classification with a significant margin.\n\nWhile the improvement over existing approaches is quite substantial, I believe the paper should not be accepted to ICLR for the following reasons. First, the contribution is quite limited and not particularly novel. While two weight functions are proposed, the majority of improvement comes simply from normalizing IDF with attention. Based on existing work on delexicalized features for NLP tasks such as parsing, this is quite a straightforward extension. Given the limited contribution, a short paper seems a better fit. Second, the approach simply trades variance for bias. This brings us to the question of how likely the approach is to be a building block in bringing us towards a pratically useful few-shot classification method. Given the weak representational power of the model, I believe this is unlikely. I see a situation similar to syntactic parsing for low-resource languages, where a collection of simple techniques similar in spirit to the current approach, like delexicalization, brought results far above the naive baselines, but never approached practically useful results. I think this is a crucial point to address in meta-learning research in general to make sure we\u2019re not just solving a toy problem with tailored heuristics.\n\nAdditional notes:\n\nWhat is the motivation for using a BiLSTM to combine inverse document frequency and inverse class entropy? Is the sequence information at all useful, or would a simple projection and nonlinearity give the same result?\n\nThe theoretical analysis is completely self-evident from the definition of the feature space. Replaing a feature with an equivalent feature of course gives the same result and I don\u2019t see the need to \u201cmathematize\u201d this.\n\nThe effect of approximating logistic regression with linear regression + calibration is not analyzed and it is not clear what the effect of this approximation is in the text classification scenario. I would suggest to compare to differentiating through a direct optimization of the logistic formulation, for example with Newton\u2019s method, or plain SGD, as in Bertinetto et al. (2019).\n\nTable 1. Why not run the attention-based feature aggregator together with all algorithms. The main contribution is at the input representation level, and this should be applicable across algorithms. In fact, if we remove the BiLSTM which seems to have a very small effect the representation function does not contain learnable parameters in itself.\n\nPlease provide the average across datasets in Table 1.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper407/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper407/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "In this paper, we explore meta-learning for few-shot text classification. Meta-learning has shown strong performance in computer vision, where low-level patterns are transferable across learning tasks. However, directly applying this approach to text is challenging--lexical features highly informative for one task may be insignificant for another. Thus, rather than learning solely from words, our model also leverages their distributional signatures, which encode pertinent word occurrence patterns. Our model is trained within a meta-learning framework to map these signatures into attention scores, which are then used to weight the lexical representations of words. We demonstrate that our model consistently outperforms prototypical networks learned on lexical knowledge (Snell et al., 2017) in both few-shot text classification and relation classification by a significant margin across six benchmark datasets (20.0% on average in 1-shot classification).", "title": "Few-shot Text Classification with Distributional Signatures", "code": "https://github.com/YujiaBao/Distributional-Signatures", "keywords": ["text classification", "meta learning", "few shot learning"], "authors": ["Yujia Bao", "Menghua Wu", "Shiyu Chang", "Regina Barzilay"], "TL;DR": "Meta-learning methods used for vision, directly applied to NLP, perform worse than nearest neighbors on new classes; we can do better with distributional signatures.", "authorids": ["yujia@csail.mit.edu", "rmwu@mit.edu", "shiyu.chang@ibm.com", "regina@csail.mit.edu"], "pdf": "/pdf/4fa31bfd21e94185de50157b87f30279d335676f.pdf", "paperhash": "bao|fewshot_text_classification_with_distributional_signatures", "_bibtex": "@inproceedings{\nBao2020Few-shot,\ntitle={Few-shot Text Classification with Distributional Signatures},\nauthor={Yujia Bao and Menghua Wu and Shiyu Chang and Regina Barzilay},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1emfT4twB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/a90b4b7b3d3a5baa79570d60c725c959d431870d.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "H1emfT4twB", "replyto": "H1emfT4twB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper407/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper407/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575541355727, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper407/Reviewers"], "noninvitees": [], "tcdate": 1570237752598, "tmdate": 1575541355741, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper407/-/Official_Review"}}}, {"id": "Bklwa634sB", "original": null, "number": 5, "cdate": 1573338558676, "ddate": null, "tcdate": 1573338558676, "tmdate": 1573338558676, "tddate": null, "forum": "H1emfT4twB", "replyto": "BkglFISTYS", "invitation": "ICLR.cc/2020/Conference/Paper407/-/Official_Comment", "content": {"title": "Intuition of distributional signatures and additional experiments", "comment": "Thank you for the detailed comments and suggestions!\n\nThe main idea of the paper is that if we want to learn transferable knowledge, methods that memorize word identities will fail when the word distribution shifts. By learning meta-knowledge on top of n-gram statistics, class-specific words will still be important (and common stop words unimportant), even if the actual words themselves change. (More specific example regarding our two statistics below.)\n\nAdditional Experiments: Based on the suggestions, we have compared our work to P-MAML and Induction Network Routing. Detailed results are located in Appendix A.5.\n \nOn average, our method outperforms P-MAML by 18.5% on 1-shot and 19.3% on 5-shot, and Induction Networks by 21.1% on 1-shot and 32.4% on 5-shot (Table 4). While both P-MAML and Induction Networks are able to overfit the meta-train data easily, they are unable to generalize when faced with lexical mismatch (Figure 9).\n\nFurthermore, we show that we can improve Induction Networks by replacing its lexically-aware encoder with our attention-weighted representation learned from distributional signatures  (Appendix A.9). On average, distributional signatures increase Induction Networks accuracy by 14.3% on 1-shot and 25.1% on 5-shot.\n\nRobustTC-FSL is not directly applicable to our setting since it considers a fixed set of tasks during meta-training (e.g. binary sentiment classification across 23 Amazon domains) and utilizes their cross-task transferability.\n\nQuestions:\n* s(.) and IDF both indicate general word importance. We experimented with both during our development stage and found that they perform similarly when used in our attention generator (idf 77.8 vs s(.) 78.0 for 5 shot classifications averaged across 6 datasets). We choose the current formulation as it is more interpretable in context of robustness against word-substitution perturbation.\n\n1) We apply an MLP on top of the [s(); t()] at each position, where ; denotes concatenation. After that we applied softmax over the output of the MLP. This MLP has 2 inputs, 50 hidden units (ReLU activation) and 1 output.\n\n2) One indicates word importance for general classification (estimated from source pool) and the other indicates how important the feature is for this particular task (a rough estimate).\n\nFor example, suppose we have lots of data from political and sports news, and we want to expand into arts news. General word importance (learned from politics and sports) can tell us that words like \u201cthe\u201d and \u201cwe\u201d are not useful, so we learn to ignore them. However, politics and sports news also have no use for arts-specific words, like \u201cpainting\u201d or \u201cperformance.\u201d Thus, we require task-specific word importance (learned from few arts examples) to refine our understanding of useful words.\n\n3) The general idea of \u201cdistributional signatures\u201d is not new. Prior to the age of deep learning, linear SVM + TF-IDF was considered a strong baseline to beat, and more recently, Arora 2016 showed that SIF-weighted representations (statistics used for s(.) in our model) do outperform LSTMs/CNNs on some (standard) tasks. In our setting, we noted that the idea may also be helpful for few-shot classification, as these statistics are more transferable across tasks. For general classification tasks with lots of annotation, the representation power of distribution signatures may be limited (though this is slightly beyond the scope of our paper).\n\n* BERT is contextual, so the embedding of one word represents not only itself, but also its surroundings. Correspondingly, if a CNN downweights an important word from an unseen class, its adjacent words still contain information about that word. This means that it is less \u201ccostly\u201d to ignore important words from unseen classes, as a result of overfitting on seen classes. For OUR, this means that we don\u2019t have to be as precise about picking out each important word.\n\n* Since the vocabulary of meta-train classes and meta-test classes may be very different, we freeze the pre-trained embeddings (Fasttext or BERT) during meta training. This is to avoid disrupting the inherent geometry of word embeddings, as finetuning will cause these embeddings to lose the relationship between meta-train vocabulary (seen during finetuning) and meta-test vocabulary (not seen, and thus not optimized for). Empirically, we show that freezing word embeddings outperforms finetuning (Table 6).\n\nWe hope we have adequately addressed your concerns. Please let us know if you have any more questions. Thank you!\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper407/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper407/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "In this paper, we explore meta-learning for few-shot text classification. Meta-learning has shown strong performance in computer vision, where low-level patterns are transferable across learning tasks. However, directly applying this approach to text is challenging--lexical features highly informative for one task may be insignificant for another. Thus, rather than learning solely from words, our model also leverages their distributional signatures, which encode pertinent word occurrence patterns. Our model is trained within a meta-learning framework to map these signatures into attention scores, which are then used to weight the lexical representations of words. We demonstrate that our model consistently outperforms prototypical networks learned on lexical knowledge (Snell et al., 2017) in both few-shot text classification and relation classification by a significant margin across six benchmark datasets (20.0% on average in 1-shot classification).", "title": "Few-shot Text Classification with Distributional Signatures", "code": "https://github.com/YujiaBao/Distributional-Signatures", "keywords": ["text classification", "meta learning", "few shot learning"], "authors": ["Yujia Bao", "Menghua Wu", "Shiyu Chang", "Regina Barzilay"], "TL;DR": "Meta-learning methods used for vision, directly applied to NLP, perform worse than nearest neighbors on new classes; we can do better with distributional signatures.", "authorids": ["yujia@csail.mit.edu", "rmwu@mit.edu", "shiyu.chang@ibm.com", "regina@csail.mit.edu"], "pdf": "/pdf/4fa31bfd21e94185de50157b87f30279d335676f.pdf", "paperhash": "bao|fewshot_text_classification_with_distributional_signatures", "_bibtex": "@inproceedings{\nBao2020Few-shot,\ntitle={Few-shot Text Classification with Distributional Signatures},\nauthor={Yujia Bao and Menghua Wu and Shiyu Chang and Regina Barzilay},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1emfT4twB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/a90b4b7b3d3a5baa79570d60c725c959d431870d.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1emfT4twB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper407/Authors", "ICLR.cc/2020/Conference/Paper407/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper407/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper407/Reviewers", "ICLR.cc/2020/Conference/Paper407/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper407/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper407/Authors|ICLR.cc/2020/Conference/Paper407/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504171923, "tmdate": 1576860540580, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper407/Authors", "ICLR.cc/2020/Conference/Paper407/Reviewers", "ICLR.cc/2020/Conference/Paper407/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper407/-/Official_Comment"}}}, {"id": "ryl0H6hEiS", "original": null, "number": 4, "cdate": 1573338438034, "ddate": null, "tcdate": 1573338438034, "tmdate": 1573338438034, "tddate": null, "forum": "H1emfT4twB", "replyto": "H1emfT4twB", "invitation": "ICLR.cc/2020/Conference/Paper407/-/Official_Comment", "content": {"title": "To all reviewers", "comment": "Thank you again for your detailed comments and suggestions. We would like to summarize the main contributions of our paper, as well as our recent updates to the paper. In addition, our code base has been updated with the latest experiments.\n\nWe would like to emphasize that this paper makes unique and valuable contributions to the few-shot learning community.\n\n1. It is the first to identify that meta-learning algorithms only memorize features that are useful during meta-training, instead of actually learning to adapt quickly to new settings.\n\n2. The main contribution of this paper is not a specific set of delexicalised features for an end task (classification/parsing), but rather a meta-learning approach towards generalizable representations. Meta-knowledge learned on top of distributional signatures can be used towards any downstream classifier to improve performance in low-resource settings.\n\n3. We provide the largest publicly available few-shot text classification benchmarks to the community. Both our code (including all reported baselines) and data splits are available for reproducibility.\n\nAdditional experiments:\n\n1. Comparison to other baselines.\nBased on suggestions, we have also compared our work to Induction Network and P-MAML. We observe that our method vastly outperforms these methods, as they both build meta-knowledge from lexical features which do not generalize to different word distributions. (Table 4, Appendix A.5).\n\n2. Distributional signatures improve other classifiers too.\nWe show that we can improve Prototypical Networks and Induction Network Routing by replacing their input representations with our attention-weighted representation learned from distributional signatures (Table 7, Appendix A.9).\n\n3. Restricting meta-knowledge to distributional signatures is crucial.\nWhen we feed the attention generator word embeddings together with the distributional signatures, performance drops significantly, as the model can perform much better on meta-train by focusing on non-transferable lexical features (Table 1, last row).\n\n4. Finetuning BERT/FastText disrupts word embedding geometry due to lexical mismatch.\nMethods generally perform worse when word embeddings are finetuned (Table 6).\n\n5. Effect of softmax calibration with ridge regression.\nReplacing ridge regression with logistic regression + Newton\u2019s method yields no significant difference in results (Table 5).\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper407/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper407/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "In this paper, we explore meta-learning for few-shot text classification. Meta-learning has shown strong performance in computer vision, where low-level patterns are transferable across learning tasks. However, directly applying this approach to text is challenging--lexical features highly informative for one task may be insignificant for another. Thus, rather than learning solely from words, our model also leverages their distributional signatures, which encode pertinent word occurrence patterns. Our model is trained within a meta-learning framework to map these signatures into attention scores, which are then used to weight the lexical representations of words. We demonstrate that our model consistently outperforms prototypical networks learned on lexical knowledge (Snell et al., 2017) in both few-shot text classification and relation classification by a significant margin across six benchmark datasets (20.0% on average in 1-shot classification).", "title": "Few-shot Text Classification with Distributional Signatures", "code": "https://github.com/YujiaBao/Distributional-Signatures", "keywords": ["text classification", "meta learning", "few shot learning"], "authors": ["Yujia Bao", "Menghua Wu", "Shiyu Chang", "Regina Barzilay"], "TL;DR": "Meta-learning methods used for vision, directly applied to NLP, perform worse than nearest neighbors on new classes; we can do better with distributional signatures.", "authorids": ["yujia@csail.mit.edu", "rmwu@mit.edu", "shiyu.chang@ibm.com", "regina@csail.mit.edu"], "pdf": "/pdf/4fa31bfd21e94185de50157b87f30279d335676f.pdf", "paperhash": "bao|fewshot_text_classification_with_distributional_signatures", "_bibtex": "@inproceedings{\nBao2020Few-shot,\ntitle={Few-shot Text Classification with Distributional Signatures},\nauthor={Yujia Bao and Menghua Wu and Shiyu Chang and Regina Barzilay},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1emfT4twB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/a90b4b7b3d3a5baa79570d60c725c959d431870d.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1emfT4twB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper407/Authors", "ICLR.cc/2020/Conference/Paper407/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper407/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper407/Reviewers", "ICLR.cc/2020/Conference/Paper407/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper407/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper407/Authors|ICLR.cc/2020/Conference/Paper407/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504171923, "tmdate": 1576860540580, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper407/Authors", "ICLR.cc/2020/Conference/Paper407/Reviewers", "ICLR.cc/2020/Conference/Paper407/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper407/-/Official_Comment"}}}, {"id": "Byx7SzJZiB", "original": null, "number": 3, "cdate": 1573085754832, "ddate": null, "tcdate": 1573085754832, "tmdate": 1573335821952, "tddate": null, "forum": "H1emfT4twB", "replyto": "rklewo2-9r", "invitation": "ICLR.cc/2020/Conference/Paper407/-/Official_Comment", "content": {"title": "Contributions and additional notes", "comment": "[This comment has been updated to reflect changes in paper numbering]\n\nThank you for your detailed comments!\n\nWe would like to emphasize that this paper makes unique and valuable contributions to the few-shot learning community.\n\n- It is the first to identify that meta-learning algorithms only memorize useful training features, instead of actually learning to adapt quickly to new settings. Thus, standard meta-learning algorithms may not generalize in NLP, when word distributions differ vastly among tasks. Later on, [a] reported similar findings for vision.\n\n- The main contribution of this paper is not a specific set of delexicalised features for an end task (classification/parsing), but rather a meta-learning approach towards generalizable representations in low-resource settings. In few-shot learning, we are the first to propose that meta-knowledge can be learned on top of feature statistics, instead of features themselves (which are not transferable).\n\n- We provide the largest publicly available few-shot text classification benchmarks to the community. Previous work [b, c] focus on binary sentiment classifiers across different domains, while we are interested in multi-class text classification. The setup of [d] is similar to ours, but neither their datasets nor code are publicly available, and they only run experiments on two datasets (RCV1, Reuters).\n\nIn terms of raw representation power, our model is definitely weaker than fully-lexical models. Instead, the key benefit is that it generalizes in low-resource settings (Figure 6). Quantitatively, our 5-shot accuracy is approximately equivalent to a fully supervised model trained on 50 examples (Figure 14).\n\nWhile 50 examples does not seem like very much, even for low-resource languages, we would like to present one case we have faced where we cannot hope for this many. We are given a set of pathology reports, which detail the diagnoses of various tissues in a patient\u2019s body (e.g. lung, ovary). We want to predict whether the patient has a disease. This is not a \u201chard\u201d task, and a CNN would perform quite well, given enough data. However, these individual diagnoses correspond to potentially thousands of diseases. The total number of {tissue diagnosis, disease} pairs far exceeds the number of reports. Often, each pair only has one or two examples. In this case, it is unrealistic to train a fully-supervised classifier for each pair.\n\nIf we resort to standard meta-learning techniques, learning lexical information from well-represented disease/tissue pairs may be distracting for rarer cases: there is a staggering number of medical terms regarding each disease/tissue, few of these terms overlap across tasks. On the other hand, if we work with distributional statistics, we can learn to ignore terms that are not useful, regardless of task. As a result, we can better focus on words that are meaningful for classification.\n\nAdditional Notes:\n1. We provide the comparison in the ablation study (Table 1, OUR w/o biLSTM), where we learn a projection from the two statistics using an MLP. On average, the biLSTM improves accuracy from 77.2 to 78.0 (best baseline RR+IDF is 74.1).\n2. The idea was to provide some intuition about distributional signatures, if the reader finds them clearer to understand in this way.\n3. We have added experiments comparing ridge regression vs. logistic regression with Newton\u2019s method in Appendix A.7. On average, RR+OUR performs slightly better than LR+OUR (78.0 vs. 77.1 on 5-shot, 60.1 vs. 58.8 on 1-shot), but both significantly outperform the best baselines (RR+IDF, 74.1 on 5-shot; LR+IDF, 52.7 on 1-shot).\n4. In this paper, we focused on RR as the main downstream predictor due to its simplicity and effectiveness. However, our experiments show that the attention-based feature aggregator also improves performance for other algorithms. Appendix A.9 contains results from distributional signatures + other classifiers. For prototypical networks, we improve 1-shot accuracy by 9.9 and 5-shot accuracy by 16.7 on average across 6 datasets, compared to the best baseline. For induction networks, we improve average accuracy by 14.3% on 1-shot and 25.1% on 5-shot (Table 7).\n5. Done, thank you for the suggestion.\n\nWe hope we have adequately addressed your concerns. Please let us know if you have any more questions. Thank you!\n\n\nReferences\n[a] Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML\n[b] Diverse Few-Shot Text Classification with Multiple Metrics\n[c] Induction Networks for Few-Shot Text Classification\n[d] Attentive Task-Agnostic Meta-Learning for Few-Shot Text Classification\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper407/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper407/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "In this paper, we explore meta-learning for few-shot text classification. Meta-learning has shown strong performance in computer vision, where low-level patterns are transferable across learning tasks. However, directly applying this approach to text is challenging--lexical features highly informative for one task may be insignificant for another. Thus, rather than learning solely from words, our model also leverages their distributional signatures, which encode pertinent word occurrence patterns. Our model is trained within a meta-learning framework to map these signatures into attention scores, which are then used to weight the lexical representations of words. We demonstrate that our model consistently outperforms prototypical networks learned on lexical knowledge (Snell et al., 2017) in both few-shot text classification and relation classification by a significant margin across six benchmark datasets (20.0% on average in 1-shot classification).", "title": "Few-shot Text Classification with Distributional Signatures", "code": "https://github.com/YujiaBao/Distributional-Signatures", "keywords": ["text classification", "meta learning", "few shot learning"], "authors": ["Yujia Bao", "Menghua Wu", "Shiyu Chang", "Regina Barzilay"], "TL;DR": "Meta-learning methods used for vision, directly applied to NLP, perform worse than nearest neighbors on new classes; we can do better with distributional signatures.", "authorids": ["yujia@csail.mit.edu", "rmwu@mit.edu", "shiyu.chang@ibm.com", "regina@csail.mit.edu"], "pdf": "/pdf/4fa31bfd21e94185de50157b87f30279d335676f.pdf", "paperhash": "bao|fewshot_text_classification_with_distributional_signatures", "_bibtex": "@inproceedings{\nBao2020Few-shot,\ntitle={Few-shot Text Classification with Distributional Signatures},\nauthor={Yujia Bao and Menghua Wu and Shiyu Chang and Regina Barzilay},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1emfT4twB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/a90b4b7b3d3a5baa79570d60c725c959d431870d.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1emfT4twB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper407/Authors", "ICLR.cc/2020/Conference/Paper407/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper407/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper407/Reviewers", "ICLR.cc/2020/Conference/Paper407/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper407/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper407/Authors|ICLR.cc/2020/Conference/Paper407/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504171923, "tmdate": 1576860540580, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper407/Authors", "ICLR.cc/2020/Conference/Paper407/Reviewers", "ICLR.cc/2020/Conference/Paper407/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper407/-/Official_Comment"}}}, {"id": "Hyl3_-kWsH", "original": null, "number": 2, "cdate": 1573085555574, "ddate": null, "tcdate": 1573085555574, "tmdate": 1573335791930, "tddate": null, "forum": "H1emfT4twB", "replyto": "ryeH-6BycH", "invitation": "ICLR.cc/2020/Conference/Paper407/-/Official_Comment", "content": {"title": "Clarification regarding our model and experiments", "comment": "[This comment has been updated to reflect changes in paper numbering]\n\nThank you for the detailed comments!\n\nClarity: Figures 4 and 5 are provided as summaries of the learning procedure and model; all components are formally defined in Sections 3 and 4, with implementation details in Section 5. \n\nModel: All notation is formally defined within the main text, with additional implementation details in the Appendix.\n- For the attention generator, the raw statistics s(.) and t(.) are defined in equations 1 and 2 respectively. Implementation details regarding t(.) are found in Appendix A.1, as cited. The attention score \\alpha is defined in equation 3. Details for the biLSTM are noted in Section 5.\n- For the ridge regressor, the weighted representations \\phi are defined in equation 4, and W is written out in equation 6.\n\nLearning Procedure: Based on the suggestions, we have added Appendix A.3 containing pseudocode for our entire learning procedure. Hyperparameters for training are already noted in Section 5.\n\nExperimental Setup: This paper does not follow the standard FewRel setup, as noted by Appendix A.4 and Table 3 (referenced in Section 5.1). We combine the train/val data of FewRel (test is not publicly available) and split it further into train/val/test.\n\nFor data splits, we consider two settings: \u201ceasy split\u201d randomly permuted classes and divided into train/val/test, and \u201chard split\u201d selected train/val/test classes based on class hierarchies or similar heuristics, such that train classes are distant from val/test. Following [a], we use the \u201chard split\u201d to test the meta-learning algorithm\u2019s generalization capacity when testing tasks may not come from the same domain as training tasks. Please see the Appendix for details regarding each dataset.\n\nFor RCV1 and Reuters, [b] does not provide pruned classes, data splits, or code, so we cannot directly compare. Our code (including all baselines), data splits, and processed data are publicly available.\n\nWe hope we have adequately addressed your concerns. Please let us know if you have any more questions. Thank you!\n\nReferences\n\n[a] Zero-Shot Learning - The Good, the Bad and the Ugly\n[b] Attentive Task-Agnostic Meta-Learning for Few-Shot Text Classification"}, "signatures": ["ICLR.cc/2020/Conference/Paper407/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper407/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "In this paper, we explore meta-learning for few-shot text classification. Meta-learning has shown strong performance in computer vision, where low-level patterns are transferable across learning tasks. However, directly applying this approach to text is challenging--lexical features highly informative for one task may be insignificant for another. Thus, rather than learning solely from words, our model also leverages their distributional signatures, which encode pertinent word occurrence patterns. Our model is trained within a meta-learning framework to map these signatures into attention scores, which are then used to weight the lexical representations of words. We demonstrate that our model consistently outperforms prototypical networks learned on lexical knowledge (Snell et al., 2017) in both few-shot text classification and relation classification by a significant margin across six benchmark datasets (20.0% on average in 1-shot classification).", "title": "Few-shot Text Classification with Distributional Signatures", "code": "https://github.com/YujiaBao/Distributional-Signatures", "keywords": ["text classification", "meta learning", "few shot learning"], "authors": ["Yujia Bao", "Menghua Wu", "Shiyu Chang", "Regina Barzilay"], "TL;DR": "Meta-learning methods used for vision, directly applied to NLP, perform worse than nearest neighbors on new classes; we can do better with distributional signatures.", "authorids": ["yujia@csail.mit.edu", "rmwu@mit.edu", "shiyu.chang@ibm.com", "regina@csail.mit.edu"], "pdf": "/pdf/4fa31bfd21e94185de50157b87f30279d335676f.pdf", "paperhash": "bao|fewshot_text_classification_with_distributional_signatures", "_bibtex": "@inproceedings{\nBao2020Few-shot,\ntitle={Few-shot Text Classification with Distributional Signatures},\nauthor={Yujia Bao and Menghua Wu and Shiyu Chang and Regina Barzilay},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1emfT4twB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/a90b4b7b3d3a5baa79570d60c725c959d431870d.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "H1emfT4twB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper407/Authors", "ICLR.cc/2020/Conference/Paper407/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper407/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper407/Reviewers", "ICLR.cc/2020/Conference/Paper407/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper407/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper407/Authors|ICLR.cc/2020/Conference/Paper407/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504171923, "tmdate": 1576860540580, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper407/Authors", "ICLR.cc/2020/Conference/Paper407/Reviewers", "ICLR.cc/2020/Conference/Paper407/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper407/-/Official_Comment"}}}, {"id": "ryeH-6BycH", "original": null, "number": 2, "cdate": 1571933436653, "ddate": null, "tcdate": 1571933436653, "tmdate": 1572972599105, "tddate": null, "forum": "H1emfT4twB", "replyto": "H1emfT4twB", "invitation": "ICLR.cc/2020/Conference/Paper407/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper focuses on applying meta learning approaches to text classification.\n\nThe primary contribution is an attention mechanism based on word statistics --- most importantly word frequency. This novel attention mechanism is motivated by the observation that the base units in text (lexemes) are more likely to have task specific interpretations than lower level patterns in vision. And, while a lexeme based attention mechanism trained on one task may not transfer well to other tasks, a mechanism based on coarser word statistics is less likely to focus in on task specific patterns.\n\nA secondary contribution is the use of ridge regression [1] to perform meta-learning for text classification.\n\nThe paper presents experiments on a number of text classification tasks from the NLP literature. Aside from the new attention mechanism and the use of ridge regression, the proposed approach makes use of FastText word embeddings or BERT sentence representations, depending on the task. The paper demonstrates significant improvements over baselines that use other methods of aggregating word representations. All of baselines were implemented for this paper.\n\nThe idea of using coarse statistical signatures to calculate attention is an interesting one. However, I have concerns about both the clarity of this paper and the lack of clear comparison to previous work.\n\n== Clarity ==\n\nMany of the details of the model and learning approach are vaguely discussed, or relegated to Figures 4 & 5. I think the paper would benefit from a more formal definition of the entire learning procedure.\n\n== Comparison to previous work ==\n\nThis paper seems to be following the standard FewRel experimental setup. Also, the RCV1 experiments seem to follow the [2] which was cited by the in the paper under review. However, it is not clear if the setups are the same or if the numbers are comparable.\n\nI am not sure about the existence of comparable results for the other tasks, but for FewRel at least the baselines presented here significantly underperform other papers' reports of equivalent models.\n\n  - The paper from [3] that introduced FewRel reported 69.2 / 84.8 for CNN based prototypical networks --- far above the 49.8 / 65.2 reported here.\n\n  - [4] found that a BERT model with no FewRel specific training at all achieves 72.9% on the 5way/1shot task. Which is above all of the BERT based models reported in Table 2.\n\nI may be missing something, but if these numbers are actually not comparable then this paper should contain an explanation of how the experimental setup differs. And if the setup is actually the same as previous work, I expect to see a comparison of results.\n\n[1] https://openreview.net/pdf?id=HyxnZh0ct7\n[2] https://openreview.net/forum?id=SyxMWh09KX\n[3] https://www.aclweb.org/anthology/D18-1514/\n[4] https://arxiv.org/abs/1906.03158"}, "signatures": ["ICLR.cc/2020/Conference/Paper407/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper407/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "In this paper, we explore meta-learning for few-shot text classification. Meta-learning has shown strong performance in computer vision, where low-level patterns are transferable across learning tasks. However, directly applying this approach to text is challenging--lexical features highly informative for one task may be insignificant for another. Thus, rather than learning solely from words, our model also leverages their distributional signatures, which encode pertinent word occurrence patterns. Our model is trained within a meta-learning framework to map these signatures into attention scores, which are then used to weight the lexical representations of words. We demonstrate that our model consistently outperforms prototypical networks learned on lexical knowledge (Snell et al., 2017) in both few-shot text classification and relation classification by a significant margin across six benchmark datasets (20.0% on average in 1-shot classification).", "title": "Few-shot Text Classification with Distributional Signatures", "code": "https://github.com/YujiaBao/Distributional-Signatures", "keywords": ["text classification", "meta learning", "few shot learning"], "authors": ["Yujia Bao", "Menghua Wu", "Shiyu Chang", "Regina Barzilay"], "TL;DR": "Meta-learning methods used for vision, directly applied to NLP, perform worse than nearest neighbors on new classes; we can do better with distributional signatures.", "authorids": ["yujia@csail.mit.edu", "rmwu@mit.edu", "shiyu.chang@ibm.com", "regina@csail.mit.edu"], "pdf": "/pdf/4fa31bfd21e94185de50157b87f30279d335676f.pdf", "paperhash": "bao|fewshot_text_classification_with_distributional_signatures", "_bibtex": "@inproceedings{\nBao2020Few-shot,\ntitle={Few-shot Text Classification with Distributional Signatures},\nauthor={Yujia Bao and Menghua Wu and Shiyu Chang and Regina Barzilay},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1emfT4twB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/a90b4b7b3d3a5baa79570d60c725c959d431870d.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "H1emfT4twB", "replyto": "H1emfT4twB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper407/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper407/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575541355727, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper407/Reviewers"], "noninvitees": [], "tcdate": 1570237752598, "tmdate": 1575541355741, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper407/-/Official_Review"}}}, {"id": "BkglFISTYS", "original": null, "number": 1, "cdate": 1571800696273, "ddate": null, "tcdate": 1571800696273, "tmdate": 1572972599008, "tddate": null, "forum": "H1emfT4twB", "replyto": "H1emfT4twB", "invitation": "ICLR.cc/2020/Conference/Paper407/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper studies the effects of using function of ngram statistics as feature to generate attention score per word. The attention score is then used as weights to aggregate document embedding by doing a weighted average on word embedding. The output is finally fed into a ridge regressor to do the final predictions on target labels. \n\nMain comments:\nThis paper has a clear motivation and decent experimental results (though some concern on baseline models, see below). The introduction of using distributional signature to derive attention scores seems interesting and a novel contribution. However I was not able to fully understand the intuition behind the benefit of doing attention mechanism on top of ngram statistics (see my question below as well). \nAlso the reference/baseline models used in the experiment might not be strong enough. If you could compare your model with some latest algorithms proposed in the few-shot-learning communities, that would be more convincing as well. \nTo list a few:\n* P-MAML: [Zhang et al., 2019]\n* Induction-Network-Routing: [Geng et al., 2019]\n* ROBUSTTC-FSL [Yu et al., 2018]\n\nI am leaning to give a \"weak reject\" based on my current knowledge and understanding of the paper. But I will be willing to revisit the decision after we get feedback from the author(s). \n\nIn particular, I would be glad if the author could clarify the questions below.\n\n* From table 1, it seems Method IDF+RR is a competitive model. IIUC, the statistics of s(.) is highly correlated with IDF which also indicates general word importance in corpus. My questions are that, \n1) regarding ablation test \"OUR w/o biLSTM\", how is $h$ calculated in this case (without biLSTM)?\n2) since each word is represented based on two statistical number (map function by t(.) and s(.)), can you give any intuitive explanation that why getting attention score from that makes sense?\n3) do you have any experiments using the distributional signature as a common feature in standard text classification problems? In other words, is this method only (significantly) beneficial to few-short-learning? If it is also useful in general text classification task, it would be a good \"plus\" here.\n\n* From table 2, can you explain why CNN+RR benefits a lot from the BERT embedding? Actually it gets more percentage of improvement than the model \"OUR\".\n\n* For all the usages of pre-trained embedding (fasttext or BERT), are you further finetuning the embedding parameters during your training? Or you freeze the embedding parameters?\n\n[Zhang et al., 2019] Ningyu Zhang et al., Improving Few-shot Text Classification via Pretrained Language Representations. arXiv preprint arXiv: 1908.08788\n[Geng et al., 2019] Ruiying Geng, Binhua Li, Yongbin Li, Yuxiao Ye, Ping Jian, and Jian Sun. 2019. Few-shot text classification with induction network. arXiv preprint arXiv:1902.10482.\n [Yu et al., 2018] Mo Yu, Xiaoxiao Guo, Jinfeng Yi, Shiyu Chang, Saloni Potdar, Yu Cheng, Gerald Tesauro, Haoyu Wang,\nand Bowen Zhou. 2018. Diverse few-shot text classification with multiple metrics. arXiv preprint arXiv:1805.07513"}, "signatures": ["ICLR.cc/2020/Conference/Paper407/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper407/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "In this paper, we explore meta-learning for few-shot text classification. Meta-learning has shown strong performance in computer vision, where low-level patterns are transferable across learning tasks. However, directly applying this approach to text is challenging--lexical features highly informative for one task may be insignificant for another. Thus, rather than learning solely from words, our model also leverages their distributional signatures, which encode pertinent word occurrence patterns. Our model is trained within a meta-learning framework to map these signatures into attention scores, which are then used to weight the lexical representations of words. We demonstrate that our model consistently outperforms prototypical networks learned on lexical knowledge (Snell et al., 2017) in both few-shot text classification and relation classification by a significant margin across six benchmark datasets (20.0% on average in 1-shot classification).", "title": "Few-shot Text Classification with Distributional Signatures", "code": "https://github.com/YujiaBao/Distributional-Signatures", "keywords": ["text classification", "meta learning", "few shot learning"], "authors": ["Yujia Bao", "Menghua Wu", "Shiyu Chang", "Regina Barzilay"], "TL;DR": "Meta-learning methods used for vision, directly applied to NLP, perform worse than nearest neighbors on new classes; we can do better with distributional signatures.", "authorids": ["yujia@csail.mit.edu", "rmwu@mit.edu", "shiyu.chang@ibm.com", "regina@csail.mit.edu"], "pdf": "/pdf/4fa31bfd21e94185de50157b87f30279d335676f.pdf", "paperhash": "bao|fewshot_text_classification_with_distributional_signatures", "_bibtex": "@inproceedings{\nBao2020Few-shot,\ntitle={Few-shot Text Classification with Distributional Signatures},\nauthor={Yujia Bao and Menghua Wu and Shiyu Chang and Regina Barzilay},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=H1emfT4twB}\n}", "full_presentation_video": "", "original_pdf": "/attachment/a90b4b7b3d3a5baa79570d60c725c959d431870d.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "H1emfT4twB", "replyto": "H1emfT4twB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper407/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper407/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575541355727, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper407/Reviewers"], "noninvitees": [], "tcdate": 1570237752598, "tmdate": 1575541355741, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper407/-/Official_Review"}}}], "count": 9}