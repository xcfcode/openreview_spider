{"notes": [{"id": "HkxzljA4_N", "original": "B1gEImON_V", "number": 52, "cdate": 1553423081866, "ddate": null, "tcdate": 1553423081866, "tmdate": 1562082114132, "tddate": null, "forum": "HkxzljA4_N", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "Online Meta-Learning", "authors": ["Chelsea Finn", "Aravind Rajeswaran", "Sham Kakade", "Sergey Levine"], "authorids": ["cbfinn@eecs.berkeley.edu", "aravraj@cs.washington.edu", "sham@cs.washington.edu", "svlevine@eecs.berkeley.edu"], "keywords": ["meta learning", "few-shot learning", "online learning"], "TL;DR": "We introduce the online meta learning problem setting to better capture the spirit and practice of continual lifelong learning.", "abstract": "A central capability of intelligent systems is the ability to continuously build upon previous experiences to speed up and enhance learning of new tasks. Two distinct research paradigms have studied this question. Meta-learning views this problem as learning a prior over model parameters that is amenable for fast adaptation on a new task, but typically assumes the set of tasks are available together as a batch. In contrast, online (regret based) learning considers a sequential setting in which problems are revealed one after the other, but conventionally train only a single model without any task-specific adaptation. This work introduces an online meta-learning setting, which merges ideas from both the aforementioned paradigms to better capture the spirit and practice of continual lifelong learning. We propose the follow the meta leader (FTML) algorithm which extends the MAML algorithm to this setting. Theoretically, this work provides an O(logT) regret guarantee for the FTML algorithm. Our experimental evaluation on three different large-scale tasks suggest that the proposed algorithm significantly outperforms alternatives based on traditional online learning approaches.", "pdf": "/pdf/e0444ac80869342599f5686fcaf11bc289ef75ea.pdf", "paperhash": "finn|online_metalearning"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "OpenReview.net"}, {"id": "ByeWbyNRt4", "original": null, "number": 1, "cdate": 1555083001329, "ddate": null, "tcdate": 1555083001329, "tmdate": 1555511875833, "tddate": null, "forum": "HkxzljA4_N", "replyto": "HkxzljA4_N", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper52/Official_Review", "content": {"title": "A new paradigm for continual lifelong learning", "review": "This paper formulated a new learning paradigm that combines meta-learning and online leanring, which is more general than few-shot supervised learning paradigm. The authors proposed a FTL-fashioned algorithm (FTML) that extends MAML to the online setting. FTML achieves a regret of order O(logT) under some C^2-smoothness assumption and a \\mu-strongly convex loss. This logarithmic regret bound is comparable to the usual FTL algorithms in a similar setting. The provable algorithm is however not straightforwardly applicable in practice, but it is shown that a MAML-typed modification can lead to reasonable performances.  \n\nRegarding the theoretical part, the contribution does not seem to be technically significant (I don't really have time to check the analysis so I may be wrong) but provided a first set of results to the new paradigm. One flaw is maybe that the implemented algorithm is not exactly the same as the provable one, but it is comprehensible...\n\nThe experimental setting, in particular the choice of baselines is reasonable and integrated since there are no real prior algorithms on this new paradigm. I somehow don't like the fact that no uncertainty are given in the figures (or at least the number of replications of each experiment could've been reported).\n\nOverall, the paper may lack of some self-containedness due to the page limits, but remains a sound enough paper for the workshop.\n\nI would vote for accept. \n\nMinor comments:\n1. The detailed assumptions have been placed in Appendix for the sake of space constraint, but in Corollary 1 it is stated that \"under assumptions 1 and 2...\" where no clue is given on where to find assumptions 1 and 2. Well I finally found them in the appendix, but it took me a bit of time.\n2. I personally don't like a sole subsection indexed x.1 within a whole section, well it's a personal taste...", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper52/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper52/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Online Meta-Learning", "authors": ["Chelsea Finn", "Aravind Rajeswaran", "Sham Kakade", "Sergey Levine"], "authorids": ["cbfinn@eecs.berkeley.edu", "aravraj@cs.washington.edu", "sham@cs.washington.edu", "svlevine@eecs.berkeley.edu"], "keywords": ["meta learning", "few-shot learning", "online learning"], "TL;DR": "We introduce the online meta learning problem setting to better capture the spirit and practice of continual lifelong learning.", "abstract": "A central capability of intelligent systems is the ability to continuously build upon previous experiences to speed up and enhance learning of new tasks. Two distinct research paradigms have studied this question. Meta-learning views this problem as learning a prior over model parameters that is amenable for fast adaptation on a new task, but typically assumes the set of tasks are available together as a batch. In contrast, online (regret based) learning considers a sequential setting in which problems are revealed one after the other, but conventionally train only a single model without any task-specific adaptation. This work introduces an online meta-learning setting, which merges ideas from both the aforementioned paradigms to better capture the spirit and practice of continual lifelong learning. We propose the follow the meta leader (FTML) algorithm which extends the MAML algorithm to this setting. Theoretically, this work provides an O(logT) regret guarantee for the FTML algorithm. Our experimental evaluation on three different large-scale tasks suggest that the proposed algorithm significantly outperforms alternatives based on traditional online learning approaches.", "pdf": "/pdf/e0444ac80869342599f5686fcaf11bc289ef75ea.pdf", "paperhash": "finn|online_metalearning"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper52/Official_Review", "cdate": 1553713412960, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "HkxzljA4_N", "replyto": "HkxzljA4_N", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper52/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper52/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713412960, "tmdate": 1555511823130, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper52/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "Ske4TVOCY4", "original": null, "number": 2, "cdate": 1555100860156, "ddate": null, "tcdate": 1555100860156, "tmdate": 1555511875186, "tddate": null, "forum": "HkxzljA4_N", "replyto": "HkxzljA4_N", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper52/Official_Review", "content": {"title": "The paper seems to be sound", "review": "The paper introduces a task of online metalearning, where the agent is doing few shot learning online -- every task is seen only once.\n\nI am not an expert in online learning, but the paper seems to be sound. The experimentation looks thorough. The results are promising, but I would like to see some dataset closer to real world.\n\nA minor point -- graphs are very hard to read, please use vector images", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper52/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper52/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Online Meta-Learning", "authors": ["Chelsea Finn", "Aravind Rajeswaran", "Sham Kakade", "Sergey Levine"], "authorids": ["cbfinn@eecs.berkeley.edu", "aravraj@cs.washington.edu", "sham@cs.washington.edu", "svlevine@eecs.berkeley.edu"], "keywords": ["meta learning", "few-shot learning", "online learning"], "TL;DR": "We introduce the online meta learning problem setting to better capture the spirit and practice of continual lifelong learning.", "abstract": "A central capability of intelligent systems is the ability to continuously build upon previous experiences to speed up and enhance learning of new tasks. Two distinct research paradigms have studied this question. Meta-learning views this problem as learning a prior over model parameters that is amenable for fast adaptation on a new task, but typically assumes the set of tasks are available together as a batch. In contrast, online (regret based) learning considers a sequential setting in which problems are revealed one after the other, but conventionally train only a single model without any task-specific adaptation. This work introduces an online meta-learning setting, which merges ideas from both the aforementioned paradigms to better capture the spirit and practice of continual lifelong learning. We propose the follow the meta leader (FTML) algorithm which extends the MAML algorithm to this setting. Theoretically, this work provides an O(logT) regret guarantee for the FTML algorithm. Our experimental evaluation on three different large-scale tasks suggest that the proposed algorithm significantly outperforms alternatives based on traditional online learning approaches.", "pdf": "/pdf/e0444ac80869342599f5686fcaf11bc289ef75ea.pdf", "paperhash": "finn|online_metalearning"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper52/Official_Review", "cdate": 1553713412960, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "HkxzljA4_N", "replyto": "HkxzljA4_N", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper52/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper52/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713412960, "tmdate": 1555511823130, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper52/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "H1lEWJjkcN", "original": null, "number": 3, "cdate": 1555177211885, "ddate": null, "tcdate": 1555177211885, "tmdate": 1555511874322, "tddate": null, "forum": "HkxzljA4_N", "replyto": "HkxzljA4_N", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper52/Official_Review", "content": {"title": "Review of \"Online Meta-Learning\"", "review": "Summary of the paper:\n\nThis work proposes a \u201cbest of both worlds approach\u201d, by introducint an online meta-learning algorithm.\nThe \u201cfollow the meta leader\u201d algorithm (and its analysis) heavily builds on the \u201cfollow the leader\u201d algorithm from online convex optimization, which leaves the door open for future improvements.\nSome numerical experiments favorably comparing the approach with previous work are provided.\n\nA few comments and questions:\n-there is a (small) typo, line 7 of section A1 page 8, in the appendix\n-second corollary, page 11: why put a 32 in the big O notation (same comment for the proof)?\n\nReviewer\u2019s assessment:\nI found the paper to be well written. The ideas are exposed clearly and the numerical results support the approach. Since the problem tackled by this work clearly falls within the scope of the workshop, I recommend to accept this paper.\n\n\n", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper52/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper52/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Online Meta-Learning", "authors": ["Chelsea Finn", "Aravind Rajeswaran", "Sham Kakade", "Sergey Levine"], "authorids": ["cbfinn@eecs.berkeley.edu", "aravraj@cs.washington.edu", "sham@cs.washington.edu", "svlevine@eecs.berkeley.edu"], "keywords": ["meta learning", "few-shot learning", "online learning"], "TL;DR": "We introduce the online meta learning problem setting to better capture the spirit and practice of continual lifelong learning.", "abstract": "A central capability of intelligent systems is the ability to continuously build upon previous experiences to speed up and enhance learning of new tasks. Two distinct research paradigms have studied this question. Meta-learning views this problem as learning a prior over model parameters that is amenable for fast adaptation on a new task, but typically assumes the set of tasks are available together as a batch. In contrast, online (regret based) learning considers a sequential setting in which problems are revealed one after the other, but conventionally train only a single model without any task-specific adaptation. This work introduces an online meta-learning setting, which merges ideas from both the aforementioned paradigms to better capture the spirit and practice of continual lifelong learning. We propose the follow the meta leader (FTML) algorithm which extends the MAML algorithm to this setting. Theoretically, this work provides an O(logT) regret guarantee for the FTML algorithm. Our experimental evaluation on three different large-scale tasks suggest that the proposed algorithm significantly outperforms alternatives based on traditional online learning approaches.", "pdf": "/pdf/e0444ac80869342599f5686fcaf11bc289ef75ea.pdf", "paperhash": "finn|online_metalearning"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper52/Official_Review", "cdate": 1553713412960, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "HkxzljA4_N", "replyto": "HkxzljA4_N", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper52/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper52/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713412960, "tmdate": 1555511823130, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper52/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "BkxkP03G9N", "original": null, "number": 1, "cdate": 1555381847321, "ddate": null, "tcdate": 1555381847321, "tmdate": 1555510976384, "tddate": null, "forum": "HkxzljA4_N", "replyto": "HkxzljA4_N", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper52/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Online Meta-Learning", "authors": ["Chelsea Finn", "Aravind Rajeswaran", "Sham Kakade", "Sergey Levine"], "authorids": ["cbfinn@eecs.berkeley.edu", "aravraj@cs.washington.edu", "sham@cs.washington.edu", "svlevine@eecs.berkeley.edu"], "keywords": ["meta learning", "few-shot learning", "online learning"], "TL;DR": "We introduce the online meta learning problem setting to better capture the spirit and practice of continual lifelong learning.", "abstract": "A central capability of intelligent systems is the ability to continuously build upon previous experiences to speed up and enhance learning of new tasks. Two distinct research paradigms have studied this question. Meta-learning views this problem as learning a prior over model parameters that is amenable for fast adaptation on a new task, but typically assumes the set of tasks are available together as a batch. In contrast, online (regret based) learning considers a sequential setting in which problems are revealed one after the other, but conventionally train only a single model without any task-specific adaptation. This work introduces an online meta-learning setting, which merges ideas from both the aforementioned paradigms to better capture the spirit and practice of continual lifelong learning. We propose the follow the meta leader (FTML) algorithm which extends the MAML algorithm to this setting. Theoretically, this work provides an O(logT) regret guarantee for the FTML algorithm. Our experimental evaluation on three different large-scale tasks suggest that the proposed algorithm significantly outperforms alternatives based on traditional online learning approaches.", "pdf": "/pdf/e0444ac80869342599f5686fcaf11bc289ef75ea.pdf", "paperhash": "finn|online_metalearning"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper52/Decision", "cdate": 1554736074429, "reply": {"forum": "HkxzljA4_N", "replyto": "HkxzljA4_N", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736074429, "tmdate": 1555510964426, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 5}