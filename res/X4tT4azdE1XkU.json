{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1391824620000, "tcdate": 1391824620000, "number": 5, "id": "nh6qniypdC210", "invitation": "ICLR.cc/2014/-/submission/workshop/review", "forum": "X4tT4azdE1XkU", "replyto": "X4tT4azdE1XkU", "signatures": ["anonymous reviewer 1704"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Unsupervised Feature Learning by Deep Sparse Coding", "review": "This paper alternates sparse-to-dense (dimensionality reduction by learning an invariant mapping: DRLIM) and dense-to-sparse (standard sparse coding) modules to produce a multi-layer image representation of images. Compared to earlier deep image recognition architectures using sparse modules and pooling modules, the proposed system is more general and displays better performance on image recognition benchmarks.\r\n\r\nThe paper itself is clear and well-motivated. While none of the building blocks is new (DRLIM blocks, sparse coding blocks, etc), the combination is novel and works well.\r\n\r\nExperiments on Caltech 101, Caltech 256, and Scenes 15 show that the new architecture performs better than earlier versions without this sparse-to-dense mapping. These are bit limited now that better datasets are widely used (e.g., imagenet), but the experiments are interesting and show that the new system allows for deeper training without increasing the dimension of dictionary used for sparse coding. I think other researchers would be interested in these results.\r\n\r\nThere are a few writing problems (e.g. 'it is important to emphasis' instead of 'emphasize') so please spell check, but this does not hinder understanding. Also, it would be simpler to write 'First' rather than 'first of all' as is done in several places.\r\n\r\nOverall this paper presents a more principled variant for a deep image recognition architecture. The datasets used are limited but show that this system has promise."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Feature Learning by Deep Sparse Coding", "decision": "submitted, no decision", "abstract": "In this paper, we propose a new unsupervised feature learning framework, namely Deep Sparse Coding (DeepSC), that extends sparse coding to a multi-layer architecture for visual object recognition tasks. The main innovation of the framework is that it connects the sparse-encoders from different layers by a sparse-to-dense module. The sparse-to-dense module is a composition of a local spatial pooling step and a low-dimensional embedding process, which takes advantage of the spatial smoothness information in the image. As a result, the new method is able to learn several levels of sparse representation of the image which capture features at a variety of abstraction levels and simultaneously preserve the spatial smoothness between the neighboring image patches. Combining the feature representations from multiple layers, DeepSC achieves the state-of-the-art performance on multiple object recognition tasks.", "pdf": "https://arxiv.org/abs/1312.5783", "paperhash": "he|unsupervised_feature_learning_by_deep_sparse_coding", "keywords": [], "conflicts": [], "authors": ["Yunlong He", "Arthur Szlam", "Yanjun Qi", "Yun Wang", "Koray Kavukcuoglu"], "authorids": ["he.yunlong@gmail.com", "aszlam@ccny.cuny.edu", "yanjun@virginia.edu", "yunwang@princeton.edu", "koray@kavukcuoglu.org"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391824620000, "tcdate": 1391824620000, "number": 7, "id": "LSHWxogcsnSVZ", "invitation": "ICLR.cc/2014/-/submission/workshop/review", "forum": "X4tT4azdE1XkU", "replyto": "X4tT4azdE1XkU", "signatures": ["anonymous reviewer 1704"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Unsupervised Feature Learning by Deep Sparse Coding", "review": "This paper alternates sparse-to-dense (dimensionality reduction by learning an invariant mapping: DRLIM) and dense-to-sparse (standard sparse coding) modules to produce a multi-layer image representation of images. Compared to earlier deep image recognition architectures using sparse modules and pooling modules, the proposed system is more general and displays better performance on image recognition benchmarks.\r\n\r\nThe paper itself is clear and well-motivated. While none of the building blocks is new (DRLIM blocks, sparse coding blocks, etc), the combination is novel and works well.\r\n\r\nExperiments on Caltech 101, Caltech 256, and Scenes 15 show that the new architecture performs better than earlier versions without this sparse-to-dense mapping. These are bit limited now that better datasets are widely used (e.g., imagenet), but the experiments are interesting and show that the new system allows for deeper training without increasing the dimension of dictionary used for sparse coding. I think other researchers would be interested in these results.\r\n\r\nThere are a few writing problems (e.g. 'it is important to emphasis' instead of 'emphasize') so please spell check, but this does not hinder understanding. Also, it would be simpler to write 'First' rather than 'first of all' as is done in several places.\r\n\r\nOverall this paper presents a more principled variant for a deep image recognition architecture. The datasets used are limited but show that this system has promise."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Feature Learning by Deep Sparse Coding", "decision": "submitted, no decision", "abstract": "In this paper, we propose a new unsupervised feature learning framework, namely Deep Sparse Coding (DeepSC), that extends sparse coding to a multi-layer architecture for visual object recognition tasks. The main innovation of the framework is that it connects the sparse-encoders from different layers by a sparse-to-dense module. The sparse-to-dense module is a composition of a local spatial pooling step and a low-dimensional embedding process, which takes advantage of the spatial smoothness information in the image. As a result, the new method is able to learn several levels of sparse representation of the image which capture features at a variety of abstraction levels and simultaneously preserve the spatial smoothness between the neighboring image patches. Combining the feature representations from multiple layers, DeepSC achieves the state-of-the-art performance on multiple object recognition tasks.", "pdf": "https://arxiv.org/abs/1312.5783", "paperhash": "he|unsupervised_feature_learning_by_deep_sparse_coding", "keywords": [], "conflicts": [], "authors": ["Yunlong He", "Arthur Szlam", "Yanjun Qi", "Yun Wang", "Koray Kavukcuoglu"], "authorids": ["he.yunlong@gmail.com", "aszlam@ccny.cuny.edu", "yanjun@virginia.edu", "yunwang@princeton.edu", "koray@kavukcuoglu.org"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391824620000, "tcdate": 1391824620000, "number": 6, "id": "lcBTcK8gLGc6X", "invitation": "ICLR.cc/2014/-/submission/workshop/review", "forum": "X4tT4azdE1XkU", "replyto": "X4tT4azdE1XkU", "signatures": ["anonymous reviewer 1704"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Unsupervised Feature Learning by Deep Sparse Coding", "review": "This paper alternates sparse-to-dense (dimensionality reduction by learning an invariant mapping: DRLIM) and dense-to-sparse (standard sparse coding) modules to produce a multi-layer image representation of images. Compared to earlier deep image recognition architectures using sparse modules and pooling modules, the proposed system is more general and displays better performance on image recognition benchmarks.\r\n\r\nThe paper itself is clear and well-motivated. While none of the building blocks is new (DRLIM blocks, sparse coding blocks, etc), the combination is novel and works well.\r\n\r\nExperiments on Caltech 101, Caltech 256, and Scenes 15 show that the new architecture performs better than earlier versions without this sparse-to-dense mapping. These are bit limited now that better datasets are widely used (e.g., imagenet), but the experiments are interesting and show that the new system allows for deeper training without increasing the dimension of dictionary used for sparse coding. I think other researchers would be interested in these results.\r\n\r\nThere are a few writing problems (e.g. 'it is important to emphasis' instead of 'emphasize') so please spell check, but this does not hinder understanding. Also, it would be simpler to write 'First' rather than 'first of all' as is done in several places.\r\n\r\nOverall this paper presents a more principled variant for a deep image recognition architecture. The datasets used are limited but show that this system has promise."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Feature Learning by Deep Sparse Coding", "decision": "submitted, no decision", "abstract": "In this paper, we propose a new unsupervised feature learning framework, namely Deep Sparse Coding (DeepSC), that extends sparse coding to a multi-layer architecture for visual object recognition tasks. The main innovation of the framework is that it connects the sparse-encoders from different layers by a sparse-to-dense module. The sparse-to-dense module is a composition of a local spatial pooling step and a low-dimensional embedding process, which takes advantage of the spatial smoothness information in the image. As a result, the new method is able to learn several levels of sparse representation of the image which capture features at a variety of abstraction levels and simultaneously preserve the spatial smoothness between the neighboring image patches. Combining the feature representations from multiple layers, DeepSC achieves the state-of-the-art performance on multiple object recognition tasks.", "pdf": "https://arxiv.org/abs/1312.5783", "paperhash": "he|unsupervised_feature_learning_by_deep_sparse_coding", "keywords": [], "conflicts": [], "authors": ["Yunlong He", "Arthur Szlam", "Yanjun Qi", "Yun Wang", "Koray Kavukcuoglu"], "authorids": ["he.yunlong@gmail.com", "aszlam@ccny.cuny.edu", "yanjun@virginia.edu", "yunwang@princeton.edu", "koray@kavukcuoglu.org"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391824500000, "tcdate": 1391824500000, "number": 4, "id": "XKgURjkon2Xoa", "invitation": "ICLR.cc/2014/-/submission/workshop/review", "forum": "X4tT4azdE1XkU", "replyto": "X4tT4azdE1XkU", "signatures": ["anonymous reviewer 1704"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Unsupervised Feature Learning by Deep Sparse Coding", "review": "Unsup feature learning by deep sparse coding\r\n\r\nThis paper alternates sparse-to-dense (dimensionality reduction by learning an invariant mapping: DRLIM) and dense-to-sparse (standard sparse coding) modules to produce a multi-layer image representation of images. Compared to earlier deep image recognition architectures using sparse modules and pooling modules, the proposed system is more general and displays better performance on image recognition benchmarks.\r\n\r\nThe paper itself is clear and well-motivated. While none of the building blocks is new (DRLIM blocks, sparse coding blocks, etc), the combination is novel and works well.\r\n\r\nExperiments on Caltech 101, Caltech 256, and Scenes 15 show that the new architecture performs better than earlier versions without this sparse-to-dense mapping. These are bit limited now that better datasets are widely used (e.g., imagenet), but the experiments are interesting and show that the new system allows for deeper training without increasing the dimension of dictionary used for sparse coding. I think other researchers would be interested in these results.\r\n\r\nThere are a few writing problems (e.g. 'it is important to emphasis' instead of 'emphasize') so please spell check, but this does not hinder understanding. Also, it would be simpler to write 'First' rather than 'first of all' as is done in several places.\r\n\r\nOverall this paper presents a more principled variant for a deep image recognition architecture. The datasets used are limited but show that this system has promise."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Feature Learning by Deep Sparse Coding", "decision": "submitted, no decision", "abstract": "In this paper, we propose a new unsupervised feature learning framework, namely Deep Sparse Coding (DeepSC), that extends sparse coding to a multi-layer architecture for visual object recognition tasks. The main innovation of the framework is that it connects the sparse-encoders from different layers by a sparse-to-dense module. The sparse-to-dense module is a composition of a local spatial pooling step and a low-dimensional embedding process, which takes advantage of the spatial smoothness information in the image. As a result, the new method is able to learn several levels of sparse representation of the image which capture features at a variety of abstraction levels and simultaneously preserve the spatial smoothness between the neighboring image patches. Combining the feature representations from multiple layers, DeepSC achieves the state-of-the-art performance on multiple object recognition tasks.", "pdf": "https://arxiv.org/abs/1312.5783", "paperhash": "he|unsupervised_feature_learning_by_deep_sparse_coding", "keywords": [], "conflicts": [], "authors": ["Yunlong He", "Arthur Szlam", "Yanjun Qi", "Yun Wang", "Koray Kavukcuoglu"], "authorids": ["he.yunlong@gmail.com", "aszlam@ccny.cuny.edu", "yanjun@virginia.edu", "yunwang@princeton.edu", "koray@kavukcuoglu.org"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391824500000, "tcdate": 1391824500000, "number": 3, "id": "kP1cPmbAG4825", "invitation": "ICLR.cc/2014/-/submission/workshop/review", "forum": "X4tT4azdE1XkU", "replyto": "X4tT4azdE1XkU", "signatures": ["anonymous reviewer 1704"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Unsupervised Feature Learning by Deep Sparse Coding", "review": "Unsup feature learning by deep sparse coding\r\n\r\nThis paper alternates sparse-to-dense (dimensionality reduction by learning an invariant mapping: DRLIM) and dense-to-sparse (standard sparse coding) modules to produce a multi-layer image representation of images. Compared to earlier deep image recognition architectures using sparse modules and pooling modules, the proposed system is more general and displays better performance on image recognition benchmarks.\r\n\r\nThe paper itself is clear and well-motivated. While none of the building blocks is new (DRLIM blocks, sparse coding blocks, etc), the combination is novel and works well.\r\n\r\nExperiments on Caltech 101, Caltech 256, and Scenes 15 show that the new architecture performs better than earlier versions without this sparse-to-dense mapping. These are bit limited now that better datasets are widely used (e.g., imagenet), but the experiments are interesting and show that the new system allows for deeper training without increasing the dimension of dictionary used for sparse coding. I think other researchers would be interested in these results.\r\n\r\nThere are a few writing problems (e.g. 'it is important to emphasis' instead of 'emphasize') so please spell check, but this does not hinder understanding. Also, it would be simpler to write 'First' rather than 'first of all' as is done in several places.\r\n\r\nOverall this paper presents a more principled variant for a deep image recognition architecture. The datasets used are limited but show that this system has promise."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Feature Learning by Deep Sparse Coding", "decision": "submitted, no decision", "abstract": "In this paper, we propose a new unsupervised feature learning framework, namely Deep Sparse Coding (DeepSC), that extends sparse coding to a multi-layer architecture for visual object recognition tasks. The main innovation of the framework is that it connects the sparse-encoders from different layers by a sparse-to-dense module. The sparse-to-dense module is a composition of a local spatial pooling step and a low-dimensional embedding process, which takes advantage of the spatial smoothness information in the image. As a result, the new method is able to learn several levels of sparse representation of the image which capture features at a variety of abstraction levels and simultaneously preserve the spatial smoothness between the neighboring image patches. Combining the feature representations from multiple layers, DeepSC achieves the state-of-the-art performance on multiple object recognition tasks.", "pdf": "https://arxiv.org/abs/1312.5783", "paperhash": "he|unsupervised_feature_learning_by_deep_sparse_coding", "keywords": [], "conflicts": [], "authors": ["Yunlong He", "Arthur Szlam", "Yanjun Qi", "Yun Wang", "Koray Kavukcuoglu"], "authorids": ["he.yunlong@gmail.com", "aszlam@ccny.cuny.edu", "yanjun@virginia.edu", "yunwang@princeton.edu", "koray@kavukcuoglu.org"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391824440000, "tcdate": 1391824440000, "number": 2, "id": "PP0zWn2N3DPOl", "invitation": "ICLR.cc/2014/-/submission/workshop/review", "forum": "X4tT4azdE1XkU", "replyto": "X4tT4azdE1XkU", "signatures": ["anonymous reviewer 1704"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Unsupervised Feature Learning by Deep Sparse Coding", "review": "Unsup feature learning by deep sparse coding\r\n\r\nThis paper alternates sparse-to-dense (dimensionality reduction by learning an invariant mapping: DRLIM) and dense-to-sparse (standard sparse coding) modules to produce a multi-layer image representation of images. Compared to earlier deep image recognition architectures using sparse modules and pooling modules, the proposed system is more general and displays better performance on image recognition benchmarks.\r\n\r\nThe paper itself is clear and well-motivated. While none of the building blocks is new (DRLIM blocks, sparse coding blocks, etc), the combination is novel and works well.\r\n\r\nExperiments on Caltech 101, Caltech 256, and Scenes 15 show that the new architecture performs better than earlier versions without this sparse-to-dense mapping. These are bit limited now that better datasets are widely used (e.g., imagenet), but the experiments are interesting and show that the new system allows for deeper training without increasing the dimension of dictionary used for sparse coding. I think other researchers would be interested in these results.\r\n\r\nThere are a few writing problems (e.g. 'it is important to emphasis' instead of 'emphasize') so please spell check, but this does not hinder understanding. Also, it would be simpler to write 'First' rather than 'first of all' as is done in several places.\r\n\r\nOverall this paper presents a more principled variant for a deep image recognition architecture. The datasets used are limited but show that this system has promise."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Feature Learning by Deep Sparse Coding", "decision": "submitted, no decision", "abstract": "In this paper, we propose a new unsupervised feature learning framework, namely Deep Sparse Coding (DeepSC), that extends sparse coding to a multi-layer architecture for visual object recognition tasks. The main innovation of the framework is that it connects the sparse-encoders from different layers by a sparse-to-dense module. The sparse-to-dense module is a composition of a local spatial pooling step and a low-dimensional embedding process, which takes advantage of the spatial smoothness information in the image. As a result, the new method is able to learn several levels of sparse representation of the image which capture features at a variety of abstraction levels and simultaneously preserve the spatial smoothness between the neighboring image patches. Combining the feature representations from multiple layers, DeepSC achieves the state-of-the-art performance on multiple object recognition tasks.", "pdf": "https://arxiv.org/abs/1312.5783", "paperhash": "he|unsupervised_feature_learning_by_deep_sparse_coding", "keywords": [], "conflicts": [], "authors": ["Yunlong He", "Arthur Szlam", "Yanjun Qi", "Yun Wang", "Koray Kavukcuoglu"], "authorids": ["he.yunlong@gmail.com", "aszlam@ccny.cuny.edu", "yanjun@virginia.edu", "yunwang@princeton.edu", "koray@kavukcuoglu.org"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1390861140000, "tcdate": 1390861140000, "number": 1, "id": "ttigSsrO9_tD7", "invitation": "ICLR.cc/2014/-/submission/workshop/review", "forum": "X4tT4azdE1XkU", "replyto": "X4tT4azdE1XkU", "signatures": ["anonymous reviewer 6331"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Unsupervised Feature Learning by Deep Sparse Coding", "review": "The paper presents a cascaded architecture that successively transforms an input representation into a sparse code, and then transforms the sparse code into a compact dense representation, making sure adjacent patches get similar dense representations. The resulting representations are passed through a spatial pyramid pooling mechanism and concatenated, and then fed to a linear SVM to learn to classify images. This architecture achieves better or similar results to other sparse coding approaches on 3 small image datasets. The paper reads quite well (the first introductory sections are really nice summary of past work in the sparse coding and dimensionality reduction domains). I like the idea of making sure that two sparse codes encoding overlapping regions should have a similar dense code. That said, I wonder why we need to use intermediate representations as input to the final SVM, and not just the last layer. I found section 3.3 less interesting as it was an obvious result (to me at least), and section 3.4 daunting as it meant two more hyper-parameters to tune in our lives... Overall, I liked the paper and would have liked to see results on one larger image dataset: the caltech-xxx datasets are quite outdated, and I'm worried results would not scale to larger and more recent datasets."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised Feature Learning by Deep Sparse Coding", "decision": "submitted, no decision", "abstract": "In this paper, we propose a new unsupervised feature learning framework, namely Deep Sparse Coding (DeepSC), that extends sparse coding to a multi-layer architecture for visual object recognition tasks. The main innovation of the framework is that it connects the sparse-encoders from different layers by a sparse-to-dense module. The sparse-to-dense module is a composition of a local spatial pooling step and a low-dimensional embedding process, which takes advantage of the spatial smoothness information in the image. As a result, the new method is able to learn several levels of sparse representation of the image which capture features at a variety of abstraction levels and simultaneously preserve the spatial smoothness between the neighboring image patches. Combining the feature representations from multiple layers, DeepSC achieves the state-of-the-art performance on multiple object recognition tasks.", "pdf": "https://arxiv.org/abs/1312.5783", "paperhash": "he|unsupervised_feature_learning_by_deep_sparse_coding", "keywords": [], "conflicts": [], "authors": ["Yunlong He", "Arthur Szlam", "Yanjun Qi", "Yun Wang", "Koray Kavukcuoglu"], "authorids": ["he.yunlong@gmail.com", "aszlam@ccny.cuny.edu", "yanjun@virginia.edu", "yunwang@princeton.edu", "koray@kavukcuoglu.org"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1387787160000, "tcdate": 1387787160000, "number": 7, "id": "X4tT4azdE1XkU", "invitation": "ICLR.cc/2014/workshop/-/submission", "forum": "X4tT4azdE1XkU", "signatures": ["he.yunlong@gmail.com"], "readers": ["everyone"], "content": {"title": "Unsupervised Feature Learning by Deep Sparse Coding", "decision": "submitted, no decision", "abstract": "In this paper, we propose a new unsupervised feature learning framework, namely Deep Sparse Coding (DeepSC), that extends sparse coding to a multi-layer architecture for visual object recognition tasks. The main innovation of the framework is that it connects the sparse-encoders from different layers by a sparse-to-dense module. The sparse-to-dense module is a composition of a local spatial pooling step and a low-dimensional embedding process, which takes advantage of the spatial smoothness information in the image. As a result, the new method is able to learn several levels of sparse representation of the image which capture features at a variety of abstraction levels and simultaneously preserve the spatial smoothness between the neighboring image patches. Combining the feature representations from multiple layers, DeepSC achieves the state-of-the-art performance on multiple object recognition tasks.", "pdf": "https://arxiv.org/abs/1312.5783", "paperhash": "he|unsupervised_feature_learning_by_deep_sparse_coding", "keywords": [], "conflicts": [], "authors": ["Yunlong He", "Arthur Szlam", "Yanjun Qi", "Yun Wang", "Koray Kavukcuoglu"], "authorids": ["he.yunlong@gmail.com", "aszlam@ccny.cuny.edu", "yanjun@virginia.edu", "yunwang@princeton.edu", "koray@kavukcuoglu.org"]}, "writers": [], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496674357014, "id": "ICLR.cc/2014/workshop/-/submission", "writers": ["ICLR.cc/2014"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717, "cdate": 1496674357014}}}], "count": 8}