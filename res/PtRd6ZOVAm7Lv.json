{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1392737640000, "tcdate": 1392737640000, "number": 1, "id": "qq1NUprOkGxvM", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "PtRd6ZOVAm7Lv", "replyto": "3aJi3mtYiya_u", "signatures": ["Wiktor M\u0142ynarski"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Thank you for your review and comments.\r\n\r\nIf one thinks about the analytic form of complex valued basis functions (such as a complex Gabor, for instance) then real and imaginary vectors indeed form Hilbert pairs. However, the sparse complex valued coding model does not make this assumption in any way. It attempts to represent the data as a linear combination of pairs of vectors which span 2-dimensional subspaces while making the amplitudes sparse and independent. No prior assumptions on the form of vectors is made. In case of natural images, the phase invariance emerges 'for free', as a reflection of the data statistics. In other signal domains it is not necessarily the case, as the present work shows.\r\n\r\nThe optimization algorithm seems to be working correctly. Polar and cartesian coordinates are after all equivalent data descriptions. Additionally, these results are not the first ones which observe that complex valued basis functions learned on natural sounds are not phase invariant (please, see the response to the first review). As a control experiment I have learned a complex dictionary without priors from natural images (new figure 5 C). Results do not qualitatively differ from previously obtained, which suggests that the algorithm works properly.\r\n\r\nThe phase slowness prior is a non-dominating penalty term, scaled by the gamma parameter, which is smaller than 1. If higher frequencies are present in the data, they will be captured, and the prior will only bias basis functions towards ones with the smoothly changing phase (of constant frequency). As the results show - this is what happens. One can interpret this prior as a penalty of variance of the temporal derivative [26]. In such interpretation it becomes more clear that all frequencies are allowed. I have added an exploanatory sentence in the text.\r\n\r\nRegarding the time-frequency tiling. I am not fully sure what would 'make sense' - the obtained result is a representation learned from the data. The arches reflect temporal frequency variation of the basis functions (see figure 1 B, second row - phases are monotonic, but rather piecewise linear functions of time). A possible explanation is that real and imaginary vectors tend to diverge from each other (as in the unconstrained model), but the prior forces them to stay close on the time frequency plane. I have commented on that in the new version.\r\n\r\nAs mentioned in the text, subspace-based models (such as complex sparse coding) learn invariances, which can not be captured by the linear models you mention. Having a phase invariant representation allows to separate amplitude and phase information, which can not be done using a linear sparse coding algorithm (at least not easily). In tasks such as sound localization, separation of these parameters is crucial. As the introduction and conclusions section discuss, learned dictionaries are adapted to the data and at the same time make explicit aspects which are not captured by simpler models. From my point of view, this is the most important gain."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Sparse, complex-valued representations of natural sounds learned with phase and amplitude continuity priors", "decision": "submitted, no decision", "abstract": "Complex-valued sparse coding is a data representation which employs a dictionary of two-dimensional subspaces, while imposing a sparse, factorial prior on complex amplitudes. When trained on a dataset of natural image patches, it learns phase invariant features which closely resemble receptive fields of complex cells in the visual cortex. Features trained on natural sounds however, rarely reveal phase invariance and capture other aspects of the data. This observation is a starting point of the present work. As its first contribution, it provides an analysis of natural sound statistics by means of learning sparse, complex representations of short speech intervals. Secondly, it proposes priors over the basis function set, which bias them towards phase-invariant solutions. In this way, a dictionary of complex basis functions can be learned from the data statistics, while preserving the phase invariance property. Finally, representations trained on speech sounds with and without priors are compared. Prior-based basis functions reveal performance comparable to unconstrained sparse coding, while explicitly representing phase as a temporal shift. Such representations can find applications in many perceptual and machine learning tasks.", "pdf": "https://arxiv.org/abs/1312.4695", "paperhash": "mlynarski|sparse_complexvalued_representations_of_natural_sounds_learned_with_phase_and_amplitude_continuity_priors", "authors": ["Wiktor Mlynarski"], "authorids": ["mlynar@mis.mpg.de"], "keywords": [], "conflicts": []}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392737580000, "tcdate": 1392737580000, "number": 1, "id": "VzhSziEbS7fbY", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "PtRd6ZOVAm7Lv", "replyto": "GdpzZnQU7qG5f", "signatures": ["Wiktor M\u0142ynarski"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Thank you for your comments and suggestions.\r\n\r\nFirstly, I agree that the paper does not introduce any fundamentally novel method. What may be considered as technical novelties are:\r\n\r\n- the fact that priors are placed on basis functions \r\n- smoothness priors are placed on both: phases and amplitudes (Cadieu et al, penalized only amplitude dynamics, not phase)\r\n- an additional term in the phase penalty, which enforces it's monotonicity.\r\n\r\nThe purpouse of the paper was not, however to introduce a novel method - it was to learn representations of a certain class of signals (natural sounds) and to study the properties of obtained features. Such representations may find applications in tasks which operate on sound data.\r\nThat is why I do not think that the present paper should be directly compared with the hierarchical model introduced by Cadieu et al. especially in the context of a method novelty. Cadieu and Olshausen, constructed a hierarchical representation of natural videos with a purpouse of extracting motion invariances. The present paper learns single layer representations of natural sounds - this is a fundamental difference.\r\n\r\nIt is an interesting question, in which (statistical) sense sounds are different from images (please, see my response to the previous review). After all, physcially they are very different stimuli. Suggested by the results presented in [21, 22] I have introduced a brief analysis of harmonic relationships between real and imaginary vectors. A full answer to that problem requires extensive research.\r\n\r\nI have performed two kinds of quantitative analysis: denoising and comparison of coefficient entropies. The analysis was performed as in cited literature [14, 28]. Due to the space constraints I have not presented more details. Personally, I find presented results conclusive. The work by Karklin et al you cite analyzed the learned representation also by performing a denoising task. I do not fully understand, how should I compare the present study to their results, as you suggest.\r\n\r\nI understand that by compression experiment you mean the comparison of coefficient entropies. Of course, a trivial solution would be a basis set which yields 0 entropies, while not being able to reconstruct the data at all (an 'infinite' reconstruction error). As the denoising experiment shows, this is not the case for any of the learned bases. Entropy estimates give therefore an idea of a relative coding cost, and according to Shannon's source coding theorem, the model yielding the lowest coding cost is closest to the true data distribution. For a detailed discussion please refer to [14, 15]. The entropy values should be considered together with the denoising performance.\r\n\r\nBounding the phase derivative from below is also a possible way to enforce the phase monotonicity. However, it would require introduction of another parameter - the bound itself. The proposed prior does not require any additional parametrization. I have modified the description of equation 9 to address your suggestion.\r\n\r\nFor convenience, gamma and beta lie in the [0, 1] interval. The gradient moduli (before multiplying by gamma, beta and the step size) can be much larger than 1. In such a case, prior strength parameters affect the gradient step very weakly. That is why gradient terms are firstly normalized to have the same length, and then multiplied by gamma and beta."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Sparse, complex-valued representations of natural sounds learned with phase and amplitude continuity priors", "decision": "submitted, no decision", "abstract": "Complex-valued sparse coding is a data representation which employs a dictionary of two-dimensional subspaces, while imposing a sparse, factorial prior on complex amplitudes. When trained on a dataset of natural image patches, it learns phase invariant features which closely resemble receptive fields of complex cells in the visual cortex. Features trained on natural sounds however, rarely reveal phase invariance and capture other aspects of the data. This observation is a starting point of the present work. As its first contribution, it provides an analysis of natural sound statistics by means of learning sparse, complex representations of short speech intervals. Secondly, it proposes priors over the basis function set, which bias them towards phase-invariant solutions. In this way, a dictionary of complex basis functions can be learned from the data statistics, while preserving the phase invariance property. Finally, representations trained on speech sounds with and without priors are compared. Prior-based basis functions reveal performance comparable to unconstrained sparse coding, while explicitly representing phase as a temporal shift. Such representations can find applications in many perceptual and machine learning tasks.", "pdf": "https://arxiv.org/abs/1312.4695", "paperhash": "mlynarski|sparse_complexvalued_representations_of_natural_sounds_learned_with_phase_and_amplitude_continuity_priors", "authors": ["Wiktor Mlynarski"], "authorids": ["mlynar@mis.mpg.de"], "keywords": [], "conflicts": []}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392737520000, "tcdate": 1392737520000, "number": 1, "id": "__7eb-mkwrzUv", "invitation": "ICLR.cc/2014/-/submission/conference/reply", "forum": "PtRd6ZOVAm7Lv", "replyto": "PgiHEe9RnQgSt", "signatures": ["Wiktor M\u0142ynarski"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "reply": "Thank you for your review and interesting comments. In a new paper version I have introduced suggested modifications and related to points you make.\r\n\r\nAs you mention, the results of training complex-valued sparse codes on natural sounds can be unexpected if one keeps the intuition from natural image statistics. One of the main messages of the paper is that this intuition does not necessarily translate between signal domains. This perhaps should not be very surprising, after all those signals arise as a result of fundamentally different physical processes. This is not the first paper which observes that same statistical models trained on natural sounds and images yield different results [22, 25] (please note that I use literature indexing according to the newest version of the paper). \r\n\r\nIt has been suggested that statistical models (such as topographic ICA, which is closely related to complex valued sparse coding) capture non-local cross-frequency correlations of natural sounds [21, 22]. Correlations of natural image patches are local, and that is why dictionaries trained on those two signals reveal very different structure. In the new version of the paper, I have included analysis of harmonic relationships between peaks of the basis function spectra. This may be an initial explanation why learned basis functions are not phase invariant and have different frequency peaks in their real and imaginary parts.\r\n\r\nIt would be hard to perform the comparison of results obtained on images and sounds. Priors introduced here are defined over one-dimensional temporal domain and are placed on basis functions. When learning natural image representations, basis functions capture spatial, not temporal relationships. Additionally they are two-dimensional, therefore the 'temporal slowness' penalty should be transformed into 'spatial smoothness' penalty and the relationship between those is non-obvious. Differences between images and sounds are, however not a fundamental focus of the current paper - it is the learning of sound representations. As a control experiment, I ran the unconstrained algorithm also on natural images. Resulting exemplary basis functions are now depicted on figure 5 C.\r\n\r\nNon-penalized basis functions form most probably a more efficient representation of the data. This can be inferred by looking at their performance in a denoising task and coefficient entropies. I have performed the experiment you suggested (using penalized basis as initial conditions for non-penalized learning) and included the results in the new version. After 30000 iterations of learning without smoothness priors, phase invariant basis functions deviate from the quadrature pair form (see new figure 5 A and B). This suggests that quadrature solutions do not constitute better local optima than unconstrained ones. As an additional control experiment I have learned a complex dictionary without priors from natural images (new figure 5 C). Results do not qualitatively differ from previously obtained.\r\n\r\nI also understand your concern regarding the use of speech as a proxy for general natural sounds. As long as speech does not include all possible acoustic structures present in the auditory environment, it contains both harmonic and non-harmonic features. Speech has been used before as a natural sound representation [1,5,13,19] and for those reasons I decided to used it here. Results obtained using different classes of natural sounds yield qualitatitvely similar results, and they were not included for simplicity and because of space constraints.\r\n\r\nI have also corrected a number of typos in the new version."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Sparse, complex-valued representations of natural sounds learned with phase and amplitude continuity priors", "decision": "submitted, no decision", "abstract": "Complex-valued sparse coding is a data representation which employs a dictionary of two-dimensional subspaces, while imposing a sparse, factorial prior on complex amplitudes. When trained on a dataset of natural image patches, it learns phase invariant features which closely resemble receptive fields of complex cells in the visual cortex. Features trained on natural sounds however, rarely reveal phase invariance and capture other aspects of the data. This observation is a starting point of the present work. As its first contribution, it provides an analysis of natural sound statistics by means of learning sparse, complex representations of short speech intervals. Secondly, it proposes priors over the basis function set, which bias them towards phase-invariant solutions. In this way, a dictionary of complex basis functions can be learned from the data statistics, while preserving the phase invariance property. Finally, representations trained on speech sounds with and without priors are compared. Prior-based basis functions reveal performance comparable to unconstrained sparse coding, while explicitly representing phase as a temporal shift. Such representations can find applications in many perceptual and machine learning tasks.", "pdf": "https://arxiv.org/abs/1312.4695", "paperhash": "mlynarski|sparse_complexvalued_representations_of_natural_sounds_learned_with_phase_and_amplitude_continuity_priors", "authors": ["Wiktor Mlynarski"], "authorids": ["mlynar@mis.mpg.de"], "keywords": [], "conflicts": []}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392193380000, "tcdate": 1392193380000, "number": 3, "id": "3aJi3mtYiya_u", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "PtRd6ZOVAm7Lv", "replyto": "PtRd6ZOVAm7Lv", "signatures": ["anonymous reviewer 01ce"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Sparse, complex-valued representations of natural sounds learned with phase and amplitude continuity priors", "review": "This paper shows that imposing a prior over the basis functions in a complex representation of sound results in bases that are closer to hilbert pairs, with smooth amplitude envelope and linear phase precession.  \r\n\r\nIt is not clear why imposing the prior directly on the basis functions is necessary.  If you  think of the complex pair as a phase-shiftable basis function, then it would make sense for the real and imaginary parts to be related by hilbert transform.  It makes me wonder whether the optimization was done correctly in inferring the sparse amplitudes - I.e., the phase must be allowed to steer to the optimal position, yielding a sparse representation.  It appears the gradients were computed with respect to the real and imaginary parts of the coefficients, rather than the amplitude and phase, which may be why the phase is not being properly  inferred.\r\n\r\nThe slowness prior on the phase doesn't make sense  - this would bias the bases toward low frequencies, no?   Some comment seems warranted.\r\n\r\nThe learned tiling in time-frequency doesn't make much sense.  What is causing the arching pattern?  It's not clear.\r\n\r\nMost of all, it's not clear what we gain from this representation beyond previous attempts to learn a sparse representation of sound (Smith & Lewicki).  It would have been nice to compare coding efficiency and so forth against a purely real (vs. complex) representation."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Sparse, complex-valued representations of natural sounds learned with phase and amplitude continuity priors", "decision": "submitted, no decision", "abstract": "Complex-valued sparse coding is a data representation which employs a dictionary of two-dimensional subspaces, while imposing a sparse, factorial prior on complex amplitudes. When trained on a dataset of natural image patches, it learns phase invariant features which closely resemble receptive fields of complex cells in the visual cortex. Features trained on natural sounds however, rarely reveal phase invariance and capture other aspects of the data. This observation is a starting point of the present work. As its first contribution, it provides an analysis of natural sound statistics by means of learning sparse, complex representations of short speech intervals. Secondly, it proposes priors over the basis function set, which bias them towards phase-invariant solutions. In this way, a dictionary of complex basis functions can be learned from the data statistics, while preserving the phase invariance property. Finally, representations trained on speech sounds with and without priors are compared. Prior-based basis functions reveal performance comparable to unconstrained sparse coding, while explicitly representing phase as a temporal shift. Such representations can find applications in many perceptual and machine learning tasks.", "pdf": "https://arxiv.org/abs/1312.4695", "paperhash": "mlynarski|sparse_complexvalued_representations_of_natural_sounds_learned_with_phase_and_amplitude_continuity_priors", "authors": ["Wiktor Mlynarski"], "authorids": ["mlynar@mis.mpg.de"], "keywords": [], "conflicts": []}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391729460000, "tcdate": 1391729460000, "number": 2, "id": "GdpzZnQU7qG5f", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "PtRd6ZOVAm7Lv", "replyto": "PtRd6ZOVAm7Lv", "signatures": ["anonymous reviewer 92c8"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Sparse, complex-valued representations of natural sounds learned with phase and amplitude continuity priors", "review": "A sparse coding model of natural sounds (speech) is proposed. The signal is represented by a complex sparse coding problem with smoothness priors on both amplitude and phase. Learning and inference proceeds as in standard sparse coding. The method is analyzed in terms of statistics of complex pairs filters as well as denoising.\r\n\r\nThe method is not very novel. Complex sparse coding was already introduced in the past and the sparsity priors on the amplitudes and coefficients are a straightforward extension (or simplification compared to the work by Cadieu et al.).\r\n\r\nPros:\r\n- interesting application\r\n- fairly clear written paper\r\n\r\nCons:\r\n- insights may be good but I probably did not fully understood them. Why are sounds inherently different from images? Is it an artifact of how the experimental set up? Without sparsity/smoothness constraints, the problem is clearly underdetermined and therefore filters do not necessarily converge to quadrature pairs.\r\n- what is the contribution of this work compared to Cadieu et al? They had an extra layer, but the basic idea of smoothness of phase and amplitude is present also in that work.\r\n- empirical validation is not sufficient because:\r\n  - more quantitative results would be beneficial to assess the benefits of this model. For instance, the authors may want to compare and cite:\r\nY. Karklin, C. Ekanadham, and E. P. Simoncelli, Hierarchical spike coding of sound, Adv in Neural Information Processing Systems (NIPS), 2012\r\n- some parts need clarification\r\n  - eq. 9: why is this a good choice? wouldn\u2019t it be better to have it bounded below?\r\n   - sec. 2.2 why rescaling the gradients when there are beta and gamma?\r\n   - in the compression experiment, shouldn\u2019t the reconstruction error be taken into account?\r\n\r\nOverall, this is interesting work. However, several clarifications are required in order to better assess novelty and to understand the method. Also, the empirical validation should be strengthened."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Sparse, complex-valued representations of natural sounds learned with phase and amplitude continuity priors", "decision": "submitted, no decision", "abstract": "Complex-valued sparse coding is a data representation which employs a dictionary of two-dimensional subspaces, while imposing a sparse, factorial prior on complex amplitudes. When trained on a dataset of natural image patches, it learns phase invariant features which closely resemble receptive fields of complex cells in the visual cortex. Features trained on natural sounds however, rarely reveal phase invariance and capture other aspects of the data. This observation is a starting point of the present work. As its first contribution, it provides an analysis of natural sound statistics by means of learning sparse, complex representations of short speech intervals. Secondly, it proposes priors over the basis function set, which bias them towards phase-invariant solutions. In this way, a dictionary of complex basis functions can be learned from the data statistics, while preserving the phase invariance property. Finally, representations trained on speech sounds with and without priors are compared. Prior-based basis functions reveal performance comparable to unconstrained sparse coding, while explicitly representing phase as a temporal shift. Such representations can find applications in many perceptual and machine learning tasks.", "pdf": "https://arxiv.org/abs/1312.4695", "paperhash": "mlynarski|sparse_complexvalued_representations_of_natural_sounds_learned_with_phase_and_amplitude_continuity_priors", "authors": ["Wiktor Mlynarski"], "authorids": ["mlynar@mis.mpg.de"], "keywords": [], "conflicts": []}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391478120000, "tcdate": 1391478120000, "number": 1, "id": "PgiHEe9RnQgSt", "invitation": "ICLR.cc/2014/-/submission/conference/review", "forum": "PtRd6ZOVAm7Lv", "replyto": "PtRd6ZOVAm7Lv", "signatures": ["anonymous reviewer 69a6"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Sparse, complex-valued representations of natural sounds learned with phase and amplitude continuity priors", "review": "The paper describes a sparse coding model with complex valued basis functions. For training, it proposes to minimize reconstruction error plus penalty terms that encourage the amplitudes and phases of the basis functions to be smooth.\r\n\r\nAt first sight the model seems reminiscent of Cadieu, Olshausen (2012) [4]. But in that work, it is the coefficients that are penalized to have smooth amplitudes over time, whereas here, it is the basis functions themselves that are penalized to be smooth.\r\n\r\nThe model is applied to time-domain speech signals (one-dimensional data). The paper compares the results of complex valued sparse coding with smoothness penalties versus complex valued sparse coding without. The comparison shows that with penalties, basis functions seem to be more localized and filters within a pair tend to have quadrature relations.\r\n\r\nWithout penalties they do not seem to. I find this somewhat surprising because I would have thought that minimizing reconstruction error (plus orthonormalizing filters within each pair as suggested) would already achieve this, like it does in the case of images. The paper does suggest that sound data is fundamentally different from image data. I am curious what it is about sound data that causes it to require this extra machinery for learning complex basis functions. It would be very good to have actual results on images as a control.  This would also help disentangle two topics that are hard to separate in the paper, which are 1) fundamental  differences in sound data versus image data, and 2) learning complex bases with and without smoothness penalties.\r\n\r\nI am wondering in what way the smoothness penalties are related to weight decay, or in what way they may just help find better local optima. It seems like this would be easy to check by initializing model A (no penalties) with model B (with penalties).\r\n\r\nThe title says 'natural sounds' but as far as I can tell, all experiments were done on a speech dataset. I'm not sure I completely agree with the statement that speech is a good enough proxy for natural sounds in general.\r\n\r\nThere are a lot of typos (e.g., 'Gramm-Schmidt', 'strucutre', 'analyzis')."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Sparse, complex-valued representations of natural sounds learned with phase and amplitude continuity priors", "decision": "submitted, no decision", "abstract": "Complex-valued sparse coding is a data representation which employs a dictionary of two-dimensional subspaces, while imposing a sparse, factorial prior on complex amplitudes. When trained on a dataset of natural image patches, it learns phase invariant features which closely resemble receptive fields of complex cells in the visual cortex. Features trained on natural sounds however, rarely reveal phase invariance and capture other aspects of the data. This observation is a starting point of the present work. As its first contribution, it provides an analysis of natural sound statistics by means of learning sparse, complex representations of short speech intervals. Secondly, it proposes priors over the basis function set, which bias them towards phase-invariant solutions. In this way, a dictionary of complex basis functions can be learned from the data statistics, while preserving the phase invariance property. Finally, representations trained on speech sounds with and without priors are compared. Prior-based basis functions reveal performance comparable to unconstrained sparse coding, while explicitly representing phase as a temporal shift. Such representations can find applications in many perceptual and machine learning tasks.", "pdf": "https://arxiv.org/abs/1312.4695", "paperhash": "mlynarski|sparse_complexvalued_representations_of_natural_sounds_learned_with_phase_and_amplitude_continuity_priors", "authors": ["Wiktor Mlynarski"], "authorids": ["mlynar@mis.mpg.de"], "keywords": [], "conflicts": []}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1387382640000, "tcdate": 1387382640000, "number": 6, "id": "PtRd6ZOVAm7Lv", "invitation": "ICLR.cc/2014/conference/-/submission", "forum": "PtRd6ZOVAm7Lv", "signatures": ["mlynar@mis.mpg.de"], "readers": ["everyone"], "content": {"title": "Sparse, complex-valued representations of natural sounds learned with phase and amplitude continuity priors", "decision": "submitted, no decision", "abstract": "Complex-valued sparse coding is a data representation which employs a dictionary of two-dimensional subspaces, while imposing a sparse, factorial prior on complex amplitudes. When trained on a dataset of natural image patches, it learns phase invariant features which closely resemble receptive fields of complex cells in the visual cortex. Features trained on natural sounds however, rarely reveal phase invariance and capture other aspects of the data. This observation is a starting point of the present work. As its first contribution, it provides an analysis of natural sound statistics by means of learning sparse, complex representations of short speech intervals. Secondly, it proposes priors over the basis function set, which bias them towards phase-invariant solutions. In this way, a dictionary of complex basis functions can be learned from the data statistics, while preserving the phase invariance property. Finally, representations trained on speech sounds with and without priors are compared. Prior-based basis functions reveal performance comparable to unconstrained sparse coding, while explicitly representing phase as a temporal shift. Such representations can find applications in many perceptual and machine learning tasks.", "pdf": "https://arxiv.org/abs/1312.4695", "paperhash": "mlynarski|sparse_complexvalued_representations_of_natural_sounds_learned_with_phase_and_amplitude_continuity_priors", "authors": ["Wiktor Mlynarski"], "authorids": ["mlynar@mis.mpg.de"], "keywords": [], "conflicts": []}, "writers": [], "details": {"replyCount": 6, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496674357195, "id": "ICLR.cc/2014/conference/-/submission", "writers": ["ICLR.cc/2014"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717, "cdate": 1496674357195}}}], "count": 7}