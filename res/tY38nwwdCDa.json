{"notes": [{"id": "tY38nwwdCDa", "original": "uQ8BWbTax6w", "number": 308, "cdate": 1601308042093, "ddate": null, "tcdate": 1601308042093, "tmdate": 1614985621867, "tddate": null, "forum": "tY38nwwdCDa", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "USING OBJECT-FOCUSED IMAGES AS AN IMAGE AUGMENTATION TECHNIQUE TO IMPROVE THE ACCURACY OF IMAGE-CLASSIFICATION MODELS WHEN VERY LIMITED DATA SETS ARE AVAILABLE", "authorids": ["~Ahmad_Melhem_Hammoud1", "arg06@mail.aub.edu"], "authors": ["Ahmad Melhem Hammoud", "Ahmad Rabih Ghandour"], "keywords": ["Machine Learning", "Computer Vision", "Data Augmentation", "Background Removal"], "abstract": "Today, many of the machine learning models are extremely data hungry. On the other hand, the accuracy of the algorithms used is very often affected by the amount of the training data available, which is, unfortunately, rarely abundant. Fortunately, image augmentation is one of the very powerful techniques that can be used by computer-vision engineers to expand their existing image data sets. This paper presents an innovative way for creating a variation of existing images and introduces the idea of using an Object-Focused Image (OFI). This is when an image includes only the labeled object and everything else is made transparent. The objective of OFI method is to expand the existing image data set and hence improve the accuracy of the model used to classify images. This paper also elaborates on the OFI approach and compares the accuracy of five different models with the same network design and settings but with different content of the training data set. The experiments presented in this paper show that using OFIs along with the original images can lead to an increase in the validation accuracy of the used model. In fact, when the OFI technique is used, the number of the images supplied nearly doubles.", "one-sentence_summary": "Before training an image classifying model, removing backgrounds from all training images and keeping just the labeled object will generate a new set of images, which will augment the data and increase the accuracy of the trained model", "pdf": "/pdf/875100ab78a50ccded86fa7b35563a7befb8417e.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hammoud|using_objectfocused_images_as_an_image_augmentation_technique_to_improve_the_accuracy_of_imageclassification_models_when_very_limited_data_sets_are_available", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=WlKZWJldjv", "_bibtex": "@misc{\nhammoud2021using,\ntitle={{\\{}USING{\\}} {\\{}OBJECT{\\}}-{\\{}FOCUSED{\\}} {\\{}IMAGES{\\}} {\\{}AS{\\}} {\\{}AN{\\}} {\\{}IMAGE{\\}} {\\{}AUGMENTATION{\\}} {\\{}TECHNIQUE{\\}} {\\{}TO{\\}} {\\{}IMPROVE{\\}} {\\{}THE{\\}} {\\{}ACCURACY{\\}} {\\{}OF{\\}} {\\{}IMAGE{\\}}-{\\{}CLASSIFICATION{\\}} {\\{}MODELS{\\}} {\\{}WHEN{\\}} {\\{}VERY{\\}} {\\{}LIMITED{\\}} {\\{}DATA{\\}} {\\{}SETS{\\}} {\\{}ARE{\\}} {\\{}AVAILABLE{\\}}},\nauthor={Ahmad Melhem Hammoud and Ahmad Rabih Ghandour},\nyear={2021},\nurl={https://openreview.net/forum?id=tY38nwwdCDa}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "stCt_NRtjHo", "original": null, "number": 1, "cdate": 1610040537712, "ddate": null, "tcdate": 1610040537712, "tmdate": 1610474147802, "tddate": null, "forum": "tY38nwwdCDa", "replyto": "tY38nwwdCDa", "invitation": "ICLR.cc/2021/Conference/Paper308/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The paper introduces an augmentation technique that, given an image with a detected object, keeps the object and removes the background.\n\nThe reviewers expressed numerous valid concerns about the paper's novelty, the setting (assumption that there's a single object), the scalability of the approach and the experimental setup, including the baselines used.\n\nThe authors have not addressed these concerns."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "USING OBJECT-FOCUSED IMAGES AS AN IMAGE AUGMENTATION TECHNIQUE TO IMPROVE THE ACCURACY OF IMAGE-CLASSIFICATION MODELS WHEN VERY LIMITED DATA SETS ARE AVAILABLE", "authorids": ["~Ahmad_Melhem_Hammoud1", "arg06@mail.aub.edu"], "authors": ["Ahmad Melhem Hammoud", "Ahmad Rabih Ghandour"], "keywords": ["Machine Learning", "Computer Vision", "Data Augmentation", "Background Removal"], "abstract": "Today, many of the machine learning models are extremely data hungry. On the other hand, the accuracy of the algorithms used is very often affected by the amount of the training data available, which is, unfortunately, rarely abundant. Fortunately, image augmentation is one of the very powerful techniques that can be used by computer-vision engineers to expand their existing image data sets. This paper presents an innovative way for creating a variation of existing images and introduces the idea of using an Object-Focused Image (OFI). This is when an image includes only the labeled object and everything else is made transparent. The objective of OFI method is to expand the existing image data set and hence improve the accuracy of the model used to classify images. This paper also elaborates on the OFI approach and compares the accuracy of five different models with the same network design and settings but with different content of the training data set. The experiments presented in this paper show that using OFIs along with the original images can lead to an increase in the validation accuracy of the used model. In fact, when the OFI technique is used, the number of the images supplied nearly doubles.", "one-sentence_summary": "Before training an image classifying model, removing backgrounds from all training images and keeping just the labeled object will generate a new set of images, which will augment the data and increase the accuracy of the trained model", "pdf": "/pdf/875100ab78a50ccded86fa7b35563a7befb8417e.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hammoud|using_objectfocused_images_as_an_image_augmentation_technique_to_improve_the_accuracy_of_imageclassification_models_when_very_limited_data_sets_are_available", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=WlKZWJldjv", "_bibtex": "@misc{\nhammoud2021using,\ntitle={{\\{}USING{\\}} {\\{}OBJECT{\\}}-{\\{}FOCUSED{\\}} {\\{}IMAGES{\\}} {\\{}AS{\\}} {\\{}AN{\\}} {\\{}IMAGE{\\}} {\\{}AUGMENTATION{\\}} {\\{}TECHNIQUE{\\}} {\\{}TO{\\}} {\\{}IMPROVE{\\}} {\\{}THE{\\}} {\\{}ACCURACY{\\}} {\\{}OF{\\}} {\\{}IMAGE{\\}}-{\\{}CLASSIFICATION{\\}} {\\{}MODELS{\\}} {\\{}WHEN{\\}} {\\{}VERY{\\}} {\\{}LIMITED{\\}} {\\{}DATA{\\}} {\\{}SETS{\\}} {\\{}ARE{\\}} {\\{}AVAILABLE{\\}}},\nauthor={Ahmad Melhem Hammoud and Ahmad Rabih Ghandour},\nyear={2021},\nurl={https://openreview.net/forum?id=tY38nwwdCDa}\n}"}, "tags": [], "invitation": {"reply": {"forum": "tY38nwwdCDa", "replyto": "tY38nwwdCDa", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040537698, "tmdate": 1610474147787, "id": "ICLR.cc/2021/Conference/Paper308/-/Decision"}}}, {"id": "7T0lOfy7Kmr", "original": null, "number": 1, "cdate": 1603747318666, "ddate": null, "tcdate": 1603747318666, "tmdate": 1605024718249, "tddate": null, "forum": "tY38nwwdCDa", "replyto": "tY38nwwdCDa", "invitation": "ICLR.cc/2021/Conference/Paper308/-/Official_Review", "content": {"title": "Recommendation to reject", "review": "Summary: Authors propose an augmentation technique for image classification. The augmented image is obtained by segmenting the salient object and masking the background. Therefore the technique gives one additional augmented image per each training image. The authors show an improved performance when using this augmentation on binary classification task (cats vs. dogs) using a dataset of 2000 images.\n\nI find the paper in its current form lacking in many aspects, mainly: questionable novelty, bad presentation, minimal experiments.\n\nConcerning novelty, the authors themselves remark: \"It is a good practice to train a model using images that include the labeled object only\". The section on related work is very superficial ignoring the achievements thanks to synthetic images. The approaches such as the following, used usually in the context of object detection, should be considered prior art and at least properly discussed, e.g.:\n\n- Gupta et al, \"Synthetic Data for Text Localisation in Natural Images\", CVPR, 2016.\n- Dwibedi et al, \"Cut, Paste and Learn: Surprisingly Easy Synthesis for Instance Detection\", ICCV, 2017.\n- Georgakis et al, \"Synthesizing Training Data for Object Detection in Indoor Scenes\", RSS, 2017\n- Dvonik et al, \"Modeling Visual Context is Key to Augmenting Object Detection Datasets\", ECCV, 2018\n- Tripathi et al, \"Learning to Generate Synthetic Data via Compositing\", CVPR, 2019\n\nThere are many places in the manuscript where the sense of the text is not clear or the text appears out of context, e.g.: \"After ResNet was proposed (He et al., 2016), new network architectures have been proposed as well (Zagoruyko and Komodakis, 2016; Han et al., 2017). Pixel-dropping, however, injects noise into the image (Sietsma and Dow, 1991).\" The text seems in general unfinished and outdated at the same time (no citations of prior art newer than 2017).\n\nConcerning experiments. The authors speak about lack of data but instead of evaluating on some few-shot datasets (e.g., mini-Imagenet or omniglot), they evaluate on a dataset with two classes and 1000 training images per class. The experiments are limited to evaluating a a model trained on the original unaugmented dataset, augmented using automatic segmentation, and augmented using manual segmentation. There is no comparison to other methods, not even the ones cited in the paper. Given obtaining segmentation can be costly I would expect the authors to test whether it is necessary at all and whether cutting the object to the bounding box is not enough. I would also expect a discussion of when can background removal actually hurt the performance (e.g., because it is predictive of the target class).", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper308/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper308/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "USING OBJECT-FOCUSED IMAGES AS AN IMAGE AUGMENTATION TECHNIQUE TO IMPROVE THE ACCURACY OF IMAGE-CLASSIFICATION MODELS WHEN VERY LIMITED DATA SETS ARE AVAILABLE", "authorids": ["~Ahmad_Melhem_Hammoud1", "arg06@mail.aub.edu"], "authors": ["Ahmad Melhem Hammoud", "Ahmad Rabih Ghandour"], "keywords": ["Machine Learning", "Computer Vision", "Data Augmentation", "Background Removal"], "abstract": "Today, many of the machine learning models are extremely data hungry. On the other hand, the accuracy of the algorithms used is very often affected by the amount of the training data available, which is, unfortunately, rarely abundant. Fortunately, image augmentation is one of the very powerful techniques that can be used by computer-vision engineers to expand their existing image data sets. This paper presents an innovative way for creating a variation of existing images and introduces the idea of using an Object-Focused Image (OFI). This is when an image includes only the labeled object and everything else is made transparent. The objective of OFI method is to expand the existing image data set and hence improve the accuracy of the model used to classify images. This paper also elaborates on the OFI approach and compares the accuracy of five different models with the same network design and settings but with different content of the training data set. The experiments presented in this paper show that using OFIs along with the original images can lead to an increase in the validation accuracy of the used model. In fact, when the OFI technique is used, the number of the images supplied nearly doubles.", "one-sentence_summary": "Before training an image classifying model, removing backgrounds from all training images and keeping just the labeled object will generate a new set of images, which will augment the data and increase the accuracy of the trained model", "pdf": "/pdf/875100ab78a50ccded86fa7b35563a7befb8417e.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hammoud|using_objectfocused_images_as_an_image_augmentation_technique_to_improve_the_accuracy_of_imageclassification_models_when_very_limited_data_sets_are_available", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=WlKZWJldjv", "_bibtex": "@misc{\nhammoud2021using,\ntitle={{\\{}USING{\\}} {\\{}OBJECT{\\}}-{\\{}FOCUSED{\\}} {\\{}IMAGES{\\}} {\\{}AS{\\}} {\\{}AN{\\}} {\\{}IMAGE{\\}} {\\{}AUGMENTATION{\\}} {\\{}TECHNIQUE{\\}} {\\{}TO{\\}} {\\{}IMPROVE{\\}} {\\{}THE{\\}} {\\{}ACCURACY{\\}} {\\{}OF{\\}} {\\{}IMAGE{\\}}-{\\{}CLASSIFICATION{\\}} {\\{}MODELS{\\}} {\\{}WHEN{\\}} {\\{}VERY{\\}} {\\{}LIMITED{\\}} {\\{}DATA{\\}} {\\{}SETS{\\}} {\\{}ARE{\\}} {\\{}AVAILABLE{\\}}},\nauthor={Ahmad Melhem Hammoud and Ahmad Rabih Ghandour},\nyear={2021},\nurl={https://openreview.net/forum?id=tY38nwwdCDa}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "tY38nwwdCDa", "replyto": "tY38nwwdCDa", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper308/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538146013, "tmdate": 1606915810502, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper308/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper308/-/Official_Review"}}}, {"id": "hMHlXEpe4Je", "original": null, "number": 2, "cdate": 1603909574926, "ddate": null, "tcdate": 1603909574926, "tmdate": 1605024718167, "tddate": null, "forum": "tY38nwwdCDa", "replyto": "tY38nwwdCDa", "invitation": "ICLR.cc/2021/Conference/Paper308/-/Official_Review", "content": {"title": "Not acceptable", "review": "This work proposes to augment object focused image to improve image classification. Essentially, this work tries to remove background from original image using an existing algorithm and human editor, and train an image classification model using different combinations of original images and background-removed image. Five simple models are trained and their performance is compared to show that using background-removed images together with original images can help improve accuracy on validation set on a simple dataset. \n\nOverall, this paper has serious flaws and is far from the level of ICLR. It is more like a course project report than a scientific paper. It lacks rigorous experiment design and result analysis, and the conclusion is not surprising or insightful. A clear rejection.\n\nDetailed comments:\n\nTechnical:\n- Although it makes sense to augment. input images to improve model performance, the design of the proposed work is less convincing. When talking about data augmentation, there usually won't be human editor/annotator involved and all the operations should be performed on-the-fly algorithmically. However, in this work, the background removal for original image is done either by a human editor or a third-party tool, which is not scalable at all. \n- The technical part is also significantly limited. The background removal assumes that there is only one dominant object related to the label in an image. This simplifies the real problem too much. As the paper shows in Figure 3, this poses a serious problem when there are more than one object and the object of interest is not dominant. I do not think the proposed method can be applied to more complex scenarios at all. \n- The paper states \"When that baby sees only a cat in the image, s/he would not get confused which object is the cat.\" However, this may not be true. Actually we haven't really understood how exactly human's perception/neural system works.\n- The performance of the model trained on images using the third-party background removal tool heavily depends on the quality of the tool. Since there is no evaluation on the tool, we do not know how the quality of background removal contributes to model performance improvement/degradation. \n\nExperiments:\n- The proposed model is only evaluated on one simple dataset containing only cats and dogs. It is more a sanity check/toy example than a realistic evaluation setting since there is just binary classification. Larger-scale datasets with multiple classes should be used.\n- The model evaluated is a simple convolutional network, and not a standard model; i.e., ResNet, VGG or other widely used model, so it is difficult to say whether the conclusion drawn from this model can by applied to other models and datasets. \n- Why not mix human edited images and images modified by the tool and train a model on all the images to see how it works? ", "rating": "2: Strong rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper308/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper308/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "USING OBJECT-FOCUSED IMAGES AS AN IMAGE AUGMENTATION TECHNIQUE TO IMPROVE THE ACCURACY OF IMAGE-CLASSIFICATION MODELS WHEN VERY LIMITED DATA SETS ARE AVAILABLE", "authorids": ["~Ahmad_Melhem_Hammoud1", "arg06@mail.aub.edu"], "authors": ["Ahmad Melhem Hammoud", "Ahmad Rabih Ghandour"], "keywords": ["Machine Learning", "Computer Vision", "Data Augmentation", "Background Removal"], "abstract": "Today, many of the machine learning models are extremely data hungry. On the other hand, the accuracy of the algorithms used is very often affected by the amount of the training data available, which is, unfortunately, rarely abundant. Fortunately, image augmentation is one of the very powerful techniques that can be used by computer-vision engineers to expand their existing image data sets. This paper presents an innovative way for creating a variation of existing images and introduces the idea of using an Object-Focused Image (OFI). This is when an image includes only the labeled object and everything else is made transparent. The objective of OFI method is to expand the existing image data set and hence improve the accuracy of the model used to classify images. This paper also elaborates on the OFI approach and compares the accuracy of five different models with the same network design and settings but with different content of the training data set. The experiments presented in this paper show that using OFIs along with the original images can lead to an increase in the validation accuracy of the used model. In fact, when the OFI technique is used, the number of the images supplied nearly doubles.", "one-sentence_summary": "Before training an image classifying model, removing backgrounds from all training images and keeping just the labeled object will generate a new set of images, which will augment the data and increase the accuracy of the trained model", "pdf": "/pdf/875100ab78a50ccded86fa7b35563a7befb8417e.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hammoud|using_objectfocused_images_as_an_image_augmentation_technique_to_improve_the_accuracy_of_imageclassification_models_when_very_limited_data_sets_are_available", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=WlKZWJldjv", "_bibtex": "@misc{\nhammoud2021using,\ntitle={{\\{}USING{\\}} {\\{}OBJECT{\\}}-{\\{}FOCUSED{\\}} {\\{}IMAGES{\\}} {\\{}AS{\\}} {\\{}AN{\\}} {\\{}IMAGE{\\}} {\\{}AUGMENTATION{\\}} {\\{}TECHNIQUE{\\}} {\\{}TO{\\}} {\\{}IMPROVE{\\}} {\\{}THE{\\}} {\\{}ACCURACY{\\}} {\\{}OF{\\}} {\\{}IMAGE{\\}}-{\\{}CLASSIFICATION{\\}} {\\{}MODELS{\\}} {\\{}WHEN{\\}} {\\{}VERY{\\}} {\\{}LIMITED{\\}} {\\{}DATA{\\}} {\\{}SETS{\\}} {\\{}ARE{\\}} {\\{}AVAILABLE{\\}}},\nauthor={Ahmad Melhem Hammoud and Ahmad Rabih Ghandour},\nyear={2021},\nurl={https://openreview.net/forum?id=tY38nwwdCDa}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "tY38nwwdCDa", "replyto": "tY38nwwdCDa", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper308/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538146013, "tmdate": 1606915810502, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper308/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper308/-/Official_Review"}}}, {"id": "y2nIK3z8pBo", "original": null, "number": 4, "cdate": 1604090216387, "ddate": null, "tcdate": 1604090216387, "tmdate": 1605024718098, "tddate": null, "forum": "tY38nwwdCDa", "replyto": "tY38nwwdCDa", "invitation": "ICLR.cc/2021/Conference/Paper308/-/Official_Review", "content": {"title": "This paper does not step to the level to be accepted at ICLR.", "review": "The paper presents an image data set augmentation approach (4 variants+ original data set variant) in order to cater to the lack of sufficient data for learning purposes by increasing available image data sets through creation of  variations of existing images. \nThe variations are all about extracting recognizable objects in images (Object-Focused Images or  OFIs), manually and automatically,  and combination with original data set images.\n\nQuestions:\n- \u201cIn fact, when the OFI technique is used, the number of the images supplied nearly doubles.\u201d\n\t- Does not this depend on the type of images in the data set: multi-object images, no discernible object sets (textures, backgrounds etc.)?\n        - Image given as example in Figure 2 is quite simplistic as the cat figure is clearly easily isolated. You Should state the type of application your model is intended for as you use for such a simplistic application.\n\n- In 3. THE OFI TECHNIQUE: \n\t- You state \u201cIt is a good practice to try to train a model using images that include the labeled object only and nothing else.\u201d. \n        \t- Does not this go against building models that will use real life images and therefore generalize well? Except may be in controlled setting like manufacturing lines.\n\n- In 4. THE EXPERIMENTS /4.1 USED MODELS:\n\t\t- You conduct 5 different tests (or models as you call them): Original images, Automatic OFIs, Manual OFIs, Original + Automatic OFIs and Original + Manual OFIs. \n\t \t- Did not you try: Original + Automatic OFIs + Manual OFIs? Why not, you had the data.\n\nComments:\n-\tIn  1 INTRODUCTION, you state: \n\t \t- \" benefit further from using the mixed data set of old and new images\u201d. Rather original data set images and derived/augmented images.\n\t \t- \"The automated method uses an Application Programming Interface (API) to remove the background of the image and leave only the labeled object (a cat or a dog) in the foreground.\u201d An API is an interface to remotely run an algorithm/call a method, not the actual method. \n\t \t- For consistency, since you deemed each experiment as a model, asking \u201cWill the model have a better validation accuracy when only the original set of images is used?\u201d is not consistent. Rather \u201cwill the model with only the original set of images \u2026\u201d\n\t \t- This paragraph seems out of place \u201d After ResNet was proposed (He et al., 2016), new network architectures have been proposed as well (Zagoruyko and Komodakis, 2016; Han et al., 2017).\u201d.\n\n- In 3, THE OFI TECHNIQUE: \n\t- Am perplexed by these questions:\n\t \t- Would our model get a little confused by those additional objects and try to be trained on? \n\t \t- Would our model keep changing its parameters and weights based on the additional objects in the image? \n- In 4. THE EXPERIMENTS /4.1 USED MODELS:\n\t- \u201cWhen a human photo editor keeps one object in the image and removes all other objects, the image tends to be more accurate.\u201d Not sure, this phrasing is\u201daccurate\u201d.\n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper308/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper308/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "USING OBJECT-FOCUSED IMAGES AS AN IMAGE AUGMENTATION TECHNIQUE TO IMPROVE THE ACCURACY OF IMAGE-CLASSIFICATION MODELS WHEN VERY LIMITED DATA SETS ARE AVAILABLE", "authorids": ["~Ahmad_Melhem_Hammoud1", "arg06@mail.aub.edu"], "authors": ["Ahmad Melhem Hammoud", "Ahmad Rabih Ghandour"], "keywords": ["Machine Learning", "Computer Vision", "Data Augmentation", "Background Removal"], "abstract": "Today, many of the machine learning models are extremely data hungry. On the other hand, the accuracy of the algorithms used is very often affected by the amount of the training data available, which is, unfortunately, rarely abundant. Fortunately, image augmentation is one of the very powerful techniques that can be used by computer-vision engineers to expand their existing image data sets. This paper presents an innovative way for creating a variation of existing images and introduces the idea of using an Object-Focused Image (OFI). This is when an image includes only the labeled object and everything else is made transparent. The objective of OFI method is to expand the existing image data set and hence improve the accuracy of the model used to classify images. This paper also elaborates on the OFI approach and compares the accuracy of five different models with the same network design and settings but with different content of the training data set. The experiments presented in this paper show that using OFIs along with the original images can lead to an increase in the validation accuracy of the used model. In fact, when the OFI technique is used, the number of the images supplied nearly doubles.", "one-sentence_summary": "Before training an image classifying model, removing backgrounds from all training images and keeping just the labeled object will generate a new set of images, which will augment the data and increase the accuracy of the trained model", "pdf": "/pdf/875100ab78a50ccded86fa7b35563a7befb8417e.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hammoud|using_objectfocused_images_as_an_image_augmentation_technique_to_improve_the_accuracy_of_imageclassification_models_when_very_limited_data_sets_are_available", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=WlKZWJldjv", "_bibtex": "@misc{\nhammoud2021using,\ntitle={{\\{}USING{\\}} {\\{}OBJECT{\\}}-{\\{}FOCUSED{\\}} {\\{}IMAGES{\\}} {\\{}AS{\\}} {\\{}AN{\\}} {\\{}IMAGE{\\}} {\\{}AUGMENTATION{\\}} {\\{}TECHNIQUE{\\}} {\\{}TO{\\}} {\\{}IMPROVE{\\}} {\\{}THE{\\}} {\\{}ACCURACY{\\}} {\\{}OF{\\}} {\\{}IMAGE{\\}}-{\\{}CLASSIFICATION{\\}} {\\{}MODELS{\\}} {\\{}WHEN{\\}} {\\{}VERY{\\}} {\\{}LIMITED{\\}} {\\{}DATA{\\}} {\\{}SETS{\\}} {\\{}ARE{\\}} {\\{}AVAILABLE{\\}}},\nauthor={Ahmad Melhem Hammoud and Ahmad Rabih Ghandour},\nyear={2021},\nurl={https://openreview.net/forum?id=tY38nwwdCDa}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "tY38nwwdCDa", "replyto": "tY38nwwdCDa", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper308/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538146013, "tmdate": 1606915810502, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper308/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper308/-/Official_Review"}}}, {"id": "tn_cPiMCTTD", "original": null, "number": 3, "cdate": 1604000466498, "ddate": null, "tcdate": 1604000466498, "tmdate": 1605024718030, "tddate": null, "forum": "tY38nwwdCDa", "replyto": "tY38nwwdCDa", "invitation": "ICLR.cc/2021/Conference/Paper308/-/Official_Review", "content": {"title": "The paper proposes using object focused images for data augmentation in CNN training; it is of limited significance ", "review": "The paper presents an object focused image based technique for CNN training, in which, for every image in the training set, another image is generated where the labeled object is kept untouched and everything in the background is rubbed out. A simple comparison is made among five scenarios on using separately or combined the original and OFI, illustrating that in the examined experiment somewhat better accuracy is obtained when combining them. \n\nThe presented research cannot be considered novel. Extracting regions of interest in images and using them for analysis, or extracting points of interest (e.g., facial landmarks) and using them together, or in addition, to the original images (e.g., faces) has been a frequently used approach to enhance object classification or regression tasks. The presented comparison has some interest, but it lacks even the required experimental validation, by comparing this data augmentation to any other competing approach - described in Figure 1.\n\nIn particular:\n\nSection 2 on related work makes reference to a large number of techniques used for data augmentation, which are summarized in Figure 1. Nevertheless, none of these techniques is used to compare to the OFI based method.\n\nThe results presented in Section 4 are of low significance. Testing in scenarios 2 and 3 would be meaningful if the statistics were similar to training; thus, obtaining lower accuracy was expected. Similarly, when comparing scenarios 1 and 4, with the latter containing augmented data, it was expected to see a better performance in the latter case.\n\nVarious presentation and language errors should be corrected (missing references, poor language, etc). ", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper308/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper308/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "USING OBJECT-FOCUSED IMAGES AS AN IMAGE AUGMENTATION TECHNIQUE TO IMPROVE THE ACCURACY OF IMAGE-CLASSIFICATION MODELS WHEN VERY LIMITED DATA SETS ARE AVAILABLE", "authorids": ["~Ahmad_Melhem_Hammoud1", "arg06@mail.aub.edu"], "authors": ["Ahmad Melhem Hammoud", "Ahmad Rabih Ghandour"], "keywords": ["Machine Learning", "Computer Vision", "Data Augmentation", "Background Removal"], "abstract": "Today, many of the machine learning models are extremely data hungry. On the other hand, the accuracy of the algorithms used is very often affected by the amount of the training data available, which is, unfortunately, rarely abundant. Fortunately, image augmentation is one of the very powerful techniques that can be used by computer-vision engineers to expand their existing image data sets. This paper presents an innovative way for creating a variation of existing images and introduces the idea of using an Object-Focused Image (OFI). This is when an image includes only the labeled object and everything else is made transparent. The objective of OFI method is to expand the existing image data set and hence improve the accuracy of the model used to classify images. This paper also elaborates on the OFI approach and compares the accuracy of five different models with the same network design and settings but with different content of the training data set. The experiments presented in this paper show that using OFIs along with the original images can lead to an increase in the validation accuracy of the used model. In fact, when the OFI technique is used, the number of the images supplied nearly doubles.", "one-sentence_summary": "Before training an image classifying model, removing backgrounds from all training images and keeping just the labeled object will generate a new set of images, which will augment the data and increase the accuracy of the trained model", "pdf": "/pdf/875100ab78a50ccded86fa7b35563a7befb8417e.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hammoud|using_objectfocused_images_as_an_image_augmentation_technique_to_improve_the_accuracy_of_imageclassification_models_when_very_limited_data_sets_are_available", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=WlKZWJldjv", "_bibtex": "@misc{\nhammoud2021using,\ntitle={{\\{}USING{\\}} {\\{}OBJECT{\\}}-{\\{}FOCUSED{\\}} {\\{}IMAGES{\\}} {\\{}AS{\\}} {\\{}AN{\\}} {\\{}IMAGE{\\}} {\\{}AUGMENTATION{\\}} {\\{}TECHNIQUE{\\}} {\\{}TO{\\}} {\\{}IMPROVE{\\}} {\\{}THE{\\}} {\\{}ACCURACY{\\}} {\\{}OF{\\}} {\\{}IMAGE{\\}}-{\\{}CLASSIFICATION{\\}} {\\{}MODELS{\\}} {\\{}WHEN{\\}} {\\{}VERY{\\}} {\\{}LIMITED{\\}} {\\{}DATA{\\}} {\\{}SETS{\\}} {\\{}ARE{\\}} {\\{}AVAILABLE{\\}}},\nauthor={Ahmad Melhem Hammoud and Ahmad Rabih Ghandour},\nyear={2021},\nurl={https://openreview.net/forum?id=tY38nwwdCDa}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "tY38nwwdCDa", "replyto": "tY38nwwdCDa", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper308/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538146013, "tmdate": 1606915810502, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper308/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper308/-/Official_Review"}}}], "count": 6}