{"notes": [{"id": "SyxPVLUYdE", "original": "Bkx8aBe9D4", "number": 25, "cdate": 1553716782879, "ddate": null, "tcdate": 1553716782879, "tmdate": 1562083040930, "tddate": null, "forum": "SyxPVLUYdE", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Blind_Submission", "content": {"title": "Revisiting Auxiliary Latent Variables in Generative Models", "authors": ["Dieterich Lawson", "George Tucker", "Bo Dai", "Rajesh Ranganath"], "authorids": ["jdl404@nyu.edu", "gjt@google.com", "bodai@google.com", "rajeshr@cims.nyu.edu"], "keywords": ["variational inference", "monte carlo objectives", "VAE", "IWAE", "sampling", "contrastive predictive coding", "CPC", "noise contrastive estimation", "NCE", "auxiliary variable variational inference", "generative modeling", "energy-based models"], "TL;DR": "Monte Carlo Objectives are analyzed using auxiliary variable variational inference, yielding a new analysis of CPC and NCE as well as a new generative model.", "abstract": "Extending models with auxiliary latent variables is a well-known technique to in-crease model expressivity. Bachman & Precup (2015); Naesseth et al. (2018); Cremer et al. (2017); Domke & Sheldon (2018) show that Importance Weighted Autoencoders (IWAE) (Burda et al., 2015) can be viewed as extending the variational family with auxiliary latent variables. Similarly, we show that this view encompasses many of the recent developments in variational bounds (Maddisonet al., 2017; Naesseth et al., 2018; Le et al., 2017; Yin & Zhou, 2018; Molchanovet al., 2018; Sobolev & Vetrov, 2018). The success of enriching the variational family with auxiliary latent variables motivates applying the same techniques to the generative model. We develop a generative model analogous to the IWAE bound and empirically show that it outperforms the recently proposed Learned Accept/Reject Sampling algorithm (Bauer & Mnih, 2018), while being substantially easier to implement. Furthermore, we show that this generative process provides new insights on ranking Noise Contrastive Estimation (Jozefowicz et al.,2016; Ma & Collins, 2018) and Contrastive Predictive Coding (Oord et al., 2018).", "pdf": "/pdf/43c852e4e6156ad65435a3e7e5a9c0bcbb2a4789.pdf", "paperhash": "lawson|revisiting_auxiliary_latent_variables_in_generative_models"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Blind_Submission", "cdate": 1547567085825, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": [".*"]}, "writers": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1547567085825, "tmdate": 1555704438520, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}}, "tauthor": "OpenReview.net"}, {"id": "BklBXunLqN", "original": null, "number": 3, "cdate": 1555642397143, "ddate": null, "tcdate": 1555642397143, "tmdate": 1556906114108, "tddate": null, "forum": "SyxPVLUYdE", "replyto": "SyxPVLUYdE", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper25/Official_Review", "content": {"title": "Review", "review": "General:\n\nThis paper revisits auxiliary latent variable formulation of variational inference. Inspired by that, the authors develop a generative model based on self-normalized importance sampling (SNIS), and connect it to recent approaches such as  NCE and CPC. The view is very interesting. In experiments on MNIST, SNIS combined with VAE framework outperforms recently proposed LARS, while being faster and computationally cheaper.\n\nPros:\n\n+ This paper provides a unified view of variational lower bound through auxiliary latent variables (this is not new though), relates that to the generative model side, and proposes a self-normalized importance sampling process as a generative model. This new method called SNIS can be connected with NCE and CPC. As mentioned in the paper, a unified view over different approaches might provide insights for future research\n\n+ While only evaluated in the VAE context, the method can be potentially general and effective for other settings (as mentioned in the LARS paper).\n\nCons:\n- I would like to see more experiments under different settings to show efficacy of the method\n", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper25/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper25/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Auxiliary Latent Variables in Generative Models", "authors": ["Dieterich Lawson", "George Tucker", "Bo Dai", "Rajesh Ranganath"], "authorids": ["jdl404@nyu.edu", "gjt@google.com", "bodai@google.com", "rajeshr@cims.nyu.edu"], "keywords": ["variational inference", "monte carlo objectives", "VAE", "IWAE", "sampling", "contrastive predictive coding", "CPC", "noise contrastive estimation", "NCE", "auxiliary variable variational inference", "generative modeling", "energy-based models"], "TL;DR": "Monte Carlo Objectives are analyzed using auxiliary variable variational inference, yielding a new analysis of CPC and NCE as well as a new generative model.", "abstract": "Extending models with auxiliary latent variables is a well-known technique to in-crease model expressivity. Bachman & Precup (2015); Naesseth et al. (2018); Cremer et al. (2017); Domke & Sheldon (2018) show that Importance Weighted Autoencoders (IWAE) (Burda et al., 2015) can be viewed as extending the variational family with auxiliary latent variables. Similarly, we show that this view encompasses many of the recent developments in variational bounds (Maddisonet al., 2017; Naesseth et al., 2018; Le et al., 2017; Yin & Zhou, 2018; Molchanovet al., 2018; Sobolev & Vetrov, 2018). The success of enriching the variational family with auxiliary latent variables motivates applying the same techniques to the generative model. We develop a generative model analogous to the IWAE bound and empirically show that it outperforms the recently proposed Learned Accept/Reject Sampling algorithm (Bauer & Mnih, 2018), while being substantially easier to implement. Furthermore, we show that this generative process provides new insights on ranking Noise Contrastive Estimation (Jozefowicz et al.,2016; Ma & Collins, 2018) and Contrastive Predictive Coding (Oord et al., 2018).", "pdf": "/pdf/43c852e4e6156ad65435a3e7e5a9c0bcbb2a4789.pdf", "paperhash": "lawson|revisiting_auxiliary_latent_variables_in_generative_models"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper25/Official_Review", "cdate": 1554234176001, "reply": {"forum": "SyxPVLUYdE", "replyto": "SyxPVLUYdE", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper25/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper25/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1554234176001, "tmdate": 1556906088556, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper25/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}, {"id": "Hye8mfl7cE", "original": null, "number": 1, "cdate": 1555395101550, "ddate": null, "tcdate": 1555395101550, "tmdate": 1556906113885, "tddate": null, "forum": "SyxPVLUYdE", "replyto": "SyxPVLUYdE", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper25/Official_Review", "content": {"title": "An interesting view of some recent work on improving variational bounds", "review": "This paper provides a different view of some recent work on improving variational bounds through auxiliary latent variable models. This connection gives some new insights in the existing work, e.g., IWAE, ranking NCE, and CPC. The paper also explores the possibility of using auxiliary latent variable models in the generative model. \n\nThe research in this paper is still in its early stage and it would be interesting to see how some of the unanswered questions in the current paper can be addressed. ", "rating": "3: Marginally above acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper25/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper25/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Auxiliary Latent Variables in Generative Models", "authors": ["Dieterich Lawson", "George Tucker", "Bo Dai", "Rajesh Ranganath"], "authorids": ["jdl404@nyu.edu", "gjt@google.com", "bodai@google.com", "rajeshr@cims.nyu.edu"], "keywords": ["variational inference", "monte carlo objectives", "VAE", "IWAE", "sampling", "contrastive predictive coding", "CPC", "noise contrastive estimation", "NCE", "auxiliary variable variational inference", "generative modeling", "energy-based models"], "TL;DR": "Monte Carlo Objectives are analyzed using auxiliary variable variational inference, yielding a new analysis of CPC and NCE as well as a new generative model.", "abstract": "Extending models with auxiliary latent variables is a well-known technique to in-crease model expressivity. Bachman & Precup (2015); Naesseth et al. (2018); Cremer et al. (2017); Domke & Sheldon (2018) show that Importance Weighted Autoencoders (IWAE) (Burda et al., 2015) can be viewed as extending the variational family with auxiliary latent variables. Similarly, we show that this view encompasses many of the recent developments in variational bounds (Maddisonet al., 2017; Naesseth et al., 2018; Le et al., 2017; Yin & Zhou, 2018; Molchanovet al., 2018; Sobolev & Vetrov, 2018). The success of enriching the variational family with auxiliary latent variables motivates applying the same techniques to the generative model. We develop a generative model analogous to the IWAE bound and empirically show that it outperforms the recently proposed Learned Accept/Reject Sampling algorithm (Bauer & Mnih, 2018), while being substantially easier to implement. Furthermore, we show that this generative process provides new insights on ranking Noise Contrastive Estimation (Jozefowicz et al.,2016; Ma & Collins, 2018) and Contrastive Predictive Coding (Oord et al., 2018).", "pdf": "/pdf/43c852e4e6156ad65435a3e7e5a9c0bcbb2a4789.pdf", "paperhash": "lawson|revisiting_auxiliary_latent_variables_in_generative_models"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper25/Official_Review", "cdate": 1554234176001, "reply": {"forum": "SyxPVLUYdE", "replyto": "SyxPVLUYdE", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper25/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper25/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1554234176001, "tmdate": 1556906088556, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper25/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}, {"id": "rklxfPosc4", "original": null, "number": 1, "cdate": 1555965704266, "ddate": null, "tcdate": 1555965704266, "tmdate": 1556906113645, "tddate": null, "forum": "SyxPVLUYdE", "replyto": "SyxPVLUYdE", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper25/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Revisiting Auxiliary Latent Variables in Generative Models", "authors": ["Dieterich Lawson", "George Tucker", "Bo Dai", "Rajesh Ranganath"], "authorids": ["jdl404@nyu.edu", "gjt@google.com", "bodai@google.com", "rajeshr@cims.nyu.edu"], "keywords": ["variational inference", "monte carlo objectives", "VAE", "IWAE", "sampling", "contrastive predictive coding", "CPC", "noise contrastive estimation", "NCE", "auxiliary variable variational inference", "generative modeling", "energy-based models"], "TL;DR": "Monte Carlo Objectives are analyzed using auxiliary variable variational inference, yielding a new analysis of CPC and NCE as well as a new generative model.", "abstract": "Extending models with auxiliary latent variables is a well-known technique to in-crease model expressivity. Bachman & Precup (2015); Naesseth et al. (2018); Cremer et al. (2017); Domke & Sheldon (2018) show that Importance Weighted Autoencoders (IWAE) (Burda et al., 2015) can be viewed as extending the variational family with auxiliary latent variables. Similarly, we show that this view encompasses many of the recent developments in variational bounds (Maddisonet al., 2017; Naesseth et al., 2018; Le et al., 2017; Yin & Zhou, 2018; Molchanovet al., 2018; Sobolev & Vetrov, 2018). The success of enriching the variational family with auxiliary latent variables motivates applying the same techniques to the generative model. We develop a generative model analogous to the IWAE bound and empirically show that it outperforms the recently proposed Learned Accept/Reject Sampling algorithm (Bauer & Mnih, 2018), while being substantially easier to implement. Furthermore, we show that this generative process provides new insights on ranking Noise Contrastive Estimation (Jozefowicz et al.,2016; Ma & Collins, 2018) and Contrastive Predictive Coding (Oord et al., 2018).", "pdf": "/pdf/43c852e4e6156ad65435a3e7e5a9c0bcbb2a4789.pdf", "paperhash": "lawson|revisiting_auxiliary_latent_variables_in_generative_models"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper25/Decision", "cdate": 1554814606749, "reply": {"forum": "SyxPVLUYdE", "replyto": "SyxPVLUYdE", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554814606749, "tmdate": 1556906098787, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}], "count": 4}