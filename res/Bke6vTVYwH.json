{"notes": [{"id": "Bke6vTVYwH", "original": "SyxMkvsDPH", "number": 612, "cdate": 1569439076691, "ddate": null, "tcdate": 1569439076691, "tmdate": 1577168226780, "tddate": null, "forum": "Bke6vTVYwH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Graph convolutional networks for learning with few clean and many noisy labels", "authors": ["Ahmet Iscen", "Giorgos Tolias", "Yannis Avrithis", "Ondrej Chum", "Cordelia Schmid"], "authorids": ["iscen@google.com", "giorgos.tolias@cmp.felk.cvut.cz", "yannis@avrithis.net", "chum@cmp.felk.cvut.cz", "cordelias@google.com"], "keywords": [], "abstract": "In this work we consider the problem of learning a classifier from noisy labels when a few clean labeled examples are given. The structure of clean and noisy data is modeled by a graph per class and Graph Convolutional Networks (GCN) are used to predict class relevance of noisy examples. For each class, the GCN is treated as a binary classifier learning to discriminate clean from noisy examples using a weighted binary cross-entropy loss function, and then the GCN-inferred \"clean\" probability is exploited as a relevance measure. Each noisy example is weighted by its relevance when learning a classifier for the end task. We evaluate our method on an extended version of a few-shot learning problem, where the few clean examples of novel classes are supplemented with additional noisy data. Experimental results show that our GCN-based cleaning process significantly improves the classification accuracy over not cleaning the noisy data and standard few-shot classification where only few clean examples are used. The proposed GCN-based method outperforms the transductive approach (Douze et al., 2018) that is using the same additional data without labels.", "pdf": "/pdf/128d55ded5d893b0eeac73626635a6274b04d1da.pdf", "paperhash": "iscen|graph_convolutional_networks_for_learning_with_few_clean_and_many_noisy_labels", "original_pdf": "/attachment/128d55ded5d893b0eeac73626635a6274b04d1da.pdf", "_bibtex": "@misc{\niscen2020graph,\ntitle={Graph convolutional networks for learning with few clean and many noisy labels},\nauthor={Ahmet Iscen and Giorgos Tolias and Yannis Avrithis and Ondrej Chum and Cordelia Schmid},\nyear={2020},\nurl={https://openreview.net/forum?id=Bke6vTVYwH}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "AbdGevkyPC", "original": null, "number": 1, "cdate": 1576798701334, "ddate": null, "tcdate": 1576798701334, "tmdate": 1576800934647, "tddate": null, "forum": "Bke6vTVYwH", "replyto": "Bke6vTVYwH", "invitation": "ICLR.cc/2020/Conference/Paper612/-/Decision", "content": {"decision": "Reject", "comment": "The paper combines graph convolutional networks with noisy label learning. The reviewers feel that novelty in the work is limited and there is a need for further experiments and  extensions. ", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph convolutional networks for learning with few clean and many noisy labels", "authors": ["Ahmet Iscen", "Giorgos Tolias", "Yannis Avrithis", "Ondrej Chum", "Cordelia Schmid"], "authorids": ["iscen@google.com", "giorgos.tolias@cmp.felk.cvut.cz", "yannis@avrithis.net", "chum@cmp.felk.cvut.cz", "cordelias@google.com"], "keywords": [], "abstract": "In this work we consider the problem of learning a classifier from noisy labels when a few clean labeled examples are given. The structure of clean and noisy data is modeled by a graph per class and Graph Convolutional Networks (GCN) are used to predict class relevance of noisy examples. For each class, the GCN is treated as a binary classifier learning to discriminate clean from noisy examples using a weighted binary cross-entropy loss function, and then the GCN-inferred \"clean\" probability is exploited as a relevance measure. Each noisy example is weighted by its relevance when learning a classifier for the end task. We evaluate our method on an extended version of a few-shot learning problem, where the few clean examples of novel classes are supplemented with additional noisy data. Experimental results show that our GCN-based cleaning process significantly improves the classification accuracy over not cleaning the noisy data and standard few-shot classification where only few clean examples are used. The proposed GCN-based method outperforms the transductive approach (Douze et al., 2018) that is using the same additional data without labels.", "pdf": "/pdf/128d55ded5d893b0eeac73626635a6274b04d1da.pdf", "paperhash": "iscen|graph_convolutional_networks_for_learning_with_few_clean_and_many_noisy_labels", "original_pdf": "/attachment/128d55ded5d893b0eeac73626635a6274b04d1da.pdf", "_bibtex": "@misc{\niscen2020graph,\ntitle={Graph convolutional networks for learning with few clean and many noisy labels},\nauthor={Ahmet Iscen and Giorgos Tolias and Yannis Avrithis and Ondrej Chum and Cordelia Schmid},\nyear={2020},\nurl={https://openreview.net/forum?id=Bke6vTVYwH}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "Bke6vTVYwH", "replyto": "Bke6vTVYwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795729074, "tmdate": 1576800281604, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper612/-/Decision"}}}, {"id": "rJxXNsJLor", "original": null, "number": 3, "cdate": 1573415723270, "ddate": null, "tcdate": 1573415723270, "tmdate": 1573415723270, "tddate": null, "forum": "Bke6vTVYwH", "replyto": "SyxC53fBir", "invitation": "ICLR.cc/2020/Conference/Paper612/-/Official_Comment", "content": {"title": "Response to Reviewer #2", "comment": "We thank the review for their positive comments.  We agree that our main contribution is to cast a graph convolution network as a binary classifier learning to discriminate clean from noisy data and show its excellent results for few-shot learning. \n\nQ1: In future, I would like to see a joint approach to such training, where the function g(), the nearest neighbour graph loss and the classification loss are all tied in the same objective function and are optimized jointly. \n\nR1: We fully agree that this is an interesting direction for future research, which should result in a further increase in performance.  It would be interesting to see if the feature extractor can benefit from the cleaning of noisy images during learning, resulting in more robust feature descriptors.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper612/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper612/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph convolutional networks for learning with few clean and many noisy labels", "authors": ["Ahmet Iscen", "Giorgos Tolias", "Yannis Avrithis", "Ondrej Chum", "Cordelia Schmid"], "authorids": ["iscen@google.com", "giorgos.tolias@cmp.felk.cvut.cz", "yannis@avrithis.net", "chum@cmp.felk.cvut.cz", "cordelias@google.com"], "keywords": [], "abstract": "In this work we consider the problem of learning a classifier from noisy labels when a few clean labeled examples are given. The structure of clean and noisy data is modeled by a graph per class and Graph Convolutional Networks (GCN) are used to predict class relevance of noisy examples. For each class, the GCN is treated as a binary classifier learning to discriminate clean from noisy examples using a weighted binary cross-entropy loss function, and then the GCN-inferred \"clean\" probability is exploited as a relevance measure. Each noisy example is weighted by its relevance when learning a classifier for the end task. We evaluate our method on an extended version of a few-shot learning problem, where the few clean examples of novel classes are supplemented with additional noisy data. Experimental results show that our GCN-based cleaning process significantly improves the classification accuracy over not cleaning the noisy data and standard few-shot classification where only few clean examples are used. The proposed GCN-based method outperforms the transductive approach (Douze et al., 2018) that is using the same additional data without labels.", "pdf": "/pdf/128d55ded5d893b0eeac73626635a6274b04d1da.pdf", "paperhash": "iscen|graph_convolutional_networks_for_learning_with_few_clean_and_many_noisy_labels", "original_pdf": "/attachment/128d55ded5d893b0eeac73626635a6274b04d1da.pdf", "_bibtex": "@misc{\niscen2020graph,\ntitle={Graph convolutional networks for learning with few clean and many noisy labels},\nauthor={Ahmet Iscen and Giorgos Tolias and Yannis Avrithis and Ondrej Chum and Cordelia Schmid},\nyear={2020},\nurl={https://openreview.net/forum?id=Bke6vTVYwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Bke6vTVYwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper612/Authors", "ICLR.cc/2020/Conference/Paper612/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper612/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper612/Reviewers", "ICLR.cc/2020/Conference/Paper612/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper612/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper612/Authors|ICLR.cc/2020/Conference/Paper612/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504168858, "tmdate": 1576860556544, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper612/Authors", "ICLR.cc/2020/Conference/Paper612/Reviewers", "ICLR.cc/2020/Conference/Paper612/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper612/-/Official_Comment"}}}, {"id": "SyxC53fBir", "original": null, "number": 3, "cdate": 1573362838443, "ddate": null, "tcdate": 1573362838443, "tmdate": 1573362838443, "tddate": null, "forum": "Bke6vTVYwH", "replyto": "Bke6vTVYwH", "invitation": "ICLR.cc/2020/Conference/Paper612/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #2", "review": "The paper makes a significant attempt at solving one of the practical problems in machine learning -- learning from many noisy and limited number of clean labels. This setting is presumably more practical than the setting of few-shot learning. Noisy labels are often abundantly available and investing in methods that can take the noise into account for building a discriminative model is quite timely. \n\nTo be honest, the theoretical contribution of the paper is limited.  The authors make use of the nearest neighbour graph obtained from a reduced-dimensional set of features to compute the weights of the noisy labels that must guide the predictive model. From this perspective, the paper seems like an application of existing tools (such as CNN, graph convolutional network and binary classification). However, that does not undermine the superior results the authors have received in the novel application they have targeted. I appreciate the effort that went validating these ideas with real-world datasets.\n\nIn future, I would like to see a joint approach to such training, where the function g(), the nearest neighbour graph loss and the classification loss are all tied in the same objective function and are optimized jointly. \n\nThe paper has few really minor grammatical errors and typos. Please fix those before uploading the final draft. ", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper612/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper612/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph convolutional networks for learning with few clean and many noisy labels", "authors": ["Ahmet Iscen", "Giorgos Tolias", "Yannis Avrithis", "Ondrej Chum", "Cordelia Schmid"], "authorids": ["iscen@google.com", "giorgos.tolias@cmp.felk.cvut.cz", "yannis@avrithis.net", "chum@cmp.felk.cvut.cz", "cordelias@google.com"], "keywords": [], "abstract": "In this work we consider the problem of learning a classifier from noisy labels when a few clean labeled examples are given. The structure of clean and noisy data is modeled by a graph per class and Graph Convolutional Networks (GCN) are used to predict class relevance of noisy examples. For each class, the GCN is treated as a binary classifier learning to discriminate clean from noisy examples using a weighted binary cross-entropy loss function, and then the GCN-inferred \"clean\" probability is exploited as a relevance measure. Each noisy example is weighted by its relevance when learning a classifier for the end task. We evaluate our method on an extended version of a few-shot learning problem, where the few clean examples of novel classes are supplemented with additional noisy data. Experimental results show that our GCN-based cleaning process significantly improves the classification accuracy over not cleaning the noisy data and standard few-shot classification where only few clean examples are used. The proposed GCN-based method outperforms the transductive approach (Douze et al., 2018) that is using the same additional data without labels.", "pdf": "/pdf/128d55ded5d893b0eeac73626635a6274b04d1da.pdf", "paperhash": "iscen|graph_convolutional_networks_for_learning_with_few_clean_and_many_noisy_labels", "original_pdf": "/attachment/128d55ded5d893b0eeac73626635a6274b04d1da.pdf", "_bibtex": "@misc{\niscen2020graph,\ntitle={Graph convolutional networks for learning with few clean and many noisy labels},\nauthor={Ahmet Iscen and Giorgos Tolias and Yannis Avrithis and Ondrej Chum and Cordelia Schmid},\nyear={2020},\nurl={https://openreview.net/forum?id=Bke6vTVYwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Bke6vTVYwH", "replyto": "Bke6vTVYwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper612/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper612/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575833769147, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper612/Reviewers"], "noninvitees": [], "tcdate": 1570237749607, "tmdate": 1575833769161, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper612/-/Official_Review"}}}, {"id": "HkgHcqLVoH", "original": null, "number": 2, "cdate": 1573313164968, "ddate": null, "tcdate": 1573313164968, "tmdate": 1573313164968, "tddate": null, "forum": "Bke6vTVYwH", "replyto": "SylESLC6Fr", "invitation": "ICLR.cc/2020/Conference/Paper612/-/Official_Comment", "content": {"title": "Response to Reviewer #3", "comment": "We would like to thank the reviewer for the positive feedback. We reply to the the two questions below.\n\nQ1: The learning procedure is confusing. It is highly recommended to provide the pseudocode of the proposed method.\n\nR1: We will provide the pseudocode in the future versions of the paper:\n\nTraining:\n\nX_L : clean set\nC_L : class set\nX_Z : noisy set\n\n# For each class name\nFor c in C_L:\n\n\t#Take the clean examples belonging to this class\n\tX_L^c : subset of X_L with label c\n\n\t#Only consider noisy examples with the class name in the text\n\tX_Z^c = filter_by_text(X_Z)\n\n\t# Build the graph for this class, and learn the GCN for cleaning\t\t\t\t\t\n\tA^c = build_graph(X_Z^c)\n\tM^c = GCN_model(X_L^c, X_Z^c, A^c)\n\n\t#Clean examples always get weight 1\n\tfor i in X_L^c:\n\t\tr_i = 1.0\t\n\n\t#Noisy examples get the learned weight\t\t\t\t\t\t\t\n\tfor i in X_Z^c:\n\t\tr_i = assign_relevance(M^c(X_Z^c(i))\t\n\n\t#Add the noisy examples to the list of training images for this class\n\tX_L^c = concatenate(X_L^c, X_z^c)\t\t\t\n\n#Learn a classifier jointly for all classes. Use the relevance weights for noisy examples when learning the classifier\nW = train_classifier(X_L^c, r)\t\t\t\t\t\n\nTesting\n\nGiven test image Q\n\nv = extract_feature(Q)\nscores = W^T v\nprediction = argmax(scores)\n\n\nQ2: Since there are many tasks and each task has a large-scale data, I'm afraid that the running time will explode. How to deal with this issue?\n\nR2: The complexity is linear in the number of classes, since classes are processed independently. Furthermore, text filtering is applied before cleaning, which reduces the number of images to be considered for a given class. Please also see the response R1 to reviewer1.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper612/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper612/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph convolutional networks for learning with few clean and many noisy labels", "authors": ["Ahmet Iscen", "Giorgos Tolias", "Yannis Avrithis", "Ondrej Chum", "Cordelia Schmid"], "authorids": ["iscen@google.com", "giorgos.tolias@cmp.felk.cvut.cz", "yannis@avrithis.net", "chum@cmp.felk.cvut.cz", "cordelias@google.com"], "keywords": [], "abstract": "In this work we consider the problem of learning a classifier from noisy labels when a few clean labeled examples are given. The structure of clean and noisy data is modeled by a graph per class and Graph Convolutional Networks (GCN) are used to predict class relevance of noisy examples. For each class, the GCN is treated as a binary classifier learning to discriminate clean from noisy examples using a weighted binary cross-entropy loss function, and then the GCN-inferred \"clean\" probability is exploited as a relevance measure. Each noisy example is weighted by its relevance when learning a classifier for the end task. We evaluate our method on an extended version of a few-shot learning problem, where the few clean examples of novel classes are supplemented with additional noisy data. Experimental results show that our GCN-based cleaning process significantly improves the classification accuracy over not cleaning the noisy data and standard few-shot classification where only few clean examples are used. The proposed GCN-based method outperforms the transductive approach (Douze et al., 2018) that is using the same additional data without labels.", "pdf": "/pdf/128d55ded5d893b0eeac73626635a6274b04d1da.pdf", "paperhash": "iscen|graph_convolutional_networks_for_learning_with_few_clean_and_many_noisy_labels", "original_pdf": "/attachment/128d55ded5d893b0eeac73626635a6274b04d1da.pdf", "_bibtex": "@misc{\niscen2020graph,\ntitle={Graph convolutional networks for learning with few clean and many noisy labels},\nauthor={Ahmet Iscen and Giorgos Tolias and Yannis Avrithis and Ondrej Chum and Cordelia Schmid},\nyear={2020},\nurl={https://openreview.net/forum?id=Bke6vTVYwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Bke6vTVYwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper612/Authors", "ICLR.cc/2020/Conference/Paper612/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper612/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper612/Reviewers", "ICLR.cc/2020/Conference/Paper612/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper612/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper612/Authors|ICLR.cc/2020/Conference/Paper612/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504168858, "tmdate": 1576860556544, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper612/Authors", "ICLR.cc/2020/Conference/Paper612/Reviewers", "ICLR.cc/2020/Conference/Paper612/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper612/-/Official_Comment"}}}, {"id": "r1lg9KIEjS", "original": null, "number": 1, "cdate": 1573312903931, "ddate": null, "tcdate": 1573312903931, "tmdate": 1573312903931, "tddate": null, "forum": "Bke6vTVYwH", "replyto": "rkgIzF3Zcr", "invitation": "ICLR.cc/2020/Conference/Paper612/-/Official_Comment", "content": {"title": "Response to Reviewer #1", "comment": "We would like to thank the reviewer for the positive feedback. We reply to the the two questions below.\n\nQ1: For the motivation of this method, why would the graph be constructed within each class? If there is a correlation between different classes, how could the model use such class-wise correlation to clean the label?\n\nR1: The most general graph would be constructed based on image and text similarities combined. Here, we pre-filter with text similarity, i.e., label names, and then build the graph based on visual similarities. This permits (a) to significantly reduce the size of the graph and hence the complexity and (b) to reduce the noise during the cleaning task. We agree that operating on the more complex graph could be the subject of future research, but a significantly different method would be required and the gain of the correlation is not granted.\n\n\nQ2: Maybe I missed it, but how is the relevance score / predicted label determined for testing data given the graphs constructed in each class of training data?\n\nR2: There is no relevance score assigned to the test data. Relevance scores are only used during training. In particular, we build per-class graphs using the training data, assign each training example a relevance score (Section 4), and train a classifier using the training data and the corresponding relevance scores (Section 5). Now given a test image, a prediction is simply made by the classifier; no data or relevance scores are used. See also pseudo-code in response R1 to reviewer 3.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper612/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper612/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph convolutional networks for learning with few clean and many noisy labels", "authors": ["Ahmet Iscen", "Giorgos Tolias", "Yannis Avrithis", "Ondrej Chum", "Cordelia Schmid"], "authorids": ["iscen@google.com", "giorgos.tolias@cmp.felk.cvut.cz", "yannis@avrithis.net", "chum@cmp.felk.cvut.cz", "cordelias@google.com"], "keywords": [], "abstract": "In this work we consider the problem of learning a classifier from noisy labels when a few clean labeled examples are given. The structure of clean and noisy data is modeled by a graph per class and Graph Convolutional Networks (GCN) are used to predict class relevance of noisy examples. For each class, the GCN is treated as a binary classifier learning to discriminate clean from noisy examples using a weighted binary cross-entropy loss function, and then the GCN-inferred \"clean\" probability is exploited as a relevance measure. Each noisy example is weighted by its relevance when learning a classifier for the end task. We evaluate our method on an extended version of a few-shot learning problem, where the few clean examples of novel classes are supplemented with additional noisy data. Experimental results show that our GCN-based cleaning process significantly improves the classification accuracy over not cleaning the noisy data and standard few-shot classification where only few clean examples are used. The proposed GCN-based method outperforms the transductive approach (Douze et al., 2018) that is using the same additional data without labels.", "pdf": "/pdf/128d55ded5d893b0eeac73626635a6274b04d1da.pdf", "paperhash": "iscen|graph_convolutional_networks_for_learning_with_few_clean_and_many_noisy_labels", "original_pdf": "/attachment/128d55ded5d893b0eeac73626635a6274b04d1da.pdf", "_bibtex": "@misc{\niscen2020graph,\ntitle={Graph convolutional networks for learning with few clean and many noisy labels},\nauthor={Ahmet Iscen and Giorgos Tolias and Yannis Avrithis and Ondrej Chum and Cordelia Schmid},\nyear={2020},\nurl={https://openreview.net/forum?id=Bke6vTVYwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Bke6vTVYwH", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper612/Authors", "ICLR.cc/2020/Conference/Paper612/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper612/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper612/Reviewers", "ICLR.cc/2020/Conference/Paper612/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper612/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper612/Authors|ICLR.cc/2020/Conference/Paper612/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504168858, "tmdate": 1576860556544, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper612/Authors", "ICLR.cc/2020/Conference/Paper612/Reviewers", "ICLR.cc/2020/Conference/Paper612/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper612/-/Official_Comment"}}}, {"id": "SylESLC6Fr", "original": null, "number": 1, "cdate": 1571837500037, "ddate": null, "tcdate": 1571837500037, "tmdate": 1572972573498, "tddate": null, "forum": "Bke6vTVYwH", "replyto": "Bke6vTVYwH", "invitation": "ICLR.cc/2020/Conference/Paper612/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper studies the problem of learning from multiple tasks and additional noisy data. The proposed representation learning method first assigns each noisy data a relevance score using the topological information. Then the authors propose to minimize a combination of the loss of a class-prototype learning loss and a cosine classifier learning loss to learn a good representation generator g_theta. The empirical study validates the effectiveness of the proposed method.\n\nI have the following comments,\n\n1. The studied problem that learning from few-shot data and large-scale noisy data is interesting. According to the experimental results, the proposed method seems to be promising.\n\n2. The learning procedure is confusing. It is highly recommended to provide the pseudocode of the proposed method.\n\n3. Since there are many tasks and each task has a large-scale data, I'm afraid that the running time will explode. How to deal with this issue?"}, "signatures": ["ICLR.cc/2020/Conference/Paper612/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper612/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph convolutional networks for learning with few clean and many noisy labels", "authors": ["Ahmet Iscen", "Giorgos Tolias", "Yannis Avrithis", "Ondrej Chum", "Cordelia Schmid"], "authorids": ["iscen@google.com", "giorgos.tolias@cmp.felk.cvut.cz", "yannis@avrithis.net", "chum@cmp.felk.cvut.cz", "cordelias@google.com"], "keywords": [], "abstract": "In this work we consider the problem of learning a classifier from noisy labels when a few clean labeled examples are given. The structure of clean and noisy data is modeled by a graph per class and Graph Convolutional Networks (GCN) are used to predict class relevance of noisy examples. For each class, the GCN is treated as a binary classifier learning to discriminate clean from noisy examples using a weighted binary cross-entropy loss function, and then the GCN-inferred \"clean\" probability is exploited as a relevance measure. Each noisy example is weighted by its relevance when learning a classifier for the end task. We evaluate our method on an extended version of a few-shot learning problem, where the few clean examples of novel classes are supplemented with additional noisy data. Experimental results show that our GCN-based cleaning process significantly improves the classification accuracy over not cleaning the noisy data and standard few-shot classification where only few clean examples are used. The proposed GCN-based method outperforms the transductive approach (Douze et al., 2018) that is using the same additional data without labels.", "pdf": "/pdf/128d55ded5d893b0eeac73626635a6274b04d1da.pdf", "paperhash": "iscen|graph_convolutional_networks_for_learning_with_few_clean_and_many_noisy_labels", "original_pdf": "/attachment/128d55ded5d893b0eeac73626635a6274b04d1da.pdf", "_bibtex": "@misc{\niscen2020graph,\ntitle={Graph convolutional networks for learning with few clean and many noisy labels},\nauthor={Ahmet Iscen and Giorgos Tolias and Yannis Avrithis and Ondrej Chum and Cordelia Schmid},\nyear={2020},\nurl={https://openreview.net/forum?id=Bke6vTVYwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Bke6vTVYwH", "replyto": "Bke6vTVYwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper612/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper612/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575833769147, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper612/Reviewers"], "noninvitees": [], "tcdate": 1570237749607, "tmdate": 1575833769161, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper612/-/Official_Review"}}}, {"id": "rkgIzF3Zcr", "original": null, "number": 2, "cdate": 1572092173552, "ddate": null, "tcdate": 1572092173552, "tmdate": 1572972573455, "tddate": null, "forum": "Bke6vTVYwH", "replyto": "Bke6vTVYwH", "invitation": "ICLR.cc/2020/Conference/Paper612/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "This paper presents a classification method when the data consists of few clean labels and many noisy labels. The authors propose to construct a graph structure within each class and use graph convolutional network to determine the clean/noisy labels of samples in each class. The model is based on a binary cross entropy loss function in each class, which learns the probability of labels to be clean. And such \"clean\" probability is used as the measure of relevance score between the sample different classes.\n\nThe idea of this paper is straightforward and the experimental results seem promising. The authors compare with several related methods and show the proposed method has better performance in few shot learning experiments.\n\nFor the motivation of this methods, why would the graph be constructed within each class? If there is correlation between different classes, how could the model use such class-wise correlation to clean the label?\n\nMaybe I missed it, but how is the relevance score / predicted label determined for testing data given the graphs constructed in each class of training data?"}, "signatures": ["ICLR.cc/2020/Conference/Paper612/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper612/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph convolutional networks for learning with few clean and many noisy labels", "authors": ["Ahmet Iscen", "Giorgos Tolias", "Yannis Avrithis", "Ondrej Chum", "Cordelia Schmid"], "authorids": ["iscen@google.com", "giorgos.tolias@cmp.felk.cvut.cz", "yannis@avrithis.net", "chum@cmp.felk.cvut.cz", "cordelias@google.com"], "keywords": [], "abstract": "In this work we consider the problem of learning a classifier from noisy labels when a few clean labeled examples are given. The structure of clean and noisy data is modeled by a graph per class and Graph Convolutional Networks (GCN) are used to predict class relevance of noisy examples. For each class, the GCN is treated as a binary classifier learning to discriminate clean from noisy examples using a weighted binary cross-entropy loss function, and then the GCN-inferred \"clean\" probability is exploited as a relevance measure. Each noisy example is weighted by its relevance when learning a classifier for the end task. We evaluate our method on an extended version of a few-shot learning problem, where the few clean examples of novel classes are supplemented with additional noisy data. Experimental results show that our GCN-based cleaning process significantly improves the classification accuracy over not cleaning the noisy data and standard few-shot classification where only few clean examples are used. The proposed GCN-based method outperforms the transductive approach (Douze et al., 2018) that is using the same additional data without labels.", "pdf": "/pdf/128d55ded5d893b0eeac73626635a6274b04d1da.pdf", "paperhash": "iscen|graph_convolutional_networks_for_learning_with_few_clean_and_many_noisy_labels", "original_pdf": "/attachment/128d55ded5d893b0eeac73626635a6274b04d1da.pdf", "_bibtex": "@misc{\niscen2020graph,\ntitle={Graph convolutional networks for learning with few clean and many noisy labels},\nauthor={Ahmet Iscen and Giorgos Tolias and Yannis Avrithis and Ondrej Chum and Cordelia Schmid},\nyear={2020},\nurl={https://openreview.net/forum?id=Bke6vTVYwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Bke6vTVYwH", "replyto": "Bke6vTVYwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper612/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper612/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575833769147, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper612/Reviewers"], "noninvitees": [], "tcdate": 1570237749607, "tmdate": 1575833769161, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper612/-/Official_Review"}}}], "count": 8}