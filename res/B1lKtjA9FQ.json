{"notes": [{"id": "B1lKtjA9FQ", "original": "r1l1vGj9FQ", "number": 464, "cdate": 1538087808888, "ddate": null, "tcdate": 1538087808888, "tmdate": 1545355441893, "tddate": null, "forum": "B1lKtjA9FQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Overfitting Detection of Deep Neural Networks without a Hold Out Set", "abstract": "Overfitting is an ubiquitous problem in neural network training and usually mitigated using a holdout data set.\nHere we challenge this rationale and investigate criteria for overfitting without using a holdout data set.\nSpecifically, we train a model for a fixed number of epochs multiple times with varying fractions of randomized labels and for a range of regularization strengths. \nA properly trained model should not be able to attain an accuracy greater than the fraction of properly labeled data points. Otherwise the model overfits. \nWe introduce two criteria for detecting overfitting and one to detect underfitting. We analyze early stopping, the regularization factor, and network depth.\nIn safety critical applications we are interested in models and parameter settings which perform well and are not likely to overfit. The methods of this paper allow characterizing and identifying such models.", "keywords": ["deep learning", "overfitting", "generalization", "memorization"], "authorids": ["konrad.groh@de.bosch.com"], "authors": ["Konrad Groh"], "TL;DR": "We introduce and analyze several criteria for detecting overfitting.", "pdf": "/pdf/60fb95af056f8b89084ffa9e89d25568cdb43f32.pdf", "paperhash": "groh|overfitting_detection_of_deep_neural_networks_without_a_hold_out_set", "_bibtex": "@misc{\ngroh2019overfitting,\ntitle={Overfitting Detection of Deep Neural Networks without a Hold Out Set},\nauthor={Konrad Groh},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lKtjA9FQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "HJxFwTCPgV", "original": null, "number": 1, "cdate": 1545231712539, "ddate": null, "tcdate": 1545231712539, "tmdate": 1545354475628, "tddate": null, "forum": "B1lKtjA9FQ", "replyto": "B1lKtjA9FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper464/Meta_Review", "content": {"metareview": "The reviewers reached a consensus that the paper is not fit for publication for the moment because a) the paper lacks thorough experiments and b) the criteria provided by the paper are relatively evague (see more details in reviewer 3's comments.\uff09", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "meta-review"}, "signatures": ["ICLR.cc/2019/Conference/Paper464/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper464/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Overfitting Detection of Deep Neural Networks without a Hold Out Set", "abstract": "Overfitting is an ubiquitous problem in neural network training and usually mitigated using a holdout data set.\nHere we challenge this rationale and investigate criteria for overfitting without using a holdout data set.\nSpecifically, we train a model for a fixed number of epochs multiple times with varying fractions of randomized labels and for a range of regularization strengths. \nA properly trained model should not be able to attain an accuracy greater than the fraction of properly labeled data points. Otherwise the model overfits. \nWe introduce two criteria for detecting overfitting and one to detect underfitting. We analyze early stopping, the regularization factor, and network depth.\nIn safety critical applications we are interested in models and parameter settings which perform well and are not likely to overfit. The methods of this paper allow characterizing and identifying such models.", "keywords": ["deep learning", "overfitting", "generalization", "memorization"], "authorids": ["konrad.groh@de.bosch.com"], "authors": ["Konrad Groh"], "TL;DR": "We introduce and analyze several criteria for detecting overfitting.", "pdf": "/pdf/60fb95af056f8b89084ffa9e89d25568cdb43f32.pdf", "paperhash": "groh|overfitting_detection_of_deep_neural_networks_without_a_hold_out_set", "_bibtex": "@misc{\ngroh2019overfitting,\ntitle={Overfitting Detection of Deep Neural Networks without a Hold Out Set},\nauthor={Konrad Groh},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lKtjA9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper464/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353208254, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1lKtjA9FQ", "replyto": "B1lKtjA9FQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper464/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper464/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper464/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353208254}}}, {"id": "SyxawBYqRQ", "original": null, "number": 1, "cdate": 1543308644931, "ddate": null, "tcdate": 1543308644931, "tmdate": 1543308644931, "tddate": null, "forum": "B1lKtjA9FQ", "replyto": "B1lKtjA9FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper464/Official_Comment", "content": {"title": "Replies to reviewers", "comment": "We would like to thank all reviewers for their time and (critical) comments. We appreciate your feed back. Let us answer your concerns.\n\nThere does not seem to be a good notion of overfitting for neural network training. This is exemplified for example in the Zhang et al. paper by showing that a network learns data with randomly shuffled labels. Or other memorization experiments, such as Arpit et al. That the authors do comes close to our criterion (C2). The Bartlett et al. and the Liang et al. papers are another example. To show the effects of their (theoretical) methods they analyze the plots of the margin distributions. This is close to (C3).\n\nOur paper tries to give some criteria at hand to show that a proposed method (such as l1-regularization) has an positive effect on the generalization capacity of the trained neural network. In the paper we propose to use criterion (C1) to address this task.\n\nThe assumptions made in Section 3.3. serve two purposes: (1) they show that making them results in concave/convex accuracy curves. (2) it connects (C1) to the already used criteria (C2) and (C3). \n\nLooking at the accuracy plots of real curves we see that they are not convex - we attribute this to the dependence of the regularization parameters to the optimization and to a lesser extend correlation within the data.\n\nTo make the arguments more convincing we included two further data sets, a different network and analyzed also drop-out and l2-regularization. To summarize the experiments it behaves as claimed, the accuracy plots on mnist looks rather neat. \n\nWe further provided a numerical measure for the criteria. We would like to make a point for visual inspection. True the ultimate gaol is an algorithm, but before that we have to be convinced that we are doing something useful. We believe that the margin histograms (C3) and also the plots of (C1) capture overfitting and underfitting quite nicely.\n\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper464/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper464/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper464/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Overfitting Detection of Deep Neural Networks without a Hold Out Set", "abstract": "Overfitting is an ubiquitous problem in neural network training and usually mitigated using a holdout data set.\nHere we challenge this rationale and investigate criteria for overfitting without using a holdout data set.\nSpecifically, we train a model for a fixed number of epochs multiple times with varying fractions of randomized labels and for a range of regularization strengths. \nA properly trained model should not be able to attain an accuracy greater than the fraction of properly labeled data points. Otherwise the model overfits. \nWe introduce two criteria for detecting overfitting and one to detect underfitting. We analyze early stopping, the regularization factor, and network depth.\nIn safety critical applications we are interested in models and parameter settings which perform well and are not likely to overfit. The methods of this paper allow characterizing and identifying such models.", "keywords": ["deep learning", "overfitting", "generalization", "memorization"], "authorids": ["konrad.groh@de.bosch.com"], "authors": ["Konrad Groh"], "TL;DR": "We introduce and analyze several criteria for detecting overfitting.", "pdf": "/pdf/60fb95af056f8b89084ffa9e89d25568cdb43f32.pdf", "paperhash": "groh|overfitting_detection_of_deep_neural_networks_without_a_hold_out_set", "_bibtex": "@misc{\ngroh2019overfitting,\ntitle={Overfitting Detection of Deep Neural Networks without a Hold Out Set},\nauthor={Konrad Groh},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lKtjA9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper464/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609682, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1lKtjA9FQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper464/Authors", "ICLR.cc/2019/Conference/Paper464/Reviewers", "ICLR.cc/2019/Conference/Paper464/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper464/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper464/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper464/Authors|ICLR.cc/2019/Conference/Paper464/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper464/Reviewers", "ICLR.cc/2019/Conference/Paper464/Authors", "ICLR.cc/2019/Conference/Paper464/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609682}}}, {"id": "B1ghFGtj27", "original": null, "number": 3, "cdate": 1541276292150, "ddate": null, "tcdate": 1541276292150, "tmdate": 1542865117025, "tddate": null, "forum": "B1lKtjA9FQ", "replyto": "B1lKtjA9FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper464/Official_Review", "content": {"title": "Novel contributions are not apparent, needs more empirical evaluation", "review": "This paper is about detecting overfitting of deep neural networks without using a validation set. This is an interesting research problem. However, it is not clear how this paper contributes to solve the problem. My understanding is that this is a preliminary work, put into a paper in haste. There are more research efforts required to turn it into a good paper, theoretically as well empirically.\n\nOne of the key ideas proposed is to obtain multiple instances of neural network models with each one from training on a dataset that is a noisier version of the original dataset; noise is added by permuting lables for a fraction of the original dataset. Then, one can plot training error w.r.t. the level of noise so as to see if the neural model is overfitting. \n\nAuthors present their intuitions on what what patterns for the curves (concave curves) would correspond to overfitting. While the arguments seem convincing, one can not be sure unless there is some solid experimental evaluation across multiple datasets or a good theoretical basis. \n\nHere it is also worth noting that the proposed method is not compared w.r.t. any other baseline methods. Basically, in their empirical evaluation, the authors use the existing techniques for regularization to build a variety of neural network models, and then manually analyze the generalization gap for a given model by looking upon the aforementioned curve on training error w.r.t. noise. \n\nDoes it mean that the method is just for tuning the values of the parameters related to regularization (like l1 regularization constant, number of iterations, etc)? If so, is there an algorithm to do the fine tuning rather than doing manual analysis of the curves with each one representing a configuration of the regularization parameter values. What would be compute complexity of such an algorithm considering the fact that producing a single curve requires training the neural network multiple times.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper464/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Overfitting Detection of Deep Neural Networks without a Hold Out Set", "abstract": "Overfitting is an ubiquitous problem in neural network training and usually mitigated using a holdout data set.\nHere we challenge this rationale and investigate criteria for overfitting without using a holdout data set.\nSpecifically, we train a model for a fixed number of epochs multiple times with varying fractions of randomized labels and for a range of regularization strengths. \nA properly trained model should not be able to attain an accuracy greater than the fraction of properly labeled data points. Otherwise the model overfits. \nWe introduce two criteria for detecting overfitting and one to detect underfitting. We analyze early stopping, the regularization factor, and network depth.\nIn safety critical applications we are interested in models and parameter settings which perform well and are not likely to overfit. The methods of this paper allow characterizing and identifying such models.", "keywords": ["deep learning", "overfitting", "generalization", "memorization"], "authorids": ["konrad.groh@de.bosch.com"], "authors": ["Konrad Groh"], "TL;DR": "We introduce and analyze several criteria for detecting overfitting.", "pdf": "/pdf/60fb95af056f8b89084ffa9e89d25568cdb43f32.pdf", "paperhash": "groh|overfitting_detection_of_deep_neural_networks_without_a_hold_out_set", "_bibtex": "@misc{\ngroh2019overfitting,\ntitle={Overfitting Detection of Deep Neural Networks without a Hold Out Set},\nauthor={Konrad Groh},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lKtjA9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper464/Official_Review", "cdate": 1542234455573, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "B1lKtjA9FQ", "replyto": "B1lKtjA9FQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper464/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335730103, "tmdate": 1552335730103, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper464/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rJlGnDM9hQ", "original": null, "number": 2, "cdate": 1541183402113, "ddate": null, "tcdate": 1541183402113, "tmdate": 1541533973196, "tddate": null, "forum": "B1lKtjA9FQ", "replyto": "B1lKtjA9FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper464/Official_Review", "content": {"title": "Not convincing enough.", "review": "This paper proposed criteria to measure the capacity of a neural network by injecting perturbation (randomized training data). The paper attempted to show that $l_1$-regularization of the kernel weights is a good measure to control the capacity of a network which contradicts the previous finding by Zhang et al (2017) on regularization which claimed that regularization is neither necessary nor by itself sufficient for controlling generalization error.\n \n\nThe proposed method does not require a held out data to check overfitting, which is an interesting direction to explore. The theoretical analysis is seeming to be correct, however, I don\u2019t have strong expertise in theory, therefore, can not assure the correctness.  The experiments, however, are limited. The experiment was done on cifar-10 and the analysis is based on the early stopping, regularization factor and network depth. \n\nThere is only one dataset that was used for the experiments, more dataset should be explored for robust evaluation. \n\nThe assumptions should be clarified and write clearly. For example, \u201cThus we also expect that accuracy drops if the regularization of the model is increased.\u201d, which accuracy (training?) and what exactly means by increased regularization (value of $\\lambda$)?\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper464/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Overfitting Detection of Deep Neural Networks without a Hold Out Set", "abstract": "Overfitting is an ubiquitous problem in neural network training and usually mitigated using a holdout data set.\nHere we challenge this rationale and investigate criteria for overfitting without using a holdout data set.\nSpecifically, we train a model for a fixed number of epochs multiple times with varying fractions of randomized labels and for a range of regularization strengths. \nA properly trained model should not be able to attain an accuracy greater than the fraction of properly labeled data points. Otherwise the model overfits. \nWe introduce two criteria for detecting overfitting and one to detect underfitting. We analyze early stopping, the regularization factor, and network depth.\nIn safety critical applications we are interested in models and parameter settings which perform well and are not likely to overfit. The methods of this paper allow characterizing and identifying such models.", "keywords": ["deep learning", "overfitting", "generalization", "memorization"], "authorids": ["konrad.groh@de.bosch.com"], "authors": ["Konrad Groh"], "TL;DR": "We introduce and analyze several criteria for detecting overfitting.", "pdf": "/pdf/60fb95af056f8b89084ffa9e89d25568cdb43f32.pdf", "paperhash": "groh|overfitting_detection_of_deep_neural_networks_without_a_hold_out_set", "_bibtex": "@misc{\ngroh2019overfitting,\ntitle={Overfitting Detection of Deep Neural Networks without a Hold Out Set},\nauthor={Konrad Groh},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lKtjA9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper464/Official_Review", "cdate": 1542234455573, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "B1lKtjA9FQ", "replyto": "B1lKtjA9FQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper464/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335730103, "tmdate": 1552335730103, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper464/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rkevTD1qh7", "original": null, "number": 1, "cdate": 1541171134924, "ddate": null, "tcdate": 1541171134924, "tmdate": 1541533972994, "tddate": null, "forum": "B1lKtjA9FQ", "replyto": "B1lKtjA9FQ", "invitation": "ICLR.cc/2019/Conference/-/Paper464/Official_Review", "content": {"title": "Potential overfitting criteria remain vague and were not properly validated", "review": "Overview:\nThe authors aim at finding and investigating criteria that allow to determine whether a deep (convolutional) model overfits the training data without using a hold-out data set.  \nInstead of using a hold-out set they propose to randomly flip the labels of certain amounts of training data and inspect the corresponding 'accuracy vs. randomization\u2018 curves. They propose three potential criteria based on the curves for determining when a model overfits and use those to determine the smallest l1-regularization parameter value that does not overfit. \nI have several issues with this work. Foremost, the presented criteria are actually not real criteria (expect maybe C1) but rather general guidelines to visually inspect 'accuracy over randomization\u2018 curves. The criteria remain very vague and seem be to applicable mainly to the evaluated data set (e.g. what defines a \u2019steep decrease\u2019?). Because of that, the experimental evaluation remains vague as well, as the criteria are tested on one data set by visual inspection. Additionally, only one type of regularization was assumed, namely l1-regularization, though other types are arguably more common in the deep (convolutional) learning literature.  \nOverall, I think this paper is not fit for publication, because the contributions of the paper seem very vague and are neither thoroughly defined nor tested.\n\n\nDetailed remarks:\n\nGeneral:\nA proper definition or at least a somewhat better notion of overfitting would have benefitted the paper. In the current version, you seem to define overfitting on-the-fly while defining your criteria. \n\nYou mention complexity of data and model several times in the paper but never define what you mean by that.\n\n\nDetailed:\nPage 3, last paragraph: Why did you not use bias terms in your model?\n\nPage 4, Assumption. \n- What do you mean by the data being independent? Independent and identically distributed?  \n- \"As in that case correlation in the data can be destroyed by the introduction of randomness making the data easier to learn.\u201c What do you mean by \"easier to learn\"? Better generalization? Better training error? \n- I don\u2019t understand the assumptions. You state that the regularization parameter should decrease complexity of the model. Is that an assumption? And how do you use that later?\n- What does \"similar scale\u201c mean? \n\nPage 4, Monotony. \n- You state two assumptions or claims, 'the accuracy curve is strictly monotonically decreasing for increasing randomness\u2018 and 'we also expect that accuracy drops if the regularization of the model is increased\u2019, and then state that 'This shows that the accuracy is strictly monotonically decreasing as a function of randomness and regularization.\u2018 Although you didn\u2019t show anything but only state assumptions or claims (which may be reasonable but are not backed up here). \nI actually don\u2019t understand the purpose of this paragraph.\n\n- Section 3.3 is confusing to me. What you actually do here is you present 3 different general criteria that could potentially detect overfitting on label-randomized  training sets. But you state it as if those measures are actually correct, which you didn\u2019t show yet.\n\nMy main concern here, besides the motivations that I did not fully understand (s.b.), is the lack of measurable criteria. While for criterion 1 you define overfitting as 'above the diagonal line\u2018 and underfitting as \u201abelow the line\u2018, which is at least measurable depending on sample density of the randomization, such criteria are missing for C2 and C3.       Instead, you present vague of \u2019sharp drops\u2019 and two modes but do not present rigorous definitions. You present a number for C2 in Section 5, but that is only applicable to the present data set (i.e. assuming that training accuracy is 1). \n\nCriterion 2 (b) is not clear.  \n- I neither understand \"As the accuracy curve is also monotone decreasing with increasing regularization we will also detect the convexity by a steep drop in accuracy as depicted by the marked point in the Figure 1(b)\" \nnor do I understand \"accuracy over regularization curve (plotted in log-log space) is constant\"?\nDoes that mean that you assume that whenever the training accuracy drops lower than that of the model without regularization, it starts to underfit?\n\nDue to the lack of numerical measures, the experimental evaluation necessarily remains vague by showing some graphs that show that all criteria are roughly met by regularization parameter \\lambda=0.00011 on the cifar data set.  In my view, this evaluation of the (vague) criteria is not fit for showing their possible merit.\n\n\n\n\n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper464/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Overfitting Detection of Deep Neural Networks without a Hold Out Set", "abstract": "Overfitting is an ubiquitous problem in neural network training and usually mitigated using a holdout data set.\nHere we challenge this rationale and investigate criteria for overfitting without using a holdout data set.\nSpecifically, we train a model for a fixed number of epochs multiple times with varying fractions of randomized labels and for a range of regularization strengths. \nA properly trained model should not be able to attain an accuracy greater than the fraction of properly labeled data points. Otherwise the model overfits. \nWe introduce two criteria for detecting overfitting and one to detect underfitting. We analyze early stopping, the regularization factor, and network depth.\nIn safety critical applications we are interested in models and parameter settings which perform well and are not likely to overfit. The methods of this paper allow characterizing and identifying such models.", "keywords": ["deep learning", "overfitting", "generalization", "memorization"], "authorids": ["konrad.groh@de.bosch.com"], "authors": ["Konrad Groh"], "TL;DR": "We introduce and analyze several criteria for detecting overfitting.", "pdf": "/pdf/60fb95af056f8b89084ffa9e89d25568cdb43f32.pdf", "paperhash": "groh|overfitting_detection_of_deep_neural_networks_without_a_hold_out_set", "_bibtex": "@misc{\ngroh2019overfitting,\ntitle={Overfitting Detection of Deep Neural Networks without a Hold Out Set},\nauthor={Konrad Groh},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lKtjA9FQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper464/Official_Review", "cdate": 1542234455573, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "B1lKtjA9FQ", "replyto": "B1lKtjA9FQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper464/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335730103, "tmdate": 1552335730103, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper464/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 6}