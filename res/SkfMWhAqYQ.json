{"notes": [{"id": "SkfMWhAqYQ", "original": "HkgToZ05Ym", "number": 1150, "cdate": 1538087930011, "ddate": null, "tcdate": 1538087930011, "tmdate": 1549550527376, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 27, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "rygfEq_qx4", "original": null, "number": 24, "cdate": 1545402921735, "ddate": null, "tcdate": 1545402921735, "tmdate": 1545402921735, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "B1g56mREeE", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "content": {"title": "Thanks for your thoughts", "comment": "Thanks for your thoughts and honest opinion! The decision period might be over but I'd still be curious to get a better understanding of your point of view. To be concrete, in the TL;DR we formulated:\n\n\"Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.\"\n\nYou seem to weigh the contributions of our paper a bit differently. If you are in the mood and can spare the time I would be very grateful if you could formulate an alternative TL;DR that is better aligned with your perception of the work."}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/Authors"], "readers": ["ICLR.cc/2019/Conference/Paper1150/Authors", "everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609590, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkfMWhAqYQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1150/Authors|ICLR.cc/2019/Conference/Paper1150/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609590}}}, {"id": "Byg9QIWlxN", "original": null, "number": 1, "cdate": 1544717857939, "ddate": null, "tcdate": 1544717857939, "tmdate": 1545354508498, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "SkfMWhAqYQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Meta_Review", "content": {"metareview": "This paper presents an approach that relies on DNNs and bags of features that are fed into them, towards object recognition.  The strength of the papers lie in the strong performance of these simple and interpretable models compared to more complex architectures.  The authors stress on the interpretability of the results that is indeed a strength of this paper.\n\nThere is plenty of discussion between the first reviewer and the authors regarding the novelty of the work as the former point out to several related papers;  however, the authors provide relatively convincing rebuttal of the concerns.\n\nOverall, after the long discussion, there is enough consensus for this paper to be accepted to the conference.", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Accept (Poster)", "title": "Meta Review"}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1150/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352946642, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkfMWhAqYQ", "replyto": "SkfMWhAqYQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1150/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1150/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352946642}}}, {"id": "B1g56mREeE", "original": null, "number": 23, "cdate": 1545032641851, "ddate": null, "tcdate": 1545032641851, "tmdate": 1545032663522, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "SkxzS7El6Q", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "content": {"title": "-", "comment": "Dear author,\n\nI guess I missed this answer. I'm not sure it is fair to claim this CNN is more interpretable, in the sens that this work opens more questions than it closes. \"a transparent and interpretable spatial aggregation mechanism\", is a bit of an overkill in my humble opinion. Do not worry, this does not affect my review or score, however I do prefer to be honest on this point.\n\nI think in the current context of DL, such works should make clear statements of their contributions(and there are a lot here!)\n\nRegards,\n_"}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1150/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609590, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkfMWhAqYQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1150/Authors|ICLR.cc/2019/Conference/Paper1150/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609590}}}, {"id": "rklqfQFACQ", "original": null, "number": 21, "cdate": 1543570194257, "ddate": null, "tcdate": 1543570194257, "tmdate": 1543570194257, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "Hyg_lE5NRX", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "content": {"title": "Thanks for this rebuttal", "comment": "Thank you. It answered all my concerns/questions."}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1150/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609590, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkfMWhAqYQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1150/Authors|ICLR.cc/2019/Conference/Paper1150/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609590}}}, {"id": "rJeVUiaFRQ", "original": null, "number": 19, "cdate": 1543261003734, "ddate": null, "tcdate": 1543261003734, "tmdate": 1543261003734, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "SkfMWhAqYQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "content": {"title": "Author's summary of rebuttal discussion", "comment": "We would like to thank all reviewers for their valuable feedback and we very much appreciate their assessment of our work as \u201cinteresting\u201d (R1), \u201cworth to be shared in the community\u201d (R2) and \u201ca valuable contribution to ICLR\u201d (R3).\n\nWe responded in detail to the comments of each reviewer below and summarise here the main changes to the manuscript:\n\n* We clarified that this work is unrelated to region proposal models (like Wei et al. or Tang et al.) in the related work section. (R1)\n* We added an experiment probing the sensitivity of the BagNets to the precise numerical values of the heatmaps in the appendix. (R3)\n* We added runtime measurements for BagNets to the results section. (R1)\n* We added a paragraph in the introduction to define precisely our meaning of interpretability. (R3)\n* We defined our notion of \u201clinear BoF models\u201d and commented on its relevance in the model description. (R3)\n* We straightened the use of the word \u201cfeature\" throughout the manuscript. (R3)\n* We modified Figure A.1 to clarify the downsampling step. (R3)"}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609590, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkfMWhAqYQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1150/Authors|ICLR.cc/2019/Conference/Paper1150/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609590}}}, {"id": "rkeeML9EAX", "original": null, "number": 18, "cdate": 1542919687778, "ddate": null, "tcdate": 1542919687778, "tmdate": 1542919687778, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "rken1AAkpm", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "content": {"title": "-", "comment": "Thanks again for the open discussion and for thinking about raising your score. Please let us know if there are any further clarifications or questions that we should address."}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609590, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkfMWhAqYQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1150/Authors|ICLR.cc/2019/Conference/Paper1150/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609590}}}, {"id": "Hyg_lE5NRX", "original": null, "number": 17, "cdate": 1542919151906, "ddate": null, "tcdate": 1542919151906, "tmdate": 1542919437543, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "SyxHQ7UVRQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "content": {"title": "Thresholding has little effect on accuracy", "comment": "As promised we tested how thresholding the logits affects accuracy. We thresholded in two ways: first, by setting all values *below* the threshold to the threshold (and all values above the threshold stay as is). In the second case we binarised the heatmaps by setting all values below the threshold to zero and all values above the threshold to one (this completely removes the amplitude). Please find the results at https://ibb.co/eLJqfV .\n\nMost interestingly, for certain binarization thresholds the top-5 accuracy is within 1-2% of the vanilla BagNet performance. This indeed supports your intuition that the amplitude of the heatmaps is not the most important factor. We will include these results (with some more intermediate values) in the appendix."}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609590, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkfMWhAqYQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1150/Authors|ICLR.cc/2019/Conference/Paper1150/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609590}}}, {"id": "Skg7JULVRm", "original": null, "number": 16, "cdate": 1542903259000, "ddate": null, "tcdate": 1542903259000, "tmdate": 1542903259000, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "rkerSzKq2X", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "content": {"title": "Thanks!", "comment": "Thanks a lot for appreciating our contribution!\n\n> Comparison with attention models is necessary to compare the important patches obtained from conventional networks.\n\nIn the paper  (section 4.3) we quantitatively show that the patches important to BagNets are also important for standard CNNs. Is that the direction you were thinking about? If you have a different experiment in mind we would like to kindly ask you for more details."}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609590, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkfMWhAqYQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1150/Authors|ICLR.cc/2019/Conference/Paper1150/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609590}}}, {"id": "SyxHQ7UVRQ", "original": null, "number": 15, "cdate": 1542902557314, "ddate": null, "tcdate": 1542902557314, "tmdate": 1542902557314, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "Skgkfb8NCX", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "content": {"title": "Thanks for the insightful review!", "comment": "Please excuse our late response and thanks for your insightful feedback and your positive assessment! We are in the middle of the thresholding experiment you suggested. We report on the results later today or tomorrow and would like to respond to the rest of your comments and suggestions:\n\n1) Reference to scattering network [1]\nThat\u2019s indeed an interesting and related reference with respect to spatially constrained network architectures that we\u2019ll add to the manuscript. The scattering network extracts patches of size 14 x 14 pixels and employs an additional two-layer fully connected network (or a ResNet-10) on top of those features. That unfortunately makes the spatial aggregation again harder to pinpoint (compared to BagNets) but the work is nonetheless an important precursor. We'll add the reference to the manuscript.\n\n2) \u00ab We construct a linear DNN-based BoF \u00bb \nThanks for pointing this out, we have to sharpen the related definitions. For us, the *classifier* is the part of the model _after_ the spatial aggregation (spatial average). The distinction of a linear vs a non-linear classifier is important because only the first is interchangeable with the spatial aggregation, which means that we can interpret the model as extracting evidence from each patch, which is then averaged across all patches. This guarantees that we can exactly attribute how important each patch is for the final model decision. This is not true if the classifier is non-linear. We will clarify this definition and its importance in the manuscript and hope that this sufficiently addresses  your concern.\n\n3) simplicity is subjective\nWe agree that one should add a more specific qualifier on \u201csimpler\u201d and \u201cmore interpretable\u201d as these terms can refer to different concepts. Thanks for pointing this out. What we mean is that the decision making process is more transparent: whereas CNNs take the whole image and somehow churn out a final label, the BagNets linearly accumulate evidence from very small patches to make a decision. This restricts the decision making to features of small size (e.g. BagNets cannot use shape), which makes it easier to understand how certain decisions have been reached (in terms of which image parts have been used). We will clarify this in the manuscript.\n\n4) \u201cthis work basically leaves the problem of understanding general CNNs to the problem of understanding MLPs\u201d\nIn terms of the evidence extraction from local patches you are right: our paper has nothing to add here. However, from the perspective of the whole image the decision making is more transparent (in terms of which image features are being used for classification) than for general CNNs. In addition, the MLPs now only look at small image patches, which means that the input distribution has much lower entropy. This makes it potentially easier to analyse what evidence is extracted by the MLPs. We will add a clarifying sentence into the manuscript.\n\n5) Network depiction in Appendix A\nThanks for pointing this out, indeed it looks as if the down pooling is performed in each block whereas in reality it\u2019s only used in the first. We\u2019ll add an arrow with a description saying \u201cdownsampling is only performed in the first block\u201d in each group.\n\n6) Usage of word \u201cfeatures\u201d\nThanks for pointing this out, we\u2019ll go through the manuscript and change the usage to \u201cimage feature\u201d (for small patches) or \u201cfeature embedding\u201d (to refer to the feature vector extracted by the DNN).\n\nQ1 : I was wondering if you did try manifold learning on the patches ? Do you expect it to work ?\nThat\u2019s an excellent question that we have not yet explored. We have some ideas in that direction (unsupervised learning of low-level image features) but no results to support or refute this idea.\n\nQ2 : Is there a batch normalization in the FC or a normalization? Did you try to threshold the heat maps before feeding them to the linear layer? I'm wondering indeed if the amplitude of those heatmaps is really key.\n\nThere is no normalisation between the average pooling and the linear classifier. We report back on the thresholding experiment today or tomorrow.\n\nQ3 : do you think it would be easy to exploit the non-overlapping patches for a better parallelization of computations ?\n\nThat\u2019s a good point, indeed that would be possible. One could simply cut an image into smaller parts (e.g. into 128 x 128 patches that overlap by q pixels on the borders where q is the RF size of the BagNet), then run each through the BagNets on separate GPUs and then sum the output of the linear classifier (before the softmax) from each part/GPU."}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609590, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkfMWhAqYQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1150/Authors|ICLR.cc/2019/Conference/Paper1150/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609590}}}, {"id": "Skgkfb8NCX", "original": null, "number": 14, "cdate": 1542902023441, "ddate": null, "tcdate": 1542902023441, "tmdate": 1542902023441, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "HJxDPF1t37", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "content": {"title": "Rebuttal?", "comment": "I'm respectfully wondering if the authors had any thoughts w.r.t. this review?"}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1150/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609590, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkfMWhAqYQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1150/Authors|ICLR.cc/2019/Conference/Paper1150/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609590}}}, {"id": "rkewfwbVCQ", "original": null, "number": 13, "cdate": 1542883086615, "ddate": null, "tcdate": 1542883086615, "tmdate": 1542883086615, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "BkxLk4fp3X", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "content": {"title": "Runtime is fast and deeper networks are only gradually shifting away from linear BagNets", "comment": "Thanks for your comments! Regarding runtimes, a BagNet-32/16/8 running on a GTX 1080 Ti can process 155 (+- 5) images / second of size 3 x 224 x 224 (in batches of 10). For comparison, a ResNet50 can process 570 images in the same time, so BagNets are around 3 to 4 times slower than standard ResNets. Please remember that BagNets are basically ResNets but with most 3x3 convolutions replaced by 1x1 convolutions, so this timing is roughly expected (we have less spatial dimensionality reduction which explains the increased runtimes).\n\nAs for deeper neural networks, we indeed observe a large deviation from BagNets the deeper and more precise the networks are. This can be observed from stronger non-linear interactions between spatial patches (Figure 6) and the reduced effectiveness of masking local regions (Figure 8). These deviations may come from (1) a more non-linear classifier on top of the local features or (2) larger local feature sizes. In any case, this is a gradual shift away from linear BagNets and we see it as a refinement of our results, not a contradiction."}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609590, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkfMWhAqYQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1150/Authors|ICLR.cc/2019/Conference/Paper1150/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609590}}}, {"id": "Bkeb0FIa2Q", "original": null, "number": 3, "cdate": 1541396936553, "ddate": null, "tcdate": 1541396936553, "tmdate": 1542810142369, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "SkfMWhAqYQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Review", "content": {"title": "Combing Patch-level CNN and BoF model has been done before, but the paper has the smallest patch", "review": "The idea of image classification based on patch-level deep feature in the BoF model has been studied extensively.  \n\n Just list few of them:\n\nWei et al. HCP: A Flexible CNN Framework for Multi-label Image Classification, IEEE TPAMI 2016\nTang et al. Deep Patch Learning for Weakly Supervised Object Classification and Discovery, Pattern Recognition 2017\nTang et al. Deep FisherNet for Object Classification, IEEE TNNLS\nArandjelovi\u0107 et al. NetVLAD: CNN Architecture for Weakly Supervised Place Recognition, CVPR 2016\n\nThe above papers are not cited in this paper.\n\nThere are some unique points. This work does not use RoIPooling layer and has results on ImageNet. But, the previous works use RoIPooling layer to save computations and works on scene understanding images, such as PASCAL. \n\nBesides, the paper uses the smallest patch among all the patch-based deep networks. It is interesting.\n\nI highly encourage the authors to finetune the ImageNet pre-trained BagNet on PASCAL VOC and compare to the previous patch-based deep networks.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Review", "cdate": 1542234294315, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SkfMWhAqYQ", "replyto": "SkfMWhAqYQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335883686, "tmdate": 1552335883686, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SkxzS7El6Q", "original": null, "number": 11, "cdate": 1541583674450, "ddate": null, "tcdate": 1541583674450, "tmdate": 1541583674450, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "B1eZr6Qxam", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "content": {"title": "Thanks for your feedback", "comment": "Thanks for your feedback! The word \"interpretable\" has different meanings for different people and we agree that we should be careful to define exactly what we mean by this term. There is a large body of literature trying to \"understand\" CNN decisions by means of a post-hoc feature attribution (i.e. which image parts have been important for the decision). So we mean \"more interpretable\" in the sense that this architecture transparently integrates evidence from different spatial locations and thus lets us precisely track which spatial features have been contributing how much to the final decision. For each individual location, however, the CNN feature extraction is still a black box. In other words, we reduced the complexity (and thus increased interpretability) of CNN decision making by introducing a transparent and interpretable spatial aggregation mechanism on top of a (still blackbox) local feature extraction. We'll update the manuscript to reflect this perspective more clearly and would appreciate your feedback."}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609590, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkfMWhAqYQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1150/Authors|ICLR.cc/2019/Conference/Paper1150/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609590}}}, {"id": "BylpZJNeTQ", "original": null, "number": 10, "cdate": 1541582597380, "ddate": null, "tcdate": 1541582597380, "tmdate": 1541582597380, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "rken1AAkpm", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "content": {"title": "-", "comment": "@R2: \"[3]\" can you comment on the accuracy of the paper you report?\n\n@R2, \"time complexity and speed\": Do you think it would be possible to design cuda routines that act in parallel on patches?\nHowever, I agree the memory use is more tricky, but I'm ok with it; this is not an engineering paper.\n\n@R2: \"ROIPooling\": could you point us to a paper using it for classification? I'd be very interested to read more about it. Thanks."}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1150/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609590, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkfMWhAqYQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1150/Authors|ICLR.cc/2019/Conference/Paper1150/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609590}}}, {"id": "B1eZr6Qxam", "original": null, "number": 9, "cdate": 1541582137392, "ddate": null, "tcdate": 1541582137392, "tmdate": 1541582137392, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "HJew0I7lpX", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "content": {"title": "-", "comment": "@authors: I'm not sure you design a more interpretable CNN: your analysis is purely spatial. I think this should be weakened in the writing because it is misleading. I agree with the other points otherwise."}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1150/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609590, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkfMWhAqYQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1150/Authors|ICLR.cc/2019/Conference/Paper1150/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609590}}}, {"id": "HJew0I7lpX", "original": null, "number": 8, "cdate": 1541580495434, "ddate": null, "tcdate": 1541580495434, "tmdate": 1541580495434, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "rken1AAkpm", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "content": {"title": "Thanks for the open discussion and further comments", "comment": "First and foremost thanks for this open debate and for reconsidering your decision. We will try to clarify the relation to the works you mentioned in our manuscript. A few more comments from our side:\n\n(1) Reference [3] builds a new feature vector for an image that combines a feature vector of the whole image with feature vectors of 128 x 128 and 64 x 64 pixel patches (in order to increase invariance to image transformations). The resulting classification is thus neither more interpretable nor constrained to small patches.\n\n(2) You mention that we should use RoIPooling to compare with [Tang]. On what metric would you want this comparison to be performed? We do not claim performance advantages in terms of object classification and do not perform object discovery (one of the subgoals of [Tang et al] which is why they use PASCAL VOC). We'd very much appreciate if you could clarify what exact experiment you have in mind.\n\n(3) Time complexity of BagNets: a BagNet-32/16/8 running on a GTX 1080 Ti can process 155 (+- 5) images / second of size 3 x 224 x 224 (in batches of 10). For comparison, a ResNet50 can process 570 images in the same time, so BagNets are around 3 to 4 times slower than standard ResNets. Please remember that BagNets are basically ResNets but with most 3x3 convolutions replaced by 1x1 convolutions, so this timing is roughly expected (we have less spatial dimensionality reduction which explains the increased runtimes).\n\nAll in all, the main contributions of this work are (1) a more transparent and interpretable object recognition pipeline (in terms of precisely which object features are being used for classification), (2) the insight that ImageNet can be solved to high accuracy with very small and local image features (so e.g. no shape recognition is required to solve ImageNet) and (3) the insight that standard and widely used ImageNet CNNs seem to use a similar BoF classification strategy. We believe that these insights go way beyond previous work and are not at all addressed in the region proposal literature. Please note that we do not want to claim that our architecture is revolutionary but that we can draw important insights from it about object classification in natural images and what internal decision making process CNNs may use in these tasks (which, given the lack of understanding of current CNN architectures, is dearly needed)."}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609590, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkfMWhAqYQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1150/Authors|ICLR.cc/2019/Conference/Paper1150/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609590}}}, {"id": "rken1AAkpm", "original": null, "number": 7, "cdate": 1541561828156, "ddate": null, "tcdate": 1541561828156, "tmdate": 1541561828156, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "BkxqZHV1pm", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "content": {"title": "I agree with the authors that BagNets have the smallest patches and the other papers (Tang et al and the NetVLAD) papers have \"large patch\" due to the receptive fields.", "comment": "I agree with the authors that BagNets have the smallest patches and the other papers (Tang et al and the NetVLAD) papers have \"large patch\" due to the receptive fields.\n\nThe first work in this field [3] uses raw patches and does not have receptive fields.\n\n[3] Yunchao Gong, Liwei Wang, Ruiqi Guo, and Svetlana Lazebnik. Multi-scale orderless pooling of deep convolutional activation features.\n\nHowever, [3] is not end-to-end trained. \n\nSo the way of combining CNN with BoF is different from the previous works. But it is not fundamentally different. \n\nIf all the rest reviewers are willing to accept the paper, I can give a weak accept.\n\nBut, still, I want the authors to give more details about the time complexity and speed. In addition, to make the paper more convincing, the authors should use RoIPooling to compare with [Tang].\n \n[Tang] Tang et al. Deep Patch Learning for Weakly Supervised Object Classification and Discovery, Pattern Recognition 2017\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/AnonReviewer2"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1150/AnonReviewer2", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609590, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkfMWhAqYQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1150/Authors|ICLR.cc/2019/Conference/Paper1150/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609590}}}, {"id": "rkerSzKq2X", "original": null, "number": 2, "cdate": 1541210685203, "ddate": null, "tcdate": 1541210685203, "tmdate": 1541533380398, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "SkfMWhAqYQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Review", "content": {"title": "This paper is worth being accepted. The bag-of-words information in the neural network is important for high prediction accuracy. Possibly has high impact in the community and need to be further investigated.", "review": "This paper suggests a novel and compact neural network architecture which uses the information within bag-of-words features. The proposed algorithm only uses the patch information independently and performs majority voting using independently classified patches. The proposed method provides the state-of-the-art prediction accuracy unexpectedly, and several additional experiments show the state-of-the-art neural networks mainly learn without association between information in different patches.\n\nThe proposed algorithm is simple and does not provide completely new idea, but this paper has a clear contribution connecting the previous main idea of feature extraction, bag-of-words, and the prevailing blackbox algorithm, CNN. The results in the paper are worth to be shared in the community and need further investigated.\n\nThe presented experiments look fair and reasonable to show the importance of the independent patch information (without association between them), and the presented experimental results show some state-of-the-art methods also perform with independent patch information. \n\nComparison with attention models is necessary to compare the important patches obtained from conventional networks.\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Review", "cdate": 1542234294315, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SkfMWhAqYQ", "replyto": "SkfMWhAqYQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335883686, "tmdate": 1552335883686, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HJxDPF1t37", "original": null, "number": 1, "cdate": 1541106014552, "ddate": null, "tcdate": 1541106014552, "tmdate": 1541533380191, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "SkfMWhAqYQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Review", "content": {"title": "Interesting empirical analysis", "review": "This is an experimental paper that investigates how spatial ordering of patches influences the classification performances of CNNs. To do so, the authors design CNNs close to ResNets that almost only consist in a simple cascade of 1x1 convolutions, obtaining relatively small receptive field. It is an interesting read, and I recommend it as a valuable contribution to ICLR, that might lead to nice future works.\n\nI have however several comments and questions, that I would like to be addressed.\n\n1) First I think a reference is missing. Indeed, to my knowledge, it is not the first work to use this kind of techniques. Cf [1]. This does not alterate however the novelty of the approach.\n\n2) \u00ab We construct a linear DNN-based BoF \u00bb : I do not like this formulation. Here, you assume that you build a ResNet-50 with 1x1 as a representation and have a last final linear layer as a classifier. One could also claim it is a ResNet-48 as a representation followed by 2 layers of 1x1 as a classifier.\n\n3) \u00ab our proposed model architecture is simpler \u00bb this is very subjective because for instance the FV models are learned in a layer-wise fashion, which makes their learning procedure more interpretable because each layer objective is specified. Furthermore, analyzing these models is now equivalent to analyze a cascade of fully connected layers, which is not simple at all.\n\n4) Again, the interpretability mentioned in Sec. 3  is in term of spatial localization, not mapping. I think it is important to make clear this consideration. Indeed, this work basically leaves the problem of understanding general CNNs to the problem of understanding MLPs.\n\n5) The graphic of the Appendix A is a bit misleading : it seems 13 downsampling are performed whereas it is not the case, because the first element of each group of block is actually only done once.(if I understood correctly)\n\n6) I think the word feature is sometimes mis-used: sometimes it seems it can refer to a patch, sometimes to the code for a patch. (\u00ab Surprisingly, feature sizes assmall as 17 \u00d7 17 pixels \u00bb)\n\nI got also few questions:\nQ1 : I was wondering if you did try manifold learning on the patches ? Do you expect it to work ?\nQ2 : Is there a batch normalization in the FC or a normalization? Did you try to threshold the heat maps before feeding them to the linear layer? I'm wondering indeed if the amplitude of those heatmaps is really key.\nQ3 : do you think it would be easy to exploit the non-overlapping patches for a better parallelization of computations ?\n\nFinally, I find very positive the amount of experiments to test the similarity with standard CNNs. Of course, it\u2019s far from being a formal proof, but I think it is a very nice first step.\n\n[1] Oyallon, Edouard, Eugene Belilovsky, and Sergey Zagoruyko. \"Scaling the scattering transform: Deep hybrid networks.\" International Conference on Computer Vision (ICCV). 2017.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Review", "cdate": 1542234294315, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SkfMWhAqYQ", "replyto": "SkfMWhAqYQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335883686, "tmdate": 1552335883686, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "BJgUOUvkpX", "original": null, "number": 6, "cdate": 1541531245992, "ddate": null, "tcdate": 1541531245992, "tmdate": 1541531245992, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "Bkeb0FIa2Q", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "content": {"title": "Another perspective that might help", "comment": "Maybe the following perspective also helps: the works you cite use BoF over larger image regions, but the embeddings for each region are still based on conventional, non-interpretable DNNs (like VGG). Our work \"opens this blackbox\" (to use a very stressed term) and provides a way to compute similar region embeddings in a much more interpretable way as a linear BoF over small patches. In other words, if the works you cite would use BagNets instead of VGG, they would basically use a \"stacked BoF\" approach: first, small and local patches are combined to yield region embeddings (BagNet), and these region embeddings are used by a second BoF to infer image-level object labels and bounding boxes."}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609590, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkfMWhAqYQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1150/Authors|ICLR.cc/2019/Conference/Paper1150/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609590}}}, {"id": "rkxKqUBka7", "original": null, "number": 5, "cdate": 1541523089016, "ddate": null, "tcdate": 1541523089016, "tmdate": 1541523089016, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "SkgfzOmkTX", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "content": {"title": "The effective minimum patch size in the cited works is much larger than 32 x 32 pixels", "comment": "Thanks for taking the time to respond! To be concrete we'll refer to Tang et al. 2017 in our response. \n\nWe believe the statement that \"the small patch is 32x32 pixels\" is based on a confusion between region proposals (the patches/bounding boxes that you see) and receptive fields. The region proposals spatially crop parts of the highest conv layer activations (e.g. for VLAD encoding, see Figure 4 in Tang et al.). What is shown in visualisations is the image part that corresponds to the cropped part (i.e. if 1/4 of the conv layer is cropped then 1/4th of the image is shown as proposal region). But that is misleading: since each feature vector already sees large parts of the image (212 x 212 pixels in VGG16 to be precise), the effective image region is much larger then the visualised region proposal (minimum is 212 x 212 pixels).\n\n> Besides, the time complexity issue of BagNet is not addressed in the paper.\n\nBagNets have roughly the same runtime as standard ResNet-50's (it's slightly higher because we have less pooling). We will add precise measurements to the paper, thanks for the suggestion.\n\nAs for previous work, in the corresponding section we wrote \"Predominantly, DNNs were used to replace the previously hand-tuned feature extraction stage in BoF models, often using intermediate or higher layer features of pretrained DNNs\" which, as far as we can see, pretty much applies to the paper you cite (all of them are based on high layer features of AlexNet and VGG). The references that we cite are:\n\n[1] Jiewei Cao, Zi Huang, and Heng Tao Shen. Local deep descriptors in bag-of-words for image retrieval. In Proceedings of the on Thematic Workshops of ACM Multimedia 2017\n[2] Jiangfan Feng, Yuanyuan Liu, and Lin Wu. Bag of visual words model with deep spatial features for geographical scene classification. Comp. Int. and Neurosc., 2017:5169675:1\u20135169675:14, 2017.\n[3] Yunchao Gong, Liwei Wang, Ruiqi Guo, and Svetlana Lazebnik. Multi-scale orderless pooling of deep convolutional activation features.\n[4] Eva Mohedano, Kevin McGuinness, Noel E. O\u2019Connor, Amaia Salvador, Ferran Marques, and Xavier Giro-i Nieto. Bags of local convolutional features for scalable instance search. In Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval, ICMR \u201916,\n[5] Joe Yue-Hei Ng, Fan Yang, and Larry S. Davis. Exploiting local features from deep networks for image retrieval. In CVPR Workshops,\n[6] Fahad Shahbaz Khan, Joost van de Weijer, Rao Muhammad Anwer, Andrew D. Bagdanov, Michael Felsberg, and Jorma Laaksonen. Scale coding bag of deep features for human attribute and action recognition. CoRR, abs/1612.04884, 2016."}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609590, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkfMWhAqYQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1150/Authors|ICLR.cc/2019/Conference/Paper1150/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609590}}}, {"id": "BkxqZHV1pm", "original": null, "number": 4, "cdate": 1541518593551, "ddate": null, "tcdate": 1541518593551, "tmdate": 1541518593551, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "SkgfzOmkTX", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "content": {"title": "-", "comment": "@R2: can you comment on the receptive field size of the final layer of the BagNet versus the works you mentioned?"}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1150/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609590, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkfMWhAqYQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1150/Authors|ICLR.cc/2019/Conference/Paper1150/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609590}}}, {"id": "SkgfzOmkTX", "original": null, "number": 3, "cdate": 1541515274433, "ddate": null, "tcdate": 1541515274433, "tmdate": 1541515274433, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "H1ep2zJyaX", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "content": {"title": "I still have the previous questions", "comment": "Thanks for the authors' response!\n\nWhat are the similar papers cited in the paper? \n\nIn the previous patch-based deep learning methods, there are multi-scale patches. For example, in PASCAL VOC, the whole image is about 500*600 px and the small patch is 32*32 px; they are not whole-object patches. In fact, it is not impossible to obtain whole-object patches, unless object detection has been perfectly done :)\n\nRegarding the effectiveness of highlighting the useful features/patches to explain CNNs, this also has been done before. Please refer to the papers I mentioned before; there are figures to useful patches. In computer vision, there are many papers working on learning mid-level features, meaningful patterns or deep patterns. You may also refer to them.\n\nIn my understanding, methodologically, there is nothing new in the paper. The explanations about the interpretability of deep nets are not deep enough (not inside of the deep net) and there are many works had ready done similar things.\n\nBesides, the time complexity issue of BagNet is not addressed in the paper.\n\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/AnonReviewer2"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1150/AnonReviewer2", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609590, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkfMWhAqYQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1150/Authors|ICLR.cc/2019/Conference/Paper1150/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609590}}}, {"id": "H1ep2zJyaX", "original": null, "number": 2, "cdate": 1541497524556, "ddate": null, "tcdate": 1541497524556, "tmdate": 1541497524556, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "Bkeb0FIa2Q", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "content": {"title": "We do cite similar approaches but they use whole-object patches (instead of small parts), barely increase interpretability and do not shed light on decision making in CNNs", "comment": "Thank you for reviewing our paper. We would like to make a quick clarification right away, which we hope will change your assessment. All works you cite use non-linear BoF encodings on top of pretrained VGG (or AlexNet) features; the effective patch size of individual features is thus large and will generally encompass the whole object of interest. In contrast, our BagNets are constrained to very small image patches (much smaller than the typical object size in ImageNet), use no region proposals (all patches are treated equally) and employ a very simple and transparent average pooling of local features (no non-linear dependence between features and regions). That\u2019s why BagNets (1) substantially increase interpretability of the decision making process (see e.g. heatmaps), (2) highlight what features and length-scales are necessary for object recognition and (3) shed light on the classification strategy followed by modern high performance CNNs. None of the cited papers addresses any of these contributions.\n\nPS: We do cite similar approaches in our paper, see first paragraph of related literature. We will add your references there."}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609590, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkfMWhAqYQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1150/Authors|ICLR.cc/2019/Conference/Paper1150/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609590}}}, {"id": "BkxLk4fp3X", "original": null, "number": 2, "cdate": 1541379037718, "ddate": null, "tcdate": 1541379037718, "tmdate": 1541379037718, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "SkfMWhAqYQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Public_Comment", "content": {"comment": "This paper combines the concept of Bag-of-Feature (BoF) with modern DNN to propose more interpretable neural network framework. Since the proposed method can achieve similar performance to the modern DNN, it can be an alternative to DNN. However, the paper lacks a description of the test phase so it is not clear how many qxq patches are extracted from the full image. As I understand, BagNet extract many small patches from the image, so probably it takes a long time to test one image. In my opinion, it is good to report the test time for the image. \n\nThe most interesting part of this paper is section 4.3  which supports the argument that modern DNN learns similar local features to the BagNet. The four experiments in section 4.3 show that VGG16 acts quite similar to the BagNet. On the other hand, the same experiments clearly show that deeper networks such as ResNet-51, DenseNet act totally different from BagNet. In my opinion, these results seem to be contrary to the contribution of the paper that modern DNN can be explained as BoF framework. \n\n", "title": "Interesting idea and results with some comments"}, "signatures": ["~Seunghyeon_Kim1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"], "writers": ["~Seunghyeon_Kim1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311666990, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "SkfMWhAqYQ", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311666990}}}, {"id": "S1xbm8rE2Q", "original": null, "number": 1, "cdate": 1540802073478, "ddate": null, "tcdate": 1540802073478, "tmdate": 1540802073478, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "SyghkZtMoX", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "content": {"title": "Architecture search could increase performance and/or efficiency", "comment": "Dear Eugene,\nthanks for your comment and the interesting reference! Indeed our results seem to confirm your suspicions regarding integration of spatial information. We'll add your paper into our related work section.\n\nWe did not vary our base architecture. For those reasons I'd expect that one can reach even higher performance with a suitable hyperparameter/architecture search or be much more efficient (more shallow/thin architecture) than what we currently use. These could definitely be interesting future directions to pursue."}, "signatures": ["ICLR.cc/2019/Conference/Paper1150/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621609590, "tddate": null, "super": null, "final": null, "reply": {"forum": "SkfMWhAqYQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1150/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1150/Authors|ICLR.cc/2019/Conference/Paper1150/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621609590}}}, {"id": "SyghkZtMoX", "original": null, "number": 1, "cdate": 1539637475667, "ddate": null, "tcdate": 1539637475667, "tmdate": 1539637475667, "tddate": null, "forum": "SkfMWhAqYQ", "replyto": "SkfMWhAqYQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1150/Public_Comment", "content": {"comment": "This paper was a nice read. I find the results in this paper quite interesting and it is refreshing to see work revisiting some of the underlying assumptions in our modern computer vision pipelines. I wanted to point out a  related result in our recent work https://arxiv.org/pdf/1703.08961.pdf (Sec 2.3,3.1) where we show that using a model localized 16x16 patches can obtain an AlexNet accuracy on imagenet. Specifically we had used a (non-overlapping) local transform with a 16x16 window followed by 3 1x1 convolutions and then an MLP. Indeed, although the MLP could potentially exploit more global spatial information we conjectured this would be quite hard/unlikely, and I believe your result that directly aggregates the predictions of the local encodings reaching nearly the same accuracy confirms this to a degree.  \n\nI was also wondering if you have tested models other than resnet50-like models  as your base, and if so whether those gave substantial differences in the result when varying the actual model  (e.g. shallower/thinner/ or non-residual). One could speculate that models applied to smaller sized patches could require a less complex network than is typically used (a potential advantage of this approach). If I understood your model is already rather small compare to the base resnet-50?\n", "title": "Interesting work and insights, a potentially related reference"}, "signatures": ["~Eugene_Belilovsky1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1150/Reviewers/Unsubmitted"], "writers": ["~Eugene_Belilovsky1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet", "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 32 x 32 px features and Alexnet performance for 16 x16 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.", "keywords": ["interpretability", "representation learning", "bag of features", "deep learning", "object recognition"], "authorids": ["wieland.brendel@bethgelab.org", "matthias.bethge@uni-tuebingen.de"], "authors": ["Wieland Brendel", "Matthias Bethge"], "TL;DR": "Aggregating class evidence from many small image patches suffices to solve ImageNet, yields more interpretable models and can explain aspects of the decision-making of popular DNNs.", "pdf": "/pdf/6080072819789a32a4ac79377f6705667d053541.pdf", "paperhash": "brendel|approximating_cnns_with_bagoflocalfeatures_models_works_surprisingly_well_on_imagenet", "_bibtex": "@inproceedings{\nbrendel2018approximating,\ntitle={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},\nauthor={Wieland Brendel and Matthias Bethge},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=SkfMWhAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1150/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311666990, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "SkfMWhAqYQ", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1150/Authors", "ICLR.cc/2019/Conference/Paper1150/Reviewers", "ICLR.cc/2019/Conference/Paper1150/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311666990}}}], "count": 28}