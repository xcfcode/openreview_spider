{"notes": [{"id": "TVbDOOr6hL", "original": "s9OzByf_oAR", "number": 1286, "cdate": 1601308143764, "ddate": null, "tcdate": 1601308143764, "tmdate": 1614985674566, "tddate": null, "forum": "TVbDOOr6hL", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Variational Auto-Encoder Architectures that Excel at Causal Inference", "authorids": ["~Negar_Hassanpour1", "~Russell_Greiner2"], "authors": ["Negar Hassanpour", "Russell Greiner"], "keywords": ["Causal Inference", "Generative Modelling", "Distributional Shift"], "abstract": "This paper provides a generative approach for causal inference using data from observational studies. Inspired by the work of Kingma et al. (2014), we propose a sequence of three architectures (namely Series, Parallel, and Hybrid) that each incorporate their M1 and M2 models as building blocks. Each architecture is an improvement over the previous one in terms of estimating causal effect, culminating in the Hybrid model. The Hybrid model is designed to encourage decomposing the underlying factors of any observational dataset; this in turn, helps to accurately estimate all treatment outcomes. Our empirical results demonstrate the superiority of all three proposed architectures compared to both state-of-the-art discriminative as well as other generative approaches in the literature. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hassanpour|variational_autoencoder_architectures_that_excel_at_causal_inference", "one-sentence_summary": "A VAE-based generative approach for causal inference using data from observational studies.", "supplementary_material": "/attachment/4a8e8cef39d97d74d2a985202167ef996aa9114d.zip", "pdf": "/pdf/9ee2d7f714872424867e14fe77cd07ebf1393391.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=00B5KMeMNB", "_bibtex": "@misc{\nhassanpour2021variational,\ntitle={Variational Auto-Encoder Architectures that Excel at Causal Inference},\nauthor={Negar Hassanpour and Russell Greiner},\nyear={2021},\nurl={https://openreview.net/forum?id=TVbDOOr6hL}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 17, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "vCz0RHivdzX", "original": null, "number": 1, "cdate": 1610040481221, "ddate": null, "tcdate": 1610040481221, "tmdate": 1610474086224, "tddate": null, "forum": "TVbDOOr6hL", "replyto": "TVbDOOr6hL", "invitation": "ICLR.cc/2021/Conference/Paper1286/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "The authors suggest a VAE model for causal inference. The approach is motivated by CEVAE (Louizos et al., 2017) which uses a VAE to learn a latent representation of confounding between the treatment, target, and covariates. This paper goes beyond this approach and tries to design generative model architectures that encourage learning disentangled representations between different underlying factors of variation inspired by Hassanpour & Greiner (2019). \n\nThe reviewers agreed that the topic will be of interest to a large group of readers. While the first version of the papers raised questions about the experimental design, several questions on the architecture design were addressed during the rebuttal period (e.g., deeper architectures). Other improvements were suggested and not adopted (e.g., alternative methods to achieve better disentanglement). The ablation studies seem to suggest that some of the loss terms are not actually needed and that non-probabilistic autoencoders (beta=0) also work well. We recommend aiming at improving the writing quality and coverage of more background material on the proposed architectures and causal factors. \n"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Auto-Encoder Architectures that Excel at Causal Inference", "authorids": ["~Negar_Hassanpour1", "~Russell_Greiner2"], "authors": ["Negar Hassanpour", "Russell Greiner"], "keywords": ["Causal Inference", "Generative Modelling", "Distributional Shift"], "abstract": "This paper provides a generative approach for causal inference using data from observational studies. Inspired by the work of Kingma et al. (2014), we propose a sequence of three architectures (namely Series, Parallel, and Hybrid) that each incorporate their M1 and M2 models as building blocks. Each architecture is an improvement over the previous one in terms of estimating causal effect, culminating in the Hybrid model. The Hybrid model is designed to encourage decomposing the underlying factors of any observational dataset; this in turn, helps to accurately estimate all treatment outcomes. Our empirical results demonstrate the superiority of all three proposed architectures compared to both state-of-the-art discriminative as well as other generative approaches in the literature. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hassanpour|variational_autoencoder_architectures_that_excel_at_causal_inference", "one-sentence_summary": "A VAE-based generative approach for causal inference using data from observational studies.", "supplementary_material": "/attachment/4a8e8cef39d97d74d2a985202167ef996aa9114d.zip", "pdf": "/pdf/9ee2d7f714872424867e14fe77cd07ebf1393391.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=00B5KMeMNB", "_bibtex": "@misc{\nhassanpour2021variational,\ntitle={Variational Auto-Encoder Architectures that Excel at Causal Inference},\nauthor={Negar Hassanpour and Russell Greiner},\nyear={2021},\nurl={https://openreview.net/forum?id=TVbDOOr6hL}\n}"}, "tags": [], "invitation": {"reply": {"forum": "TVbDOOr6hL", "replyto": "TVbDOOr6hL", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040481208, "tmdate": 1610474086207, "id": "ICLR.cc/2021/Conference/Paper1286/-/Decision"}}}, {"id": "1IUHSnQWqOh", "original": null, "number": 4, "cdate": 1603903428863, "ddate": null, "tcdate": 1603903428863, "tmdate": 1606283527517, "tddate": null, "forum": "TVbDOOr6hL", "replyto": "TVbDOOr6hL", "invitation": "ICLR.cc/2021/Conference/Paper1286/-/Official_Review", "content": {"title": "Good work on causal inference for observational studies but a bit incremental", "review": "Summary:\n\nThis paper introduces a new VAE architecture for performing\ncausal inference. It shows superior precision on estimating\nthe heterogeneous effect and lower bias in estimating the\ntreatment effect.\n\nClarity:\n\nThe paper was fairly clearly written and straightforward to follow.\nI think a small amount of explanation of Kingma's M1 and M2 models\nwould have be improved the flow as your model does build on these\nsemi-supervised architectures.\n\nTechnical Quality:\n\nThe method and experiments are well-thought out and very clearly\nevaluate the work.\n\nWhat's not clear to me is how much the extra performance is from just\nhaving a larger model and more parameters that can be fit. The\nappendix says there are 3 layers of 200 variables each but the hybrid\narchitecture clearly has more parameters. Are those distributed\nappropriately? It's also unclear how much the other architectures were\ndesigned to estimate the heterogeneous effect.\n\nSignificance and Originality:\n\nThe work does feel more incremental than anything but it is an\nimportant problem and there is value in estimate treatment\neffect with higher accuracy.\n\n\nMinor notes:\n\n* First sentence of Section 3. \"follows a(n unknown)\" -> \"follows an unknown\"\n\n* Some of the figures don't look like they are vector graphics\n\n* The code doesn't seem intended to be executed. Hopefully if a full implementation can be made available later", "rating": "7: Good paper, accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["ICLR.cc/2021/Conference/Paper1286/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Auto-Encoder Architectures that Excel at Causal Inference", "authorids": ["~Negar_Hassanpour1", "~Russell_Greiner2"], "authors": ["Negar Hassanpour", "Russell Greiner"], "keywords": ["Causal Inference", "Generative Modelling", "Distributional Shift"], "abstract": "This paper provides a generative approach for causal inference using data from observational studies. Inspired by the work of Kingma et al. (2014), we propose a sequence of three architectures (namely Series, Parallel, and Hybrid) that each incorporate their M1 and M2 models as building blocks. Each architecture is an improvement over the previous one in terms of estimating causal effect, culminating in the Hybrid model. The Hybrid model is designed to encourage decomposing the underlying factors of any observational dataset; this in turn, helps to accurately estimate all treatment outcomes. Our empirical results demonstrate the superiority of all three proposed architectures compared to both state-of-the-art discriminative as well as other generative approaches in the literature. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hassanpour|variational_autoencoder_architectures_that_excel_at_causal_inference", "one-sentence_summary": "A VAE-based generative approach for causal inference using data from observational studies.", "supplementary_material": "/attachment/4a8e8cef39d97d74d2a985202167ef996aa9114d.zip", "pdf": "/pdf/9ee2d7f714872424867e14fe77cd07ebf1393391.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=00B5KMeMNB", "_bibtex": "@misc{\nhassanpour2021variational,\ntitle={Variational Auto-Encoder Architectures that Excel at Causal Inference},\nauthor={Negar Hassanpour and Russell Greiner},\nyear={2021},\nurl={https://openreview.net/forum?id=TVbDOOr6hL}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "TVbDOOr6hL", "replyto": "TVbDOOr6hL", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1286/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538122158, "tmdate": 1606915795089, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1286/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1286/-/Official_Review"}}}, {"id": "MqBU0zHp7Nh", "original": null, "number": 13, "cdate": 1606283509240, "ddate": null, "tcdate": 1606283509240, "tmdate": 1606283509240, "tddate": null, "forum": "TVbDOOr6hL", "replyto": "zb7eDZnvFkr", "invitation": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment", "content": {"title": "Rebuttal addresses all my concerns", "comment": "Thanks! Your response addresses enough of my concerns about this paper!"}, "signatures": ["ICLR.cc/2021/Conference/Paper1286/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Auto-Encoder Architectures that Excel at Causal Inference", "authorids": ["~Negar_Hassanpour1", "~Russell_Greiner2"], "authors": ["Negar Hassanpour", "Russell Greiner"], "keywords": ["Causal Inference", "Generative Modelling", "Distributional Shift"], "abstract": "This paper provides a generative approach for causal inference using data from observational studies. Inspired by the work of Kingma et al. (2014), we propose a sequence of three architectures (namely Series, Parallel, and Hybrid) that each incorporate their M1 and M2 models as building blocks. Each architecture is an improvement over the previous one in terms of estimating causal effect, culminating in the Hybrid model. The Hybrid model is designed to encourage decomposing the underlying factors of any observational dataset; this in turn, helps to accurately estimate all treatment outcomes. Our empirical results demonstrate the superiority of all three proposed architectures compared to both state-of-the-art discriminative as well as other generative approaches in the literature. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hassanpour|variational_autoencoder_architectures_that_excel_at_causal_inference", "one-sentence_summary": "A VAE-based generative approach for causal inference using data from observational studies.", "supplementary_material": "/attachment/4a8e8cef39d97d74d2a985202167ef996aa9114d.zip", "pdf": "/pdf/9ee2d7f714872424867e14fe77cd07ebf1393391.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=00B5KMeMNB", "_bibtex": "@misc{\nhassanpour2021variational,\ntitle={Variational Auto-Encoder Architectures that Excel at Causal Inference},\nauthor={Negar Hassanpour and Russell Greiner},\nyear={2021},\nurl={https://openreview.net/forum?id=TVbDOOr6hL}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "TVbDOOr6hL", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1286/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1286/Authors|ICLR.cc/2021/Conference/Paper1286/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923861460, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment"}}}, {"id": "yMHx0dcCbZ", "original": null, "number": 12, "cdate": 1606236816161, "ddate": null, "tcdate": 1606236816161, "tmdate": 1606236816161, "tddate": null, "forum": "TVbDOOr6hL", "replyto": "n6PxveiNg_U", "invitation": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment", "content": {"title": "Thank you!", "comment": "Thank you for your great feedback."}, "signatures": ["ICLR.cc/2021/Conference/Paper1286/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Auto-Encoder Architectures that Excel at Causal Inference", "authorids": ["~Negar_Hassanpour1", "~Russell_Greiner2"], "authors": ["Negar Hassanpour", "Russell Greiner"], "keywords": ["Causal Inference", "Generative Modelling", "Distributional Shift"], "abstract": "This paper provides a generative approach for causal inference using data from observational studies. Inspired by the work of Kingma et al. (2014), we propose a sequence of three architectures (namely Series, Parallel, and Hybrid) that each incorporate their M1 and M2 models as building blocks. Each architecture is an improvement over the previous one in terms of estimating causal effect, culminating in the Hybrid model. The Hybrid model is designed to encourage decomposing the underlying factors of any observational dataset; this in turn, helps to accurately estimate all treatment outcomes. Our empirical results demonstrate the superiority of all three proposed architectures compared to both state-of-the-art discriminative as well as other generative approaches in the literature. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hassanpour|variational_autoencoder_architectures_that_excel_at_causal_inference", "one-sentence_summary": "A VAE-based generative approach for causal inference using data from observational studies.", "supplementary_material": "/attachment/4a8e8cef39d97d74d2a985202167ef996aa9114d.zip", "pdf": "/pdf/9ee2d7f714872424867e14fe77cd07ebf1393391.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=00B5KMeMNB", "_bibtex": "@misc{\nhassanpour2021variational,\ntitle={Variational Auto-Encoder Architectures that Excel at Causal Inference},\nauthor={Negar Hassanpour and Russell Greiner},\nyear={2021},\nurl={https://openreview.net/forum?id=TVbDOOr6hL}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "TVbDOOr6hL", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1286/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1286/Authors|ICLR.cc/2021/Conference/Paper1286/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923861460, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment"}}}, {"id": "n6PxveiNg_U", "original": null, "number": 11, "cdate": 1606095701893, "ddate": null, "tcdate": 1606095701893, "tmdate": 1606095701893, "tddate": null, "forum": "TVbDOOr6hL", "replyto": "tkZp4fZEQAW", "invitation": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment", "content": {"title": "Thank you", "comment": "I would like to thank the authors for their answers. I have kept my score. "}, "signatures": ["ICLR.cc/2021/Conference/Paper1286/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Auto-Encoder Architectures that Excel at Causal Inference", "authorids": ["~Negar_Hassanpour1", "~Russell_Greiner2"], "authors": ["Negar Hassanpour", "Russell Greiner"], "keywords": ["Causal Inference", "Generative Modelling", "Distributional Shift"], "abstract": "This paper provides a generative approach for causal inference using data from observational studies. Inspired by the work of Kingma et al. (2014), we propose a sequence of three architectures (namely Series, Parallel, and Hybrid) that each incorporate their M1 and M2 models as building blocks. Each architecture is an improvement over the previous one in terms of estimating causal effect, culminating in the Hybrid model. The Hybrid model is designed to encourage decomposing the underlying factors of any observational dataset; this in turn, helps to accurately estimate all treatment outcomes. Our empirical results demonstrate the superiority of all three proposed architectures compared to both state-of-the-art discriminative as well as other generative approaches in the literature. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hassanpour|variational_autoencoder_architectures_that_excel_at_causal_inference", "one-sentence_summary": "A VAE-based generative approach for causal inference using data from observational studies.", "supplementary_material": "/attachment/4a8e8cef39d97d74d2a985202167ef996aa9114d.zip", "pdf": "/pdf/9ee2d7f714872424867e14fe77cd07ebf1393391.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=00B5KMeMNB", "_bibtex": "@misc{\nhassanpour2021variational,\ntitle={Variational Auto-Encoder Architectures that Excel at Causal Inference},\nauthor={Negar Hassanpour and Russell Greiner},\nyear={2021},\nurl={https://openreview.net/forum?id=TVbDOOr6hL}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "TVbDOOr6hL", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1286/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1286/Authors|ICLR.cc/2021/Conference/Paper1286/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923861460, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment"}}}, {"id": "PQRkUQvPxzX", "original": null, "number": 10, "cdate": 1606082040356, "ddate": null, "tcdate": 1606082040356, "tmdate": 1606082040356, "tddate": null, "forum": "TVbDOOr6hL", "replyto": "G4dRcxLfiWr", "invitation": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment", "content": {"title": "Thank you!", "comment": "Thank you for your great comments, and for your subsequent re-evaluation!\n\nPlease feel free to forward any other suggestions."}, "signatures": ["ICLR.cc/2021/Conference/Paper1286/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Auto-Encoder Architectures that Excel at Causal Inference", "authorids": ["~Negar_Hassanpour1", "~Russell_Greiner2"], "authors": ["Negar Hassanpour", "Russell Greiner"], "keywords": ["Causal Inference", "Generative Modelling", "Distributional Shift"], "abstract": "This paper provides a generative approach for causal inference using data from observational studies. Inspired by the work of Kingma et al. (2014), we propose a sequence of three architectures (namely Series, Parallel, and Hybrid) that each incorporate their M1 and M2 models as building blocks. Each architecture is an improvement over the previous one in terms of estimating causal effect, culminating in the Hybrid model. The Hybrid model is designed to encourage decomposing the underlying factors of any observational dataset; this in turn, helps to accurately estimate all treatment outcomes. Our empirical results demonstrate the superiority of all three proposed architectures compared to both state-of-the-art discriminative as well as other generative approaches in the literature. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hassanpour|variational_autoencoder_architectures_that_excel_at_causal_inference", "one-sentence_summary": "A VAE-based generative approach for causal inference using data from observational studies.", "supplementary_material": "/attachment/4a8e8cef39d97d74d2a985202167ef996aa9114d.zip", "pdf": "/pdf/9ee2d7f714872424867e14fe77cd07ebf1393391.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=00B5KMeMNB", "_bibtex": "@misc{\nhassanpour2021variational,\ntitle={Variational Auto-Encoder Architectures that Excel at Causal Inference},\nauthor={Negar Hassanpour and Russell Greiner},\nyear={2021},\nurl={https://openreview.net/forum?id=TVbDOOr6hL}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "TVbDOOr6hL", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1286/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1286/Authors|ICLR.cc/2021/Conference/Paper1286/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923861460, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment"}}}, {"id": "G4dRcxLfiWr", "original": null, "number": 9, "cdate": 1606067656795, "ddate": null, "tcdate": 1606067656795, "tmdate": 1606067656795, "tddate": null, "forum": "TVbDOOr6hL", "replyto": "-ErrVRQgK7p", "invitation": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment", "content": {"title": "Updated review", "comment": "I appreciate the authors' additional discussions and experiments added to the paper and clarifications made in their rebuttal to address the concerns raised. I agree this improves the paper and have increased my score."}, "signatures": ["ICLR.cc/2021/Conference/Paper1286/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Auto-Encoder Architectures that Excel at Causal Inference", "authorids": ["~Negar_Hassanpour1", "~Russell_Greiner2"], "authors": ["Negar Hassanpour", "Russell Greiner"], "keywords": ["Causal Inference", "Generative Modelling", "Distributional Shift"], "abstract": "This paper provides a generative approach for causal inference using data from observational studies. Inspired by the work of Kingma et al. (2014), we propose a sequence of three architectures (namely Series, Parallel, and Hybrid) that each incorporate their M1 and M2 models as building blocks. Each architecture is an improvement over the previous one in terms of estimating causal effect, culminating in the Hybrid model. The Hybrid model is designed to encourage decomposing the underlying factors of any observational dataset; this in turn, helps to accurately estimate all treatment outcomes. Our empirical results demonstrate the superiority of all three proposed architectures compared to both state-of-the-art discriminative as well as other generative approaches in the literature. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hassanpour|variational_autoencoder_architectures_that_excel_at_causal_inference", "one-sentence_summary": "A VAE-based generative approach for causal inference using data from observational studies.", "supplementary_material": "/attachment/4a8e8cef39d97d74d2a985202167ef996aa9114d.zip", "pdf": "/pdf/9ee2d7f714872424867e14fe77cd07ebf1393391.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=00B5KMeMNB", "_bibtex": "@misc{\nhassanpour2021variational,\ntitle={Variational Auto-Encoder Architectures that Excel at Causal Inference},\nauthor={Negar Hassanpour and Russell Greiner},\nyear={2021},\nurl={https://openreview.net/forum?id=TVbDOOr6hL}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "TVbDOOr6hL", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1286/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1286/Authors|ICLR.cc/2021/Conference/Paper1286/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923861460, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment"}}}, {"id": "Tf8nQ5s5YNY", "original": null, "number": 3, "cdate": 1603647699018, "ddate": null, "tcdate": 1603647699018, "tmdate": 1606067455928, "tddate": null, "forum": "TVbDOOr6hL", "replyto": "TVbDOOr6hL", "invitation": "ICLR.cc/2021/Conference/Paper1286/-/Official_Review", "content": {"title": "Proposes some interesting architectures, but novelty limited and motivations/conclusions not strongly supported by experiments", "review": "The paper proposes three VAE architectures for ATE estimation.\n\nThe approach is motivated by CEVAE which uses a VAE to learn a single latent representation of confounding between the treatment, target and covariates, but attempts to disentangle the confounding between the covariates and the treatment, confounding between the covariates, treatment and target, confounding between the covariates and the target and covariates-only information. \n\nTo attempt to to this, 3 different hierarchical VAE architectures are proposed which involve stacking M1 and M2 units. They also include an MMD term in the loss to encourage independence between one of the latent representations and the target.\n\nThe proposed method is evaluated using synthetic data and on two real datasets. In both cases, the proposed method outperforms the SoTA methods, but the results are only significant in one case.\n\nThe paper is generally well written. The problem and general motivation are clearly stated. However, the specific motivations for the 3 specific architectures tested could be more rigorously explained and backed up experimentally.\n\nGiven that this is more of an architecture paper, the evaluation of the specific architecture choices could be more thorough. The attempt to account for the contributions of the different latent factors is appreciated, but the results are not strongly convincing. It seems clear that Z3/Z4 captures Gamma, but it\u2019s not clear that any of the other architecture choices make a difference. The performance results do not seem to support that they are (they do not appear to be significantly different).\n\nIt\u2019s also not clear what to conclude regarding the hyper parameter sensitivity. It would be interesting to see whether alpha affects the ATE estimation, i.e. whether the MMD term is making a difference.\n\nIn summary, the paper proposes 3 architectures for ATE estimation. It is well written and presents reasonable ideas, but the novelty is somewhat limited (it combines existing ideas and architectures), the performance advantage over the existing SoTA is not strongly convincing and the specific architecture choices could be better motivated and evaluated experimentally.\n\n--Post-rebuttal--\n\nI have increased my score in response to the authors' clarifications and additional experiments and updates added to the paper.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1286/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Auto-Encoder Architectures that Excel at Causal Inference", "authorids": ["~Negar_Hassanpour1", "~Russell_Greiner2"], "authors": ["Negar Hassanpour", "Russell Greiner"], "keywords": ["Causal Inference", "Generative Modelling", "Distributional Shift"], "abstract": "This paper provides a generative approach for causal inference using data from observational studies. Inspired by the work of Kingma et al. (2014), we propose a sequence of three architectures (namely Series, Parallel, and Hybrid) that each incorporate their M1 and M2 models as building blocks. Each architecture is an improvement over the previous one in terms of estimating causal effect, culminating in the Hybrid model. The Hybrid model is designed to encourage decomposing the underlying factors of any observational dataset; this in turn, helps to accurately estimate all treatment outcomes. Our empirical results demonstrate the superiority of all three proposed architectures compared to both state-of-the-art discriminative as well as other generative approaches in the literature. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hassanpour|variational_autoencoder_architectures_that_excel_at_causal_inference", "one-sentence_summary": "A VAE-based generative approach for causal inference using data from observational studies.", "supplementary_material": "/attachment/4a8e8cef39d97d74d2a985202167ef996aa9114d.zip", "pdf": "/pdf/9ee2d7f714872424867e14fe77cd07ebf1393391.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=00B5KMeMNB", "_bibtex": "@misc{\nhassanpour2021variational,\ntitle={Variational Auto-Encoder Architectures that Excel at Causal Inference},\nauthor={Negar Hassanpour and Russell Greiner},\nyear={2021},\nurl={https://openreview.net/forum?id=TVbDOOr6hL}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "TVbDOOr6hL", "replyto": "TVbDOOr6hL", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1286/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538122158, "tmdate": 1606915795089, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1286/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1286/-/Official_Review"}}}, {"id": "CHpTzO-uqo", "original": null, "number": 8, "cdate": 1605932776039, "ddate": null, "tcdate": 1605932776039, "tmdate": 1605932795969, "tddate": null, "forum": "TVbDOOr6hL", "replyto": "RGkMGg5W3wr", "invitation": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment", "content": {"title": "Thank you!", "comment": "Thank you for your great comments, and for your subsequent re-evaluation!\n\nPlease feel free to forward any other suggestions."}, "signatures": ["ICLR.cc/2021/Conference/Paper1286/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Auto-Encoder Architectures that Excel at Causal Inference", "authorids": ["~Negar_Hassanpour1", "~Russell_Greiner2"], "authors": ["Negar Hassanpour", "Russell Greiner"], "keywords": ["Causal Inference", "Generative Modelling", "Distributional Shift"], "abstract": "This paper provides a generative approach for causal inference using data from observational studies. Inspired by the work of Kingma et al. (2014), we propose a sequence of three architectures (namely Series, Parallel, and Hybrid) that each incorporate their M1 and M2 models as building blocks. Each architecture is an improvement over the previous one in terms of estimating causal effect, culminating in the Hybrid model. The Hybrid model is designed to encourage decomposing the underlying factors of any observational dataset; this in turn, helps to accurately estimate all treatment outcomes. Our empirical results demonstrate the superiority of all three proposed architectures compared to both state-of-the-art discriminative as well as other generative approaches in the literature. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hassanpour|variational_autoencoder_architectures_that_excel_at_causal_inference", "one-sentence_summary": "A VAE-based generative approach for causal inference using data from observational studies.", "supplementary_material": "/attachment/4a8e8cef39d97d74d2a985202167ef996aa9114d.zip", "pdf": "/pdf/9ee2d7f714872424867e14fe77cd07ebf1393391.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=00B5KMeMNB", "_bibtex": "@misc{\nhassanpour2021variational,\ntitle={Variational Auto-Encoder Architectures that Excel at Causal Inference},\nauthor={Negar Hassanpour and Russell Greiner},\nyear={2021},\nurl={https://openreview.net/forum?id=TVbDOOr6hL}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "TVbDOOr6hL", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1286/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1286/Authors|ICLR.cc/2021/Conference/Paper1286/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923861460, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment"}}}, {"id": "RGkMGg5W3wr", "original": null, "number": 7, "cdate": 1605872046007, "ddate": null, "tcdate": 1605872046007, "tmdate": 1605872046007, "tddate": null, "forum": "TVbDOOr6hL", "replyto": "TDknr1R3Hf-", "invitation": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment", "content": {"title": "Thanks", "comment": "Thanks for the detailed clarifications, the additional experiments, and additional discussions in the paper. I agree that they have much improved the paper. I have increased my score accordingly."}, "signatures": ["ICLR.cc/2021/Conference/Paper1286/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Auto-Encoder Architectures that Excel at Causal Inference", "authorids": ["~Negar_Hassanpour1", "~Russell_Greiner2"], "authors": ["Negar Hassanpour", "Russell Greiner"], "keywords": ["Causal Inference", "Generative Modelling", "Distributional Shift"], "abstract": "This paper provides a generative approach for causal inference using data from observational studies. Inspired by the work of Kingma et al. (2014), we propose a sequence of three architectures (namely Series, Parallel, and Hybrid) that each incorporate their M1 and M2 models as building blocks. Each architecture is an improvement over the previous one in terms of estimating causal effect, culminating in the Hybrid model. The Hybrid model is designed to encourage decomposing the underlying factors of any observational dataset; this in turn, helps to accurately estimate all treatment outcomes. Our empirical results demonstrate the superiority of all three proposed architectures compared to both state-of-the-art discriminative as well as other generative approaches in the literature. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hassanpour|variational_autoencoder_architectures_that_excel_at_causal_inference", "one-sentence_summary": "A VAE-based generative approach for causal inference using data from observational studies.", "supplementary_material": "/attachment/4a8e8cef39d97d74d2a985202167ef996aa9114d.zip", "pdf": "/pdf/9ee2d7f714872424867e14fe77cd07ebf1393391.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=00B5KMeMNB", "_bibtex": "@misc{\nhassanpour2021variational,\ntitle={Variational Auto-Encoder Architectures that Excel at Causal Inference},\nauthor={Negar Hassanpour and Russell Greiner},\nyear={2021},\nurl={https://openreview.net/forum?id=TVbDOOr6hL}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "TVbDOOr6hL", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1286/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1286/Authors|ICLR.cc/2021/Conference/Paper1286/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923861460, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment"}}}, {"id": "_nf3URHCD5", "original": null, "number": 1, "cdate": 1603476450205, "ddate": null, "tcdate": 1603476450205, "tmdate": 1605871991833, "tddate": null, "forum": "TVbDOOr6hL", "replyto": "TVbDOOr6hL", "invitation": "ICLR.cc/2021/Conference/Paper1286/-/Official_Review", "content": {"title": "The ablation studies are a bit concerning", "review": "The authors provide some novel VAE architectures for causal inference. They compare different architectures and assess their respective strengths and weaknesses. They empirically test the models on synthetic and real-world data and compare them to some baselines.\n\nMajor comments:\n- The Hybrid model seems to perform best, but it also has the largest number of parameters and latent variables. What would happen if one would introduce even more layers of latent variables? Would the performance get even better? Is there a tradeoff between performance and complexity?\n- In Figure 6 (a,b), it seems like the best method (H-VAE-CI) works very well with alpha=0 and beta=0. How can that be explained? If those loss terms are not needed, what is it that actually makes the model better?\n- Moreover, in Fig. 6 (c), the H-VAE-CI also still has a considerable gap to the other models at gamma=0, which means completely without VAE loss. How can that be explained?\n\nMinor comments:\n- The KLD is the Kullback-Leibler *divergence*, which is crucially *not a distance* (because it's not symmetric)\n- Could a more performant disentangling VAE be used? The beta-VAE is generally not the best [1]\n- Generally, how do these disentanglement results relate to the impossibility theorem in [1]?\n- How is the IPM chosen for L_disc? If it's the MMD, how is the kernel chosen? Does it depend on the task?\n- In Table 3, the DR-CFR seems better than the S-VAE-CI and P-VAE-CI. Why are they boldened?\n\nSummary:\nThe idea is very interesting, but the experiments are not fully convincing. Especially the ablation studies (Fig. 6) seem to suggest that most of the loss terms are not actually needed for the proposed model (H-VAE-CI) to perform well. I think further experimentation is needed to fully understand what really makes the proposed model work better than the baselines. For this, it could also be interesting to construct even \"deeper\" models than the (H-VAE-CI), which would be less informed by prior assumptions, and see if they might not work even better.\n\nUpdate: Thanks to the additional experiment and discussions, I have increased my score.\n\n\n[1] Locatello, F., Bauer, S., Lucic, M., Raetsch, G., Gelly, S., Sch\u00f6lkopf, B., & Bachem, O. (2019, May). Challenging common assumptions in the unsupervised learning of disentangled representations. In international conference on machine learning (pp. 4114-4124).\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1286/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Auto-Encoder Architectures that Excel at Causal Inference", "authorids": ["~Negar_Hassanpour1", "~Russell_Greiner2"], "authors": ["Negar Hassanpour", "Russell Greiner"], "keywords": ["Causal Inference", "Generative Modelling", "Distributional Shift"], "abstract": "This paper provides a generative approach for causal inference using data from observational studies. Inspired by the work of Kingma et al. (2014), we propose a sequence of three architectures (namely Series, Parallel, and Hybrid) that each incorporate their M1 and M2 models as building blocks. Each architecture is an improvement over the previous one in terms of estimating causal effect, culminating in the Hybrid model. The Hybrid model is designed to encourage decomposing the underlying factors of any observational dataset; this in turn, helps to accurately estimate all treatment outcomes. Our empirical results demonstrate the superiority of all three proposed architectures compared to both state-of-the-art discriminative as well as other generative approaches in the literature. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hassanpour|variational_autoencoder_architectures_that_excel_at_causal_inference", "one-sentence_summary": "A VAE-based generative approach for causal inference using data from observational studies.", "supplementary_material": "/attachment/4a8e8cef39d97d74d2a985202167ef996aa9114d.zip", "pdf": "/pdf/9ee2d7f714872424867e14fe77cd07ebf1393391.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=00B5KMeMNB", "_bibtex": "@misc{\nhassanpour2021variational,\ntitle={Variational Auto-Encoder Architectures that Excel at Causal Inference},\nauthor={Negar Hassanpour and Russell Greiner},\nyear={2021},\nurl={https://openreview.net/forum?id=TVbDOOr6hL}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "TVbDOOr6hL", "replyto": "TVbDOOr6hL", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1286/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538122158, "tmdate": 1606915795089, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1286/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1286/-/Official_Review"}}}, {"id": "zb7eDZnvFkr", "original": null, "number": 2, "cdate": 1605732556043, "ddate": null, "tcdate": 1605732556043, "tmdate": 1605736194505, "tddate": null, "forum": "TVbDOOr6hL", "replyto": "1IUHSnQWqOh", "invitation": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment", "content": {"title": "We have updated the paper to address your great questions / suggestions.", "comment": "Thank you for your helpful feedback and suggestions. We highly appreciate it.\n\n\n**Explanation of Kingma's M1 and M2 models.**\n\nWe have added a paragraph that briefly describes the M1 and M2 models in the Related Works section. Please see the teal text on page 3, marked as \u201cR2\u201d. Appendix A.1 presents a more detailed overview of these two models.\n\n\n**How much the extra performance is from just having a larger model?**\n\nGreat question! We ran a version of CFR with deeper as well as wider networks, such that it has the exact same number of neurons as H-VAE-CI. For the Synthetic benchmark, the $\\textrm{PEHE}$ improved only slightly, from $0.41 {\\scriptsize(0.10)}$ to $0.39 {\\scriptsize (0.08)}$, which is not statistically significant (based on Welch's unpaired t-test with $\\alpha=0.05$); but the $\\epsilon_{\\textrm{ATE}}$ degraded from $0.027 {\\scriptsize (0.020)}$ to $0.040 {\\scriptsize (0.028)}$. For the IHDP and ACIC\u201918 benchmarks, the performance significantly degraded with bigger networks. This suggests a tradeoff between performance and complexity, and that the architecture and objective function of H-VAE-CI is indeed adding value compared to those of CFR. We have updated the performance results in Table 3 as well as Figure 5, and added a footnote in Appendix A.4 -- see the added text in orange and marked as \u201cR1 & R2\u201d.\n\n\n**Incremental contribution.**\n\nStand-alone pioneering research is extremely rare -- essentially every novel research stands on the shoulders of the previous works. \n\nTo further demonstrate the merit of this work and the new possibilities that it provides, we explored one of our future-work items in this rebuttal period. This framework allowed us to quickly obtain some preliminary results on incorporating a context-aware re-weighting scheme that requires the disentangled learned representation of $\\Delta$ in order to compute its weights. We are happy to report that these new results beat our previously presented SOTA. See pages 6 and 8 (in purple), as well as the updated Tables 1, 2, and 3, and Figures 5 and 6, in the new version of the paper. These results suggest that our contributions are effective and useful! Thanks!\n\n\n**The code is not executable.**\n\nWe have adopted the code-base of CFR, online available at https://github.com/clinicalml/cfrnet, and developed our code (the tensorflow graph of the proposed methods; provided in the supplementary material) on top of that -- see the comment on top of our published code. We have, however, modified several of their helper functions as well. But of course, in order to publish the code independently, we need to ask for the Sontag Lab\u2019s permission; which we will, upon acceptance of the paper."}, "signatures": ["ICLR.cc/2021/Conference/Paper1286/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Auto-Encoder Architectures that Excel at Causal Inference", "authorids": ["~Negar_Hassanpour1", "~Russell_Greiner2"], "authors": ["Negar Hassanpour", "Russell Greiner"], "keywords": ["Causal Inference", "Generative Modelling", "Distributional Shift"], "abstract": "This paper provides a generative approach for causal inference using data from observational studies. Inspired by the work of Kingma et al. (2014), we propose a sequence of three architectures (namely Series, Parallel, and Hybrid) that each incorporate their M1 and M2 models as building blocks. Each architecture is an improvement over the previous one in terms of estimating causal effect, culminating in the Hybrid model. The Hybrid model is designed to encourage decomposing the underlying factors of any observational dataset; this in turn, helps to accurately estimate all treatment outcomes. Our empirical results demonstrate the superiority of all three proposed architectures compared to both state-of-the-art discriminative as well as other generative approaches in the literature. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hassanpour|variational_autoencoder_architectures_that_excel_at_causal_inference", "one-sentence_summary": "A VAE-based generative approach for causal inference using data from observational studies.", "supplementary_material": "/attachment/4a8e8cef39d97d74d2a985202167ef996aa9114d.zip", "pdf": "/pdf/9ee2d7f714872424867e14fe77cd07ebf1393391.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=00B5KMeMNB", "_bibtex": "@misc{\nhassanpour2021variational,\ntitle={Variational Auto-Encoder Architectures that Excel at Causal Inference},\nauthor={Negar Hassanpour and Russell Greiner},\nyear={2021},\nurl={https://openreview.net/forum?id=TVbDOOr6hL}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "TVbDOOr6hL", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1286/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1286/Authors|ICLR.cc/2021/Conference/Paper1286/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923861460, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment"}}}, {"id": "-ErrVRQgK7p", "original": null, "number": 3, "cdate": 1605732740745, "ddate": null, "tcdate": 1605732740745, "tmdate": 1605736183985, "tddate": null, "forum": "TVbDOOr6hL", "replyto": "Tf8nQ5s5YNY", "invitation": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment", "content": {"title": "We have updated the paper to address your great questions / suggestions.", "comment": "We thank R4 for your excellent, thought-provoking feedback. Our attempt to answer your questions (especially the one on the hyperparameters\u2019 sensitivity analyses) resulted in a modified paper that includes strong analytical discussions and new exciting findings that substantially improved our paper. For this, we are grateful!\n\n\n**Statistical significance of the results that beat the SOTA.**\n\nOur results are better than the SOTA in all three benchmarks, and this improvement is statistically significant on both IHDP and Synthetic benchmarks. The reason why it is not significant for ACIC'18 is that, while our proposed method has small variance, the *other* competing methods have large variances in their performance. This speaks to their instability on harder datasets (notice the larger magnitude of $\\textrm{PEHE}$ and $\\epsilon_{\\textrm{ATE}}$ on the ACIC\u201918 benchmark compared to the other benchmarks). \n\n\n**Specific architecture choices could be more thorough and more rigorously explained.**\n\nWe should have further emphasized that our champion model is H-VAE-CI (i.e., the Hybrid model). The paper describes the Series and Parallel models only to provide our line of thought in achieving the proposed design of the Hybrid model. The new manuscript provides these motivations on pages 4 and 5 -- see the green text labeled as \u201cR4\u201d.\n\n\n**Z3/Z4 do capture $\\Gamma$, but not clear for the other factors.**\n\nSection 4.2 and Figure 4 is our attempt to report the ability of various methods to capture disentangled representations of $\\Gamma$, $\\Delta$, and $\\Upsilon$. We emphasize that only H-VAE-CI (and not the other methods) is capable of disentangling all three factors. The green table in Figure 4 illustrates this, as $Z_1$ has the largest ratio for $\\Upsilon$, and $Z_5$ has the largest ratio for $\\Delta$. We agree that $Z_3$ has a more substantial ratio compared to $Z_1$ and $Z_5$; but in all fairness, this is a measure that we developed that crudely evaluates disentanglement. More research is needed to evaluate disentanglement of the underlying factors in an observational study. \n\nNote also that the green table in Figure 4 is not a single observation; we have conducted this analysis for multiple hyperparameter settings and achieved a similar distribution of ratios (see the newly added Figure 9 in the Appendix A.5). Finally, as stated in the Future Work section, *\u201cwe are yet to invent algorithms that can learn to perfectly disentangle factors $\\Delta$ and $\\Upsilon$\u201d*. Stay tuned! \n\nWe have updated the last paragraph of Section 4.2 (in green text; marked as \u201cR4\u201d) as well as a footnote (in green text; marked as \u201cR1 & R4\u201d) to include more detailed discussion on this matter.\n\n\n**What to conclude regarding the hyper parameter sensitivity?**\n\nWe have extensively updated the paper with detailed discussions on our ablation studies for $\\alpha$, $\\beta$, and $\\gamma$ coefficients. Please see the newly added green texts with labels \u201cR1 & R4\u201d and \u201cR1 & R3 & R4\u201d on pages 8 and 9.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1286/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Auto-Encoder Architectures that Excel at Causal Inference", "authorids": ["~Negar_Hassanpour1", "~Russell_Greiner2"], "authors": ["Negar Hassanpour", "Russell Greiner"], "keywords": ["Causal Inference", "Generative Modelling", "Distributional Shift"], "abstract": "This paper provides a generative approach for causal inference using data from observational studies. Inspired by the work of Kingma et al. (2014), we propose a sequence of three architectures (namely Series, Parallel, and Hybrid) that each incorporate their M1 and M2 models as building blocks. Each architecture is an improvement over the previous one in terms of estimating causal effect, culminating in the Hybrid model. The Hybrid model is designed to encourage decomposing the underlying factors of any observational dataset; this in turn, helps to accurately estimate all treatment outcomes. Our empirical results demonstrate the superiority of all three proposed architectures compared to both state-of-the-art discriminative as well as other generative approaches in the literature. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hassanpour|variational_autoencoder_architectures_that_excel_at_causal_inference", "one-sentence_summary": "A VAE-based generative approach for causal inference using data from observational studies.", "supplementary_material": "/attachment/4a8e8cef39d97d74d2a985202167ef996aa9114d.zip", "pdf": "/pdf/9ee2d7f714872424867e14fe77cd07ebf1393391.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=00B5KMeMNB", "_bibtex": "@misc{\nhassanpour2021variational,\ntitle={Variational Auto-Encoder Architectures that Excel at Causal Inference},\nauthor={Negar Hassanpour and Russell Greiner},\nyear={2021},\nurl={https://openreview.net/forum?id=TVbDOOr6hL}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "TVbDOOr6hL", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1286/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1286/Authors|ICLR.cc/2021/Conference/Paper1286/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923861460, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment"}}}, {"id": "tkZp4fZEQAW", "original": null, "number": 4, "cdate": 1605732863403, "ddate": null, "tcdate": 1605732863403, "tmdate": 1605736173993, "tddate": null, "forum": "TVbDOOr6hL", "replyto": "1heHh-sxYd", "invitation": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment", "content": {"title": "We have updated the paper to address your great questions / suggestions.", "comment": "Thank you for your positive opinion and great feedback. We highly appreciate it.\n\n\n**Analyse results of the ablation study for $\\beta=0$; is the resulting model still able to generate data, from the prior predictive density?**\n\nThis is a great point. Our initial hypothesis in using $\\beta$-VAE was that it might help *further* disentangle the underlying factors. However, Figure 6(b) suggests that close-to-zero or even zero $\\beta$s also work effectively. To further explore this hypothesis, we examined the decomposition tables (similar to Figure 4) of H-VAE-CI for configurations with $\\beta=0$ and observed that they were all effective at decomposing the underlying factors $\\Gamma$, $\\Delta$, and $\\Upsilon$ -- similar to the performance reported in the green table in Figure 4. The newly added Figure 9 in the Appendix shows several of these tables. Our interpretation here is that the H-VAE-CI's architecture already takes care of decomposing the $\\Gamma$, $\\Delta$, and $\\Upsilon$ factors, without needing the help of a KLD penalty. \n\n\n**Is it more advantageous to use other disentanglement constraints instead of the beta-VAE?**\n\nIn light of the above discussion, and as you correctly point out, this means either of the following is happening:\n1. $\\beta$-VAE is not the best performing disentangling method and better disentangling constraints should be used instead -- e.g., works of Chen et al. (2018) and Lopez et al. (2018); thank you for the pointers by the way.\n2. It is theoretically impossible to achieve disentanglement without some supervision (Locatello et al, 2019) ... which might not be possible to provide in this task.\n\nExploring these options is out of the scope of this paper and is a great future direction for this work.\nPlease see the updated green text on page 8 (marked as \u201cR1 & R3 & R4\u201d), as well as the newly added Appendix A.5 (marked as \u201cR1 & R3\u201d).\n\nREFERENCES\n- Ricky TQ Chen, Xuechen Li, Roger B Grosse, and David K Duvenaud. Isolating sources of disentanglement in variational autoencoders. In *NeurIPS*, 2018.\n- Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Raetsch, Sylvain Gelly, Bernhard Sch\u00f6lkopf, and Olivier Bachem. Challenging common assumptions in the unsupervised learning of disentangled representations. In *ICML*, 2019.\n- Romain Lopez, Jeffrey Regier, Michael I Jordan, and Nir Yosef. Information constraints on auto-encoding variational bayes. In *NeurIPS*, 2018.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1286/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Auto-Encoder Architectures that Excel at Causal Inference", "authorids": ["~Negar_Hassanpour1", "~Russell_Greiner2"], "authors": ["Negar Hassanpour", "Russell Greiner"], "keywords": ["Causal Inference", "Generative Modelling", "Distributional Shift"], "abstract": "This paper provides a generative approach for causal inference using data from observational studies. Inspired by the work of Kingma et al. (2014), we propose a sequence of three architectures (namely Series, Parallel, and Hybrid) that each incorporate their M1 and M2 models as building blocks. Each architecture is an improvement over the previous one in terms of estimating causal effect, culminating in the Hybrid model. The Hybrid model is designed to encourage decomposing the underlying factors of any observational dataset; this in turn, helps to accurately estimate all treatment outcomes. Our empirical results demonstrate the superiority of all three proposed architectures compared to both state-of-the-art discriminative as well as other generative approaches in the literature. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hassanpour|variational_autoencoder_architectures_that_excel_at_causal_inference", "one-sentence_summary": "A VAE-based generative approach for causal inference using data from observational studies.", "supplementary_material": "/attachment/4a8e8cef39d97d74d2a985202167ef996aa9114d.zip", "pdf": "/pdf/9ee2d7f714872424867e14fe77cd07ebf1393391.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=00B5KMeMNB", "_bibtex": "@misc{\nhassanpour2021variational,\ntitle={Variational Auto-Encoder Architectures that Excel at Causal Inference},\nauthor={Negar Hassanpour and Russell Greiner},\nyear={2021},\nurl={https://openreview.net/forum?id=TVbDOOr6hL}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "TVbDOOr6hL", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1286/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1286/Authors|ICLR.cc/2021/Conference/Paper1286/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923861460, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment"}}}, {"id": "WS66kQG4oHJ", "original": null, "number": 5, "cdate": 1605733176433, "ddate": null, "tcdate": 1605733176433, "tmdate": 1605736158054, "tddate": null, "forum": "TVbDOOr6hL", "replyto": "_nf3URHCD5", "invitation": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment", "content": {"title": "We have updated the paper to address your great questions / suggestions.", "comment": "We thank R1 for the excellent, thought-provoking feedback and suggestions. Addressing those insightful questions resulted in a modified paper that includes strong analytical discussions and new exciting findings that substantially improved our paper. For this, we are very grateful! \n\n\n**Is there a tradeoff between performance and complexity?**\n\nWe ran a version of CFR with deeper as well as wider networks, such that it has the exact same number of neurons as H-VAE-CI. For the Synthetic benchmark, the $\\textrm{PEHE}$ improved only slightly, from $0.41 {\\scriptsize(0.10)}$ to $0.39 {\\scriptsize (0.08)}$, which is not statistically significant (based on Welch's unpaired t-test with $\\alpha=0.05$); but the $\\epsilon_{\\textrm{ATE}}$ degraded from $0.027 {\\scriptsize (0.020)}$ to $0.040 {\\scriptsize (0.028)}$. For the IHDP and ACIC\u201918 benchmarks, the performance significantly degraded with bigger networks. This suggests a tradeoff between performance and complexity, and that the architecture and objective function of H-VAE-CI is indeed adding value compared to those of CFR. We have updated the performance results in Table 3 as well as Figure 5, and added a footnote in Appendix A.4 -- see the added text in orange and marked as \u201cR1 & R2\u201d. \n\n\n**Construct \"deeper\" models than the (H-VAE-CI) and see if they work even better.**\n\nGreat suggestion! We ran the H-VAE-CI code with both deeper and wider networks on the Synthetic benchmark. However, going deeper with {layer_in=5, width_in=200} significantly worsened the performance. Going wider did not improve it either, as the $\\textrm{PEHE}$ performance for the original network with {layer_in=3, width_in=200} is $0.20 {\\scriptsize (0.03)}$ (as reported in the paper), which only matched the performance of wider networks with {layer_in=3, width_in=[350, 500]}: $0.20 {\\scriptsize (0.05)}$.\n\n\n**Analyse results of the ablation study for $\\alpha=0$.**\n\nFor $\\alpha=0$, $Z_1$ will no longer capture mostly $\\Upsilon$ and $Z_5$ will not capture mostly $\\Delta$; in other words, $Z_1$ and $Z_5$ will not learn disentangled factors. However, this has not negatively impacted the performance since the current implementation does not *require* this disentanglement to work properly. This is because the weighting scheme in our original submission (as stated at the end of Section 3.4) is *Population-Based* (PB) -- i.e., it is only based on $Pr(\\,t\\,)$; equivalent to the weighting scheme used in (Shalit et al., 2017). We now refer to this specific model as \u201cH-VAE-CI (PB)\u201d. Note that when the outcome prediction is based on a PB weighted factual loss, we only need the concatenation of $\\Delta$ and $\\Upsilon$. Therefore, even if the learned representations $Z_1$ and $Z_5$ are not disentangled, it will not impact the outcome prediction performance. \n\nDisentangling $\\Delta$ from $\\Upsilon$ only becomes important when we want to *further* account for selection bias using *Context-Aware* (CA) re-weighting of the factual loss (e.g., Hassanpour and Greiner (2019)\u2019s work). As stated in Section 5, we had left the use of $\\Delta$-based CA weights to future work. However, in the rebuttal period, we ran H-VAE-CI with Hassanpour and Greiner (2019)\u2019s CA weighting scheme (as a proof of concept), leading to \u201cH-VAE-CI (CA)\u201d. As expected, we found out that the performance improves from $\\textrm{PEHE}$ of $0.20 {\\scriptsize (0.03)}$ to $0.18 {\\scriptsize (0.02)}$ (this improvement is statistically significant) and no change in $\\epsilon_{\\textrm{ATE}}$ of $0.003 {\\scriptsize (0.002)}$.\n\nOn another note, observe that the performance of CFR, as well as {S,P}-VAE-CI, deteriorates as $\\alpha$ increases from $0.1$. This is because this penalty term becomes so strong that $\\Delta$ is removed from their $Z_1$, and since these methods do not have another node to capture $\\Delta$, their outcome prediction performance is hindered. Note that neither DR-CFR nor H-VAE-CI suffer from this issue since they have another independent node to capture $\\Delta$. \n\nTo summarize, one important contribution of our work was showing that it is *possible* to learn disentangled representations of the underlying factors in observational studies. We only hypothesised that such disentanglement should be advantageous for causal effect estimation performance. However, our new results (that we produced during the rebuttal period) show that it is indeed *advantageous* to have disentangled representations if context-aware importance weighting is used. **Thanks R1 for your excellent question!** We have updated the paper to include these new exciting results. See the updated text in purple in pages 6 and 8 (marked as \u201cR1\u201d) and green text in page 8 (marked as \u201cR1 & R4\u201d), as well as updated Tables 1, 2, and 3, and Figures 5 and 6."}, "signatures": ["ICLR.cc/2021/Conference/Paper1286/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Auto-Encoder Architectures that Excel at Causal Inference", "authorids": ["~Negar_Hassanpour1", "~Russell_Greiner2"], "authors": ["Negar Hassanpour", "Russell Greiner"], "keywords": ["Causal Inference", "Generative Modelling", "Distributional Shift"], "abstract": "This paper provides a generative approach for causal inference using data from observational studies. Inspired by the work of Kingma et al. (2014), we propose a sequence of three architectures (namely Series, Parallel, and Hybrid) that each incorporate their M1 and M2 models as building blocks. Each architecture is an improvement over the previous one in terms of estimating causal effect, culminating in the Hybrid model. The Hybrid model is designed to encourage decomposing the underlying factors of any observational dataset; this in turn, helps to accurately estimate all treatment outcomes. Our empirical results demonstrate the superiority of all three proposed architectures compared to both state-of-the-art discriminative as well as other generative approaches in the literature. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hassanpour|variational_autoencoder_architectures_that_excel_at_causal_inference", "one-sentence_summary": "A VAE-based generative approach for causal inference using data from observational studies.", "supplementary_material": "/attachment/4a8e8cef39d97d74d2a985202167ef996aa9114d.zip", "pdf": "/pdf/9ee2d7f714872424867e14fe77cd07ebf1393391.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=00B5KMeMNB", "_bibtex": "@misc{\nhassanpour2021variational,\ntitle={Variational Auto-Encoder Architectures that Excel at Causal Inference},\nauthor={Negar Hassanpour and Russell Greiner},\nyear={2021},\nurl={https://openreview.net/forum?id=TVbDOOr6hL}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "TVbDOOr6hL", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1286/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1286/Authors|ICLR.cc/2021/Conference/Paper1286/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923861460, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment"}}}, {"id": "TDknr1R3Hf-", "original": null, "number": 6, "cdate": 1605733424798, "ddate": null, "tcdate": 1605733424798, "tmdate": 1605736132182, "tddate": null, "forum": "TVbDOOr6hL", "replyto": "WS66kQG4oHJ", "invitation": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment", "content": {"title": "Rebuttal continued ...", "comment": "**Analyse results of the ablation study for $\\beta=0$; whether a more performant disentangling VAE could be used; and relationship to the impossibility theorem.**\n\nRegarding $\\beta$ values, our hypothesis was that using $\\beta$-VAE might help *further* disentangle the underlying factors; however, as you correctly point out, it appears that close-to-zero or even zero $\\beta$s work perfectly fine. Our empirical results support this observation also, as we looked at the decomposition tables (similar to those in Figure 4) of H-VAE-CI for configurations with $\\beta=0$ and observed that they all did a fairly good job (similar to the performance reported in the green table in Figure 4) at decomposing the underlying factors $\\Gamma$, $\\Delta$, and $\\Upsilon$. The newly added Figure 9 in the Appendix shows several of these tables. \n\nOur interpretation of this observation is that the H-VAE-CI architecture is already decomposing the $\\Gamma$, $\\Delta$, and $\\Upsilon$ factors, without needing a KLD penalty. As you correctly point out, this means either of the following is happening:\n1. $\\beta$-VAE is not the best performing disentangling method and better disentangling constraints should be used instead -- e.g., works of Chen et al. (2018) and Lopez et al. (2018).\n2. It is theoretically impossible to achieve disentanglement without some supervision (Locatello et al, 2019) ... which might not be possible to provide in this task.\nExploring these options is beyond the scope of this paper and is a great future direction for this work.\n\nWe have updated the paper to include the above discussions; see the green text on page 8 (marked as \u201cR1 & R3 & R4\u201d), and the Future Work in green text on page 9 (marked as \u201cR1 & R3\u201d), as well as the newly added Appendix A.5 in (marked as \u201cR1 & R3\u201d).\t \n\nREFERENCES\n- Ricky TQ Chen, Xuechen Li, Roger B Grosse, and David K Duvenaud. Isolating sources of disentanglement in variational autoencoders. In *NeurIPS*, 2018.\n- Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Raetsch, Sylvain Gelly, Bernhard Sch\u00f6lkopf, and Olivier Bachem. Challenging common assumptions in the unsupervised learning of disentangled representations. In *ICML*, 2019.\n- Romain Lopez, Jeffrey Regier, Michael I Jordan, and Nir Yosef. Information constraints on auto-encoding variational bayes. In *NeurIPS*, 2018.\n\n\n**Explain why H-VAE-CI has a considerable gap to the other models at $\\gamma=0$.**\n\nWIth $\\gamma=0$, we get discriminative only models. Hence, we view your question as asking: *\u201cWhy is one discriminative model performing better than other discriminative models?\u201d* \u2026 which is a fundamental question in Machine Learning in general. It is in fact quite common for models from the same family (e.g., neural network (NN)) with different architectures to perform differently (e.g., a fully connected NN vs. a convolutional NN). In case of our paper, H-VAE-CI seems to be more resilient to different $\\gamma$ values in general (including $\\gamma=0$), compared to {S,P}-VAE-CI -- note H-VAE-CI\u2019s better $\\textrm{PEHE}$, particularly for $\\gamma \\leq 0.01$. \n\nViewed from another perspective, it appears that having the $L_{\\textrm{VAE}}$ term is more important for {S,P}-VAE-CI than for H-VAE-CI to perform well. We hypothesize that H-VAE-CI already learns expressive representations $Z_3$ and $Z_7$, meaning the optimization no longer really *requires* the $L_{\\textrm{VAE}}$ term to impose that. This is in contrast to $Z_1$ in S-VAE-CI and $Z_1$ and $Z_3$ in P-VAE-CI. To check if this hypothesis holds, we tried to calculate the mutual information (following Belghazi, et al. (2018)\u2019s method) between $\\[Z_3, Z_7\\]$ and $X$ (i.e., $ MI(\\ \\[ Z_3, Z_7 \\], X \\ ) $) for H-VAE-CI, and compare the results with $ MI(\\ \\[ Z_1, Z_3 \\], X\\ ) $ for P-VAE-CI as well as $ MI(\\ Z_1, X\\ ) $ for S-VAE-CI. Unfortunately, however, it appears that Belghazi, et al. (2018)\u2019s method for estimating MI does not work for high-dimensional data such as ours. We appreciate any suggestions you might have to test this hypothesis.\n\nWe have updated the paper on pages 7 and 9 in green text (marked as \u201cR1 & R4\u201d), to touch on this analysis.\n\nREFERENCE\n- Belghazi, M. I., Baratin, A., Rajeshwar, S., Ozair, S., Bengio, Y., Courville, A., & Hjelm, D. (2018). MINE: Mutual Information Neural Estimation. In *ICML*.\n\n\n**How is the IPM chosen for $\\mathcal{L}_{\\mathtt{disc}}$?**\n\nThe IPM we used in our experiments is the linear MMD. Note that we have developed our code on top of the CFR\u2019s code-base, available online at https://github.com/clinicalml/cfrnet, from which we inherit the helper functions such as calculation of the $\\mathcal{L}_{\\mathtt{disc}}$. This is why our supplementary material only included the files for our proposed methods\u2019 tensorflow graph. See the comment at the top of our published codes.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1286/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Auto-Encoder Architectures that Excel at Causal Inference", "authorids": ["~Negar_Hassanpour1", "~Russell_Greiner2"], "authors": ["Negar Hassanpour", "Russell Greiner"], "keywords": ["Causal Inference", "Generative Modelling", "Distributional Shift"], "abstract": "This paper provides a generative approach for causal inference using data from observational studies. Inspired by the work of Kingma et al. (2014), we propose a sequence of three architectures (namely Series, Parallel, and Hybrid) that each incorporate their M1 and M2 models as building blocks. Each architecture is an improvement over the previous one in terms of estimating causal effect, culminating in the Hybrid model. The Hybrid model is designed to encourage decomposing the underlying factors of any observational dataset; this in turn, helps to accurately estimate all treatment outcomes. Our empirical results demonstrate the superiority of all three proposed architectures compared to both state-of-the-art discriminative as well as other generative approaches in the literature. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hassanpour|variational_autoencoder_architectures_that_excel_at_causal_inference", "one-sentence_summary": "A VAE-based generative approach for causal inference using data from observational studies.", "supplementary_material": "/attachment/4a8e8cef39d97d74d2a985202167ef996aa9114d.zip", "pdf": "/pdf/9ee2d7f714872424867e14fe77cd07ebf1393391.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=00B5KMeMNB", "_bibtex": "@misc{\nhassanpour2021variational,\ntitle={Variational Auto-Encoder Architectures that Excel at Causal Inference},\nauthor={Negar Hassanpour and Russell Greiner},\nyear={2021},\nurl={https://openreview.net/forum?id=TVbDOOr6hL}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "TVbDOOr6hL", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1286/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1286/Authors|ICLR.cc/2021/Conference/Paper1286/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923861460, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1286/-/Official_Comment"}}}, {"id": "1heHh-sxYd", "original": null, "number": 2, "cdate": 1603496697152, "ddate": null, "tcdate": 1603496697152, "tmdate": 1605024482536, "tddate": null, "forum": "TVbDOOr6hL", "replyto": "TVbDOOr6hL", "invitation": "ICLR.cc/2021/Conference/Paper1286/-/Official_Review", "content": {"title": "Official review #3", "review": "Summary: Some generative models have been proposed for causal effect estimation but they often do not have a competitive performance. Recent work suggested that a combination of generative and discriminative model may improve treatment estimation with observational data, and further suggests a generic latent variable model for factorizing selection bias, as well as outcome. The author(s) build on this work and propose a set of deep generative models, with a hybrid objective function (generative + discriminative), that outperforms current approaches for ATE. \n\nThe proposed family of models is appealing. The proposed objective function is motivated from previous literature. I think it is always a shame (but alright) that one must add those beta constraints on VAEs in order to get sensible results (see my question below). Still, the experimental section makes a strong point that the method is effective and outperform previous approaches.\n\nQuestion:\n1. What are the results of the hyperparameter search for beta? In particular, if the result of beta is small (or zero), can the model still be called a VAE, as it should degenerate as an autoencoder. In that case, the approximate posterior may have near zero variance and the model barely capture any uncertainty. I wish to understand (a) whether the resulting model is still able to really generate data, from the prior predictive density and (b) what would be the performance of the model with a fixed beta, or a beta annealing as an ablation study. \n2. Would it be more advantageous to use other disentanglement constraints instead of the beta-VAE? [1, 2]\n\n[1] https://arxiv.org/pdf/1802.04942.pdf\n[2] https://arxiv.org/abs/1805.08672\n\n ", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1286/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1286/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Variational Auto-Encoder Architectures that Excel at Causal Inference", "authorids": ["~Negar_Hassanpour1", "~Russell_Greiner2"], "authors": ["Negar Hassanpour", "Russell Greiner"], "keywords": ["Causal Inference", "Generative Modelling", "Distributional Shift"], "abstract": "This paper provides a generative approach for causal inference using data from observational studies. Inspired by the work of Kingma et al. (2014), we propose a sequence of three architectures (namely Series, Parallel, and Hybrid) that each incorporate their M1 and M2 models as building blocks. Each architecture is an improvement over the previous one in terms of estimating causal effect, culminating in the Hybrid model. The Hybrid model is designed to encourage decomposing the underlying factors of any observational dataset; this in turn, helps to accurately estimate all treatment outcomes. Our empirical results demonstrate the superiority of all three proposed architectures compared to both state-of-the-art discriminative as well as other generative approaches in the literature. ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "hassanpour|variational_autoencoder_architectures_that_excel_at_causal_inference", "one-sentence_summary": "A VAE-based generative approach for causal inference using data from observational studies.", "supplementary_material": "/attachment/4a8e8cef39d97d74d2a985202167ef996aa9114d.zip", "pdf": "/pdf/9ee2d7f714872424867e14fe77cd07ebf1393391.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=00B5KMeMNB", "_bibtex": "@misc{\nhassanpour2021variational,\ntitle={Variational Auto-Encoder Architectures that Excel at Causal Inference},\nauthor={Negar Hassanpour and Russell Greiner},\nyear={2021},\nurl={https://openreview.net/forum?id=TVbDOOr6hL}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "TVbDOOr6hL", "replyto": "TVbDOOr6hL", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1286/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538122158, "tmdate": 1606915795089, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1286/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1286/-/Official_Review"}}}], "count": 18}