{"notes": [{"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1458583392386, "tcdate": 1458583392386, "id": "vl6qw8NMYH7OYLG5in8q", "invitation": "ICLR.cc/2016/workshop/-/paper/194/review/11", "forum": "OM0jKROjrFp57ZJjtNkv", "replyto": "OM0jKROjrFp57ZJjtNkv", "signatures": ["ICLR.cc/2016/workshop/paper/194/reviewer/11"], "readers": ["everyone"], "writers": ["ICLR.cc/2016/workshop/paper/194/reviewer/11"], "content": {"title": "A thoughtful and interesting analysis", "rating": "8: Top 50% of accepted papers, clear accept", "review": "This paper presents a detailed analysis of the random effects of the training sample order and weight initialisation on the WER of two ASR tasks.  The interesting finding is that this randomisation can in fact lead to substantial changes in performance -- such that similar magnitudes of variation would often be taken as significant differences between algorithms.  This is an important, and perhaps shocking finding.  The results are given added credibility by the use of state-of-the-art ASR systems in all work.\n\nThe paper is accompanied by an thorough and interesting analysis.  Particularly interesting is the comparison of the random effects of training data ordering vs. network initialisation.\n\nOf course, one negative aspect, as the authors note themselves, is that this study is extremely computationally expensive, and for real practical benefit to come from it, more efficient methods would need to be found.  However, this in no way diminishes the interest of this timely work.\n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Neural Network Training Variations in Speech and Subsequent Performance Evaluation", "abstract": "In this work we study variance in the results of neural network training on a wide\nvariety of configurations in automatic speech recognition. Although this variance\nitself is well known, this is, to the best of our knowledge, the first paper that\nperforms an extensive empirical study on its effects in speech recognition. We\nview training as sampling from a distribution and show that these distributions\ncan have a substantial variance. These observations have important implications\non way results in the literature are reported and interpreted. ", "pdf": "/pdf/OM0jKROjrFp57ZJjtNkv.pdf", "paperhash": "berg|neural_network_training_variations_in_speech_and_subsequent_performance_evaluation", "conflicts": ["us.ibm.com"], "authorids": ["evanden@us.ibm.com", "bhuvana@us.ibm.com", "picheny@us.ibm.com"], "authors": ["Ewout van den Berg", "Bhuvana Ramabhadran", "Michael Picheny"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456580182172, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456580182172, "id": "ICLR.cc/2016/workshop/-/paper/194/review/11", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "OM0jKROjrFp57ZJjtNkv", "replyto": "OM0jKROjrFp57ZJjtNkv", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/194/reviewer/11", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1457646936062, "tcdate": 1457646936062, "id": "71BERYqPlfAE8VvKUQqG", "invitation": "ICLR.cc/2016/workshop/-/paper/194/review/12", "forum": "OM0jKROjrFp57ZJjtNkv", "replyto": "OM0jKROjrFp57ZJjtNkv", "signatures": ["ICLR.cc/2016/workshop/paper/194/reviewer/12"], "readers": ["everyone"], "writers": ["ICLR.cc/2016/workshop/paper/194/reviewer/12"], "content": {"title": "issue worth reminding", "rating": "7: Good paper, accept", "review": "\nThis paper shows experimentally that error bars for the exactly same NN models trained with exactly same data but with different initial seeds of pseudo-random number generators (initial weights, data shuffling, etc.) can be really significant. The range between best and worst models often exceeds rather genuine and incremental improvements reported in ASR field in recent years (which itself are rather inflated, since if we were improving by ~10\\% relative each year, ASR problem would be solved long time ago - this is just a digression, not a complaint regarding this particular paper of course). The findings are not new and well known to many who trained NNs but I think worth reminding, and a workshop is a very good venue for it.\n\nI know you reference papers for your model configurations (sorry, my fault I didn't had a chance to check if they contain this information) but it would be a good idea to put more details on how exactly you initialise the models - what range of initial parameters, is pre-training used, etc. -- since this paper is mostly about this aspect, it would be nice to have them in-place.\n\nOne criticism I have is the experiments investigate only sigmoid models, which are known to be particularly sensitive to weights initialisation, which can heavily affect training dynamics in deep models. It would be really nice if you could try if (and to what extent) this issue persist with piece-wise linear units.\n\nAlso, since you already have this, could you plot or write somewhere a short comment whether and to what extent training objective is correlated with the obtained WERs, is it at least monotnous? Otherwise, even if one was able to derive some uncertainty bounds on the NN outputs, this still would be an unsatisfactory predictor of WERs, at least with CE criterion.\n\nRegarding this sentence \"Interestingly, the starting point seems to be much more important than the network quality used to generate the lattices\" is not that surprising to me. Any denominator lattices will do, given the right paths (or right kind of mistakes) are in them, and those models are likely to make similar ones anyway.\n \nIt is also interesting and somehow a counter example of claims (of, by the way excellent paper, of Choromanska et al.,2014) that for sufficiently large models, it is rather hard to end up in poor or saddle point minima, and that most local minima will do a good job. It's subjective, but perhaps 15.5% for SWBD (the worst minima you report) isn't that bad at all.\n\nFig. 1 typo in the word cross-entropy *loos*", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Neural Network Training Variations in Speech and Subsequent Performance Evaluation", "abstract": "In this work we study variance in the results of neural network training on a wide\nvariety of configurations in automatic speech recognition. Although this variance\nitself is well known, this is, to the best of our knowledge, the first paper that\nperforms an extensive empirical study on its effects in speech recognition. We\nview training as sampling from a distribution and show that these distributions\ncan have a substantial variance. These observations have important implications\non way results in the literature are reported and interpreted. ", "pdf": "/pdf/OM0jKROjrFp57ZJjtNkv.pdf", "paperhash": "berg|neural_network_training_variations_in_speech_and_subsequent_performance_evaluation", "conflicts": ["us.ibm.com"], "authorids": ["evanden@us.ibm.com", "bhuvana@us.ibm.com", "picheny@us.ibm.com"], "authors": ["Ewout van den Berg", "Bhuvana Ramabhadran", "Michael Picheny"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456580181843, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456580181843, "id": "ICLR.cc/2016/workshop/-/paper/194/review/12", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "OM0jKROjrFp57ZJjtNkv", "replyto": "OM0jKROjrFp57ZJjtNkv", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/194/reviewer/12", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1456642427341, "tcdate": 1456642427341, "id": "0YrxNE3vKCGJ7gK5tR29", "invitation": "ICLR.cc/2016/workshop/-/paper/194/review/10", "forum": "OM0jKROjrFp57ZJjtNkv", "replyto": "OM0jKROjrFp57ZJjtNkv", "signatures": ["~Dong_Yu1"], "readers": ["everyone"], "writers": ["~Dong_Yu1"], "content": {"title": "well known conclusion but maybe useful empirical result", "rating": "5: Marginally below acceptance threshold", "review": "This paper studies the variance in the results of neural network training on a wide variety of con\ufb01gurations in automatic speech recognition. It raises the question on how to compare two deep learning models when it's difficult and sometimes impossible to run many experiments.\n\nThis variance problem is well known. The main contribution of this work is running many empirical experiments to demonstrate the problem in ASR and alerting readers on the right way to compare two different models. I think it can bring some values to the community. However, if a practical formula for comparing different models can be provided the significance of the paper would be greatly improved.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Neural Network Training Variations in Speech and Subsequent Performance Evaluation", "abstract": "In this work we study variance in the results of neural network training on a wide\nvariety of configurations in automatic speech recognition. Although this variance\nitself is well known, this is, to the best of our knowledge, the first paper that\nperforms an extensive empirical study on its effects in speech recognition. We\nview training as sampling from a distribution and show that these distributions\ncan have a substantial variance. These observations have important implications\non way results in the literature are reported and interpreted. ", "pdf": "/pdf/OM0jKROjrFp57ZJjtNkv.pdf", "paperhash": "berg|neural_network_training_variations_in_speech_and_subsequent_performance_evaluation", "conflicts": ["us.ibm.com"], "authorids": ["evanden@us.ibm.com", "bhuvana@us.ibm.com", "picheny@us.ibm.com"], "authors": ["Ewout van den Berg", "Bhuvana Ramabhadran", "Michael Picheny"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456580182429, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456580182429, "id": "ICLR.cc/2016/workshop/-/paper/194/review/10", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "OM0jKROjrFp57ZJjtNkv", "replyto": "OM0jKROjrFp57ZJjtNkv", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/194/reviewer/10", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1455946075227, "tcdate": 1455946075227, "id": "lx9o0N4jZT2OVPy8Cvyy", "invitation": "ICLR.cc/2016/workshop/-/paper/194/comment", "forum": "OM0jKROjrFp57ZJjtNkv", "replyto": "OM0jKROjrFp57ZJjtNkv", "signatures": ["~Han_Xiao1"], "readers": ["everyone"], "writers": ["~Han_Xiao1"], "content": {"title": "I am a freshman for this website.", "comment": "I am interested in this paper and don't know how to read its reviews?\nThis paper is really good.\n\nHey, I am sorry for disturbing others, but I really dont know how to delete this post?\nWho can help me?\n\n: )"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Neural Network Training Variations in Speech and Subsequent Performance Evaluation", "abstract": "In this work we study variance in the results of neural network training on a wide\nvariety of configurations in automatic speech recognition. Although this variance\nitself is well known, this is, to the best of our knowledge, the first paper that\nperforms an extensive empirical study on its effects in speech recognition. We\nview training as sampling from a distribution and show that these distributions\ncan have a substantial variance. These observations have important implications\non way results in the literature are reported and interpreted. ", "pdf": "/pdf/OM0jKROjrFp57ZJjtNkv.pdf", "paperhash": "berg|neural_network_training_variations_in_speech_and_subsequent_performance_evaluation", "conflicts": ["us.ibm.com"], "authorids": ["evanden@us.ibm.com", "bhuvana@us.ibm.com", "picheny@us.ibm.com"], "authors": ["Ewout van den Berg", "Bhuvana Ramabhadran", "Michael Picheny"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "tmdate": null, "cdate": 1455833569891, "ddate": null, "super": null, "final": null, "tcdate": 1455833569891, "id": "ICLR.cc/2016/workshop/-/paper/194/comment", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "readers": ["everyone"], "reply": {"pdf": null, "replyto": null, "writers": {"values-regex": "~.*"}, "forum": "OM0jKROjrFp57ZJjtNkv", "signatures": {"values-regex": "~.*", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "invitees": ["~", "ICLR.cc/2016/workshop/paper/194/reviewer"], "nonreaders": [], "noninvitees": []}}}, {"tddate": null, "number": null, "replyto": null, "ddate": null, "cdate": null, "tmdate": 1455833567751, "tcdate": 1455833567751, "id": "OM0jKROjrFp57ZJjtNkv", "invitation": "ICLR.cc/2016/workshop/-/submission", "forum": "OM0jKROjrFp57ZJjtNkv", "signatures": ["~Ewout_van_den_Berg1"], "readers": ["everyone"], "writers": ["~Ewout_van_den_Berg1"], "content": {"CMT_id": "", "title": "Neural Network Training Variations in Speech and Subsequent Performance Evaluation", "abstract": "In this work we study variance in the results of neural network training on a wide\nvariety of configurations in automatic speech recognition. Although this variance\nitself is well known, this is, to the best of our knowledge, the first paper that\nperforms an extensive empirical study on its effects in speech recognition. We\nview training as sampling from a distribution and show that these distributions\ncan have a substantial variance. These observations have important implications\non way results in the literature are reported and interpreted. ", "pdf": "/pdf/OM0jKROjrFp57ZJjtNkv.pdf", "paperhash": "berg|neural_network_training_variations_in_speech_and_subsequent_performance_evaluation", "conflicts": ["us.ibm.com"], "authorids": ["evanden@us.ibm.com", "bhuvana@us.ibm.com", "picheny@us.ibm.com"], "authors": ["Ewout van den Berg", "Bhuvana Ramabhadran", "Michael Picheny"]}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1454464564200, "ddate": null, "super": null, "final": null, "duedate": 1455833700000, "tcdate": 1454464564200, "id": "ICLR.cc/2016/workshop/-/submission", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "readers": ["everyone"], "reply": {"pdf": null, "forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"order": 4, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv.", "value-regex": "upload|http://arxiv.org/pdf/.+"}, "title": {"order": 3, "description": "Title of paper.", "value-regex": ".{0,500}"}, "abstract": {"order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"order": 1, "description": "Comma separated list of author names, as they appear in the paper.", "value-regex": "[^,\\n]+(,[^,\\n]+)*"}, "author_emails": {"order": 2, "description": "Comma separated list of author email addresses, in the same order as above.", "value-regex": "[^,\\n]+(,[^,\\n]+)*"}, "conflicts": {"order": 100, "description": "Semi-colon separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.).", "value-regex": "^([a-zA-Z0-9][a-zA-Z0-9-_]{0,61}[a-zA-Z0-9]{0,1}\\.([a-zA-Z]{1,6}|[a-zA-Z0-9-]{1,30}\\.[a-zA-Z]{2,3}))+(;[a-zA-Z0-9][a-zA-Z0-9-_]{0,61}[a-zA-Z0-9]{0,1}\\.([a-zA-Z]{1,6}|[a-zA-Z0-9-]{1,30}\\.[a-zA-Z]{2,3}))*$"}, "CMT_id": {"order": 5, "value-regex": ".*", "description": "If the paper is a resubmission from the ICLR 2016 Conference Track, enter its CMT ID; otherwise, leave blank."}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "expdate": 1463609700000}}}], "count": 5}