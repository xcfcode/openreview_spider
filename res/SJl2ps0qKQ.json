{"notes": [{"id": "SJl2ps0qKQ", "original": "HkeCV5pqF7", "number": 842, "cdate": 1538087876420, "ddate": null, "tcdate": 1538087876420, "tmdate": 1545355433129, "tddate": null, "forum": "SJl2ps0qKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Learning to Decompose Compound Questions with Reinforcement Learning", "abstract": "As for knowledge-based question answering, a fundamental problem is to relax the assumption of answerable questions from simple questions to compound questions. Traditional approaches firstly detect topic entity mentioned in questions, then traverse the knowledge graph to find relations as a multi-hop path to answers, while we propose a novel approach to leverage simple-question answerers to answer compound questions. Our model consists of two parts: (i) a novel learning-to-decompose agent that learns a policy to decompose a compound question into simple questions and (ii) three independent simple-question answerers that classify the corresponding relations for each simple question. Experiments demonstrate that our model learns complex rules of compositionality as stochastic policy, which benefits simple neural networks to achieve state-of-the-art results on WebQuestions and MetaQA. We analyze the interpretable decomposition process as well as generated partitions.", "keywords": ["Compound Question Decomposition", "Reinforcement Learning", "Knowledge-Based Question Answering", "Learning-to-decompose"], "authorids": ["capriceyhh@zju.edu.cn", "wanghanwh@zju.edu.cn", "guoshuang@zju.edu.cn", "lantau.zw@alibaba-inc.com", "huajunsir@zju.edu.cn"], "authors": ["Haihong Yang", "Han Wang", "Shuang Guo", "Wei Zhang", "Huajun Chen"], "TL;DR": "We propose a learning-to-decompose agent that helps simple-question answerers to answer compound question over knowledge graph.", "pdf": "/pdf/1c9f6ef4b3d02a397e1b8ee17c6f62b7917fe696.pdf", "paperhash": "yang|learning_to_decompose_compound_questions_with_reinforcement_learning", "_bibtex": "@misc{\nyang2019learning,\ntitle={Learning to Decompose Compound Questions with Reinforcement Learning},\nauthor={Haihong Yang and Han Wang and Shuang Guo and Wei Zhang and Huajun Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl2ps0qKQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "B1eLMCmHlN", "original": null, "number": 1, "cdate": 1545055758116, "ddate": null, "tcdate": 1545055758116, "tmdate": 1545354483400, "tddate": null, "forum": "SJl2ps0qKQ", "replyto": "SJl2ps0qKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper842/Meta_Review", "content": {"metareview": "+ an interesting task -- learning to decompose questions without supervision\n\n- reviewers are not convinced by evaluation. Initially evaluated on MetaQA only, later relation classification on WebQuestions has been added.  It is not really clear that the approach is indeed beneficial on WebQuestion relation classification (no analysis / ablations) and MetaQA is not a very standard dataset.\n\n-  Reviewers have concerns about comparison to previous work / the lack of state-of-the-art baselines. Some of these issues have been addressed though (e.g., discussion of Iyyer et al. 2016)\n\n\n\n", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Reject", "title": "interesting directions / results are not very convincing"}, "signatures": ["ICLR.cc/2019/Conference/Paper842/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper842/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Decompose Compound Questions with Reinforcement Learning", "abstract": "As for knowledge-based question answering, a fundamental problem is to relax the assumption of answerable questions from simple questions to compound questions. Traditional approaches firstly detect topic entity mentioned in questions, then traverse the knowledge graph to find relations as a multi-hop path to answers, while we propose a novel approach to leverage simple-question answerers to answer compound questions. Our model consists of two parts: (i) a novel learning-to-decompose agent that learns a policy to decompose a compound question into simple questions and (ii) three independent simple-question answerers that classify the corresponding relations for each simple question. Experiments demonstrate that our model learns complex rules of compositionality as stochastic policy, which benefits simple neural networks to achieve state-of-the-art results on WebQuestions and MetaQA. We analyze the interpretable decomposition process as well as generated partitions.", "keywords": ["Compound Question Decomposition", "Reinforcement Learning", "Knowledge-Based Question Answering", "Learning-to-decompose"], "authorids": ["capriceyhh@zju.edu.cn", "wanghanwh@zju.edu.cn", "guoshuang@zju.edu.cn", "lantau.zw@alibaba-inc.com", "huajunsir@zju.edu.cn"], "authors": ["Haihong Yang", "Han Wang", "Shuang Guo", "Wei Zhang", "Huajun Chen"], "TL;DR": "We propose a learning-to-decompose agent that helps simple-question answerers to answer compound question over knowledge graph.", "pdf": "/pdf/1c9f6ef4b3d02a397e1b8ee17c6f62b7917fe696.pdf", "paperhash": "yang|learning_to_decompose_compound_questions_with_reinforcement_learning", "_bibtex": "@misc{\nyang2019learning,\ntitle={Learning to Decompose Compound Questions with Reinforcement Learning},\nauthor={Haihong Yang and Han Wang and Shuang Guo and Wei Zhang and Huajun Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl2ps0qKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper842/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353064781, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJl2ps0qKQ", "replyto": "SJl2ps0qKQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper842/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper842/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper842/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353064781}}}, {"id": "ryeHUaMqRQ", "original": null, "number": 7, "cdate": 1543281996696, "ddate": null, "tcdate": 1543281996696, "tmdate": 1543286770656, "tddate": null, "forum": "SJl2ps0qKQ", "replyto": "BJlhURN5nm", "invitation": "ICLR.cc/2019/Conference/-/Paper842/Official_Comment", "content": {"title": "Thank you very much for your helpful reviews! We have updated our paper for clarification.", "comment": "Thank you very much for your valuable review! We have updated our paper with additional experiments! We will provide detailed explanation for your concerns. \n\nPlease refer to global comments for brief version of model improvement and paper refinement!\n\nQ1: Does this mean that the model can have <=3 partitions, but not more? How is this number decided?\nA1:\n- The central assumption of our paper is to generalize the assumption of answerable questions from simple questions to compound questions (simple questions included). \n\n- Based on the observation of daily questions asked by people (e.g. WebQuestions) and the currently available datasets (MetaQA), it is hard to find compound questions with more than three partitions to experiment with. So the default number of partitions is 2 or 3 (<=3). We have updated our paper for ablation test of these two options. Results and discussion can be found in section 4.3.\n\nQ2: From Eq (4), it seems that the answerer only uses the current partition, is that the case? Moreover, how is the gold relation r obtained?\nA2: In our improved model, we use three answerers for each partition. The vector representation of a partition is the last hidden state of answerer's LSTM network. The golden relation $r$ is part of the golden label providing by datasets. The answerer predicts and updates according to the gradients of cross entropy loss.\n\nQ3: It would be nice to add more explanation to the caption of Figure 4 to make it self-contained.\nA3: We have updated our paper to make it self-contained! Please check out our paper for more details.\n\nQ4: The case study section (4.3) only contains a single example. It would be very helpful to include more examples of question partitions (there is enough space). Error analysis would also be helpful to understand, for example, why the proposed model is worse than VRN (Zhang et al. 2017) on 1- and 2-hop questions.\nA4:\n- Case Study is now section 4.4! The main purpose of case study is to illustrate that our agent can maximize information utilization by assigning words to the best position. \n\n- We also add an ablation test for providing better understanding of our model. Since we have further improved our model, please refer to global comments for reasons of model change. It directly leads to outperforming the state-of-the-art model by ~8% overall accuracy.\n\nThank you again for your time and helpful review! We really appreciate it! We would be happy to open source our code and hyper-parameters until the final decisions are out!"}, "signatures": ["ICLR.cc/2019/Conference/Paper842/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper842/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper842/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Decompose Compound Questions with Reinforcement Learning", "abstract": "As for knowledge-based question answering, a fundamental problem is to relax the assumption of answerable questions from simple questions to compound questions. Traditional approaches firstly detect topic entity mentioned in questions, then traverse the knowledge graph to find relations as a multi-hop path to answers, while we propose a novel approach to leverage simple-question answerers to answer compound questions. Our model consists of two parts: (i) a novel learning-to-decompose agent that learns a policy to decompose a compound question into simple questions and (ii) three independent simple-question answerers that classify the corresponding relations for each simple question. Experiments demonstrate that our model learns complex rules of compositionality as stochastic policy, which benefits simple neural networks to achieve state-of-the-art results on WebQuestions and MetaQA. We analyze the interpretable decomposition process as well as generated partitions.", "keywords": ["Compound Question Decomposition", "Reinforcement Learning", "Knowledge-Based Question Answering", "Learning-to-decompose"], "authorids": ["capriceyhh@zju.edu.cn", "wanghanwh@zju.edu.cn", "guoshuang@zju.edu.cn", "lantau.zw@alibaba-inc.com", "huajunsir@zju.edu.cn"], "authors": ["Haihong Yang", "Han Wang", "Shuang Guo", "Wei Zhang", "Huajun Chen"], "TL;DR": "We propose a learning-to-decompose agent that helps simple-question answerers to answer compound question over knowledge graph.", "pdf": "/pdf/1c9f6ef4b3d02a397e1b8ee17c6f62b7917fe696.pdf", "paperhash": "yang|learning_to_decompose_compound_questions_with_reinforcement_learning", "_bibtex": "@misc{\nyang2019learning,\ntitle={Learning to Decompose Compound Questions with Reinforcement Learning},\nauthor={Haihong Yang and Han Wang and Shuang Guo and Wei Zhang and Huajun Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl2ps0qKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper842/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621606813, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJl2ps0qKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper842/Authors", "ICLR.cc/2019/Conference/Paper842/Reviewers", "ICLR.cc/2019/Conference/Paper842/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper842/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper842/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper842/Authors|ICLR.cc/2019/Conference/Paper842/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper842/Reviewers", "ICLR.cc/2019/Conference/Paper842/Authors", "ICLR.cc/2019/Conference/Paper842/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621606813}}}, {"id": "Bkl2pJE5Am", "original": null, "number": 8, "cdate": 1543286724455, "ddate": null, "tcdate": 1543286724455, "tmdate": 1543286724455, "tddate": null, "forum": "SJl2ps0qKQ", "replyto": "BJesG858hQ", "invitation": "ICLR.cc/2019/Conference/-/Paper842/Official_Comment", "content": {"title": "Thank you very much for your insightful review! Paper updates and model improves! ", "comment": "Thank you very much for your insightful review! We have updated our paper with new experiments! We will address your concerns point by point.\n\nPlease refer to global comments for brief version of model improvement and paper refinement!\n\nQ1: Could you provide results on WebQuestions (or WebQSP).\nA1: Yes! We conduct experiments on WebQuestions relation detection since relation detection is believed to be the bottleneck of KBQA and we attempt to solve it. It achieves competitive results to strong baseline (Yu et al, 2017, [1]). \n\nIt seems like our model performs differently in two datasets. Here are the reasons:\n- There are ~5% relations that remains unseen in training set. It is a harmful setting for classification task.\n- To address the above issue, recent approaches try to leverage the information from knowledge base, especially the detailed name or schema info of Freebase relations. By contrast, our proposed model only leverages the question information to achieve competitive results.\n\nQ2: \"I think the authors should compare their approach with previous work.\"\nA2: We have updated our paper for discussion in related work (Please check out paragraph 2 & 3 in section 2.2). We tried to reimplement their methods and found that it is not suitable for our setup.\n\n* Search-based Neural Structured Learning for Sequential Question Answering\nWhen generating datasets, the author employs crowdsourcing workers to manually decompose questions from WikiTableQuestions into sequential questions. It aims to train a text-to-sql model for querying answers and updating next input question interactively. Conversely, our proposed model emphasizes decomposing compound questions automatically with fewer supervision.\n\n* ComplexWebQuestions\n- The state-of-the-art solution of ComplexWebQuestions adopts pointer network to decompose complex web questions into simple ones. This decomposition process is guided by supervisions inline with human logic (e.g., conjunction or composition etc.). The author feeds all the decomposed questions into search engine then collects top-ranked web snippets as data source of answers. \n\n- Note that the pointer network is trained via maximizing log-likelihood of annotations.\n\n- The problem is that, if we replace pointer network with our learning-to-decompose agent, we cannot afford to crawl web pages during training because our agent will generate different partitions.\n\nThank you again for your valuable review and inspiration! We would be happy to open source our code and hyper-parameters until the final decisions are out!\n\n[1] Yu et al. Improve Neural Relation Detection for Knowledge-based Question Answering. ACL, 2017."}, "signatures": ["ICLR.cc/2019/Conference/Paper842/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper842/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper842/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Decompose Compound Questions with Reinforcement Learning", "abstract": "As for knowledge-based question answering, a fundamental problem is to relax the assumption of answerable questions from simple questions to compound questions. Traditional approaches firstly detect topic entity mentioned in questions, then traverse the knowledge graph to find relations as a multi-hop path to answers, while we propose a novel approach to leverage simple-question answerers to answer compound questions. Our model consists of two parts: (i) a novel learning-to-decompose agent that learns a policy to decompose a compound question into simple questions and (ii) three independent simple-question answerers that classify the corresponding relations for each simple question. Experiments demonstrate that our model learns complex rules of compositionality as stochastic policy, which benefits simple neural networks to achieve state-of-the-art results on WebQuestions and MetaQA. We analyze the interpretable decomposition process as well as generated partitions.", "keywords": ["Compound Question Decomposition", "Reinforcement Learning", "Knowledge-Based Question Answering", "Learning-to-decompose"], "authorids": ["capriceyhh@zju.edu.cn", "wanghanwh@zju.edu.cn", "guoshuang@zju.edu.cn", "lantau.zw@alibaba-inc.com", "huajunsir@zju.edu.cn"], "authors": ["Haihong Yang", "Han Wang", "Shuang Guo", "Wei Zhang", "Huajun Chen"], "TL;DR": "We propose a learning-to-decompose agent that helps simple-question answerers to answer compound question over knowledge graph.", "pdf": "/pdf/1c9f6ef4b3d02a397e1b8ee17c6f62b7917fe696.pdf", "paperhash": "yang|learning_to_decompose_compound_questions_with_reinforcement_learning", "_bibtex": "@misc{\nyang2019learning,\ntitle={Learning to Decompose Compound Questions with Reinforcement Learning},\nauthor={Haihong Yang and Han Wang and Shuang Guo and Wei Zhang and Huajun Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl2ps0qKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper842/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621606813, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJl2ps0qKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper842/Authors", "ICLR.cc/2019/Conference/Paper842/Reviewers", "ICLR.cc/2019/Conference/Paper842/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper842/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper842/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper842/Authors|ICLR.cc/2019/Conference/Paper842/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper842/Reviewers", "ICLR.cc/2019/Conference/Paper842/Authors", "ICLR.cc/2019/Conference/Paper842/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621606813}}}, {"id": "rkgD8DMcC7", "original": null, "number": 6, "cdate": 1543280463298, "ddate": null, "tcdate": 1543280463298, "tmdate": 1543280946439, "tddate": null, "forum": "SJl2ps0qKQ", "replyto": "BJe28_qT27", "invitation": "ICLR.cc/2019/Conference/-/Paper842/Official_Comment", "content": {"title": "Thank you very much! Please check out our latest version of paper for model improvement and paper refinement!", "comment": "Thank you very much for your detailed and helpful review! We have updated our paper with your suggestions! We will address your concerns point by point. Please refer to global comments for brief version of model improvement and paper refinement!\n\n* Reply for Weakness\nWe compare [1] with our work and summarize an important line of Semantic Role Labeling in our latest paper. We like to point out that [1] decomposes WikiTableQuestions into sequential questions by crowdsourcing workers (manually) in the process of generating SequentialQA dataset. However, we train our agent to learn to decompose questions automatically.\n\nSemantic Role Labeling is similar to labeling priority/actions word by word, which is part of our proposed method. However, we don't require supervision signals at the token-level. The only supervision for our agent is the +1/-1 reward as feedbacks.\n\n* Questions\nQ1: How do you obtain x^(k)? Is it the last state of the LSTM?\nA1: Yes, it is the last hidden state $h$ of the LSTM. For clarity, there are two x^(k) with different style in our paper. The bold x^(k) denotes a sub-sequence of words as a partition. Another bold italic x^(k) denotes the final vector representation of corresponding partition. We have updated our paper for clarification.\n\nQ2: Why did you have to augment \u201cNO_OP\u201d relation in the MetaQA dataset?\nA2: \n(1) The main reason for augmenting a dummy relation is to provide more freedom of the cooperation among our agent and the answerers\\*. When our model is trying to answer a simple question, our agent may filter some unrelated words (e.g. stop words) out of the first partition because of its stochastic policy. The second and the third answerer can return a \"NO_OP\" relation when receiving some meaningless inputs. \n\n(2) If we don't augment a \"NO_OP\" relation, our agent has to assign every single word to the first partition and hope the first answerer can predict the golden relation correctly, which is too strict for a feasible solution. Note that we allow our agent to learn partition strategies that is different from human intuition since we train it using RL settings.\n\nQ3: Why +1 reward has lower variance than probabilistic reward? Explanation or citation would be needed.\nA3: \n(1) Because the maximum value of variance of +1/-1 reward is 1 (Please see proof below). The variance of probabilistic reward does not necessarily have an upper bound since the value of logarithmic function goes negative infinity if the likelihood is sufficiently small. This kind of situation is likely to occur in the early stages of training when the agent explores the space of partition strategies actively. \n\n(2) From the perspective of model design, we have tried our best to disentangle our model, i.e. prohibiting our agent to update the embedding layer and use +1/-1 reward. If the agent is allowed to observe probabilistic reward as feedback, it will greedily maximize partial reward (say the first term of the sum of log-likelihood). The feedback from first answerer will dominate before the agent fully explores the search space. Hence the model is likely to collapse which leads to unstable training.\n\n[Proof]: Suppose the probability mass function (PMF) of reward is defined as \n$p_X(x) = p if x = +1 \n              = q if x = -1, p + q = 1.$\nThe expected reward is $E[x] = p + (1 - p)(-1) = 2p - 1$.\nThe variance is \n\t$Var[x] = \\Sigma (x - E[x])^2 \\times p(x) \n\t              = 4pq \n\t            <= 4 ((p + q) / 2)^2 \n\t              = 1$,\nwith equality if and only if $p = q = 0.5$. #\n\nQ4: What if two partitions need to share a word? The current setup necessitates that a word participates in only one partition. Wouldn\u2019t this be problematic?\nA4: No, we provide the following four explanations.\n(1) Maximum Information Utilization. The current setup forces the agent to fully explore the search space of partition strategies such that each word in the questions contributes to the confidence of downstream classifiers. Imagine a key word being misplaced, one classifier losses information and the other classifier receives extra noise, which harms information utilization significantly.\n\n(2) Performance and size of search space tradeoff. If we allow two partitions to share a word, the size of search space increases by a factor of 2^N (from 3^N to 6^N). N denotes the length of a question. It would be interesting to further investigate whether the generalized model is able to converge and produce better results or interpretability.\n\nQ5: I am a bit confused about how the simple question answering module is trained. Is it directly trained by the gold relation label?\nA5: Sorry for the confusion. Yes. It is fair to train simple question answerers by the gold relation label directly, compared to training three independent question classifier using the same supervision. We have updated our paper for clarification."}, "signatures": ["ICLR.cc/2019/Conference/Paper842/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper842/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper842/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Decompose Compound Questions with Reinforcement Learning", "abstract": "As for knowledge-based question answering, a fundamental problem is to relax the assumption of answerable questions from simple questions to compound questions. Traditional approaches firstly detect topic entity mentioned in questions, then traverse the knowledge graph to find relations as a multi-hop path to answers, while we propose a novel approach to leverage simple-question answerers to answer compound questions. Our model consists of two parts: (i) a novel learning-to-decompose agent that learns a policy to decompose a compound question into simple questions and (ii) three independent simple-question answerers that classify the corresponding relations for each simple question. Experiments demonstrate that our model learns complex rules of compositionality as stochastic policy, which benefits simple neural networks to achieve state-of-the-art results on WebQuestions and MetaQA. We analyze the interpretable decomposition process as well as generated partitions.", "keywords": ["Compound Question Decomposition", "Reinforcement Learning", "Knowledge-Based Question Answering", "Learning-to-decompose"], "authorids": ["capriceyhh@zju.edu.cn", "wanghanwh@zju.edu.cn", "guoshuang@zju.edu.cn", "lantau.zw@alibaba-inc.com", "huajunsir@zju.edu.cn"], "authors": ["Haihong Yang", "Han Wang", "Shuang Guo", "Wei Zhang", "Huajun Chen"], "TL;DR": "We propose a learning-to-decompose agent that helps simple-question answerers to answer compound question over knowledge graph.", "pdf": "/pdf/1c9f6ef4b3d02a397e1b8ee17c6f62b7917fe696.pdf", "paperhash": "yang|learning_to_decompose_compound_questions_with_reinforcement_learning", "_bibtex": "@misc{\nyang2019learning,\ntitle={Learning to Decompose Compound Questions with Reinforcement Learning},\nauthor={Haihong Yang and Han Wang and Shuang Guo and Wei Zhang and Huajun Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl2ps0qKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper842/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621606813, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJl2ps0qKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper842/Authors", "ICLR.cc/2019/Conference/Paper842/Reviewers", "ICLR.cc/2019/Conference/Paper842/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper842/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper842/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper842/Authors|ICLR.cc/2019/Conference/Paper842/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper842/Reviewers", "ICLR.cc/2019/Conference/Paper842/Authors", "ICLR.cc/2019/Conference/Paper842/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621606813}}}, {"id": "BJln2XG5AX", "original": null, "number": 5, "cdate": 1543279540220, "ddate": null, "tcdate": 1543279540220, "tmdate": 1543279622765, "tddate": null, "forum": "SJl2ps0qKQ", "replyto": "SJl2ps0qKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper842/Official_Comment", "content": {"title": "Dear reviewers, we thread a global comment for improvement on both our model and paper.", "comment": "## Main Improvement\n1. We have improved our model by replacing the answerer into three identical simple-question answerers with embedding layer shared. \n\n* Reasons\nDuring experiments, we observe that if we share the simple-question answerer across different partitions of a question, our agent may generate conflict assignments at the beginning of training process. Data conflicts undermine the decision boundary learned by the answerer (classifier). \n\n* An Example\n Considering a four-word question \"w1 w2 w3 w4?\", the agent generates two different labeling \"1st 1st 2nd 2nd\" and \"2nd 2nd 1st 1st\" in two different epoch. Since the answerer is shared, \n\n- the former mapping (f(\"w1 w2\") -> 1st_golden_relation) and\n- the latter mapping    (f(\"w1 w2\") -> 2nd_golden_relation) is conflicting. \n\n* Performance Improvement\n- On MetaQA, our model now outperforms state-of-the-art by ~8% overall accuracy, and\n- On WebQuestions, our model achieves competitive result to results that leverage knowledge base information by only using question information. \n- Details are described in section 4.2 of our paper.\n\n2. We have updated the following subsections.\n- Section 2.2 for detailed comparison of Iyyer et al., 2016 [1] and other works related to complex questions;\n- Section 2.3 for Deep Semantic Role Labeling and its relevance to our work;\n- Section 3.2 for describing our improved model architecture;\n- Section 3.3 for more training details;\n- Section 4.2 for benchmarking WebQuestions which is widely used in the KBQA community;\n- Section 4.3 for ablation study to conclude that there exists a tradeoff between model assumption and model performance.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper842/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper842/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper842/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Decompose Compound Questions with Reinforcement Learning", "abstract": "As for knowledge-based question answering, a fundamental problem is to relax the assumption of answerable questions from simple questions to compound questions. Traditional approaches firstly detect topic entity mentioned in questions, then traverse the knowledge graph to find relations as a multi-hop path to answers, while we propose a novel approach to leverage simple-question answerers to answer compound questions. Our model consists of two parts: (i) a novel learning-to-decompose agent that learns a policy to decompose a compound question into simple questions and (ii) three independent simple-question answerers that classify the corresponding relations for each simple question. Experiments demonstrate that our model learns complex rules of compositionality as stochastic policy, which benefits simple neural networks to achieve state-of-the-art results on WebQuestions and MetaQA. We analyze the interpretable decomposition process as well as generated partitions.", "keywords": ["Compound Question Decomposition", "Reinforcement Learning", "Knowledge-Based Question Answering", "Learning-to-decompose"], "authorids": ["capriceyhh@zju.edu.cn", "wanghanwh@zju.edu.cn", "guoshuang@zju.edu.cn", "lantau.zw@alibaba-inc.com", "huajunsir@zju.edu.cn"], "authors": ["Haihong Yang", "Han Wang", "Shuang Guo", "Wei Zhang", "Huajun Chen"], "TL;DR": "We propose a learning-to-decompose agent that helps simple-question answerers to answer compound question over knowledge graph.", "pdf": "/pdf/1c9f6ef4b3d02a397e1b8ee17c6f62b7917fe696.pdf", "paperhash": "yang|learning_to_decompose_compound_questions_with_reinforcement_learning", "_bibtex": "@misc{\nyang2019learning,\ntitle={Learning to Decompose Compound Questions with Reinforcement Learning},\nauthor={Haihong Yang and Han Wang and Shuang Guo and Wei Zhang and Huajun Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl2ps0qKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper842/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621606813, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJl2ps0qKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper842/Authors", "ICLR.cc/2019/Conference/Paper842/Reviewers", "ICLR.cc/2019/Conference/Paper842/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper842/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper842/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper842/Authors|ICLR.cc/2019/Conference/Paper842/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper842/Reviewers", "ICLR.cc/2019/Conference/Paper842/Authors", "ICLR.cc/2019/Conference/Paper842/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621606813}}}, {"id": "BJe28_qT27", "original": null, "number": 3, "cdate": 1541412947990, "ddate": null, "tcdate": 1541412947990, "tmdate": 1541533644208, "tddate": null, "forum": "SJl2ps0qKQ", "replyto": "SJl2ps0qKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper842/Official_Review", "content": {"title": "Good paper, but need more related work discussions", "review": "Summary: the paper is interested in parsing compound questions for querying on knowledge graph, e.g. MetaQA by Zhang et al. (2017). The paper proposes to have two modules, one that segments the question into partitions (up to three) and the other that looks at each segment to get the relation. The relations are merged to obtain a single KG path, which is queried to obtain the answer. Since the segmentation is a non-differentiable process, the paper uses reinforcement learning to propagate gradient to the segmentation model. The segmentation is a process of classifying each word for which partition it should be tied to. Answering is a process of classifying the partition into one of the possible relation edges. The model shows expected results in a synthetic arithmetic dataset, and obtains the state of the art in MetaQA, improving nearly 5% over the baseline. The model especially does much better on 3-hop questions, with nearly 20% improvement.\n\nStrengths: the paper is well-written. The model is simple yet effective and is a novel contribution to compound question answering on KG. Especially, the improvement on 3-hop category is nearly 20%, which is substantial and quite impressive. \n\nWeaknesses: My biggest concern is the lack of discussions on its relevance to  (Iyyer et al., 2016), which also proposed to decompose question into simpler ones for WIkiTableQuestions. Also, I think it would be good to mention Semantic Role Labeling as related literature, which is about tagging each word with its role in the sentence. The partition index can be somewhat considered as a \u201crole\u201d in the sentence.\n\nQuestions:\n1. How do you obtain x^(k)? Is it the last state of the LSTM?\n2. Why did you have to augment \u201cNO_OP\u201d relation in the MetaQA dataset?\n3. Why +1 reward has lower variance than probabilistic reward? Explanation or citation would be needed.\n4. What if two partitions need to share a word? The current setup necessitates that a word participates in only one partition. Wouldn\u2019t this be problematic?\n5. I am a bit confused about how the simple question answering module is trained. Is it directly trained by the gold relation label?\n\nTypos and Suggestions:\n- Second paragraph of 2.1: in stead -> instead\n- Third paragraph of 2.1: research. -> research\n- c_t + h_t: would be good to explicitly mention that the circled plus sign is concatenation.\n- Last paragraph on page 4: \u201cleave to be\u201d?\n- Second last paragraph of 4.1: he -> The\n- Second paragraph of 4.2: \u201cif exists a proper meaning\u201d?\n- First paragraph of page 7: be either assume -> either assume\n- Last paragraph of Section 5: generalizing -> generalize\n- I think you should not put acknowledgment in a double-blind submission.\n\nM Iyyer, W Yih, MW Chang. Answering complicated question intents expressed in decomposed question sequences. 2016 (https://arxiv.org/abs/1611.01242)\n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper842/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Decompose Compound Questions with Reinforcement Learning", "abstract": "As for knowledge-based question answering, a fundamental problem is to relax the assumption of answerable questions from simple questions to compound questions. Traditional approaches firstly detect topic entity mentioned in questions, then traverse the knowledge graph to find relations as a multi-hop path to answers, while we propose a novel approach to leverage simple-question answerers to answer compound questions. Our model consists of two parts: (i) a novel learning-to-decompose agent that learns a policy to decompose a compound question into simple questions and (ii) three independent simple-question answerers that classify the corresponding relations for each simple question. Experiments demonstrate that our model learns complex rules of compositionality as stochastic policy, which benefits simple neural networks to achieve state-of-the-art results on WebQuestions and MetaQA. We analyze the interpretable decomposition process as well as generated partitions.", "keywords": ["Compound Question Decomposition", "Reinforcement Learning", "Knowledge-Based Question Answering", "Learning-to-decompose"], "authorids": ["capriceyhh@zju.edu.cn", "wanghanwh@zju.edu.cn", "guoshuang@zju.edu.cn", "lantau.zw@alibaba-inc.com", "huajunsir@zju.edu.cn"], "authors": ["Haihong Yang", "Han Wang", "Shuang Guo", "Wei Zhang", "Huajun Chen"], "TL;DR": "We propose a learning-to-decompose agent that helps simple-question answerers to answer compound question over knowledge graph.", "pdf": "/pdf/1c9f6ef4b3d02a397e1b8ee17c6f62b7917fe696.pdf", "paperhash": "yang|learning_to_decompose_compound_questions_with_reinforcement_learning", "_bibtex": "@misc{\nyang2019learning,\ntitle={Learning to Decompose Compound Questions with Reinforcement Learning},\nauthor={Haihong Yang and Han Wang and Shuang Guo and Wei Zhang and Huajun Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl2ps0qKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper842/Official_Review", "cdate": 1542234364439, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJl2ps0qKQ", "replyto": "SJl2ps0qKQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper842/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335814888, "tmdate": 1552335814888, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper842/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "BJlhURN5nm", "original": null, "number": 2, "cdate": 1541193300114, "ddate": null, "tcdate": 1541193300114, "tmdate": 1541533644004, "tddate": null, "forum": "SJl2ps0qKQ", "replyto": "SJl2ps0qKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper842/Official_Review", "content": {"title": "Interesting idea. Lacking technical details and error analysis.", "review": "This paper proposes a knowledge-based QA system that learns to decompose compound questions into simple ones. The decomposition is modeled by assigning each token in the input question to one of the partitions and receiving reward signal based on the final gold answer. The model achieves the state-of-the-art performance on the MetaQA dataset. \n\nMy main complaint about the paper is its lack of technical details and analysis of empirical results. Parts of the paper seem quite unclear, for example:\n\nIn the last paragraph of Section 3.1, it says \u201cWe do not assume that nay question should be divided into exactly three parts. \u2026 See section 4 for case study.\u201d Does this mean that the model can have <=3 partitions, but not more? How is this number decided?\n\nSection 3.2 describes the simple-question answer. From Eq (4), it seems that the answerer only uses the current partition, is that the case? Moreover, how is the gold relation r obtained?\n\nIt would be nice to add more explanation to the caption of Figure 4 to make it self-contained.\n\nThe case study section (4.3) only contains a single example. It would be very helpful to include more examples of question partitions (there is enough space). Error analysis would also be helpful to understand, for example, why the proposed model is worse than VRN (Zhang et al. 2017) on 1- and 2-hop questions.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper842/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Decompose Compound Questions with Reinforcement Learning", "abstract": "As for knowledge-based question answering, a fundamental problem is to relax the assumption of answerable questions from simple questions to compound questions. Traditional approaches firstly detect topic entity mentioned in questions, then traverse the knowledge graph to find relations as a multi-hop path to answers, while we propose a novel approach to leverage simple-question answerers to answer compound questions. Our model consists of two parts: (i) a novel learning-to-decompose agent that learns a policy to decompose a compound question into simple questions and (ii) three independent simple-question answerers that classify the corresponding relations for each simple question. Experiments demonstrate that our model learns complex rules of compositionality as stochastic policy, which benefits simple neural networks to achieve state-of-the-art results on WebQuestions and MetaQA. We analyze the interpretable decomposition process as well as generated partitions.", "keywords": ["Compound Question Decomposition", "Reinforcement Learning", "Knowledge-Based Question Answering", "Learning-to-decompose"], "authorids": ["capriceyhh@zju.edu.cn", "wanghanwh@zju.edu.cn", "guoshuang@zju.edu.cn", "lantau.zw@alibaba-inc.com", "huajunsir@zju.edu.cn"], "authors": ["Haihong Yang", "Han Wang", "Shuang Guo", "Wei Zhang", "Huajun Chen"], "TL;DR": "We propose a learning-to-decompose agent that helps simple-question answerers to answer compound question over knowledge graph.", "pdf": "/pdf/1c9f6ef4b3d02a397e1b8ee17c6f62b7917fe696.pdf", "paperhash": "yang|learning_to_decompose_compound_questions_with_reinforcement_learning", "_bibtex": "@misc{\nyang2019learning,\ntitle={Learning to Decompose Compound Questions with Reinforcement Learning},\nauthor={Haihong Yang and Han Wang and Shuang Guo and Wei Zhang and Huajun Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl2ps0qKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper842/Official_Review", "cdate": 1542234364439, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJl2ps0qKQ", "replyto": "SJl2ps0qKQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper842/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335814888, "tmdate": 1552335814888, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper842/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "BJesG858hQ", "original": null, "number": 1, "cdate": 1540953618942, "ddate": null, "tcdate": 1540953618942, "tmdate": 1541533643800, "tddate": null, "forum": "SJl2ps0qKQ", "replyto": "SJl2ps0qKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper842/Official_Review", "content": {"title": "Lack of comparison with previous state-of-the-art methods over more widely used benchmarks", "review": "This paper proposes a new approach for answering questions requiring multi-hop reasoning. The key idea is to introduce a sequence labeler to divide the question into at most 3 parts, each part corresponds to a relation-tuple. The labeler is trained with the whole KB-QA pipeline with REINFORCE in an end-to-end way.\n\nThe proposed approach was applied to a synthetic dataset and a new KB-QA dataset MetaQA, and achieves good results.\n\nI like the proposed idea, which sounds a straightforward solution to compound question answering. I also like the clarification between \"compound questions\" instead of \"multi-hop questions\". In my opinion, \"multi-hop questions\" can also refer to the cases where the questions (can be simple questions) require multi-hop over evidence to answer.\n\nMy only concern is about the evaluation on MetaQA, which seems a not widely used dataset in our community. Therefore I am wondering whether the authors could address the following related questions in the rebuttal or revision:\n\n(1) I was surprised that WebQuestions is not used in the experiments. Could you explain the reason? My guess is that WebQuestions contains compound questions that cannot be simply decomposed as sequence labeling, because that some parts of the question can participant in different relations. If this is not true, could you provide results on WebQuestions (or WebQSP).\n\n(2) There were several previous methods proposed for decomposition of compound questions, although they are not proposed for KB-QA. Examples include \"Search-based Neural Structured Learning for Sequential Question Answering\" and \"ComplexWebQuestions\". I think the authors should compare their approach with previous work. One choice is to reimplement their methods. An easier option might be applying the proposed methods to some previous datasets, because the proposed method is not specific to KB-QA, as long as the simple question answerer is replaced to other components like a reader in the ComplexWebQuestions work.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper842/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Decompose Compound Questions with Reinforcement Learning", "abstract": "As for knowledge-based question answering, a fundamental problem is to relax the assumption of answerable questions from simple questions to compound questions. Traditional approaches firstly detect topic entity mentioned in questions, then traverse the knowledge graph to find relations as a multi-hop path to answers, while we propose a novel approach to leverage simple-question answerers to answer compound questions. Our model consists of two parts: (i) a novel learning-to-decompose agent that learns a policy to decompose a compound question into simple questions and (ii) three independent simple-question answerers that classify the corresponding relations for each simple question. Experiments demonstrate that our model learns complex rules of compositionality as stochastic policy, which benefits simple neural networks to achieve state-of-the-art results on WebQuestions and MetaQA. We analyze the interpretable decomposition process as well as generated partitions.", "keywords": ["Compound Question Decomposition", "Reinforcement Learning", "Knowledge-Based Question Answering", "Learning-to-decompose"], "authorids": ["capriceyhh@zju.edu.cn", "wanghanwh@zju.edu.cn", "guoshuang@zju.edu.cn", "lantau.zw@alibaba-inc.com", "huajunsir@zju.edu.cn"], "authors": ["Haihong Yang", "Han Wang", "Shuang Guo", "Wei Zhang", "Huajun Chen"], "TL;DR": "We propose a learning-to-decompose agent that helps simple-question answerers to answer compound question over knowledge graph.", "pdf": "/pdf/1c9f6ef4b3d02a397e1b8ee17c6f62b7917fe696.pdf", "paperhash": "yang|learning_to_decompose_compound_questions_with_reinforcement_learning", "_bibtex": "@misc{\nyang2019learning,\ntitle={Learning to Decompose Compound Questions with Reinforcement Learning},\nauthor={Haihong Yang and Han Wang and Shuang Guo and Wei Zhang and Huajun Chen},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl2ps0qKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper842/Official_Review", "cdate": 1542234364439, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJl2ps0qKQ", "replyto": "SJl2ps0qKQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper842/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335814888, "tmdate": 1552335814888, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper842/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 9}