{"notes": [{"id": "SJe0ELLKuE", "original": "Skx5J5X_uE", "number": 39, "cdate": 1553716790194, "ddate": null, "tcdate": 1553716790194, "tmdate": 1562083043735, "tddate": null, "forum": "SJe0ELLKuE", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Blind_Submission", "content": {"title": "Bias Correction of Learned Generative Models via Likelihood-free Importance Weighting", "authors": ["Aditya Grover", "Jiaming Song", "Ashish Kapoor", "Kenneth Tran", "Alekh Agarwal", "Eric Horvitz", "Stefano Ermon"], "authorids": ["adityag@cs.stanford.edu"], "keywords": [], "abstract": "A learned generative model often gives biased statistics relative to the underlying data distribution. A standard technique to correct this bias is by importance weighting samples from the model by the likelihood ratio under the model and true distributions. When the likelihood ratio is unknown, it can be estimated by training a probabilistic classifier to distinguish samples from the two distributions. In this paper, we employ this likelihood-free importance weighting framework to correct for the bias in using state-of-the-art deep generative models.We find that this technique consistently improves standard goodness-of-fit metrics for evaluating the sample quality of state-of-the-art generative models, suggesting reduced bias. Finally, we demonstrate its utility on representative applications in a) data augmentation for classification using generative adversarial networks, and b) model-based policy evaluation using off-policy data.", "pdf": "/pdf/a3d6955f6317c2a43f0d3f3eca710f5acefb70cb.pdf", "paperhash": "grover|bias_correction_of_learned_generative_models_via_likelihoodfree_importance_weighting"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Blind_Submission", "cdate": 1547567085825, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": [".*"]}, "writers": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1547567085825, "tmdate": 1555704438520, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"]}}, "tauthor": "OpenReview.net"}, {"id": "HklZvojr5E", "original": null, "number": 2, "cdate": 1555573593280, "ddate": null, "tcdate": 1555573593280, "tmdate": 1556906126475, "tddate": null, "forum": "SJe0ELLKuE", "replyto": "SJe0ELLKuE", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper39/Official_Review", "content": {"title": "Interesting paper, but the experiments could be improved", "review": "The paper proposes to use importance sampling to debias expectations computed using deep generative models. They demonstrate the usefulness of the idea on tasks such as goodness-of-fit testing, data augmentation and model-based off-policy evaluation. While the underlying ideas have been proposed earlier, I think the combination of ideas (estimating density ratio using a deep neural network and using that to debias deep generative models) is novel and interesting.\n\nMajor comments:\n\n- The papers by Azadi et al. 2018 and Turner et al. 2018 propose rejection sampling for GANs. Given the similarity between rejection sampling and importance sampling (the latter is a soft-weighted version of the former), I wish the authors had more prominently discussed the connections between their paper and these papers, and empirically compared to rejection sampling in some of their experiments. I also feel noise contrastive estimation deserves a more prominent discussion.\n\n- \u201cSynthetic experiment\u201d in page 5: how is the uncertainty computed?\n\n- Page 6: \u201censured that the classifiers used were well-calibrated\u201d how?\n\n- The experiments are not very compelling and could be improved. Table 2: Why is D_g + IW so poor?\n\n- Importance sampling is known to suffer from high variance. How do you address this?\n\nMinor comments:\n\n- Typo in page 5: \u201cparameteric\u201d", "rating": "3: Marginally above acceptance threshold", "confidence": "3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper39/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper39/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bias Correction of Learned Generative Models via Likelihood-free Importance Weighting", "authors": ["Aditya Grover", "Jiaming Song", "Ashish Kapoor", "Kenneth Tran", "Alekh Agarwal", "Eric Horvitz", "Stefano Ermon"], "authorids": ["adityag@cs.stanford.edu"], "keywords": [], "abstract": "A learned generative model often gives biased statistics relative to the underlying data distribution. A standard technique to correct this bias is by importance weighting samples from the model by the likelihood ratio under the model and true distributions. When the likelihood ratio is unknown, it can be estimated by training a probabilistic classifier to distinguish samples from the two distributions. In this paper, we employ this likelihood-free importance weighting framework to correct for the bias in using state-of-the-art deep generative models.We find that this technique consistently improves standard goodness-of-fit metrics for evaluating the sample quality of state-of-the-art generative models, suggesting reduced bias. Finally, we demonstrate its utility on representative applications in a) data augmentation for classification using generative adversarial networks, and b) model-based policy evaluation using off-policy data.", "pdf": "/pdf/a3d6955f6317c2a43f0d3f3eca710f5acefb70cb.pdf", "paperhash": "grover|bias_correction_of_learned_generative_models_via_likelihoodfree_importance_weighting"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper39/Official_Review", "cdate": 1554234172530, "reply": {"forum": "SJe0ELLKuE", "replyto": "SJe0ELLKuE", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper39/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper39/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1554234172530, "tmdate": 1556906091744, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper39/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}, {"id": "rklH0mE8KN", "original": null, "number": 1, "cdate": 1554559949262, "ddate": null, "tcdate": 1554559949262, "tmdate": 1556906126257, "tddate": null, "forum": "SJe0ELLKuE", "replyto": "SJe0ELLKuE", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper39/Official_Review", "content": {"title": "Good idea, good experiments", "review": "Pros:\n  * shows improvements in data augmentation, choosing samples from generative models, and model based policy elevation. \n  * well written.\n  * experiments in 3 domains, for evaluation, data augmentation and policy evaluation.\n\nCons:\n  * missing ablation experiments for what made the density ratio trick work: self normalization, architecture, etc.\n  * for policy evaluation, missing baseline with model free evaluation - by storing the log probs / policy that was used to obtain a particular trajectory, as standard in model free off policy learning.\n  * for the generative model evaluation experiments, the starting point is a pretrained classifier. Would be good to know what happens when a classifier is trained from scratch. \n  * lacking a bigger discussion for what happens when the two distributions lack common support. \n  \nMissing citations:\nAzadi S, Olsson C, Darrell T, Goodfellow I, Odena A. Discriminator rejection sampling. arXiv preprint arXiv:1810.06758. 2018 Oct 16.  - a discussion of using the discriminator in GANs \nRosca M, Lakshminarayanan B, Mohamed S. Distribution matching in variational inference. arXiv preprint arXiv:1802.06847. 2018 Feb 19. - experimental work showing the failure modes of the density ratio trick.", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper39/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper39/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bias Correction of Learned Generative Models via Likelihood-free Importance Weighting", "authors": ["Aditya Grover", "Jiaming Song", "Ashish Kapoor", "Kenneth Tran", "Alekh Agarwal", "Eric Horvitz", "Stefano Ermon"], "authorids": ["adityag@cs.stanford.edu"], "keywords": [], "abstract": "A learned generative model often gives biased statistics relative to the underlying data distribution. A standard technique to correct this bias is by importance weighting samples from the model by the likelihood ratio under the model and true distributions. When the likelihood ratio is unknown, it can be estimated by training a probabilistic classifier to distinguish samples from the two distributions. In this paper, we employ this likelihood-free importance weighting framework to correct for the bias in using state-of-the-art deep generative models.We find that this technique consistently improves standard goodness-of-fit metrics for evaluating the sample quality of state-of-the-art generative models, suggesting reduced bias. Finally, we demonstrate its utility on representative applications in a) data augmentation for classification using generative adversarial networks, and b) model-based policy evaluation using off-policy data.", "pdf": "/pdf/a3d6955f6317c2a43f0d3f3eca710f5acefb70cb.pdf", "paperhash": "grover|bias_correction_of_learned_generative_models_via_likelihoodfree_importance_weighting"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper39/Official_Review", "cdate": 1554234172530, "reply": {"forum": "SJe0ELLKuE", "replyto": "SJe0ELLKuE", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper39/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/DeepGenStruct/Paper39/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1554234172530, "tmdate": 1556906091744, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Paper39/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}, {"id": "HklF74dD5E", "original": null, "number": 1, "cdate": 1555690529347, "ddate": null, "tcdate": 1555690529347, "tmdate": 1556906126046, "tddate": null, "forum": "SJe0ELLKuE", "replyto": "SJe0ELLKuE", "invitation": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper39/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Bias Correction of Learned Generative Models via Likelihood-free Importance Weighting", "authors": ["Aditya Grover", "Jiaming Song", "Ashish Kapoor", "Kenneth Tran", "Alekh Agarwal", "Eric Horvitz", "Stefano Ermon"], "authorids": ["adityag@cs.stanford.edu"], "keywords": [], "abstract": "A learned generative model often gives biased statistics relative to the underlying data distribution. A standard technique to correct this bias is by importance weighting samples from the model by the likelihood ratio under the model and true distributions. When the likelihood ratio is unknown, it can be estimated by training a probabilistic classifier to distinguish samples from the two distributions. In this paper, we employ this likelihood-free importance weighting framework to correct for the bias in using state-of-the-art deep generative models.We find that this technique consistently improves standard goodness-of-fit metrics for evaluating the sample quality of state-of-the-art generative models, suggesting reduced bias. Finally, we demonstrate its utility on representative applications in a) data augmentation for classification using generative adversarial networks, and b) model-based policy evaluation using off-policy data.", "pdf": "/pdf/a3d6955f6317c2a43f0d3f3eca710f5acefb70cb.pdf", "paperhash": "grover|bias_correction_of_learned_generative_models_via_likelihoodfree_importance_weighting"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/DeepGenStruct/-/Paper39/Decision", "cdate": 1554814603607, "reply": {"forum": "SJe0ELLKuE", "replyto": "SJe0ELLKuE", "readers": [".*"], "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554814603607, "tmdate": 1556906101498, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "invitees": ["ICLR.cc/2019/Workshop/DeepGenStruct/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/DeepGenStruct"], "details": {"writable": true}}}}], "count": 4}