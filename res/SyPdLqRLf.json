{"notes": [{"tddate": null, "ddate": null, "original": null, "tmdate": 1521582941907, "tcdate": 1520270659109, "number": 1, "cdate": 1520270659109, "id": "S1iHTgidG", "invitation": "ICLR.cc/2018/Workshop/-/Paper84/Official_Review", "forum": "SyPdLqRLf", "replyto": "SyPdLqRLf", "signatures": ["ICLR.cc/2018/Workshop/Paper84/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper84/AnonReviewer2"], "content": {"title": "The notion of learnability in this paper is questionable", "rating": "4: Ok but not good enough - rejection", "review": "This paper proposes the measure of learnability and empirically evaluate it using various neural network architectures.\nHowever, I am not fully convinced with the notion of learnability.\nSince it checks whether or not the results of two trained models matches, it is more suitable to call it the \"stability\" of models.\nMoreover, the concept would be strongly related with bias and variance which are well studied in the context of statistical learning theory.\nHence the notion of learnability is not appropriate and I recommend to carefully discuss with the proposed measure and such existing measures.\n\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learnability Of Learned Neural Networks", "abstract": "This paper explores the simplicity of learned neural networks under various settings: learned on real vs random data, varying size/architecture and using large minibatch size vs small minibatch size. The notion of simplicity used here is that of learnability i.e., how accurately can the prediction function of a neural network be learned from labeled samples from it. While learnability is different from (in fact often higher than) test accuracy, the results herein suggest that there is a strong correlation between small generalization errors and high learnability. This work also shows that there exist significant qualitative differences in shallow networks as compared to popular deep networks. More broadly, this paper extends in a new direction, previous work on understanding the properties of learned neural networks.Our hope is that such an empirical study of understanding learned neural networks might shed light on the right assumptions that can be made for a theoretical study of deep learning.", "pdf": "/pdf/6833626f9d7e4af0894c627c40daecd55e5536ef.pdf", "TL;DR": "Towards understanding generalization through the lens of learnability", "paperhash": "sharma|learnability_of_learned_neural_networks", "_bibtex": "@misc{\nanand2018learnability,\ntitle={Learnability of Learned Neural Networks},\nauthor={Rahul Anand Sharma and Navin Goyal and Monojit Choudhury and Praneeth Netrapalli},\nyear={2018},\nurl={https://openreview.net/forum?id=rJ1RPJWAW},\n}", "keywords": ["Learnability", "Generalizability", "Generalization", "Understanding Deep Learning"], "authors": ["Rahul Anand Sharma", "Monojit Choudhury", "Navin Goyal and Praneeth Netrapalli"], "authorids": ["t-rahsha@microsoft.com", "monojitc@microsoft.com", "navingo@microsoft.com", "praneeth@microsoft.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582941707, "id": "ICLR.cc/2018/Workshop/-/Paper84/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper84/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper84/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper84/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper84/AnonReviewer1"], "reply": {"forum": "SyPdLqRLf", "replyto": "SyPdLqRLf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper84/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper84/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582941707}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582901933, "tcdate": 1520462523977, "number": 2, "cdate": 1520462523977, "id": "ByV6qyRuM", "invitation": "ICLR.cc/2018/Workshop/-/Paper84/Official_Review", "forum": "SyPdLqRLf", "replyto": "SyPdLqRLf", "signatures": ["ICLR.cc/2018/Workshop/Paper84/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper84/AnonReviewer3"], "content": {"title": "Empirical study on learnability", "rating": "5: Marginally below acceptance threshold", "review": "The authors of this paper reported their intensive experimental results on learnability when varying network complexity and using random data. This paper does not provide any theoretical justification of learnability, but their empirical results may interest some people. \n\nMinors:\n1. I could not understand this: \"structured prediction,on,\"\n2. The format of references should be consistent.\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learnability Of Learned Neural Networks", "abstract": "This paper explores the simplicity of learned neural networks under various settings: learned on real vs random data, varying size/architecture and using large minibatch size vs small minibatch size. The notion of simplicity used here is that of learnability i.e., how accurately can the prediction function of a neural network be learned from labeled samples from it. While learnability is different from (in fact often higher than) test accuracy, the results herein suggest that there is a strong correlation between small generalization errors and high learnability. This work also shows that there exist significant qualitative differences in shallow networks as compared to popular deep networks. More broadly, this paper extends in a new direction, previous work on understanding the properties of learned neural networks.Our hope is that such an empirical study of understanding learned neural networks might shed light on the right assumptions that can be made for a theoretical study of deep learning.", "pdf": "/pdf/6833626f9d7e4af0894c627c40daecd55e5536ef.pdf", "TL;DR": "Towards understanding generalization through the lens of learnability", "paperhash": "sharma|learnability_of_learned_neural_networks", "_bibtex": "@misc{\nanand2018learnability,\ntitle={Learnability of Learned Neural Networks},\nauthor={Rahul Anand Sharma and Navin Goyal and Monojit Choudhury and Praneeth Netrapalli},\nyear={2018},\nurl={https://openreview.net/forum?id=rJ1RPJWAW},\n}", "keywords": ["Learnability", "Generalizability", "Generalization", "Understanding Deep Learning"], "authors": ["Rahul Anand Sharma", "Monojit Choudhury", "Navin Goyal and Praneeth Netrapalli"], "authorids": ["t-rahsha@microsoft.com", "monojitc@microsoft.com", "navingo@microsoft.com", "praneeth@microsoft.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582941707, "id": "ICLR.cc/2018/Workshop/-/Paper84/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper84/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper84/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper84/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper84/AnonReviewer1"], "reply": {"forum": "SyPdLqRLf", "replyto": "SyPdLqRLf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper84/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper84/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582941707}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582751912, "tcdate": 1520652528931, "number": 3, "cdate": 1520652528931, "id": "H1_lZ0gtG", "invitation": "ICLR.cc/2018/Workshop/-/Paper84/Official_Review", "forum": "SyPdLqRLf", "replyto": "SyPdLqRLf", "signatures": ["ICLR.cc/2018/Workshop/Paper84/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper84/AnonReviewer1"], "content": {"title": "Interesting idea. Worthy to explore. ", "rating": "6: Marginally above acceptance threshold", "review": "The paper proposed a novel approach to explore what networks learn. The idea revolves around asking questions about a trained network for relearning the dataset. \n\nThe influence of depth and labeled data shows how to define a simple task for nn. Relating learnability to generalization on a theoretical footing for a simple 1nn would improve the merits of the approach.\n\nBased on the author rebuttal from conference review this work needs more attention. Worthy to explore as a part of the workshop. ", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learnability Of Learned Neural Networks", "abstract": "This paper explores the simplicity of learned neural networks under various settings: learned on real vs random data, varying size/architecture and using large minibatch size vs small minibatch size. The notion of simplicity used here is that of learnability i.e., how accurately can the prediction function of a neural network be learned from labeled samples from it. While learnability is different from (in fact often higher than) test accuracy, the results herein suggest that there is a strong correlation between small generalization errors and high learnability. This work also shows that there exist significant qualitative differences in shallow networks as compared to popular deep networks. More broadly, this paper extends in a new direction, previous work on understanding the properties of learned neural networks.Our hope is that such an empirical study of understanding learned neural networks might shed light on the right assumptions that can be made for a theoretical study of deep learning.", "pdf": "/pdf/6833626f9d7e4af0894c627c40daecd55e5536ef.pdf", "TL;DR": "Towards understanding generalization through the lens of learnability", "paperhash": "sharma|learnability_of_learned_neural_networks", "_bibtex": "@misc{\nanand2018learnability,\ntitle={Learnability of Learned Neural Networks},\nauthor={Rahul Anand Sharma and Navin Goyal and Monojit Choudhury and Praneeth Netrapalli},\nyear={2018},\nurl={https://openreview.net/forum?id=rJ1RPJWAW},\n}", "keywords": ["Learnability", "Generalizability", "Generalization", "Understanding Deep Learning"], "authors": ["Rahul Anand Sharma", "Monojit Choudhury", "Navin Goyal and Praneeth Netrapalli"], "authorids": ["t-rahsha@microsoft.com", "monojitc@microsoft.com", "navingo@microsoft.com", "praneeth@microsoft.com"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582941707, "id": "ICLR.cc/2018/Workshop/-/Paper84/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper84/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper84/AnonReviewer2", "ICLR.cc/2018/Workshop/Paper84/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper84/AnonReviewer1"], "reply": {"forum": "SyPdLqRLf", "replyto": "SyPdLqRLf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper84/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper84/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582941707}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573583794, "tcdate": 1521573583794, "number": 174, "cdate": 1521573583446, "id": "BkuRCRRKz", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "SyPdLqRLf", "replyto": "SyPdLqRLf", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Based on the reviews, this paper has not been accepted for presentation at the ICLR workshop. However, the conversation and updates can continue to appear here on OpenReview."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learnability Of Learned Neural Networks", "abstract": "This paper explores the simplicity of learned neural networks under various settings: learned on real vs random data, varying size/architecture and using large minibatch size vs small minibatch size. The notion of simplicity used here is that of learnability i.e., how accurately can the prediction function of a neural network be learned from labeled samples from it. While learnability is different from (in fact often higher than) test accuracy, the results herein suggest that there is a strong correlation between small generalization errors and high learnability. This work also shows that there exist significant qualitative differences in shallow networks as compared to popular deep networks. More broadly, this paper extends in a new direction, previous work on understanding the properties of learned neural networks.Our hope is that such an empirical study of understanding learned neural networks might shed light on the right assumptions that can be made for a theoretical study of deep learning.", "pdf": "/pdf/6833626f9d7e4af0894c627c40daecd55e5536ef.pdf", "TL;DR": "Towards understanding generalization through the lens of learnability", "paperhash": "sharma|learnability_of_learned_neural_networks", "_bibtex": "@misc{\nanand2018learnability,\ntitle={Learnability of Learned Neural Networks},\nauthor={Rahul Anand Sharma and Navin Goyal and Monojit Choudhury and Praneeth Netrapalli},\nyear={2018},\nurl={https://openreview.net/forum?id=rJ1RPJWAW},\n}", "keywords": ["Learnability", "Generalizability", "Generalization", "Understanding Deep Learning"], "authors": ["Rahul Anand Sharma", "Monojit Choudhury", "Navin Goyal and Praneeth Netrapalli"], "authorids": ["t-rahsha@microsoft.com", "monojitc@microsoft.com", "navingo@microsoft.com", "praneeth@microsoft.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1518730176081, "tcdate": 1518409326692, "number": 84, "cdate": 1518409326692, "id": "SyPdLqRLf", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "SyPdLqRLf", "original": "rJ1RPJWAW", "signatures": ["~Rahul_Anand_Sharma2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Learnability Of Learned Neural Networks", "abstract": "This paper explores the simplicity of learned neural networks under various settings: learned on real vs random data, varying size/architecture and using large minibatch size vs small minibatch size. The notion of simplicity used here is that of learnability i.e., how accurately can the prediction function of a neural network be learned from labeled samples from it. While learnability is different from (in fact often higher than) test accuracy, the results herein suggest that there is a strong correlation between small generalization errors and high learnability. This work also shows that there exist significant qualitative differences in shallow networks as compared to popular deep networks. More broadly, this paper extends in a new direction, previous work on understanding the properties of learned neural networks.Our hope is that such an empirical study of understanding learned neural networks might shed light on the right assumptions that can be made for a theoretical study of deep learning.", "pdf": "/pdf/6833626f9d7e4af0894c627c40daecd55e5536ef.pdf", "TL;DR": "Towards understanding generalization through the lens of learnability", "paperhash": "sharma|learnability_of_learned_neural_networks", "_bibtex": "@misc{\nanand2018learnability,\ntitle={Learnability of Learned Neural Networks},\nauthor={Rahul Anand Sharma and Navin Goyal and Monojit Choudhury and Praneeth Netrapalli},\nyear={2018},\nurl={https://openreview.net/forum?id=rJ1RPJWAW},\n}", "keywords": ["Learnability", "Generalizability", "Generalization", "Understanding Deep Learning"], "authors": ["Rahul Anand Sharma", "Monojit Choudhury", "Navin Goyal and Praneeth Netrapalli"], "authorids": ["t-rahsha@microsoft.com", "monojitc@microsoft.com", "navingo@microsoft.com", "praneeth@microsoft.com"]}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "original": {"tddate": null, "ddate": null, "tmdate": 1518730176081, "tcdate": 1509124038857, "number": 485, "cdate": 1518730176070, "id": "rJ1RPJWAW", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "rJ1RPJWAW", "original": "HJCpDJZC-", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "Learnability of Learned Neural Networks", "abstract": "This paper explores the simplicity of learned neural networks under various settings: learned on real vs random data, varying size/architecture and using large minibatch size vs small minibatch size. The notion of simplicity used here is that of learnability i.e., how accurately can the prediction function of a neural network be learned from labeled samples from it. While learnability is different from (in fact often higher than) test accuracy, the results herein suggest that there is a strong correlation between small generalization errors and high learnability.\nThis work also shows that there exist significant qualitative differences in shallow networks as compared to popular deep networks. More broadly, this paper extends in a new direction, previous work on understanding the properties of learned neural networks. Our hope is that such an empirical study of understanding learned neural networks might shed light on the right assumptions that can be made for a theoretical study of deep learning.", "pdf": "/pdf/08c7f0f93abaec729098d397e9d2ca9d63a64371.pdf", "TL;DR": "Exploring the Learnability of Learned Neural Networks", "paperhash": "sharma|learnability_of_learned_neural_networks", "_bibtex": "@misc{\nanand2018learnability,\ntitle={Learnability of Learned Neural Networks},\nauthor={Rahul Anand Sharma and Navin Goyal and Monojit Choudhury and Praneeth Netrapalli},\nyear={2018},\nurl={https://openreview.net/forum?id=rJ1RPJWAW},\n}", "keywords": ["Learnability", "Generalizability", "Understanding Deep Learning"], "authors": ["Rahul Anand Sharma", "Navin Goyal", "Monojit Choudhury", "Praneeth Netrapalli"], "authorids": ["t-rahsha@microsoft.com", "navingo@microsoft.com", "monojitc@microsoft.com", "praneeth@microsoft.com"]}, "nonreaders": []}, "originalWritable": false, "originalInvitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}, "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}], "count": 5}