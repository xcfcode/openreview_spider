{"notes": [{"id": "rJlMBjAcYX", "original": "B1lnJ_ActX", "number": 66, "cdate": 1538087737664, "ddate": null, "tcdate": 1538087737664, "tmdate": 1545355416668, "tddate": null, "forum": "rJlMBjAcYX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Optimizing for Generalization in Machine Learning with Cross-Validation Gradients", "abstract": "Cross-validation is the workhorse of modern applied statistics and machine learning, as it provides a principled framework for selecting the model that maximizes generalization performance. In this paper, we show that the cross-validation risk is differentiable with respect to the hyperparameters and training data for many common machine learning algorithms, including logistic regression, elastic-net regression, and support vector machines. Leveraging this property of differentiability, we propose a cross-validation gradient method (CVGM) for hyperparameter optimization. Our method enables efficient optimization in high-dimensional hyperparameter spaces of the cross-validation risk, the best surrogate of the true generalization ability of our learning algorithm.", "keywords": [], "authorids": ["sbarratt@stanford.edu", "rsh@stanford.edu"], "authors": ["Barratt", "Shane", "Sharma", "Rishi"], "pdf": "/pdf/1e5875aa94670102890369a0ee6874ac48b77ee2.pdf", "paperhash": "barratt|optimizing_for_generalization_in_machine_learning_with_crossvalidation_gradients", "_bibtex": "@misc{\nbarratt2019optimizing,\ntitle={Optimizing for Generalization in Machine Learning with Cross-Validation Gradients},\nauthor={Barratt and Shane and Sharma and Rishi},\nyear={2019},\nurl={https://openreview.net/forum?id=rJlMBjAcYX},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "H1gV32I2y4", "original": null, "number": 1, "cdate": 1544477868117, "ddate": null, "tcdate": 1544477868117, "tmdate": 1545354498233, "tddate": null, "forum": "rJlMBjAcYX", "replyto": "rJlMBjAcYX", "invitation": "ICLR.cc/2019/Conference/-/Paper66/Meta_Review", "content": {"metareview": "This paper gives explicit hyperparameter gradients for several models with convex losses.  The idea is well-motivated and clearly presented, but because it's relatively incremental, it needs a more systematic experimental section, or at least a stronger characterization of its scope and limitations.  I would also recommend an investigation of more expressive hyperparameterizations (like in Maclaurin et al 2015) and/or an investigation of overfitting on the validation set.", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Reject", "title": "Fine idea but incremental and limited experiments"}, "signatures": ["ICLR.cc/2019/Conference/Paper66/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper66/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimizing for Generalization in Machine Learning with Cross-Validation Gradients", "abstract": "Cross-validation is the workhorse of modern applied statistics and machine learning, as it provides a principled framework for selecting the model that maximizes generalization performance. In this paper, we show that the cross-validation risk is differentiable with respect to the hyperparameters and training data for many common machine learning algorithms, including logistic regression, elastic-net regression, and support vector machines. Leveraging this property of differentiability, we propose a cross-validation gradient method (CVGM) for hyperparameter optimization. Our method enables efficient optimization in high-dimensional hyperparameter spaces of the cross-validation risk, the best surrogate of the true generalization ability of our learning algorithm.", "keywords": [], "authorids": ["sbarratt@stanford.edu", "rsh@stanford.edu"], "authors": ["Barratt", "Shane", "Sharma", "Rishi"], "pdf": "/pdf/1e5875aa94670102890369a0ee6874ac48b77ee2.pdf", "paperhash": "barratt|optimizing_for_generalization_in_machine_learning_with_crossvalidation_gradients", "_bibtex": "@misc{\nbarratt2019optimizing,\ntitle={Optimizing for Generalization in Machine Learning with Cross-Validation Gradients},\nauthor={Barratt and Shane and Sharma and Rishi},\nyear={2019},\nurl={https://openreview.net/forum?id=rJlMBjAcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper66/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353350187, "tddate": null, "super": null, "final": null, "reply": {"forum": "rJlMBjAcYX", "replyto": "rJlMBjAcYX", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper66/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper66/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper66/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353350187}}}, {"id": "HkgzyGoV2Q", "original": null, "number": 3, "cdate": 1540825561668, "ddate": null, "tcdate": 1540825561668, "tmdate": 1541534315465, "tddate": null, "forum": "rJlMBjAcYX", "replyto": "rJlMBjAcYX", "invitation": "ICLR.cc/2019/Conference/-/Paper66/Official_Review", "content": {"title": "Interesting paper but with limited novelty and lacking convincing experiments", "review": "This paper proposes the so-called cross-validation gradient method (CVGM).\nThis is idea is to express the CV score as a differentiable function\nof the hyperparameters and then to update hyperparameters with gradient\ndescent. Derivations are provided with Logistic regression and Elastic-Net\nthanks to the sign splitting trick.\n\nOnce the problem is expressed as a QP, the work is mostly done\nby the qpth library that offers a differentiable layer for the QP solver.\n\nMajor points:\n\n- This idea has been around for quite some time but yes it is now certainly more\ntimely with the new DL tools such as pytorch. However the novelty is limited\nwhich means that numerical experiments should be quite extensive to\ndemonstrate a clear impact on the field. Unfortunately the experiments\nare very limited: data mostly simulated and very small. What is missing\nis a real evaluation of larger datasets and a demonstration that one can\noutperform the state of the art using CVGM. For example for the Elastic-Net\nit is unclear if CVGM is faster than glmnet that computes full grid search\nbut uses warm start so is very efficient.\n\n- Given a new dataset, how do you set step sizes? The purpose is to\nfind faster good hyperparameters than using Bayes Opt or random search\nbut if I need to fiddle with the choice of step size is it really worth it?\n\nMinor points:\n\nPlease proof read manuscript as there are a few typos.", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper66/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimizing for Generalization in Machine Learning with Cross-Validation Gradients", "abstract": "Cross-validation is the workhorse of modern applied statistics and machine learning, as it provides a principled framework for selecting the model that maximizes generalization performance. In this paper, we show that the cross-validation risk is differentiable with respect to the hyperparameters and training data for many common machine learning algorithms, including logistic regression, elastic-net regression, and support vector machines. Leveraging this property of differentiability, we propose a cross-validation gradient method (CVGM) for hyperparameter optimization. Our method enables efficient optimization in high-dimensional hyperparameter spaces of the cross-validation risk, the best surrogate of the true generalization ability of our learning algorithm.", "keywords": [], "authorids": ["sbarratt@stanford.edu", "rsh@stanford.edu"], "authors": ["Barratt", "Shane", "Sharma", "Rishi"], "pdf": "/pdf/1e5875aa94670102890369a0ee6874ac48b77ee2.pdf", "paperhash": "barratt|optimizing_for_generalization_in_machine_learning_with_crossvalidation_gradients", "_bibtex": "@misc{\nbarratt2019optimizing,\ntitle={Optimizing for Generalization in Machine Learning with Cross-Validation Gradients},\nauthor={Barratt and Shane and Sharma and Rishi},\nyear={2019},\nurl={https://openreview.net/forum?id=rJlMBjAcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper66/Official_Review", "cdate": 1542234545537, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rJlMBjAcYX", "replyto": "rJlMBjAcYX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper66/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335641515, "tmdate": 1552335641515, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper66/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HJeaamKV3Q", "original": null, "number": 2, "cdate": 1540817860734, "ddate": null, "tcdate": 1540817860734, "tmdate": 1541534315258, "tddate": null, "forum": "rJlMBjAcYX", "replyto": "rJlMBjAcYX", "invitation": "ICLR.cc/2019/Conference/-/Paper66/Official_Review", "content": {"title": "I think there is not enough novelty in this work to be considered for this conference.", "review": "The paper considers the problem of automatic tuning of hyperparameters in machine learning models. To address this problem the authors propose to use the so called cross-validation gradients, which optimize a validation objective with respect to the hyperparameters of a model. This approach and the investigated setting falls into a class of optimization problems known as bilevel optimization. The main characteristic of this class of optimization problems is the nested structure, with an outer and inner optimization objectives/problems. The outer problem corresponds to the validation objective and it is defined via an optimal solution to the inner problem which corresponds to a training objective. The paper, however, fails to make a reference to a rather rich literature on bilevel optimization (e.g., see [3-5] and references therein).\n\nThe approach, presented as Algorithm 1, does not seem different from [1] and [2] where hyperparameter optimization was considered for (kernel) support vector machines and (kernel) ridge regression. The data is initially split into k-folds (not necessarily of identical size) and each fold is used exactly once to define a validation objective whereas the complementary folds act as training data. The validation gradient is obtained by averaging the gradients of the k validation folds. Essentially, the same algorithm with k-fold cross-validation was considered in [1]. Thus, for me there does not seem to be any novelty in this approach and the paper itself.\n\nThe experiments involve synthetic regression and classification datasets but there are no novel insights that advance what is already known about the hyperparameter optimization (e.g., see [3]). For example, there is no intuition on the geometry of the optimization problem and the optimality of the outer optimization problem which is non-convex (e.g., see [7]), or dependence of the outer solution on the accuracy of the inner solution.\n\nReferences:\n\n[1] S. Keerthi, V. Sindhwani, and O. Chapelle. An Efficient Method for Gradient-Based Adaptation of Hyperparameters. NIPS 2007.\n[2] O. Chapelle, V. Vapnik, O. Bousquet, and S. Mukherjee. Choosing Multiple Parameters for Support Vector Machines. Machine Learning, 2002.\n\n[-3] L. Franceschi, P. Frasconi, S. Salzo, R. Grazzi, and M. Pontil. Bilevel Programming for Hyperparameter Optimization and Meta-Learning. ICML 2018.\n[-4] G. Kunapuli, K.P. Bennet, J. Hu, and J-S. Pang. Bilevel Model Selection for SVMs. American Mathematical Society, 2008.\n[-5] E.S.H. Neto and A.R. de Pierro. On Perturbed Steepest Descent Methods with Inexact Line Search for Bilevel Convex Optimization. Journal of Mathematical Programming and Operations Research, 2011.\n[-6] B. Colson, P. Marcotte, and G. Savard. A Trust-Region Method for Nonlinear Bilevel Programming: Algorithms and Computational Experience. Computational Optimization and Applications, 2005.\n[-7] M. Janzamin, H. Sedghi, and A. Anandkumar. Beating the Perils of Non-Convexity: Guaranteed Training of Neural Networks using Tensor Method. arXiv preprint arXiv:1506.08473v3, 2016.\n", "rating": "2: Strong rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper66/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimizing for Generalization in Machine Learning with Cross-Validation Gradients", "abstract": "Cross-validation is the workhorse of modern applied statistics and machine learning, as it provides a principled framework for selecting the model that maximizes generalization performance. In this paper, we show that the cross-validation risk is differentiable with respect to the hyperparameters and training data for many common machine learning algorithms, including logistic regression, elastic-net regression, and support vector machines. Leveraging this property of differentiability, we propose a cross-validation gradient method (CVGM) for hyperparameter optimization. Our method enables efficient optimization in high-dimensional hyperparameter spaces of the cross-validation risk, the best surrogate of the true generalization ability of our learning algorithm.", "keywords": [], "authorids": ["sbarratt@stanford.edu", "rsh@stanford.edu"], "authors": ["Barratt", "Shane", "Sharma", "Rishi"], "pdf": "/pdf/1e5875aa94670102890369a0ee6874ac48b77ee2.pdf", "paperhash": "barratt|optimizing_for_generalization_in_machine_learning_with_crossvalidation_gradients", "_bibtex": "@misc{\nbarratt2019optimizing,\ntitle={Optimizing for Generalization in Machine Learning with Cross-Validation Gradients},\nauthor={Barratt and Shane and Sharma and Rishi},\nyear={2019},\nurl={https://openreview.net/forum?id=rJlMBjAcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper66/Official_Review", "cdate": 1542234545537, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rJlMBjAcYX", "replyto": "rJlMBjAcYX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper66/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335641515, "tmdate": 1552335641515, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper66/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "Skl1tO4ZnX", "original": null, "number": 1, "cdate": 1540601974992, "ddate": null, "tcdate": 1540601974992, "tmdate": 1541534315018, "tddate": null, "forum": "rJlMBjAcYX", "replyto": "rJlMBjAcYX", "invitation": "ICLR.cc/2019/Conference/-/Paper66/Official_Review", "content": {"title": "Clearly written but incremental with respect to related work.", "review": "The paper proposes a method to optimize for the cross-validation performance of a model by expressing said performance as a differentiable function of the model parameters and applying a gradient-based method. \n\nThe majority of the work is clear and well-written, and appears to be correct, but I find it lacking in originality. The main contribution over related work  (references cited under the \"Implicit Differentiation\" heading in section 2.2) appears to be that the hyperparameters are optimized with respect to a cross-validation loss rather than a held out validation set. That is, using K=1 in the CVGM (Algorithm 1) reduces to existing work. There is also a discussion of when the cross-validation loss will be differentiable, but no new results on this. I am not sure that these contributions justify the paper. \n\nThe experiments are also not particularly strong. Only synthetic data is considered. The logistic regression baseline for the classification application in section 5.2 is irrelevant, and the neural network baseline could be clarified. Does the baseline also use the optimal parameters in the last layer throughout training? If not, how much of the improvement of the CVGM over the baseline is due to this change? \n\nTo say that the CVGM is able to stably learn the \u201chyperparameters\u201d of the network kernel in this setting seems like an exaggeration -- the neural network baseline also learns these \u201chyperparameters\u201d. The difference is that they are optimized with respect to the CV loss rather than the training loss. \n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper66/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimizing for Generalization in Machine Learning with Cross-Validation Gradients", "abstract": "Cross-validation is the workhorse of modern applied statistics and machine learning, as it provides a principled framework for selecting the model that maximizes generalization performance. In this paper, we show that the cross-validation risk is differentiable with respect to the hyperparameters and training data for many common machine learning algorithms, including logistic regression, elastic-net regression, and support vector machines. Leveraging this property of differentiability, we propose a cross-validation gradient method (CVGM) for hyperparameter optimization. Our method enables efficient optimization in high-dimensional hyperparameter spaces of the cross-validation risk, the best surrogate of the true generalization ability of our learning algorithm.", "keywords": [], "authorids": ["sbarratt@stanford.edu", "rsh@stanford.edu"], "authors": ["Barratt", "Shane", "Sharma", "Rishi"], "pdf": "/pdf/1e5875aa94670102890369a0ee6874ac48b77ee2.pdf", "paperhash": "barratt|optimizing_for_generalization_in_machine_learning_with_crossvalidation_gradients", "_bibtex": "@misc{\nbarratt2019optimizing,\ntitle={Optimizing for Generalization in Machine Learning with Cross-Validation Gradients},\nauthor={Barratt and Shane and Sharma and Rishi},\nyear={2019},\nurl={https://openreview.net/forum?id=rJlMBjAcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper66/Official_Review", "cdate": 1542234545537, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rJlMBjAcYX", "replyto": "rJlMBjAcYX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper66/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335641515, "tmdate": 1552335641515, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper66/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "r1xKLdD_9Q", "original": null, "number": 1, "cdate": 1538975825344, "ddate": null, "tcdate": 1538975825344, "tmdate": 1538975825344, "tddate": null, "forum": "rJlMBjAcYX", "replyto": "rJlMBjAcYX", "invitation": "ICLR.cc/2019/Conference/-/Paper66/Public_Comment", "content": {"comment": "Cross-validation risk is the best surrogate of the true generalization, which is for assessment instead of being optimized however. With a strengthened optimization, cross-validation no longer reflects the generalization. The authors need to be aware of this.", "title": "A comment"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper66/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Optimizing for Generalization in Machine Learning with Cross-Validation Gradients", "abstract": "Cross-validation is the workhorse of modern applied statistics and machine learning, as it provides a principled framework for selecting the model that maximizes generalization performance. In this paper, we show that the cross-validation risk is differentiable with respect to the hyperparameters and training data for many common machine learning algorithms, including logistic regression, elastic-net regression, and support vector machines. Leveraging this property of differentiability, we propose a cross-validation gradient method (CVGM) for hyperparameter optimization. Our method enables efficient optimization in high-dimensional hyperparameter spaces of the cross-validation risk, the best surrogate of the true generalization ability of our learning algorithm.", "keywords": [], "authorids": ["sbarratt@stanford.edu", "rsh@stanford.edu"], "authors": ["Barratt", "Shane", "Sharma", "Rishi"], "pdf": "/pdf/1e5875aa94670102890369a0ee6874ac48b77ee2.pdf", "paperhash": "barratt|optimizing_for_generalization_in_machine_learning_with_crossvalidation_gradients", "_bibtex": "@misc{\nbarratt2019optimizing,\ntitle={Optimizing for Generalization in Machine Learning with Cross-Validation Gradients},\nauthor={Barratt and Shane and Sharma and Rishi},\nyear={2019},\nurl={https://openreview.net/forum?id=rJlMBjAcYX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper66/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311926662, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "rJlMBjAcYX", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper66/Authors", "ICLR.cc/2019/Conference/Paper66/Reviewers", "ICLR.cc/2019/Conference/Paper66/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper66/Authors", "ICLR.cc/2019/Conference/Paper66/Reviewers", "ICLR.cc/2019/Conference/Paper66/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311926662}}}], "count": 6}