{"notes": [{"tddate": null, "ddate": null, "original": null, "tmdate": 1521573619232, "tcdate": 1521573619232, "number": 319, "cdate": 1521573618877, "id": "S1jxkyy9G", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "SJOOAEJwf", "replyto": "SJOOAEJwf", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "This paper was invited to the workshop track based on reviews at the main conference."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Decoding Decoders: Finding Optimal Representation Spaces for Unsupervised Similarity Tasks", "abstract": "Experimental evidence indicates that simple models outperform complex deep networks on many unsupervised similarity tasks. We provide a simple yet rigorous explanation for this behaviour by introducing the concept of an optimal representation space, in which semantically close symbols are mapped to representations that are close under a similarity measure induced by the model\u2019s objective function. In addition, we present a straightforward procedure that, without any retraining or architectural modifications, allows deep recurrent models to perform equally well (and sometimes better) when compared to shallow models. To validate our analysis, we conduct a set of consistent empirical evaluations and introduce several new sentence embedding models in the process. Even though this work is presented within the context of natural language processing, the insights are readily applicable to other domains that rely on distributed representations for transfer tasks.", "pdf": "/pdf/718bc72af2d1c70b3c812ff06f00c1192eeaa733.pdf", "TL;DR": "By introducing the notion of an optimal representation space, we provide a theoretical argument and experimental validation that an unsupervised model for sentences can perform well on both supervised similarity and unsupervised transfer tasks.", "paperhash": "zhelezniak|decoding_decoders_finding_optimal_representation_spaces_for_unsupervised_similarity_tasks", "_bibtex": "@misc{\nzhelezniak2018decoding,\ntitle={Decoding Decoders: Finding Optimal Representation Spaces for Unsupervised Similarity Tasks},\nauthor={Vitalii Zhelezniak, Dan Busbridge, April Shen, Samuel L. Smith, Nils Y. Hammerla},\nyear={2018},\nurl={https://openreview.net/forum?id=Byd-EfWCb},\n}", "keywords": ["distributed representations", "sentence embedding", "representation learning", "unsupervised learning", "encoder-decoder", "RNN"], "authors": ["Vitalii Zhelezniak", "Dan Busbridge", "April Shen", "Samuel L. Smith", "Nils Y. Hammerla"], "authorids": ["vitali.zhelezniak@babylonhealth.com", "dan.busbridge@babylonhealth.com", "april.shen@babylonhealth.com", "slsmith@google.com", "nils.hammerla@babylonhealth.com"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}, {"tddate": null, "ddate": null, "tmdate": 1518730164083, "tcdate": 1518452336718, "number": 148, "cdate": 1518452336718, "id": "SJOOAEJwf", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "SJOOAEJwf", "original": "Byd-EfWCb", "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Decoding Decoders: Finding Optimal Representation Spaces for Unsupervised Similarity Tasks", "abstract": "Experimental evidence indicates that simple models outperform complex deep networks on many unsupervised similarity tasks. We provide a simple yet rigorous explanation for this behaviour by introducing the concept of an optimal representation space, in which semantically close symbols are mapped to representations that are close under a similarity measure induced by the model\u2019s objective function. In addition, we present a straightforward procedure that, without any retraining or architectural modifications, allows deep recurrent models to perform equally well (and sometimes better) when compared to shallow models. To validate our analysis, we conduct a set of consistent empirical evaluations and introduce several new sentence embedding models in the process. Even though this work is presented within the context of natural language processing, the insights are readily applicable to other domains that rely on distributed representations for transfer tasks.", "pdf": "/pdf/718bc72af2d1c70b3c812ff06f00c1192eeaa733.pdf", "TL;DR": "By introducing the notion of an optimal representation space, we provide a theoretical argument and experimental validation that an unsupervised model for sentences can perform well on both supervised similarity and unsupervised transfer tasks.", "paperhash": "zhelezniak|decoding_decoders_finding_optimal_representation_spaces_for_unsupervised_similarity_tasks", "_bibtex": "@misc{\nzhelezniak2018decoding,\ntitle={Decoding Decoders: Finding Optimal Representation Spaces for Unsupervised Similarity Tasks},\nauthor={Vitalii Zhelezniak, Dan Busbridge, April Shen, Samuel L. Smith, Nils Y. Hammerla},\nyear={2018},\nurl={https://openreview.net/forum?id=Byd-EfWCb},\n}", "keywords": ["distributed representations", "sentence embedding", "representation learning", "unsupervised learning", "encoder-decoder", "RNN"], "authors": ["Vitalii Zhelezniak", "Dan Busbridge", "April Shen", "Samuel L. Smith", "Nils Y. Hammerla"], "authorids": ["vitali.zhelezniak@babylonhealth.com", "dan.busbridge@babylonhealth.com", "april.shen@babylonhealth.com", "slsmith@google.com", "nils.hammerla@babylonhealth.com"]}, "nonreaders": [], "details": {"replyCount": 1, "writable": false, "overwriting": [], "revisions": true, "tags": [], "original": {"tddate": null, "ddate": null, "tmdate": 1518730164083, "tcdate": 1509135359800, "number": 816, "cdate": 1518730164070, "id": "Byd-EfWCb", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "Byd-EfWCb", "original": "rJGWNMb0W", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "Decoding Decoders: Finding Optimal Representation Spaces for Unsupervised Similarity Tasks", "abstract": "Experimental evidence indicates that simple models outperform complex deep networks on many unsupervised similarity tasks. Introducing the concept of an optimal representation space, we provide a simple theoretical resolution to this apparent paradox. In addition, we present a straightforward procedure that, without any retraining or architectural modifications, allows deep recurrent models to perform equally well (and sometimes better) when compared to shallow models. To validate our analysis, we conduct a set of consistent empirical evaluations and introduce several new sentence embedding models in the process. Even though this work is presented within the context of natural language processing, the insights are readily applicable to other domains that rely on distributed representations for transfer tasks.", "pdf": "/pdf/b6463b36667c3b309055c09cd730e6eb944f54cb.pdf", "TL;DR": "By introducing the notion of an optimal representation space, we provide a theoretical argument and experimental validation that an unsupervised model for sentences can perform well on both supervised similarity and unsupervised transfer tasks.", "paperhash": "zhelezniak|decoding_decoders_finding_optimal_representation_spaces_for_unsupervised_similarity_tasks", "_bibtex": "@misc{\nzhelezniak2018decoding,\ntitle={Decoding Decoders: Finding Optimal Representation Spaces for Unsupervised Similarity Tasks},\nauthor={Vitalii Zhelezniak and Dan Busbridge and April Shen and Samuel L. Smith and Nils Y. Hammerla},\nyear={2018},\nurl={https://openreview.net/forum?id=Byd-EfWCb},\n}", "keywords": ["distributed representations", "sentence embedding", "representation learning", "unsupervised learning", "encoder-decoder", "RNN"], "authors": ["Vitalii Zhelezniak", "Dan Busbridge", "April Shen", "Samuel L. Smith", "Nils Y. Hammerla"], "authorids": ["vitali.zhelezniak@babylonhealth.com", "dan.busbridge@babylonhealth.com", "april.shen@babylonhealth.com", "slsmith@google.com", "nils.hammerla@babylonhealth.com"]}, "nonreaders": []}, "originalWritable": false, "originalInvitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}, "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}, "tauthor": "ICLR.cc/2018/Workshop"}], "count": 2}