{"notes": [{"id": "SyedHyBFwS", "original": "rJgULzpdvB", "number": 1697, "cdate": 1569439552058, "ddate": null, "tcdate": 1569439552058, "tmdate": 1577168278794, "tddate": null, "forum": "SyedHyBFwS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Relative Pixel Prediction For Autoregressive Image Generation", "authors": ["Wang Ling", "Chris Dyer", "Lei Yu", "Lingpeng Kong", "Dani Yogatama", "Susannah Young"], "authorids": ["lingwang@google.com", "cdyer@google.com", "leiyu@google.com", "lingpenk@google.com", "dyogatama@google.com", "susannahy@google.com"], "keywords": ["Image Generation", "Autoregressive"], "abstract": "In natural images, transitions between adjacent pixels tend to be smooth and gradual, a fact that has long been exploited in image compression models based on predictive coding. In contrast, existing neural autoregressive image generation models predict the absolute pixel intensities at each position, which is a more challenging problem. In this paper, we propose to predict pixels relatively, by predicting new pixels relative to previously generated pixels (or pixels from the conditioning context, when available). We show that this form of prediction fare favorably to its absolute counterpart when used independently, but their coordination under an unified probabilistic model yields optimal performance, as the model learns to predict sharp transitions using the absolute predictor, while generating smooth transitions using the relative predictor.\nExperiments on multiple benchmarks for unconditional image generation, image colorization, and super-resolution indicate that our presented mechanism leads to improvements in terms of likelihood compared to the absolute prediction counterparts. ", "pdf": "/pdf/3ea163163e2371ad13d13f296a926bc7f7bfbd43.pdf", "paperhash": "ling|relative_pixel_prediction_for_autoregressive_image_generation", "original_pdf": "/attachment/3ea163163e2371ad13d13f296a926bc7f7bfbd43.pdf", "_bibtex": "@misc{\nling2020relative,\ntitle={Relative Pixel Prediction For Autoregressive Image Generation},\nauthor={Wang Ling and Chris Dyer and Lei Yu and Lingpeng Kong and Dani Yogatama and Susannah Young},\nyear={2020},\nurl={https://openreview.net/forum?id=SyedHyBFwS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "sT8BSRAqgw", "original": null, "number": 1, "cdate": 1576798730127, "ddate": null, "tcdate": 1576798730127, "tmdate": 1576800906381, "tddate": null, "forum": "SyedHyBFwS", "replyto": "SyedHyBFwS", "invitation": "ICLR.cc/2020/Conference/Paper1697/-/Decision", "content": {"decision": "Reject", "comment": "All reviewers rated this submission as a weak reject and there was no author response.\nThe AC recommends rejection.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Relative Pixel Prediction For Autoregressive Image Generation", "authors": ["Wang Ling", "Chris Dyer", "Lei Yu", "Lingpeng Kong", "Dani Yogatama", "Susannah Young"], "authorids": ["lingwang@google.com", "cdyer@google.com", "leiyu@google.com", "lingpenk@google.com", "dyogatama@google.com", "susannahy@google.com"], "keywords": ["Image Generation", "Autoregressive"], "abstract": "In natural images, transitions between adjacent pixels tend to be smooth and gradual, a fact that has long been exploited in image compression models based on predictive coding. In contrast, existing neural autoregressive image generation models predict the absolute pixel intensities at each position, which is a more challenging problem. In this paper, we propose to predict pixels relatively, by predicting new pixels relative to previously generated pixels (or pixels from the conditioning context, when available). We show that this form of prediction fare favorably to its absolute counterpart when used independently, but their coordination under an unified probabilistic model yields optimal performance, as the model learns to predict sharp transitions using the absolute predictor, while generating smooth transitions using the relative predictor.\nExperiments on multiple benchmarks for unconditional image generation, image colorization, and super-resolution indicate that our presented mechanism leads to improvements in terms of likelihood compared to the absolute prediction counterparts. ", "pdf": "/pdf/3ea163163e2371ad13d13f296a926bc7f7bfbd43.pdf", "paperhash": "ling|relative_pixel_prediction_for_autoregressive_image_generation", "original_pdf": "/attachment/3ea163163e2371ad13d13f296a926bc7f7bfbd43.pdf", "_bibtex": "@misc{\nling2020relative,\ntitle={Relative Pixel Prediction For Autoregressive Image Generation},\nauthor={Wang Ling and Chris Dyer and Lei Yu and Lingpeng Kong and Dani Yogatama and Susannah Young},\nyear={2020},\nurl={https://openreview.net/forum?id=SyedHyBFwS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "SyedHyBFwS", "replyto": "SyedHyBFwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795726413, "tmdate": 1576800278539, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1697/-/Decision"}}}, {"id": "rJgWhRKyjH", "original": null, "number": 3, "cdate": 1572998824898, "ddate": null, "tcdate": 1572998824898, "tmdate": 1572998824898, "tddate": null, "forum": "SyedHyBFwS", "replyto": "SyedHyBFwS", "invitation": "ICLR.cc/2020/Conference/Paper1697/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #4", "review": "The paper bases its methodology on well known developments in image analysis/synthesis about similarity of pixel values in adjacent locations. Many techniques have been used for modelling this similarity, including predictive models, cliques and graphs. The paper uses a simple autoregressive model for generating pixel values based on the values of previously processed pixels, estimating the differences between these neighboring pixel values. \n\nThe method is implemented through copying the pixel values and adjusting the differences.  Three types of prediction, based on absolute, or relative values are examined, for image generation, colorization, super-resolution. The problems are significant, but the approach rather superficial. A small experimental study is presented, based on CIFAR-10 and downsampled ImageNet datsaets. Much more experiments, including quantitative and qualitative results are reuired, to validate the prospects of the method in different types of (complex) problems and contexts. Marginal improvements are observed in the presented results. Since image generation and image to image translation are targeted, comparison and/or combined use with Sota methods, i.e., GANs should be examined. \n\nMoreover, the paper presentation needs improvement; for example, symbols are undefined when used for the first time in the text (see eq. 3), etc.  \n\n   ", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1697/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1697/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Relative Pixel Prediction For Autoregressive Image Generation", "authors": ["Wang Ling", "Chris Dyer", "Lei Yu", "Lingpeng Kong", "Dani Yogatama", "Susannah Young"], "authorids": ["lingwang@google.com", "cdyer@google.com", "leiyu@google.com", "lingpenk@google.com", "dyogatama@google.com", "susannahy@google.com"], "keywords": ["Image Generation", "Autoregressive"], "abstract": "In natural images, transitions between adjacent pixels tend to be smooth and gradual, a fact that has long been exploited in image compression models based on predictive coding. In contrast, existing neural autoregressive image generation models predict the absolute pixel intensities at each position, which is a more challenging problem. In this paper, we propose to predict pixels relatively, by predicting new pixels relative to previously generated pixels (or pixels from the conditioning context, when available). We show that this form of prediction fare favorably to its absolute counterpart when used independently, but their coordination under an unified probabilistic model yields optimal performance, as the model learns to predict sharp transitions using the absolute predictor, while generating smooth transitions using the relative predictor.\nExperiments on multiple benchmarks for unconditional image generation, image colorization, and super-resolution indicate that our presented mechanism leads to improvements in terms of likelihood compared to the absolute prediction counterparts. ", "pdf": "/pdf/3ea163163e2371ad13d13f296a926bc7f7bfbd43.pdf", "paperhash": "ling|relative_pixel_prediction_for_autoregressive_image_generation", "original_pdf": "/attachment/3ea163163e2371ad13d13f296a926bc7f7bfbd43.pdf", "_bibtex": "@misc{\nling2020relative,\ntitle={Relative Pixel Prediction For Autoregressive Image Generation},\nauthor={Wang Ling and Chris Dyer and Lei Yu and Lingpeng Kong and Dani Yogatama and Susannah Young},\nyear={2020},\nurl={https://openreview.net/forum?id=SyedHyBFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SyedHyBFwS", "replyto": "SyedHyBFwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1697/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1697/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575216071703, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1697/Reviewers"], "noninvitees": [], "tcdate": 1570237733601, "tmdate": 1575216071715, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1697/-/Official_Review"}}}, {"id": "H1xVFeinYr", "original": null, "number": 1, "cdate": 1571758204468, "ddate": null, "tcdate": 1571758204468, "tmdate": 1572972434876, "tddate": null, "forum": "SyedHyBFwS", "replyto": "SyedHyBFwS", "invitation": "ICLR.cc/2020/Conference/Paper1697/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper proposes an approach for image generation that relies on an autoregressive model for the image pixels. These models are popularly used in image coding and compression settings, and have been used in generative models like PixelCNN. In contrast to this prior work, the proposed model is based on the selection of a previously available pixel and the modeling of the differences between the old pixel and the new one. The copy and adjustment models, i.e., eqs (3) and (5-6), are straightforward. Applications to image-to-image translation are also presented.\n\nI am rating the paper \"weak reject\" mostly due to the limited set of comparisons in experimental results. There is no qualitative comparison to other algorithms for two of the problems considered (colorization, super-resolution) and the comparison with other algorithms for unconditional image generation is limited to CIFAR-10; thus, the impact of this contribution is not clear. Furthermore there is no discussion of these comparison results - i.e., what the proposed algorithm contributes given that it's outperformed by the sparse transformer.\n\nIt is not clear at first what the authors mean by \"sub-pixel\", which appears to be one of the color/spectrum channels of a pixel of the image? Also not clear what \"outcome masking\" refers to. The explanation of the hidden states (g,h) used for each mechanism are not always clear or explicit. For example, can you write an equation for h_{i,c-1} which is more explicit than \"composing the history of generated sub-pixels\"? Can you define Ui when it is first used in (6)? What is the difference between the pixel state h_{r,C} and its values x_r?\n\nMinor comments\nThe second equation in Section 2.3 is missing =\nIn Section 5.1, it is not clear what is meant by \"discrediting\" the image.\nThe table in Fig. 3 could use full names for the problems instead of initials."}, "signatures": ["ICLR.cc/2020/Conference/Paper1697/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1697/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Relative Pixel Prediction For Autoregressive Image Generation", "authors": ["Wang Ling", "Chris Dyer", "Lei Yu", "Lingpeng Kong", "Dani Yogatama", "Susannah Young"], "authorids": ["lingwang@google.com", "cdyer@google.com", "leiyu@google.com", "lingpenk@google.com", "dyogatama@google.com", "susannahy@google.com"], "keywords": ["Image Generation", "Autoregressive"], "abstract": "In natural images, transitions between adjacent pixels tend to be smooth and gradual, a fact that has long been exploited in image compression models based on predictive coding. In contrast, existing neural autoregressive image generation models predict the absolute pixel intensities at each position, which is a more challenging problem. In this paper, we propose to predict pixels relatively, by predicting new pixels relative to previously generated pixels (or pixels from the conditioning context, when available). We show that this form of prediction fare favorably to its absolute counterpart when used independently, but their coordination under an unified probabilistic model yields optimal performance, as the model learns to predict sharp transitions using the absolute predictor, while generating smooth transitions using the relative predictor.\nExperiments on multiple benchmarks for unconditional image generation, image colorization, and super-resolution indicate that our presented mechanism leads to improvements in terms of likelihood compared to the absolute prediction counterparts. ", "pdf": "/pdf/3ea163163e2371ad13d13f296a926bc7f7bfbd43.pdf", "paperhash": "ling|relative_pixel_prediction_for_autoregressive_image_generation", "original_pdf": "/attachment/3ea163163e2371ad13d13f296a926bc7f7bfbd43.pdf", "_bibtex": "@misc{\nling2020relative,\ntitle={Relative Pixel Prediction For Autoregressive Image Generation},\nauthor={Wang Ling and Chris Dyer and Lei Yu and Lingpeng Kong and Dani Yogatama and Susannah Young},\nyear={2020},\nurl={https://openreview.net/forum?id=SyedHyBFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SyedHyBFwS", "replyto": "SyedHyBFwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1697/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1697/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575216071703, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1697/Reviewers"], "noninvitees": [], "tcdate": 1570237733601, "tmdate": 1575216071715, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1697/-/Official_Review"}}}, {"id": "SyxKniRnYS", "original": null, "number": 2, "cdate": 1571773361037, "ddate": null, "tcdate": 1571773361037, "tmdate": 1572972434832, "tddate": null, "forum": "SyedHyBFwS", "replyto": "SyedHyBFwS", "invitation": "ICLR.cc/2020/Conference/Paper1697/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "In this paper the authors present a new way to use autoregressive modeling to generate images pixel by pixel where each pixel is generated by modeling the difference between the current pixel value and  the preexistent ones. In order to achieve that, the authors propose a copy and adjustment mechanism that select an existing pixel, and then adjust its sub-pixel (channel values) to generate the new pixel. The proposed model is demonstrated with a suite of experiments in classic image generation benchmark. The authors also demonstrate the use of their technique in Image to Image translation.\nOverall, although the paper explain clearly the intuition and the motivation of the proposed technique, I think that the paper in its present state have low novelty, weak related work analysis review and insufficient experiments to support a publication at ICLR. \n\n\n\n**Novelty, contribution and related work**\nThe authors should highlight better their main contribution novelty of the proposed method compared to their baseline.\n\n\n**Result and conducted experiments**\nthe correctness of the proposed approach is not proved by the conducted experiment  in fact:\nThe experiments do not provide the details of the used architecture compared to your baseline. \nIn Table 1 you report the results using your technique on several computer vision tasks (generation, colorization and super-resolution) but you're not comparing with the SoA of each of these tasks.\nThe  results reported in Tables 1 and 2 are not convincing  when compared to existing approaches (using only CIFAR10 in Table2). \nThere are so many missing details specially to validate Image-To-image translation \nFigure 3 is confusing and  not clear  \n\n**Minor comments**\nIn  references section : (Kingma & Dhariwal, 2018) is not in a proper format (nips 2018)\nBad quality of illustrations and images \nBe coherent with the position of captions (figure 3)"}, "signatures": ["ICLR.cc/2020/Conference/Paper1697/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1697/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Relative Pixel Prediction For Autoregressive Image Generation", "authors": ["Wang Ling", "Chris Dyer", "Lei Yu", "Lingpeng Kong", "Dani Yogatama", "Susannah Young"], "authorids": ["lingwang@google.com", "cdyer@google.com", "leiyu@google.com", "lingpenk@google.com", "dyogatama@google.com", "susannahy@google.com"], "keywords": ["Image Generation", "Autoregressive"], "abstract": "In natural images, transitions between adjacent pixels tend to be smooth and gradual, a fact that has long been exploited in image compression models based on predictive coding. In contrast, existing neural autoregressive image generation models predict the absolute pixel intensities at each position, which is a more challenging problem. In this paper, we propose to predict pixels relatively, by predicting new pixels relative to previously generated pixels (or pixels from the conditioning context, when available). We show that this form of prediction fare favorably to its absolute counterpart when used independently, but their coordination under an unified probabilistic model yields optimal performance, as the model learns to predict sharp transitions using the absolute predictor, while generating smooth transitions using the relative predictor.\nExperiments on multiple benchmarks for unconditional image generation, image colorization, and super-resolution indicate that our presented mechanism leads to improvements in terms of likelihood compared to the absolute prediction counterparts. ", "pdf": "/pdf/3ea163163e2371ad13d13f296a926bc7f7bfbd43.pdf", "paperhash": "ling|relative_pixel_prediction_for_autoregressive_image_generation", "original_pdf": "/attachment/3ea163163e2371ad13d13f296a926bc7f7bfbd43.pdf", "_bibtex": "@misc{\nling2020relative,\ntitle={Relative Pixel Prediction For Autoregressive Image Generation},\nauthor={Wang Ling and Chris Dyer and Lei Yu and Lingpeng Kong and Dani Yogatama and Susannah Young},\nyear={2020},\nurl={https://openreview.net/forum?id=SyedHyBFwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SyedHyBFwS", "replyto": "SyedHyBFwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1697/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1697/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575216071703, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1697/Reviewers"], "noninvitees": [], "tcdate": 1570237733601, "tmdate": 1575216071715, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1697/-/Official_Review"}}}], "count": 5}