{"notes": [{"id": "rJVoEiCqKQ", "original": "rken9UgutQ", "number": 32, "cdate": 1538087731328, "ddate": null, "tcdate": 1538087731328, "tmdate": 1545355426401, "tddate": null, "forum": "rJVoEiCqKQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks", "abstract": "Many real-world problems, e.g. object detection, have outputs that are naturally expressed as sets of entities. This creates a challenge for traditional deep neural networks which naturally deal with structured outputs such as vectors, matrices or tensors. We present a novel approach for learning to predict sets with unknown permutation and cardinality using deep neural networks. Specifically, in our formulation we incorporate the permutation as unobservable variable and estimate its distribution during the learning process using alternating optimization. We demonstrate the validity of this new formulation on two relevant vision problems: object detection, for which our formulation outperforms state-of-the-art detectors such as Faster R-CNN and YOLO, and a complex CAPTCHA test, where we observe that, surprisingly, our set based network acquired the ability of mimicking arithmetics without any rules being coded.", "paperhash": "rezatofighi|deep_permset_net_learn_to_predict_sets_with_unknown_permutation_and_cardinality_using_deep_neural_networks", "keywords": ["Set learning", "Permutation invariant", "Object detection", "CAPTCHA test"], "authorids": ["hamid.rezatofighi@adelaide.edu.au", "roman.kaskman@tum.de", "farbod.motlagh@student.adelaide.edu.au", "javen.shi@adelaide.edu.au", "cremers@tum.de", "leal.taixe@tum.de", "ian.reid@adelaide.edu.au"], "authors": ["S. Hamid Rezatofighi", "Roman Kaskman", "Farbod T. Motlagh", "Qinfeng Shi", "Daniel Cremers", "Laura Leal-Taix\u00e9", "Ian Reid"], "TL;DR": "We present a novel approach for learning to predict sets with unknown permutation and cardinality using feed-forward deep neural networks.", "pdf": "/pdf/1a3f4c416c02f44141e22fb24062203ccd658b06.pdf", "_bibtex": "@misc{\nrezatofighi2019deep,\ntitle={Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks},\nauthor={S. Hamid Rezatofighi and Roman Kaskman and Farbod T. Motlagh and Qinfeng Shi and Daniel Cremers and Laura Leal-Taix\u00e9 and Ian Reid},\nyear={2019},\nurl={https://openreview.net/forum?id=rJVoEiCqKQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 11, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "SkgTh_R7gN", "original": null, "number": 1, "cdate": 1544968372582, "ddate": null, "tcdate": 1544968372582, "tmdate": 1545354489494, "tddate": null, "forum": "rJVoEiCqKQ", "replyto": "rJVoEiCqKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper32/Meta_Review", "content": {"metareview": "Strengths:\nThe method extends [21], which proposes an unordered set prediction model for multi-class classification.\nThe submission proposes a formulation to learn the distribution over unobservable permutation variables based on deep networks and uses a MAP  estimator for inference.\nWhile the failure of NMS to detect overlapping objects is expected, the experiments showing that perm-set prediction handles them well is interesting and promising. \n\nWeaknesses:\n\nReviewer 1: \"I find the paper still too scattered, trying to solve diverse problems with a hammer without properly motivating / analyzing key details of this hammer. So I keep my rating.\"\nReviewer 2: \"I'm glad that the authors are seeing good performance and seem to have an effective method for matching outputs to fixed predictions, however the quality of the paper is too poor for publication.\"\n\nPoints of contention:\n\n Although there was one reviewer who gave a high rating, they were not responsive in the rebuttal phase.  The other two reviewers took into account the author responses, and a contributed comment by an unaffiliated reviewer, and both concluded that the paper still had serious issues.  The main issues were: lack of clear methodology and poor clarity (AnonReviewer2), and poor organization and lack of motivation for modeling choices (AnonReviewer1).", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "Area chair recommendation"}, "signatures": ["ICLR.cc/2019/Conference/Paper32/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper32/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks", "abstract": "Many real-world problems, e.g. object detection, have outputs that are naturally expressed as sets of entities. This creates a challenge for traditional deep neural networks which naturally deal with structured outputs such as vectors, matrices or tensors. We present a novel approach for learning to predict sets with unknown permutation and cardinality using deep neural networks. Specifically, in our formulation we incorporate the permutation as unobservable variable and estimate its distribution during the learning process using alternating optimization. We demonstrate the validity of this new formulation on two relevant vision problems: object detection, for which our formulation outperforms state-of-the-art detectors such as Faster R-CNN and YOLO, and a complex CAPTCHA test, where we observe that, surprisingly, our set based network acquired the ability of mimicking arithmetics without any rules being coded.", "paperhash": "rezatofighi|deep_permset_net_learn_to_predict_sets_with_unknown_permutation_and_cardinality_using_deep_neural_networks", "keywords": ["Set learning", "Permutation invariant", "Object detection", "CAPTCHA test"], "authorids": ["hamid.rezatofighi@adelaide.edu.au", "roman.kaskman@tum.de", "farbod.motlagh@student.adelaide.edu.au", "javen.shi@adelaide.edu.au", "cremers@tum.de", "leal.taixe@tum.de", "ian.reid@adelaide.edu.au"], "authors": ["S. Hamid Rezatofighi", "Roman Kaskman", "Farbod T. Motlagh", "Qinfeng Shi", "Daniel Cremers", "Laura Leal-Taix\u00e9", "Ian Reid"], "TL;DR": "We present a novel approach for learning to predict sets with unknown permutation and cardinality using feed-forward deep neural networks.", "pdf": "/pdf/1a3f4c416c02f44141e22fb24062203ccd658b06.pdf", "_bibtex": "@misc{\nrezatofighi2019deep,\ntitle={Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks},\nauthor={S. Hamid Rezatofighi and Roman Kaskman and Farbod T. Motlagh and Qinfeng Shi and Daniel Cremers and Laura Leal-Taix\u00e9 and Ian Reid},\nyear={2019},\nurl={https://openreview.net/forum?id=rJVoEiCqKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper32/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353362075, "tddate": null, "super": null, "final": null, "reply": {"forum": "rJVoEiCqKQ", "replyto": "rJVoEiCqKQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper32/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper32/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper32/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353362075}}}, {"id": "rkg0ogbkkE", "original": null, "number": 9, "cdate": 1543602341747, "ddate": null, "tcdate": 1543602341747, "tmdate": 1543602341747, "tddate": null, "forum": "rJVoEiCqKQ", "replyto": "rkxaglcwTm", "invitation": "ICLR.cc/2019/Conference/-/Paper32/Official_Comment", "content": {"title": "Poor Clarity", "comment": "Misunderstandings are due to poor clarity in the text as written.\n\n\"... (we) assume p_m(\\pi | x_i, w) is uniform,\" this is very unclear in the text.\n\nI also appreciate that one may want to make use of a permutation to match outputs to fixed predictions. However, I again invite the authors to stare at what they have written (eq. 6): p(y_\\sigma | x_i, w, \u03c0). Note that the model does not have access (it is not conditioned on) to the indices \\sigma, it is completely exchangeable. As I explained, this boils down to a mixture model. Now, what it sounds like the authors wanted to write (to match things up) is:  p(y_\\sigma | x_i, w, \u03c0, \\sigma). It's a small change that makes a big difference, and illustrates the sort of clarity issues that abound the paper.\n\n(There is also something to be said that a sequential auto-regressive methods can already keep track of what has been seen, and doesn't require any matching of permutations. This was my point about having a truly orderless model, that does not need order matching, or just having a sequential method.)\n\nI'm glad that the authors are seeing good performance and seem to have an effective method for matching outputs to fixed predictions, however the quality of the paper is too poor for publication."}, "signatures": ["ICLR.cc/2019/Conference/Paper32/AnonReviewer2"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper32/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper32/AnonReviewer2", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks", "abstract": "Many real-world problems, e.g. object detection, have outputs that are naturally expressed as sets of entities. This creates a challenge for traditional deep neural networks which naturally deal with structured outputs such as vectors, matrices or tensors. We present a novel approach for learning to predict sets with unknown permutation and cardinality using deep neural networks. Specifically, in our formulation we incorporate the permutation as unobservable variable and estimate its distribution during the learning process using alternating optimization. We demonstrate the validity of this new formulation on two relevant vision problems: object detection, for which our formulation outperforms state-of-the-art detectors such as Faster R-CNN and YOLO, and a complex CAPTCHA test, where we observe that, surprisingly, our set based network acquired the ability of mimicking arithmetics without any rules being coded.", "paperhash": "rezatofighi|deep_permset_net_learn_to_predict_sets_with_unknown_permutation_and_cardinality_using_deep_neural_networks", "keywords": ["Set learning", "Permutation invariant", "Object detection", "CAPTCHA test"], "authorids": ["hamid.rezatofighi@adelaide.edu.au", "roman.kaskman@tum.de", "farbod.motlagh@student.adelaide.edu.au", "javen.shi@adelaide.edu.au", "cremers@tum.de", "leal.taixe@tum.de", "ian.reid@adelaide.edu.au"], "authors": ["S. Hamid Rezatofighi", "Roman Kaskman", "Farbod T. Motlagh", "Qinfeng Shi", "Daniel Cremers", "Laura Leal-Taix\u00e9", "Ian Reid"], "TL;DR": "We present a novel approach for learning to predict sets with unknown permutation and cardinality using feed-forward deep neural networks.", "pdf": "/pdf/1a3f4c416c02f44141e22fb24062203ccd658b06.pdf", "_bibtex": "@misc{\nrezatofighi2019deep,\ntitle={Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks},\nauthor={S. Hamid Rezatofighi and Roman Kaskman and Farbod T. Motlagh and Qinfeng Shi and Daniel Cremers and Laura Leal-Taix\u00e9 and Ian Reid},\nyear={2019},\nurl={https://openreview.net/forum?id=rJVoEiCqKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper32/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621875, "tddate": null, "super": null, "final": null, "reply": {"forum": "rJVoEiCqKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper32/Authors", "ICLR.cc/2019/Conference/Paper32/Reviewers", "ICLR.cc/2019/Conference/Paper32/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper32/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper32/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper32/Authors|ICLR.cc/2019/Conference/Paper32/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper32/Reviewers", "ICLR.cc/2019/Conference/Paper32/Authors", "ICLR.cc/2019/Conference/Paper32/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621875}}}, {"id": "BklHs9ycRX", "original": null, "number": 8, "cdate": 1543269021300, "ddate": null, "tcdate": 1543269021300, "tmdate": 1543269081937, "tddate": null, "forum": "rJVoEiCqKQ", "replyto": "SkxrcuFw6m", "invitation": "ICLR.cc/2019/Conference/-/Paper32/Official_Comment", "content": {"title": "keeping my rating, despite helpful clarifications", "comment": "Thank you for clarifying details I asked about. Specifically, U^m, p(w|D) in Eq 2 and the network architecture. On the latter please note that it's not obvious whether you add any extra FC layers between ResNet and your outputs. ResNet typically does not have these Dense layers (excluding the softmax) yet they are shown in Fig1. What are their sizes? \n\nI find the paper still too scattered, trying to solve diverse problems with a hammer without properly motivating / analyzing key details of this hammer. So I keep my rating. \n\nSignificance of the permutation head (the main technical contribution, really). Ablation would illuminate the impact of the modeling choices made in this paper: \n-- You point to a comparison to [21] in the appendix, however [21] seems completely permutation-unaware so it understandably fails. I was expecting a comparison with  hungarian matching for the detection case -- what happens if you completely omit f2 in Eq5.  You suggest this yourself in your feedback -- why is there no experimental ablation of this key detail? Additionally, what happens if vanilla Hungarian matching is done using simply a box overlap metric in Eq 5 -- this is essentially what anchor boxes do, and can be a standard baseline. \n-- If we have Hungarian matching working, we can completely remove the permutation head from the detection network and have something that trains potentially fine? How well does this work? \n-- What is exactly the effect of having the weight w~tilde from Eq 3 estimated from past SGD iteration frequency. What if I omit it or what if I use the posterior of head O2? \n\nIt is true that doing set prediction goes beyond the detection example -- as illustrated in the two toy examples -- there are cases indeed where the permutation head can be directly useful as output, but those do remain toy examples (one of them is entirely in the appendix so it carries limited weight). "}, "signatures": ["ICLR.cc/2019/Conference/Paper32/AnonReviewer1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper32/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper32/AnonReviewer1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks", "abstract": "Many real-world problems, e.g. object detection, have outputs that are naturally expressed as sets of entities. This creates a challenge for traditional deep neural networks which naturally deal with structured outputs such as vectors, matrices or tensors. We present a novel approach for learning to predict sets with unknown permutation and cardinality using deep neural networks. Specifically, in our formulation we incorporate the permutation as unobservable variable and estimate its distribution during the learning process using alternating optimization. We demonstrate the validity of this new formulation on two relevant vision problems: object detection, for which our formulation outperforms state-of-the-art detectors such as Faster R-CNN and YOLO, and a complex CAPTCHA test, where we observe that, surprisingly, our set based network acquired the ability of mimicking arithmetics without any rules being coded.", "paperhash": "rezatofighi|deep_permset_net_learn_to_predict_sets_with_unknown_permutation_and_cardinality_using_deep_neural_networks", "keywords": ["Set learning", "Permutation invariant", "Object detection", "CAPTCHA test"], "authorids": ["hamid.rezatofighi@adelaide.edu.au", "roman.kaskman@tum.de", "farbod.motlagh@student.adelaide.edu.au", "javen.shi@adelaide.edu.au", "cremers@tum.de", "leal.taixe@tum.de", "ian.reid@adelaide.edu.au"], "authors": ["S. Hamid Rezatofighi", "Roman Kaskman", "Farbod T. Motlagh", "Qinfeng Shi", "Daniel Cremers", "Laura Leal-Taix\u00e9", "Ian Reid"], "TL;DR": "We present a novel approach for learning to predict sets with unknown permutation and cardinality using feed-forward deep neural networks.", "pdf": "/pdf/1a3f4c416c02f44141e22fb24062203ccd658b06.pdf", "_bibtex": "@misc{\nrezatofighi2019deep,\ntitle={Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks},\nauthor={S. Hamid Rezatofighi and Roman Kaskman and Farbod T. Motlagh and Qinfeng Shi and Daniel Cremers and Laura Leal-Taix\u00e9 and Ian Reid},\nyear={2019},\nurl={https://openreview.net/forum?id=rJVoEiCqKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper32/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621875, "tddate": null, "super": null, "final": null, "reply": {"forum": "rJVoEiCqKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper32/Authors", "ICLR.cc/2019/Conference/Paper32/Reviewers", "ICLR.cc/2019/Conference/Paper32/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper32/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper32/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper32/Authors|ICLR.cc/2019/Conference/Paper32/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper32/Reviewers", "ICLR.cc/2019/Conference/Paper32/Authors", "ICLR.cc/2019/Conference/Paper32/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621875}}}, {"id": "ryl0dgqwam", "original": null, "number": 4, "cdate": 1542066293597, "ddate": null, "tcdate": 1542066293597, "tmdate": 1542066293597, "tddate": null, "forum": "rJVoEiCqKQ", "replyto": "H1eoH7T167", "invitation": "ICLR.cc/2019/Conference/-/Paper32/Official_Comment", "content": {"title": "Thank you ", "comment": "We appreciate your clarification. "}, "signatures": ["ICLR.cc/2019/Conference/Paper32/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper32/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper32/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks", "abstract": "Many real-world problems, e.g. object detection, have outputs that are naturally expressed as sets of entities. This creates a challenge for traditional deep neural networks which naturally deal with structured outputs such as vectors, matrices or tensors. We present a novel approach for learning to predict sets with unknown permutation and cardinality using deep neural networks. Specifically, in our formulation we incorporate the permutation as unobservable variable and estimate its distribution during the learning process using alternating optimization. We demonstrate the validity of this new formulation on two relevant vision problems: object detection, for which our formulation outperforms state-of-the-art detectors such as Faster R-CNN and YOLO, and a complex CAPTCHA test, where we observe that, surprisingly, our set based network acquired the ability of mimicking arithmetics without any rules being coded.", "paperhash": "rezatofighi|deep_permset_net_learn_to_predict_sets_with_unknown_permutation_and_cardinality_using_deep_neural_networks", "keywords": ["Set learning", "Permutation invariant", "Object detection", "CAPTCHA test"], "authorids": ["hamid.rezatofighi@adelaide.edu.au", "roman.kaskman@tum.de", "farbod.motlagh@student.adelaide.edu.au", "javen.shi@adelaide.edu.au", "cremers@tum.de", "leal.taixe@tum.de", "ian.reid@adelaide.edu.au"], "authors": ["S. Hamid Rezatofighi", "Roman Kaskman", "Farbod T. Motlagh", "Qinfeng Shi", "Daniel Cremers", "Laura Leal-Taix\u00e9", "Ian Reid"], "TL;DR": "We present a novel approach for learning to predict sets with unknown permutation and cardinality using feed-forward deep neural networks.", "pdf": "/pdf/1a3f4c416c02f44141e22fb24062203ccd658b06.pdf", "_bibtex": "@misc{\nrezatofighi2019deep,\ntitle={Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks},\nauthor={S. Hamid Rezatofighi and Roman Kaskman and Farbod T. Motlagh and Qinfeng Shi and Daniel Cremers and Laura Leal-Taix\u00e9 and Ian Reid},\nyear={2019},\nurl={https://openreview.net/forum?id=rJVoEiCqKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper32/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621875, "tddate": null, "super": null, "final": null, "reply": {"forum": "rJVoEiCqKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper32/Authors", "ICLR.cc/2019/Conference/Paper32/Reviewers", "ICLR.cc/2019/Conference/Paper32/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper32/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper32/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper32/Authors|ICLR.cc/2019/Conference/Paper32/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper32/Reviewers", "ICLR.cc/2019/Conference/Paper32/Authors", "ICLR.cc/2019/Conference/Paper32/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621875}}}, {"id": "rkxaglcwTm", "original": null, "number": 3, "cdate": 1542066164541, "ddate": null, "tcdate": 1542066164541, "tmdate": 1542066164541, "tddate": null, "forum": "rJVoEiCqKQ", "replyto": "r1x0cUg5nm", "invitation": "ICLR.cc/2019/Conference/-/Paper32/Official_Comment", "content": {"title": "Clarifying the formulation", "comment": "We thank Maxwell for some clarification. We believe AnonReviewer2 misunderstood some of the concepts and we will try to clarify them here and update the paper accordingly.  \n\n- predicting unordered sets\nThe assumption is what is available as GT is a set. This means we cannot infer any specific ordering from GT. The proposed framework is very flexible as we don\u2019t need to enforce the problem to be necessarily orderless  (although it can be). The reason we would like to learn  p_m(\\pi | x_i, w) is to infer the nature of the problem. However, excluding the main experiment in supplementary material, we did enforce the problem to be orderless by removing O2 and the permutation loss. This is equivalent to assume p_m(\\pi | x_i, w) is uniform (order does not matter) in Eq.2 and you can see O2 and its loss will be eliminated from Eq. 5 and 6. However, we still require to solve Eq. 5 to find the best permutation based on f1 only, which is equivalent to use Hungarian to solve the assignments. \n \nWe also disagree with R3 that the problem is either unordered sets or there exist only one order to be correct. There can exist multiple orders to be true, but not all. This can be inferred by learning p_m(\\pi | x_i, w) from samples derived during training by Eq. 5. \n\n- permutation in the likelihood (2) does not make sense:\nIn addition to what is explained by Maxwell, I add this clarification:\np_y(y_1 | x, w, (1, 2)) means the first output is assigned to the first ground truth, while p_y(y_1 | x, w, (2, 1)) mean the first output is assigned to the second ground truth. These two scenarios are acctally generate very different gradient.  The same argument can be extended to p_y(y_2 | x, w, (1, 2)) and p_y(y_2 | x, w, (2, 1)). \n\n- the dependence on \\pi drops out when getting a MAP estimate of outputs: \nThe permutation takes into the account when there is loss and a GT to compare as GT  annotations are permutated to be assigned to the outputs. During inference, we don\u2019t have loss and GT. We just have the predicted outputs, e.g. cardinality, states and premutation and the order which we want to show the states will not change the value of the states. \n\n\nWe hope to have clarified all the technical misunderstandings. We would like to point the reviewer again to our impressive results in the detection problem and ask him/her to reconsider his/her rating if the technical concerns are now clear."}, "signatures": ["ICLR.cc/2019/Conference/Paper32/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper32/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper32/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks", "abstract": "Many real-world problems, e.g. object detection, have outputs that are naturally expressed as sets of entities. This creates a challenge for traditional deep neural networks which naturally deal with structured outputs such as vectors, matrices or tensors. We present a novel approach for learning to predict sets with unknown permutation and cardinality using deep neural networks. Specifically, in our formulation we incorporate the permutation as unobservable variable and estimate its distribution during the learning process using alternating optimization. We demonstrate the validity of this new formulation on two relevant vision problems: object detection, for which our formulation outperforms state-of-the-art detectors such as Faster R-CNN and YOLO, and a complex CAPTCHA test, where we observe that, surprisingly, our set based network acquired the ability of mimicking arithmetics without any rules being coded.", "paperhash": "rezatofighi|deep_permset_net_learn_to_predict_sets_with_unknown_permutation_and_cardinality_using_deep_neural_networks", "keywords": ["Set learning", "Permutation invariant", "Object detection", "CAPTCHA test"], "authorids": ["hamid.rezatofighi@adelaide.edu.au", "roman.kaskman@tum.de", "farbod.motlagh@student.adelaide.edu.au", "javen.shi@adelaide.edu.au", "cremers@tum.de", "leal.taixe@tum.de", "ian.reid@adelaide.edu.au"], "authors": ["S. Hamid Rezatofighi", "Roman Kaskman", "Farbod T. Motlagh", "Qinfeng Shi", "Daniel Cremers", "Laura Leal-Taix\u00e9", "Ian Reid"], "TL;DR": "We present a novel approach for learning to predict sets with unknown permutation and cardinality using feed-forward deep neural networks.", "pdf": "/pdf/1a3f4c416c02f44141e22fb24062203ccd658b06.pdf", "_bibtex": "@misc{\nrezatofighi2019deep,\ntitle={Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks},\nauthor={S. Hamid Rezatofighi and Roman Kaskman and Farbod T. Motlagh and Qinfeng Shi and Daniel Cremers and Laura Leal-Taix\u00e9 and Ian Reid},\nyear={2019},\nurl={https://openreview.net/forum?id=rJVoEiCqKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper32/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621875, "tddate": null, "super": null, "final": null, "reply": {"forum": "rJVoEiCqKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper32/Authors", "ICLR.cc/2019/Conference/Paper32/Reviewers", "ICLR.cc/2019/Conference/Paper32/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper32/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper32/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper32/Authors|ICLR.cc/2019/Conference/Paper32/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper32/Reviewers", "ICLR.cc/2019/Conference/Paper32/Authors", "ICLR.cc/2019/Conference/Paper32/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621875}}}, {"id": "SkxrcuFw6m", "original": null, "number": 2, "cdate": 1542064269484, "ddate": null, "tcdate": 1542064269484, "tmdate": 1542064269484, "tddate": null, "forum": "rJVoEiCqKQ", "replyto": "S1l5N7S53X", "invitation": "ICLR.cc/2019/Conference/-/Paper32/Official_Comment", "content": {"title": "Clarifying all key details", "comment": " U^m in Eq 1:\nThis term is clearly defined at the beginning of section 3, first paragraph, line 6 \u201cU is the unit of hyper-volume in ...\u201d . U^m is simply U powered by the cardinality variable. \nIn section 3.3, in the paragraph after Eq.7 line 2, we explain the mechanism to obtain U. For each experiment, we also report the tuned value for U. \n\n- The term p(w) in Eq 2:\nNote Eq. 2 calculates the posterior, i.e., p(w|D) and according to the Bayes theorem, it is p(w|D)\u00a0\\propto\u00a0p(D|w)p(w)\u00a0which\u00a0is\u00a0simply\u00a0Eq. 1.\n\n- Eq 5 confusion :\nTo explain Eq.5 and Eq. 6, the training works as follows:\nAt each iteration k-1, the network predicts the outputs, i.e., O1, O2 and \\alpha. We first solve a discrete optimization to find the permutation (matching) between the predictions at k-1 and the ground truth (GT). Then, we use this permutation to order GT and back-propagate the losses to update w at iteration k. Please note that cardinality loss does not depend on this permutation variable.\n\n- The network architecture :\nNote that our described methodology can be applied to any network architecture. In ALL our experiments, we use Res-net 101 (mentioned several times on page 6 and 8). \nWe\u00a0only\u00a0need to define the number of outputs and use the set loss defined in Eq. 5 and 6. For example, for the set size with maximum cardinality 4, we need 5 outputs\u00a0( \\alpha)\u00a0for cardinality m = {0, 1,...4}.\u00a0If the state of each set is 5 for the detection experiment, we need 4*5=20 outputs for the state  loss (O1). For the permutation (O2), we need 4!=24 outputs.\nFor each output we have a loss defined for each experiment\u00a0in the text.\n\n- the permutation to benefit training:\nWe refer the reviewer to the experiment we have already included in Appendix titled \u201cAn additional baseline experiment\u201d, which unfortunately we could not include in the main manuscript due to space constraints.\n We use a baseline model with no permutation, which is exactly same as [21], to train the network for the detection task. The results show the model is not able to learn this task, hence highlighting the need for permutation prediction for a complete set prediction network.\nEven if we remove the permutation head, O2, from our model, we still need to calculate the permutation using Eq. 5 and use it for backpropagation in Eq. 6. However the model in [21] completely ignore the permutation in its formulation. Therefore, it cannot learn the detection task.  \n\n- Term f2 in Eq5 uses w~ estimates: \nYour interpretation is indeed correct. Given the predictions of O1 and O2 using statistics from past SGD runs, we want to find the best permutation. There are indeed m! way to assign GT set elements to the predictions. We solve this optimization to find the best one.\u00a0\n\n- the significance of the permutation:\nEven if we don\u2019t use f2 for the estimation of the best permutation, we can use \\pi* as ground truth for updating its loss in Eq. 6.\n\n- classifying permutations:\nClassifying the permutations provides the extra information about the structure of the problem, e.g. there exist a single order which matters or it can be several different orders or the problem is orderless. We simply do not ignore the permutations from Hungarian by allowing the network to learn them. We refer you to the experiment we have already included in Appendix titled \u201cDetection & Identification results\u201d, where we used the predicted permutations to identify the bounding boxes for similar looking objects across different test images\n\n-  larger images and many instances:\nWe agree. We leave this as future work, as it would require an engineering effort that departs from the main purpose of our paper, which is to show theoretically how to construct a network that can work with sets instead of tensors.\n\n- sensitivity to seeing a certain cardinality:\nDuring the training, we do the data augmentation (by cropping, flipping etc) to ensure the network sees enough sample for each cardinality. We will include this detail in the text.\n\n- Related work \nWe are happy to include these references. But these works are orthogonal to the main subject of our paper. In our paper the goal is to introduce a framework to output a set using neural networks and we used the detection task as one of the set prediction examples.\nWe would like to add few comment about these two works:\nThese approaches try to learn a pairwise relationship between the boxes outputted using the conventional proposal based detection approaches. First a) they need to introduce extra pairwise network or heavier computation to learn these pairwise relationship b) they assume the relationship is pairwise between bounding boxes. Out framework is a single stage approach which uses a conventional convnet backbones with no extra computation. Since it is end-to-end prediction of boxes, we don\u2019t enforce any pairwise or higher order relationships between the outputs. We all rely on the layer of neural nets to capture high level relationship between outputs before predicting them.\u00a0"}, "signatures": ["ICLR.cc/2019/Conference/Paper32/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper32/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper32/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks", "abstract": "Many real-world problems, e.g. object detection, have outputs that are naturally expressed as sets of entities. This creates a challenge for traditional deep neural networks which naturally deal with structured outputs such as vectors, matrices or tensors. We present a novel approach for learning to predict sets with unknown permutation and cardinality using deep neural networks. Specifically, in our formulation we incorporate the permutation as unobservable variable and estimate its distribution during the learning process using alternating optimization. We demonstrate the validity of this new formulation on two relevant vision problems: object detection, for which our formulation outperforms state-of-the-art detectors such as Faster R-CNN and YOLO, and a complex CAPTCHA test, where we observe that, surprisingly, our set based network acquired the ability of mimicking arithmetics without any rules being coded.", "paperhash": "rezatofighi|deep_permset_net_learn_to_predict_sets_with_unknown_permutation_and_cardinality_using_deep_neural_networks", "keywords": ["Set learning", "Permutation invariant", "Object detection", "CAPTCHA test"], "authorids": ["hamid.rezatofighi@adelaide.edu.au", "roman.kaskman@tum.de", "farbod.motlagh@student.adelaide.edu.au", "javen.shi@adelaide.edu.au", "cremers@tum.de", "leal.taixe@tum.de", "ian.reid@adelaide.edu.au"], "authors": ["S. Hamid Rezatofighi", "Roman Kaskman", "Farbod T. Motlagh", "Qinfeng Shi", "Daniel Cremers", "Laura Leal-Taix\u00e9", "Ian Reid"], "TL;DR": "We present a novel approach for learning to predict sets with unknown permutation and cardinality using feed-forward deep neural networks.", "pdf": "/pdf/1a3f4c416c02f44141e22fb24062203ccd658b06.pdf", "_bibtex": "@misc{\nrezatofighi2019deep,\ntitle={Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks},\nauthor={S. Hamid Rezatofighi and Roman Kaskman and Farbod T. Motlagh and Qinfeng Shi and Daniel Cremers and Laura Leal-Taix\u00e9 and Ian Reid},\nyear={2019},\nurl={https://openreview.net/forum?id=rJVoEiCqKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper32/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621875, "tddate": null, "super": null, "final": null, "reply": {"forum": "rJVoEiCqKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper32/Authors", "ICLR.cc/2019/Conference/Paper32/Reviewers", "ICLR.cc/2019/Conference/Paper32/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper32/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper32/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper32/Authors|ICLR.cc/2019/Conference/Paper32/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper32/Reviewers", "ICLR.cc/2019/Conference/Paper32/Authors", "ICLR.cc/2019/Conference/Paper32/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621875}}}, {"id": "ryx3iYPDam", "original": null, "number": 1, "cdate": 1542056355585, "ddate": null, "tcdate": 1542056355585, "tmdate": 1542056355585, "tddate": null, "forum": "rJVoEiCqKQ", "replyto": "rJegAZu6nQ", "invitation": "ICLR.cc/2019/Conference/-/Paper32/Official_Comment", "content": {"title": "Network details and inference time", "comment": "We appreciate AnonReviewer3\u2019s recognition of our work. \n\n- Network details\nWe only replace the last fc layer of ResNet-101 with a new fc layer mapping to 49 (5+20+24 = 49) outputs for calculating cardinality, states and permutation (the choice of these numbers explained in our response to R2). \n\n- inference time\nWe also performed extra experiment on accuracy and inference time between different detectors (on the same machine and GPU) reported here:\n\nFaster R-CNN: AP=0.68, Inference time=101 ms\nYOLO\u00a0v2: AP=0.68, Inference time=12.3 ms\nYOLO\u00a0v3: AP=0.70, Inference time=18.2 ms\nOur network: AP=0.75, Inference time=15.1 ms\n\n- test on PASCAL VOC\nWe observed PASCAL VOC dataset include many images with more than 4 persons. Considering the images include up to 4 persons only, we might not have enough training data to train ResNet-101 network. "}, "signatures": ["ICLR.cc/2019/Conference/Paper32/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper32/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper32/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks", "abstract": "Many real-world problems, e.g. object detection, have outputs that are naturally expressed as sets of entities. This creates a challenge for traditional deep neural networks which naturally deal with structured outputs such as vectors, matrices or tensors. We present a novel approach for learning to predict sets with unknown permutation and cardinality using deep neural networks. Specifically, in our formulation we incorporate the permutation as unobservable variable and estimate its distribution during the learning process using alternating optimization. We demonstrate the validity of this new formulation on two relevant vision problems: object detection, for which our formulation outperforms state-of-the-art detectors such as Faster R-CNN and YOLO, and a complex CAPTCHA test, where we observe that, surprisingly, our set based network acquired the ability of mimicking arithmetics without any rules being coded.", "paperhash": "rezatofighi|deep_permset_net_learn_to_predict_sets_with_unknown_permutation_and_cardinality_using_deep_neural_networks", "keywords": ["Set learning", "Permutation invariant", "Object detection", "CAPTCHA test"], "authorids": ["hamid.rezatofighi@adelaide.edu.au", "roman.kaskman@tum.de", "farbod.motlagh@student.adelaide.edu.au", "javen.shi@adelaide.edu.au", "cremers@tum.de", "leal.taixe@tum.de", "ian.reid@adelaide.edu.au"], "authors": ["S. Hamid Rezatofighi", "Roman Kaskman", "Farbod T. Motlagh", "Qinfeng Shi", "Daniel Cremers", "Laura Leal-Taix\u00e9", "Ian Reid"], "TL;DR": "We present a novel approach for learning to predict sets with unknown permutation and cardinality using feed-forward deep neural networks.", "pdf": "/pdf/1a3f4c416c02f44141e22fb24062203ccd658b06.pdf", "_bibtex": "@misc{\nrezatofighi2019deep,\ntitle={Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks},\nauthor={S. Hamid Rezatofighi and Roman Kaskman and Farbod T. Motlagh and Qinfeng Shi and Daniel Cremers and Laura Leal-Taix\u00e9 and Ian Reid},\nyear={2019},\nurl={https://openreview.net/forum?id=rJVoEiCqKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper32/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621621875, "tddate": null, "super": null, "final": null, "reply": {"forum": "rJVoEiCqKQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper32/Authors", "ICLR.cc/2019/Conference/Paper32/Reviewers", "ICLR.cc/2019/Conference/Paper32/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper32/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper32/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper32/Authors|ICLR.cc/2019/Conference/Paper32/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper32/Reviewers", "ICLR.cc/2019/Conference/Paper32/Authors", "ICLR.cc/2019/Conference/Paper32/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621621875}}}, {"id": "H1eoH7T167", "original": null, "number": 1, "cdate": 1541555010799, "ddate": null, "tcdate": 1541555010799, "tmdate": 1541556189251, "tddate": null, "forum": "rJVoEiCqKQ", "replyto": "r1x0cUg5nm", "invitation": "ICLR.cc/2019/Conference/-/Paper32/Public_Comment", "content": {"comment": "I am not affiliated with the authors of this paper, but I spent quite some time puzzling over it myself. The question of \"if it's for unordered sets, why on Earth does it need to bother with predicting the permutation in the first place?\" puzzled me as well, but I think I eventually figured it out.\n\nIt's for aligning the output with the training labels. That's why the permutation element only matters during training and is ignored at inference! If you want to properly score two sets against each other, you have to decide which element should be compared with which; if you're predicting, say, sets of numbers and you predict {10, -3} when the ground-truth labels are {-4, 9}, then how you score the model will depend greatly on how you align each element of the sets. It matters quite a bit for the loss - and the resulting gradient - if you view the 10 as a pathetic failure to predict that the set should contain a -4, or if you instead treat it as a nearly-accurate prediction of the set containing a 9.  \n\nSo in order to fairly score the set output versus the ground truth set, you essentially have to examine every possible way of matching up output elements to input elements in order to select the one which gives the closest match. This would be staggeringly computationally expensive, so they settle for just trying to guess what permutation will line up with the training data best, and then directly scoring that permutation against the ground-truth labels and hoping that comes close enough.\n\nIn the DeepSets paper (https://arxiv.org/abs/1703.06114), this is why it was limited to only producing sets of the same cardinality and permutation as the input set; because that way, you can directly track the attribution and determine which label properly belongs to which input element, and thereby score the corresponding outputs on how close they got to that label. \n\n(In other words: the permutation matters only for credit assignment purposes.)", "title": "The purpose of the permutation component"}, "signatures": ["~Maxwell_B_Greason1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Maxwell_B_Greason1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks", "abstract": "Many real-world problems, e.g. object detection, have outputs that are naturally expressed as sets of entities. This creates a challenge for traditional deep neural networks which naturally deal with structured outputs such as vectors, matrices or tensors. We present a novel approach for learning to predict sets with unknown permutation and cardinality using deep neural networks. Specifically, in our formulation we incorporate the permutation as unobservable variable and estimate its distribution during the learning process using alternating optimization. We demonstrate the validity of this new formulation on two relevant vision problems: object detection, for which our formulation outperforms state-of-the-art detectors such as Faster R-CNN and YOLO, and a complex CAPTCHA test, where we observe that, surprisingly, our set based network acquired the ability of mimicking arithmetics without any rules being coded.", "paperhash": "rezatofighi|deep_permset_net_learn_to_predict_sets_with_unknown_permutation_and_cardinality_using_deep_neural_networks", "keywords": ["Set learning", "Permutation invariant", "Object detection", "CAPTCHA test"], "authorids": ["hamid.rezatofighi@adelaide.edu.au", "roman.kaskman@tum.de", "farbod.motlagh@student.adelaide.edu.au", "javen.shi@adelaide.edu.au", "cremers@tum.de", "leal.taixe@tum.de", "ian.reid@adelaide.edu.au"], "authors": ["S. Hamid Rezatofighi", "Roman Kaskman", "Farbod T. Motlagh", "Qinfeng Shi", "Daniel Cremers", "Laura Leal-Taix\u00e9", "Ian Reid"], "TL;DR": "We present a novel approach for learning to predict sets with unknown permutation and cardinality using feed-forward deep neural networks.", "pdf": "/pdf/1a3f4c416c02f44141e22fb24062203ccd658b06.pdf", "_bibtex": "@misc{\nrezatofighi2019deep,\ntitle={Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks},\nauthor={S. Hamid Rezatofighi and Roman Kaskman and Farbod T. Motlagh and Qinfeng Shi and Daniel Cremers and Laura Leal-Taix\u00e9 and Ian Reid},\nyear={2019},\nurl={https://openreview.net/forum?id=rJVoEiCqKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper32/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311934968, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "rJVoEiCqKQ", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper32/Authors", "ICLR.cc/2019/Conference/Paper32/Reviewers", "ICLR.cc/2019/Conference/Paper32/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper32/Authors", "ICLR.cc/2019/Conference/Paper32/Reviewers", "ICLR.cc/2019/Conference/Paper32/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311934968}}}, {"id": "rJegAZu6nQ", "original": null, "number": 3, "cdate": 1541403080446, "ddate": null, "tcdate": 1541403080446, "tmdate": 1541534344779, "tddate": null, "forum": "rJVoEiCqKQ", "replyto": "rJVoEiCqKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper32/Official_Review", "content": {"title": "novel, potentially significant & with limitation on large-scale problem", "review": "\nThe paper is really interesting. Set prediction problem has lots of applications in AI applications and the problem has not been conquered by deep networks. \n\nThe paper proposes a formulation to learn the distribution over unobservable permutation variables based on deep networks and uses a MAP  estimator for inference.  It has object detection applications. The results show that it can outperform YOLOv2 and Faster R-CNN in a small pedestrian detection dataset which contains heavy occlusions. \n\nThe limitation is clearly stated in the last part of the paper that the number of possible permutations exponentially grows with the maximum set size (cardinality). \n\nIn the author response period, I would like the author give more details about the pedestrian detection experiments, such as how many dense layers are used after ResNet-101, what are the training and inference time, is it possible to report results on PASCAL VOC (only the person class).\n\nThe method is exciting for object detection funs.  I would like to encourage the authors to release the code and let the whole object detection community overcome the limitation in the paper. \n\n\n\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper32/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks", "abstract": "Many real-world problems, e.g. object detection, have outputs that are naturally expressed as sets of entities. This creates a challenge for traditional deep neural networks which naturally deal with structured outputs such as vectors, matrices or tensors. We present a novel approach for learning to predict sets with unknown permutation and cardinality using deep neural networks. Specifically, in our formulation we incorporate the permutation as unobservable variable and estimate its distribution during the learning process using alternating optimization. We demonstrate the validity of this new formulation on two relevant vision problems: object detection, for which our formulation outperforms state-of-the-art detectors such as Faster R-CNN and YOLO, and a complex CAPTCHA test, where we observe that, surprisingly, our set based network acquired the ability of mimicking arithmetics without any rules being coded.", "paperhash": "rezatofighi|deep_permset_net_learn_to_predict_sets_with_unknown_permutation_and_cardinality_using_deep_neural_networks", "keywords": ["Set learning", "Permutation invariant", "Object detection", "CAPTCHA test"], "authorids": ["hamid.rezatofighi@adelaide.edu.au", "roman.kaskman@tum.de", "farbod.motlagh@student.adelaide.edu.au", "javen.shi@adelaide.edu.au", "cremers@tum.de", "leal.taixe@tum.de", "ian.reid@adelaide.edu.au"], "authors": ["S. Hamid Rezatofighi", "Roman Kaskman", "Farbod T. Motlagh", "Qinfeng Shi", "Daniel Cremers", "Laura Leal-Taix\u00e9", "Ian Reid"], "TL;DR": "We present a novel approach for learning to predict sets with unknown permutation and cardinality using feed-forward deep neural networks.", "pdf": "/pdf/1a3f4c416c02f44141e22fb24062203ccd658b06.pdf", "_bibtex": "@misc{\nrezatofighi2019deep,\ntitle={Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks},\nauthor={S. Hamid Rezatofighi and Roman Kaskman and Farbod T. Motlagh and Qinfeng Shi and Daniel Cremers and Laura Leal-Taix\u00e9 and Ian Reid},\nyear={2019},\nurl={https://openreview.net/forum?id=rJVoEiCqKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper32/Official_Review", "cdate": 1542234553455, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rJVoEiCqKQ", "replyto": "rJVoEiCqKQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper32/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335633724, "tmdate": 1552335633724, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper32/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "S1l5N7S53X", "original": null, "number": 2, "cdate": 1541194545680, "ddate": null, "tcdate": 1541194545680, "tmdate": 1541534344571, "tddate": null, "forum": "rJVoEiCqKQ", "replyto": "rJVoEiCqKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper32/Official_Review", "content": {"title": "Interesting results on object detection for overlapping objects and CAPTCHA toy problem, but key details seem unclear", "review": "\u2014 Summary\nThe method extends [21], which proposes an unordered set prediction model for multi-class classification. For that problem, [21] can assume logistic outputs for all distinct classes. This work extends set prediction to the object detection task, where box identity is not distinct \u2014 this is handled by an additional model output that reasons about the most likely object permutations. The permutation predictions are used during training, but are not needed at inference time \u2014 as shown in Fig1 and Eq 7. Results are on detection of overlapping objects and a CAPTCHA toy summation example.\n\n\u2014 Clarity \nThe exposition is not particularly clear in several places: \n - U^m in Eq 1 is undefined and un-discussed. What probability term does it correspond to? It is supposed to make probabilities of different cardinalities comparable, but the exact mechanism is unclear. \n - The term p(w) disappears on the left hand side of Eq 2. \n - Notation in Sec. 3.2 is very cumbersome, making it hard to follow. Furthermore, I found the description ambiguous, preventing me from understanding how exactly the permutation head output is used in Eq 5. Specifically, there is some confusion about estimation of w~, which seems based on frequency estimation from past SGD iterations (Eq 3). If so, why does term f2 in Eq 5 contain the permutation head output O2 and how do the two relate? \n - The network architecture is never described, especially the transition from Conv to Dense and the layer sizes, making the work hard to reproduce. The dimensions of the convolutional feature map matter (probably need to be kept tractable). \n\n\u2014 Significance\nKey aspects of the model are not particularly clear, specifically about how the permutation prediction ( the key novelty here) is used to benefit training. \n\u2014 Term f2 in Eq5 uses w~ estimates, which appeared to be based on statistics from past SGD runs, yet also depends on the output of the permutation head O2. Am I misinterpreting the method?\n\u2014 In the paragraph right after Eq5, it\u2019s claimed that \u201cEmpirically, in our applications, we found out that estimation of the permutations from just f1 [in Eq5] is sufficient to train properly \u2026 by using the Hungarian algorithm\u201d. So then f2 term is not even used in. Eq5? If so, what is the significance of the permutation head other than adding an auxiliary loss? \n\nFurthermore, there are no experimental results demonstrating the effect of the permutation head and the design choices above \u2014 if we could get by with only using the Hungarian algorithm, why bother classifying an exponential number of permutations? Do they help when added as an auxiliary loss?  \n\nWhile the failure of NMS to detect overlapping objects is expected, the experiments showing that perm-set prediction handles them well is interesting and promising. Solving the general case with larger images and many instances would increase the impact significantly \u2014 and likely require a combination of perm-set prediction and image tiling, although this is just a hypothesis. The Captcha toy example also shows some interesting behavior emerging \u2014 without digit-specific annotations (otherwise it would be multi-class classification setup from [21]), the model can handle the majority of summations correctly. \n\n\u2014 Experimental results\nThe results are interesting proofs-of-concept but a few more experiments/answers would be helpful:\n- It still appears that PR curve in the high-precision regime (fig 3b) has lower precision than FRCNN/YOLO. Any idea as to why? \n- Ablation results on the effect of the permutation predictions vs Hungarian algorithm, etc would be helpful, as discussed above. \n- How sensitive is the method to seeing a certain cardinality? What if it never sees 3 pedestrians in an image, but only 1,2,4 will it fail to predict 3? Or alternatively, if we train a model that can handle up to 5-6 entities with examples than have <=4? What is the right way of data augmentation for this model (was there any and should there be?)\n- Given that values for U differ across applications, how sensitive is the output / how much sweeping did you have to do?\u2028\n\n-- Related work\nTo the best of my knowledge it's representative. It would help to cite more recent work that decreases detector dependence on NMS. For example, \"Learning Non-Maximum Suppression\", Hosang, Benenson, Schiele, CVPR 2017 or \"Relation Networks for Object Detection\", by Hu et al, CVPR 2018 and references therein. ", "rating": "3: Clear rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper32/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks", "abstract": "Many real-world problems, e.g. object detection, have outputs that are naturally expressed as sets of entities. This creates a challenge for traditional deep neural networks which naturally deal with structured outputs such as vectors, matrices or tensors. We present a novel approach for learning to predict sets with unknown permutation and cardinality using deep neural networks. Specifically, in our formulation we incorporate the permutation as unobservable variable and estimate its distribution during the learning process using alternating optimization. We demonstrate the validity of this new formulation on two relevant vision problems: object detection, for which our formulation outperforms state-of-the-art detectors such as Faster R-CNN and YOLO, and a complex CAPTCHA test, where we observe that, surprisingly, our set based network acquired the ability of mimicking arithmetics without any rules being coded.", "paperhash": "rezatofighi|deep_permset_net_learn_to_predict_sets_with_unknown_permutation_and_cardinality_using_deep_neural_networks", "keywords": ["Set learning", "Permutation invariant", "Object detection", "CAPTCHA test"], "authorids": ["hamid.rezatofighi@adelaide.edu.au", "roman.kaskman@tum.de", "farbod.motlagh@student.adelaide.edu.au", "javen.shi@adelaide.edu.au", "cremers@tum.de", "leal.taixe@tum.de", "ian.reid@adelaide.edu.au"], "authors": ["S. Hamid Rezatofighi", "Roman Kaskman", "Farbod T. Motlagh", "Qinfeng Shi", "Daniel Cremers", "Laura Leal-Taix\u00e9", "Ian Reid"], "TL;DR": "We present a novel approach for learning to predict sets with unknown permutation and cardinality using feed-forward deep neural networks.", "pdf": "/pdf/1a3f4c416c02f44141e22fb24062203ccd658b06.pdf", "_bibtex": "@misc{\nrezatofighi2019deep,\ntitle={Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks},\nauthor={S. Hamid Rezatofighi and Roman Kaskman and Farbod T. Motlagh and Qinfeng Shi and Daniel Cremers and Laura Leal-Taix\u00e9 and Ian Reid},\nyear={2019},\nurl={https://openreview.net/forum?id=rJVoEiCqKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper32/Official_Review", "cdate": 1542234553455, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rJVoEiCqKQ", "replyto": "rJVoEiCqKQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper32/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335633724, "tmdate": 1552335633724, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper32/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "r1x0cUg5nm", "original": null, "number": 1, "cdate": 1541174933912, "ddate": null, "tcdate": 1541174933912, "tmdate": 1541534344325, "tddate": null, "forum": "rJVoEiCqKQ", "replyto": "rJVoEiCqKQ", "invitation": "ICLR.cc/2019/Conference/-/Paper32/Official_Review", "content": {"title": "Lacks clarity of methodology.", "review": "This paper looks to predict \"unstructured\" set output data. It extends Rezatofighi et al 2018 by modeling a latent permutation.\n\nUnfortunately, there is a bit of an identity crisis happening in this paper. There are several choices that do not follow based on the data the paper considers. \n1) The paper claims to want to predict unordered sets, yet the model is clearly indicating a dependence in the order of the outputs and the input p_m(\\pi | x_i, w) (1); this feels like a very odd choice to me. The outputs are either unordered sets, where you would have a permutation invariant (or exchangeable) likelihood, or they are ordered sequence where the order of the outputs does matter, as some are more likely than others.\n2) The paper still makes very odd choices even if one ignores the above and wants to model some orderings as more likely than others. The way the permutation, or the order of the data, accounts in the likelihood (2) does not make sense. Conditioned on the permutation of the set, the points are exchangeable. Let's just consider a 2 element \"set\" at the moment Y = (y_1, y_2). Order matters, so either this is being observed as pi=(1, 2) or pi=(2, 1), both of which depend on the input x. However, the likelihood of the points does not actually depend on the order in any traditional sense of the word. we have:\np_\\pi((1, 2) | x, w) p_y(y_1 |  x, w, (1, 2)) p_y(y_2 |  x, w, (1, 2)) + p_\\pi((2, 1) | x, w) p_y(y_1 |  x, w, (2, 1)) p_y(y_2 |  x, w, (2, 1))\n*Note that in here (as in eq. 2) the output distribution p_y does not know what the index is of what it is outputting, since it is iid.* So what does this mean? It means that the order (permutation) can only affect the distribution in an iid (exchangeable, order invariant) way. Essentially the paper has just written a mixture model for the output points where there are as many components as permutations. I don't think this makes much sense, and if it was an intentional choice, the paper did a poor job of indicating it.\n3) Supposing even still that one does want a mixture model with as many components as permutations, there are still some issues. It is very unclear how the dependence on \\pi drops out when getting a MAP estimate of outputs in section 3.3. This needs to be justified.\n\nThere are some stylistic shortcomings as well. For example, the related works paper would read better if it wasn't one long block (i.e. break it into several paragraphs). Also, the paper claims that it will use a super script m to denote a known cardinality, yet omits \\mathcal{Y}_i^{m_i} in the training set of the first sentence in 3.1. But these and other points are minor.\n\nThe paper should not be published until it can resolve or make sense of the methodological discrepancies between what it says it looks to do and what it actually does as described in points 1), 2), and 3) above.", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper32/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks", "abstract": "Many real-world problems, e.g. object detection, have outputs that are naturally expressed as sets of entities. This creates a challenge for traditional deep neural networks which naturally deal with structured outputs such as vectors, matrices or tensors. We present a novel approach for learning to predict sets with unknown permutation and cardinality using deep neural networks. Specifically, in our formulation we incorporate the permutation as unobservable variable and estimate its distribution during the learning process using alternating optimization. We demonstrate the validity of this new formulation on two relevant vision problems: object detection, for which our formulation outperforms state-of-the-art detectors such as Faster R-CNN and YOLO, and a complex CAPTCHA test, where we observe that, surprisingly, our set based network acquired the ability of mimicking arithmetics without any rules being coded.", "paperhash": "rezatofighi|deep_permset_net_learn_to_predict_sets_with_unknown_permutation_and_cardinality_using_deep_neural_networks", "keywords": ["Set learning", "Permutation invariant", "Object detection", "CAPTCHA test"], "authorids": ["hamid.rezatofighi@adelaide.edu.au", "roman.kaskman@tum.de", "farbod.motlagh@student.adelaide.edu.au", "javen.shi@adelaide.edu.au", "cremers@tum.de", "leal.taixe@tum.de", "ian.reid@adelaide.edu.au"], "authors": ["S. Hamid Rezatofighi", "Roman Kaskman", "Farbod T. Motlagh", "Qinfeng Shi", "Daniel Cremers", "Laura Leal-Taix\u00e9", "Ian Reid"], "TL;DR": "We present a novel approach for learning to predict sets with unknown permutation and cardinality using feed-forward deep neural networks.", "pdf": "/pdf/1a3f4c416c02f44141e22fb24062203ccd658b06.pdf", "_bibtex": "@misc{\nrezatofighi2019deep,\ntitle={Deep Perm-Set Net: Learn to predict sets with unknown permutation and cardinality using deep neural networks},\nauthor={S. Hamid Rezatofighi and Roman Kaskman and Farbod T. Motlagh and Qinfeng Shi and Daniel Cremers and Laura Leal-Taix\u00e9 and Ian Reid},\nyear={2019},\nurl={https://openreview.net/forum?id=rJVoEiCqKQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper32/Official_Review", "cdate": 1542234553455, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rJVoEiCqKQ", "replyto": "rJVoEiCqKQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper32/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335633724, "tmdate": 1552335633724, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper32/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 12}