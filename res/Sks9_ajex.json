{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1486936896058, "tcdate": 1478379666965, "number": 610, "id": "Sks9_ajex", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "Sks9_ajex", "signatures": ["~Sergey_Zagoruyko1"], "readers": ["everyone"], "content": {"TL;DR": "", "title": "Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer", "abstract": "Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network. To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures.", "pdf": "/pdf/db088e768de05a386c4b19d7832062562661d4f7.pdf", "paperhash": "zagoruyko|paying_more_attention_to_attention_improving_the_performance_of_convolutional_neural_networks_via_attention_transfer", "conflicts": ["fb.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Sergey Zagoruyko", "Nikos Komodakis"], "authorids": ["sergey.zagoruyko@enpc.fr", "nikos.komodakis@enpc.fr"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 18, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396706324, "tcdate": 1486396706324, "number": 1, "id": "ry9mTGLul", "invitation": "ICLR.cc/2017/conference/-/paper610/acceptance", "forum": "Sks9_ajex", "replyto": "Sks9_ajex", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "Important task (attention models), interesting distillation application, well-written paper. The authors have been responsive in updating the paper, adding new experiments, and being balanced in presenting their findings. I support accepting this paper.", "decision": "Accept (Poster)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer", "abstract": "Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network. To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures.", "pdf": "/pdf/db088e768de05a386c4b19d7832062562661d4f7.pdf", "paperhash": "zagoruyko|paying_more_attention_to_attention_improving_the_performance_of_convolutional_neural_networks_via_attention_transfer", "conflicts": ["fb.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Sergey Zagoruyko", "Nikos Komodakis"], "authorids": ["sergey.zagoruyko@enpc.fr", "nikos.komodakis@enpc.fr"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396706785, "id": "ICLR.cc/2017/conference/-/paper610/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "Sks9_ajex", "replyto": "Sks9_ajex", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396706785}}}, {"tddate": null, "tmdate": 1485218385643, "tcdate": 1482264252799, "number": 2, "id": "H1BT0bwVe", "invitation": "ICLR.cc/2017/conference/-/paper610/official/review", "forum": "Sks9_ajex", "replyto": "Sks9_ajex", "signatures": ["ICLR.cc/2017/conference/paper610/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper610/AnonReviewer2"], "content": {"title": "Review", "rating": "6: Marginally above acceptance threshold", "review": "The paper presented a modified knowledge distillation framework that minimizes the difference of the sum of statistics across the a feature map between the teacher and the student network. The authors empirically demonstrated the proposed methods outperform the fitnet style distillation baseline. \n\nPros:\n+ The author evaluated the proposed methods on various computer vision dataset \n+ The paper is in general well-written\n\nCons:  \n- The method seems to be limited to the convolutional architecture\n- The attention terminology is misleading in the paper. The proposed method really just try to distill the summed squared(or other statistics e.g. summed lp norm) of  activations in a hidden feature map.\n- The gradient-based attention transfer seems out-of-place. The proposed gradient-based methods are never compared directly to nor are used jointly with the \"attention-based\" transfer. It seems like a parallel idea added to the paper that does not seem to add much value.\n- It is also not clear how the induced 2-norms in eq.(2) is computed. Q is a matrix \\in \\mathbb{R}^{H \\times W}  whose induced 2-norm is its largest singular value. It seems computationally expensive to compute such cost function. Is it possible the authors really mean the Frobenius norm?\n\nOverall, the proposed distillation method works well in practice but the paper has some organization issues and unclear notation.  \n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer", "abstract": "Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network. To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures.", "pdf": "/pdf/db088e768de05a386c4b19d7832062562661d4f7.pdf", "paperhash": "zagoruyko|paying_more_attention_to_attention_improving_the_performance_of_convolutional_neural_networks_via_attention_transfer", "conflicts": ["fb.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Sergey Zagoruyko", "Nikos Komodakis"], "authorids": ["sergey.zagoruyko@enpc.fr", "nikos.komodakis@enpc.fr"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512525389, "id": "ICLR.cc/2017/conference/-/paper610/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper610/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper610/AnonReviewer1", "ICLR.cc/2017/conference/paper610/AnonReviewer2", "ICLR.cc/2017/conference/paper610/AnonReviewer3"], "reply": {"forum": "Sks9_ajex", "replyto": "Sks9_ajex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper610/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper610/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512525389}}}, {"tddate": null, "tmdate": 1485218351794, "tcdate": 1485218351794, "number": 3, "id": "SkdNzQ4Pe", "invitation": "ICLR.cc/2017/conference/-/paper610/official/comment", "forum": "Sks9_ajex", "replyto": "rJYIlMlPx", "signatures": ["ICLR.cc/2017/conference/paper610/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper610/AnonReviewer2"], "content": {"title": "incremental paper", "comment": "I like the additional experiments author have done to compare act-AT and grad-AT in Table 3. It pretty much shows the act-AT is a much superior method comparing to the computationally expensive grad-AT that does not provide any benefit over KD baseline. Therefore, the grad-AT does not add much value to the paper and require an additional adhoc horizontal flip trick. The story will be much cleaner if the paper just focuses on summed square attention map and show it is a much simpler and more effective way to achieve fitnet like transfer. The authors have addressed my concerns from the previous review. I have changed my review score accordingly."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer", "abstract": "Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network. To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures.", "pdf": "/pdf/db088e768de05a386c4b19d7832062562661d4f7.pdf", "paperhash": "zagoruyko|paying_more_attention_to_attention_improving_the_performance_of_convolutional_neural_networks_via_attention_transfer", "conflicts": ["fb.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Sergey Zagoruyko", "Nikos Komodakis"], "authorids": ["sergey.zagoruyko@enpc.fr", "nikos.komodakis@enpc.fr"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287500754, "id": "ICLR.cc/2017/conference/-/paper610/official/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "reply": {"forum": "Sks9_ajex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper610/(AnonReviewer|areachair)[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper610/(AnonReviewer|areachair)[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/conference/paper610/reviewers", "ICLR.cc/2017/conference/paper610/areachairs"], "cdate": 1485287500754}}}, {"tddate": null, "tmdate": 1484951633155, "tcdate": 1484951633155, "number": 12, "id": "rJYIlMlPx", "invitation": "ICLR.cc/2017/conference/-/paper610/public/comment", "forum": "Sks9_ajex", "replyto": "rJOmeeQSx", "signatures": ["~Sergey_Zagoruyko1"], "readers": ["everyone"], "writers": ["~Sergey_Zagoruyko1"], "content": {"title": "Update", "comment": "Regarding \"Q: The gradient-based attention transfer seems out-of-place. The proposed gradient-based methods are never compared directly to nor are used jointly with the \"attention-based\" transfer. It seems like a parallel idea added to the paper that does not seem to add much value.\":\n\nWe trained thin NIN with activation based AT in the same conditions as grad-based experiments, and, interestingly, it converges to better accuracy than KD or grad-based methods, 11.2% error on CIFAR-10 (table 3 in the paper)."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer", "abstract": "Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network. To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures.", "pdf": "/pdf/db088e768de05a386c4b19d7832062562661d4f7.pdf", "paperhash": "zagoruyko|paying_more_attention_to_attention_improving_the_performance_of_convolutional_neural_networks_via_attention_transfer", "conflicts": ["fb.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Sergey Zagoruyko", "Nikos Komodakis"], "authorids": ["sergey.zagoruyko@enpc.fr", "nikos.komodakis@enpc.fr"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287500885, "id": "ICLR.cc/2017/conference/-/paper610/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sks9_ajex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper610/reviewers", "ICLR.cc/2017/conference/paper610/areachairs"], "cdate": 1485287500885}}}, {"tddate": null, "tmdate": 1484951069530, "tcdate": 1484951069530, "number": 11, "id": "BkSXAbevl", "invitation": "ICLR.cc/2017/conference/-/paper610/public/comment", "forum": "Sks9_ajex", "replyto": "By6ieemHg", "signatures": ["~Sergey_Zagoruyko1"], "readers": ["everyone"], "writers": ["~Sergey_Zagoruyko1"], "content": {"title": "Update", "comment": "Although we tried several things, we were not able to achieve positive results with KD on ImageNet. With ResNet-18/ResNet-34 student/teacher pair it actually hurts convergence with the same hyperparameters as on CIFAR. As it was reported that KD struggles to work if teacher and student have different architecture/depth (we observed the same on CIFAR), we tried using the same architecture and depth for attention transfer:\nResNet-18 as student and trained ResNet-18 as teacher\nResNet-34 as student and trained ResNet-34 as teacher\nOn CIFAR both AT and KD work well in this case and improve convergence and final accuracy, on ImageNet though KD converges significantly slower (we didn\u2019t train it until the end, because we can do only 1-2 experiments at a time). We also couldn\u2019t find in the literature any reported results of FitNets, KD or similar methods on ImageNet, and we also contacted the authors of FitNets, as well as a few people who had similar experience with KD on ImageNet. Given the above, we can assume that our proposed activation-based attention transfer approach is the first knowledge transfer method to be successfully applied on ImageNet."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer", "abstract": "Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network. To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures.", "pdf": "/pdf/db088e768de05a386c4b19d7832062562661d4f7.pdf", "paperhash": "zagoruyko|paying_more_attention_to_attention_improving_the_performance_of_convolutional_neural_networks_via_attention_transfer", "conflicts": ["fb.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Sergey Zagoruyko", "Nikos Komodakis"], "authorids": ["sergey.zagoruyko@enpc.fr", "nikos.komodakis@enpc.fr"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287500885, "id": "ICLR.cc/2017/conference/-/paper610/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sks9_ajex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper610/reviewers", "ICLR.cc/2017/conference/paper610/areachairs"], "cdate": 1485287500885}}}, {"tddate": null, "tmdate": 1484950845124, "tcdate": 1484950845124, "number": 10, "id": "SyrB6bxDl", "invitation": "ICLR.cc/2017/conference/-/paper610/public/comment", "forum": "Sks9_ajex", "replyto": "HkGl0JXrl", "signatures": ["~Sergey_Zagoruyko1"], "readers": ["everyone"], "writers": ["~Sergey_Zagoruyko1"], "content": {"title": "Update", "comment": "We updated the paper with the following new experiments:\n - Activation based AT in the same conditions as grad-based AT: activation-based AT gives better results than KD or grad-based AT;\n - KD on ImageNet: we were unable to get any improvement over baseline ResNets.\n\nWe elaborate on both experiments in our corresponding responses below.\n\nAlso, the code for CIFAR and ImageNet experiments is publicly available: https://github.com/szagoruyko/attention-transfer\nWe plan to add more experiments in the future."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer", "abstract": "Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network. To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures.", "pdf": "/pdf/db088e768de05a386c4b19d7832062562661d4f7.pdf", "paperhash": "zagoruyko|paying_more_attention_to_attention_improving_the_performance_of_convolutional_neural_networks_via_attention_transfer", "conflicts": ["fb.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Sergey Zagoruyko", "Nikos Komodakis"], "authorids": ["sergey.zagoruyko@enpc.fr", "nikos.komodakis@enpc.fr"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287500885, "id": "ICLR.cc/2017/conference/-/paper610/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sks9_ajex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper610/reviewers", "ICLR.cc/2017/conference/paper610/areachairs"], "cdate": 1485287500885}}}, {"tddate": null, "tmdate": 1483043006785, "tcdate": 1483042847639, "number": 8, "id": "rJOmeeQSx", "invitation": "ICLR.cc/2017/conference/-/paper610/public/comment", "forum": "Sks9_ajex", "replyto": "H1BT0bwVe", "signatures": ["~Sergey_Zagoruyko1"], "readers": ["everyone"], "writers": ["~Sergey_Zagoruyko1"], "content": {"title": "Rebuttal answer", "comment": "Dear Reviewer,\n\nBelow are our answers:\n\nQ: The method seems to be limited to the convolutional architecture\nA: Fist, we would like to note that our method can be directly applied even to non convolutional  architectures (such as MLPs) given that our definitions of attention are also valid for such architectures. We\u2019re also currently looking into applying attention transfer for recurrent neural networks in NLP tasks. Independently of the above, we consider that the convolutional architecture is one of the most important and widely used type of network architectures (with a really huge impact on several fields). \n\nQ: The attention terminology is misleading in the paper. The proposed method really just try to distill the summed squared(or other statistics e.g. summed lp norm) of  activations in a hidden feature map.\nA: We respectfully disagree with this statement. In our view a spatial attention map is supposed to indicate how important each spatial location of the input layer (or of an intermediate layer) is w.r.t. the output computed by the network (in other words, roughly how much focus the network puts per spatial location). Here we provide two simple ways of defining such an attention map, an activation based one and a gradient based one.\n\nQ: The gradient-based attention transfer seems out-of-place. The proposed gradient-based methods are never compared directly to nor are used jointly with the \"attention-based\" transfer. It seems like a parallel idea added to the paper that does not seem to add much value.\nA: A main contribution of this work is the idea that attention transfer can be very useful for improving the performance of a network. We therefore wanted to show that this is indeed true even when using different ways for defining attention, which is why we included results for both activation based and gradient based attention. Nevertheless we agree that it will be useful to compare the  two methods under the same conditions, and, to that end, we are going to update the paper with new experiments.\n\nQ: It is also not clear how the induced 2-norms in eq.(2) is computed. Q is a matrix \\in \\mathbb{R}^{H \\times W}  whose induced 2-norm is its largest singular value. It seems computationally expensive to compute such cost function. Is it possible the authors really mean the Frobenius norm?\nA: Sorry for the confusion, it is indeed a Frobenius norm. Essentially, in eq. (2)  we consider that all attention maps are in vectorized form, in which case the standard norm notation for vectors applies. We have updated the paper respectively.\n\nThanks."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer", "abstract": "Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network. To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures.", "pdf": "/pdf/db088e768de05a386c4b19d7832062562661d4f7.pdf", "paperhash": "zagoruyko|paying_more_attention_to_attention_improving_the_performance_of_convolutional_neural_networks_via_attention_transfer", "conflicts": ["fb.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Sergey Zagoruyko", "Nikos Komodakis"], "authorids": ["sergey.zagoruyko@enpc.fr", "nikos.komodakis@enpc.fr"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287500885, "id": "ICLR.cc/2017/conference/-/paper610/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sks9_ajex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper610/reviewers", "ICLR.cc/2017/conference/paper610/areachairs"], "cdate": 1485287500885}}}, {"tddate": null, "tmdate": 1483042981461, "tcdate": 1483042981461, "number": 9, "id": "By6ieemHg", "invitation": "ICLR.cc/2017/conference/-/paper610/public/comment", "forum": "Sks9_ajex", "replyto": "H1NPJoPNg", "signatures": ["~Sergey_Zagoruyko1"], "readers": ["everyone"], "writers": ["~Sergey_Zagoruyko1"], "content": {"title": "Rebuttal answer", "comment": "Dear Reviewer,\n\nBelow is our answer:\n\nQ: However, the experiments don\u2019t show a big improvement compared with knowledge distillation alone and I think more experiments are required in IMAGENET section.\nA: We\u2019ve updated the paper with an ImageNet experiment where we used two attention losses and trained  from scratch, and got 1.1%/0.8% top1/top5 accuracy improvement over baseline ResNet-18, ~30% reduction in error difference between teacher and student. We think that this is a remarkable result, considering our very limited computational resources (8 GPUs), and are sure it could be easily further improved by using more AT losses, tuning hyperparameters, or using more powerful teachers.\nWe are currently running experiments with:\n1. \tAll four AT losses, one for each group of residual blocks;\n2. \tKD baseline;\nand will update the paper as soon as we get the results.\n\nThanks."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer", "abstract": "Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network. To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures.", "pdf": "/pdf/db088e768de05a386c4b19d7832062562661d4f7.pdf", "paperhash": "zagoruyko|paying_more_attention_to_attention_improving_the_performance_of_convolutional_neural_networks_via_attention_transfer", "conflicts": ["fb.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Sergey Zagoruyko", "Nikos Komodakis"], "authorids": ["sergey.zagoruyko@enpc.fr", "nikos.komodakis@enpc.fr"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287500885, "id": "ICLR.cc/2017/conference/-/paper610/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sks9_ajex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper610/reviewers", "ICLR.cc/2017/conference/paper610/areachairs"], "cdate": 1485287500885}}}, {"tddate": null, "tmdate": 1483042626483, "tcdate": 1483042282201, "number": 6, "id": "HkGl0JXrl", "invitation": "ICLR.cc/2017/conference/-/paper610/public/comment", "forum": "Sks9_ajex", "replyto": "Sks9_ajex", "signatures": ["~Sergey_Zagoruyko1"], "readers": ["everyone"], "writers": ["~Sergey_Zagoruyko1"], "content": {"title": "Answer to reviewers", "comment": "We would like to thank the reviewers for their comments and for providing us with valuable feedback. We already updated the paper with new results on ImageNet, and are also going to further update the paper based on the reviewer comments as explained in our responses below.\nWe also plan to release the code for our experiments next week."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer", "abstract": "Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network. To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures.", "pdf": "/pdf/db088e768de05a386c4b19d7832062562661d4f7.pdf", "paperhash": "zagoruyko|paying_more_attention_to_attention_improving_the_performance_of_convolutional_neural_networks_via_attention_transfer", "conflicts": ["fb.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Sergey Zagoruyko", "Nikos Komodakis"], "authorids": ["sergey.zagoruyko@enpc.fr", "nikos.komodakis@enpc.fr"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287500885, "id": "ICLR.cc/2017/conference/-/paper610/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sks9_ajex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper610/reviewers", "ICLR.cc/2017/conference/paper610/areachairs"], "cdate": 1485287500885}}}, {"tddate": null, "tmdate": 1483042537338, "tcdate": 1483042537338, "number": 7, "id": "BJWekg7Sx", "invitation": "ICLR.cc/2017/conference/-/paper610/public/comment", "forum": "Sks9_ajex", "replyto": "HyiC5efNg", "signatures": ["~Sergey_Zagoruyko1"], "readers": ["everyone"], "writers": ["~Sergey_Zagoruyko1"], "content": {"title": "Rebuttal answer", "comment": "Dear Reviewer,\n\nBelow are our answers:\n\nQ: in section 3 authors claim that networks with higher accuracy have a higher spatial correlation between the object and the attention map. While Figure 4 is compelling, it would be nice to have quantitative results showing that as well.\nA: Thanks for the suggestion. We are going to try to look into how to do that for the VOC or COCO dataset. However, it should be noted that this is in fact a not so trivial task (e.g., due to the need of bounding box or segmentation mask annotations, due to the need to deal with overlapping objects etc.)\n\nQ: how did you choose the hyperparameter values, it would be nice to see what is the impact of $\\beta$.\nA: We found our method to be quite stable with respect to different values of beta, i.e. in all our experiments we observed that there\u2019s typically a wide range of values which give improvements close to optimal;\n\nQ: it would be nice to report teacher train and validation loss in Figure 7 b)\nA: Thanks, we are going to add this;\n\nQ: from the experiments, it is not clear what at the pros/cons of the different attention maps\nA: We are currently running attention transfer experiments using grad-based and activation-based attention maps under the same conditions, and going to update the paper as soon as we have the results;\n\nQ: AT does not lead to better result than the teacher. However, the student networks have less parameters. It would be interesting to characterise the corresponding speed-up. If you keep the same architecture between the student and the teacher, is there any benefit to the attention transfer?\nA: The baselines we choose have very different numbers of parameters, thus making it very difficult for student to have better or even the same accuracy as teacher, as network performance largely depends on this number. This was shown in a number of recent works, including our Wide ResNet paper. It can be shown though that AT leads to drastic improvements in speed and number of parameters needed to achieve the same accuracy. For example, to achieve 7.5% on CIFAR-10 one would need a ResNet with 300k (e.g. WRN-16-1.3) parameters, whereas AT+KD achieves it with only 160k parameters, resulting in about 2x less parameters and a much more efficient network;\n \nQ: Somewhat incremental novelty relatively to Fitnet\nA: We would like to note that one main goal/contribution of this work is to convey the idea that the use of attention transfer during training can be an important factor for improving a network\u2019s performance.  In a case like this, the student is forced to mimic only a small \u201csummary\u201d of the teacher\u2019s data, as opposed to FitNets that try to mimic the full activation maps. Yet we show that our method achieves much better results, which we consider as a very interesting finding.\n \nThanks."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer", "abstract": "Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network. To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures.", "pdf": "/pdf/db088e768de05a386c4b19d7832062562661d4f7.pdf", "paperhash": "zagoruyko|paying_more_attention_to_attention_improving_the_performance_of_convolutional_neural_networks_via_attention_transfer", "conflicts": ["fb.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Sergey Zagoruyko", "Nikos Komodakis"], "authorids": ["sergey.zagoruyko@enpc.fr", "nikos.komodakis@enpc.fr"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287500885, "id": "ICLR.cc/2017/conference/-/paper610/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sks9_ajex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper610/reviewers", "ICLR.cc/2017/conference/paper610/areachairs"], "cdate": 1485287500885}}}, {"tddate": null, "tmdate": 1482301276344, "tcdate": 1482301276344, "number": 3, "id": "H1NPJoPNg", "invitation": "ICLR.cc/2017/conference/-/paper610/official/review", "forum": "Sks9_ajex", "replyto": "Sks9_ajex", "signatures": ["ICLR.cc/2017/conference/paper610/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper610/AnonReviewer3"], "content": {"title": "official review", "rating": "6: Marginally above acceptance threshold", "review": "The paper proposes a new way of transferring knowledge.\nI like the idea of transferring attention maps instead of activations.\nHowever, the experiments don\u2019t show a big improvement compared with knowledge distillation alone and I think more experiments are required in IMAGENET section.\nI would consider updating the score if the authors extend the last section 4.2.2.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer", "abstract": "Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network. To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures.", "pdf": "/pdf/db088e768de05a386c4b19d7832062562661d4f7.pdf", "paperhash": "zagoruyko|paying_more_attention_to_attention_improving_the_performance_of_convolutional_neural_networks_via_attention_transfer", "conflicts": ["fb.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Sergey Zagoruyko", "Nikos Komodakis"], "authorids": ["sergey.zagoruyko@enpc.fr", "nikos.komodakis@enpc.fr"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512525389, "id": "ICLR.cc/2017/conference/-/paper610/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper610/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper610/AnonReviewer1", "ICLR.cc/2017/conference/paper610/AnonReviewer2", "ICLR.cc/2017/conference/paper610/AnonReviewer3"], "reply": {"forum": "Sks9_ajex", "replyto": "Sks9_ajex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper610/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper610/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512525389}}}, {"tddate": null, "tmdate": 1481931475159, "tcdate": 1481931475159, "number": 1, "id": "HyiC5efNg", "invitation": "ICLR.cc/2017/conference/-/paper610/official/review", "forum": "Sks9_ajex", "replyto": "Sks9_ajex", "signatures": ["ICLR.cc/2017/conference/paper610/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper610/AnonReviewer1"], "content": {"title": "Some nice results, but it is not clear what are the advantages/drawbacks of the different attention maps", "rating": "6: Marginally above acceptance threshold", "review": "This paper proposes to investigate attention transfers between a teacher and a student network. \n\nAttention transfer is performed by minimising the l2 distance between the teacher/student attention maps at different layers, in addition to minimising the classification loss and optionally a knowledge distillation term.\nAuthors define several activation based attentions (sum of absolute feature values raise at the power p or max of values raised at the power p). They also propose a gradient based attention (derivative of the Loss w.r.t. inputs). \n\nThey evaluate their approaches on several datasets (CIFAR, Cub/Scene, Imagenet) showing that attention transfers  does help improving the student network test performance.  However, the student networks performs worst than the teacher, even with attention.\n\nFew remarks/questions:\n- in section 3 authors  claim that networks with higher accuracy have a higher spatial correlation between the object and the attention map. While Figure 4 is compelling, it would be nice to have quantitative results showing that as well.\n- how did you choose the hyperparameter values, it would be nice to see what is the impact of $\\beta$.\n- it would be nice to report teacher train and validation loss in Figure 7 b)\n- from the experiments, it is not clear what at the pros/cons of the different attention maps\n- AT does not lead to better result than the teacher. However, the student networks have less parameters. It would be interesting to characterise the corresponding speed-up. If you keep the same architecture between the student and the teacher, is there any benefit to the attention transfer?\n\nIn summary:\nPros:\n- Clearly written and well motivated.\n- Consistent improvement of the student with attention compared to the student alone.\nCons:\n- Students have worst performances than the teacher models.\n- It is not clear which attention to use in which case?\n- Somewhat incremental novelty relatively to Fitnet\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer", "abstract": "Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network. To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures.", "pdf": "/pdf/db088e768de05a386c4b19d7832062562661d4f7.pdf", "paperhash": "zagoruyko|paying_more_attention_to_attention_improving_the_performance_of_convolutional_neural_networks_via_attention_transfer", "conflicts": ["fb.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Sergey Zagoruyko", "Nikos Komodakis"], "authorids": ["sergey.zagoruyko@enpc.fr", "nikos.komodakis@enpc.fr"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512525389, "id": "ICLR.cc/2017/conference/-/paper610/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper610/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper610/AnonReviewer1", "ICLR.cc/2017/conference/paper610/AnonReviewer2", "ICLR.cc/2017/conference/paper610/AnonReviewer3"], "reply": {"forum": "Sks9_ajex", "replyto": "Sks9_ajex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper610/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper610/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512525389}}}, {"tddate": null, "tmdate": 1481542327850, "tcdate": 1481542327842, "number": 5, "id": "HkepqW3Qx", "invitation": "ICLR.cc/2017/conference/-/paper610/public/comment", "forum": "Sks9_ajex", "replyto": "SJNA9asQe", "signatures": ["~Sergey_Zagoruyko1"], "readers": ["everyone"], "writers": ["~Sergey_Zagoruyko1"], "content": {"title": "Answer", "comment": "Hi Zehao,\n\nIn case of ReLU, absolute can indeed be omitted, e.g. in NIN we compute attention after ReLU. In ResNets we use outputs of residual blocks x + F(x) which are not strictly nonnegative, so absolute is needed.\n\nSergey."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer", "abstract": "Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network. To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures.", "pdf": "/pdf/db088e768de05a386c4b19d7832062562661d4f7.pdf", "paperhash": "zagoruyko|paying_more_attention_to_attention_improving_the_performance_of_convolutional_neural_networks_via_attention_transfer", "conflicts": ["fb.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Sergey Zagoruyko", "Nikos Komodakis"], "authorids": ["sergey.zagoruyko@enpc.fr", "nikos.komodakis@enpc.fr"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287500885, "id": "ICLR.cc/2017/conference/-/paper610/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sks9_ajex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper610/reviewers", "ICLR.cc/2017/conference/paper610/areachairs"], "cdate": 1485287500885}}}, {"tddate": null, "tmdate": 1481526005772, "tcdate": 1481525964091, "number": 4, "id": "SJNA9asQe", "invitation": "ICLR.cc/2017/conference/-/paper610/public/comment", "forum": "Sks9_ajex", "replyto": "Sks9_ajex", "signatures": ["~Zehao_Huang1"], "readers": ["everyone"], "writers": ["~Zehao_Huang1"], "content": {"title": "the definition of activation tensor", "comment": "Hi, Sergey.\n\nI am confused about the definition of activation tensor in section 3.1.\n\nIs it obtained before or after ReLU activation function?\n\nIf it's got after ReLu, there is no need adding absolute function.\n\nThanks!"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer", "abstract": "Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network. To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures.", "pdf": "/pdf/db088e768de05a386c4b19d7832062562661d4f7.pdf", "paperhash": "zagoruyko|paying_more_attention_to_attention_improving_the_performance_of_convolutional_neural_networks_via_attention_transfer", "conflicts": ["fb.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Sergey Zagoruyko", "Nikos Komodakis"], "authorids": ["sergey.zagoruyko@enpc.fr", "nikos.komodakis@enpc.fr"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287500885, "id": "ICLR.cc/2017/conference/-/paper610/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sks9_ajex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper610/reviewers", "ICLR.cc/2017/conference/paper610/areachairs"], "cdate": 1485287500885}}}, {"tddate": null, "tmdate": 1481474593141, "tcdate": 1481473674270, "number": 3, "id": "B1M9AljQe", "invitation": "ICLR.cc/2017/conference/-/paper610/public/comment", "forum": "Sks9_ajex", "replyto": "BJa9Fl0zx", "signatures": ["~Sergey_Zagoruyko1"], "readers": ["everyone"], "writers": ["~Sergey_Zagoruyko1"], "content": {"title": "answer", "comment": "Thanks for the questions, they were indeed very helpful and we updated the paper with new experiments and better explanations. Below are our answers:\n\n1) It is unclear how batch normalization should work with double backpropagation. So far we tried to fix it on second bprop, and couldn\u2019t reproduce the behaviour of a network without batch normalization. Maybe a better way would be do a fprop+bprop+double bprop with fixed statistics after a normal fprop+bprop, but we haven\u2019t tried that yet. We mention this in the updated version.\n\n2) Right, they have a similar effect, both AT and full-activation transfer (similar to FitNets) speed up training significantly (see figure 7b in the updated paper), but AT gives better final accuracy.\n\nSince the setup is quite different from original FitNets paper, we tried to do full-activation transfer with 1x1 convolutional layers to match tensor shapes, and l_2 normalization. We added these results to the paper. For ResNets the improvements from such approach are minimal (see table 1 in the updated paper, F-ActT column), and for NIN the improvement is slightly better, which aligns with FitNet results since the architecture is more similar.\n\n3) It is difficult to compare the two, because teacher information is propagated from an opposite side of the network in gradient attention transfer, still it\u2019s able to improve student as much. We think that gradient attention transfer could be improved by making teacher gradient information less noisy and more stable. We actually tried to aggregate gradients from several teacher evaluations, and this seems to improve gradient attention transfer already, but we didn\u2019t include this due to lack of space.\n\n4) We set it to ~0.1, 10^3 divided by the number of elements in attention map and batch size. We tried to decay it, it doesn\u2019t improve results when only AT or full-activation transfer (similar to FitNet) used, but is needed to combine well with KD. We mention this in the updated version."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer", "abstract": "Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network. To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures.", "pdf": "/pdf/db088e768de05a386c4b19d7832062562661d4f7.pdf", "paperhash": "zagoruyko|paying_more_attention_to_attention_improving_the_performance_of_convolutional_neural_networks_via_attention_transfer", "conflicts": ["fb.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Sergey Zagoruyko", "Nikos Komodakis"], "authorids": ["sergey.zagoruyko@enpc.fr", "nikos.komodakis@enpc.fr"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287500885, "id": "ICLR.cc/2017/conference/-/paper610/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sks9_ajex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper610/reviewers", "ICLR.cc/2017/conference/paper610/areachairs"], "cdate": 1485287500885}}}, {"tddate": null, "tmdate": 1481473057123, "tcdate": 1481473057118, "number": 2, "id": "ryK73xsXl", "invitation": "ICLR.cc/2017/conference/-/paper610/public/comment", "forum": "Sks9_ajex", "replyto": "HJxWd9JQg", "signatures": ["~Sergey_Zagoruyko1"], "readers": ["everyone"], "writers": ["~Sergey_Zagoruyko1"], "content": {"title": "answer", "comment": "Sorry for the ambiguous notation, the operations are in fact element-wise, so it\u2019s not a matrix norm. We updated the paper to reflect this."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer", "abstract": "Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network. To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures.", "pdf": "/pdf/db088e768de05a386c4b19d7832062562661d4f7.pdf", "paperhash": "zagoruyko|paying_more_attention_to_attention_improving_the_performance_of_convolutional_neural_networks_via_attention_transfer", "conflicts": ["fb.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Sergey Zagoruyko", "Nikos Komodakis"], "authorids": ["sergey.zagoruyko@enpc.fr", "nikos.komodakis@enpc.fr"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287500885, "id": "ICLR.cc/2017/conference/-/paper610/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "Sks9_ajex", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper610/reviewers", "ICLR.cc/2017/conference/paper610/areachairs"], "cdate": 1485287500885}}}, {"tddate": null, "tmdate": 1480726519746, "tcdate": 1480726519741, "number": 2, "id": "HJxWd9JQg", "invitation": "ICLR.cc/2017/conference/-/paper610/pre-review/question", "forum": "Sks9_ajex", "replyto": "Sks9_ajex", "signatures": ["ICLR.cc/2017/conference/paper610/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper610/AnonReviewer2"], "content": {"title": "Notation question", "question": "F is a mapping from a 3 tensor to a matrix defined in Eq. (1). So I assume I assume the Lp norm in Eq. (2) is in fact matrix norm. So the question is do you solve for the largest eigenvalue of F(A)^T F(A) in order to normalize the attention map F(A) ? \n\nAlso are the absolute value notations in section 3.1 element-wise or matrix-wise? "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer", "abstract": "Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network. To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures.", "pdf": "/pdf/db088e768de05a386c4b19d7832062562661d4f7.pdf", "paperhash": "zagoruyko|paying_more_attention_to_attention_improving_the_performance_of_convolutional_neural_networks_via_attention_transfer", "conflicts": ["fb.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Sergey Zagoruyko", "Nikos Komodakis"], "authorids": ["sergey.zagoruyko@enpc.fr", "nikos.komodakis@enpc.fr"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959188146, "id": "ICLR.cc/2017/conference/-/paper610/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper610/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper610/AnonReviewer1", "ICLR.cc/2017/conference/paper610/AnonReviewer2"], "reply": {"forum": "Sks9_ajex", "replyto": "Sks9_ajex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper610/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper610/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959188146}}}, {"tddate": null, "tmdate": 1480620436977, "tcdate": 1480620436971, "number": 1, "id": "BJa9Fl0zx", "invitation": "ICLR.cc/2017/conference/-/paper610/pre-review/question", "forum": "Sks9_ajex", "replyto": "Sks9_ajex", "signatures": ["ICLR.cc/2017/conference/paper610/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper610/AnonReviewer1"], "content": {"title": "Pre review questions", "question": "Here are a few short pre-review questions\n\n1) Why don't you use the same settings for the activation-based and gradient-based attention transfer on the CIFAR-10, it would be nice to compare those two approaches as it not clear what are their relative advantages/drawbacks.\n\n2) Intermediate hints in Fitnet have been introduced to ease the optimization of the student network. It would be nice to see if the attention transfer have similar effect, or if it provide more benefits in term of generalization.\n\nAlso, you mention that you have experimented with Fitnet hint. It would be nice to report the obtained results, and do a comparison with your activation-based attention transfer as the two approaches are close.\n\n3) Gradient attention transfer does not seems to improve upon knowledge distillation in Table 3. Do you have an intuition explaining this result?\n\n4) What value are you using for the hyperparameter \\beta (controlling the attention transfer cost). Did you try decaying it during training?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"TL;DR": "", "title": "Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer", "abstract": "Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network. To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures.", "pdf": "/pdf/db088e768de05a386c4b19d7832062562661d4f7.pdf", "paperhash": "zagoruyko|paying_more_attention_to_attention_improving_the_performance_of_convolutional_neural_networks_via_attention_transfer", "conflicts": ["fb.com"], "keywords": ["Computer vision", "Deep learning", "Supervised Learning"], "authors": ["Sergey Zagoruyko", "Nikos Komodakis"], "authorids": ["sergey.zagoruyko@enpc.fr", "nikos.komodakis@enpc.fr"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1480959188146, "id": "ICLR.cc/2017/conference/-/paper610/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper610/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper610/AnonReviewer1", "ICLR.cc/2017/conference/paper610/AnonReviewer2"], "reply": {"forum": "Sks9_ajex", "replyto": "Sks9_ajex", "writers": {"values-regex": "ICLR.cc/2017/conference/paper610/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper610/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1480959188146}}}], "count": 19}