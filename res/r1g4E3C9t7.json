{"notes": [{"id": "r1g4E3C9t7", "original": "rkeToK69tQ", "number": 1439, "cdate": 1538087979594, "ddate": null, "tcdate": 1538087979594, "tmdate": 1551761328335, "tddate": null, "forum": "r1g4E3C9t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Characterizing Audio Adversarial Examples Using Temporal Dependency", "abstract": "Recent studies have highlighted adversarial examples as a ubiquitous threat to different neural network models and many downstream  applications. Nonetheless, as unique data properties have inspired distinct and powerful learning principles, this paper aims to explore their potentials towards mitigating adversarial inputs. In particular, our results reveal the importance of using the temporal dependency in audio data to gain discriminate power against adversarial examples. Tested on the automatic speech recognition (ASR) tasks and three recent audio adversarial attacks, we find that (i) input transformation developed from image adversarial defense provides limited robustness improvement and is subtle to advanced attacks; (ii) temporal dependency can be exploited to gain discriminative power against audio adversarial examples and is resistant to adaptive attacks considered in our experiments. Our results not only show promising means of improving the robustness of ASR systems, but also offer novel insights in exploiting domain-specific data properties to mitigate negative effects of adversarial examples.", "keywords": ["audio adversarial example", "mitigation", "detection", "machine learning"], "authorids": ["lucas110550@sjtu.edu.cn", "lxbosky@gmail.com", "pin-yu.chen@ibm.com", "dawnsong@gmail.com"], "authors": ["Zhuolin Yang", "Bo Li", "Pin-Yu Chen", "Dawn Song"], "TL;DR": "Adversarial audio discrimination using temporal dependency", "pdf": "/pdf/312fc5f40208f39aa6860b54ece6696cd4397424.pdf", "paperhash": "yang|characterizing_audio_adversarial_examples_using_temporal_dependency", "_bibtex": "@inproceedings{\nyang2018characterizing,\ntitle={Characterizing Audio Adversarial Examples Using Temporal Dependency},\nauthor={Zhuolin Yang and Bo Li and Pin-Yu Chen and Dawn Song},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1g4E3C9t7},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 12, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "r1lBqwjWxN", "original": null, "number": 1, "cdate": 1544824716770, "ddate": null, "tcdate": 1544824716770, "tmdate": 1545354529593, "tddate": null, "forum": "r1g4E3C9t7", "replyto": "r1g4E3C9t7", "invitation": "ICLR.cc/2019/Conference/-/Paper1439/Meta_Review", "content": {"metareview": "The authors present a study characterizing adversarial examples in the audio domain. They highlight the importance of temporal dependency when defining defense against adversarial attacks.\n\nStrengths\n- The work presents an interesting analysis of properties of audio adversarial examples, and contrasts it with those in vision literature.\n- Proposes a novel defense mechanism that is based on the idea of temporal dependency.\n\nWeaknesses\n- The technique identifies adversarial examples but is not able to make the correct prediction.\n- The reviewers raised issue around clarity, but the authors took the effort to improve the section during the revision process. \n\nThe reviewers agree that the contribution is significant and useful for the community. There are still some concerns about clarity, which the authors should consider improving in the final version. Overall, the paper received positive reviews and therefore, is recommended to be accepted to the conference.", "confidence": "5: The area chair is absolutely certain", "recommendation": "Accept (Poster)", "title": "Interesting findings about audio adversarial examples"}, "signatures": ["ICLR.cc/2019/Conference/Paper1439/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1439/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Characterizing Audio Adversarial Examples Using Temporal Dependency", "abstract": "Recent studies have highlighted adversarial examples as a ubiquitous threat to different neural network models and many downstream  applications. Nonetheless, as unique data properties have inspired distinct and powerful learning principles, this paper aims to explore their potentials towards mitigating adversarial inputs. In particular, our results reveal the importance of using the temporal dependency in audio data to gain discriminate power against adversarial examples. Tested on the automatic speech recognition (ASR) tasks and three recent audio adversarial attacks, we find that (i) input transformation developed from image adversarial defense provides limited robustness improvement and is subtle to advanced attacks; (ii) temporal dependency can be exploited to gain discriminative power against audio adversarial examples and is resistant to adaptive attacks considered in our experiments. Our results not only show promising means of improving the robustness of ASR systems, but also offer novel insights in exploiting domain-specific data properties to mitigate negative effects of adversarial examples.", "keywords": ["audio adversarial example", "mitigation", "detection", "machine learning"], "authorids": ["lucas110550@sjtu.edu.cn", "lxbosky@gmail.com", "pin-yu.chen@ibm.com", "dawnsong@gmail.com"], "authors": ["Zhuolin Yang", "Bo Li", "Pin-Yu Chen", "Dawn Song"], "TL;DR": "Adversarial audio discrimination using temporal dependency", "pdf": "/pdf/312fc5f40208f39aa6860b54ece6696cd4397424.pdf", "paperhash": "yang|characterizing_audio_adversarial_examples_using_temporal_dependency", "_bibtex": "@inproceedings{\nyang2018characterizing,\ntitle={Characterizing Audio Adversarial Examples Using Temporal Dependency},\nauthor={Zhuolin Yang and Bo Li and Pin-Yu Chen and Dawn Song},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1g4E3C9t7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1439/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352838854, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1g4E3C9t7", "replyto": "r1g4E3C9t7", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1439/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1439/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1439/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352838854}}}, {"id": "SJxUvUaK27", "original": null, "number": 1, "cdate": 1541162589937, "ddate": null, "tcdate": 1541162589937, "tmdate": 1543487350985, "tddate": null, "forum": "r1g4E3C9t7", "replyto": "r1g4E3C9t7", "invitation": "ICLR.cc/2019/Conference/-/Paper1439/Official_Review", "content": {"title": "Review", "review": "This paper investigates adversarial examples for audio data. The standard defense techniques proposed for images are studied in the context of audio. It is shown that these techniques are somewhat robust to adversarial attacks, but fail against adaptive attacks. A method exploiting the temporal dependencies of the data is then presented and shown to be robust to adversarial examples and to adaptive attacks.\n\nThe paper addresses an important issue, and the two main findings of the paper, the transformation methods used in computer vision are not useful against audio adversarial example and using temporal dependencies improves the defense capability are significant. The proposed TD method is novel.\n\nThe first part of the paper is easy to read (Section 1-3), but Section 4 is hard to follow, for the following reasons:\n* Section 4.1 presents the metrics used in the evaluation, which is nice. But in the following subsections, other metrics are used: effectiveness ratio, detection rate and relative perturbation. They should be clearly defined in 4.1, and the authors should discuss why they used these metrics.\n* Section 4.2 should be reorganized as it is hard to follow: there are three types of attack, so one subsection per attack should make the section clearer.\n* It's not always clear what each attack is doing and why it is used. I suggest the authors to have a separate subsection with the description of each attack and the motivation of why it is used.\n\nBecause of the above, it's hard to clearly assess the performance of each method for each attack, it would be better to have a Table that summarizes the results for the transformation methods. Also, I don't understand the statement in 4.2: \"We report that the autoencoder works fine for transforming benign instances (57.6% WER in Common Voice compared to 27.5%)\": given that it's not an attack, the PER should be the same with and without transform, as we don't want the transform to affect non-adversarial examples ? Please clarify that.\nThe experiments on the proposed TD method are clear enough to show the viability of the approach.\n\nOverall, the findings of this paper are significant and it is good step towards audio adversarial examples defense. But the experimental part is hard to follow and does not bring a clear picture. I am still willing to accept the paper if the authors improve and clarify Section 4.\n\nRevision after rebuttal:\nThe new version is definitely clearer and easier to read, hence I support the paper for acceptance and change my rating to 7. \nThere are still minor improvements that can be done in Section 4 to improve the overall clarity:\n* About the metrics, the \"Average attack success rate\" and the \"Target command recognition rate\" should be clearly defined, probably under the description of the attack methods.\n* The Adaptive attack approach could be introduced unter \"Attack methods\" in 4.1.\n* Table 4 is not easy to read, the authors should improve it.\n* The first paragraph in Section 4 (\"The presentation flows ...\") is very interesting, but almost reads like a conclusion, so maybe the authors could move that to the end of Section 4 or to Section 5.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1439/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Characterizing Audio Adversarial Examples Using Temporal Dependency", "abstract": "Recent studies have highlighted adversarial examples as a ubiquitous threat to different neural network models and many downstream  applications. Nonetheless, as unique data properties have inspired distinct and powerful learning principles, this paper aims to explore their potentials towards mitigating adversarial inputs. In particular, our results reveal the importance of using the temporal dependency in audio data to gain discriminate power against adversarial examples. Tested on the automatic speech recognition (ASR) tasks and three recent audio adversarial attacks, we find that (i) input transformation developed from image adversarial defense provides limited robustness improvement and is subtle to advanced attacks; (ii) temporal dependency can be exploited to gain discriminative power against audio adversarial examples and is resistant to adaptive attacks considered in our experiments. Our results not only show promising means of improving the robustness of ASR systems, but also offer novel insights in exploiting domain-specific data properties to mitigate negative effects of adversarial examples.", "keywords": ["audio adversarial example", "mitigation", "detection", "machine learning"], "authorids": ["lucas110550@sjtu.edu.cn", "lxbosky@gmail.com", "pin-yu.chen@ibm.com", "dawnsong@gmail.com"], "authors": ["Zhuolin Yang", "Bo Li", "Pin-Yu Chen", "Dawn Song"], "TL;DR": "Adversarial audio discrimination using temporal dependency", "pdf": "/pdf/312fc5f40208f39aa6860b54ece6696cd4397424.pdf", "paperhash": "yang|characterizing_audio_adversarial_examples_using_temporal_dependency", "_bibtex": "@inproceedings{\nyang2018characterizing,\ntitle={Characterizing Audio Adversarial Examples Using Temporal Dependency},\nauthor={Zhuolin Yang and Bo Li and Pin-Yu Chen and Dawn Song},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1g4E3C9t7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1439/Official_Review", "cdate": 1542234229369, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "r1g4E3C9t7", "replyto": "r1g4E3C9t7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1439/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335947209, "tmdate": 1552335947209, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1439/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HyxdLrxcCQ", "original": null, "number": 6, "cdate": 1543271759752, "ddate": null, "tcdate": 1543271759752, "tmdate": 1543271802941, "tddate": null, "forum": "r1g4E3C9t7", "replyto": "SJxUvUaK27", "invitation": "ICLR.cc/2019/Conference/-/Paper1439/Official_Comment", "content": {"title": "Our response to Reviewer 1", "comment": "Thanks for your insightful comments.\n\nQ: hard to understand Section 4:\nA: We apologize that we did not put enough efforts in presenting the experimental results in Section 4. Based on the review comments, we have reorganized and revised Section 4 to make the presentation clearer, including adding new tables  (Tables 1 & 4) that highlight the overall structure of our attack & defense / detection.\n\n\nQ: Also, I don't understand the statement in 4.2: \"We report that the autoencoder works fine for transforming benign instances (57.6% WER in Common Voice compared to 27.5%)\": given that it's not an attack, the WER should be the same with and without transform, as we don't want the transform to affect non-adversarial examples ? \nA: We agree with the reviewer that in this setting an \u201cideal\u201d autoencoder would not affect the performance of benign examples and will mitigative the negative effects of adversarial examples. However, in our experiments, we were not able to find such an ideal autoencoder.\nGiven the reconstruction nature of autoencoder based on the training data, here we aim to do an ablation study to make sure that the applied transformation will not affect the translation results of benign instance too much. And there appears to be a tradeoff between accuracy and robustness. \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1439/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1439/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1439/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Characterizing Audio Adversarial Examples Using Temporal Dependency", "abstract": "Recent studies have highlighted adversarial examples as a ubiquitous threat to different neural network models and many downstream  applications. Nonetheless, as unique data properties have inspired distinct and powerful learning principles, this paper aims to explore their potentials towards mitigating adversarial inputs. In particular, our results reveal the importance of using the temporal dependency in audio data to gain discriminate power against adversarial examples. Tested on the automatic speech recognition (ASR) tasks and three recent audio adversarial attacks, we find that (i) input transformation developed from image adversarial defense provides limited robustness improvement and is subtle to advanced attacks; (ii) temporal dependency can be exploited to gain discriminative power against audio adversarial examples and is resistant to adaptive attacks considered in our experiments. Our results not only show promising means of improving the robustness of ASR systems, but also offer novel insights in exploiting domain-specific data properties to mitigate negative effects of adversarial examples.", "keywords": ["audio adversarial example", "mitigation", "detection", "machine learning"], "authorids": ["lucas110550@sjtu.edu.cn", "lxbosky@gmail.com", "pin-yu.chen@ibm.com", "dawnsong@gmail.com"], "authors": ["Zhuolin Yang", "Bo Li", "Pin-Yu Chen", "Dawn Song"], "TL;DR": "Adversarial audio discrimination using temporal dependency", "pdf": "/pdf/312fc5f40208f39aa6860b54ece6696cd4397424.pdf", "paperhash": "yang|characterizing_audio_adversarial_examples_using_temporal_dependency", "_bibtex": "@inproceedings{\nyang2018characterizing,\ntitle={Characterizing Audio Adversarial Examples Using Temporal Dependency},\nauthor={Zhuolin Yang and Bo Li and Pin-Yu Chen and Dawn Song},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1g4E3C9t7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1439/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621608529, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1g4E3C9t7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1439/Authors", "ICLR.cc/2019/Conference/Paper1439/Reviewers", "ICLR.cc/2019/Conference/Paper1439/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1439/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1439/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1439/Authors|ICLR.cc/2019/Conference/Paper1439/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1439/Reviewers", "ICLR.cc/2019/Conference/Paper1439/Authors", "ICLR.cc/2019/Conference/Paper1439/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621608529}}}, {"id": "HJeScNx9CX", "original": null, "number": 5, "cdate": 1543271565008, "ddate": null, "tcdate": 1543271565008, "tmdate": 1543271565008, "tddate": null, "forum": "r1g4E3C9t7", "replyto": "SJgCwLfxa7", "invitation": "ICLR.cc/2019/Conference/-/Paper1439/Official_Comment", "content": {"title": "Our response to Reviewer 2", "comment": "Thanks for your constructive comments.\n\nQ: writing in Section 4\nA: We apologize that we did not put enough efforts in presenting the experimental results in Section 4. Based on the review comments, we have reorganized and revised Section 4 to make the presentation clearer, including adding new tables (Tables 1 & 4) that highlight the overall structure of our attack & defense / detection.\n\n\nQ: prefix of length k\nA: Thanks for the precious suggestion and we modified the name as you suggested in the revised version.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1439/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1439/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1439/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Characterizing Audio Adversarial Examples Using Temporal Dependency", "abstract": "Recent studies have highlighted adversarial examples as a ubiquitous threat to different neural network models and many downstream  applications. Nonetheless, as unique data properties have inspired distinct and powerful learning principles, this paper aims to explore their potentials towards mitigating adversarial inputs. In particular, our results reveal the importance of using the temporal dependency in audio data to gain discriminate power against adversarial examples. Tested on the automatic speech recognition (ASR) tasks and three recent audio adversarial attacks, we find that (i) input transformation developed from image adversarial defense provides limited robustness improvement and is subtle to advanced attacks; (ii) temporal dependency can be exploited to gain discriminative power against audio adversarial examples and is resistant to adaptive attacks considered in our experiments. Our results not only show promising means of improving the robustness of ASR systems, but also offer novel insights in exploiting domain-specific data properties to mitigate negative effects of adversarial examples.", "keywords": ["audio adversarial example", "mitigation", "detection", "machine learning"], "authorids": ["lucas110550@sjtu.edu.cn", "lxbosky@gmail.com", "pin-yu.chen@ibm.com", "dawnsong@gmail.com"], "authors": ["Zhuolin Yang", "Bo Li", "Pin-Yu Chen", "Dawn Song"], "TL;DR": "Adversarial audio discrimination using temporal dependency", "pdf": "/pdf/312fc5f40208f39aa6860b54ece6696cd4397424.pdf", "paperhash": "yang|characterizing_audio_adversarial_examples_using_temporal_dependency", "_bibtex": "@inproceedings{\nyang2018characterizing,\ntitle={Characterizing Audio Adversarial Examples Using Temporal Dependency},\nauthor={Zhuolin Yang and Bo Li and Pin-Yu Chen and Dawn Song},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1g4E3C9t7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1439/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621608529, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1g4E3C9t7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1439/Authors", "ICLR.cc/2019/Conference/Paper1439/Reviewers", "ICLR.cc/2019/Conference/Paper1439/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1439/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1439/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1439/Authors|ICLR.cc/2019/Conference/Paper1439/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1439/Reviewers", "ICLR.cc/2019/Conference/Paper1439/Authors", "ICLR.cc/2019/Conference/Paper1439/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621608529}}}, {"id": "rJejAXe907", "original": null, "number": 4, "cdate": 1543271378973, "ddate": null, "tcdate": 1543271378973, "tmdate": 1543271462091, "tddate": null, "forum": "r1g4E3C9t7", "replyto": "ryx9MuhU6Q", "invitation": "ICLR.cc/2019/Conference/-/Paper1439/Official_Comment", "content": {"title": "Our response to Review 4", "comment": "We appreciate your insightful comments and feel sorry about hard following in Section 4. Here are some response to questions you concerned and we\u2019ve uploaded new version of our paper with clearer structure.\n\nQ: My question is if the attacker uses the random sample K_A to generate the adversarial examples, then how the performance would be.\nA: Following your comment, we added the corresponding experiments in TableA7 in Appendix when k_A = rand(0.2, 0.8). We observe that even k_A is chosen randomly, the results are similar to k_A equals to a fixed number when k_D is also a random number. And when k_D is a fixed number, the attack detection results are also good because if k_A is not close to defender\u2019s k_D, the attack effectiveness will be limited. \n\nQ: Another limitation of this work is that the proposed defense can differentiate the adversarial examples to some extent, but the ASR is not able to make a right prediction for adversarial examples\nA: Yes, the proposed TD method is a detection instead of defense method, and our goal is to tell the adversarial instances apart from benign. In many scenarios, detection is very important. For instance, in malware or adversarial audio based attacks, if users can detect adversarial instances and remove or ignore them, it indeed helps to ensure system security.\n\nQ: writing in Section 4\nA: We apologize that we did not put enough efforts in presenting the experimental results in Section 4. Based on the review comments, we have reorganized and revised Section 4 to make the presentation clearer, including adding new tables (Tables 1 & 4) that highlight the overall structure of our attack & defense / detection."}, "signatures": ["ICLR.cc/2019/Conference/Paper1439/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1439/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1439/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Characterizing Audio Adversarial Examples Using Temporal Dependency", "abstract": "Recent studies have highlighted adversarial examples as a ubiquitous threat to different neural network models and many downstream  applications. Nonetheless, as unique data properties have inspired distinct and powerful learning principles, this paper aims to explore their potentials towards mitigating adversarial inputs. In particular, our results reveal the importance of using the temporal dependency in audio data to gain discriminate power against adversarial examples. Tested on the automatic speech recognition (ASR) tasks and three recent audio adversarial attacks, we find that (i) input transformation developed from image adversarial defense provides limited robustness improvement and is subtle to advanced attacks; (ii) temporal dependency can be exploited to gain discriminative power against audio adversarial examples and is resistant to adaptive attacks considered in our experiments. Our results not only show promising means of improving the robustness of ASR systems, but also offer novel insights in exploiting domain-specific data properties to mitigate negative effects of adversarial examples.", "keywords": ["audio adversarial example", "mitigation", "detection", "machine learning"], "authorids": ["lucas110550@sjtu.edu.cn", "lxbosky@gmail.com", "pin-yu.chen@ibm.com", "dawnsong@gmail.com"], "authors": ["Zhuolin Yang", "Bo Li", "Pin-Yu Chen", "Dawn Song"], "TL;DR": "Adversarial audio discrimination using temporal dependency", "pdf": "/pdf/312fc5f40208f39aa6860b54ece6696cd4397424.pdf", "paperhash": "yang|characterizing_audio_adversarial_examples_using_temporal_dependency", "_bibtex": "@inproceedings{\nyang2018characterizing,\ntitle={Characterizing Audio Adversarial Examples Using Temporal Dependency},\nauthor={Zhuolin Yang and Bo Li and Pin-Yu Chen and Dawn Song},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1g4E3C9t7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1439/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621608529, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1g4E3C9t7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1439/Authors", "ICLR.cc/2019/Conference/Paper1439/Reviewers", "ICLR.cc/2019/Conference/Paper1439/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1439/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1439/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1439/Authors|ICLR.cc/2019/Conference/Paper1439/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1439/Reviewers", "ICLR.cc/2019/Conference/Paper1439/Authors", "ICLR.cc/2019/Conference/Paper1439/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621608529}}}, {"id": "BJgFHzg90X", "original": null, "number": 3, "cdate": 1543270977500, "ddate": null, "tcdate": 1543270977500, "tmdate": 1543271040252, "tddate": null, "forum": "r1g4E3C9t7", "replyto": "r1g4E3C9t7", "invitation": "ICLR.cc/2019/Conference/-/Paper1439/Official_Comment", "content": {"title": "General Response", "comment": "We thank the reviewers for their valuable comments and suggestions. We are happy to learn that the contributions of this are well acknowledged by all reviewers. Meanwhile, we are sorry that the reviewers feel the experiment part (Section 4) is hard to follow. Based on the review comments, we have reorganized and revised Section 4 to make the presentation clearer, including adding new tables (Tables 1 & 4) that highlight the experiment settings and the overall structure of the considered attack & defense / detection.\n\nSpecifically, we made the following updates to our revision:\n1. We rewrite Section 4 to make the structure more clear. Previously, since there are too many defense and attack methods, some of which requires slightly different evaluation metrics, Section 4 can be confusing as pointed by reviewers. In our revision, we added Table 1 and Table 4 to illustrate the defense and attack methods we evaluated, as well as the corresponding evaluation metrics and brief result summary.\n2. We added additional experiments to show that even when K_A and K_D are both random, our proposed TD method can still detect different attacks with high AUC.\n3. We also added additional experiments in Appendix Table A7 according to Review 4\u2019s comments to show that even when k_A is random and k_D equals to \u00bd , \u2154, \u00be, or a random number chosen from [0.2, 0.8], our proposed TD method can still detect different attacks with high AUC.\n\nPlease don\u2019t hesitate to let us know if you have any additional comments.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1439/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1439/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1439/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Characterizing Audio Adversarial Examples Using Temporal Dependency", "abstract": "Recent studies have highlighted adversarial examples as a ubiquitous threat to different neural network models and many downstream  applications. Nonetheless, as unique data properties have inspired distinct and powerful learning principles, this paper aims to explore their potentials towards mitigating adversarial inputs. In particular, our results reveal the importance of using the temporal dependency in audio data to gain discriminate power against adversarial examples. Tested on the automatic speech recognition (ASR) tasks and three recent audio adversarial attacks, we find that (i) input transformation developed from image adversarial defense provides limited robustness improvement and is subtle to advanced attacks; (ii) temporal dependency can be exploited to gain discriminative power against audio adversarial examples and is resistant to adaptive attacks considered in our experiments. Our results not only show promising means of improving the robustness of ASR systems, but also offer novel insights in exploiting domain-specific data properties to mitigate negative effects of adversarial examples.", "keywords": ["audio adversarial example", "mitigation", "detection", "machine learning"], "authorids": ["lucas110550@sjtu.edu.cn", "lxbosky@gmail.com", "pin-yu.chen@ibm.com", "dawnsong@gmail.com"], "authors": ["Zhuolin Yang", "Bo Li", "Pin-Yu Chen", "Dawn Song"], "TL;DR": "Adversarial audio discrimination using temporal dependency", "pdf": "/pdf/312fc5f40208f39aa6860b54ece6696cd4397424.pdf", "paperhash": "yang|characterizing_audio_adversarial_examples_using_temporal_dependency", "_bibtex": "@inproceedings{\nyang2018characterizing,\ntitle={Characterizing Audio Adversarial Examples Using Temporal Dependency},\nauthor={Zhuolin Yang and Bo Li and Pin-Yu Chen and Dawn Song},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1g4E3C9t7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1439/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621608529, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1g4E3C9t7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1439/Authors", "ICLR.cc/2019/Conference/Paper1439/Reviewers", "ICLR.cc/2019/Conference/Paper1439/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1439/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1439/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1439/Authors|ICLR.cc/2019/Conference/Paper1439/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1439/Reviewers", "ICLR.cc/2019/Conference/Paper1439/Authors", "ICLR.cc/2019/Conference/Paper1439/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621608529}}}, {"id": "ryx9MuhU6Q", "original": null, "number": 3, "cdate": 1542010897786, "ddate": null, "tcdate": 1542010897786, "tmdate": 1542010897786, "tddate": null, "forum": "r1g4E3C9t7", "replyto": "r1g4E3C9t7", "invitation": "ICLR.cc/2019/Conference/-/Paper1439/Official_Review", "content": {"title": "Interesting findings but hard to fully understand the experiments.", "review": "This paper proposed a study on audio adversarial examples and conclude the input transformation-based defenses do not work very well on the audio domain, especially for adaptive attacks. They also point out the importance of temporal dependency in designing defenses which is specific for the audio domain. This observation is very interesting and inspiring as temporal dependency is an important character that should be paid attention to in the field of audio adversarial examples. They also design some adaptive attacks to the defense based on temporal dependency but either fail to attack the system or can be detected by the defense.\n\nBased on the results in Table S7, it seems like being aware of the parameter k when designing attacks are very helpful for reducing the AUC score. My question is if the attacker uses the random sample K_A to generate the adversarial examples, then how the performance would be. Another limitation of this work is that the proposed defense can differentiate the adversarial examples to some extent, but the ASR is not able to make a right prediction for adversarial examples. In addition, the writing of Section 4 is not very clear and easy to follow.\n\nIn all, this paper proposed some interesting findings and point out a very important direction for audio adversarial examples. If the author can improve the writing in experiments and answer the above questions, I would support for the acceptance.\n\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1439/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Characterizing Audio Adversarial Examples Using Temporal Dependency", "abstract": "Recent studies have highlighted adversarial examples as a ubiquitous threat to different neural network models and many downstream  applications. Nonetheless, as unique data properties have inspired distinct and powerful learning principles, this paper aims to explore their potentials towards mitigating adversarial inputs. In particular, our results reveal the importance of using the temporal dependency in audio data to gain discriminate power against adversarial examples. Tested on the automatic speech recognition (ASR) tasks and three recent audio adversarial attacks, we find that (i) input transformation developed from image adversarial defense provides limited robustness improvement and is subtle to advanced attacks; (ii) temporal dependency can be exploited to gain discriminative power against audio adversarial examples and is resistant to adaptive attacks considered in our experiments. Our results not only show promising means of improving the robustness of ASR systems, but also offer novel insights in exploiting domain-specific data properties to mitigate negative effects of adversarial examples.", "keywords": ["audio adversarial example", "mitigation", "detection", "machine learning"], "authorids": ["lucas110550@sjtu.edu.cn", "lxbosky@gmail.com", "pin-yu.chen@ibm.com", "dawnsong@gmail.com"], "authors": ["Zhuolin Yang", "Bo Li", "Pin-Yu Chen", "Dawn Song"], "TL;DR": "Adversarial audio discrimination using temporal dependency", "pdf": "/pdf/312fc5f40208f39aa6860b54ece6696cd4397424.pdf", "paperhash": "yang|characterizing_audio_adversarial_examples_using_temporal_dependency", "_bibtex": "@inproceedings{\nyang2018characterizing,\ntitle={Characterizing Audio Adversarial Examples Using Temporal Dependency},\nauthor={Zhuolin Yang and Bo Li and Pin-Yu Chen and Dawn Song},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1g4E3C9t7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1439/Official_Review", "cdate": 1542234229369, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "r1g4E3C9t7", "replyto": "r1g4E3C9t7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1439/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335947209, "tmdate": 1552335947209, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1439/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SJgCwLfxa7", "original": null, "number": 2, "cdate": 1541576293947, "ddate": null, "tcdate": 1541576293947, "tmdate": 1541576293947, "tddate": null, "forum": "r1g4E3C9t7", "replyto": "r1g4E3C9t7", "invitation": "ICLR.cc/2019/Conference/-/Paper1439/Official_Review", "content": {"title": "Important problem, reasonable evaluation, hard to follow. ", "review": "This paper presents a study of the problem of generating adversarial examples for speech processing systems. Two versions of this problem are considered: attacks against audio classification and against text to speech. The authors first study a the practice of input transformations as means of defense against adversarial examples. To do so, they evaluate three recent adversarial attacks on audio classification and TTS models trained on several datasets. It is found that input transformations have limited utility against adaptive attacks. Moreover, a novel type of defense is developed in which the prefix (of some fixed length) of the audio input is converted to text and compared with the prefix of the text output of the entire input, flagging the input as adversarial if sufficient mismatch is detected. It is found that this method is robust against a number of attacks.\n\nThis paper tackles a relevant problem and presents some surprising (the robustness of the prefix method) as well as some not surprising results. The evaluation has reasonable enough breadth to give the conclusions credibility. \n\nMy main complaint is that the exposition is somewhat hard to follow at places, especially in section 4. It is hard to keep track of which attack is applied to which scenario and what the conclusions were. Perhaps this could be summarized in some kind of high-level table. It would also be greatly beneficial if the attacks are briefly summarized somewhere. E.g., without following the references, it is completely unclear what is the \"Commander Song\" setting and what is it important. \nFinally, I would advise the authors to not use the term \"first k portion\". This made understanding their proposed defense much harder than it needed to be. Perhaps \"prefix of length k\" or something along these lines would be easier to follow. \n\nIn summary, if the authors commit to improving the clarity of the paper,  I would be willing to support its acceptance by virtue of the breadth of the investigation and the importance of the problem.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1439/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Characterizing Audio Adversarial Examples Using Temporal Dependency", "abstract": "Recent studies have highlighted adversarial examples as a ubiquitous threat to different neural network models and many downstream  applications. Nonetheless, as unique data properties have inspired distinct and powerful learning principles, this paper aims to explore their potentials towards mitigating adversarial inputs. In particular, our results reveal the importance of using the temporal dependency in audio data to gain discriminate power against adversarial examples. Tested on the automatic speech recognition (ASR) tasks and three recent audio adversarial attacks, we find that (i) input transformation developed from image adversarial defense provides limited robustness improvement and is subtle to advanced attacks; (ii) temporal dependency can be exploited to gain discriminative power against audio adversarial examples and is resistant to adaptive attacks considered in our experiments. Our results not only show promising means of improving the robustness of ASR systems, but also offer novel insights in exploiting domain-specific data properties to mitigate negative effects of adversarial examples.", "keywords": ["audio adversarial example", "mitigation", "detection", "machine learning"], "authorids": ["lucas110550@sjtu.edu.cn", "lxbosky@gmail.com", "pin-yu.chen@ibm.com", "dawnsong@gmail.com"], "authors": ["Zhuolin Yang", "Bo Li", "Pin-Yu Chen", "Dawn Song"], "TL;DR": "Adversarial audio discrimination using temporal dependency", "pdf": "/pdf/312fc5f40208f39aa6860b54ece6696cd4397424.pdf", "paperhash": "yang|characterizing_audio_adversarial_examples_using_temporal_dependency", "_bibtex": "@inproceedings{\nyang2018characterizing,\ntitle={Characterizing Audio Adversarial Examples Using Temporal Dependency},\nauthor={Zhuolin Yang and Bo Li and Pin-Yu Chen and Dawn Song},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1g4E3C9t7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1439/Official_Review", "cdate": 1542234229369, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "r1g4E3C9t7", "replyto": "r1g4E3C9t7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1439/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335947209, "tmdate": 1552335947209, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1439/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rke8d0QE3m", "original": null, "number": 2, "cdate": 1540796014451, "ddate": null, "tcdate": 1540796014451, "tmdate": 1540796067635, "tddate": null, "forum": "r1g4E3C9t7", "replyto": "BJxqwKRJ2m", "invitation": "ICLR.cc/2019/Conference/-/Paper1439/Official_Comment", "content": {"title": "reply to \"example for TEMPORAL DEPENDENCY BASED METHOD\"", "comment": "Thank you for the interesting question. \nFirst, in this work we aim to detect the state-of-the-art attacks such as [Carlini et al], and therefore we obtain their adversarial examples online directly and perform detection for the purpose of fair comparison.\nIn addition, we conduct a new set of experiments these days based on your suggestion.\nIn particular, we set the adversarial target as just modifying one single word, such as  it -> he, morning -> evening, open -> close, and perform the TD detection against them (we list some examples in the end of this answer). Overall, for 50 samples, if we choose a single k, the AUC based on WER and CER score are around 0.65, and LCP 0.7.\nWe also try to perform TD based on ensemble of k as k = (3/8, 4/8, 5/8, 6/8, 7/8} and select the maximum score among WER / CER / LCP for each k, which leads to AUC =0.832.\nThis shows that TD still performs effectively for detecting such \u201csingle word\u201d adversarial audio, though less powerful than detecting those with larger perturbation. \nThe reason is obvious by looking at the examples below. In each example, row 1 shows the translation result of the first k portion (TD), row 2 shows the \u201csingle word\u201d adversarial target (Adv), while row 3 denotes the original benign translation (Benign).\nWe can see that the perturbation of such \u201csingle word attack\u201d will only introduce inconsistency for the \u201ctarget word\u201d, and therefore reduce the gap between adversarial and benign instances. Though harder to detect, such attacks limit the adversary\u2019s attack ability in practice. If we want to detect them more effectively, better similarity metrics may be helpful, and we will explore such metrics in our future work.\n\nExamples:\n\nTD: and he [leges] against the wa lost in r\nAdv: and he [fights] against the wa lost in reveriey\nBenign: and he [leaned] against the wa lost in reveriey\n\nTD: this [perning] they all\nAdv: this [morning] they all said\nBenign: this [evening] they all said\n\nTD: they [eafned] about the fur tree and rustled among the bra\nAdv: they [learned] about the fur tree and rustled among the branches\nBenign: they [snuffed] about the fur tree and rustled among the branches\n\nTD: in the [voning] the servants and the housemaid kape\nAdv: in the [evening] the servants and the housemaid came in\nBenign: in the [morning] the servants and the housemaid came in\n\nTD: said the fur [ouse] thinking over what he had himself\nAdv: said the fur [mouse] thinking over what he had himself related\nBenign: said the fur [tree] thinking over what he had himself related\n\nTD: the [erfficer] as well as the young ladies te\nAdv: the [officer] as well as the young ladies decparated it\nBenign: the [servants] as well as the young ladies decparated it\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1439/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1439/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1439/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Characterizing Audio Adversarial Examples Using Temporal Dependency", "abstract": "Recent studies have highlighted adversarial examples as a ubiquitous threat to different neural network models and many downstream  applications. Nonetheless, as unique data properties have inspired distinct and powerful learning principles, this paper aims to explore their potentials towards mitigating adversarial inputs. In particular, our results reveal the importance of using the temporal dependency in audio data to gain discriminate power against adversarial examples. Tested on the automatic speech recognition (ASR) tasks and three recent audio adversarial attacks, we find that (i) input transformation developed from image adversarial defense provides limited robustness improvement and is subtle to advanced attacks; (ii) temporal dependency can be exploited to gain discriminative power against audio adversarial examples and is resistant to adaptive attacks considered in our experiments. Our results not only show promising means of improving the robustness of ASR systems, but also offer novel insights in exploiting domain-specific data properties to mitigate negative effects of adversarial examples.", "keywords": ["audio adversarial example", "mitigation", "detection", "machine learning"], "authorids": ["lucas110550@sjtu.edu.cn", "lxbosky@gmail.com", "pin-yu.chen@ibm.com", "dawnsong@gmail.com"], "authors": ["Zhuolin Yang", "Bo Li", "Pin-Yu Chen", "Dawn Song"], "TL;DR": "Adversarial audio discrimination using temporal dependency", "pdf": "/pdf/312fc5f40208f39aa6860b54ece6696cd4397424.pdf", "paperhash": "yang|characterizing_audio_adversarial_examples_using_temporal_dependency", "_bibtex": "@inproceedings{\nyang2018characterizing,\ntitle={Characterizing Audio Adversarial Examples Using Temporal Dependency},\nauthor={Zhuolin Yang and Bo Li and Pin-Yu Chen and Dawn Song},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1g4E3C9t7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1439/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621608529, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1g4E3C9t7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1439/Authors", "ICLR.cc/2019/Conference/Paper1439/Reviewers", "ICLR.cc/2019/Conference/Paper1439/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1439/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1439/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1439/Authors|ICLR.cc/2019/Conference/Paper1439/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1439/Reviewers", "ICLR.cc/2019/Conference/Paper1439/Authors", "ICLR.cc/2019/Conference/Paper1439/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621608529}}}, {"id": "BJxqwKRJ2m", "original": null, "number": 2, "cdate": 1540512097526, "ddate": null, "tcdate": 1540512097526, "tmdate": 1540512097526, "tddate": null, "forum": "r1g4E3C9t7", "replyto": "r1g4E3C9t7", "invitation": "ICLR.cc/2019/Conference/-/Paper1439/Public_Comment", "content": {"comment": "Hi, for TEMPORAL DEPENDENCY BASED METHOD, you only show the example that perturbs a sentence to a totally different one without any same words. However, if the adversarial attack just changing one or two keywords in the sentence, will your method still be effective? For example, perturb from \"Alex, call Tom and open the front door\" to \"Alex, call Tome and open the back door\".  ", "title": "example for TEMPORAL DEPENDENCY BASED METHOD"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1439/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Characterizing Audio Adversarial Examples Using Temporal Dependency", "abstract": "Recent studies have highlighted adversarial examples as a ubiquitous threat to different neural network models and many downstream  applications. Nonetheless, as unique data properties have inspired distinct and powerful learning principles, this paper aims to explore their potentials towards mitigating adversarial inputs. In particular, our results reveal the importance of using the temporal dependency in audio data to gain discriminate power against adversarial examples. Tested on the automatic speech recognition (ASR) tasks and three recent audio adversarial attacks, we find that (i) input transformation developed from image adversarial defense provides limited robustness improvement and is subtle to advanced attacks; (ii) temporal dependency can be exploited to gain discriminative power against audio adversarial examples and is resistant to adaptive attacks considered in our experiments. Our results not only show promising means of improving the robustness of ASR systems, but also offer novel insights in exploiting domain-specific data properties to mitigate negative effects of adversarial examples.", "keywords": ["audio adversarial example", "mitigation", "detection", "machine learning"], "authorids": ["lucas110550@sjtu.edu.cn", "lxbosky@gmail.com", "pin-yu.chen@ibm.com", "dawnsong@gmail.com"], "authors": ["Zhuolin Yang", "Bo Li", "Pin-Yu Chen", "Dawn Song"], "TL;DR": "Adversarial audio discrimination using temporal dependency", "pdf": "/pdf/312fc5f40208f39aa6860b54ece6696cd4397424.pdf", "paperhash": "yang|characterizing_audio_adversarial_examples_using_temporal_dependency", "_bibtex": "@inproceedings{\nyang2018characterizing,\ntitle={Characterizing Audio Adversarial Examples Using Temporal Dependency},\nauthor={Zhuolin Yang and Bo Li and Pin-Yu Chen and Dawn Song},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1g4E3C9t7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1439/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311597091, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "r1g4E3C9t7", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1439/Authors", "ICLR.cc/2019/Conference/Paper1439/Reviewers", "ICLR.cc/2019/Conference/Paper1439/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1439/Authors", "ICLR.cc/2019/Conference/Paper1439/Reviewers", "ICLR.cc/2019/Conference/Paper1439/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311597091}}}, {"id": "SklHTV9Aim", "original": null, "number": 1, "cdate": 1540428989398, "ddate": null, "tcdate": 1540428989398, "tmdate": 1540428989398, "tddate": null, "forum": "r1g4E3C9t7", "replyto": "rJe03DXAiX", "invitation": "ICLR.cc/2019/Conference/-/Paper1439/Official_Comment", "content": {"title": "Reply to \"Attack cannot succeed\"", "comment": "Thank you for the valuable comments.\nYes, we indeed allow the distortion to be the largest possible in practice, which is the amplitude of the original audio waveform. If the distortion is larger than the original audio waveform, the benign audio will be totally covered by the adversarial one and hence the adversarial attack will become trivial but meaningless.\n\nSuch rational setting for maximum distortion is also mentioned in (Carlini et al. 2018), and we will add corresponding discussion in our updated version as well. Thank you for pointing this out.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1439/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1439/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1439/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Characterizing Audio Adversarial Examples Using Temporal Dependency", "abstract": "Recent studies have highlighted adversarial examples as a ubiquitous threat to different neural network models and many downstream  applications. Nonetheless, as unique data properties have inspired distinct and powerful learning principles, this paper aims to explore their potentials towards mitigating adversarial inputs. In particular, our results reveal the importance of using the temporal dependency in audio data to gain discriminate power against adversarial examples. Tested on the automatic speech recognition (ASR) tasks and three recent audio adversarial attacks, we find that (i) input transformation developed from image adversarial defense provides limited robustness improvement and is subtle to advanced attacks; (ii) temporal dependency can be exploited to gain discriminative power against audio adversarial examples and is resistant to adaptive attacks considered in our experiments. Our results not only show promising means of improving the robustness of ASR systems, but also offer novel insights in exploiting domain-specific data properties to mitigate negative effects of adversarial examples.", "keywords": ["audio adversarial example", "mitigation", "detection", "machine learning"], "authorids": ["lucas110550@sjtu.edu.cn", "lxbosky@gmail.com", "pin-yu.chen@ibm.com", "dawnsong@gmail.com"], "authors": ["Zhuolin Yang", "Bo Li", "Pin-Yu Chen", "Dawn Song"], "TL;DR": "Adversarial audio discrimination using temporal dependency", "pdf": "/pdf/312fc5f40208f39aa6860b54ece6696cd4397424.pdf", "paperhash": "yang|characterizing_audio_adversarial_examples_using_temporal_dependency", "_bibtex": "@inproceedings{\nyang2018characterizing,\ntitle={Characterizing Audio Adversarial Examples Using Temporal Dependency},\nauthor={Zhuolin Yang and Bo Li and Pin-Yu Chen and Dawn Song},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1g4E3C9t7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1439/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621608529, "tddate": null, "super": null, "final": null, "reply": {"forum": "r1g4E3C9t7", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1439/Authors", "ICLR.cc/2019/Conference/Paper1439/Reviewers", "ICLR.cc/2019/Conference/Paper1439/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1439/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1439/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1439/Authors|ICLR.cc/2019/Conference/Paper1439/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1439/Reviewers", "ICLR.cc/2019/Conference/Paper1439/Authors", "ICLR.cc/2019/Conference/Paper1439/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621608529}}}, {"id": "rJe03DXAiX", "original": null, "number": 1, "cdate": 1540401078262, "ddate": null, "tcdate": 1540401078262, "tmdate": 1540401078262, "tddate": null, "forum": "r1g4E3C9t7", "replyto": "r1g4E3C9t7", "invitation": "ICLR.cc/2019/Conference/-/Paper1439/Public_Comment", "content": {"comment": "You write that the adaptive attack \"cannot succeed\". I wonder if you have tried verifying that the attack does eventually succeed if you allow larger distortions as suggested by (Athalye et al. 2018) to verify the attack is working as expected.", "title": "\"Attack cannot succeed\""}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1439/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Characterizing Audio Adversarial Examples Using Temporal Dependency", "abstract": "Recent studies have highlighted adversarial examples as a ubiquitous threat to different neural network models and many downstream  applications. Nonetheless, as unique data properties have inspired distinct and powerful learning principles, this paper aims to explore their potentials towards mitigating adversarial inputs. In particular, our results reveal the importance of using the temporal dependency in audio data to gain discriminate power against adversarial examples. Tested on the automatic speech recognition (ASR) tasks and three recent audio adversarial attacks, we find that (i) input transformation developed from image adversarial defense provides limited robustness improvement and is subtle to advanced attacks; (ii) temporal dependency can be exploited to gain discriminative power against audio adversarial examples and is resistant to adaptive attacks considered in our experiments. Our results not only show promising means of improving the robustness of ASR systems, but also offer novel insights in exploiting domain-specific data properties to mitigate negative effects of adversarial examples.", "keywords": ["audio adversarial example", "mitigation", "detection", "machine learning"], "authorids": ["lucas110550@sjtu.edu.cn", "lxbosky@gmail.com", "pin-yu.chen@ibm.com", "dawnsong@gmail.com"], "authors": ["Zhuolin Yang", "Bo Li", "Pin-Yu Chen", "Dawn Song"], "TL;DR": "Adversarial audio discrimination using temporal dependency", "pdf": "/pdf/312fc5f40208f39aa6860b54ece6696cd4397424.pdf", "paperhash": "yang|characterizing_audio_adversarial_examples_using_temporal_dependency", "_bibtex": "@inproceedings{\nyang2018characterizing,\ntitle={Characterizing Audio Adversarial Examples Using Temporal Dependency},\nauthor={Zhuolin Yang and Bo Li and Pin-Yu Chen and Dawn Song},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=r1g4E3C9t7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1439/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311597091, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "r1g4E3C9t7", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1439/Authors", "ICLR.cc/2019/Conference/Paper1439/Reviewers", "ICLR.cc/2019/Conference/Paper1439/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1439/Authors", "ICLR.cc/2019/Conference/Paper1439/Reviewers", "ICLR.cc/2019/Conference/Paper1439/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311597091}}}], "count": 13}