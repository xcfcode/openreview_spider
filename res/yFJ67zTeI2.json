{"notes": [{"id": "yFJ67zTeI2", "original": "0USvRJDCq3f", "number": 2660, "cdate": 1601308294652, "ddate": null, "tcdate": 1601308294652, "tmdate": 1614907211898, "tddate": null, "forum": "yFJ67zTeI2", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Semi-supervised Keypoint Localization", "authorids": ["~Olga_Moskvyak1", "~Frederic_Maire1", "~Feras_Dayoub1", "~Mahsa_Baktashmotlagh1"], "authors": ["Olga Moskvyak", "Frederic Maire", "Feras Dayoub", "Mahsa Baktashmotlagh"], "keywords": ["semi-supervised learning", "keypoint localization", "limited data", "unsupervised loss"], "abstract": "Knowledge about the locations of keypoints of an object in an image can assist in fine-grained classification and identification tasks, particularly for the case of objects that exhibit large variations in poses that greatly influence their visual appearance, such as wild animals. However, supervised training of a keypoint detection network requires annotating a large image dataset for each animal species, which is a labor-intensive task. To reduce the need for labeled data, we propose to learn simultaneously keypoint heatmaps and pose invariant keypoint representations in a semi-supervised manner using a small set of labeled images along with a larger set of unlabeled images. Keypoint representations are learnt with a semantic keypoint consistency constraint that forces the keypoint detection network to learn similar features for the same keypoint across the dataset. Pose invariance is achieved by making keypoint representations for the image and its augmented copies closer together in feature space. Our semi-supervised approach significantly outperforms previous methods on several benchmarks for human and animal body landmark localization.", "one-sentence_summary": "A novel method for semi-supervised keypoint localization via learning semantic keypoint representations.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "moskvyak|semisupervised_keypoint_localization", "supplementary_material": "/attachment/b5162dde48bb712cd85686eb240af271f9c208e3.zip", "pdf": "/pdf/60b9fa896e2494cd3d4cdf45231c251d92e4bb9f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nmoskvyak2021semisupervised,\ntitle={Semi-supervised Keypoint Localization},\nauthor={Olga Moskvyak and Frederic Maire and Feras Dayoub and Mahsa Baktashmotlagh},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=yFJ67zTeI2}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "ClMc_4RQjjF", "original": null, "number": 1, "cdate": 1610040468778, "ddate": null, "tcdate": 1610040468778, "tmdate": 1610474072603, "tddate": null, "forum": "yFJ67zTeI2", "replyto": "yFJ67zTeI2", "invitation": "ICLR.cc/2021/Conference/Paper2660/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Poster)", "comment": "This paper received three borderline reviews (2+ / 1-) and one positive review.  Having read through the reviews and author responses, the AC recommends the paper to be accepted.  The method, while simple, is proven experimentally to be effectively and will add to the body of work on key-point localization.   The authors are requested to add their additional baselines in the response text to the revision of their paper if it has not already been done.\n"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Semi-supervised Keypoint Localization", "authorids": ["~Olga_Moskvyak1", "~Frederic_Maire1", "~Feras_Dayoub1", "~Mahsa_Baktashmotlagh1"], "authors": ["Olga Moskvyak", "Frederic Maire", "Feras Dayoub", "Mahsa Baktashmotlagh"], "keywords": ["semi-supervised learning", "keypoint localization", "limited data", "unsupervised loss"], "abstract": "Knowledge about the locations of keypoints of an object in an image can assist in fine-grained classification and identification tasks, particularly for the case of objects that exhibit large variations in poses that greatly influence their visual appearance, such as wild animals. However, supervised training of a keypoint detection network requires annotating a large image dataset for each animal species, which is a labor-intensive task. To reduce the need for labeled data, we propose to learn simultaneously keypoint heatmaps and pose invariant keypoint representations in a semi-supervised manner using a small set of labeled images along with a larger set of unlabeled images. Keypoint representations are learnt with a semantic keypoint consistency constraint that forces the keypoint detection network to learn similar features for the same keypoint across the dataset. Pose invariance is achieved by making keypoint representations for the image and its augmented copies closer together in feature space. Our semi-supervised approach significantly outperforms previous methods on several benchmarks for human and animal body landmark localization.", "one-sentence_summary": "A novel method for semi-supervised keypoint localization via learning semantic keypoint representations.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "moskvyak|semisupervised_keypoint_localization", "supplementary_material": "/attachment/b5162dde48bb712cd85686eb240af271f9c208e3.zip", "pdf": "/pdf/60b9fa896e2494cd3d4cdf45231c251d92e4bb9f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nmoskvyak2021semisupervised,\ntitle={Semi-supervised Keypoint Localization},\nauthor={Olga Moskvyak and Frederic Maire and Feras Dayoub and Mahsa Baktashmotlagh},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=yFJ67zTeI2}\n}"}, "tags": [], "invitation": {"reply": {"forum": "yFJ67zTeI2", "replyto": "yFJ67zTeI2", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040468765, "tmdate": 1610474072586, "id": "ICLR.cc/2021/Conference/Paper2660/-/Decision"}}}, {"id": "LVzk2pcF13K", "original": null, "number": 1, "cdate": 1603724665490, "ddate": null, "tcdate": 1603724665490, "tmdate": 1606766195536, "tddate": null, "forum": "yFJ67zTeI2", "replyto": "yFJ67zTeI2", "invitation": "ICLR.cc/2021/Conference/Paper2660/-/Official_Review", "content": {"title": "This paper proposes a model for landmark/keypoint localization trained in a semi-supervised way", "review": "It can be applied to point heatmaps based network by adding a semantic representation learn by a three loss terms: one supervised and two semi-supervised. The proposed architecture combines a Keypoint Localization Network with a Keypoint Classification Network. Experiments are achieved on four public datasets. \n\nThe main contribution of the paper is the model and losses proposed to train, in a semi-supervised way, the network. \n\nContributions are clearly stated and validated. \nThe idea of using intermediate features to produce a map that will select keypoint features with an element-wise product with the heatmap is good. Its looks like a kind of attention module. Additional information should be provide to explain the differences: this is mandatory\nThe transformation consistency constraints are also good ideas and the modified transformation equivariance is a smart trick. \nExperiments have been achieved in order to compare the proposed semi-supervised model with other semi-supervised models (2 are selected). Results are good. \nMoreover, an ablation study is proposed. It reports the effect of each unsupervised loss. It should be interesting to add the score of the model without unsupervised loss. It will, for example show if for 100% sample trained, adding unsupervised loss improves the method. A visualisation ok keypoint embedding using the tSNE technic is also proposed. I'am not sure that this figure gives usefull information for the study if not compared to the one obtained by only supervised training. \n\nThe implementation details points that \"unsupervised loss may hurt the learning at the beginning\" and proposes to use ground truth heatmaps. This is not really an implementation detail to my point of view are more information and experiments about this trick should be given. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2660/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2660/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Semi-supervised Keypoint Localization", "authorids": ["~Olga_Moskvyak1", "~Frederic_Maire1", "~Feras_Dayoub1", "~Mahsa_Baktashmotlagh1"], "authors": ["Olga Moskvyak", "Frederic Maire", "Feras Dayoub", "Mahsa Baktashmotlagh"], "keywords": ["semi-supervised learning", "keypoint localization", "limited data", "unsupervised loss"], "abstract": "Knowledge about the locations of keypoints of an object in an image can assist in fine-grained classification and identification tasks, particularly for the case of objects that exhibit large variations in poses that greatly influence their visual appearance, such as wild animals. However, supervised training of a keypoint detection network requires annotating a large image dataset for each animal species, which is a labor-intensive task. To reduce the need for labeled data, we propose to learn simultaneously keypoint heatmaps and pose invariant keypoint representations in a semi-supervised manner using a small set of labeled images along with a larger set of unlabeled images. Keypoint representations are learnt with a semantic keypoint consistency constraint that forces the keypoint detection network to learn similar features for the same keypoint across the dataset. Pose invariance is achieved by making keypoint representations for the image and its augmented copies closer together in feature space. Our semi-supervised approach significantly outperforms previous methods on several benchmarks for human and animal body landmark localization.", "one-sentence_summary": "A novel method for semi-supervised keypoint localization via learning semantic keypoint representations.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "moskvyak|semisupervised_keypoint_localization", "supplementary_material": "/attachment/b5162dde48bb712cd85686eb240af271f9c208e3.zip", "pdf": "/pdf/60b9fa896e2494cd3d4cdf45231c251d92e4bb9f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nmoskvyak2021semisupervised,\ntitle={Semi-supervised Keypoint Localization},\nauthor={Olga Moskvyak and Frederic Maire and Feras Dayoub and Mahsa Baktashmotlagh},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=yFJ67zTeI2}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "yFJ67zTeI2", "replyto": "yFJ67zTeI2", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2660/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538091320, "tmdate": 1606915791727, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2660/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2660/-/Official_Review"}}}, {"id": "OuoQtSA3niV", "original": null, "number": 6, "cdate": 1606101283644, "ddate": null, "tcdate": 1606101283644, "tmdate": 1606101283644, "tddate": null, "forum": "yFJ67zTeI2", "replyto": "_WpvDEP5pCy", "invitation": "ICLR.cc/2021/Conference/Paper2660/-/Official_Comment", "content": {"title": "Thanks for clarification", "comment": "My questions were well addressed. I think this work is solid and I recommend acceptance."}, "signatures": ["ICLR.cc/2021/Conference/Paper2660/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2660/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Semi-supervised Keypoint Localization", "authorids": ["~Olga_Moskvyak1", "~Frederic_Maire1", "~Feras_Dayoub1", "~Mahsa_Baktashmotlagh1"], "authors": ["Olga Moskvyak", "Frederic Maire", "Feras Dayoub", "Mahsa Baktashmotlagh"], "keywords": ["semi-supervised learning", "keypoint localization", "limited data", "unsupervised loss"], "abstract": "Knowledge about the locations of keypoints of an object in an image can assist in fine-grained classification and identification tasks, particularly for the case of objects that exhibit large variations in poses that greatly influence their visual appearance, such as wild animals. However, supervised training of a keypoint detection network requires annotating a large image dataset for each animal species, which is a labor-intensive task. To reduce the need for labeled data, we propose to learn simultaneously keypoint heatmaps and pose invariant keypoint representations in a semi-supervised manner using a small set of labeled images along with a larger set of unlabeled images. Keypoint representations are learnt with a semantic keypoint consistency constraint that forces the keypoint detection network to learn similar features for the same keypoint across the dataset. Pose invariance is achieved by making keypoint representations for the image and its augmented copies closer together in feature space. Our semi-supervised approach significantly outperforms previous methods on several benchmarks for human and animal body landmark localization.", "one-sentence_summary": "A novel method for semi-supervised keypoint localization via learning semantic keypoint representations.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "moskvyak|semisupervised_keypoint_localization", "supplementary_material": "/attachment/b5162dde48bb712cd85686eb240af271f9c208e3.zip", "pdf": "/pdf/60b9fa896e2494cd3d4cdf45231c251d92e4bb9f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nmoskvyak2021semisupervised,\ntitle={Semi-supervised Keypoint Localization},\nauthor={Olga Moskvyak and Frederic Maire and Feras Dayoub and Mahsa Baktashmotlagh},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=yFJ67zTeI2}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "yFJ67zTeI2", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2660/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2660/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2660/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2660/Authors|ICLR.cc/2021/Conference/Paper2660/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2660/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923845806, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2660/-/Official_Comment"}}}, {"id": "Rk1ELcXzknN", "original": null, "number": 5, "cdate": 1605846173926, "ddate": null, "tcdate": 1605846173926, "tmdate": 1605846173926, "tddate": null, "forum": "yFJ67zTeI2", "replyto": "LVzk2pcF13K", "invitation": "ICLR.cc/2021/Conference/Paper2660/-/Official_Comment", "content": {"title": "Additional ablation studies and response to questions", "comment": "We thank the reviewer for the positive comments and constructive feedback. We have completed the additional ablation study and addressed the questions below. The paper is revised accordingly.\t\n\nIn response to the question of comparing our method to attention models: Similar to attention modules (Vaswani et al., 2017, Ramachandran et al., 2019, Hu et al., 2020), our network has the ability to focus on a subset of features using element-wise multiplication with the heatmaps. However, our model uses the attention-based mechanism to learn additional keypoint representations (apart from the main heatmap output) from unlabeled data by optimizing a set of unsupervised losses. \n \nIn response to the reviewer\u2019s comment on providing the results of our framework without the unsupervised losses, we added a supervised baseline to Table 2 for convenient comparison. The results in Table 2 show clearly that adding unsupervised losses improves the supervised score.\nTable 2 (shown below) is updated in the revised paper accordingly.\n \n**Updated Table 2**\n \n| Unsupervised losses \t| 5% \t| 10% \t| 20% \t| 50% \t| 100% \t|\n|-\t|:-:\t|:-:\t|:-:\t|:-:\t|:-:\t|\n| TE + TI + SC \t| 66.32 \t| 69.09 \t| 71.62 \t| 72.19 \t| 74.44 \t|\n| TE + TI \t| 46.76 \t| 55.18 \t| 64.01 \t| 67.54 \t| 72.11 \t|\n| SC \t| 64.74 \t| 67.43 \t| 69.65 \t| 70.61 \t| 72.85 \t|\n| TI + SC \t| 65.23 \t| 68.11 \t| 70.12 \t| 71.28 \t| 73.56 \t|\n| TE + SC \t| 65.78 \t| 68.51 \t| 70.56 \t| 71.77 \t| 73.89 \t|\n| TI \t| 43.62 \t| 53.74 \t| 61.12 \t| 65.32 \t| 71.80 \t|\n| Supervised baseline \t| 39.16 \t| 44.36 \t| 54.23 \t| 61.73 \t| 71.91 \t|\n \nWe conduct an ablation study to provide an insight on using available ground truth heatmaps in unsupervised losses. Experiments on the LSP dataset show a decrease of 1-2% in the score for all cases when ground truth heatmaps are not used. The results prove the benefit of using the signal from available ground truth heatmaps.\nThe following results are added as Table 4 to the paper:\n \n| Method \t| 5% \t| 10% \t| 20% \t| 50% \t| 100% \t|\n|-\t|:-:\t|:-:\t|:-:\t|:-:\t|:-:\t|\n| With g/t heatmaps \t| 66.32 \t| 69.09 \t| 71.62 \t| 72.19 \t| 74.44 \t|\n| Without g/t heatmaps \t| 64.75 \t| 67.27 \t| 69.91 \t| 70.55 \t| 73.65 \t|\n \n \n\nReferences:\n\nHu, J., Shen, L., Albanie, S., Sun, G., & Wu, E. (2020). Squeeze-and-Excitation Networks. IEEE Transactions on Pattern Analysis and Machine Intelligence, 42, 2011-2023.\n\nRamachandran, P., Parmar, N., Vaswani, A., Bello, I., Levskaya, A., & Shlens, J. (2019). Stand-Alone Self-Attention in Vision Models. NeurIPS.\n\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., & Polosukhin, I. (2017). Attention is All you Need. NIPS.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper2660/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2660/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Semi-supervised Keypoint Localization", "authorids": ["~Olga_Moskvyak1", "~Frederic_Maire1", "~Feras_Dayoub1", "~Mahsa_Baktashmotlagh1"], "authors": ["Olga Moskvyak", "Frederic Maire", "Feras Dayoub", "Mahsa Baktashmotlagh"], "keywords": ["semi-supervised learning", "keypoint localization", "limited data", "unsupervised loss"], "abstract": "Knowledge about the locations of keypoints of an object in an image can assist in fine-grained classification and identification tasks, particularly for the case of objects that exhibit large variations in poses that greatly influence their visual appearance, such as wild animals. However, supervised training of a keypoint detection network requires annotating a large image dataset for each animal species, which is a labor-intensive task. To reduce the need for labeled data, we propose to learn simultaneously keypoint heatmaps and pose invariant keypoint representations in a semi-supervised manner using a small set of labeled images along with a larger set of unlabeled images. Keypoint representations are learnt with a semantic keypoint consistency constraint that forces the keypoint detection network to learn similar features for the same keypoint across the dataset. Pose invariance is achieved by making keypoint representations for the image and its augmented copies closer together in feature space. Our semi-supervised approach significantly outperforms previous methods on several benchmarks for human and animal body landmark localization.", "one-sentence_summary": "A novel method for semi-supervised keypoint localization via learning semantic keypoint representations.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "moskvyak|semisupervised_keypoint_localization", "supplementary_material": "/attachment/b5162dde48bb712cd85686eb240af271f9c208e3.zip", "pdf": "/pdf/60b9fa896e2494cd3d4cdf45231c251d92e4bb9f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nmoskvyak2021semisupervised,\ntitle={Semi-supervised Keypoint Localization},\nauthor={Olga Moskvyak and Frederic Maire and Feras Dayoub and Mahsa Baktashmotlagh},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=yFJ67zTeI2}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "yFJ67zTeI2", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2660/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2660/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2660/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2660/Authors|ICLR.cc/2021/Conference/Paper2660/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2660/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923845806, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2660/-/Official_Comment"}}}, {"id": "_WpvDEP5pCy", "original": null, "number": 4, "cdate": 1605845839696, "ddate": null, "tcdate": 1605845839696, "tmdate": 1605846032217, "tddate": null, "forum": "yFJ67zTeI2", "replyto": "4etN2AwuCbf", "invitation": "ICLR.cc/2021/Conference/Paper2660/-/Official_Comment", "content": {"title": "Results of pseudo-labeled baseline and updated ablation study", "comment": "We thank the reviewer for the constructive comments. We appreciate the suggestion of additional baseline and supplementary ablation studies. We conducted the proposed experiments, and the manuscript is revised accordingly.  \n \n 1. We obtained the results of pseudo-labeled baseline (Radosavovic et al., 2018) on our datasets and added the results to Table 1. Overall, our approach outperforms the pseudo-labeled baseline on all datasets used in our study. One possible explanation is that  Radosavovic et al. (2018) used datasets that are by order of magnitude larger than our data. For example,  COCO (Lin et al., 2014) consists of 80,000 labeled and 120,000 unlabeled images vs 10,000 total images in our LSP dataset. Therefore models pretrained on the labeled subset are already good enough to generate reliable pseudo-labels. \n \n2. Results of the pseudo-labeled baseline from the previous question provide the evidence for our claim: \u201cwhere there is a high risk of transferring inaccurate pseudo-labeled examples to the retraining stage that is harmful for the model.\u201d  \nFor example, the supervised baseline only achieves the score of 40% on LSP with 5% of labeled data. The score of pseudo-labeled baseline drops to 37% due to low-quality pseudo-labels from the supervised model.\n \n3. We conducted the suggested ablation studies to enhance the quality of the paper: \n\n(1) We observe in the experiments that our method on 100% labeled data outperforms the supervised baseline by a small margin. This can be due to the fact that by learning supplementary semantic keypoint representations with unsupervised losses, the model learns to generalize better. \n\n(2-3) We analyzed the influence of each unsupervised loss separately. As opposed to the original submission where the transformation equivariance (TE) and invariance (TI) are combined as TC (transformation consistency), in the updated ablation study, we treat them separately and evaluate the contribution of each constraint on the performance individually. We evaluate all possible combinations except single TE separately because it does not optimize both representations. The results of ablation study are added to Table 2. \n \n**Updated Table 2**\n\n| Unsupervised losses \t| 5% \t| 10% \t| 20% \t| 50% \t| 100% \t|\n|-\t|:-:\t|:-:\t|:-:\t|:-:\t|:-:\t|\n| TE + TI + SC \t| 66.32 \t| 69.09 \t| 71.62 \t| 72.19 \t| 74.44 \t|\n| TE + TI \t| 46.76 \t| 55.18 \t| 64.01 \t| 67.54 \t| 72.11 \t|\n| SC \t| 64.74 \t| 67.43 \t| 69.65 \t| 70.61 \t| 72.85 \t|\n| TI + SC \t| 65.23 \t| 68.11 \t| 70.12 \t| 71.28 \t| 73.56 \t|\n| TE + SC \t| 65.78 \t| 68.51 \t| 70.56 \t| 71.77 \t| 73.89 \t|\n| TI \t| 43.62 \t| 53.74 \t| 61.12 \t| 65.32 \t| 71.80 \t|\n| Supervised baseline \t| 39.16 \t| 44.36 \t| 54.23 \t| 61.73 \t| 71.91 \t|\n   \n \nIn response to the question, we have updated Table 3 in the revised paper with the supervised baseline (SB) for convenient comparison: \n\n**Updated Table 3**\n\n| Dataset \t| 10% \t| 20% \t| 50% \t| 100% \t| SB \t|\n|-\t|:-:\t|:-:\t|:-:\t|:-:\t|:-:\t|\n| CUB-200-2011 \t| 87.01 \t| 88.33 \t| 89.44 \t| 91.34 \t| 85.33 \t|\n| ATRW \t| 72.04 \t| 76.65 \t| 86.56 \t| 93.02 \t| 69.84 \t|\n \n  \nWe fixed the typos in the revised version. \nWe thank the reviewer for the suggestion to expand the scope and apply our method to other tasks. We will consider applying it to other vision tasks in future work. \n  \nReferences: \n\nTsung-Yi Lin, M. Maire, Serge J. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollar, and C. L.Zitnick. Microsoft coco: Common objects in context. InProc. ECCV, 2014. \n\nlija Radosavovic, P. Dollar, Ross B. Girshick, Georgia Gkioxari, and Kaiming He. Data distillation: Towards omni-supervised learning. In Proc. CVPR, 2018"}, "signatures": ["ICLR.cc/2021/Conference/Paper2660/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2660/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Semi-supervised Keypoint Localization", "authorids": ["~Olga_Moskvyak1", "~Frederic_Maire1", "~Feras_Dayoub1", "~Mahsa_Baktashmotlagh1"], "authors": ["Olga Moskvyak", "Frederic Maire", "Feras Dayoub", "Mahsa Baktashmotlagh"], "keywords": ["semi-supervised learning", "keypoint localization", "limited data", "unsupervised loss"], "abstract": "Knowledge about the locations of keypoints of an object in an image can assist in fine-grained classification and identification tasks, particularly for the case of objects that exhibit large variations in poses that greatly influence their visual appearance, such as wild animals. However, supervised training of a keypoint detection network requires annotating a large image dataset for each animal species, which is a labor-intensive task. To reduce the need for labeled data, we propose to learn simultaneously keypoint heatmaps and pose invariant keypoint representations in a semi-supervised manner using a small set of labeled images along with a larger set of unlabeled images. Keypoint representations are learnt with a semantic keypoint consistency constraint that forces the keypoint detection network to learn similar features for the same keypoint across the dataset. Pose invariance is achieved by making keypoint representations for the image and its augmented copies closer together in feature space. Our semi-supervised approach significantly outperforms previous methods on several benchmarks for human and animal body landmark localization.", "one-sentence_summary": "A novel method for semi-supervised keypoint localization via learning semantic keypoint representations.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "moskvyak|semisupervised_keypoint_localization", "supplementary_material": "/attachment/b5162dde48bb712cd85686eb240af271f9c208e3.zip", "pdf": "/pdf/60b9fa896e2494cd3d4cdf45231c251d92e4bb9f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nmoskvyak2021semisupervised,\ntitle={Semi-supervised Keypoint Localization},\nauthor={Olga Moskvyak and Frederic Maire and Feras Dayoub and Mahsa Baktashmotlagh},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=yFJ67zTeI2}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "yFJ67zTeI2", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2660/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2660/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2660/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2660/Authors|ICLR.cc/2021/Conference/Paper2660/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2660/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923845806, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2660/-/Official_Comment"}}}, {"id": "SGJWN1Dw1R", "original": null, "number": 3, "cdate": 1605845194525, "ddate": null, "tcdate": 1605845194525, "tmdate": 1605845194525, "tddate": null, "forum": "yFJ67zTeI2", "replyto": "TYQ8n1FzYdT", "invitation": "ICLR.cc/2021/Conference/Paper2660/-/Official_Comment", "content": {"title": "We thank the reviewer for the positive feedback", "comment": "We thank the reviewer for the positive feedback, and suggestions that helped improve our paper.\nWe took into account all the minor comments of the reviewer in the revised paper."}, "signatures": ["ICLR.cc/2021/Conference/Paper2660/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2660/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Semi-supervised Keypoint Localization", "authorids": ["~Olga_Moskvyak1", "~Frederic_Maire1", "~Feras_Dayoub1", "~Mahsa_Baktashmotlagh1"], "authors": ["Olga Moskvyak", "Frederic Maire", "Feras Dayoub", "Mahsa Baktashmotlagh"], "keywords": ["semi-supervised learning", "keypoint localization", "limited data", "unsupervised loss"], "abstract": "Knowledge about the locations of keypoints of an object in an image can assist in fine-grained classification and identification tasks, particularly for the case of objects that exhibit large variations in poses that greatly influence their visual appearance, such as wild animals. However, supervised training of a keypoint detection network requires annotating a large image dataset for each animal species, which is a labor-intensive task. To reduce the need for labeled data, we propose to learn simultaneously keypoint heatmaps and pose invariant keypoint representations in a semi-supervised manner using a small set of labeled images along with a larger set of unlabeled images. Keypoint representations are learnt with a semantic keypoint consistency constraint that forces the keypoint detection network to learn similar features for the same keypoint across the dataset. Pose invariance is achieved by making keypoint representations for the image and its augmented copies closer together in feature space. Our semi-supervised approach significantly outperforms previous methods on several benchmarks for human and animal body landmark localization.", "one-sentence_summary": "A novel method for semi-supervised keypoint localization via learning semantic keypoint representations.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "moskvyak|semisupervised_keypoint_localization", "supplementary_material": "/attachment/b5162dde48bb712cd85686eb240af271f9c208e3.zip", "pdf": "/pdf/60b9fa896e2494cd3d4cdf45231c251d92e4bb9f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nmoskvyak2021semisupervised,\ntitle={Semi-supervised Keypoint Localization},\nauthor={Olga Moskvyak and Frederic Maire and Feras Dayoub and Mahsa Baktashmotlagh},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=yFJ67zTeI2}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "yFJ67zTeI2", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2660/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2660/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2660/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2660/Authors|ICLR.cc/2021/Conference/Paper2660/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2660/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923845806, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2660/-/Official_Comment"}}}, {"id": "tdJ5PF83kY0", "original": null, "number": 2, "cdate": 1605844599798, "ddate": null, "tcdate": 1605844599798, "tmdate": 1605845060037, "tddate": null, "forum": "yFJ67zTeI2", "replyto": "2uMZ4MvuUCd", "invitation": "ICLR.cc/2021/Conference/Paper2660/-/Official_Comment", "content": {"title": "Updated ablation study and additional sensitivity analysis", "comment": "We thank the reviewer for the constructive feedback and suggestions. We have addressed all the reviewer\u2019s concerns and conducted additional ablation studies and sensitivity analysis experiments. The paper is revised accordingly with all the requested results added.\n\n1. As acknowledged in our submission, the transformation equivariance (TE) loss in Eq. (2) is inspired by the work of Honari et al., CVPR\u201918. Therefore, we did not claim this loss as our methodological contribution. However, we demonstrate that our modified TE loss can experimentally achieve better results compared to the loss of Honari et al., CVPR\u201918. We conducted additional experiments by replacing our TE loss with an inverse transformation loss of Honari et al. in our framework, and applied it on ATRW (tigers) and CUB-200-2011 (birds) datasets with 20% of labeled data. We observed that the score decreased by 1% on both datasets.\n\n2. In the updated ablation study (Table 2 of the paper), we show experimentally that transformation invariance (4) contributes to the performance gain. As opposed to the original submission where the transformation equivariance and invariance are combined as TC (transformation consistency), in the updated ablation study, we treat them separately and evaluate the contribution of each constraint on the performance individually. The results of ablation study are added to Table 2.\n\n**Updated Table 2**\n\n| Unsupervised losses \t| 5% \t| 10% \t| 20% \t| 50% \t| 100% \t|\n|-\t|:-:\t|:-:\t|:-:\t|:-:\t|:-:\t|\n| TE + TI + SC \t| 66.32 \t| 69.09 \t| 71.62 \t| 72.19 \t| 74.44 \t|\n| TE + TI \t| 46.76 \t| 55.18 \t| 64.01 \t| 67.54 \t| 72.11 \t|\n| SC \t| 64.74 \t| 67.43 \t| 69.65 \t| 70.61 \t| 72.85 \t|\n| TI + SC \t| 65.23 \t| 68.11 \t| 70.12 \t| 71.28 \t| 73.56 \t|\n| TE + SC \t| 65.78 \t| 68.51 \t| 70.56 \t| 71.77 \t| 73.89 \t|\n| TI \t| 43.62 \t| 53.74 \t| 61.12 \t| 65.32 \t| 71.80 \t|\n| Supervised baseline \t| 39.16 \t| 44.36 \t| 54.23 \t| 61.73 \t| 71.91 \t|\n \n3. We conducted the proposed sensitivity analysis and evaluated the influence of the weights of loss components $(\\lambda_1, \\lambda_2, \\lambda_3, \\lambda_4)$ on the LSP dataset with 50% labeled data. We fixed the weight of supervised loss $\\lambda_1 = 10^3$ and tested the following weights of unsupervised losses: $\\lambda_2 =  (0.1, 0.5, 1.), \\lambda_3 =  (10^1, 10^2, 10^3)$ and $\\lambda_4 = (10^1, 10^2, 10^3)$. The ranges of weight values are different due to differences in scales for mean squared error of normalized pixels and cross-entropy loss. Experiments show that our method is not sensitive to variations of TE ($\\lambda_3$) and TI ($\\lambda_4$) losses (Figure 3 in the revised paper). The most notable drop in accuracy is observed when the weight of SC loss ($\\lambda_2$) is reduced to 0.1 and the accuracy is at the same level when $\\lambda_2$ equals 0.5 and 1.0.  We select the combination of $(\\lambda_2, \\lambda_3, \\lambda_4) = (0.5, 10^2, 10^2)$ that achieves the highest score.  \n \nWe provide a table with the results of experiments because we cannot embed an image in comments. The paper is updated with Figure 3 which visually represents the results from the table:\n \n$\\lambda_2$    |         $\\lambda_3$       |   $\\lambda_4$    |     Score|\n- | - | - | - | \n0.1    |     10^1    |   10^1 |     71.55\n0.1    |     10^1    |   10^2   |   71.78\n0.1    |     10^1    |   10^3   |   72.05\n0.1    |     10^2   |    10^1  |    71.56\n0.1    |     10^2    |   10^2  |    71.63\n0.1    |     10^2    |   10^3   |   71.76\n0.1    |     10^3   |    10^1   |   71.48\n0.1   |      10^3   |    10^2  |    71.57\n0.1   |      10^3   |    10^3    |  71.88\n0.5   |      10^1   |    10^1 |     72.14\n0.5   |      10^1   |    10^2   |   72.25\n0.5   |      10^1   |    10^3  |    72.52\n0.5   |      10^2   |    10^1   |   72.47\n0.5   |      10^2   |    10^2   |   72.63\n0.5   |    10^2   |    10^3  |    72.56\n0.5   |      10^3   |    10^1   |   72.45\n0.5   |      10^3   |    10^2   |   72.49\n0.5   |      10^3   |    10^3   |   72.26\n1.0   |      10^1   |    10^1   |   72.44\n1.0   |      10^1   |    10^2   |   72.45\n1.0   |      10^1   |    10^3   |   72.41\n1.0   |      10^2   |    10^1   |   72.41\n1.0   |      10^2   |    10^2   |   72.34\n1.0   |      10^2   |    10^3   |   72.31\n1.0   |      10^3   |    10^1   |   72.40\n1.0   |      10^3   |    10^2   |   72.44\n1.0   |      10^3   |    10^3   |   72.42\n\n4. We are not sure if the proposed study with only unsupervised losses can be directly applicable and comparable to the semi-supervised methods, and as such, to our approach. The evaluation in semi-supervised methods is based on the comparison against the ground truth, while in unsupervised methods, the detected keypoints are semantically different from the ones identified by human annotators."}, "signatures": ["ICLR.cc/2021/Conference/Paper2660/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2660/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Semi-supervised Keypoint Localization", "authorids": ["~Olga_Moskvyak1", "~Frederic_Maire1", "~Feras_Dayoub1", "~Mahsa_Baktashmotlagh1"], "authors": ["Olga Moskvyak", "Frederic Maire", "Feras Dayoub", "Mahsa Baktashmotlagh"], "keywords": ["semi-supervised learning", "keypoint localization", "limited data", "unsupervised loss"], "abstract": "Knowledge about the locations of keypoints of an object in an image can assist in fine-grained classification and identification tasks, particularly for the case of objects that exhibit large variations in poses that greatly influence their visual appearance, such as wild animals. However, supervised training of a keypoint detection network requires annotating a large image dataset for each animal species, which is a labor-intensive task. To reduce the need for labeled data, we propose to learn simultaneously keypoint heatmaps and pose invariant keypoint representations in a semi-supervised manner using a small set of labeled images along with a larger set of unlabeled images. Keypoint representations are learnt with a semantic keypoint consistency constraint that forces the keypoint detection network to learn similar features for the same keypoint across the dataset. Pose invariance is achieved by making keypoint representations for the image and its augmented copies closer together in feature space. Our semi-supervised approach significantly outperforms previous methods on several benchmarks for human and animal body landmark localization.", "one-sentence_summary": "A novel method for semi-supervised keypoint localization via learning semantic keypoint representations.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "moskvyak|semisupervised_keypoint_localization", "supplementary_material": "/attachment/b5162dde48bb712cd85686eb240af271f9c208e3.zip", "pdf": "/pdf/60b9fa896e2494cd3d4cdf45231c251d92e4bb9f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nmoskvyak2021semisupervised,\ntitle={Semi-supervised Keypoint Localization},\nauthor={Olga Moskvyak and Frederic Maire and Feras Dayoub and Mahsa Baktashmotlagh},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=yFJ67zTeI2}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "yFJ67zTeI2", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2660/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper2660/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2660/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper2660/Authors|ICLR.cc/2021/Conference/Paper2660/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2660/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923845806, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper2660/-/Official_Comment"}}}, {"id": "4etN2AwuCbf", "original": null, "number": 2, "cdate": 1603901410185, "ddate": null, "tcdate": 1603901410185, "tmdate": 1605024159233, "tddate": null, "forum": "yFJ67zTeI2", "replyto": "yFJ67zTeI2", "invitation": "ICLR.cc/2021/Conference/Paper2660/-/Official_Review", "content": {"title": "Official Blind Review1", "review": "Summary:\n\nThis paper presents an interesting method for semi-supervised keypoint localization, that jointly learns the keypoint heatmaps and pose-invariant keypoint representations. The model is trained semi-supervised by applying transformation consistency and semantic consistency constraints. The proposed method is evaluated on several benchmarks and it significantly outperforms other semi- & un- supervised methods.\n\n##################################################################\n\nReasons for score: \n\nThe paper is mostly clear and well-motivated. The authors develop a novel approach to tackle the problem of semi-supervised keypoint localization. The reviewer appreciates the novelty and ingenuity of this approach. It achieves the state-of-the-art performance, compared to other semi-supervised methods. The proposed method is easy-to-implement and can be added to any existing keypoint localization networks. Also the extra keypoint classification branch is only used for training and can be discarded during inference. \n\nThere is still room for greatly improving the experiment section. Hopefully the authors can address the concerns in the rebuttal period. One major problem is the missing comparisons with pseudo-labeling baselines (Dong & Yang, 2019; Radosavovic et al., 2018). Another limitation of this work is the relatively narrow scope. The paper only focuses on one application of semi-supervised keypoint localization. However, I believe such techniques may also applicable to other tasks. \n\n##################################################################\n\nPros:\n\n1.The proposed method is very interesting and novel. The authors propose to add a keypoint classification branch, and design several well-motivated consistency losses. \n2.The paper is clear and well-written.\n3.The proposed method is easily added to any existing keypoint localization networks, which means many previous works can be jointly trained in a much larger unlabeled dataset and it may enhance the robustness and performance of the models.\n\n##################################################################\n\nCons:\n\n1. One major problem is the missing comparisons with pseudo-labeling baselines (Dong & Yang, 2019; Radosavovic et al., 2018). The reviewer believes that the comparisons are critical in showing the effectiveness of the proposed method. \n2. The authors said \u201cwhere there is a high risk of transferring inaccurate pseudo-labeled examples to the retraining stage that is harmful for the model.\u201dHowever, no evidence is provided in the experiment sections.\n3. Although the proposed method provides several ablation studies, the reviewer suggests to consider adding the following experiments to enhance the quality of the paper:\n\n(1)\tWhen percentage of labeled images is 100%, which is totally supervised, the proposed method already outperforms the baseline. Is this method also applicable to improving the performance of fully-supervised cases? Please analyze why. \n\n(2) Ablation study of only adding the keypoint classification branch (without the consistency losses).\n\n(3) Lacking of ablation study about TC in Table 2. The effectivess of transformation equivariance and transformation invariance should be considered separately.\n\n\n##################################################################\n\nQuestions during rebuttal period:\n\n1.In Table3, it reads\u201cOur method outperforms the supervised score only by a small margin with 10% of unlabelled data.\u201d It would be more convenient, if the supervised scores are also listed in the Table. \n\nSome typos:\n\n(1) 4.1 ATRW: where l is is the head \u2192 where l is the head\n(2) Table 2\uff1a Usupervised losses \u2192 Unsupervised losses\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2660/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2660/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Semi-supervised Keypoint Localization", "authorids": ["~Olga_Moskvyak1", "~Frederic_Maire1", "~Feras_Dayoub1", "~Mahsa_Baktashmotlagh1"], "authors": ["Olga Moskvyak", "Frederic Maire", "Feras Dayoub", "Mahsa Baktashmotlagh"], "keywords": ["semi-supervised learning", "keypoint localization", "limited data", "unsupervised loss"], "abstract": "Knowledge about the locations of keypoints of an object in an image can assist in fine-grained classification and identification tasks, particularly for the case of objects that exhibit large variations in poses that greatly influence their visual appearance, such as wild animals. However, supervised training of a keypoint detection network requires annotating a large image dataset for each animal species, which is a labor-intensive task. To reduce the need for labeled data, we propose to learn simultaneously keypoint heatmaps and pose invariant keypoint representations in a semi-supervised manner using a small set of labeled images along with a larger set of unlabeled images. Keypoint representations are learnt with a semantic keypoint consistency constraint that forces the keypoint detection network to learn similar features for the same keypoint across the dataset. Pose invariance is achieved by making keypoint representations for the image and its augmented copies closer together in feature space. Our semi-supervised approach significantly outperforms previous methods on several benchmarks for human and animal body landmark localization.", "one-sentence_summary": "A novel method for semi-supervised keypoint localization via learning semantic keypoint representations.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "moskvyak|semisupervised_keypoint_localization", "supplementary_material": "/attachment/b5162dde48bb712cd85686eb240af271f9c208e3.zip", "pdf": "/pdf/60b9fa896e2494cd3d4cdf45231c251d92e4bb9f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nmoskvyak2021semisupervised,\ntitle={Semi-supervised Keypoint Localization},\nauthor={Olga Moskvyak and Frederic Maire and Feras Dayoub and Mahsa Baktashmotlagh},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=yFJ67zTeI2}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "yFJ67zTeI2", "replyto": "yFJ67zTeI2", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2660/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538091320, "tmdate": 1606915791727, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2660/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2660/-/Official_Review"}}}, {"id": "TYQ8n1FzYdT", "original": null, "number": 3, "cdate": 1603901745241, "ddate": null, "tcdate": 1603901745241, "tmdate": 1605024159175, "tddate": null, "forum": "yFJ67zTeI2", "replyto": "yFJ67zTeI2", "invitation": "ICLR.cc/2021/Conference/Paper2660/-/Official_Review", "content": {"title": "SEMI-SUPERVISED KEYPOINT LOCALIZATION", "review": "**Summary**\n\nThe paper presents an approach to keypoint localization (to retrieve people/animals pose) combining labeled and unlabeled data. Features are extracted and concatenated into a single descriptor per keypoints, by multiplying feature maps and heatmaps and max-pooling over the spatial domain, and used for semantic classification. Images are transformed with simple perspective augmentations. The non-supervised part comes in enforcing that keypoint representations for unlabeled images remain close.\n\n**Pros**\n\n* Very simple formulation.\n* Thorough evaluation on four datasets with strong results.\n* Informative ablation tests.\n\n**Cons**\n\n* Relatively light on contributions, as the paper is quite simple.\n\n**Details**\n\nPlease cite Adam (mentioned but not cited).\n\nThe baselines/datasets seem sufficient, but I might have missed relevant works (I do not work in this field).\n\n\"Dialated\": dilated\n\n---\n\nP.S. I received an automated email complaining that my review was too short. The paper\u00a0is nice, straightforward, and easy to follow. The evaluation seems thorough. I did not find any mistakes. I don't have too much to say about it. My review is positive and, I hope, constructive.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2660/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2660/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Semi-supervised Keypoint Localization", "authorids": ["~Olga_Moskvyak1", "~Frederic_Maire1", "~Feras_Dayoub1", "~Mahsa_Baktashmotlagh1"], "authors": ["Olga Moskvyak", "Frederic Maire", "Feras Dayoub", "Mahsa Baktashmotlagh"], "keywords": ["semi-supervised learning", "keypoint localization", "limited data", "unsupervised loss"], "abstract": "Knowledge about the locations of keypoints of an object in an image can assist in fine-grained classification and identification tasks, particularly for the case of objects that exhibit large variations in poses that greatly influence their visual appearance, such as wild animals. However, supervised training of a keypoint detection network requires annotating a large image dataset for each animal species, which is a labor-intensive task. To reduce the need for labeled data, we propose to learn simultaneously keypoint heatmaps and pose invariant keypoint representations in a semi-supervised manner using a small set of labeled images along with a larger set of unlabeled images. Keypoint representations are learnt with a semantic keypoint consistency constraint that forces the keypoint detection network to learn similar features for the same keypoint across the dataset. Pose invariance is achieved by making keypoint representations for the image and its augmented copies closer together in feature space. Our semi-supervised approach significantly outperforms previous methods on several benchmarks for human and animal body landmark localization.", "one-sentence_summary": "A novel method for semi-supervised keypoint localization via learning semantic keypoint representations.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "moskvyak|semisupervised_keypoint_localization", "supplementary_material": "/attachment/b5162dde48bb712cd85686eb240af271f9c208e3.zip", "pdf": "/pdf/60b9fa896e2494cd3d4cdf45231c251d92e4bb9f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nmoskvyak2021semisupervised,\ntitle={Semi-supervised Keypoint Localization},\nauthor={Olga Moskvyak and Frederic Maire and Feras Dayoub and Mahsa Baktashmotlagh},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=yFJ67zTeI2}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "yFJ67zTeI2", "replyto": "yFJ67zTeI2", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2660/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538091320, "tmdate": 1606915791727, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2660/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2660/-/Official_Review"}}}, {"id": "2uMZ4MvuUCd", "original": null, "number": 4, "cdate": 1604124582282, "ddate": null, "tcdate": 1604124582282, "tmdate": 1605024159102, "tddate": null, "forum": "yFJ67zTeI2", "replyto": "yFJ67zTeI2", "invitation": "ICLR.cc/2021/Conference/Paper2660/-/Official_Review", "content": {"title": "Review for \"semi-supervised keypoint localization\"", "review": "** Paper Summary **\n\nThis paper presents semi-supervised keypoint localization networks and loss functions to overcome the need for the labeled keypoint data for that task. It simultaneously generates keypoint heatmaps and pose invariant keypoint representations, where these representations were separately used to enforce translation equivariance, and translation invariance, and semantic consistency, respectively. The proposed method attains the improvement on several benchmarks for human and animal body landmark localization.\n\n** Paper Strength **\n\n+ Learning keypoints with a minimal supervision is an essential step for numerous applications, thus solving such a problem is important.\n+ Using two kinds of representations, i.e., heatmap and keypoint feature, makes sense, enabling to apply different loss functions that achieve different aspects, e.g., translation equivariance and translation invariance, and semantic consistency.\n+ Compared to other previous methods to train the keypoint estimation networks in a self-supervised manner, e.g., Thewlis et al., 2019, the proposed methods incorporates the semantic consistency loss that makes the networks achieve a semantic awareness. \n+ But, results on several benchmarks were clearly state-of-the-arts. \n\n** Paper Weakness **\n\n- Even though this paper was tailored to semi-supervision learning, unsupervised losses themself contribute the performance gains solely. So, I'm really interested in what happens the networks are trained only with unsupervised losses, i.e., SC and TC. It would be interesting because some datasets might not have any ground truth keypoints. In Table 2 and 3, the authors tried to provide an ablation study relevant to this, but the case of percentage of labeled images as 0 would be interesting. \n- Conceptually, the transformation equivariance loss in (2) is similar to equivariant landmark transformation loss proposed by Honari et al. (2018) and recent other variants. The authors argue the proposed loss in (2) are different with them in that the previous methods leverage an inverse transformation. But, the methodological improvement is marginal and incremental.\n- Transformation invariance loss in (4) is also interesting, but the loss itself might not contribute the performance gain. For example, if z and z' converge to 0, the loss is going to be minimum, but the networks are not trained well. \n- In addition, because the paper solves the semi-supervised learning, the weights of loss components are important hyper-parameters, but there lack the ablation study for those.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper2660/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper2660/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Semi-supervised Keypoint Localization", "authorids": ["~Olga_Moskvyak1", "~Frederic_Maire1", "~Feras_Dayoub1", "~Mahsa_Baktashmotlagh1"], "authors": ["Olga Moskvyak", "Frederic Maire", "Feras Dayoub", "Mahsa Baktashmotlagh"], "keywords": ["semi-supervised learning", "keypoint localization", "limited data", "unsupervised loss"], "abstract": "Knowledge about the locations of keypoints of an object in an image can assist in fine-grained classification and identification tasks, particularly for the case of objects that exhibit large variations in poses that greatly influence their visual appearance, such as wild animals. However, supervised training of a keypoint detection network requires annotating a large image dataset for each animal species, which is a labor-intensive task. To reduce the need for labeled data, we propose to learn simultaneously keypoint heatmaps and pose invariant keypoint representations in a semi-supervised manner using a small set of labeled images along with a larger set of unlabeled images. Keypoint representations are learnt with a semantic keypoint consistency constraint that forces the keypoint detection network to learn similar features for the same keypoint across the dataset. Pose invariance is achieved by making keypoint representations for the image and its augmented copies closer together in feature space. Our semi-supervised approach significantly outperforms previous methods on several benchmarks for human and animal body landmark localization.", "one-sentence_summary": "A novel method for semi-supervised keypoint localization via learning semantic keypoint representations.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "moskvyak|semisupervised_keypoint_localization", "supplementary_material": "/attachment/b5162dde48bb712cd85686eb240af271f9c208e3.zip", "pdf": "/pdf/60b9fa896e2494cd3d4cdf45231c251d92e4bb9f.pdf", "venue": "ICLR 2021 Poster", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nmoskvyak2021semisupervised,\ntitle={Semi-supervised Keypoint Localization},\nauthor={Olga Moskvyak and Frederic Maire and Feras Dayoub and Mahsa Baktashmotlagh},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=yFJ67zTeI2}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "yFJ67zTeI2", "replyto": "yFJ67zTeI2", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper2660/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538091320, "tmdate": 1606915791727, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper2660/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper2660/-/Official_Review"}}}], "count": 11}