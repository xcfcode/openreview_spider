{"notes": [{"id": "SkeyppEFvS", "original": "rygHguxuwS", "number": 804, "cdate": 1569439159479, "ddate": null, "tcdate": 1569439159479, "tmdate": 1583912052675, "tddate": null, "forum": "SkeyppEFvS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["fabien.baradel@insa-lyon.fr", "nneverova@fb.com", "julien.mille@insa-cvl.fr", "mori@cs.sfu.ca", "christian.wolf@insa-lyon.fr"], "title": "CoPhy: Counterfactual Learning of Physical Dynamics", "authors": ["Fabien Baradel", "Natalia Neverova", "Julien Mille", "Greg Mori", "Christian Wolf"], "pdf": "/pdf/f00a0eeedb2a7f893adea8ba02e04d6836be26b0.pdf", "abstract": "Understanding causes and effects in mechanical systems is an essential component of reasoning in the physical world. This work poses a new problem of counterfactual learning of object mechanics from visual input.  We develop the CoPhy benchmark to assess the capacity of the state-of-the-art models for causal physical reasoning in a synthetic 3D environment and propose a model for learning the physical dynamics in a counterfactual setting. Having observed a mechanical experiment that involves, for example, a falling tower of blocks, a set of bouncing balls or colliding objects, we learn to predict how its outcome is affected by an arbitrary intervention on its initial conditions, such as displacing one of the objects in the scene. The alternative future is predicted given the altered past and a latent representation of the confounders learned by the model in an end-to-end fashion with no supervision. We compare against feedforward video prediction baselines and show how observing alternative experiences allows the network to capture latent physical properties of the environment, which results in significantly more accurate predictions at the level of super human performance.", "keywords": ["intuitive physics", "visual reasoning"], "paperhash": "baradel|cophy_counterfactual_learning_of_physical_dynamics", "code": "https://github.com/fabienbaradel/cophy", "_bibtex": "@inproceedings{\nBaradel2020CoPhy:,\ntitle={CoPhy: Counterfactual Learning of Physical Dynamics},\nauthor={Fabien Baradel and Natalia Neverova and Julien Mille and Greg Mori and Christian Wolf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SkeyppEFvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/503b179d2367c446d221d0f628acaf9a4497bd85.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 10, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "ICLR.cc/2020/Conference"}, {"id": "7HUOXMKov", "original": null, "number": 1, "cdate": 1576798706621, "ddate": null, "tcdate": 1576798706621, "tmdate": 1576800929621, "tddate": null, "forum": "SkeyppEFvS", "replyto": "SkeyppEFvS", "invitation": "ICLR.cc/2020/Conference/Paper804/-/Decision", "content": {"decision": "Accept (Spotlight)", "comment": "The reviewers are unanimous in their opinion that this paper offers a novel approach to learning na\u00efve physics.  I concur.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["fabien.baradel@insa-lyon.fr", "nneverova@fb.com", "julien.mille@insa-cvl.fr", "mori@cs.sfu.ca", "christian.wolf@insa-lyon.fr"], "title": "CoPhy: Counterfactual Learning of Physical Dynamics", "authors": ["Fabien Baradel", "Natalia Neverova", "Julien Mille", "Greg Mori", "Christian Wolf"], "pdf": "/pdf/f00a0eeedb2a7f893adea8ba02e04d6836be26b0.pdf", "abstract": "Understanding causes and effects in mechanical systems is an essential component of reasoning in the physical world. This work poses a new problem of counterfactual learning of object mechanics from visual input.  We develop the CoPhy benchmark to assess the capacity of the state-of-the-art models for causal physical reasoning in a synthetic 3D environment and propose a model for learning the physical dynamics in a counterfactual setting. Having observed a mechanical experiment that involves, for example, a falling tower of blocks, a set of bouncing balls or colliding objects, we learn to predict how its outcome is affected by an arbitrary intervention on its initial conditions, such as displacing one of the objects in the scene. The alternative future is predicted given the altered past and a latent representation of the confounders learned by the model in an end-to-end fashion with no supervision. We compare against feedforward video prediction baselines and show how observing alternative experiences allows the network to capture latent physical properties of the environment, which results in significantly more accurate predictions at the level of super human performance.", "keywords": ["intuitive physics", "visual reasoning"], "paperhash": "baradel|cophy_counterfactual_learning_of_physical_dynamics", "code": "https://github.com/fabienbaradel/cophy", "_bibtex": "@inproceedings{\nBaradel2020CoPhy:,\ntitle={CoPhy: Counterfactual Learning of Physical Dynamics},\nauthor={Fabien Baradel and Natalia Neverova and Julien Mille and Greg Mori and Christian Wolf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SkeyppEFvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/503b179d2367c446d221d0f628acaf9a4497bd85.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "SkeyppEFvS", "replyto": "SkeyppEFvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795713611, "tmdate": 1576800263262, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper804/-/Decision"}}}, {"id": "ryloApppFB", "original": null, "number": 1, "cdate": 1571835346575, "ddate": null, "tcdate": 1571835346575, "tmdate": 1574379785983, "tddate": null, "forum": "SkeyppEFvS", "replyto": "SkeyppEFvS", "invitation": "ICLR.cc/2020/Conference/Paper804/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "N/A", "title": "Official Blind Review #3", "review": "Update: after revision, I have decided to keep the score unchanged.\n\nOriginal comments:\n\nIn this paper, the authors proposed a new method to learn physical dynamics based on counterfactual reasoning. \n\n1. As also summarized by the paper, over recent years, there has been increasing interest in the research community for the study of visual reasoning, intuitive physics and perceptual causality. This work provides an interesting framework that combines all the three domains together to solve the problem of learning physical dynamics. The experimental result also shows promise. \n\n2. This paper also provides a nice work that bridges the gap between the counterfactual reasoning and deep learning community.\n\nWith all of this said, I think overall the paper is an interesting addition to the causal inference and deep learning literature.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"}, "signatures": ["ICLR.cc/2020/Conference/Paper804/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper804/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["fabien.baradel@insa-lyon.fr", "nneverova@fb.com", "julien.mille@insa-cvl.fr", "mori@cs.sfu.ca", "christian.wolf@insa-lyon.fr"], "title": "CoPhy: Counterfactual Learning of Physical Dynamics", "authors": ["Fabien Baradel", "Natalia Neverova", "Julien Mille", "Greg Mori", "Christian Wolf"], "pdf": "/pdf/f00a0eeedb2a7f893adea8ba02e04d6836be26b0.pdf", "abstract": "Understanding causes and effects in mechanical systems is an essential component of reasoning in the physical world. This work poses a new problem of counterfactual learning of object mechanics from visual input.  We develop the CoPhy benchmark to assess the capacity of the state-of-the-art models for causal physical reasoning in a synthetic 3D environment and propose a model for learning the physical dynamics in a counterfactual setting. Having observed a mechanical experiment that involves, for example, a falling tower of blocks, a set of bouncing balls or colliding objects, we learn to predict how its outcome is affected by an arbitrary intervention on its initial conditions, such as displacing one of the objects in the scene. The alternative future is predicted given the altered past and a latent representation of the confounders learned by the model in an end-to-end fashion with no supervision. We compare against feedforward video prediction baselines and show how observing alternative experiences allows the network to capture latent physical properties of the environment, which results in significantly more accurate predictions at the level of super human performance.", "keywords": ["intuitive physics", "visual reasoning"], "paperhash": "baradel|cophy_counterfactual_learning_of_physical_dynamics", "code": "https://github.com/fabienbaradel/cophy", "_bibtex": "@inproceedings{\nBaradel2020CoPhy:,\ntitle={CoPhy: Counterfactual Learning of Physical Dynamics},\nauthor={Fabien Baradel and Natalia Neverova and Julien Mille and Greg Mori and Christian Wolf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SkeyppEFvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/503b179d2367c446d221d0f628acaf9a4497bd85.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SkeyppEFvS", "replyto": "SkeyppEFvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper804/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper804/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575916780113, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper804/Reviewers"], "noninvitees": [], "tcdate": 1570237746761, "tmdate": 1575916780126, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper804/-/Official_Review"}}}, {"id": "BkgCHpSosB", "original": null, "number": 6, "cdate": 1573768518516, "ddate": null, "tcdate": 1573768518516, "tmdate": 1573768518516, "tddate": null, "forum": "SkeyppEFvS", "replyto": "rke4DbQqsS", "invitation": "ICLR.cc/2020/Conference/Paper804/-/Official_Comment", "content": {"title": "Re: Response to Review 2", "comment": "We are pleased that the rebuttal addressed your comments. We agree that with some of our responses we targeted the reviewers more than the readers, and that these points should also be included in the paper. This now has been done.\n\n- The abstract has been changed as requested.\n\n- The related works section now contains a new paragraph ``Other physics benchmarks and simulators'' with a discussion which is heavily based on our rebuttal, and which should clearly distinguish the goals of CoPHy compared with IntPhys and Phyre."}, "signatures": ["ICLR.cc/2020/Conference/Paper804/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper804/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["fabien.baradel@insa-lyon.fr", "nneverova@fb.com", "julien.mille@insa-cvl.fr", "mori@cs.sfu.ca", "christian.wolf@insa-lyon.fr"], "title": "CoPhy: Counterfactual Learning of Physical Dynamics", "authors": ["Fabien Baradel", "Natalia Neverova", "Julien Mille", "Greg Mori", "Christian Wolf"], "pdf": "/pdf/f00a0eeedb2a7f893adea8ba02e04d6836be26b0.pdf", "abstract": "Understanding causes and effects in mechanical systems is an essential component of reasoning in the physical world. This work poses a new problem of counterfactual learning of object mechanics from visual input.  We develop the CoPhy benchmark to assess the capacity of the state-of-the-art models for causal physical reasoning in a synthetic 3D environment and propose a model for learning the physical dynamics in a counterfactual setting. Having observed a mechanical experiment that involves, for example, a falling tower of blocks, a set of bouncing balls or colliding objects, we learn to predict how its outcome is affected by an arbitrary intervention on its initial conditions, such as displacing one of the objects in the scene. The alternative future is predicted given the altered past and a latent representation of the confounders learned by the model in an end-to-end fashion with no supervision. We compare against feedforward video prediction baselines and show how observing alternative experiences allows the network to capture latent physical properties of the environment, which results in significantly more accurate predictions at the level of super human performance.", "keywords": ["intuitive physics", "visual reasoning"], "paperhash": "baradel|cophy_counterfactual_learning_of_physical_dynamics", "code": "https://github.com/fabienbaradel/cophy", "_bibtex": "@inproceedings{\nBaradel2020CoPhy:,\ntitle={CoPhy: Counterfactual Learning of Physical Dynamics},\nauthor={Fabien Baradel and Natalia Neverova and Julien Mille and Greg Mori and Christian Wolf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SkeyppEFvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/503b179d2367c446d221d0f628acaf9a4497bd85.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SkeyppEFvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper804/Authors", "ICLR.cc/2020/Conference/Paper804/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper804/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper804/Reviewers", "ICLR.cc/2020/Conference/Paper804/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper804/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper804/Authors|ICLR.cc/2020/Conference/Paper804/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165967, "tmdate": 1576860543878, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper804/Authors", "ICLR.cc/2020/Conference/Paper804/Reviewers", "ICLR.cc/2020/Conference/Paper804/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper804/-/Official_Comment"}}}, {"id": "rke4DbQqsS", "original": null, "number": 5, "cdate": 1573691740213, "ddate": null, "tcdate": 1573691740213, "tmdate": 1573691763914, "tddate": null, "forum": "SkeyppEFvS", "replyto": "Skesm4MLoB", "invitation": "ICLR.cc/2020/Conference/Paper804/-/Official_Comment", "content": {"title": "Response to \"Response to Review 2\"", "comment": "I am satisfied with your responses, but I would like to see them better-integrated into the paper so that future readers will not have the same doubts as me.\n\n- In the abstract, change \"with no supervision\" to \"with no supervision of confounders\" (so that it doesn't read like _only_ observations are available)\n\n- Please include more clarification in the paper about why a reader would want to use the proposed dataset instead of IntPhys or Phyre. This can probably be done easily by integrating the discussion from your response above. It should be clear from the paper, that, essentially: \"If I want to solve/evaluate tasks X, simulators A and B may appear related, but they are missing Y which is important to be able to solve/evaluate X because of Z.\""}, "signatures": ["ICLR.cc/2020/Conference/Paper804/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper804/AnonReviewer2", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["fabien.baradel@insa-lyon.fr", "nneverova@fb.com", "julien.mille@insa-cvl.fr", "mori@cs.sfu.ca", "christian.wolf@insa-lyon.fr"], "title": "CoPhy: Counterfactual Learning of Physical Dynamics", "authors": ["Fabien Baradel", "Natalia Neverova", "Julien Mille", "Greg Mori", "Christian Wolf"], "pdf": "/pdf/f00a0eeedb2a7f893adea8ba02e04d6836be26b0.pdf", "abstract": "Understanding causes and effects in mechanical systems is an essential component of reasoning in the physical world. This work poses a new problem of counterfactual learning of object mechanics from visual input.  We develop the CoPhy benchmark to assess the capacity of the state-of-the-art models for causal physical reasoning in a synthetic 3D environment and propose a model for learning the physical dynamics in a counterfactual setting. Having observed a mechanical experiment that involves, for example, a falling tower of blocks, a set of bouncing balls or colliding objects, we learn to predict how its outcome is affected by an arbitrary intervention on its initial conditions, such as displacing one of the objects in the scene. The alternative future is predicted given the altered past and a latent representation of the confounders learned by the model in an end-to-end fashion with no supervision. We compare against feedforward video prediction baselines and show how observing alternative experiences allows the network to capture latent physical properties of the environment, which results in significantly more accurate predictions at the level of super human performance.", "keywords": ["intuitive physics", "visual reasoning"], "paperhash": "baradel|cophy_counterfactual_learning_of_physical_dynamics", "code": "https://github.com/fabienbaradel/cophy", "_bibtex": "@inproceedings{\nBaradel2020CoPhy:,\ntitle={CoPhy: Counterfactual Learning of Physical Dynamics},\nauthor={Fabien Baradel and Natalia Neverova and Julien Mille and Greg Mori and Christian Wolf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SkeyppEFvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/503b179d2367c446d221d0f628acaf9a4497bd85.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SkeyppEFvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper804/Authors", "ICLR.cc/2020/Conference/Paper804/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper804/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper804/Reviewers", "ICLR.cc/2020/Conference/Paper804/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper804/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper804/Authors|ICLR.cc/2020/Conference/Paper804/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165967, "tmdate": 1576860543878, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper804/Authors", "ICLR.cc/2020/Conference/Paper804/Reviewers", "ICLR.cc/2020/Conference/Paper804/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper804/-/Official_Comment"}}}, {"id": "Skesm4MLoB", "original": null, "number": 4, "cdate": 1573426211295, "ddate": null, "tcdate": 1573426211295, "tmdate": 1573426211295, "tddate": null, "forum": "SkeyppEFvS", "replyto": "H1lOZEz8ir", "invitation": "ICLR.cc/2020/Conference/Paper804/-/Official_Comment", "content": {"title": "Response to Review 2: Part 2", "comment": "* Further questions:\n\nYes, NPE and IN are both feedforward methods which leverage access to the ground-truth positions at training and test time and which thus assume that the de-rendering step is solved. They reason on positions. We added a new paragraph to the appendix giving more details on IN and NPE.\n\nWhile CophyNet consistently outperforms the baselines in comparable settings, we agree that it does not always outperforms the augmented (i.e. ``cheating'') variants, we modified this statement in the revised paper.\n\nWe did not introduce stochasticity into the created data. The prediction are fully deterministic given the object position and the confounder quantities of each object up to the inherent stochasticity of the physical simulator.\n\nAs requested, in the revised paper We now introduce the supervision on GT object positions very early, when the sequences A,B,C,D are introduced at the beginning of section 3. We also introduce the symbol right after the equation of the training objective. This has been changed in the revised version of the paper.\n\nWe also added experiments on GT object positions as input, i.e. without the  derendering step during training, to the appendix. The performance is slightly better when the model is fed GT positions during training, as expected.\n\nIn Fig. 2 we use four different colors for differentiating the different states of the counterfactual process (blue for A and B (original past and outcome), red for C (modified/alternative past) and green for D (alternative outcome)). We are of course aware of standards in graphical models indicating the difference between observed (shown shaded) and latent (shown empty) variables. However, we think that the distinction between A,B,C,D is so central to our paper, that we chose these colors as a running thread used throughout the paper to make these differences clearer. They are used in figures 1, 2 and 4, so not only in the figure showing graphical model notation. We also respect GM notation in that all observed nodes are shaded (A,B,C,D are observed during training, the confounders are not).\n\nUnfortunately we will not have enough time during the rebuttal phase to produce the proposed baseline experiments (stacking A,B,C to produce D), but we agree that it makes sense to perform them, thank you for the remark. However, A+B alone is a sequence of non-neglectable length (20 instants), so stacking would very likely be a sub-optimal solution, akin to stacking in other sequence tasks like activity recognition or NLP, and as opposed to RNNs, 1D convolutions, or attention/transformers. On a related note, we experimented with replacing graph convolutional networks with stacking, which led to bad results, as expected.\n\nWe replaced double quotes by back tics for forward quotes, as is LaTeX standard, agreed."}, "signatures": ["ICLR.cc/2020/Conference/Paper804/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper804/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["fabien.baradel@insa-lyon.fr", "nneverova@fb.com", "julien.mille@insa-cvl.fr", "mori@cs.sfu.ca", "christian.wolf@insa-lyon.fr"], "title": "CoPhy: Counterfactual Learning of Physical Dynamics", "authors": ["Fabien Baradel", "Natalia Neverova", "Julien Mille", "Greg Mori", "Christian Wolf"], "pdf": "/pdf/f00a0eeedb2a7f893adea8ba02e04d6836be26b0.pdf", "abstract": "Understanding causes and effects in mechanical systems is an essential component of reasoning in the physical world. This work poses a new problem of counterfactual learning of object mechanics from visual input.  We develop the CoPhy benchmark to assess the capacity of the state-of-the-art models for causal physical reasoning in a synthetic 3D environment and propose a model for learning the physical dynamics in a counterfactual setting. Having observed a mechanical experiment that involves, for example, a falling tower of blocks, a set of bouncing balls or colliding objects, we learn to predict how its outcome is affected by an arbitrary intervention on its initial conditions, such as displacing one of the objects in the scene. The alternative future is predicted given the altered past and a latent representation of the confounders learned by the model in an end-to-end fashion with no supervision. We compare against feedforward video prediction baselines and show how observing alternative experiences allows the network to capture latent physical properties of the environment, which results in significantly more accurate predictions at the level of super human performance.", "keywords": ["intuitive physics", "visual reasoning"], "paperhash": "baradel|cophy_counterfactual_learning_of_physical_dynamics", "code": "https://github.com/fabienbaradel/cophy", "_bibtex": "@inproceedings{\nBaradel2020CoPhy:,\ntitle={CoPhy: Counterfactual Learning of Physical Dynamics},\nauthor={Fabien Baradel and Natalia Neverova and Julien Mille and Greg Mori and Christian Wolf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SkeyppEFvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/503b179d2367c446d221d0f628acaf9a4497bd85.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SkeyppEFvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper804/Authors", "ICLR.cc/2020/Conference/Paper804/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper804/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper804/Reviewers", "ICLR.cc/2020/Conference/Paper804/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper804/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper804/Authors|ICLR.cc/2020/Conference/Paper804/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165967, "tmdate": 1576860543878, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper804/Authors", "ICLR.cc/2020/Conference/Paper804/Reviewers", "ICLR.cc/2020/Conference/Paper804/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper804/-/Official_Comment"}}}, {"id": "H1lOZEz8ir", "original": null, "number": 3, "cdate": 1573426175783, "ddate": null, "tcdate": 1573426175783, "tmdate": 1573426175783, "tddate": null, "forum": "SkeyppEFvS", "replyto": "B1gVN4rCtS", "invitation": "ICLR.cc/2020/Conference/Paper804/-/Official_Comment", "content": {"title": "Response to Review 2: Part 1", "comment": "We are glad that R2 appreciates the novelty, importance and difficulty of the task, in particular that he estimates that \"other researchers are likely to build on the task and data released\". We want to thanks R2 for his valuable and detailed feedback. Below are our answers:\n\n* Solving the problem in high-dimensional space:\n\nOur input are high-dimensional images, but we provide supervision of GT positions during training time. We see this as an inductive bias, which currently makes it feasible to solve the problem, but we agree that at some point the goal should be to remove this. We think that the current state of the art in machine learning is not yet ready to tackle the problem directly.\n\nWe would like to point out, that even our de-rendering module tackles a more difficult problem than the state of the art, which reasons on ground truth positions (done by the leading methods IN and NPE). Compared to this, our method goes one step further. Our object-centric approach still needs to address noise and incorrect estimations of the object positions, compared to existing literature.\n\n* Justification over recent intuitive physic simulators:\n\nThe main objective of this study on the data construction side is creating a benchmark that is (a) focused specifically on evaluating capabilities of state of the art models for performing counterfactual reasoning, in a clean way, (b) unbiased in terms of distributions of parameters to be estimated and balanced with respect to possible outcomes (c) has sufficient variety in terms of scenarios and latent physical characteristics of the scene that are not visually observed and therefore can act as confounders. To be best of our knowledge, none of existing intuitive physics benchmarks have these properties. The IntPhys benchmark by Riochet et al. is focused on a high level task of estimating physical plausibility in a black box fashion and modeling out of distribution events at test time. Phyre by Bakhtin et al. is an environment for solving physics based puzzles, where achieving sample efficiency may implicitly require counterfactual reasoning, but this component is not explicitly evaluated, construction of parallel data with several alternative outcomes here is not straightforward, and the trivial baseline performance levels are not easy to estimate. Adapting these benchmarks for the task of counterfactual reasoning would require a significant refactoring and changing the logic of the data sampling.\nAt the same time, we agree that the models discussed in our work could be adapted and inspire future work applied in these other settings as well.    \n\n* Ambiguity on experiments\n\nad 0) We updated the table references (confusion of references to tables 5 and 6) and apologize for this.\n\nad 1) We consider a feedforward method an approach taking into account C only, so only the modified past and _NOT_ the original past (A) and outcome (B). This corresponds to classical non-counterfactual prediction of the future, which is an ill-posed problem since the confounder estimates are not available (unless explicitly fed in). We give a definition of feedforward future forecasting in Figure 2 (Left) and surrounding text. \n\nad 2) The random baseline level in Table 5 corresponds to the chance results from a uniform distribution as a baseline classifier. This has been added to the revised version.\n\nad 3) For the prediction of mass and friction coefficients, we use a dense layer on top of the \"confounder\" representation of each object denoted u^k. This description has been added to the appendix of the paper (other architectures section).\n\n* Human studies:\n\nWe will downplay the comparison against human baselines, but we still think that it is interesting to know that humans are outperformed per simple baselines, since this is an experimental result per see, which to us was not obvious beforehand."}, "signatures": ["ICLR.cc/2020/Conference/Paper804/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper804/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["fabien.baradel@insa-lyon.fr", "nneverova@fb.com", "julien.mille@insa-cvl.fr", "mori@cs.sfu.ca", "christian.wolf@insa-lyon.fr"], "title": "CoPhy: Counterfactual Learning of Physical Dynamics", "authors": ["Fabien Baradel", "Natalia Neverova", "Julien Mille", "Greg Mori", "Christian Wolf"], "pdf": "/pdf/f00a0eeedb2a7f893adea8ba02e04d6836be26b0.pdf", "abstract": "Understanding causes and effects in mechanical systems is an essential component of reasoning in the physical world. This work poses a new problem of counterfactual learning of object mechanics from visual input.  We develop the CoPhy benchmark to assess the capacity of the state-of-the-art models for causal physical reasoning in a synthetic 3D environment and propose a model for learning the physical dynamics in a counterfactual setting. Having observed a mechanical experiment that involves, for example, a falling tower of blocks, a set of bouncing balls or colliding objects, we learn to predict how its outcome is affected by an arbitrary intervention on its initial conditions, such as displacing one of the objects in the scene. The alternative future is predicted given the altered past and a latent representation of the confounders learned by the model in an end-to-end fashion with no supervision. We compare against feedforward video prediction baselines and show how observing alternative experiences allows the network to capture latent physical properties of the environment, which results in significantly more accurate predictions at the level of super human performance.", "keywords": ["intuitive physics", "visual reasoning"], "paperhash": "baradel|cophy_counterfactual_learning_of_physical_dynamics", "code": "https://github.com/fabienbaradel/cophy", "_bibtex": "@inproceedings{\nBaradel2020CoPhy:,\ntitle={CoPhy: Counterfactual Learning of Physical Dynamics},\nauthor={Fabien Baradel and Natalia Neverova and Julien Mille and Greg Mori and Christian Wolf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SkeyppEFvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/503b179d2367c446d221d0f628acaf9a4497bd85.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SkeyppEFvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper804/Authors", "ICLR.cc/2020/Conference/Paper804/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper804/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper804/Reviewers", "ICLR.cc/2020/Conference/Paper804/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper804/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper804/Authors|ICLR.cc/2020/Conference/Paper804/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165967, "tmdate": 1576860543878, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper804/Authors", "ICLR.cc/2020/Conference/Paper804/Reviewers", "ICLR.cc/2020/Conference/Paper804/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper804/-/Official_Comment"}}}, {"id": "Byl-77z8sr", "original": null, "number": 2, "cdate": 1573425945462, "ddate": null, "tcdate": 1573425945462, "tmdate": 1573425945462, "tddate": null, "forum": "SkeyppEFvS", "replyto": "BkMT-8Rtr", "invitation": "ICLR.cc/2020/Conference/Paper804/-/Official_Comment", "content": {"title": "Response to Review 1", "comment": "We are glad that R1 appreciates the novelty and importance of the task. Below are our answers, we also revised and updated the paper itself.\n\n* Experiments on real data:\n\nLearning physics is a hard problem, which (up to our knowledge) has been addressed on simulated data only by the community up to now. In particular, we are not aware of any dataset where counterfactual learning can be performed on physics. Up to our knowledge we are the first to tackle this problem. We agree that an important task for the community will be to extend this type of problems to more general domains, but we think this is just not yet within the reach of our algorithms.\n\n* De-rendering module for complex real scenes:\n\nThe de-rendering module can be seen as an object detection module, which should be easily generalizeable to more complex scenes, in particular when the backbone is changed to methods performing instance segmentation like Mask R-CNN. Recent works in action recognition have been using such object-centric approaches such as Actor-centric relation networks [1], Video as a Space-Time Graph [2] or Object Relational Networks [3]:\n\n[1] \"Actor-Centric Relation Network\", Sun, Shrivastava, Vondrick, Murphy, Sukthankar, Schmid, ECCV 2018\n[2] \"Video as a Space-Time Graph\", Wang, Gupta, ECCV 2018\n[3] \"Object level visual Reasoning in Videos\", Baradel, Neverova, Wolf, Mille, Mori, ECCV 2018\n\n* Ablation experiments on ball/collision scenarios.\n\nBlocktowerCF is arguably the most complex dataset of the three, so most of our ablation experiments are reserved on this dataset. That said, we do provide ablations on the two other datasets, showing the generalization of the model to unknown regimes: In Table 3 we provide results on BallsCF when the model is trained on N balls and tested on K balls where K!=N and we show that our proposed approach outperforms baselines. In Table 4 we provide results on CollisionCF when the model is trained with a certain type of moving object (e.g. sphere) and tested with another type of moving object (e.g. cylinder). We show that the model generalizes well compared to the baselines.\n\n* Human studies on ball/collision scenarios\n\nThe human studies were meant to be complementary to the neural estimators. Given the short available time for the rebuttal we unfortunately cannot provide a human study for the two other scenarios (balls and collisions). We think that human studies on BlockTowerCF should provide indications about human performance on a counterfactual visual setup, in particular since the targeted subset is the most challenging one."}, "signatures": ["ICLR.cc/2020/Conference/Paper804/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper804/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["fabien.baradel@insa-lyon.fr", "nneverova@fb.com", "julien.mille@insa-cvl.fr", "mori@cs.sfu.ca", "christian.wolf@insa-lyon.fr"], "title": "CoPhy: Counterfactual Learning of Physical Dynamics", "authors": ["Fabien Baradel", "Natalia Neverova", "Julien Mille", "Greg Mori", "Christian Wolf"], "pdf": "/pdf/f00a0eeedb2a7f893adea8ba02e04d6836be26b0.pdf", "abstract": "Understanding causes and effects in mechanical systems is an essential component of reasoning in the physical world. This work poses a new problem of counterfactual learning of object mechanics from visual input.  We develop the CoPhy benchmark to assess the capacity of the state-of-the-art models for causal physical reasoning in a synthetic 3D environment and propose a model for learning the physical dynamics in a counterfactual setting. Having observed a mechanical experiment that involves, for example, a falling tower of blocks, a set of bouncing balls or colliding objects, we learn to predict how its outcome is affected by an arbitrary intervention on its initial conditions, such as displacing one of the objects in the scene. The alternative future is predicted given the altered past and a latent representation of the confounders learned by the model in an end-to-end fashion with no supervision. We compare against feedforward video prediction baselines and show how observing alternative experiences allows the network to capture latent physical properties of the environment, which results in significantly more accurate predictions at the level of super human performance.", "keywords": ["intuitive physics", "visual reasoning"], "paperhash": "baradel|cophy_counterfactual_learning_of_physical_dynamics", "code": "https://github.com/fabienbaradel/cophy", "_bibtex": "@inproceedings{\nBaradel2020CoPhy:,\ntitle={CoPhy: Counterfactual Learning of Physical Dynamics},\nauthor={Fabien Baradel and Natalia Neverova and Julien Mille and Greg Mori and Christian Wolf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SkeyppEFvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/503b179d2367c446d221d0f628acaf9a4497bd85.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SkeyppEFvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper804/Authors", "ICLR.cc/2020/Conference/Paper804/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper804/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper804/Reviewers", "ICLR.cc/2020/Conference/Paper804/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper804/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper804/Authors|ICLR.cc/2020/Conference/Paper804/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165967, "tmdate": 1576860543878, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper804/Authors", "ICLR.cc/2020/Conference/Paper804/Reviewers", "ICLR.cc/2020/Conference/Paper804/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper804/-/Official_Comment"}}}, {"id": "BJeBRMzUsB", "original": null, "number": 1, "cdate": 1573425869182, "ddate": null, "tcdate": 1573425869182, "tmdate": 1573425869182, "tddate": null, "forum": "SkeyppEFvS", "replyto": "ryloApppFB", "invitation": "ICLR.cc/2020/Conference/Paper804/-/Official_Comment", "content": {"title": "Response to Review 3", "comment": "We are glad that R3 has appreciated this work as bridging the gap between deep learning and counterfactual reasoning / causal inference. We indeed hope that this will lead to increased communication and joint work between these communities."}, "signatures": ["ICLR.cc/2020/Conference/Paper804/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper804/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["fabien.baradel@insa-lyon.fr", "nneverova@fb.com", "julien.mille@insa-cvl.fr", "mori@cs.sfu.ca", "christian.wolf@insa-lyon.fr"], "title": "CoPhy: Counterfactual Learning of Physical Dynamics", "authors": ["Fabien Baradel", "Natalia Neverova", "Julien Mille", "Greg Mori", "Christian Wolf"], "pdf": "/pdf/f00a0eeedb2a7f893adea8ba02e04d6836be26b0.pdf", "abstract": "Understanding causes and effects in mechanical systems is an essential component of reasoning in the physical world. This work poses a new problem of counterfactual learning of object mechanics from visual input.  We develop the CoPhy benchmark to assess the capacity of the state-of-the-art models for causal physical reasoning in a synthetic 3D environment and propose a model for learning the physical dynamics in a counterfactual setting. Having observed a mechanical experiment that involves, for example, a falling tower of blocks, a set of bouncing balls or colliding objects, we learn to predict how its outcome is affected by an arbitrary intervention on its initial conditions, such as displacing one of the objects in the scene. The alternative future is predicted given the altered past and a latent representation of the confounders learned by the model in an end-to-end fashion with no supervision. We compare against feedforward video prediction baselines and show how observing alternative experiences allows the network to capture latent physical properties of the environment, which results in significantly more accurate predictions at the level of super human performance.", "keywords": ["intuitive physics", "visual reasoning"], "paperhash": "baradel|cophy_counterfactual_learning_of_physical_dynamics", "code": "https://github.com/fabienbaradel/cophy", "_bibtex": "@inproceedings{\nBaradel2020CoPhy:,\ntitle={CoPhy: Counterfactual Learning of Physical Dynamics},\nauthor={Fabien Baradel and Natalia Neverova and Julien Mille and Greg Mori and Christian Wolf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SkeyppEFvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/503b179d2367c446d221d0f628acaf9a4497bd85.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "SkeyppEFvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper804/Authors", "ICLR.cc/2020/Conference/Paper804/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper804/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper804/Reviewers", "ICLR.cc/2020/Conference/Paper804/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper804/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper804/Authors|ICLR.cc/2020/Conference/Paper804/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504165967, "tmdate": 1576860543878, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper804/Authors", "ICLR.cc/2020/Conference/Paper804/Reviewers", "ICLR.cc/2020/Conference/Paper804/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper804/-/Official_Comment"}}}, {"id": "B1gVN4rCtS", "original": null, "number": 2, "cdate": 1571865643935, "ddate": null, "tcdate": 1571865643935, "tmdate": 1572972550204, "tddate": null, "forum": "SkeyppEFvS", "replyto": "SkeyppEFvS", "invitation": "ICLR.cc/2020/Conference/Paper804/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "Summary of what the paper claims and contributes\n---\nThis paper presents a new object forecasting task in the setting of \"intuitive physics\" that requires counterfactual reasoning and also presents method to perform this task. The task is to predict the alternative future trajectory of objects in 3D simulation given a video (A_frame,B_frames) of how the objects move in one situation and an alternative single frame (C_frame) that corresponds to modifying object position(s) at the first timestep of the input video. Due to unobserved confounding factors such as mass and friction that are not directly observable in either the video or the intervened frame, successful forecasting requires either implicitly or explicitly estimating these confounders. The motivation for this task is the hypothesis that counterfactual reasoning is a necessary component to forecast in general, unobserved situations. Prior work on explicit causal reasoning mainly concerns lower-dimensional problems, and prior work on high-dimensional \"intuitive physics\" has not evaluated the capability of models to perform counterfactual reasoning.\n\nThe paper proposes a neural network that learns to implicitly predict sufficient statistics of confounders of the situation. Training occurs in two stages. First, it is trained to estimate 3d positions of objects from images given pairs of (image, ground truth 3d positions). Then, it is trained to forecast future unobserved object positions with a graph convolutional network. Inference is performed by estimating the current object positions in all of the frames of the input (A_frame, B_frames), and then using the final representation of the input situation as the representation of confounders that is fed into the alternative-future prediction.\n\nThe experiments find:\n1) Humans are not very good at these specific tasks, as evidenced by a simple position-copying baseline that outperforms humans. Given that the simple copying baseline is so performant, the claim in the abstract of \"super human performance\"  is also true for the copying baseline, and therefore that claim isn't very meaningful and should be removed.\n2) The proposed approach outperforms position-copying and two non-counterfactual approaches that do not reason (explicitly or implicitly) about confounders,.\n3) The approach attempts to show that confounder representations are learned as the main evidence that the model can perform counterfactual reasoning. However, several aspects of this experiment are unclear, making the claim difficult to evaluate.\n\nFinally, although the abstract and the main text say that the task is to perform counterfactual forecasting in high-dimensional scenarios in a unsupervised way, the paper ends up using direct supervision of the object positions. With this knowledge, the problem is not that different than counterfactual forecasting in low-dimensional settings, as the positions of the objects at all frames corresponding to \\mathbf{A}, \\mathbf{B}, and \\mathbf{C} could simply be extracted with this detector. Thus, through this supervision the approach seems to circumvent most of the challenges imposed by high-dimensional forecasting.\n\nEvaluation\n---\n\n>Originality:\nAre the tasks or methods new?\nThe task of counterfactual forecasting from high-dimensional observations is new. The proposed method extends prior work to the new task.\n\nIs the work a novel combination of well-known techniques?\nYes.\n\nIs it clear how this work differs from previous contributions?\nYes.\n\nIs related work adequately cited?\nTo my knowledge, yes.\n\n>Quality:\nIs the submission technically sound?\nYes.\n\nAre claims well supported by theoretical analysis or experimental results?\nSome of the claims are supported, but the evidence for the counterfactual representation recovery claim is currently unclear. Additionally, the high-level motivation of counterfactual forecasting in high-dimensional settings is significantly undermined by the use of low-level supervision information that could feasibly be predicted at test time.\n\nIs this a complete piece of work or work in progress?\nIt seems relatively complete.\n\nAre the authors careful and honest about evaluating both the strengths and weaknesses of their work?\nWeaknesses are not explicitly explored. It would be good to include discussion that illuminates or hypothesizes when and why the method fails, and how it could be made to perform better.\n\n>Clarity:\nIs the submission clearly written?\nThe submission is mostly clear, however there are some significant ambiguities in the experiments.\n\nIs it well organized?\nYes.\n\nDoes it adequately inform the reader?\nMostly -- see ambiguities.\n\n>Significance:\nAre the results important?\nIt's currently unclear whether the results are significant, but it's clear the task is important (only when not supervised by object positions). However, justification with respect to other recent intuitive physics simulators is needed.\n\nAre others (researchers or practitioners) likely to use the ideas or build on them?\nOther researchers are likely to build on the task and data released.\n\nDoes the submission address a difficult task in a better way than previous work?\nN/A (new task)\n\nDoes it advance the state of the art in a demonstrable way?\nThere is no SOTA on this new task.\n\nDoes it provide unique data, unique conclusions about existing data, or a unique theoretical or experimental approach?\nYes, one of the main strengths of the paper is the task and dataset that will be released. This experimental approach could be very useful for future research.\n\nAdditional feedback\n---\nThe experiments to validate the cofounder estimation is unclear. Ambiguities:\n0) In the text, the classification of mass and friction is presented as follows: \"The obtained results are shown in Table 6 (middle)\", yet the results are in Table 5. The impact of confounder supervision is described as follows \"we do, however, explore what effect supervision could have on performance, as shown in Table 5\", yet the results are in Table 6. These typos, when combined with the layout of Tables 5 and 6, makes it very difficult to interpret these results.\n1) What is feedforward method? I can't find any description. Is this the IN or the NPE baseline, or something different? Why aren't both used? Without more details, its unclear that the proposed method actually learns confounder representations better than other methods.\n2) What is the \"random baseline level\"? Is this just chance results from a uniform distribution as a baseline classifier?\n3) What are the details of the classifier that predicts the mass and friction coefficients?\n\nIt is a bit odd to include comparisons to humans on a task on which the humans are outperformed by a very simple baseline. Either downplay the role of these comparisons, or remove these comparisons, or change the task such that humans cannot be outperformed by a simple baseline.\n\nMore details about the NPE and IN baselines are missing. Specifically, do they also leverage access to the ground-truth positions at training time? If so, how do they do this? This discussion is important for the paper to be self-contained. \n\nPage 9 \"The CophyNet model also consistently outperforms the augmented variants...\" the outperformance isn't present in all cases (i.e. not in 4->2 or 4->3); change to \"usually\".\n\nIt's not clear if there is any stochasticity in the dynamics of the created data (which would be relevant to modeling and evaluation).\n\nIt wasn't clear until page 7 that the training leveraged GT positions in 3d space. The training objective (equation after Eq (5)) has an undefined o^*, which the reader must infer corresponds to GT, or read appendix A.1, to understand. The description of the method was introduced in terms of A, B, C, and D which are images or videos. To me, the fact that GT 3D positions are used seems like it was \"buried\" later in the paper, rather than described up-front alongside the introduction of A, B, C, and D.\n\nThe meaning of the colors, if any, in Fig 2 is unclear. If they are meant to illustrate observed information, perhaps grayscale shading could be used instead, as is standard in PGMs.\n\nThe latent representation in Fig 4 appear to emerge just from the red object's RNN, rather than all of the objects RNNs.\n\nTables 1 and 2 appear very far from their description in the text.\n\nMore discussion is needed that relates the tasks in to the tasks in Riochet2018 and Bakhtin2019. It's not clear why a new benchmark is needed without this discussion. Specifically, could the proposed method and evaluation be applied to these benchmark simulators? If not, why not? The answers to these questions seem to be the main motivation for the proposed tasks.\n\nThe simplest baseline would be to simply stack (A,B,C) as contextual input to a learned regressor of the future positions in D. Another simple baseline is to use the learned position estimator to predict all of the positions in (A,B,C) and use these positions as input to a learned regressor.\n\nUse two backtick characters instead of the double-quote character for starting forward quotations.\n\nRecommendation\n---\nTaken together, the novelty of the task and dataset, the discrepancy between problem motivation (high-dimensional counterfactual reasoning vs. uses low-dimensional ground-truth), and the partial clarity of the experimental results, leads me to conclude that although the proposed task and data are quite interesting and promising, the paper needs significant work to clarify its motivation and justification of its claims. I would rate the paper borderline, however it appears I'm forced to discretize to WA or WR. I choose WA because I am optimistic that the authors could address my doubts.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper804/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper804/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["fabien.baradel@insa-lyon.fr", "nneverova@fb.com", "julien.mille@insa-cvl.fr", "mori@cs.sfu.ca", "christian.wolf@insa-lyon.fr"], "title": "CoPhy: Counterfactual Learning of Physical Dynamics", "authors": ["Fabien Baradel", "Natalia Neverova", "Julien Mille", "Greg Mori", "Christian Wolf"], "pdf": "/pdf/f00a0eeedb2a7f893adea8ba02e04d6836be26b0.pdf", "abstract": "Understanding causes and effects in mechanical systems is an essential component of reasoning in the physical world. This work poses a new problem of counterfactual learning of object mechanics from visual input.  We develop the CoPhy benchmark to assess the capacity of the state-of-the-art models for causal physical reasoning in a synthetic 3D environment and propose a model for learning the physical dynamics in a counterfactual setting. Having observed a mechanical experiment that involves, for example, a falling tower of blocks, a set of bouncing balls or colliding objects, we learn to predict how its outcome is affected by an arbitrary intervention on its initial conditions, such as displacing one of the objects in the scene. The alternative future is predicted given the altered past and a latent representation of the confounders learned by the model in an end-to-end fashion with no supervision. We compare against feedforward video prediction baselines and show how observing alternative experiences allows the network to capture latent physical properties of the environment, which results in significantly more accurate predictions at the level of super human performance.", "keywords": ["intuitive physics", "visual reasoning"], "paperhash": "baradel|cophy_counterfactual_learning_of_physical_dynamics", "code": "https://github.com/fabienbaradel/cophy", "_bibtex": "@inproceedings{\nBaradel2020CoPhy:,\ntitle={CoPhy: Counterfactual Learning of Physical Dynamics},\nauthor={Fabien Baradel and Natalia Neverova and Julien Mille and Greg Mori and Christian Wolf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SkeyppEFvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/503b179d2367c446d221d0f628acaf9a4497bd85.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SkeyppEFvS", "replyto": "SkeyppEFvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper804/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper804/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575916780113, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper804/Reviewers"], "noninvitees": [], "tcdate": 1570237746761, "tmdate": 1575916780126, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper804/-/Official_Review"}}}, {"id": "BkMT-8Rtr", "original": null, "number": 3, "cdate": 1571869113517, "ddate": null, "tcdate": 1571869113517, "tmdate": 1572972550162, "tddate": null, "forum": "SkeyppEFvS", "replyto": "SkeyppEFvS", "invitation": "ICLR.cc/2020/Conference/Paper804/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper studies counterfactual event prediction in physical simulation. The authors proposed a model that leverages object-centric scene representations and graph networks for modeling object interactions. The model also uses a recurrent network to encode and extract the confounder information for counterfactual prediction. In the experiments, the authors compared the proposed method, baselines, and human performance on pose estimation and counterfactual prediction.\n\nI reviewed an earlier version of the paper at another venue. Compared with that, the current manuscript has improved a lot. It's studying an important problem. The model builds upon SOTA techniques such as GCN. Experiments are conducted on multiple physical events with multiple confounders. There are also rich ablation studies. The writing is clear and easy to follow. My recommendation is weak accept.\n\nI think the paper can be improved by adding experiments on real data. The model involves 'de-rendering' which seems not easily generalizable to complex real scenes. Also, while the block tower scenario has been well studied, the discussion on ball and collision scenarios is quite limited. I encourage the authors to include more results on those datasets. The authors should also conduct human studies there, too.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper804/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper804/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["fabien.baradel@insa-lyon.fr", "nneverova@fb.com", "julien.mille@insa-cvl.fr", "mori@cs.sfu.ca", "christian.wolf@insa-lyon.fr"], "title": "CoPhy: Counterfactual Learning of Physical Dynamics", "authors": ["Fabien Baradel", "Natalia Neverova", "Julien Mille", "Greg Mori", "Christian Wolf"], "pdf": "/pdf/f00a0eeedb2a7f893adea8ba02e04d6836be26b0.pdf", "abstract": "Understanding causes and effects in mechanical systems is an essential component of reasoning in the physical world. This work poses a new problem of counterfactual learning of object mechanics from visual input.  We develop the CoPhy benchmark to assess the capacity of the state-of-the-art models for causal physical reasoning in a synthetic 3D environment and propose a model for learning the physical dynamics in a counterfactual setting. Having observed a mechanical experiment that involves, for example, a falling tower of blocks, a set of bouncing balls or colliding objects, we learn to predict how its outcome is affected by an arbitrary intervention on its initial conditions, such as displacing one of the objects in the scene. The alternative future is predicted given the altered past and a latent representation of the confounders learned by the model in an end-to-end fashion with no supervision. We compare against feedforward video prediction baselines and show how observing alternative experiences allows the network to capture latent physical properties of the environment, which results in significantly more accurate predictions at the level of super human performance.", "keywords": ["intuitive physics", "visual reasoning"], "paperhash": "baradel|cophy_counterfactual_learning_of_physical_dynamics", "code": "https://github.com/fabienbaradel/cophy", "_bibtex": "@inproceedings{\nBaradel2020CoPhy:,\ntitle={CoPhy: Counterfactual Learning of Physical Dynamics},\nauthor={Fabien Baradel and Natalia Neverova and Julien Mille and Greg Mori and Christian Wolf},\nbooktitle={International Conference on Learning Representations},\nyear={2020},\nurl={https://openreview.net/forum?id=SkeyppEFvS}\n}", "full_presentation_video": "", "original_pdf": "/attachment/503b179d2367c446d221d0f628acaf9a4497bd85.pdf", "appendix": "", "poster": "", "spotlight_video": "", "slides": ""}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SkeyppEFvS", "replyto": "SkeyppEFvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper804/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper804/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575916780113, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper804/Reviewers"], "noninvitees": [], "tcdate": 1570237746761, "tmdate": 1575916780126, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper804/-/Official_Review"}}}], "count": 11}