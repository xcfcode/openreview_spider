{"notes": [{"tddate": null, "ddate": null, "cdate": null, "original": null, "tmdate": 1490028559001, "tcdate": 1490028559001, "number": 1, "id": "r1vzdFaie", "invitation": "ICLR.cc/2017/workshop/-/paper29/acceptance", "forum": "B1fUVMzKg", "replyto": "B1fUVMzKg", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Accept", "title": "ICLR committee final decision"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization", "abstract": "Gatys et al. (2015) recently introduced a neural algorithm that renders a content image in the style of another image, achieving so-called \\emph{style transfer}. However, their framework requires a slow iterative optimization process, which limits its practical application. Fast approximations with  feed-forward neural networks have been proposed to speed up neural style transfer. Unfortunately, the speed improvement comes at a cost: the network is usually tied to a fixed set of styles and cannot adapt to arbitrary new styles. In this paper, we present a simple yet effective approach that for the first time enables arbitrary style transfer in real-time. At the heart of our method is a novel adaptive instance normalization~(AdaIN) layer that aligns the mean and variance of the content features with those of the style features. Our method achieves speed comparable to the fastest existing approach, without the restriction to a pre-defined set of styles.", "pdf": "/pdf/a04110db2d7b23ec4e046630c4d11aad17261cd5.pdf", "TL;DR": "The first real-time style transfer method that can transfer arbitrary styles.", "paperhash": "huang|arbitrary_style_transfer_in_realtime_with_adaptive_instance_normalization", "conflicts": ["cornell.edu"], "keywords": ["Computer vision", "Unsupervised Learning", "Applications"], "authors": ["Xun Huang", "Serge Belongie"], "authorids": ["xh258@cornell.edu", "sjb344@cornell.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1490028559557, "id": "ICLR.cc/2017/workshop/-/paper29/acceptance", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "B1fUVMzKg", "replyto": "B1fUVMzKg", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept", "Reject"]}}}, "nonreaders": [], "cdate": 1490028559557}}}, {"tddate": null, "nonreaders": null, "tmdate": 1489898999183, "tcdate": 1489898918191, "number": 2, "id": "H1RsTFssl", "invitation": "ICLR.cc/2017/workshop/-/paper29/public/comment", "forum": "B1fUVMzKg", "replyto": "B1fUVMzKg", "signatures": ["~Xun_Huang1"], "readers": ["everyone"], "writers": ["~Xun_Huang1"], "content": {"title": "Updated results", "comment": "We have updated new results with improved quality and qualitative comparisons with Ulyanov et al. 2017, Chen and Schmidt 2016, and Gatys et al. 2016. The main difference is to use relu4_1 instead of relu3_1 of the VGG network."}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization", "abstract": "Gatys et al. (2015) recently introduced a neural algorithm that renders a content image in the style of another image, achieving so-called \\emph{style transfer}. However, their framework requires a slow iterative optimization process, which limits its practical application. Fast approximations with  feed-forward neural networks have been proposed to speed up neural style transfer. Unfortunately, the speed improvement comes at a cost: the network is usually tied to a fixed set of styles and cannot adapt to arbitrary new styles. In this paper, we present a simple yet effective approach that for the first time enables arbitrary style transfer in real-time. At the heart of our method is a novel adaptive instance normalization~(AdaIN) layer that aligns the mean and variance of the content features with those of the style features. Our method achieves speed comparable to the fastest existing approach, without the restriction to a pre-defined set of styles.", "pdf": "/pdf/a04110db2d7b23ec4e046630c4d11aad17261cd5.pdf", "TL;DR": "The first real-time style transfer method that can transfer arbitrary styles.", "paperhash": "huang|arbitrary_style_transfer_in_realtime_with_adaptive_instance_normalization", "conflicts": ["cornell.edu"], "keywords": ["Computer vision", "Unsupervised Learning", "Applications"], "authors": ["Xun Huang", "Serge Belongie"], "authorids": ["xh258@cornell.edu", "sjb344@cornell.edu"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487180875188, "tcdate": 1487180875188, "id": "ICLR.cc/2017/workshop/-/paper29/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper29/reviewers"], "reply": {"forum": "B1fUVMzKg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487180875188}}}, {"tddate": null, "replyto": null, "nonreaders": null, "ddate": null, "tmdate": 1489898775217, "tcdate": 1487180874522, "number": 29, "id": "B1fUVMzKg", "invitation": "ICLR.cc/2017/workshop/-/submission", "forum": "B1fUVMzKg", "signatures": ["~Xun_Huang1"], "readers": ["everyone"], "content": {"title": "Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization", "abstract": "Gatys et al. (2015) recently introduced a neural algorithm that renders a content image in the style of another image, achieving so-called \\emph{style transfer}. However, their framework requires a slow iterative optimization process, which limits its practical application. Fast approximations with  feed-forward neural networks have been proposed to speed up neural style transfer. Unfortunately, the speed improvement comes at a cost: the network is usually tied to a fixed set of styles and cannot adapt to arbitrary new styles. In this paper, we present a simple yet effective approach that for the first time enables arbitrary style transfer in real-time. At the heart of our method is a novel adaptive instance normalization~(AdaIN) layer that aligns the mean and variance of the content features with those of the style features. Our method achieves speed comparable to the fastest existing approach, without the restriction to a pre-defined set of styles.", "pdf": "/pdf/a04110db2d7b23ec4e046630c4d11aad17261cd5.pdf", "TL;DR": "The first real-time style transfer method that can transfer arbitrary styles.", "paperhash": "huang|arbitrary_style_transfer_in_realtime_with_adaptive_instance_normalization", "conflicts": ["cornell.edu"], "keywords": ["Computer vision", "Unsupervised Learning", "Applications"], "authors": ["Xun Huang", "Serge Belongie"], "authorids": ["xh258@cornell.edu", "sjb344@cornell.edu"]}, "writers": [], "details": {"replyCount": 5, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1487690420000, "tmdate": 1484242559574, "id": "ICLR.cc/2017/workshop/-/submission", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1495466420000, "cdate": 1484242559574}}}, {"tddate": null, "tmdate": 1489628241624, "tcdate": 1489628241624, "number": 1, "id": "Hy9L2DDjl", "invitation": "ICLR.cc/2017/workshop/-/paper29/public/comment", "forum": "B1fUVMzKg", "replyto": "SJKTic4ie", "signatures": ["~Xun_Huang1"], "readers": ["everyone"], "writers": ["~Xun_Huang1"], "content": {"title": "Added more experiments to test our hypothesis", "comment": "Thanks for the helpful feedback!\n\nWe have added experimental results in appendix to support our hypothesis that instance normalization (IN) does perform a kind of style normalization. Ulyanov et al. attribute the success of IN to its invariance to the content image contrast. We find this explanation unsatisfactory, as IN remains effective even when all images are already contrast normalized (Fig. 3(b)). However, the improvement brought by IN is much smaller when images are already style normalized (Fig. 3(c)).\n\nOur method is not as good as the single-style transfer method (Ulyanov et al.) for some images. We believe this is not unexpected, and does not conflict with our assumption. We train 1 network for ~80000 styles and test it on new styles, while Ulyanov et al. fit 1 network to 1 style and test it on the same style. It is not surprising that the latter should fit the objective better while sacrificing flexibility.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization", "abstract": "Gatys et al. (2015) recently introduced a neural algorithm that renders a content image in the style of another image, achieving so-called \\emph{style transfer}. However, their framework requires a slow iterative optimization process, which limits its practical application. Fast approximations with  feed-forward neural networks have been proposed to speed up neural style transfer. Unfortunately, the speed improvement comes at a cost: the network is usually tied to a fixed set of styles and cannot adapt to arbitrary new styles. In this paper, we present a simple yet effective approach that for the first time enables arbitrary style transfer in real-time. At the heart of our method is a novel adaptive instance normalization~(AdaIN) layer that aligns the mean and variance of the content features with those of the style features. Our method achieves speed comparable to the fastest existing approach, without the restriction to a pre-defined set of styles.", "pdf": "/pdf/a04110db2d7b23ec4e046630c4d11aad17261cd5.pdf", "TL;DR": "The first real-time style transfer method that can transfer arbitrary styles.", "paperhash": "huang|arbitrary_style_transfer_in_realtime_with_adaptive_instance_normalization", "conflicts": ["cornell.edu"], "keywords": ["Computer vision", "Unsupervised Learning", "Applications"], "authors": ["Xun Huang", "Serge Belongie"], "authorids": ["xh258@cornell.edu", "sjb344@cornell.edu"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487180875188, "tcdate": 1487180875188, "id": "ICLR.cc/2017/workshop/-/paper29/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper29/reviewers"], "reply": {"forum": "B1fUVMzKg", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487180875188}}}, {"tddate": null, "tmdate": 1489443777038, "tcdate": 1489443777038, "number": 2, "id": "SJKTic4ie", "invitation": "ICLR.cc/2017/workshop/-/paper29/official/review", "forum": "B1fUVMzKg", "replyto": "B1fUVMzKg", "signatures": ["ICLR.cc/2017/workshop/paper29/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper29/AnonReviewer2"], "content": {"title": "Minor tweak for doing style transfer quickly", "rating": "6: Marginally above acceptance threshold", "review": "Summary: The paper proposes a novel approach for doing style transfer in a fast manner. The authors conjecture that the instance normalization in the feature space performs style normalization. Inspired by their hypothesis they propose a new module, which they call, Adaptive Instance Normalization (AdaIN) which adaptively normalizes the input to an arbitrary given style. The entire system is a feed-forward network and hence transferring the style is extremely fast. The output images shown in the paper partially validate the author's hypothesis. \n\nI think the paper proposes an interesting tweak to doing fast style transfer. The authors validate their hypothesis over a handful of images. While the results show that the style transfer does happens, the results are not as good at the previously proposed approaches. As a result I feel that there's more to it than the author's simple hypothesis. Nevertheless the paper proposes an interesting idea and can potentially be worth talking about as a workshop presentation. \n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization", "abstract": "Gatys et al. (2015) recently introduced a neural algorithm that renders a content image in the style of another image, achieving so-called \\emph{style transfer}. However, their framework requires a slow iterative optimization process, which limits its practical application. Fast approximations with  feed-forward neural networks have been proposed to speed up neural style transfer. Unfortunately, the speed improvement comes at a cost: the network is usually tied to a fixed set of styles and cannot adapt to arbitrary new styles. In this paper, we present a simple yet effective approach that for the first time enables arbitrary style transfer in real-time. At the heart of our method is a novel adaptive instance normalization~(AdaIN) layer that aligns the mean and variance of the content features with those of the style features. Our method achieves speed comparable to the fastest existing approach, without the restriction to a pre-defined set of styles.", "pdf": "/pdf/a04110db2d7b23ec4e046630c4d11aad17261cd5.pdf", "TL;DR": "The first real-time style transfer method that can transfer arbitrary styles.", "paperhash": "huang|arbitrary_style_transfer_in_realtime_with_adaptive_instance_normalization", "conflicts": ["cornell.edu"], "keywords": ["Computer vision", "Unsupervised Learning", "Applications"], "authors": ["Xun Huang", "Serge Belongie"], "authorids": ["xh258@cornell.edu", "sjb344@cornell.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489443777709, "id": "ICLR.cc/2017/workshop/-/paper29/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper29/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper29/AnonReviewer1", "ICLR.cc/2017/workshop/paper29/AnonReviewer2"], "reply": {"forum": "B1fUVMzKg", "replyto": "B1fUVMzKg", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper29/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper29/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489443777709}}}, {"tddate": null, "tmdate": 1489066058647, "tcdate": 1489066058647, "number": 1, "id": "ByQ8u0Ace", "invitation": "ICLR.cc/2017/workshop/-/paper29/official/review", "forum": "B1fUVMzKg", "replyto": "B1fUVMzKg", "signatures": ["ICLR.cc/2017/workshop/paper29/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper29/AnonReviewer1"], "content": {"title": "Interesting direction for fast style transfer", "rating": "6: Marginally above acceptance threshold", "review": "The submission proposes a method for fast style transfer with arbitrary styles. A content and style image is encoded in the \u2018relu3_1\u2019 feature space of the VGG-19 network. Then the content feature maps are shifted and scaled to match the mean and variance of the style feature maps. Finally a decoder network is trained to invert the representations back to image space.\n\nThis is a promising direction for fast style transfer with arbitrary style targets. The results so far are not bad but also not particularly compelling. \nNevertheless, I would expect them to improve to a level comparable to other fast style transfer methods with a little more engineering, e.g. by improving the decoder.\n\nAll in all this submission could be appropriate for presentation at the ICLR Workshops.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization", "abstract": "Gatys et al. (2015) recently introduced a neural algorithm that renders a content image in the style of another image, achieving so-called \\emph{style transfer}. However, their framework requires a slow iterative optimization process, which limits its practical application. Fast approximations with  feed-forward neural networks have been proposed to speed up neural style transfer. Unfortunately, the speed improvement comes at a cost: the network is usually tied to a fixed set of styles and cannot adapt to arbitrary new styles. In this paper, we present a simple yet effective approach that for the first time enables arbitrary style transfer in real-time. At the heart of our method is a novel adaptive instance normalization~(AdaIN) layer that aligns the mean and variance of the content features with those of the style features. Our method achieves speed comparable to the fastest existing approach, without the restriction to a pre-defined set of styles.", "pdf": "/pdf/a04110db2d7b23ec4e046630c4d11aad17261cd5.pdf", "TL;DR": "The first real-time style transfer method that can transfer arbitrary styles.", "paperhash": "huang|arbitrary_style_transfer_in_realtime_with_adaptive_instance_normalization", "conflicts": ["cornell.edu"], "keywords": ["Computer vision", "Unsupervised Learning", "Applications"], "authors": ["Xun Huang", "Serge Belongie"], "authorids": ["xh258@cornell.edu", "sjb344@cornell.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489443777709, "id": "ICLR.cc/2017/workshop/-/paper29/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper29/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper29/AnonReviewer1", "ICLR.cc/2017/workshop/paper29/AnonReviewer2"], "reply": {"forum": "B1fUVMzKg", "replyto": "B1fUVMzKg", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper29/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper29/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489443777709}}}], "count": 6}