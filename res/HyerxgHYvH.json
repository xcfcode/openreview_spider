{"notes": [{"id": "HyerxgHYvH", "original": "SJePfa1tPH", "number": 2097, "cdate": 1569439724898, "ddate": null, "tcdate": 1569439724898, "tmdate": 1577168294131, "tddate": null, "forum": "HyerxgHYvH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["ammarahmad977@gmail.com", "oneebalibabar@gmail.com", "murtaza.taj@lums.edu.pk"], "title": "Neural Arithmetic Unit by reusing many small pre-trained networks", "authors": ["Ammar Ahmad", "Oneeb Babar", "Murtaza Taj"], "pdf": "/pdf/fdbea97f07135cd8a74697b40863f2f77a52bbab.pdf", "TL;DR": "We train many small networks each for a specific operation, these are then combined to perform complex operations", "abstract": "We propose a solution for evaluation of mathematical expression. However, instead of designing a single end-to-end model we propose a Lego bricks style architecture. In this architecture instead of training a complex end-to-end neural network, many small networks can be trained independently each accomplishing one specific operation and acting a single lego brick. More difficult or complex task can then be solved using a combination of these smaller network. In this work we first identify 8 fundamental operations that are commonly used to solve arithmetic operations (such as 1 digit multiplication, addition, subtraction, sign calculator etc). These fundamental operations are then learned using simple feed forward neural networks. We then shows that different operations can be designed simply by reusing these smaller networks. As an example we reuse these smaller networks to develop larger and a more complex network to solve n-digit multiplication, n-digit division, and cross product. This bottom-up strategy not only introduces reusability, we also show that it allows to generalize for computations involving n-digits and we show results for up to 7 digit numbers. Unlike existing methods, our solution also generalizes for both positive as well as negative numbers.", "keywords": ["NALU", "feed forward NN"], "paperhash": "ahmad|neural_arithmetic_unit_by_reusing_many_small_pretrained_networks", "original_pdf": "/attachment/fdbea97f07135cd8a74697b40863f2f77a52bbab.pdf", "_bibtex": "@misc{\nahmad2020neural,\ntitle={Neural Arithmetic Unit by reusing many small pre-trained networks},\nauthor={Ammar Ahmad and Oneeb Babar and Murtaza Taj},\nyear={2020},\nurl={https://openreview.net/forum?id=HyerxgHYvH}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "jB_WnSCRH", "original": null, "number": 1, "cdate": 1576798740443, "ddate": null, "tcdate": 1576798740443, "tmdate": 1576800895805, "tddate": null, "forum": "HyerxgHYvH", "replyto": "HyerxgHYvH", "invitation": "ICLR.cc/2020/Conference/Paper2097/-/Decision", "content": {"decision": "Reject", "comment": "This paper proposes to train and compose neural networks for the purposes of arithmetic operations. All reviewers agree that the motivation for such a work is unclear, and the general presentation in the paper can be significantly improved. As such, I cannot recommend this paper in its current state for publication.\n", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["ammarahmad977@gmail.com", "oneebalibabar@gmail.com", "murtaza.taj@lums.edu.pk"], "title": "Neural Arithmetic Unit by reusing many small pre-trained networks", "authors": ["Ammar Ahmad", "Oneeb Babar", "Murtaza Taj"], "pdf": "/pdf/fdbea97f07135cd8a74697b40863f2f77a52bbab.pdf", "TL;DR": "We train many small networks each for a specific operation, these are then combined to perform complex operations", "abstract": "We propose a solution for evaluation of mathematical expression. However, instead of designing a single end-to-end model we propose a Lego bricks style architecture. In this architecture instead of training a complex end-to-end neural network, many small networks can be trained independently each accomplishing one specific operation and acting a single lego brick. More difficult or complex task can then be solved using a combination of these smaller network. In this work we first identify 8 fundamental operations that are commonly used to solve arithmetic operations (such as 1 digit multiplication, addition, subtraction, sign calculator etc). These fundamental operations are then learned using simple feed forward neural networks. We then shows that different operations can be designed simply by reusing these smaller networks. As an example we reuse these smaller networks to develop larger and a more complex network to solve n-digit multiplication, n-digit division, and cross product. This bottom-up strategy not only introduces reusability, we also show that it allows to generalize for computations involving n-digits and we show results for up to 7 digit numbers. Unlike existing methods, our solution also generalizes for both positive as well as negative numbers.", "keywords": ["NALU", "feed forward NN"], "paperhash": "ahmad|neural_arithmetic_unit_by_reusing_many_small_pretrained_networks", "original_pdf": "/attachment/fdbea97f07135cd8a74697b40863f2f77a52bbab.pdf", "_bibtex": "@misc{\nahmad2020neural,\ntitle={Neural Arithmetic Unit by reusing many small pre-trained networks},\nauthor={Ammar Ahmad and Oneeb Babar and Murtaza Taj},\nyear={2020},\nurl={https://openreview.net/forum?id=HyerxgHYvH}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "HyerxgHYvH", "replyto": "HyerxgHYvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795725575, "tmdate": 1576800277494, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2097/-/Decision"}}}, {"id": "BygZ_Hp9FS", "original": null, "number": 1, "cdate": 1571636585336, "ddate": null, "tcdate": 1571636585336, "tmdate": 1572972383474, "tddate": null, "forum": "HyerxgHYvH", "replyto": "HyerxgHYvH", "invitation": "ICLR.cc/2020/Conference/Paper2097/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper proposes to use neural networks to evaluate the mathematical expressions by designing 8 small building blocks for 8 fundamental operations, e.g., addition, subtraction, etc. They then design multi-digit multiplication and division using these small blocks. \n\nThe motivation of this paper is not very clear to me, i.e., why do you want to mimic the arithmetic operations using the logic networks, what is the real use case here. In the introduction, the paper motivates by pointing out the limitation of neural networks, which is memorization based and they want to generalize by understanding the inherent rules. However, if you look at the way the fundamental building blocks are designed, and how the multiplication model works, the rules are injected based on human knowledge, e.g., the way signal digit multiplication extends to multi-digit multiplication, there is simply no understanding by the model itself. Besides, the whole process has no training, i.e., the weights of the small networks are fixed, and what is the trainable parts? \n\nThe whole paper has many spelling and grammar errors, which hinders the reading. And the writing needs to be significantly improved. "}, "signatures": ["ICLR.cc/2020/Conference/Paper2097/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2097/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["ammarahmad977@gmail.com", "oneebalibabar@gmail.com", "murtaza.taj@lums.edu.pk"], "title": "Neural Arithmetic Unit by reusing many small pre-trained networks", "authors": ["Ammar Ahmad", "Oneeb Babar", "Murtaza Taj"], "pdf": "/pdf/fdbea97f07135cd8a74697b40863f2f77a52bbab.pdf", "TL;DR": "We train many small networks each for a specific operation, these are then combined to perform complex operations", "abstract": "We propose a solution for evaluation of mathematical expression. However, instead of designing a single end-to-end model we propose a Lego bricks style architecture. In this architecture instead of training a complex end-to-end neural network, many small networks can be trained independently each accomplishing one specific operation and acting a single lego brick. More difficult or complex task can then be solved using a combination of these smaller network. In this work we first identify 8 fundamental operations that are commonly used to solve arithmetic operations (such as 1 digit multiplication, addition, subtraction, sign calculator etc). These fundamental operations are then learned using simple feed forward neural networks. We then shows that different operations can be designed simply by reusing these smaller networks. As an example we reuse these smaller networks to develop larger and a more complex network to solve n-digit multiplication, n-digit division, and cross product. This bottom-up strategy not only introduces reusability, we also show that it allows to generalize for computations involving n-digits and we show results for up to 7 digit numbers. Unlike existing methods, our solution also generalizes for both positive as well as negative numbers.", "keywords": ["NALU", "feed forward NN"], "paperhash": "ahmad|neural_arithmetic_unit_by_reusing_many_small_pretrained_networks", "original_pdf": "/attachment/fdbea97f07135cd8a74697b40863f2f77a52bbab.pdf", "_bibtex": "@misc{\nahmad2020neural,\ntitle={Neural Arithmetic Unit by reusing many small pre-trained networks},\nauthor={Ammar Ahmad and Oneeb Babar and Murtaza Taj},\nyear={2020},\nurl={https://openreview.net/forum?id=HyerxgHYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HyerxgHYvH", "replyto": "HyerxgHYvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2097/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2097/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576478323177, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2097/Reviewers"], "noninvitees": [], "tcdate": 1570237727759, "tmdate": 1576478323188, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2097/-/Official_Review"}}}, {"id": "H1luNTN3tS", "original": null, "number": 2, "cdate": 1571732784428, "ddate": null, "tcdate": 1571732784428, "tmdate": 1572972383439, "tddate": null, "forum": "HyerxgHYvH", "replyto": "HyerxgHYvH", "invitation": "ICLR.cc/2020/Conference/Paper2097/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper proposes a method to design a NN based mathematical expression evaluation engine. I find that the paper could benefit a lot from some rewriting as it is not very clear and over claiming at points.\nThe introduction states that almost all ANNs lack generalization, this is in my opinion an overstatement. Domain shift and adaptation are techniques to cope with situations where the test data distribution is not coherent with the training data distribution. If this would be true in general we would have not seen such a resurgence and widespread use of ANN in the past years.\n\nThe paper lacks also proper citations to previous work and I find the background section and motivation rather weak. \n\nThe fundamental operations presented in section 3 do not involve any learning at all, contrary to the referenced work of Trask et al where parameters are actually learned (see relaxation of sign function with tanh etc.). I therefore find the use of ANN as basic constituent of the block to be wrong, each network has fixed hand-crafted weights. If I were to replace ANN with the ordinary corresponding function nothing would in the presented framework.\n\nMultiplication and division as explained in the algorithms do not require learning at all. I am afraid the ML contribution of this work is in my opinion almost non existent. I see every component as being scripted rather than learned from the data, which would be of course much more interesting.\n\nExperiments are not clear at all, setup and explanation of results are not sufficient and I find them not thoroughly executed. Table 1 mentioned classification but the task is never clearly explained. Experiment 2 compares to NALU but in the proposed work nothing is learned, unless I misunderstood the work entirely.\n\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2097/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2097/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["ammarahmad977@gmail.com", "oneebalibabar@gmail.com", "murtaza.taj@lums.edu.pk"], "title": "Neural Arithmetic Unit by reusing many small pre-trained networks", "authors": ["Ammar Ahmad", "Oneeb Babar", "Murtaza Taj"], "pdf": "/pdf/fdbea97f07135cd8a74697b40863f2f77a52bbab.pdf", "TL;DR": "We train many small networks each for a specific operation, these are then combined to perform complex operations", "abstract": "We propose a solution for evaluation of mathematical expression. However, instead of designing a single end-to-end model we propose a Lego bricks style architecture. In this architecture instead of training a complex end-to-end neural network, many small networks can be trained independently each accomplishing one specific operation and acting a single lego brick. More difficult or complex task can then be solved using a combination of these smaller network. In this work we first identify 8 fundamental operations that are commonly used to solve arithmetic operations (such as 1 digit multiplication, addition, subtraction, sign calculator etc). These fundamental operations are then learned using simple feed forward neural networks. We then shows that different operations can be designed simply by reusing these smaller networks. As an example we reuse these smaller networks to develop larger and a more complex network to solve n-digit multiplication, n-digit division, and cross product. This bottom-up strategy not only introduces reusability, we also show that it allows to generalize for computations involving n-digits and we show results for up to 7 digit numbers. Unlike existing methods, our solution also generalizes for both positive as well as negative numbers.", "keywords": ["NALU", "feed forward NN"], "paperhash": "ahmad|neural_arithmetic_unit_by_reusing_many_small_pretrained_networks", "original_pdf": "/attachment/fdbea97f07135cd8a74697b40863f2f77a52bbab.pdf", "_bibtex": "@misc{\nahmad2020neural,\ntitle={Neural Arithmetic Unit by reusing many small pre-trained networks},\nauthor={Ammar Ahmad and Oneeb Babar and Murtaza Taj},\nyear={2020},\nurl={https://openreview.net/forum?id=HyerxgHYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HyerxgHYvH", "replyto": "HyerxgHYvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2097/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2097/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576478323177, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2097/Reviewers"], "noninvitees": [], "tcdate": 1570237727759, "tmdate": 1576478323188, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2097/-/Official_Review"}}}, {"id": "H1gznbUMqr", "original": null, "number": 3, "cdate": 1572131242390, "ddate": null, "tcdate": 1572131242390, "tmdate": 1572972383405, "tddate": null, "forum": "HyerxgHYvH", "replyto": "HyerxgHYvH", "invitation": "ICLR.cc/2020/Conference/Paper2097/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "Writing\nOverall, the readability of this paper is far from the acceptance criteria of ICLR. there are just way too many grammatical errors or typos throughout the entire paper that prevent me from understanding this paper, such as\nSec.1\nAlthough\u2026, however\u2026\nIn neural network -> neural networks\nThey lack understanding -> it lacks understanding\nNumerical and quantitative reasoning is their r fundamental capability -> are .. capabilities\u2026\n...\nJust too many to print all of them here. Please proofread your paper before submission.\n\nThe introduction is poorly written that I cannot get a full picture of what goals this paper tries/has achieved after reading it.\n\nAlgorithm 1 and 2 seem to be very poorly formatted but only illustrate minimal useful information.\n\n\nMotivation\nI don\u2019t see clear usage nor convincing results based on the current shape of this paper -- what application could this work enable or what theoretical insights it reveals?\n\nMethod\nThis paper proposes to use neural nets to do arithmetic operations (though I don\u2019t see convincing motivations to do so). A new idea the paper proposes is to train a few networks to first learn/fit basic operations, and then use these trained NNs to assemble large NNs which are supposed to form more complex arithmetic operations. Unfortunately, the writing of this paper prevents me from fully understanding the technical details of this paper.\n\nResults\nThe results in this paper are currently minimal. Many details about the experiment setup or how different methods are compared are not clear.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2097/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2097/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["ammarahmad977@gmail.com", "oneebalibabar@gmail.com", "murtaza.taj@lums.edu.pk"], "title": "Neural Arithmetic Unit by reusing many small pre-trained networks", "authors": ["Ammar Ahmad", "Oneeb Babar", "Murtaza Taj"], "pdf": "/pdf/fdbea97f07135cd8a74697b40863f2f77a52bbab.pdf", "TL;DR": "We train many small networks each for a specific operation, these are then combined to perform complex operations", "abstract": "We propose a solution for evaluation of mathematical expression. However, instead of designing a single end-to-end model we propose a Lego bricks style architecture. In this architecture instead of training a complex end-to-end neural network, many small networks can be trained independently each accomplishing one specific operation and acting a single lego brick. More difficult or complex task can then be solved using a combination of these smaller network. In this work we first identify 8 fundamental operations that are commonly used to solve arithmetic operations (such as 1 digit multiplication, addition, subtraction, sign calculator etc). These fundamental operations are then learned using simple feed forward neural networks. We then shows that different operations can be designed simply by reusing these smaller networks. As an example we reuse these smaller networks to develop larger and a more complex network to solve n-digit multiplication, n-digit division, and cross product. This bottom-up strategy not only introduces reusability, we also show that it allows to generalize for computations involving n-digits and we show results for up to 7 digit numbers. Unlike existing methods, our solution also generalizes for both positive as well as negative numbers.", "keywords": ["NALU", "feed forward NN"], "paperhash": "ahmad|neural_arithmetic_unit_by_reusing_many_small_pretrained_networks", "original_pdf": "/attachment/fdbea97f07135cd8a74697b40863f2f77a52bbab.pdf", "_bibtex": "@misc{\nahmad2020neural,\ntitle={Neural Arithmetic Unit by reusing many small pre-trained networks},\nauthor={Ammar Ahmad and Oneeb Babar and Murtaza Taj},\nyear={2020},\nurl={https://openreview.net/forum?id=HyerxgHYvH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HyerxgHYvH", "replyto": "HyerxgHYvH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2097/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2097/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576478323177, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2097/Reviewers"], "noninvitees": [], "tcdate": 1570237727759, "tmdate": 1576478323188, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2097/-/Official_Review"}}}], "count": 5}