{"notes": [{"id": "BylSX4meOV", "original": "SyeP7Ju_PN", "number": 18, "cdate": 1553114141066, "ddate": null, "tcdate": 1553114141066, "tmdate": 1562082107452, "tddate": null, "forum": "BylSX4meOV", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "Adversarial Learning of General Transformations for Data Augmentation", "authors": ["Saypraseuth Mounsaveng", "David Vazquez", "Ismail Ben Ayed", "Marco Pedersoli"], "authorids": ["saypraseuth.mounsaveng.1@etsmtl.net", "dvazquez@elementai.com", "ismail.benayed@etsmtl.ca", "marco.pedersoli@etsmtl.ca"], "keywords": ["GAN", "Data Augmentation", "Image Classification"], "TL;DR": "Automatic Learning of data augmentation using a GAN based architecture to improve an image classifier", "abstract": "Data augmentation (DA) is fundamental against overfitting in large convolutional neural networks, especially with a limited training dataset. In images, DA is usually based on heuristic transformations, like geometric or color transformations. Instead of using predefined transformations, our work learns data augmentation directly from the training data by learning to transform images with an encoder-decoder architecture combined with a spatial transformer network. The transformed images still belong to the same class, but are new, more complex samples for the classifier. Our experiments show that our approach is better than previous generative data augmentation methods, and comparable to predefined transformation methods when training an image classifier.", "pdf": "/pdf/f0c95e1bc20263644bfdd195579b2e62f8ac34f4.pdf", "paperhash": "mounsaveng|adversarial_learning_of_general_transformations_for_data_augmentation"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "OpenReview.net"}, {"id": "SJebvU4Mt4", "original": null, "number": 1, "cdate": 1554298457013, "ddate": null, "tcdate": 1554298457013, "tmdate": 1555512028099, "tddate": null, "forum": "BylSX4meOV", "replyto": "BylSX4meOV", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper18/Official_Review", "content": {"title": "Easy to follow, Interesting approach, Results not so decisive", "review": "The authors of this work propose and evaluate a scheme for data augmentation (DA) that is based on rigid and non-rigid transformations of the training samples. The proposed approach is based on a generative adversarial training paradigm that is constrained by two discriminators that regularize the generated(-transformed) images to conform with the class of the input sample and at the same time ensure dissimilarity with input sample. Since the proposed scheme is differentiable it can be trained jointly ans in an end-to-end fashion with a classifier.\n\n# Pros\n- The text is well written in terms of the language and structure, while the authors adequately describe the proposed scheme. \n- The contributions have been clearly stated\n- The results along with the examples in Appendix C look promising\n\n# Cons\n- One of the claimed contributions (i.e. well suited for low-data regime) is not fully supported by the experimental results (Figure 2, CIFAR10 results)\n- Some details are missing in the description of the experimental setup. Are the results presented in 3.1, with or without joint training with the classifier?\n- In Figre 3 (section 3.2), there are no results with the classic baseline-light/strong DA. It would be insightful on how the joint training could affect the performance of the classifier. \n- [minor] there some grammatical mistakes in the second paragraph of the Introduction\n\nOverall, the text is easy to follow and well written. The combination of the spatial transformer block with a generative model is an interesting approach yet the performance seems to be slightly lower the state of the art. Considering also the fact that such generative schemes are difficult to define and train I wonder if it worth the effort. I would greatly appreciate such a discussion in the text.", "rating": "3: Marginally above acceptance threshold", "confidence": "3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper18/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper18/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adversarial Learning of General Transformations for Data Augmentation", "authors": ["Saypraseuth Mounsaveng", "David Vazquez", "Ismail Ben Ayed", "Marco Pedersoli"], "authorids": ["saypraseuth.mounsaveng.1@etsmtl.net", "dvazquez@elementai.com", "ismail.benayed@etsmtl.ca", "marco.pedersoli@etsmtl.ca"], "keywords": ["GAN", "Data Augmentation", "Image Classification"], "TL;DR": "Automatic Learning of data augmentation using a GAN based architecture to improve an image classifier", "abstract": "Data augmentation (DA) is fundamental against overfitting in large convolutional neural networks, especially with a limited training dataset. In images, DA is usually based on heuristic transformations, like geometric or color transformations. Instead of using predefined transformations, our work learns data augmentation directly from the training data by learning to transform images with an encoder-decoder architecture combined with a spatial transformer network. The transformed images still belong to the same class, but are new, more complex samples for the classifier. Our experiments show that our approach is better than previous generative data augmentation methods, and comparable to predefined transformation methods when training an image classifier.", "pdf": "/pdf/f0c95e1bc20263644bfdd195579b2e62f8ac34f4.pdf", "paperhash": "mounsaveng|adversarial_learning_of_general_transformations_for_data_augmentation"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper18/Official_Review", "cdate": 1553713419368, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "BylSX4meOV", "replyto": "BylSX4meOV", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper18/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper18/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713419368, "tmdate": 1555511817122, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper18/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "HkePDwl_KN", "original": null, "number": 2, "cdate": 1554675551186, "ddate": null, "tcdate": 1554675551186, "tmdate": 1555511888605, "tddate": null, "forum": "BylSX4meOV", "replyto": "BylSX4meOV", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper18/Official_Review", "content": {"title": "This paper proposed an interesting data augmentation method using GAN and STN, however the result is not so good.", "review": "The paper proposed to augment training data by spacial transformer network, which impose a set of simple transformations to the image and is fully differentiable. The method can learn data-specific transformations and outperforms other GAN-based methods in limited-data setting. Compared to Ratner, the method can be trained in an end-to-end manner, but the evaluation result is lower.\n\nAs the experiment result is not so good, I'd recommend a weak accept.\n\n", "rating": "3: Marginally above acceptance threshold", "confidence": "1: The reviewer's evaluation is an educated guess"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper18/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper18/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adversarial Learning of General Transformations for Data Augmentation", "authors": ["Saypraseuth Mounsaveng", "David Vazquez", "Ismail Ben Ayed", "Marco Pedersoli"], "authorids": ["saypraseuth.mounsaveng.1@etsmtl.net", "dvazquez@elementai.com", "ismail.benayed@etsmtl.ca", "marco.pedersoli@etsmtl.ca"], "keywords": ["GAN", "Data Augmentation", "Image Classification"], "TL;DR": "Automatic Learning of data augmentation using a GAN based architecture to improve an image classifier", "abstract": "Data augmentation (DA) is fundamental against overfitting in large convolutional neural networks, especially with a limited training dataset. In images, DA is usually based on heuristic transformations, like geometric or color transformations. Instead of using predefined transformations, our work learns data augmentation directly from the training data by learning to transform images with an encoder-decoder architecture combined with a spatial transformer network. The transformed images still belong to the same class, but are new, more complex samples for the classifier. Our experiments show that our approach is better than previous generative data augmentation methods, and comparable to predefined transformation methods when training an image classifier.", "pdf": "/pdf/f0c95e1bc20263644bfdd195579b2e62f8ac34f4.pdf", "paperhash": "mounsaveng|adversarial_learning_of_general_transformations_for_data_augmentation"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper18/Official_Review", "cdate": 1553713419368, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "BylSX4meOV", "replyto": "BylSX4meOV", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper18/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper18/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713419368, "tmdate": 1555511817122, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper18/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "BkljnWmf5E", "original": null, "number": 1, "cdate": 1555341746889, "ddate": null, "tcdate": 1555341746889, "tmdate": 1555510981464, "tddate": null, "forum": "BylSX4meOV", "replyto": "BylSX4meOV", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper18/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Adversarial Learning of General Transformations for Data Augmentation", "authors": ["Saypraseuth Mounsaveng", "David Vazquez", "Ismail Ben Ayed", "Marco Pedersoli"], "authorids": ["saypraseuth.mounsaveng.1@etsmtl.net", "dvazquez@elementai.com", "ismail.benayed@etsmtl.ca", "marco.pedersoli@etsmtl.ca"], "keywords": ["GAN", "Data Augmentation", "Image Classification"], "TL;DR": "Automatic Learning of data augmentation using a GAN based architecture to improve an image classifier", "abstract": "Data augmentation (DA) is fundamental against overfitting in large convolutional neural networks, especially with a limited training dataset. In images, DA is usually based on heuristic transformations, like geometric or color transformations. Instead of using predefined transformations, our work learns data augmentation directly from the training data by learning to transform images with an encoder-decoder architecture combined with a spatial transformer network. The transformed images still belong to the same class, but are new, more complex samples for the classifier. Our experiments show that our approach is better than previous generative data augmentation methods, and comparable to predefined transformation methods when training an image classifier.", "pdf": "/pdf/f0c95e1bc20263644bfdd195579b2e62f8ac34f4.pdf", "paperhash": "mounsaveng|adversarial_learning_of_general_transformations_for_data_augmentation"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper18/Decision", "cdate": 1554736068306, "reply": {"forum": "BylSX4meOV", "replyto": "BylSX4meOV", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736068306, "tmdate": 1555510970378, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 4}