{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124282073, "tcdate": 1518464740921, "number": 237, "cdate": 1518464740921, "id": "rJT1k_JDf", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "rJT1k_JDf", "signatures": ["~Romain_Laroche1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "In reinforcement learning, all objective functions are not equal", "abstract": "We study the learnability of value functions. We get the reward back propagation out of the way by fitting directly a deep neural network on the analytically computed optimal value function, given a chosen objective function. We show that some objective functions are easier to train than others by several magnitude orders. We observe in particular the influence of the $\\gamma$ parameter and the decomposition of the task into subtasks.", "paperhash": "seijen|in_reinforcement_learning_all_objective_functions_are_not_equal", "keywords": ["reinforcement learning", "deep learning"], "_bibtex": "@misc{\n  seijen2018in,\n  title={In reinforcement learning, all objective functions are not equal},\n  author={Romain Laroche \\& Harm van Seijen},\n  year={2018},\n  url={https://openreview.net/forum?id=rJT1k_JDf}\n}", "authorids": ["romain.laroche@gmail.com", "harm.vanseijen@microsoft.com"], "authors": ["Romain Laroche \\& Harm van Seijen"], "TL;DR": "In reinforcement learning, all objective functions are not equal", "pdf": "/pdf/dfd0a81fc7ca5d1620b25666bba3dd69e6911692.pdf"}, "nonreaders": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582687382, "tcdate": 1520718271283, "number": 1, "cdate": 1520718271283, "id": "HyvT-RZtG", "invitation": "ICLR.cc/2018/Workshop/-/Paper237/Official_Review", "forum": "rJT1k_JDf", "replyto": "rJT1k_JDf", "signatures": ["ICLR.cc/2018/Workshop/Paper237/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper237/AnonReviewer1"], "content": {"title": "Interesting experiment on the choice of objective functions for RL", "rating": "7: Good paper, accept", "review": "In this paper the authors study the effect of the choice of the objective function in the ease of training Reinforcement Learning agents to solve the particular task. In particular the authors base their experiments on a toy task of fruit gathering on a 5x5 grid which is very similar to the Taxi environment. The goal is to find the shortest path navigating the grid to collect all the fruit, and is small enough to be a solvable TSP instance. The authors then train RL agents on a variety of objective functions including the TSP objective, the RL objective which is the cumulative discounted term, and the decomposed reward. The authors also study the effect of the choice of the discount factor on the ease of learnability of the problem. The authors conclude that the more complicated the objective function (like the TSP objective function), the harder it is to train. The authors also make the observation that very high values of the discount factor (> 0.9) are also harder to train.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "In reinforcement learning, all objective functions are not equal", "abstract": "We study the learnability of value functions. We get the reward back propagation out of the way by fitting directly a deep neural network on the analytically computed optimal value function, given a chosen objective function. We show that some objective functions are easier to train than others by several magnitude orders. We observe in particular the influence of the $\\gamma$ parameter and the decomposition of the task into subtasks.", "paperhash": "seijen|in_reinforcement_learning_all_objective_functions_are_not_equal", "keywords": ["reinforcement learning", "deep learning"], "_bibtex": "@misc{\n  seijen2018in,\n  title={In reinforcement learning, all objective functions are not equal},\n  author={Romain Laroche \\& Harm van Seijen},\n  year={2018},\n  url={https://openreview.net/forum?id=rJT1k_JDf}\n}", "authorids": ["romain.laroche@gmail.com", "harm.vanseijen@microsoft.com"], "authors": ["Romain Laroche \\& Harm van Seijen"], "TL;DR": "In reinforcement learning, all objective functions are not equal", "pdf": "/pdf/dfd0a81fc7ca5d1620b25666bba3dd69e6911692.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582687190, "id": "ICLR.cc/2018/Workshop/-/Paper237/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper237/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper237/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper237/AnonReviewer4"], "reply": {"forum": "rJT1k_JDf", "replyto": "rJT1k_JDf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper237/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper237/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582687190}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582579907, "tcdate": 1521384766288, "number": 2, "cdate": 1521384766288, "id": "r1LBal3Yf", "invitation": "ICLR.cc/2018/Workshop/-/Paper237/Official_Review", "forum": "rJT1k_JDf", "replyto": "rJT1k_JDf", "signatures": ["ICLR.cc/2018/Workshop/Paper237/AnonReviewer4"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper237/AnonReviewer4"], "content": {"title": "Interesting Empirical results, but lacks related work analysis / references", "rating": "5: Marginally below acceptance threshold", "review": "Empirical paper which shows somewhat surprising results: suboptimal reward functions may lead to better solutions due to learnability of the underlying (potentially suboptimal) reward shaping.\n\nThe paper uses TSP in an RL context, and it should be updated to contain several related works which demonstrate the effectiveness of RL / supervised learning in the context of TSP. Ideally, it should use the same setup as in [1,2], which would make the contributions much stronger and interesting.\n\n[1] https://arxiv.org/abs/1611.09940\n[2] https://arxiv.org/abs/1506.03134", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "In reinforcement learning, all objective functions are not equal", "abstract": "We study the learnability of value functions. We get the reward back propagation out of the way by fitting directly a deep neural network on the analytically computed optimal value function, given a chosen objective function. We show that some objective functions are easier to train than others by several magnitude orders. We observe in particular the influence of the $\\gamma$ parameter and the decomposition of the task into subtasks.", "paperhash": "seijen|in_reinforcement_learning_all_objective_functions_are_not_equal", "keywords": ["reinforcement learning", "deep learning"], "_bibtex": "@misc{\n  seijen2018in,\n  title={In reinforcement learning, all objective functions are not equal},\n  author={Romain Laroche \\& Harm van Seijen},\n  year={2018},\n  url={https://openreview.net/forum?id=rJT1k_JDf}\n}", "authorids": ["romain.laroche@gmail.com", "harm.vanseijen@microsoft.com"], "authors": ["Romain Laroche \\& Harm van Seijen"], "TL;DR": "In reinforcement learning, all objective functions are not equal", "pdf": "/pdf/dfd0a81fc7ca5d1620b25666bba3dd69e6911692.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582687190, "id": "ICLR.cc/2018/Workshop/-/Paper237/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper237/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper237/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper237/AnonReviewer4"], "reply": {"forum": "rJT1k_JDf", "replyto": "rJT1k_JDf", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper237/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper237/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582687190}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573552326, "tcdate": 1521573552326, "number": 40, "cdate": 1521573551993, "id": "SJu3RCRtz", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "rJT1k_JDf", "replyto": "rJT1k_JDf", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "In reinforcement learning, all objective functions are not equal", "abstract": "We study the learnability of value functions. We get the reward back propagation out of the way by fitting directly a deep neural network on the analytically computed optimal value function, given a chosen objective function. We show that some objective functions are easier to train than others by several magnitude orders. We observe in particular the influence of the $\\gamma$ parameter and the decomposition of the task into subtasks.", "paperhash": "seijen|in_reinforcement_learning_all_objective_functions_are_not_equal", "keywords": ["reinforcement learning", "deep learning"], "_bibtex": "@misc{\n  seijen2018in,\n  title={In reinforcement learning, all objective functions are not equal},\n  author={Romain Laroche \\& Harm van Seijen},\n  year={2018},\n  url={https://openreview.net/forum?id=rJT1k_JDf}\n}", "authorids": ["romain.laroche@gmail.com", "harm.vanseijen@microsoft.com"], "authors": ["Romain Laroche \\& Harm van Seijen"], "TL;DR": "In reinforcement learning, all objective functions are not equal", "pdf": "/pdf/dfd0a81fc7ca5d1620b25666bba3dd69e6911692.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 4}