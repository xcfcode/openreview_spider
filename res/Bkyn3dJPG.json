{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124455224, "tcdate": 1518468262975, "number": 258, "cdate": 1518468262975, "id": "Bkyn3dJPG", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "Bkyn3dJPG", "signatures": ["~Natasha_Jaques1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Learning via social awareness: improving sketch representations with facial feedback", "abstract": "In the quest towards general artificial intelligence (AI), researchers have explored developing loss functions that act as intrinsic motivators in the absence of external rewards. This paper argues that such research has overlooked an important and useful intrinsic motivator: social interaction. We posit that making an AI agent aware of implicit social feedback from humans can allow for faster learning of more generalizable and useful representations, and could potentially impact AI safety. We collect social feedback in the form of facial expression reactions to samples from Sketch RNN, an LSTM-based variational autoencoder (VAE) designed to produce sketch drawings. We use a Latent Constraints GAN (LC-GAN) to learn from the facial feedback of a small group of viewers, and then show in an independent evaluation with 76 users that this model produced sketches that lead to significantly more positive facial expressions. Thus, we establish that implicit social feedback can improve the output of a deep learning model.", "paperhash": "jaques|learning_via_social_awareness_improving_sketch_representations_with_facial_feedback", "keywords": ["social feedback", "LSTM", "VAE", "latent constraints", "GAN", "MDN", "facial expressions", "intrinsic motivation"], "_bibtex": "@misc{\n  jaques2018learning,\n  title={Learning via social awareness: improving sketch representations with facial feedback},\n  author={Natasha Jaques and Jesse Engel and David Ha and Fred Bertsch and Rosalind Picard and Douglas Eck},\n  year={2018},\n  url={https://openreview.net/forum?id=Bkyn3dJPG}\n}", "authorids": ["jaquesn@mit.edu", "jesseengel@google.com", "hadavid@google.com", "fredbersch@google.com", "picard@media.mit.edu", "deck@google.com"], "authors": ["Natasha Jaques", "Jesse Engel", "David Ha", "Fred Bertsch", "Rosalind Picard", "Douglas Eck"], "TL;DR": "We argue that awareness of implicit social feedback is an important intrinsic motivator for both humans and deep learning models, and provide evidence that awareness of social cues like facial expressions can improve the output of a VAE sequence model. ", "pdf": "/pdf/4281fc2d4ec6cfbd0f43bc4409a4e3abdeb42302.pdf"}, "nonreaders": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582777291, "tcdate": 1520635105284, "number": 1, "cdate": 1520635105284, "id": "SkYkTYlFz", "invitation": "ICLR.cc/2018/Workshop/-/Paper258/Official_Review", "forum": "Bkyn3dJPG", "replyto": "Bkyn3dJPG", "signatures": ["ICLR.cc/2018/Workshop/Paper258/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper258/AnonReviewer3"], "content": {"title": "This submission proposes to utilize social interaction, facial expressions in this submission, to improve deep learning model output. It is an interesting topic, although it lacks some important technical details.", "rating": "6: Marginally above acceptance threshold", "review": "This submission proposes to utilize social interatction, facial expressions in this submission, to improve deep learning model output. \n\n-- Pros:\n   -- This topic is very intestesting. It tries to utilze the human interatctions to improve AI agent learning.\n\n-- Cons:\n   -- Some technical details are missing in this submission. For example, the configuration of LC-GAN and Sketch RNN used in this paper are not mentioned. So it might be a little early to achieve a conclusion from Figure 2.\n\n   -- The author doesn't provide details about what facial expression detector they are using in this work,  and how accurate the detector is.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning via social awareness: improving sketch representations with facial feedback", "abstract": "In the quest towards general artificial intelligence (AI), researchers have explored developing loss functions that act as intrinsic motivators in the absence of external rewards. This paper argues that such research has overlooked an important and useful intrinsic motivator: social interaction. We posit that making an AI agent aware of implicit social feedback from humans can allow for faster learning of more generalizable and useful representations, and could potentially impact AI safety. We collect social feedback in the form of facial expression reactions to samples from Sketch RNN, an LSTM-based variational autoencoder (VAE) designed to produce sketch drawings. We use a Latent Constraints GAN (LC-GAN) to learn from the facial feedback of a small group of viewers, and then show in an independent evaluation with 76 users that this model produced sketches that lead to significantly more positive facial expressions. Thus, we establish that implicit social feedback can improve the output of a deep learning model.", "paperhash": "jaques|learning_via_social_awareness_improving_sketch_representations_with_facial_feedback", "keywords": ["social feedback", "LSTM", "VAE", "latent constraints", "GAN", "MDN", "facial expressions", "intrinsic motivation"], "_bibtex": "@misc{\n  jaques2018learning,\n  title={Learning via social awareness: improving sketch representations with facial feedback},\n  author={Natasha Jaques and Jesse Engel and David Ha and Fred Bertsch and Rosalind Picard and Douglas Eck},\n  year={2018},\n  url={https://openreview.net/forum?id=Bkyn3dJPG}\n}", "authorids": ["jaquesn@mit.edu", "jesseengel@google.com", "hadavid@google.com", "fredbersch@google.com", "picard@media.mit.edu", "deck@google.com"], "authors": ["Natasha Jaques", "Jesse Engel", "David Ha", "Fred Bertsch", "Rosalind Picard", "Douglas Eck"], "TL;DR": "We argue that awareness of implicit social feedback is an important intrinsic motivator for both humans and deep learning models, and provide evidence that awareness of social cues like facial expressions can improve the output of a VAE sequence model. ", "pdf": "/pdf/4281fc2d4ec6cfbd0f43bc4409a4e3abdeb42302.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582777104, "id": "ICLR.cc/2018/Workshop/-/Paper258/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper258/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper258/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper258/AnonReviewer1"], "reply": {"forum": "Bkyn3dJPG", "replyto": "Bkyn3dJPG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper258/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper258/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582777104}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582657504, "tcdate": 1520776103476, "number": 2, "cdate": 1520776103476, "id": "H1knXnzYf", "invitation": "ICLR.cc/2018/Workshop/-/Paper258/Official_Review", "forum": "Bkyn3dJPG", "replyto": "Bkyn3dJPG", "signatures": ["ICLR.cc/2018/Workshop/Paper258/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper258/AnonReviewer1"], "content": {"title": "interesting research direction, expected results", "rating": "6: Marginally above acceptance threshold", "review": "In this work the authors utilize a latent constraints GAN to produce embeddings for the variational Sketch-RNN model, that are likely to produce drawings leading to positive facial expressions.  The authors train the LC-GAN to produce embeddings that when utilized with sketch-RNN, produce sketches that maximize positive and minimize negative emotions.  \n\nOn the negative side of things, there not enough details on the facial expression recognition system utilized, although the authors show that the results correlate well with the self-reported emotions.   The evaluation part of the paper could be further improved (e.g., discuss the facial expression metrics that are mentioned).  \n\nDue to the methods used, I feel that the results are expected (i.e., this is what LC-GAN is supposed  to do - map embeddings maximizing a value function).  Nevertheless, I think that it is a very interesting research direction: to incorporate implicit human social feedback in AI.\n\n\n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning via social awareness: improving sketch representations with facial feedback", "abstract": "In the quest towards general artificial intelligence (AI), researchers have explored developing loss functions that act as intrinsic motivators in the absence of external rewards. This paper argues that such research has overlooked an important and useful intrinsic motivator: social interaction. We posit that making an AI agent aware of implicit social feedback from humans can allow for faster learning of more generalizable and useful representations, and could potentially impact AI safety. We collect social feedback in the form of facial expression reactions to samples from Sketch RNN, an LSTM-based variational autoencoder (VAE) designed to produce sketch drawings. We use a Latent Constraints GAN (LC-GAN) to learn from the facial feedback of a small group of viewers, and then show in an independent evaluation with 76 users that this model produced sketches that lead to significantly more positive facial expressions. Thus, we establish that implicit social feedback can improve the output of a deep learning model.", "paperhash": "jaques|learning_via_social_awareness_improving_sketch_representations_with_facial_feedback", "keywords": ["social feedback", "LSTM", "VAE", "latent constraints", "GAN", "MDN", "facial expressions", "intrinsic motivation"], "_bibtex": "@misc{\n  jaques2018learning,\n  title={Learning via social awareness: improving sketch representations with facial feedback},\n  author={Natasha Jaques and Jesse Engel and David Ha and Fred Bertsch and Rosalind Picard and Douglas Eck},\n  year={2018},\n  url={https://openreview.net/forum?id=Bkyn3dJPG}\n}", "authorids": ["jaquesn@mit.edu", "jesseengel@google.com", "hadavid@google.com", "fredbersch@google.com", "picard@media.mit.edu", "deck@google.com"], "authors": ["Natasha Jaques", "Jesse Engel", "David Ha", "Fred Bertsch", "Rosalind Picard", "Douglas Eck"], "TL;DR": "We argue that awareness of implicit social feedback is an important intrinsic motivator for both humans and deep learning models, and provide evidence that awareness of social cues like facial expressions can improve the output of a VAE sequence model. ", "pdf": "/pdf/4281fc2d4ec6cfbd0f43bc4409a4e3abdeb42302.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582777104, "id": "ICLR.cc/2018/Workshop/-/Paper258/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper258/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper258/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper258/AnonReviewer1"], "reply": {"forum": "Bkyn3dJPG", "replyto": "Bkyn3dJPG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper258/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper258/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582777104}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573571926, "tcdate": 1521573571926, "number": 127, "cdate": 1521573571586, "id": "ry2pC00YG", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "Bkyn3dJPG", "replyto": "Bkyn3dJPG", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning via social awareness: improving sketch representations with facial feedback", "abstract": "In the quest towards general artificial intelligence (AI), researchers have explored developing loss functions that act as intrinsic motivators in the absence of external rewards. This paper argues that such research has overlooked an important and useful intrinsic motivator: social interaction. We posit that making an AI agent aware of implicit social feedback from humans can allow for faster learning of more generalizable and useful representations, and could potentially impact AI safety. We collect social feedback in the form of facial expression reactions to samples from Sketch RNN, an LSTM-based variational autoencoder (VAE) designed to produce sketch drawings. We use a Latent Constraints GAN (LC-GAN) to learn from the facial feedback of a small group of viewers, and then show in an independent evaluation with 76 users that this model produced sketches that lead to significantly more positive facial expressions. Thus, we establish that implicit social feedback can improve the output of a deep learning model.", "paperhash": "jaques|learning_via_social_awareness_improving_sketch_representations_with_facial_feedback", "keywords": ["social feedback", "LSTM", "VAE", "latent constraints", "GAN", "MDN", "facial expressions", "intrinsic motivation"], "_bibtex": "@misc{\n  jaques2018learning,\n  title={Learning via social awareness: improving sketch representations with facial feedback},\n  author={Natasha Jaques and Jesse Engel and David Ha and Fred Bertsch and Rosalind Picard and Douglas Eck},\n  year={2018},\n  url={https://openreview.net/forum?id=Bkyn3dJPG}\n}", "authorids": ["jaquesn@mit.edu", "jesseengel@google.com", "hadavid@google.com", "fredbersch@google.com", "picard@media.mit.edu", "deck@google.com"], "authors": ["Natasha Jaques", "Jesse Engel", "David Ha", "Fred Bertsch", "Rosalind Picard", "Douglas Eck"], "TL;DR": "We argue that awareness of implicit social feedback is an important intrinsic motivator for both humans and deep learning models, and provide evidence that awareness of social cues like facial expressions can improve the output of a VAE sequence model. ", "pdf": "/pdf/4281fc2d4ec6cfbd0f43bc4409a4e3abdeb42302.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 4}