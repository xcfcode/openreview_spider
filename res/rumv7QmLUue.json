{"notes": [{"id": "rumv7QmLUue", "original": "9RbjJvCqfD", "number": 1732, "cdate": 1601308191338, "ddate": null, "tcdate": 1601308191338, "tmdate": 1615746170268, "tddate": null, "forum": "rumv7QmLUue", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "A Gradient Flow Framework For Analyzing Network Pruning", "authorids": ["~Ekdeep_Singh_Lubana1", "~Robert_Dick1"], "authors": ["Ekdeep Singh Lubana", "Robert Dick"], "keywords": ["Network pruning", "Gradient flow", "Early pruning"], "abstract": "Recent network pruning methods focus on pruning models early-on in training. To estimate the impact of removing a parameter, these methods use importance measures that were originally designed to prune trained models. Despite lacking justification for their use early-on in training, such measures result in surprisingly low accuracy loss. To better explain this behavior, we develop a general framework that uses gradient flow to unify state-of-the-art importance measures through the norm of model parameters. We use this framework to determine the relationship between pruning measures and evolution of model parameters, establishing several results related to pruning models early-on in training: (i) magnitude-based pruning removes parameters that contribute least to reduction in loss, resulting in models that converge faster than magnitude-agnostic methods; (ii) loss-preservation based pruning preserves first-order model evolution dynamics and its use is therefore justified for pruning minimally trained models; and (iii) gradient-norm based pruning affects second-order model evolution dynamics, such that increasing gradient norm via pruning can produce poorly performing models. We validate our claims on several VGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10/CIFAR-100.", "one-sentence_summary": "This paper establishes the relationship between regularly used importance measures for network pruning and evolution of model parameters under gradient flow, thus providing useful insights into pruning early-on in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "lubana|a_gradient_flow_framework_for_analyzing_network_pruning", "supplementary_material": "/attachment/55f70fff9fa45cb35c2ef591e9e64817b40a6ed3.zip", "pdf": "/pdf/63800abe280bf68010c0dc83d2d4d40dc80e496a.pdf", "venue": "ICLR 2021 Spotlight", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nlubana2021a,\ntitle={A Gradient Flow Framework For Analyzing Network Pruning},\nauthor={Ekdeep Singh Lubana and Robert Dick},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=rumv7QmLUue}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 14, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "hUgt1MxdWY", "original": null, "number": 1, "cdate": 1610040390291, "ddate": null, "tcdate": 1610040390291, "tmdate": 1610473984520, "tddate": null, "forum": "rumv7QmLUue", "replyto": "rumv7QmLUue", "invitation": "ICLR.cc/2021/Conference/Paper1732/-/Decision", "content": {"title": "Final Decision", "decision": "Accept (Spotlight)", "comment": "This paper proposes a broad framework for unifying various pruning approaches and performs detailed analyses to make recommendations about the settings in which various approaches may be most useful. Reviewers were generally excited by the framework and analyses, but had some concerns regarding scale and the paper's focus on structured pruning. The authors included new experiments however, which mostly addressed reviewer concerns. Overall, I think is a strong paper which will likely be provide needed grounding for pruning frameworks and recommend acceptance. "}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Gradient Flow Framework For Analyzing Network Pruning", "authorids": ["~Ekdeep_Singh_Lubana1", "~Robert_Dick1"], "authors": ["Ekdeep Singh Lubana", "Robert Dick"], "keywords": ["Network pruning", "Gradient flow", "Early pruning"], "abstract": "Recent network pruning methods focus on pruning models early-on in training. To estimate the impact of removing a parameter, these methods use importance measures that were originally designed to prune trained models. Despite lacking justification for their use early-on in training, such measures result in surprisingly low accuracy loss. To better explain this behavior, we develop a general framework that uses gradient flow to unify state-of-the-art importance measures through the norm of model parameters. We use this framework to determine the relationship between pruning measures and evolution of model parameters, establishing several results related to pruning models early-on in training: (i) magnitude-based pruning removes parameters that contribute least to reduction in loss, resulting in models that converge faster than magnitude-agnostic methods; (ii) loss-preservation based pruning preserves first-order model evolution dynamics and its use is therefore justified for pruning minimally trained models; and (iii) gradient-norm based pruning affects second-order model evolution dynamics, such that increasing gradient norm via pruning can produce poorly performing models. We validate our claims on several VGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10/CIFAR-100.", "one-sentence_summary": "This paper establishes the relationship between regularly used importance measures for network pruning and evolution of model parameters under gradient flow, thus providing useful insights into pruning early-on in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "lubana|a_gradient_flow_framework_for_analyzing_network_pruning", "supplementary_material": "/attachment/55f70fff9fa45cb35c2ef591e9e64817b40a6ed3.zip", "pdf": "/pdf/63800abe280bf68010c0dc83d2d4d40dc80e496a.pdf", "venue": "ICLR 2021 Spotlight", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nlubana2021a,\ntitle={A Gradient Flow Framework For Analyzing Network Pruning},\nauthor={Ekdeep Singh Lubana and Robert Dick},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=rumv7QmLUue}\n}"}, "tags": [], "invitation": {"reply": {"forum": "rumv7QmLUue", "replyto": "rumv7QmLUue", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040390276, "tmdate": 1610473984503, "id": "ICLR.cc/2021/Conference/Paper1732/-/Decision"}}}, {"id": "S_xhcwa9775", "original": null, "number": 4, "cdate": 1604265980747, "ddate": null, "tcdate": 1604265980747, "tmdate": 1606495102635, "tddate": null, "forum": "rumv7QmLUue", "replyto": "rumv7QmLUue", "invitation": "ICLR.cc/2021/Conference/Paper1732/-/Official_Review", "content": {"title": "novelty & experiment at scale", "review": "This paper proposes a detailed analysis on pruning heuristics, and its applications to early pruning. It thoroughly analyzed magnitude-based pruning, loss-preservation based pruning, and gradient-norm based pruning. The paper demonstrated the results on CIFAR-10 and CIFAR-100 datasets. it's very timely research to guide the audience which heuristic is better. My major concern is the novelty over existing pruning heuristics, since the techniques have all been proposed before. The other concern is the evaluation and the scale of the dataset. Given the results in table 2 different by less than a percent, and Cifar training is very noisy, it's hard to tell the difference. Just like the Lottery Ticket hypothesis works on Cifar but does not work on ImageNet, different pruning heuristics needs to be verified on the large scale ImageNet dataset in order to be convincing. ", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1732/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1732/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Gradient Flow Framework For Analyzing Network Pruning", "authorids": ["~Ekdeep_Singh_Lubana1", "~Robert_Dick1"], "authors": ["Ekdeep Singh Lubana", "Robert Dick"], "keywords": ["Network pruning", "Gradient flow", "Early pruning"], "abstract": "Recent network pruning methods focus on pruning models early-on in training. To estimate the impact of removing a parameter, these methods use importance measures that were originally designed to prune trained models. Despite lacking justification for their use early-on in training, such measures result in surprisingly low accuracy loss. To better explain this behavior, we develop a general framework that uses gradient flow to unify state-of-the-art importance measures through the norm of model parameters. We use this framework to determine the relationship between pruning measures and evolution of model parameters, establishing several results related to pruning models early-on in training: (i) magnitude-based pruning removes parameters that contribute least to reduction in loss, resulting in models that converge faster than magnitude-agnostic methods; (ii) loss-preservation based pruning preserves first-order model evolution dynamics and its use is therefore justified for pruning minimally trained models; and (iii) gradient-norm based pruning affects second-order model evolution dynamics, such that increasing gradient norm via pruning can produce poorly performing models. We validate our claims on several VGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10/CIFAR-100.", "one-sentence_summary": "This paper establishes the relationship between regularly used importance measures for network pruning and evolution of model parameters under gradient flow, thus providing useful insights into pruning early-on in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "lubana|a_gradient_flow_framework_for_analyzing_network_pruning", "supplementary_material": "/attachment/55f70fff9fa45cb35c2ef591e9e64817b40a6ed3.zip", "pdf": "/pdf/63800abe280bf68010c0dc83d2d4d40dc80e496a.pdf", "venue": "ICLR 2021 Spotlight", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nlubana2021a,\ntitle={A Gradient Flow Framework For Analyzing Network Pruning},\nauthor={Ekdeep Singh Lubana and Robert Dick},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=rumv7QmLUue}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "rumv7QmLUue", "replyto": "rumv7QmLUue", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1732/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538111929, "tmdate": 1606915769687, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1732/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1732/-/Official_Review"}}}, {"id": "pyzaVKzFDlW", "original": null, "number": 10, "cdate": 1606253938529, "ddate": null, "tcdate": 1606253938529, "tmdate": 1606256958783, "tddate": null, "forum": "rumv7QmLUue", "replyto": "KNDUlWMyEMn", "invitation": "ICLR.cc/2021/Conference/Paper1732/-/Official_Comment", "content": {"title": "Thank you for your response! Updated discussion in related work.", "comment": "Thank you for your response! \n\nYour original review contains comments such as \"Since we can retrain pruned networks from scratch, it probably doesn't matter which neuron we choose and therefore which criteria is better\", which we believe implies even random pruning on minimally (untrained/partially trained) trained models should result in architectures capable of performing as well as a more sophisticated criteria (e.g., loss preservation based pruning). This indeed isn't the case, which we show in Appendix E. Based on your response, we believe this is your position as well, that different pruning criteria indeed matter. Thus, we may have misinterpreted your original comment related to a discussion on [1]. Our current interpretation of your comments is that since authors in [1] show reinitializing pruned models, as extracted from trained networks, does not result in performance loss, the value of network pruning lies in determining an optimal architecture that can support both high accuracy and high computational efficiency. By discussing [1] along with our already reported demonstration of why pruning criteria designed for trained models are useful on untrained/partially trained models as well, the motivation of our work can be presented more strongly. There's a chance we may still be misinterpreting your comments and, if so, we would be grateful for further clarification. \n\nCurrently, we've updated the second paragraph of Section 2 (Related work) as follows to reflect our interpretation of your comments and to discuss [1]:\n*Despite its success, the foundations of network pruning are not well understood. Recent work has shown that good \"subnetworks\" that achieve similar performance to the original network exist within both trained  (Ye et al. (2020)) and untrained models (Frankle & Carbin (2019); Malach et al. (2020)). These works thus prove networks can be pruned without loss in performance, but do not indicate how a network should be pruned, i.e, which importance measures are preferable. In fact, Liu et al. (2019) show reinitializing pruned models before retraining rarely affects their performance, indicating the consequential differences among importance measures are in the properties of architectures they produce. Since different importance measures perform differently (see Appendix E), analyzing popular measures to determine which model properties they tend to preserve reveal which measures can result in better-performing architectures.*\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1732/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1732/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Gradient Flow Framework For Analyzing Network Pruning", "authorids": ["~Ekdeep_Singh_Lubana1", "~Robert_Dick1"], "authors": ["Ekdeep Singh Lubana", "Robert Dick"], "keywords": ["Network pruning", "Gradient flow", "Early pruning"], "abstract": "Recent network pruning methods focus on pruning models early-on in training. To estimate the impact of removing a parameter, these methods use importance measures that were originally designed to prune trained models. Despite lacking justification for their use early-on in training, such measures result in surprisingly low accuracy loss. To better explain this behavior, we develop a general framework that uses gradient flow to unify state-of-the-art importance measures through the norm of model parameters. We use this framework to determine the relationship between pruning measures and evolution of model parameters, establishing several results related to pruning models early-on in training: (i) magnitude-based pruning removes parameters that contribute least to reduction in loss, resulting in models that converge faster than magnitude-agnostic methods; (ii) loss-preservation based pruning preserves first-order model evolution dynamics and its use is therefore justified for pruning minimally trained models; and (iii) gradient-norm based pruning affects second-order model evolution dynamics, such that increasing gradient norm via pruning can produce poorly performing models. We validate our claims on several VGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10/CIFAR-100.", "one-sentence_summary": "This paper establishes the relationship between regularly used importance measures for network pruning and evolution of model parameters under gradient flow, thus providing useful insights into pruning early-on in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "lubana|a_gradient_flow_framework_for_analyzing_network_pruning", "supplementary_material": "/attachment/55f70fff9fa45cb35c2ef591e9e64817b40a6ed3.zip", "pdf": "/pdf/63800abe280bf68010c0dc83d2d4d40dc80e496a.pdf", "venue": "ICLR 2021 Spotlight", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nlubana2021a,\ntitle={A Gradient Flow Framework For Analyzing Network Pruning},\nauthor={Ekdeep Singh Lubana and Robert Dick},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=rumv7QmLUue}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "rumv7QmLUue", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1732/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1732/Authors|ICLR.cc/2021/Conference/Paper1732/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923856355, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1732/-/Official_Comment"}}}, {"id": "vP_27zj314p", "original": null, "number": 9, "cdate": 1606234858996, "ddate": null, "tcdate": 1606234858996, "tmdate": 1606234858996, "tddate": null, "forum": "rumv7QmLUue", "replyto": "IyxotXG1tq", "invitation": "ICLR.cc/2021/Conference/Paper1732/-/Official_Comment", "content": {"title": "Reviewer Response 1", "comment": "Thank you to the authors for their response. I think the paper should be accepted, and the feedback below is just general feedback to help improve the paper further.\n\nThe additional experiments are helpful. A non-vision task like WikiText-103 with a Transformer model would also be very helpful to show that the observation generalize across model classes. I would still encourage the authors to pursue larger datasets e.g., full ImageNet for their existing experiments.\n\nA footnote and a forward reference is helpful, but I'd recommend a re-structuring of the text to make the paper more clear. It is a flaw in the writing if the reader has to jump around to understand what's going on."}, "signatures": ["ICLR.cc/2021/Conference/Paper1732/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1732/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Gradient Flow Framework For Analyzing Network Pruning", "authorids": ["~Ekdeep_Singh_Lubana1", "~Robert_Dick1"], "authors": ["Ekdeep Singh Lubana", "Robert Dick"], "keywords": ["Network pruning", "Gradient flow", "Early pruning"], "abstract": "Recent network pruning methods focus on pruning models early-on in training. To estimate the impact of removing a parameter, these methods use importance measures that were originally designed to prune trained models. Despite lacking justification for their use early-on in training, such measures result in surprisingly low accuracy loss. To better explain this behavior, we develop a general framework that uses gradient flow to unify state-of-the-art importance measures through the norm of model parameters. We use this framework to determine the relationship between pruning measures and evolution of model parameters, establishing several results related to pruning models early-on in training: (i) magnitude-based pruning removes parameters that contribute least to reduction in loss, resulting in models that converge faster than magnitude-agnostic methods; (ii) loss-preservation based pruning preserves first-order model evolution dynamics and its use is therefore justified for pruning minimally trained models; and (iii) gradient-norm based pruning affects second-order model evolution dynamics, such that increasing gradient norm via pruning can produce poorly performing models. We validate our claims on several VGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10/CIFAR-100.", "one-sentence_summary": "This paper establishes the relationship between regularly used importance measures for network pruning and evolution of model parameters under gradient flow, thus providing useful insights into pruning early-on in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "lubana|a_gradient_flow_framework_for_analyzing_network_pruning", "supplementary_material": "/attachment/55f70fff9fa45cb35c2ef591e9e64817b40a6ed3.zip", "pdf": "/pdf/63800abe280bf68010c0dc83d2d4d40dc80e496a.pdf", "venue": "ICLR 2021 Spotlight", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nlubana2021a,\ntitle={A Gradient Flow Framework For Analyzing Network Pruning},\nauthor={Ekdeep Singh Lubana and Robert Dick},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=rumv7QmLUue}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "rumv7QmLUue", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1732/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1732/Authors|ICLR.cc/2021/Conference/Paper1732/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923856355, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1732/-/Official_Comment"}}}, {"id": "Fpj2dqMqygP", "original": null, "number": 3, "cdate": 1603890826593, "ddate": null, "tcdate": 1603890826593, "tmdate": 1606160476504, "tddate": null, "forum": "rumv7QmLUue", "replyto": "rumv7QmLUue", "invitation": "ICLR.cc/2021/Conference/Paper1732/-/Official_Review", "content": {"title": "Review", "review": "## Summary\nThis paper studies different families of pruning criteria and their impact on training dynamics (especially early training). Stemming from the observations, authors provide improvements to the 1st and 2nd order saliency methods. \n\n## Pros\n- Authors provide simple and useful explanations to various pruning criteria that are based on the Taylor approximation of the loss functions.\n- Even the authors don't mention this in the contributions, they propose some improved versions of existing criteria. For example the updated taylor score with $\\theta^2g(\\theta)$ or absolute valued GrasP. This is great and it might worth focusing on these criteria further providing further evidence on their usefulness. Currently, they seem a bit arbitrary. For example, why not third power $\\theta^3g(\\theta)$ or additive biasing of magnitude $(g(\\theta)+c)*\\theta$. I recommend authors to run their versions in unstructured setting too.\n\n## Cons \n- Authors choose to focus on structured pruning since resulting networks are dense and acceleration is straight-forward. However,  they miss an important work on structured pruning [1]. This relatively well-known work shows that pruned (structured) networks can be trained to full accuracy from scratch. In other words, their value lies on doing some kind of an architecture search over layer widths. The motivation of the work needs to be revisited in the light of these results. Since we can retrain pruned networks from scratch, it probably doesn't matter which neuron we choose and therefore which criteria is better. Unstructured pruning doesn't have this training from scratch issue, and I recommend authors to at least include and maybe shift the focus to unstructured pruning. \n- \"but requires specially designed hardware (Han et al. (2016a)) or software (Elsen et al. (2020)). While results in this paper are applicable in both settings, our experimental evaluation focuses on structured pruning due to its higher relevance to practitioners.\" All neural networks require special hardware if you want to accelerate them. I think a better motivation here is to point out to the difficulties at accelerating sparse operations and limited availability/support for such operations in existing frameworks. And I am not sure how useful structured pruning algorithms are given the results of [1].\n- \"The larger the magnitude of parameters at a particular instant, the smaller the model loss at that instant will be.\" This is likely to be true in simple settings, however it is not a sufficient condition; especially for networks with batch norm. You can arbitrarily scale neurons if there is a batch-norm and you can come-up with arbitrary ordering if needed. I recommend re-phrasing this observation and/or stating the assumptions better (I don't remember seeing any assumption on the network itself). How the regularization or gradient noise will effect this statement? \n- \"Thus, the parameter with the most negative value for \u0398(t)g(\u0398(t)) is likely to also have a large, negative value for \u0398(t)H(\u0398(t))g(\u0398(t))\" This is not clear to me. Assume 1d case where \u0398(t)= -1; g(\u0398(t))=2; H(\u0398(t))=-1 -> \u0398(t)g(\u0398(t))=-2; \u0398(t)H(\u0398(t))g(\u0398(t))=2. I can see the correlation in the figure but it doesn't seem like an obvious thing. Maybe because hessian don't have many negative eigenvalues?\n\n## Rating\nI found the results and analysis interesting, however motivation needs to be updated. The work would also benefit from including unstructured pruning experiments. \n\n## Minor Points\n- \"Recent works focus on pruning models at initialization (Frankle & Carbin (2019);...\" Lottery Ticket paper prunes after training and show existence of some initializations that achieve good performance.. \n-  Equations 6/7 $\\frac{dL}{dt}= ||g(\\theta)||^2$ assuming gradient descent shouldn't be a learning rate?\n- \"...than magnitude-agnostic techniques.\" Which methods are these? As far as I see, all methods use magnitude information in their formulas directly or indirectly.\n- In Table:1, I recommend authors to bold both scores if they lie within the std of each other; so that we can identify which improvements are significant.\n- It would be nice to show how the temperature parameter is used for GrasP\n\n[1] https://arxiv.org/abs/1810.05270\n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper1732/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1732/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Gradient Flow Framework For Analyzing Network Pruning", "authorids": ["~Ekdeep_Singh_Lubana1", "~Robert_Dick1"], "authors": ["Ekdeep Singh Lubana", "Robert Dick"], "keywords": ["Network pruning", "Gradient flow", "Early pruning"], "abstract": "Recent network pruning methods focus on pruning models early-on in training. To estimate the impact of removing a parameter, these methods use importance measures that were originally designed to prune trained models. Despite lacking justification for their use early-on in training, such measures result in surprisingly low accuracy loss. To better explain this behavior, we develop a general framework that uses gradient flow to unify state-of-the-art importance measures through the norm of model parameters. We use this framework to determine the relationship between pruning measures and evolution of model parameters, establishing several results related to pruning models early-on in training: (i) magnitude-based pruning removes parameters that contribute least to reduction in loss, resulting in models that converge faster than magnitude-agnostic methods; (ii) loss-preservation based pruning preserves first-order model evolution dynamics and its use is therefore justified for pruning minimally trained models; and (iii) gradient-norm based pruning affects second-order model evolution dynamics, such that increasing gradient norm via pruning can produce poorly performing models. We validate our claims on several VGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10/CIFAR-100.", "one-sentence_summary": "This paper establishes the relationship between regularly used importance measures for network pruning and evolution of model parameters under gradient flow, thus providing useful insights into pruning early-on in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "lubana|a_gradient_flow_framework_for_analyzing_network_pruning", "supplementary_material": "/attachment/55f70fff9fa45cb35c2ef591e9e64817b40a6ed3.zip", "pdf": "/pdf/63800abe280bf68010c0dc83d2d4d40dc80e496a.pdf", "venue": "ICLR 2021 Spotlight", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nlubana2021a,\ntitle={A Gradient Flow Framework For Analyzing Network Pruning},\nauthor={Ekdeep Singh Lubana and Robert Dick},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=rumv7QmLUue}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "rumv7QmLUue", "replyto": "rumv7QmLUue", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1732/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538111929, "tmdate": 1606915769687, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1732/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1732/-/Official_Review"}}}, {"id": "KNDUlWMyEMn", "original": null, "number": 8, "cdate": 1606160450333, "ddate": null, "tcdate": 1606160450333, "tmdate": 1606160450333, "tddate": null, "forum": "rumv7QmLUue", "replyto": "Fpj2dqMqygP", "invitation": "ICLR.cc/2021/Conference/Paper1732/-/Official_Comment", "content": {"title": "Thank you for rebuttal / updated score & remaining concern. ", "comment": "I like to thank authors for taking time on the rebuttal and adding (at least) 3 appendix section that addresses various questions/concerns I had. Most of my concerns are addressed (therefore raised score), however, a high-level concern remains about the value of structured pruning; \n\n- **structured pruning**; I still don't see any reference to [1] nor a discussion about it. Experiments in Appendix-E is seems insufficient/expected and they are not the baselines proposed in [1]. Of course pruning criteria matters when you prune a trained network. But do you need to prune a trained network? Instead can you just train the small architecture found ( possibly non-uniform shrinking)? [1] shows that the answer is 'yes' for the major methods of the time and shows the importance of having simple baselines when evaluating pruning criteria. This baselines are called Scratch-E and Scratch-B and I think having these baselines along with a discussion would add great value to the usefulness of the pruning criteria.\n[2] https://arxiv.org/abs/1911.11134"}, "signatures": ["ICLR.cc/2021/Conference/Paper1732/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1732/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Gradient Flow Framework For Analyzing Network Pruning", "authorids": ["~Ekdeep_Singh_Lubana1", "~Robert_Dick1"], "authors": ["Ekdeep Singh Lubana", "Robert Dick"], "keywords": ["Network pruning", "Gradient flow", "Early pruning"], "abstract": "Recent network pruning methods focus on pruning models early-on in training. To estimate the impact of removing a parameter, these methods use importance measures that were originally designed to prune trained models. Despite lacking justification for their use early-on in training, such measures result in surprisingly low accuracy loss. To better explain this behavior, we develop a general framework that uses gradient flow to unify state-of-the-art importance measures through the norm of model parameters. We use this framework to determine the relationship between pruning measures and evolution of model parameters, establishing several results related to pruning models early-on in training: (i) magnitude-based pruning removes parameters that contribute least to reduction in loss, resulting in models that converge faster than magnitude-agnostic methods; (ii) loss-preservation based pruning preserves first-order model evolution dynamics and its use is therefore justified for pruning minimally trained models; and (iii) gradient-norm based pruning affects second-order model evolution dynamics, such that increasing gradient norm via pruning can produce poorly performing models. We validate our claims on several VGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10/CIFAR-100.", "one-sentence_summary": "This paper establishes the relationship between regularly used importance measures for network pruning and evolution of model parameters under gradient flow, thus providing useful insights into pruning early-on in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "lubana|a_gradient_flow_framework_for_analyzing_network_pruning", "supplementary_material": "/attachment/55f70fff9fa45cb35c2ef591e9e64817b40a6ed3.zip", "pdf": "/pdf/63800abe280bf68010c0dc83d2d4d40dc80e496a.pdf", "venue": "ICLR 2021 Spotlight", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nlubana2021a,\ntitle={A Gradient Flow Framework For Analyzing Network Pruning},\nauthor={Ekdeep Singh Lubana and Robert Dick},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=rumv7QmLUue}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "rumv7QmLUue", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1732/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1732/Authors|ICLR.cc/2021/Conference/Paper1732/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923856355, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1732/-/Official_Comment"}}}, {"id": "OG_IFZ9_-PY", "original": null, "number": 7, "cdate": 1605671843756, "ddate": null, "tcdate": 1605671843756, "tmdate": 1605744314528, "tddate": null, "forum": "rumv7QmLUue", "replyto": "TZkJhHfSwtZ", "invitation": "ICLR.cc/2021/Conference/Paper1732/-/Official_Comment", "content": {"title": "Response (part 3)", "comment": "**Response to Minor Points**\n\n1. *\"Recent works focus on pruning models at initialization (Frankle \\& Carbin (2019);...\" Lottery Ticket paper prunes after training and show existence of some initializations that achieve good performance..*\n\nThank you for pointing this out! We've rephrased this statement.\n\n2. \"Equations 6/7 $\\frac{dL}{dt} = -||g(\\theta)||^{2}$ assuming gradient descent shouldn't be a learning rate?\"\n\nNote that gradient flow is the infinitesimal variant of gradient descent, and therefore $dt$ is the learning rate. To be more precise, if a model has parameters $\\theta$, then loss evolution under gradient descent up to a first-order Taylor approximation is: \n\n$L(\\theta - \\eta g(\\theta)) - L(\\theta) = -\\eta g(\\theta)^{T} g(\\theta) = - \\eta ||g(\\theta)||^{2}$. \n\nDefine $dt := \\lim_{\\eta \\rightarrow 0}$, then we have:\n\n$dL = L(\\theta - dt g(\\theta)) - L(\\theta) = - dt ||g(\\theta)||^{2} \\implies \\frac{dL}{dt} = -||g(\\theta)||^{2}$.\n\n3. *\"...than magnitude-agnostic techniques.\" Which methods are these? As far as I see, all methods use magnitude information in their formulas directly or indirectly.*\n\nThis seems to be a disagreement about definitions. While the derivative of a function may be dependent on the function value, its mathematical definition isn't directly dependent on the function's value. Our work shows the importance measure used for loss-preservation based pruning is equal to the first-order time-derivative of norm of model parameters, not the norm itself. Thus, we call such a method magnitude-agnostic\u2014i.e., they are dependent on properties (e.g., first-order time derivative) related to evolution of the magnitude, but not the magnitude itself.\n\nWe have also added a brief footnote under Observation 2 of our paper to make this point clear: \"This observation also implies loss preservation\u2019s importance measure does not depend on magnitude of parameters directly. We thus call loss-preservation a magnitude-agnostic technique.\"\n\n4. *It would be nice to show how the temperature parameter is used for GrasP*\n\nThank you for this comment! We've added further details and a reference to Appendix G: \"For the original GraSP variant that increases gradient norm, we follow the original implementation and use a temperature of $200$ during the calculation of Hessian-gradient product. This involves division of the model output (i.e., the logits vector) by a constant T ($=200$) before using softmax for classification (see Hinton et al. (2015) for further details).\""}, "signatures": ["ICLR.cc/2021/Conference/Paper1732/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1732/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Gradient Flow Framework For Analyzing Network Pruning", "authorids": ["~Ekdeep_Singh_Lubana1", "~Robert_Dick1"], "authors": ["Ekdeep Singh Lubana", "Robert Dick"], "keywords": ["Network pruning", "Gradient flow", "Early pruning"], "abstract": "Recent network pruning methods focus on pruning models early-on in training. To estimate the impact of removing a parameter, these methods use importance measures that were originally designed to prune trained models. Despite lacking justification for their use early-on in training, such measures result in surprisingly low accuracy loss. To better explain this behavior, we develop a general framework that uses gradient flow to unify state-of-the-art importance measures through the norm of model parameters. We use this framework to determine the relationship between pruning measures and evolution of model parameters, establishing several results related to pruning models early-on in training: (i) magnitude-based pruning removes parameters that contribute least to reduction in loss, resulting in models that converge faster than magnitude-agnostic methods; (ii) loss-preservation based pruning preserves first-order model evolution dynamics and its use is therefore justified for pruning minimally trained models; and (iii) gradient-norm based pruning affects second-order model evolution dynamics, such that increasing gradient norm via pruning can produce poorly performing models. We validate our claims on several VGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10/CIFAR-100.", "one-sentence_summary": "This paper establishes the relationship between regularly used importance measures for network pruning and evolution of model parameters under gradient flow, thus providing useful insights into pruning early-on in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "lubana|a_gradient_flow_framework_for_analyzing_network_pruning", "supplementary_material": "/attachment/55f70fff9fa45cb35c2ef591e9e64817b40a6ed3.zip", "pdf": "/pdf/63800abe280bf68010c0dc83d2d4d40dc80e496a.pdf", "venue": "ICLR 2021 Spotlight", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nlubana2021a,\ntitle={A Gradient Flow Framework For Analyzing Network Pruning},\nauthor={Ekdeep Singh Lubana and Robert Dick},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=rumv7QmLUue}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "rumv7QmLUue", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1732/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1732/Authors|ICLR.cc/2021/Conference/Paper1732/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923856355, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1732/-/Official_Comment"}}}, {"id": "r4rga-lQQs", "original": null, "number": 4, "cdate": 1605671205652, "ddate": null, "tcdate": 1605671205652, "tmdate": 1605675430529, "tddate": null, "forum": "rumv7QmLUue", "replyto": "1DY7M6s1lU2", "invitation": "ICLR.cc/2021/Conference/Paper1732/-/Official_Comment", "content": {"title": "Thank you for your valuable feedback! Responses to specific comments are provided below. ", "comment": "Thank you for your valuable feedback! Responses to specific comments are provided below. \n\n**Response to Main concerns:**\n\n1. *The main concern is that there is a gap between the flow model and the actual optimization method used in this work (SGD with momentum), or more generally standard optimization methods for deep learning. In this regard, the claim of \"evolution dynamics\" seems a bit exaggerated and remains as theoretical; experiments are strictly speaking not entirely valid to support it either.*\n\nTo address this point, we've added a theoretical analysis of evolution of norm of model parameters under the commonly used SGD training method (see Appendix B). Therein, we show the expected first- and second-order time derivative of norm of model parameters for SGD training exactly match the first- and second-order time derivatives of norm of model parameters for gradient flow. The involved assumption is that terms beyond $\\mathcal{O}(\\eta^{2})$ and $\\mathcal{O}(\\eta^{3})$, where $\\eta$ is the learning rate, can be ignored, as is generally assumed in development of the importance measures analyzed in this work. This implies our claims are not just theoretical, but in fact provide a valid approximation to SGD training.\n\n2. *(minor) Related work is written as if pruning is only done via saliency-based methods (e.g., \"pruning frameworks generally define importance measures\") without taking into account various others such as optimization based methods employing sparsity inducing penalty terms. On a different but related note, the writing becomes a bit loose when it comes to referencing existing methods; it is worth correcting them and clarifying the scope/focus of this work.*\n\nThank you for pointing this out! We've updated the related work section to indicate our work focuses on pruning frameworks that specifically involve the use of an importance measure.\n\n**Response to Further questions:**\n\n1. *Why do you study structured pruning only? The provided reasons (\"unstructured pruning requires specially designed hardwares or softwares\" or \"higher relevance to practitioners\") don't seem valid enough if the purpose really lies in analyzing. Can you provide any results for unstructured pruning?*\n\nStructured pruning faces fewer barriers to widespread use. By clarifying benefits and pitfalls of existing importance measures, we aim at enabling practitioners with limited resources to make informed choices on how to minimize their network training expenses. Most works on pruning early-on in training also share this motivation, but ultimately provide results under unstructured pruning setups, which do not translate to execution efficiency directly. \n\nHowever, we agree that testing our claims in the context of unstructured pruning is valuable. Appendix H now contains experimental results demonstrating validity of our importance measure claims (Observations 2, 3, and 4) at parameter-level granularity, i.e., for unstructured pruning. We also refer the reviewer to a parallel submission at ICLR (https://openreview.net/forum?id=Ig-VyQc-MLK), which independently arrives at one of our claims (Observation 5) through an empirical analysis and shows its validity in unstructured pruning settings.\n\n2. *Can you provide evidence to support the claim \"GraSP without large temperature chooses to prune earlier layers aggressively\" (besides Raghu et al. 2017)?*\n\nWe've added layer-wise pruning ratios for different models in Appendix G.2 (see Figures 16\u201320). The plots clearly indicate that in comparison to other variants, GraSP without temperature prunes earlier layers more aggressively.\n\nIn the same section (Appendix G.2), we also use gradient flow to show that since reduction in model loss is proportional to gradient norm, the layer-wise gradient norm (see Figure 21) can be a good indicator of which layers are most responsible for reduction in model loss. Early-on in training, gradient-norm is generally highest for earlier layers. This indicates reduction in model loss early-on in training can indeed be attributed to earlier layers, as also claimed by Raghu et al., 2017 through the use of SVCCA. \n\n3. *Based on Tables 1 and 2 the proposed extension to loss-preservation method works the best, while the differences across different methods seem a bit marginal. Is my understanding correct?*\n\nGenerally, we found most metrics perform equally well, while both magnitude-based pruning and the extended measure work the best. On several experiments, magnitude-based pruning outperforms the proposed extension and vice versa. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1732/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1732/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Gradient Flow Framework For Analyzing Network Pruning", "authorids": ["~Ekdeep_Singh_Lubana1", "~Robert_Dick1"], "authors": ["Ekdeep Singh Lubana", "Robert Dick"], "keywords": ["Network pruning", "Gradient flow", "Early pruning"], "abstract": "Recent network pruning methods focus on pruning models early-on in training. To estimate the impact of removing a parameter, these methods use importance measures that were originally designed to prune trained models. Despite lacking justification for their use early-on in training, such measures result in surprisingly low accuracy loss. To better explain this behavior, we develop a general framework that uses gradient flow to unify state-of-the-art importance measures through the norm of model parameters. We use this framework to determine the relationship between pruning measures and evolution of model parameters, establishing several results related to pruning models early-on in training: (i) magnitude-based pruning removes parameters that contribute least to reduction in loss, resulting in models that converge faster than magnitude-agnostic methods; (ii) loss-preservation based pruning preserves first-order model evolution dynamics and its use is therefore justified for pruning minimally trained models; and (iii) gradient-norm based pruning affects second-order model evolution dynamics, such that increasing gradient norm via pruning can produce poorly performing models. We validate our claims on several VGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10/CIFAR-100.", "one-sentence_summary": "This paper establishes the relationship between regularly used importance measures for network pruning and evolution of model parameters under gradient flow, thus providing useful insights into pruning early-on in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "lubana|a_gradient_flow_framework_for_analyzing_network_pruning", "supplementary_material": "/attachment/55f70fff9fa45cb35c2ef591e9e64817b40a6ed3.zip", "pdf": "/pdf/63800abe280bf68010c0dc83d2d4d40dc80e496a.pdf", "venue": "ICLR 2021 Spotlight", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nlubana2021a,\ntitle={A Gradient Flow Framework For Analyzing Network Pruning},\nauthor={Ekdeep Singh Lubana and Robert Dick},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=rumv7QmLUue}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "rumv7QmLUue", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1732/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1732/Authors|ICLR.cc/2021/Conference/Paper1732/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923856355, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1732/-/Official_Comment"}}}, {"id": "f707wRQQbJv", "original": null, "number": 5, "cdate": 1605671774795, "ddate": null, "tcdate": 1605671774795, "tmdate": 1605672608460, "tddate": null, "forum": "rumv7QmLUue", "replyto": "Fpj2dqMqygP", "invitation": "ICLR.cc/2021/Conference/Paper1732/-/Official_Comment", "content": {"title": "Thank you for your valuable feedback! Responses to specific comments are provided below. ", "comment": "Thank you for your valuable feedback! Responses to specific comments are provided below.\n\n**Response to Cons**\n\n1. *Authors choose to focus on structured pruning since resulting networks are dense and acceleration is straight-forward. However, they miss an important work on structured pruning [1]. This relatively well-known work shows that pruned (structured) networks can be trained to full accuracy from scratch. In other words, their value lies on doing some kind of an architecture search over layer widths. The motivation of the work needs to be revisited in the light of these results. Since we can retrain pruned networks from scratch, it probably doesn't matter which neuron we choose and therefore which criteria is better.*\n\nThank you for bringing [1] to our attention. We were aware of that work, but do not believe that it weakens our work's motivation. That paper claims that structured pruning frameworks help design architectures that are capable of achieving high accuracy, but preserving the weights of a pruned model after pruning is unnecessary. However, the authors never imply that the choice of importance measure used for structured pruning doesn't matter. In fact, as per your claim (\"it probably doesn't matter which neuron we choose and therefore which criteria is better\"), if it indeed does not matter which criteria are used for structured pruning, even random or uniform pruning should work well. To demonstrate that this is not the case, we have added experimental results on random/uniform pruning to Appendix E. These results demonstrate that both uniform and random pruning perform much worse (4\u20145% lower accuracy, frequently) than a standard pruning measure based on magnitude, loss preservation, or gradient norm.\n\nNonetheless, we agree that evaluating our claims in the context of unstructured pruning is also valuable. Thus, we've added experiments (see Appendix H) demonstrating validity of our claims related to importance measures (Observations 2, 3, and 4) at parameter-level granularity, i.e., for unstructured pruning. We also refer the reviewer to a parallel submission at ICLR (https://openreview.net/forum?id=Ig-VyQc-MLK), which independently arrives at one of our claims (Observation 5) through empirical analysis and shows its validity in the context of unstructured pruning.\n\n2. *\"but requires specially designed hardware (Han et al. (2016a)) or software (Elsen et al. (2020)). While results in this paper are applicable in both settings, our experimental evaluation focuses on structured pruning due to its higher relevance to practitioners.\" All neural networks require special hardware if you want to accelerate them. I think a better motivation here is to point out to the difficulties at accelerating sparse operations and limited availability/support for such operations in existing frameworks.*\n\nThanks! We have changed the phrasing of that paragraph to more precisely express our intent (found in Section 2: Related Work): \"From an implementation standpoint, pruning approaches can be placed in two categories. The first, structured pruning ((Li et al. (2017); He et al. (2018); Liu et al. (2017); Molchanov et al. (2019; 2017); Gao et al. (2019))), removes entire filters, thus preserving structural regularity and directly improving execution efficiency on commodity hardware platforms. The second, unstructured pruning (Han et al. (2016b); LeCun et al. (1990); Hassibi \\& Stork (1993)), is more fine-grained, operating at the level of individual parameters instead of filters. Unstructured pruning has recently been used to reduce computational complexity as well, but requires specially designed hardware (Han et al. (2016a)) or software (Elsen et al. (2020)) that are capable of accelerating sparse operations. By clarifying benefits and pitfalls of existing importance measures, our work aims to ensure practitioners are better able to make informed choices for reducing DNN training/inference expenditure via network pruning. Thus, while results in this paper are applicable in both structured and unstructured settings, our experimental evaluation primarily focuses on structured pruning early-on in training.\"\n\n(Continued in next comment.)"}, "signatures": ["ICLR.cc/2021/Conference/Paper1732/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1732/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Gradient Flow Framework For Analyzing Network Pruning", "authorids": ["~Ekdeep_Singh_Lubana1", "~Robert_Dick1"], "authors": ["Ekdeep Singh Lubana", "Robert Dick"], "keywords": ["Network pruning", "Gradient flow", "Early pruning"], "abstract": "Recent network pruning methods focus on pruning models early-on in training. To estimate the impact of removing a parameter, these methods use importance measures that were originally designed to prune trained models. Despite lacking justification for their use early-on in training, such measures result in surprisingly low accuracy loss. To better explain this behavior, we develop a general framework that uses gradient flow to unify state-of-the-art importance measures through the norm of model parameters. We use this framework to determine the relationship between pruning measures and evolution of model parameters, establishing several results related to pruning models early-on in training: (i) magnitude-based pruning removes parameters that contribute least to reduction in loss, resulting in models that converge faster than magnitude-agnostic methods; (ii) loss-preservation based pruning preserves first-order model evolution dynamics and its use is therefore justified for pruning minimally trained models; and (iii) gradient-norm based pruning affects second-order model evolution dynamics, such that increasing gradient norm via pruning can produce poorly performing models. We validate our claims on several VGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10/CIFAR-100.", "one-sentence_summary": "This paper establishes the relationship between regularly used importance measures for network pruning and evolution of model parameters under gradient flow, thus providing useful insights into pruning early-on in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "lubana|a_gradient_flow_framework_for_analyzing_network_pruning", "supplementary_material": "/attachment/55f70fff9fa45cb35c2ef591e9e64817b40a6ed3.zip", "pdf": "/pdf/63800abe280bf68010c0dc83d2d4d40dc80e496a.pdf", "venue": "ICLR 2021 Spotlight", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nlubana2021a,\ntitle={A Gradient Flow Framework For Analyzing Network Pruning},\nauthor={Ekdeep Singh Lubana and Robert Dick},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=rumv7QmLUue}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "rumv7QmLUue", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1732/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1732/Authors|ICLR.cc/2021/Conference/Paper1732/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923856355, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1732/-/Official_Comment"}}}, {"id": "IyxotXG1tq", "original": null, "number": 3, "cdate": 1605670934312, "ddate": null, "tcdate": 1605670934312, "tmdate": 1605672557289, "tddate": null, "forum": "rumv7QmLUue", "replyto": "UT4XYNMXeI7", "invitation": "ICLR.cc/2021/Conference/Paper1732/-/Official_Comment", "content": {"title": "Thank you for your valuable feedback! Responses to specific comments are provided below.", "comment": "Thank you for your valuable feedback! Responses to specific comments are provided below.\n\n1. *This paper has few limitations. The main limitation is that all experiments were conducted on relatively small datasets (CIFAR). Given that is has been shown that some techniques in model compression produce state-of-the-art results on small tasks but fail on larger models and datasets [1, 2], I'd encourage their authors to further validate their insights on a larger dataset (i.e., ImageNet).*\n\nPlease see Appendix I. We have added further verifications on Tiny-ImageNet for our observations related to behaviors of different importance measures (Observations 2, 3, and 4). For Observation 5, we refer the reviewer to a parallel submission at ICLR (https://openreview.net/forum?id=Ig-VyQc-MLK) which independently arrives at Observation 5 through empirical analysis and verifies it on ImageNet in an unstructured pruning setting. \n\n2. *I found that the authors waited a long time to explain the term \"gradient flow\" which was important in sections 1--3 but not fully detailed until the start of section 4.*\n\nThank you for pointing this out! We have added a footnote and a forward reference to another section that provides a short primer on gradient flow.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1732/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1732/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Gradient Flow Framework For Analyzing Network Pruning", "authorids": ["~Ekdeep_Singh_Lubana1", "~Robert_Dick1"], "authors": ["Ekdeep Singh Lubana", "Robert Dick"], "keywords": ["Network pruning", "Gradient flow", "Early pruning"], "abstract": "Recent network pruning methods focus on pruning models early-on in training. To estimate the impact of removing a parameter, these methods use importance measures that were originally designed to prune trained models. Despite lacking justification for their use early-on in training, such measures result in surprisingly low accuracy loss. To better explain this behavior, we develop a general framework that uses gradient flow to unify state-of-the-art importance measures through the norm of model parameters. We use this framework to determine the relationship between pruning measures and evolution of model parameters, establishing several results related to pruning models early-on in training: (i) magnitude-based pruning removes parameters that contribute least to reduction in loss, resulting in models that converge faster than magnitude-agnostic methods; (ii) loss-preservation based pruning preserves first-order model evolution dynamics and its use is therefore justified for pruning minimally trained models; and (iii) gradient-norm based pruning affects second-order model evolution dynamics, such that increasing gradient norm via pruning can produce poorly performing models. We validate our claims on several VGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10/CIFAR-100.", "one-sentence_summary": "This paper establishes the relationship between regularly used importance measures for network pruning and evolution of model parameters under gradient flow, thus providing useful insights into pruning early-on in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "lubana|a_gradient_flow_framework_for_analyzing_network_pruning", "supplementary_material": "/attachment/55f70fff9fa45cb35c2ef591e9e64817b40a6ed3.zip", "pdf": "/pdf/63800abe280bf68010c0dc83d2d4d40dc80e496a.pdf", "venue": "ICLR 2021 Spotlight", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nlubana2021a,\ntitle={A Gradient Flow Framework For Analyzing Network Pruning},\nauthor={Ekdeep Singh Lubana and Robert Dick},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=rumv7QmLUue}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "rumv7QmLUue", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1732/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1732/Authors|ICLR.cc/2021/Conference/Paper1732/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923856355, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1732/-/Official_Comment"}}}, {"id": "TZkJhHfSwtZ", "original": null, "number": 6, "cdate": 1605671818405, "ddate": null, "tcdate": 1605671818405, "tmdate": 1605672539904, "tddate": null, "forum": "rumv7QmLUue", "replyto": "f707wRQQbJv", "invitation": "ICLR.cc/2021/Conference/Paper1732/-/Official_Comment", "content": {"title": "Response (part 2)", "comment": "3. *\"The larger the magnitude of parameters at a particular instant, the smaller the model loss at that instant will be.\" This is likely to be true in simple settings, however it is not a sufficient condition; especially for networks with batch norm. You can arbitrarily scale neurons if there is a batch-norm and you can come-up with arbitrary ordering if needed. I recommend re-phrasing this observation and/or stating the assumptions better (I don't remember seeing any assumption on the network itself). How the regularization or gradient noise will effect this statement?*\n\nPlease refer to Du et al., 2018 (https://arxiv.org/pdf/1806.00900.pdf). That paper demonstrates deep homogeneous models (models with ReLU activations) trained using gradient flow are constrained by an implicit regularization mechanism which balances the norms of model parameters across layers. That is, the model parameters evolve such that difference of norm of layer-wise parameters remains constant. A more recent paper provides a variant of that result for SGD-trained models (see Figure 5 and Equation 18 of https://openreview.net/forum?id=q8qLAbQBupm), demonstrating that the layer-wise norms of parameters obey the same balanced-norm property with an additional term that exponentially decays over time.\n\nTherefore, when a model is allowed to train naturally under gradient descent variants (such as SGD or gradient flow), an unconstrained update that uniformly scales all parameters of a layer to increase their magnitude is prevented by the implicit regularization mechanism. Thus, to respond to your specific comment on what conditions enable our observation to hold well, we simply require a model to be optimized through a standard gradient descent framework. As clarified in the beginning of Section 4, we study model evolution under gradient flow and this is a constant assumption throughout our paper. An artificial perturbation, such as the suggested scaling up of all parameters, does not occur naturally in this regime.\n\n4. *\"Thus, the parameter with the most negative value for \u0398(t)g(\u0398(t)) is likely to also have a large, negative value for \u0398(t)H(\u0398(t))g(\u0398(t))\" This is not clear to me. Assume 1d case where \u0398(t)= -1; g(\u0398(t))=2; H(\u0398(t))=-1 -> \u0398(t)g(\u0398(t))=-2; \u0398(t)H(\u0398(t))g(\u0398(t))=2. I can see the correlation in the figure but it doesn't seem like an obvious thing. Maybe because hessian don't have many negative eigenvalues?\"*\n\nWe agree about your observation, but note that we used the term \"likely\", not \"necessarily\", in the quoted comment. Rarely, but some times, a quantity changes with negative acceleration and positive velocity. Such cases exist in our reported experiments as well. For example, in Figure 3, where scatter plots of \u0398(t) H(\u0398(t)) g(\u0398(t)) versus \u0398(t) g(\u0398(t)) are shown, one can see the fourth quadrant of the plots has a few points. These points have a positive value for \u0398(t) g(\u0398(t)), but negative value for \u0398(t) H(\u0398(t)) g(\u0398(t)). However, our claim implies that if a quantity has negative acceleration, it is likely to have negative velocity too. For majority of the model parameters, this holds well: negative \u0398(t) H(\u0398(t)) g(\u0398(t)) and negative \u0398(t) g(\u0398(t)) occur simultaneously for most parameters. In fact, the correlation between the two metrics reaches 0.95\u20140.99 in several cases.\n\n(Continued in next comment.)"}, "signatures": ["ICLR.cc/2021/Conference/Paper1732/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1732/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Gradient Flow Framework For Analyzing Network Pruning", "authorids": ["~Ekdeep_Singh_Lubana1", "~Robert_Dick1"], "authors": ["Ekdeep Singh Lubana", "Robert Dick"], "keywords": ["Network pruning", "Gradient flow", "Early pruning"], "abstract": "Recent network pruning methods focus on pruning models early-on in training. To estimate the impact of removing a parameter, these methods use importance measures that were originally designed to prune trained models. Despite lacking justification for their use early-on in training, such measures result in surprisingly low accuracy loss. To better explain this behavior, we develop a general framework that uses gradient flow to unify state-of-the-art importance measures through the norm of model parameters. We use this framework to determine the relationship between pruning measures and evolution of model parameters, establishing several results related to pruning models early-on in training: (i) magnitude-based pruning removes parameters that contribute least to reduction in loss, resulting in models that converge faster than magnitude-agnostic methods; (ii) loss-preservation based pruning preserves first-order model evolution dynamics and its use is therefore justified for pruning minimally trained models; and (iii) gradient-norm based pruning affects second-order model evolution dynamics, such that increasing gradient norm via pruning can produce poorly performing models. We validate our claims on several VGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10/CIFAR-100.", "one-sentence_summary": "This paper establishes the relationship between regularly used importance measures for network pruning and evolution of model parameters under gradient flow, thus providing useful insights into pruning early-on in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "lubana|a_gradient_flow_framework_for_analyzing_network_pruning", "supplementary_material": "/attachment/55f70fff9fa45cb35c2ef591e9e64817b40a6ed3.zip", "pdf": "/pdf/63800abe280bf68010c0dc83d2d4d40dc80e496a.pdf", "venue": "ICLR 2021 Spotlight", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nlubana2021a,\ntitle={A Gradient Flow Framework For Analyzing Network Pruning},\nauthor={Ekdeep Singh Lubana and Robert Dick},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=rumv7QmLUue}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "rumv7QmLUue", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1732/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1732/Authors|ICLR.cc/2021/Conference/Paper1732/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923856355, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1732/-/Official_Comment"}}}, {"id": "wdclN65oGdC", "original": null, "number": 2, "cdate": 1605670756565, "ddate": null, "tcdate": 1605670756565, "tmdate": 1605672090376, "tddate": null, "forum": "rumv7QmLUue", "replyto": "S_xhcwa9775", "invitation": "ICLR.cc/2021/Conference/Paper1732/-/Official_Comment", "content": {"title": "Thank you for your valuable feedback! Responses to specific comments are provided below.", "comment": "Thank you for your valuable feedback! Responses to specific comments are provided below.\n\n1. *My major concern is the novelty over existing pruning heuristics, since the techniques have all been proposed before.*\n\nOur main objective in this work is not to propose new pruning heuristics, but to analyze the benefits and limitations of existing pruning heuristics in a theoretically grounded manner\u2014e.g., during early phases of this work, we noticed that GraSP is pathologically aggressive in its pruning of early layers if the model is even slightly trained. Through our analysis, we are able to provide a grounded explanation for this behavior. Such expositions, if published, will enable practitioners to avoid inherent weaknesses in existing pruning techniques. In fact, our work's contributions can be very well summarized by quoting your own comment, \"This paper proposes a detailed analysis on pruning heuristics, and its applications to early pruning. $\\dots$ It's very timely research to guide the audience which heuristic is better.\"\n\n2. *The other concern is the evaluation and the scale of the dataset. Given the results in table 2 different by less than a percent, and Cifar training is very noisy, it's hard to tell the difference.*\n\nOur experimental results show that substantial differences are common.  Table 2 shows results for different variants of GraSP: (a) our proposed variant; (b) GraSP with large temperature (as originally proposed by the work's authors); and (c) GraSP without temperature. The table lists 18 experiments. One-third of these have a $>$4.5\\% accuracy gap between our proposed variant of GraSP and the next best performing method. Since the margin of difference is large on many settings, we disagree that our results can be attributed to noisy training on datasets only.\n\n3. *Just like the Lottery Ticket hypothesis works on Cifar but does not work on ImageNet, different pruning heuristics needs to be verified on the large scale ImageNet dataset in order to be convincing.*\n\nPlease see Appendix I. We have added further verifications on Tiny-ImageNet for our observations related to behaviors of different importance measures (Observations 2, 3, and 4). For Observation 5, we refer the reviewer to a parallel submission at ICLR (https://openreview.net/forum?id=Ig-VyQc-MLK) which independently arrives at Observation 5 through an empirical analysis and verifies it on ImageNet in unstructured pruning settings. \n"}, "signatures": ["ICLR.cc/2021/Conference/Paper1732/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1732/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Gradient Flow Framework For Analyzing Network Pruning", "authorids": ["~Ekdeep_Singh_Lubana1", "~Robert_Dick1"], "authors": ["Ekdeep Singh Lubana", "Robert Dick"], "keywords": ["Network pruning", "Gradient flow", "Early pruning"], "abstract": "Recent network pruning methods focus on pruning models early-on in training. To estimate the impact of removing a parameter, these methods use importance measures that were originally designed to prune trained models. Despite lacking justification for their use early-on in training, such measures result in surprisingly low accuracy loss. To better explain this behavior, we develop a general framework that uses gradient flow to unify state-of-the-art importance measures through the norm of model parameters. We use this framework to determine the relationship between pruning measures and evolution of model parameters, establishing several results related to pruning models early-on in training: (i) magnitude-based pruning removes parameters that contribute least to reduction in loss, resulting in models that converge faster than magnitude-agnostic methods; (ii) loss-preservation based pruning preserves first-order model evolution dynamics and its use is therefore justified for pruning minimally trained models; and (iii) gradient-norm based pruning affects second-order model evolution dynamics, such that increasing gradient norm via pruning can produce poorly performing models. We validate our claims on several VGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10/CIFAR-100.", "one-sentence_summary": "This paper establishes the relationship between regularly used importance measures for network pruning and evolution of model parameters under gradient flow, thus providing useful insights into pruning early-on in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "lubana|a_gradient_flow_framework_for_analyzing_network_pruning", "supplementary_material": "/attachment/55f70fff9fa45cb35c2ef591e9e64817b40a6ed3.zip", "pdf": "/pdf/63800abe280bf68010c0dc83d2d4d40dc80e496a.pdf", "venue": "ICLR 2021 Spotlight", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nlubana2021a,\ntitle={A Gradient Flow Framework For Analyzing Network Pruning},\nauthor={Ekdeep Singh Lubana and Robert Dick},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=rumv7QmLUue}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "rumv7QmLUue", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1732/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper1732/Authors|ICLR.cc/2021/Conference/Paper1732/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1732/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923856355, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper1732/-/Official_Comment"}}}, {"id": "1DY7M6s1lU2", "original": null, "number": 1, "cdate": 1603723198826, "ddate": null, "tcdate": 1603723198826, "tmdate": 1605024371307, "tddate": null, "forum": "rumv7QmLUue", "replyto": "rumv7QmLUue", "invitation": "ICLR.cc/2021/Conference/Paper1732/-/Official_Review", "content": {"title": "Use of gradient flow to derive interesting relationship and interpretations for pruning early", "review": "The paper contributes to explaining why saliency measures used for pruning trained models may (or may not) also be effective for pruning untrained or minimally trained models, by developing the relationship between those saliency measures and different forms of the norm of model parameters based on the evolution of model parameters via gradient flow (basically derivatives w.r.t. time). This result leads to several interesting interpretations that could shed some light on on-going efforts to understand recent methods of pruning early-on (e.g., pruning at initialization or after minimal training) and potential extensions to existing saliency measures. The idea of employing gradient flow is novel for its purpose and seems to be accurately executed.\n\nThe main concern is that there is a gap between the flow model and the actual optimization method used in this work (SGD with momentum), or more generally standard optimization methods for deep learning. In this regard, the claim of \u201cevolution dynamics\u201d seems a bit exaggerated and remains as theoretical; experiments are strictly speaking not entirely valid to support it either. (minor) Related work is written as if pruning is only done via saliency-based methods (e.g., \u201cpruning frameworks generally define importance measures\u201d) without taking into account various others such as optimization based methods employing sparsity inducing penalty terms. On a different but related note, the writing becomes a bit loose when it comes to referencing existing methods; it is worth correcting them and clarifying the scope/focus of this work.\n\nFurther questions:\n- Why do you study structured pruning *only*? The provided reasons (\u201cunstructured pruning requires specially designed hardwares or softwares\u201d or \u201chigher relevance to practitioners\u201d) don\u2019t seem valid enough if the purpose really lies in analyzing. Can you provide any results for unstructured pruning?\n- Can you provide evidence to support the claim \u201cGraSP without large temperature chooses to prune earlier layers aggressively\u201d (besides Raghu et al. 2017)?\n- Based on Tables 1 and 2 the proposed extension to loss-preservation method works the best, while the differences across different methods seem a bit marginal. Is my understanding correct?", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1732/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1732/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Gradient Flow Framework For Analyzing Network Pruning", "authorids": ["~Ekdeep_Singh_Lubana1", "~Robert_Dick1"], "authors": ["Ekdeep Singh Lubana", "Robert Dick"], "keywords": ["Network pruning", "Gradient flow", "Early pruning"], "abstract": "Recent network pruning methods focus on pruning models early-on in training. To estimate the impact of removing a parameter, these methods use importance measures that were originally designed to prune trained models. Despite lacking justification for their use early-on in training, such measures result in surprisingly low accuracy loss. To better explain this behavior, we develop a general framework that uses gradient flow to unify state-of-the-art importance measures through the norm of model parameters. We use this framework to determine the relationship between pruning measures and evolution of model parameters, establishing several results related to pruning models early-on in training: (i) magnitude-based pruning removes parameters that contribute least to reduction in loss, resulting in models that converge faster than magnitude-agnostic methods; (ii) loss-preservation based pruning preserves first-order model evolution dynamics and its use is therefore justified for pruning minimally trained models; and (iii) gradient-norm based pruning affects second-order model evolution dynamics, such that increasing gradient norm via pruning can produce poorly performing models. We validate our claims on several VGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10/CIFAR-100.", "one-sentence_summary": "This paper establishes the relationship between regularly used importance measures for network pruning and evolution of model parameters under gradient flow, thus providing useful insights into pruning early-on in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "lubana|a_gradient_flow_framework_for_analyzing_network_pruning", "supplementary_material": "/attachment/55f70fff9fa45cb35c2ef591e9e64817b40a6ed3.zip", "pdf": "/pdf/63800abe280bf68010c0dc83d2d4d40dc80e496a.pdf", "venue": "ICLR 2021 Spotlight", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nlubana2021a,\ntitle={A Gradient Flow Framework For Analyzing Network Pruning},\nauthor={Ekdeep Singh Lubana and Robert Dick},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=rumv7QmLUue}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "rumv7QmLUue", "replyto": "rumv7QmLUue", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1732/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538111929, "tmdate": 1606915769687, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1732/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1732/-/Official_Review"}}}, {"id": "UT4XYNMXeI7", "original": null, "number": 2, "cdate": 1603826886081, "ddate": null, "tcdate": 1603826886081, "tmdate": 1605024371232, "tddate": null, "forum": "rumv7QmLUue", "replyto": "rumv7QmLUue", "invitation": "ICLR.cc/2021/Conference/Paper1732/-/Official_Review", "content": {"title": "Excellent, clear paper with compelling insights and empirical results", "review": "Summary:\n\nThe authors study proposed importance metrics for pruning neurons/channels in deep neural networks and analyze what properties of parameters are favored by each approach by studying the relationship between model parameters, gradients, 2nd order derivatives and loss. Through this analysis they develop a rich understanding of the consequences of different pruning criteria and use their understanding to propose modifications to existing techniques that produce higher quality models across different settings.\n\nPros:\n\nThe framework used by the authors is clear and easy to understand but also very general. The authors\u2019 mix of empirical results and theoretical analysis makes a convincing case for the accuracy of their observations. The authors go beyond observation and analysis and use their insights to design new approaches to pruning that outperform existing techniques. The paper is well written and well organized.\n\nCons:\n\nThis paper has few limitations. The main limitation is that all experiments were conducted on relatively small datasets (CIFAR). Given that is has been shown that some techniques in model compression produce state-of-the-art results on small tasks but fail on larger models and datasets [1, 2], I\u2019d encourage their authors to further validate their insights on a larger dataset (i.e., ImageNet).\n\nComments:\n\nI found that the authors waited a long time to explain the term \u201cgradient flow\u201d, which was important in sections 1-3 but not fully detailed until the start of section 4. On page 1 the authors say in parenthesis that gradient flow is \u201cgradient descent with infinitesimal learning rate\u201d, but I found this explanation was not clear. The second sentence of section 4 \u201cthe evolution over time of model parameters, gradient, and loss\u201d was much more clear. I\u2019d encourage the authors to potentially work some of these details earlier into the text.\n\nReferences:\n1. https://arxiv.org/abs/1902.09574\n2. https://arxiv.org/abs/2003.03033\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper1732/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1732/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A Gradient Flow Framework For Analyzing Network Pruning", "authorids": ["~Ekdeep_Singh_Lubana1", "~Robert_Dick1"], "authors": ["Ekdeep Singh Lubana", "Robert Dick"], "keywords": ["Network pruning", "Gradient flow", "Early pruning"], "abstract": "Recent network pruning methods focus on pruning models early-on in training. To estimate the impact of removing a parameter, these methods use importance measures that were originally designed to prune trained models. Despite lacking justification for their use early-on in training, such measures result in surprisingly low accuracy loss. To better explain this behavior, we develop a general framework that uses gradient flow to unify state-of-the-art importance measures through the norm of model parameters. We use this framework to determine the relationship between pruning measures and evolution of model parameters, establishing several results related to pruning models early-on in training: (i) magnitude-based pruning removes parameters that contribute least to reduction in loss, resulting in models that converge faster than magnitude-agnostic methods; (ii) loss-preservation based pruning preserves first-order model evolution dynamics and its use is therefore justified for pruning minimally trained models; and (iii) gradient-norm based pruning affects second-order model evolution dynamics, such that increasing gradient norm via pruning can produce poorly performing models. We validate our claims on several VGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10/CIFAR-100.", "one-sentence_summary": "This paper establishes the relationship between regularly used importance measures for network pruning and evolution of model parameters under gradient flow, thus providing useful insights into pruning early-on in training.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "lubana|a_gradient_flow_framework_for_analyzing_network_pruning", "supplementary_material": "/attachment/55f70fff9fa45cb35c2ef591e9e64817b40a6ed3.zip", "pdf": "/pdf/63800abe280bf68010c0dc83d2d4d40dc80e496a.pdf", "venue": "ICLR 2021 Spotlight", "venueid": "ICLR.cc/2021/Conference", "_bibtex": "@inproceedings{\nlubana2021a,\ntitle={A Gradient Flow Framework For Analyzing Network Pruning},\nauthor={Ekdeep Singh Lubana and Robert Dick},\nbooktitle={International Conference on Learning Representations},\nyear={2021},\nurl={https://openreview.net/forum?id=rumv7QmLUue}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "rumv7QmLUue", "replyto": "rumv7QmLUue", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1732/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538111929, "tmdate": 1606915769687, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1732/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1732/-/Official_Review"}}}], "count": 15}