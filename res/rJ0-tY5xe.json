{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1488486546205, "tcdate": 1478297861826, "number": 510, "id": "rJ0-tY5xe", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "rJ0-tY5xe", "signatures": ["~Tim_Klinger1"], "readers": ["everyone"], "content": {"title": "Learning to Query, Reason, and Answer Questions On Ambiguous Texts", "abstract": "A key goal of research in conversational systems is to train an interactive agent to help a user with a task. Human conversation, however, is notoriously incomplete, ambiguous, and full of extraneous detail. To operate effectively, the agent must not only understand what was explicitly conveyed but also be able to reason in the presence of missing or unclear information. When unable to resolve ambiguities on its own, the agent must be able to ask the user for the necessary clarifications and incorporate the response in its reasoning. Motivated by this problem we introduce QRAQ (\"crack\"; Query, Reason, and Answer Questions), a new synthetic domain, in which a User gives an Agent a short story and asks a challenge question. These problems are designed to test the reasoning and interaction capabilities of a learning-based Agent in a setting that requires multiple conversational turns. A good Agent should ask only non-deducible, relevant questions until it has enough information to correctly answer the User's question. We use standard and improved reinforcement learning based memory-network architectures to solve QRAQ problems in the difficult setting where the reward signal only tells the Agent if its final answer to the challenge question is correct or not. To provide an upper-bound to the RL results we also train the same architectures using supervised information that tells the Agent during training which variables to query and the answer to the challenge question. We evaluate our architectures on four QRAQ dataset types, and scale the complexity for each along multiple dimensions.", "pdf": "/pdf/f3e3beec28f8af589ab294b451dacd73e524b4f5.pdf", "TL;DR": "A new dataset QRAQ of ambiguous stories in which an Agent must learn to reason and interact with a User to obtain important missing information needed to answer a challenge question.", "paperhash": "guo|learning_to_query_reason_and_answer_questions_on_ambiguous_texts", "keywords": ["Natural language processing", "Deep learning", "Reinforcement Learning"], "conflicts": ["cs.umich.edu", "ibm.com", "cs.umass.edu"], "authors": ["Xiaoxiao Guo", "Tim Klinger", "Clemens Rosenbaum", "Joseph P. Bigus", "Murray Campbell", "Ban Kawas", "Kartik Talamadupula", "Gerry Tesauro", "Satinder   Singh"], "authorids": ["tklinger@us.ibm.com", "guoxiao@umich.edu", "cgbr@cs.umass.edu", "jbigus@us.ibm.com", "mcam@us.ibm.com", "bkawas@us.ibm.com", "krtalamad@us.ibm.com", "gtesauro@us.ibm.com", "baveja@umich.edu"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 14, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}, {"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396642020, "tcdate": 1486396642020, "number": 1, "id": "SJ5y6MUdx", "invitation": "ICLR.cc/2017/conference/-/paper510/acceptance", "forum": "rJ0-tY5xe", "replyto": "rJ0-tY5xe", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"title": "ICLR committee final decision", "comment": "The program committee appreciates the authors' response to concerns raised in the reviews. While there are some concerns with the paper that the authors are strongly encouraged to address for the final version of the paper, overall, the work has contributions that are worth presenting at ICLR.", "decision": "Accept (Poster)"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Query, Reason, and Answer Questions On Ambiguous Texts", "abstract": "A key goal of research in conversational systems is to train an interactive agent to help a user with a task. Human conversation, however, is notoriously incomplete, ambiguous, and full of extraneous detail. To operate effectively, the agent must not only understand what was explicitly conveyed but also be able to reason in the presence of missing or unclear information. When unable to resolve ambiguities on its own, the agent must be able to ask the user for the necessary clarifications and incorporate the response in its reasoning. Motivated by this problem we introduce QRAQ (\"crack\"; Query, Reason, and Answer Questions), a new synthetic domain, in which a User gives an Agent a short story and asks a challenge question. These problems are designed to test the reasoning and interaction capabilities of a learning-based Agent in a setting that requires multiple conversational turns. A good Agent should ask only non-deducible, relevant questions until it has enough information to correctly answer the User's question. We use standard and improved reinforcement learning based memory-network architectures to solve QRAQ problems in the difficult setting where the reward signal only tells the Agent if its final answer to the challenge question is correct or not. To provide an upper-bound to the RL results we also train the same architectures using supervised information that tells the Agent during training which variables to query and the answer to the challenge question. We evaluate our architectures on four QRAQ dataset types, and scale the complexity for each along multiple dimensions.", "pdf": "/pdf/f3e3beec28f8af589ab294b451dacd73e524b4f5.pdf", "TL;DR": "A new dataset QRAQ of ambiguous stories in which an Agent must learn to reason and interact with a User to obtain important missing information needed to answer a challenge question.", "paperhash": "guo|learning_to_query_reason_and_answer_questions_on_ambiguous_texts", "keywords": ["Natural language processing", "Deep learning", "Reinforcement Learning"], "conflicts": ["cs.umich.edu", "ibm.com", "cs.umass.edu"], "authors": ["Xiaoxiao Guo", "Tim Klinger", "Clemens Rosenbaum", "Joseph P. Bigus", "Murray Campbell", "Ban Kawas", "Kartik Talamadupula", "Gerry Tesauro", "Satinder   Singh"], "authorids": ["tklinger@us.ibm.com", "guoxiao@umich.edu", "cgbr@cs.umass.edu", "jbigus@us.ibm.com", "mcam@us.ibm.com", "bkawas@us.ibm.com", "krtalamad@us.ibm.com", "gtesauro@us.ibm.com", "baveja@umich.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396643653, "id": "ICLR.cc/2017/conference/-/paper510/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "rJ0-tY5xe", "replyto": "rJ0-tY5xe", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396643653}}}, {"tddate": null, "tmdate": 1484845071130, "tcdate": 1484845071130, "number": 7, "id": "SyDfguRLg", "invitation": "ICLR.cc/2017/conference/-/paper510/public/comment", "forum": "rJ0-tY5xe", "replyto": "BkOLm4DEx", "signatures": ["~Tim_Klinger1"], "readers": ["everyone"], "writers": ["~Tim_Klinger1"], "content": {"title": "Some more data on the effectiveness of the curriculum training", "comment": "We are still running experiments but have some additional preliminary curriculum analysis to report for impRL on the loc+obj dataset:\n\nMetric, with curriculum training, without curriculum training (baseline), improvement from curriculum\nAnswerAcc, 81.1, 68.1, +13%\nTrajAcc, 74.9, 68.1, +6.8%\nTrajCmpl, 61.8, 43.3, +18.5%\n\nThe baseline agent queries very little, so the gap between answer accuracy and trajectory accuracy is minimal. However, the gap between trajectory accuracy and trajectory completeness is increased. Not surprisingly, the baseline agent somehow manages to guess correctly without asking the relevant variables for some of the problems. In general, the result shows that the curriculum learning is quite effective in training the agents to solve the problem. A stronger baseline without curriculum learning would require tuning the value of the penalty of asking queries, which will require additional experiments."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Query, Reason, and Answer Questions On Ambiguous Texts", "abstract": "A key goal of research in conversational systems is to train an interactive agent to help a user with a task. Human conversation, however, is notoriously incomplete, ambiguous, and full of extraneous detail. To operate effectively, the agent must not only understand what was explicitly conveyed but also be able to reason in the presence of missing or unclear information. When unable to resolve ambiguities on its own, the agent must be able to ask the user for the necessary clarifications and incorporate the response in its reasoning. Motivated by this problem we introduce QRAQ (\"crack\"; Query, Reason, and Answer Questions), a new synthetic domain, in which a User gives an Agent a short story and asks a challenge question. These problems are designed to test the reasoning and interaction capabilities of a learning-based Agent in a setting that requires multiple conversational turns. A good Agent should ask only non-deducible, relevant questions until it has enough information to correctly answer the User's question. We use standard and improved reinforcement learning based memory-network architectures to solve QRAQ problems in the difficult setting where the reward signal only tells the Agent if its final answer to the challenge question is correct or not. To provide an upper-bound to the RL results we also train the same architectures using supervised information that tells the Agent during training which variables to query and the answer to the challenge question. We evaluate our architectures on four QRAQ dataset types, and scale the complexity for each along multiple dimensions.", "pdf": "/pdf/f3e3beec28f8af589ab294b451dacd73e524b4f5.pdf", "TL;DR": "A new dataset QRAQ of ambiguous stories in which an Agent must learn to reason and interact with a User to obtain important missing information needed to answer a challenge question.", "paperhash": "guo|learning_to_query_reason_and_answer_questions_on_ambiguous_texts", "keywords": ["Natural language processing", "Deep learning", "Reinforcement Learning"], "conflicts": ["cs.umich.edu", "ibm.com", "cs.umass.edu"], "authors": ["Xiaoxiao Guo", "Tim Klinger", "Clemens Rosenbaum", "Joseph P. Bigus", "Murray Campbell", "Ban Kawas", "Kartik Talamadupula", "Gerry Tesauro", "Satinder   Singh"], "authorids": ["tklinger@us.ibm.com", "guoxiao@umich.edu", "cgbr@cs.umass.edu", "jbigus@us.ibm.com", "mcam@us.ibm.com", "bkawas@us.ibm.com", "krtalamad@us.ibm.com", "gtesauro@us.ibm.com", "baveja@umich.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287545937, "id": "ICLR.cc/2017/conference/-/paper510/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJ0-tY5xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper510/reviewers", "ICLR.cc/2017/conference/paper510/areachairs"], "cdate": 1485287545937}}}, {"tddate": null, "tmdate": 1482854365799, "tcdate": 1482854309521, "number": 6, "id": "SkaskzlHx", "invitation": "ICLR.cc/2017/conference/-/paper510/public/comment", "forum": "rJ0-tY5xe", "replyto": "rJ0-tY5xe", "signatures": ["~Tim_Klinger1"], "readers": ["everyone"], "writers": ["~Tim_Klinger1"], "content": {"title": "Thanks to all the reviewers!", "comment": "Happy holidays and thank you all for your careful reading and thoughtful, constructive comments!\n\nA few responses to your last set of comments/questions:\n\nTo Reviewer 3:\n\nWe definitely agree that because of the limited vocabulary and grammar, this is more about reasoning than language.  As you point out, the interaction in these problems  boils down to repeated variable queries until the Agent decides it has enough info.  We decided on the term \"interaction\" to differentiate our problems from the bAbI problems, which are 1 shot question answering, and to emphasize the idea that, although simplified, this has the same structure as a dialogue interaction with the Agent (for example a tech support agent) asking clarifying questions of the User until being able to answer the User's question. We can try to think of a better term -- perhaps \"multi-turn\"?\n\nTo Reviewer 2:\n\n(1) how does the model extend to the case with multiple variables in a single sentence?\n\nCurrently we leverage the fact that there is just one variable per sentence to save on parameters and avoid a linear transformation before the softmax in the query network.  To support more than one variable per sentence would just require adding a linear transformation on the output before softmax, making the query network have the same structure as the answer network.\n\n(2) If the answer is out of vocabulary, how would the model handle it?\n\nOut of vocabulary words are in general a problem for networks which do a softmax over a fixed vocabulary.  One potential way to address this would be to use something like the Pointer Networks of Vinyals, Fortunato, and Jaitly(https://arxiv.org/abs/1506.03134) which can refer back to input elements.\n\n(3) I hope the authors can provide more analysis about the curriculum learning part, since it is very important for the RL model training.\n\nWe agree that the curriculum learning is important. Given the short amount of time remaining we are not sure we will have time to do a thorough analysis.  But we will try to add something on this and will certainly make it a priority for future revisions of the paper. \n\n(4) In the training, in each iteration, how the data samples were selected, by random or from simple one depth to multiple depth?\n\nThe results are based on random sampling. \n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Query, Reason, and Answer Questions On Ambiguous Texts", "abstract": "A key goal of research in conversational systems is to train an interactive agent to help a user with a task. Human conversation, however, is notoriously incomplete, ambiguous, and full of extraneous detail. To operate effectively, the agent must not only understand what was explicitly conveyed but also be able to reason in the presence of missing or unclear information. When unable to resolve ambiguities on its own, the agent must be able to ask the user for the necessary clarifications and incorporate the response in its reasoning. Motivated by this problem we introduce QRAQ (\"crack\"; Query, Reason, and Answer Questions), a new synthetic domain, in which a User gives an Agent a short story and asks a challenge question. These problems are designed to test the reasoning and interaction capabilities of a learning-based Agent in a setting that requires multiple conversational turns. A good Agent should ask only non-deducible, relevant questions until it has enough information to correctly answer the User's question. We use standard and improved reinforcement learning based memory-network architectures to solve QRAQ problems in the difficult setting where the reward signal only tells the Agent if its final answer to the challenge question is correct or not. To provide an upper-bound to the RL results we also train the same architectures using supervised information that tells the Agent during training which variables to query and the answer to the challenge question. We evaluate our architectures on four QRAQ dataset types, and scale the complexity for each along multiple dimensions.", "pdf": "/pdf/f3e3beec28f8af589ab294b451dacd73e524b4f5.pdf", "TL;DR": "A new dataset QRAQ of ambiguous stories in which an Agent must learn to reason and interact with a User to obtain important missing information needed to answer a challenge question.", "paperhash": "guo|learning_to_query_reason_and_answer_questions_on_ambiguous_texts", "keywords": ["Natural language processing", "Deep learning", "Reinforcement Learning"], "conflicts": ["cs.umich.edu", "ibm.com", "cs.umass.edu"], "authors": ["Xiaoxiao Guo", "Tim Klinger", "Clemens Rosenbaum", "Joseph P. Bigus", "Murray Campbell", "Ban Kawas", "Kartik Talamadupula", "Gerry Tesauro", "Satinder   Singh"], "authorids": ["tklinger@us.ibm.com", "guoxiao@umich.edu", "cgbr@cs.umass.edu", "jbigus@us.ibm.com", "mcam@us.ibm.com", "bkawas@us.ibm.com", "krtalamad@us.ibm.com", "gtesauro@us.ibm.com", "baveja@umich.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287545937, "id": "ICLR.cc/2017/conference/-/paper510/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJ0-tY5xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper510/reviewers", "ICLR.cc/2017/conference/paper510/areachairs"], "cdate": 1485287545937}}}, {"tddate": null, "tmdate": 1482273616256, "tcdate": 1482273616256, "number": 3, "id": "BkOLm4DEx", "invitation": "ICLR.cc/2017/conference/-/paper510/official/review", "forum": "rJ0-tY5xe", "replyto": "rJ0-tY5xe", "signatures": ["ICLR.cc/2017/conference/paper510/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper510/AnonReviewer2"], "content": {"title": "", "rating": "6: Marginally above acceptance threshold", "review": "This paper proposed an integration of memory network with reinforcement learning. The experimental data is simple, but the model is very interesting and relatively novel. There are some questions about the model:\n\n1. how does the model extend to the case with multiple variables in a single sentence?\n\n2. If the answer is out of vocabulary, how would the model handle it?\n\n3. I hope the authors can provide more analysis about the curriculum learning part, since it is very important for the RL model training.\n\n4. In the training, in each iteration, how the data samples were selected, by random or from simple one depth to multiple depth? \n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Query, Reason, and Answer Questions On Ambiguous Texts", "abstract": "A key goal of research in conversational systems is to train an interactive agent to help a user with a task. Human conversation, however, is notoriously incomplete, ambiguous, and full of extraneous detail. To operate effectively, the agent must not only understand what was explicitly conveyed but also be able to reason in the presence of missing or unclear information. When unable to resolve ambiguities on its own, the agent must be able to ask the user for the necessary clarifications and incorporate the response in its reasoning. Motivated by this problem we introduce QRAQ (\"crack\"; Query, Reason, and Answer Questions), a new synthetic domain, in which a User gives an Agent a short story and asks a challenge question. These problems are designed to test the reasoning and interaction capabilities of a learning-based Agent in a setting that requires multiple conversational turns. A good Agent should ask only non-deducible, relevant questions until it has enough information to correctly answer the User's question. We use standard and improved reinforcement learning based memory-network architectures to solve QRAQ problems in the difficult setting where the reward signal only tells the Agent if its final answer to the challenge question is correct or not. To provide an upper-bound to the RL results we also train the same architectures using supervised information that tells the Agent during training which variables to query and the answer to the challenge question. We evaluate our architectures on four QRAQ dataset types, and scale the complexity for each along multiple dimensions.", "pdf": "/pdf/f3e3beec28f8af589ab294b451dacd73e524b4f5.pdf", "TL;DR": "A new dataset QRAQ of ambiguous stories in which an Agent must learn to reason and interact with a User to obtain important missing information needed to answer a challenge question.", "paperhash": "guo|learning_to_query_reason_and_answer_questions_on_ambiguous_texts", "keywords": ["Natural language processing", "Deep learning", "Reinforcement Learning"], "conflicts": ["cs.umich.edu", "ibm.com", "cs.umass.edu"], "authors": ["Xiaoxiao Guo", "Tim Klinger", "Clemens Rosenbaum", "Joseph P. Bigus", "Murray Campbell", "Ban Kawas", "Kartik Talamadupula", "Gerry Tesauro", "Satinder   Singh"], "authorids": ["tklinger@us.ibm.com", "guoxiao@umich.edu", "cgbr@cs.umass.edu", "jbigus@us.ibm.com", "mcam@us.ibm.com", "bkawas@us.ibm.com", "krtalamad@us.ibm.com", "gtesauro@us.ibm.com", "baveja@umich.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512558606, "id": "ICLR.cc/2017/conference/-/paper510/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper510/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper510/AnonReviewer3", "ICLR.cc/2017/conference/paper510/AnonReviewer1", "ICLR.cc/2017/conference/paper510/AnonReviewer2"], "reply": {"forum": "rJ0-tY5xe", "replyto": "rJ0-tY5xe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper510/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper510/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512558606}}}, {"tddate": null, "tmdate": 1481969504484, "tcdate": 1481969504484, "number": 2, "id": "SkdvJ9MEl", "invitation": "ICLR.cc/2017/conference/-/paper510/official/review", "forum": "rJ0-tY5xe", "replyto": "rJ0-tY5xe", "signatures": ["ICLR.cc/2017/conference/paper510/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper510/AnonReviewer1"], "content": {"title": "", "rating": "7: Good paper, accept", "review": "This paper introduces a nice dataset/data generator that creates bAbI like tasks, except where the questioning answering agent is required to clarify the values of some variables in order to succeed.  I think the baselines the authors use to test the tasks are appropriate.   I am a bit worried that the tasks may be too easy (as the bAbI tasks have been), but still, I think locally these will be useful.  If the generation code is well written, and the tasks are extensible, they may be useful for some time.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Query, Reason, and Answer Questions On Ambiguous Texts", "abstract": "A key goal of research in conversational systems is to train an interactive agent to help a user with a task. Human conversation, however, is notoriously incomplete, ambiguous, and full of extraneous detail. To operate effectively, the agent must not only understand what was explicitly conveyed but also be able to reason in the presence of missing or unclear information. When unable to resolve ambiguities on its own, the agent must be able to ask the user for the necessary clarifications and incorporate the response in its reasoning. Motivated by this problem we introduce QRAQ (\"crack\"; Query, Reason, and Answer Questions), a new synthetic domain, in which a User gives an Agent a short story and asks a challenge question. These problems are designed to test the reasoning and interaction capabilities of a learning-based Agent in a setting that requires multiple conversational turns. A good Agent should ask only non-deducible, relevant questions until it has enough information to correctly answer the User's question. We use standard and improved reinforcement learning based memory-network architectures to solve QRAQ problems in the difficult setting where the reward signal only tells the Agent if its final answer to the challenge question is correct or not. To provide an upper-bound to the RL results we also train the same architectures using supervised information that tells the Agent during training which variables to query and the answer to the challenge question. We evaluate our architectures on four QRAQ dataset types, and scale the complexity for each along multiple dimensions.", "pdf": "/pdf/f3e3beec28f8af589ab294b451dacd73e524b4f5.pdf", "TL;DR": "A new dataset QRAQ of ambiguous stories in which an Agent must learn to reason and interact with a User to obtain important missing information needed to answer a challenge question.", "paperhash": "guo|learning_to_query_reason_and_answer_questions_on_ambiguous_texts", "keywords": ["Natural language processing", "Deep learning", "Reinforcement Learning"], "conflicts": ["cs.umich.edu", "ibm.com", "cs.umass.edu"], "authors": ["Xiaoxiao Guo", "Tim Klinger", "Clemens Rosenbaum", "Joseph P. Bigus", "Murray Campbell", "Ban Kawas", "Kartik Talamadupula", "Gerry Tesauro", "Satinder   Singh"], "authorids": ["tklinger@us.ibm.com", "guoxiao@umich.edu", "cgbr@cs.umass.edu", "jbigus@us.ibm.com", "mcam@us.ibm.com", "bkawas@us.ibm.com", "krtalamad@us.ibm.com", "gtesauro@us.ibm.com", "baveja@umich.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512558606, "id": "ICLR.cc/2017/conference/-/paper510/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper510/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper510/AnonReviewer3", "ICLR.cc/2017/conference/paper510/AnonReviewer1", "ICLR.cc/2017/conference/paper510/AnonReviewer2"], "reply": {"forum": "rJ0-tY5xe", "replyto": "rJ0-tY5xe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper510/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper510/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512558606}}}, {"tddate": null, "tmdate": 1481925158252, "tcdate": 1481925158252, "number": 1, "id": "ByC7GyG4l", "invitation": "ICLR.cc/2017/conference/-/paper510/official/review", "forum": "rJ0-tY5xe", "replyto": "rJ0-tY5xe", "signatures": ["ICLR.cc/2017/conference/paper510/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper510/AnonReviewer3"], "content": {"title": "Review", "rating": "7: Good paper, accept", "review": "This paper investigates a set of tasks that augment the basic bAbI problems. In particular, some of the people and objects in the scenarios are replaced with unknown variables. Some of these variables must be known to solve the question, thus the agent must learn to query for the values of these variables. Interestingly, one can now measure both the performance of the agent in correctly answering the question, and its efficiency in asking for the values of the correct unknown variables (and not variables that are unnecessary to answer the question). This inferring of unknown variables goes beyond what is required for the vanilla version of the bAbI tasks, which are now more or less solved.\n\nThe paper is well-written, and the contributions are clear. Due to the very limited vocabulary and structure of the bAbI problems in general, I think these tasks (and variants on them) should be viewed more as basic reasoning tasks than natural language understanding. I\u2019m not convinced by the claim of the paper that this really tests the \u2018interaction\u2019 capabilities of agents \u2013 while the task is phrased as a kind of interaction, I think it\u2019s more aptly described by simply \u2018inferring important unknown variables\u2019, which (while important) is more related to reasoning. I\u2019m not sure whether the connection of this ability to \u2018interaction\u2019 is more a superficial one.\n\nThat being said, it is certainly true that conversational agents will need basic reasoning abilities to converse meaningfully with humans. I sympathise with the general goal of the bAbI tasks, which is to test these reasoning abilities in synthetic environments, that are just complicated enough (but not more) to drive the construction of interesting models. I am convinced by the authors that their extension to these tasks are interesting and worthy of future investigation, and thus I recommend the acceptance of the paper.\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Query, Reason, and Answer Questions On Ambiguous Texts", "abstract": "A key goal of research in conversational systems is to train an interactive agent to help a user with a task. Human conversation, however, is notoriously incomplete, ambiguous, and full of extraneous detail. To operate effectively, the agent must not only understand what was explicitly conveyed but also be able to reason in the presence of missing or unclear information. When unable to resolve ambiguities on its own, the agent must be able to ask the user for the necessary clarifications and incorporate the response in its reasoning. Motivated by this problem we introduce QRAQ (\"crack\"; Query, Reason, and Answer Questions), a new synthetic domain, in which a User gives an Agent a short story and asks a challenge question. These problems are designed to test the reasoning and interaction capabilities of a learning-based Agent in a setting that requires multiple conversational turns. A good Agent should ask only non-deducible, relevant questions until it has enough information to correctly answer the User's question. We use standard and improved reinforcement learning based memory-network architectures to solve QRAQ problems in the difficult setting where the reward signal only tells the Agent if its final answer to the challenge question is correct or not. To provide an upper-bound to the RL results we also train the same architectures using supervised information that tells the Agent during training which variables to query and the answer to the challenge question. We evaluate our architectures on four QRAQ dataset types, and scale the complexity for each along multiple dimensions.", "pdf": "/pdf/f3e3beec28f8af589ab294b451dacd73e524b4f5.pdf", "TL;DR": "A new dataset QRAQ of ambiguous stories in which an Agent must learn to reason and interact with a User to obtain important missing information needed to answer a challenge question.", "paperhash": "guo|learning_to_query_reason_and_answer_questions_on_ambiguous_texts", "keywords": ["Natural language processing", "Deep learning", "Reinforcement Learning"], "conflicts": ["cs.umich.edu", "ibm.com", "cs.umass.edu"], "authors": ["Xiaoxiao Guo", "Tim Klinger", "Clemens Rosenbaum", "Joseph P. Bigus", "Murray Campbell", "Ban Kawas", "Kartik Talamadupula", "Gerry Tesauro", "Satinder   Singh"], "authorids": ["tklinger@us.ibm.com", "guoxiao@umich.edu", "cgbr@cs.umass.edu", "jbigus@us.ibm.com", "mcam@us.ibm.com", "bkawas@us.ibm.com", "krtalamad@us.ibm.com", "gtesauro@us.ibm.com", "baveja@umich.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512558606, "id": "ICLR.cc/2017/conference/-/paper510/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper510/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper510/AnonReviewer3", "ICLR.cc/2017/conference/paper510/AnonReviewer1", "ICLR.cc/2017/conference/paper510/AnonReviewer2"], "reply": {"forum": "rJ0-tY5xe", "replyto": "rJ0-tY5xe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper510/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper510/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512558606}}}, {"tddate": null, "tmdate": 1481640145039, "tcdate": 1481640145033, "number": 5, "id": "HyYRdKTXe", "invitation": "ICLR.cc/2017/conference/-/paper510/public/comment", "forum": "rJ0-tY5xe", "replyto": "Sypz-N2Xe", "signatures": ["~Tim_Klinger1"], "readers": ["everyone"], "writers": ["~Tim_Klinger1"], "content": {"title": "Thanks for the comment", "comment": "We agree that a \"query them all\" baseline would be useful to compute and we will try to run the experiments before the accept/reject deadline if we can.\n\nWe explored five pairs of query reward values for the curriculum (+/-0.01, +/-0.05, +/-0.1, +/-0.5, +/-1) and found that +/-0.05 was the best performing but don't yet have any deeper insights about why some values are better than others.  We probably won't be able to do the query cost tradeoff analysis for this paper but agree also that it would be a good direction for further analysis.\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Query, Reason, and Answer Questions On Ambiguous Texts", "abstract": "A key goal of research in conversational systems is to train an interactive agent to help a user with a task. Human conversation, however, is notoriously incomplete, ambiguous, and full of extraneous detail. To operate effectively, the agent must not only understand what was explicitly conveyed but also be able to reason in the presence of missing or unclear information. When unable to resolve ambiguities on its own, the agent must be able to ask the user for the necessary clarifications and incorporate the response in its reasoning. Motivated by this problem we introduce QRAQ (\"crack\"; Query, Reason, and Answer Questions), a new synthetic domain, in which a User gives an Agent a short story and asks a challenge question. These problems are designed to test the reasoning and interaction capabilities of a learning-based Agent in a setting that requires multiple conversational turns. A good Agent should ask only non-deducible, relevant questions until it has enough information to correctly answer the User's question. We use standard and improved reinforcement learning based memory-network architectures to solve QRAQ problems in the difficult setting where the reward signal only tells the Agent if its final answer to the challenge question is correct or not. To provide an upper-bound to the RL results we also train the same architectures using supervised information that tells the Agent during training which variables to query and the answer to the challenge question. We evaluate our architectures on four QRAQ dataset types, and scale the complexity for each along multiple dimensions.", "pdf": "/pdf/f3e3beec28f8af589ab294b451dacd73e524b4f5.pdf", "TL;DR": "A new dataset QRAQ of ambiguous stories in which an Agent must learn to reason and interact with a User to obtain important missing information needed to answer a challenge question.", "paperhash": "guo|learning_to_query_reason_and_answer_questions_on_ambiguous_texts", "keywords": ["Natural language processing", "Deep learning", "Reinforcement Learning"], "conflicts": ["cs.umich.edu", "ibm.com", "cs.umass.edu"], "authors": ["Xiaoxiao Guo", "Tim Klinger", "Clemens Rosenbaum", "Joseph P. Bigus", "Murray Campbell", "Ban Kawas", "Kartik Talamadupula", "Gerry Tesauro", "Satinder   Singh"], "authorids": ["tklinger@us.ibm.com", "guoxiao@umich.edu", "cgbr@cs.umass.edu", "jbigus@us.ibm.com", "mcam@us.ibm.com", "bkawas@us.ibm.com", "krtalamad@us.ibm.com", "gtesauro@us.ibm.com", "baveja@umich.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287545937, "id": "ICLR.cc/2017/conference/-/paper510/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJ0-tY5xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper510/reviewers", "ICLR.cc/2017/conference/paper510/areachairs"], "cdate": 1485287545937}}}, {"tddate": null, "tmdate": 1481552148935, "tcdate": 1481552148929, "number": 3, "id": "Sypz-N2Xe", "invitation": "ICLR.cc/2017/conference/-/paper510/pre-review/question", "forum": "rJ0-tY5xe", "replyto": "rJ0-tY5xe", "signatures": ["ICLR.cc/2017/conference/paper510/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper510/AnonReviewer1"], "content": {"title": "reward vs accuracy", "question": "I would be curious to see how well a \"greedy\" question-asker would fair in terms of reward and the evaluations you show.  More generally, it would be interesting to see the tradeoffs between different query costs and the success metrics you compute.    How did you choose .05 --> -.05 ? "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Query, Reason, and Answer Questions On Ambiguous Texts", "abstract": "A key goal of research in conversational systems is to train an interactive agent to help a user with a task. Human conversation, however, is notoriously incomplete, ambiguous, and full of extraneous detail. To operate effectively, the agent must not only understand what was explicitly conveyed but also be able to reason in the presence of missing or unclear information. When unable to resolve ambiguities on its own, the agent must be able to ask the user for the necessary clarifications and incorporate the response in its reasoning. Motivated by this problem we introduce QRAQ (\"crack\"; Query, Reason, and Answer Questions), a new synthetic domain, in which a User gives an Agent a short story and asks a challenge question. These problems are designed to test the reasoning and interaction capabilities of a learning-based Agent in a setting that requires multiple conversational turns. A good Agent should ask only non-deducible, relevant questions until it has enough information to correctly answer the User's question. We use standard and improved reinforcement learning based memory-network architectures to solve QRAQ problems in the difficult setting where the reward signal only tells the Agent if its final answer to the challenge question is correct or not. To provide an upper-bound to the RL results we also train the same architectures using supervised information that tells the Agent during training which variables to query and the answer to the challenge question. We evaluate our architectures on four QRAQ dataset types, and scale the complexity for each along multiple dimensions.", "pdf": "/pdf/f3e3beec28f8af589ab294b451dacd73e524b4f5.pdf", "TL;DR": "A new dataset QRAQ of ambiguous stories in which an Agent must learn to reason and interact with a User to obtain important missing information needed to answer a challenge question.", "paperhash": "guo|learning_to_query_reason_and_answer_questions_on_ambiguous_texts", "keywords": ["Natural language processing", "Deep learning", "Reinforcement Learning"], "conflicts": ["cs.umich.edu", "ibm.com", "cs.umass.edu"], "authors": ["Xiaoxiao Guo", "Tim Klinger", "Clemens Rosenbaum", "Joseph P. Bigus", "Murray Campbell", "Ban Kawas", "Kartik Talamadupula", "Gerry Tesauro", "Satinder   Singh"], "authorids": ["tklinger@us.ibm.com", "guoxiao@umich.edu", "cgbr@cs.umass.edu", "jbigus@us.ibm.com", "mcam@us.ibm.com", "bkawas@us.ibm.com", "krtalamad@us.ibm.com", "gtesauro@us.ibm.com", "baveja@umich.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481552149555, "id": "ICLR.cc/2017/conference/-/paper510/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper510/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper510/AnonReviewer3", "ICLR.cc/2017/conference/paper510/AnonReviewer2", "ICLR.cc/2017/conference/paper510/AnonReviewer1"], "reply": {"forum": "rJ0-tY5xe", "replyto": "rJ0-tY5xe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper510/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper510/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481552149555}}}, {"tddate": null, "tmdate": 1480957058710, "tcdate": 1480956308107, "number": 4, "id": "BJh9Kz7Qx", "invitation": "ICLR.cc/2017/conference/-/paper510/public/comment", "forum": "rJ0-tY5xe", "replyto": "SJKAqPJ7e", "signatures": ["~Tim_Klinger1"], "readers": ["everyone"], "writers": ["~Tim_Klinger1"], "content": {"title": "Thanks for the comments.  A response to your concerns.", "comment": "(1) For example, it seems like the model can achieve very high answer accuracy without good trajectory accuracy, thereby making it dubious as to whether the model is actually \"learning\" a policy that is actually reasoning over the relevant variables. \n\nTrajectory Accuracy (TrajAcc) requires the agent to query only relevant variables then answer correctly; Trajectory Completeness (TrajCmpl) accuracy requires the agent in addition to not answer if there are still unqueried relevant variables; answer accuracy (AnsAcc) just requires the agent to answer correctly regardless of how it queries.  So it is always the case that TrajCmpl <= TrajAcc <= AnsAcc. The gap between trajectory accuracy and answer accuracy is because of the difficulty of learning to query all and only relevant variables. We have performed an additional analysis to understand to what degree the agent has really learned to query -- both for querying relevant vars and not querying irrelevant ones.  We also calculated how much \"guessing\" the agent is doing when it answers correctly without having queried all the relevant variables.\n\nIn the table below rows 1-3 just copy the metrics from our table.  Row 4 is calculated as 1-(TrajCmpl/AnsAcc).  TrajCmpl/AnsAcc is the proportion of correct answers which had completely correct queries, so 1-(TrajCmpl/AnsAcc) is the proportion of correct answers given after some query mistake -- either a query of an irrelevant variable or a failure to query a relevant one before answering.  Row 4 shows that a majority of the time in all the Loc problems, when the RL agent answers correctly, it does so having done exactly the right querying.  For the first two loc columns, the query errors are in the 4-6% range, which increases to 35-47% for the harder last 3 columns.  This indicates that the RL agent answers correctly it does so having learned to query correctly in a majority of cases across all the Loc columns.  For the first two columns, which are easier, it has learned to query almost perfectly before answering correctly.\n\nRows 5 and 6 break this query error number down into the \"queried irrelevant\" and \"failed to query relevant\" components (i.e. row 5 + row 6 = row 4). From these we can see that when the RL agent makes a query mistake it's usually because it has queried something irrelevant not failed to query something relevant.  In fact row 6 shows that even in one of the hardest loc cases (rightmost col) the RL agent is only guessing the answer 11% of the time when it answers correctly; the rest of the time it has the information needed to correctly answer, though may have queried some variables unnecessarily.\n\n1. TrajCmpl in %; impRL: 94.5, 88.7, 55.8, 46.9, 37.8\n2. AnsACC in %; impRL: 99.1, 94.4, 86.5, 89, 64.2\n3. TrajAcc in %; impRL: 94.5, 90.9, 61.9, 52, 45.1\n4. % of correct answers after a query mistake:\t0.04641776, 0.060381356, 0.354913295, 0.473033708, 0.411214953\n(either irrelevant query or relevant var unqueried)\t\t\t\t\t\n5. % of correct answers after an irrelevant var query: 0.04641776, 0.037076271, 0.284393064, 0.415730337, 0.297507788\n6. % of correct answers with rel var unqueried (i.e. guesses): 0, 0.023305085, 0.070520231, 0.057303371, 0.113707165\n\n(4) In particular, counterintuitively, it seems that the trajectory accuracy isn't correlated with higher answer accuracy. This leads one to question whether reasoning over the relevant variables is even required to obtain good final performance (eg. answer accuracy) on the task. \n\nAs mentioned above, the toughest measure of final performance is the trajectory completeness accuracy (TrajCmpl) not the answer accuracy (AnsAcc).  To the extent that there is a difference between the two it means that the difficulty of the two key sub-problems (querying and answering) scale differently.\n\n(5) Another concern is that there is significant jump in query accuracy in the last column of the \"Loc\" results. What's the intuition behind this? I would like to see more analysis of the numbers in the results table from the authors.\n\nOur intuition here is the following. If you look at the table you can see that query accuracy is closely correlated with the % of relevant vars (over all variables) which the agent must query in the worst case (it is shown as sum(depth)/sum(var) in the results table).  An agent which is less performant in determining the relevant variables (for example if it guesses in some cases) would be sensitive to this metric. We interpret this correlation as indicating the RL agent is sensitive in this way (though the SL agent is much better).  We discuss this point in the Results section."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Query, Reason, and Answer Questions On Ambiguous Texts", "abstract": "A key goal of research in conversational systems is to train an interactive agent to help a user with a task. Human conversation, however, is notoriously incomplete, ambiguous, and full of extraneous detail. To operate effectively, the agent must not only understand what was explicitly conveyed but also be able to reason in the presence of missing or unclear information. When unable to resolve ambiguities on its own, the agent must be able to ask the user for the necessary clarifications and incorporate the response in its reasoning. Motivated by this problem we introduce QRAQ (\"crack\"; Query, Reason, and Answer Questions), a new synthetic domain, in which a User gives an Agent a short story and asks a challenge question. These problems are designed to test the reasoning and interaction capabilities of a learning-based Agent in a setting that requires multiple conversational turns. A good Agent should ask only non-deducible, relevant questions until it has enough information to correctly answer the User's question. We use standard and improved reinforcement learning based memory-network architectures to solve QRAQ problems in the difficult setting where the reward signal only tells the Agent if its final answer to the challenge question is correct or not. To provide an upper-bound to the RL results we also train the same architectures using supervised information that tells the Agent during training which variables to query and the answer to the challenge question. We evaluate our architectures on four QRAQ dataset types, and scale the complexity for each along multiple dimensions.", "pdf": "/pdf/f3e3beec28f8af589ab294b451dacd73e524b4f5.pdf", "TL;DR": "A new dataset QRAQ of ambiguous stories in which an Agent must learn to reason and interact with a User to obtain important missing information needed to answer a challenge question.", "paperhash": "guo|learning_to_query_reason_and_answer_questions_on_ambiguous_texts", "keywords": ["Natural language processing", "Deep learning", "Reinforcement Learning"], "conflicts": ["cs.umich.edu", "ibm.com", "cs.umass.edu"], "authors": ["Xiaoxiao Guo", "Tim Klinger", "Clemens Rosenbaum", "Joseph P. Bigus", "Murray Campbell", "Ban Kawas", "Kartik Talamadupula", "Gerry Tesauro", "Satinder   Singh"], "authorids": ["tklinger@us.ibm.com", "guoxiao@umich.edu", "cgbr@cs.umass.edu", "jbigus@us.ibm.com", "mcam@us.ibm.com", "bkawas@us.ibm.com", "krtalamad@us.ibm.com", "gtesauro@us.ibm.com", "baveja@umich.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287545937, "id": "ICLR.cc/2017/conference/-/paper510/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJ0-tY5xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper510/reviewers", "ICLR.cc/2017/conference/paper510/areachairs"], "cdate": 1485287545937}}}, {"tddate": null, "tmdate": 1480954578540, "tcdate": 1480954578533, "number": 3, "id": "HycCGzQXg", "invitation": "ICLR.cc/2017/conference/-/paper510/public/comment", "forum": "rJ0-tY5xe", "replyto": "SyO3imJme", "signatures": ["~Tim_Klinger1"], "readers": ["everyone"], "writers": ["~Tim_Klinger1"], "content": {"title": "Thanks for your comments", "comment": "(1) Have the authors considered also using locations as unknown variables, rather than just people names?\n\nThere is no technical impediment to having room protagonists.  However, what makes the reasoning interesting for people (and objects) is the domain rule that constrains people to be in one room at a time.  This is what drives the harder deductions and makes finding the non-deducible, relevant variables more difficult for the agent.  Rooms have no constraints in either the bAbI or QRAQ domain so stories with room variables and room protagonists would often simply require the agent to learn to query every variable until it reveals the answer.  For example,\n \nA is in R1\nB is in R2\nC is in R3\nA goes from R1 to $X1\nB goes from R2 to $X2\n \nwho is in R2?\n \nHere the agent must just query the remaining variables in turn until it finds out which one corresponds to R2.\n \nOne way to make room protagonists more interesting/difficult is to add constraints on room occupancy.  For example, require that rooms have no more than 2 people in them at a time.  This would force the agent to learn to count to determine whether a room could be the destination of a move.\n \nFor example,\nA is in R1\nB is in R2\nC is in R2\nD is in R3\nA goes from R1 to $X\n\nFrom this the agent must deduce that $X must be D since R2 is fully occupied.  Another natural constraint would be to create a non-trivial connection matrix for rooms.\n \nThese would be interesting extensions, but given the difficulty of the existing datasets, it's one that we leave for the future.\n\n(2) What thoughts do the authors have on scaling these kinds of approaches to more realistic language settings? The bAbI tasks are notoriously vocabulary/ structure constrained, making the task significantly easier.\n\nWe agree that synthetic datasets are much more constrained than realistic datasets.  We view the solution of problems, like those in QRAQ, as a necessary (but not sufficient) requirement for solving more realistic problems.  There are several ways we have worked to make the QRAQ problems more realistic and thus able to offer serious challenges to learning algorithms in this space.  First, we have included knobs in the problem generator that allow us to generate problems with a large vocabulary, large numbers of variables, high depth, etc. This allows us to test the robustness of our models as these parameters scale up. Some experiments along these lines are reported in our results.  Second, we have focused our efforts on RL approaches (though we also report supervised numbers) which are more realistic for real-world settings.  We believe that the baseline memory net approaches are not sufficient to learn these tasks well and working to develop new approaches which we hope will scale well in the RL setting."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Query, Reason, and Answer Questions On Ambiguous Texts", "abstract": "A key goal of research in conversational systems is to train an interactive agent to help a user with a task. Human conversation, however, is notoriously incomplete, ambiguous, and full of extraneous detail. To operate effectively, the agent must not only understand what was explicitly conveyed but also be able to reason in the presence of missing or unclear information. When unable to resolve ambiguities on its own, the agent must be able to ask the user for the necessary clarifications and incorporate the response in its reasoning. Motivated by this problem we introduce QRAQ (\"crack\"; Query, Reason, and Answer Questions), a new synthetic domain, in which a User gives an Agent a short story and asks a challenge question. These problems are designed to test the reasoning and interaction capabilities of a learning-based Agent in a setting that requires multiple conversational turns. A good Agent should ask only non-deducible, relevant questions until it has enough information to correctly answer the User's question. We use standard and improved reinforcement learning based memory-network architectures to solve QRAQ problems in the difficult setting where the reward signal only tells the Agent if its final answer to the challenge question is correct or not. To provide an upper-bound to the RL results we also train the same architectures using supervised information that tells the Agent during training which variables to query and the answer to the challenge question. We evaluate our architectures on four QRAQ dataset types, and scale the complexity for each along multiple dimensions.", "pdf": "/pdf/f3e3beec28f8af589ab294b451dacd73e524b4f5.pdf", "TL;DR": "A new dataset QRAQ of ambiguous stories in which an Agent must learn to reason and interact with a User to obtain important missing information needed to answer a challenge question.", "paperhash": "guo|learning_to_query_reason_and_answer_questions_on_ambiguous_texts", "keywords": ["Natural language processing", "Deep learning", "Reinforcement Learning"], "conflicts": ["cs.umich.edu", "ibm.com", "cs.umass.edu"], "authors": ["Xiaoxiao Guo", "Tim Klinger", "Clemens Rosenbaum", "Joseph P. Bigus", "Murray Campbell", "Ban Kawas", "Kartik Talamadupula", "Gerry Tesauro", "Satinder   Singh"], "authorids": ["tklinger@us.ibm.com", "guoxiao@umich.edu", "cgbr@cs.umass.edu", "jbigus@us.ibm.com", "mcam@us.ibm.com", "bkawas@us.ibm.com", "krtalamad@us.ibm.com", "gtesauro@us.ibm.com", "baveja@umich.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287545937, "id": "ICLR.cc/2017/conference/-/paper510/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJ0-tY5xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper510/reviewers", "ICLR.cc/2017/conference/paper510/areachairs"], "cdate": 1485287545937}}}, {"tddate": null, "tmdate": 1480714960973, "tcdate": 1480714960968, "number": 2, "id": "SJKAqPJ7e", "invitation": "ICLR.cc/2017/conference/-/paper510/pre-review/question", "forum": "rJ0-tY5xe", "replyto": "rJ0-tY5xe", "signatures": ["ICLR.cc/2017/conference/paper510/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper510/AnonReviewer2"], "content": {"title": "some concerns", "question": "The proposed task is interesting in that it makes headways towards realistic, goal-oriented AI systems. However, I am skeptical regarding some of the evaluation metrics. For example, it seems like the model can achieve very high answer accuracy without good trajectory accuracy, thereby making it dubious as to whether the model is actually \"learning\" a policy that is actually reasoning over the relevant variables. In particular, counterintuitively, it seems that the trajectory accuracy isn't correlated with higher answer accuracy. This leads one to question whether reasoning over the relevant variables is even required to obtain good final performance (eg. answer accuracy) on the task. Another concern is that there is significant jump in query accuracy in the last column of the \"Loc\" results. What's the intuition behind this? I would like to see more analysis of the numbers in the results table from the authors."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Query, Reason, and Answer Questions On Ambiguous Texts", "abstract": "A key goal of research in conversational systems is to train an interactive agent to help a user with a task. Human conversation, however, is notoriously incomplete, ambiguous, and full of extraneous detail. To operate effectively, the agent must not only understand what was explicitly conveyed but also be able to reason in the presence of missing or unclear information. When unable to resolve ambiguities on its own, the agent must be able to ask the user for the necessary clarifications and incorporate the response in its reasoning. Motivated by this problem we introduce QRAQ (\"crack\"; Query, Reason, and Answer Questions), a new synthetic domain, in which a User gives an Agent a short story and asks a challenge question. These problems are designed to test the reasoning and interaction capabilities of a learning-based Agent in a setting that requires multiple conversational turns. A good Agent should ask only non-deducible, relevant questions until it has enough information to correctly answer the User's question. We use standard and improved reinforcement learning based memory-network architectures to solve QRAQ problems in the difficult setting where the reward signal only tells the Agent if its final answer to the challenge question is correct or not. To provide an upper-bound to the RL results we also train the same architectures using supervised information that tells the Agent during training which variables to query and the answer to the challenge question. We evaluate our architectures on four QRAQ dataset types, and scale the complexity for each along multiple dimensions.", "pdf": "/pdf/f3e3beec28f8af589ab294b451dacd73e524b4f5.pdf", "TL;DR": "A new dataset QRAQ of ambiguous stories in which an Agent must learn to reason and interact with a User to obtain important missing information needed to answer a challenge question.", "paperhash": "guo|learning_to_query_reason_and_answer_questions_on_ambiguous_texts", "keywords": ["Natural language processing", "Deep learning", "Reinforcement Learning"], "conflicts": ["cs.umich.edu", "ibm.com", "cs.umass.edu"], "authors": ["Xiaoxiao Guo", "Tim Klinger", "Clemens Rosenbaum", "Joseph P. Bigus", "Murray Campbell", "Ban Kawas", "Kartik Talamadupula", "Gerry Tesauro", "Satinder   Singh"], "authorids": ["tklinger@us.ibm.com", "guoxiao@umich.edu", "cgbr@cs.umass.edu", "jbigus@us.ibm.com", "mcam@us.ibm.com", "bkawas@us.ibm.com", "krtalamad@us.ibm.com", "gtesauro@us.ibm.com", "baveja@umich.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481552149555, "id": "ICLR.cc/2017/conference/-/paper510/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper510/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper510/AnonReviewer3", "ICLR.cc/2017/conference/paper510/AnonReviewer2", "ICLR.cc/2017/conference/paper510/AnonReviewer1"], "reply": {"forum": "rJ0-tY5xe", "replyto": "rJ0-tY5xe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper510/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper510/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481552149555}}}, {"tddate": null, "tmdate": 1480698799844, "tcdate": 1480698799840, "number": 1, "id": "SyO3imJme", "invitation": "ICLR.cc/2017/conference/-/paper510/pre-review/question", "forum": "rJ0-tY5xe", "replyto": "rJ0-tY5xe", "signatures": ["ICLR.cc/2017/conference/paper510/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper510/AnonReviewer3"], "content": {"title": "paper is clear", "question": "\nI think the stated contributions of the paper are quite clear. I had a couple of general questions:\n\n1) Have the authors considered also using locations as unknown variables, rather than just people names?\n2) What thoughts do the authors have on scaling these kinds of approaches to more realistic language settings? The bAbI tasks are notoriously vocabulary/ structure constrained, making the task significantly easier."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Query, Reason, and Answer Questions On Ambiguous Texts", "abstract": "A key goal of research in conversational systems is to train an interactive agent to help a user with a task. Human conversation, however, is notoriously incomplete, ambiguous, and full of extraneous detail. To operate effectively, the agent must not only understand what was explicitly conveyed but also be able to reason in the presence of missing or unclear information. When unable to resolve ambiguities on its own, the agent must be able to ask the user for the necessary clarifications and incorporate the response in its reasoning. Motivated by this problem we introduce QRAQ (\"crack\"; Query, Reason, and Answer Questions), a new synthetic domain, in which a User gives an Agent a short story and asks a challenge question. These problems are designed to test the reasoning and interaction capabilities of a learning-based Agent in a setting that requires multiple conversational turns. A good Agent should ask only non-deducible, relevant questions until it has enough information to correctly answer the User's question. We use standard and improved reinforcement learning based memory-network architectures to solve QRAQ problems in the difficult setting where the reward signal only tells the Agent if its final answer to the challenge question is correct or not. To provide an upper-bound to the RL results we also train the same architectures using supervised information that tells the Agent during training which variables to query and the answer to the challenge question. We evaluate our architectures on four QRAQ dataset types, and scale the complexity for each along multiple dimensions.", "pdf": "/pdf/f3e3beec28f8af589ab294b451dacd73e524b4f5.pdf", "TL;DR": "A new dataset QRAQ of ambiguous stories in which an Agent must learn to reason and interact with a User to obtain important missing information needed to answer a challenge question.", "paperhash": "guo|learning_to_query_reason_and_answer_questions_on_ambiguous_texts", "keywords": ["Natural language processing", "Deep learning", "Reinforcement Learning"], "conflicts": ["cs.umich.edu", "ibm.com", "cs.umass.edu"], "authors": ["Xiaoxiao Guo", "Tim Klinger", "Clemens Rosenbaum", "Joseph P. Bigus", "Murray Campbell", "Ban Kawas", "Kartik Talamadupula", "Gerry Tesauro", "Satinder   Singh"], "authorids": ["tklinger@us.ibm.com", "guoxiao@umich.edu", "cgbr@cs.umass.edu", "jbigus@us.ibm.com", "mcam@us.ibm.com", "bkawas@us.ibm.com", "krtalamad@us.ibm.com", "gtesauro@us.ibm.com", "baveja@umich.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481552149555, "id": "ICLR.cc/2017/conference/-/paper510/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper510/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper510/AnonReviewer3", "ICLR.cc/2017/conference/paper510/AnonReviewer2", "ICLR.cc/2017/conference/paper510/AnonReviewer1"], "reply": {"forum": "rJ0-tY5xe", "replyto": "rJ0-tY5xe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper510/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper510/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481552149555}}}, {"tddate": null, "tmdate": 1478624423703, "tcdate": 1478624423683, "number": 2, "id": "HJx2VYJbg", "invitation": "ICLR.cc/2017/conference/-/paper510/public/comment", "forum": "rJ0-tY5xe", "replyto": "r1Ugwv0xx", "signatures": ["~Tim_Klinger1"], "readers": ["everyone"], "writers": ["~Tim_Klinger1"], "content": {"title": "Thanks Tara", "comment": "We've uploaded a revised version that should have all the formatting issues fixed."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Query, Reason, and Answer Questions On Ambiguous Texts", "abstract": "A key goal of research in conversational systems is to train an interactive agent to help a user with a task. Human conversation, however, is notoriously incomplete, ambiguous, and full of extraneous detail. To operate effectively, the agent must not only understand what was explicitly conveyed but also be able to reason in the presence of missing or unclear information. When unable to resolve ambiguities on its own, the agent must be able to ask the user for the necessary clarifications and incorporate the response in its reasoning. Motivated by this problem we introduce QRAQ (\"crack\"; Query, Reason, and Answer Questions), a new synthetic domain, in which a User gives an Agent a short story and asks a challenge question. These problems are designed to test the reasoning and interaction capabilities of a learning-based Agent in a setting that requires multiple conversational turns. A good Agent should ask only non-deducible, relevant questions until it has enough information to correctly answer the User's question. We use standard and improved reinforcement learning based memory-network architectures to solve QRAQ problems in the difficult setting where the reward signal only tells the Agent if its final answer to the challenge question is correct or not. To provide an upper-bound to the RL results we also train the same architectures using supervised information that tells the Agent during training which variables to query and the answer to the challenge question. We evaluate our architectures on four QRAQ dataset types, and scale the complexity for each along multiple dimensions.", "pdf": "/pdf/f3e3beec28f8af589ab294b451dacd73e524b4f5.pdf", "TL;DR": "A new dataset QRAQ of ambiguous stories in which an Agent must learn to reason and interact with a User to obtain important missing information needed to answer a challenge question.", "paperhash": "guo|learning_to_query_reason_and_answer_questions_on_ambiguous_texts", "keywords": ["Natural language processing", "Deep learning", "Reinforcement Learning"], "conflicts": ["cs.umich.edu", "ibm.com", "cs.umass.edu"], "authors": ["Xiaoxiao Guo", "Tim Klinger", "Clemens Rosenbaum", "Joseph P. Bigus", "Murray Campbell", "Ban Kawas", "Kartik Talamadupula", "Gerry Tesauro", "Satinder   Singh"], "authorids": ["tklinger@us.ibm.com", "guoxiao@umich.edu", "cgbr@cs.umass.edu", "jbigus@us.ibm.com", "mcam@us.ibm.com", "bkawas@us.ibm.com", "krtalamad@us.ibm.com", "gtesauro@us.ibm.com", "baveja@umich.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287545937, "id": "ICLR.cc/2017/conference/-/paper510/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJ0-tY5xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper510/reviewers", "ICLR.cc/2017/conference/paper510/areachairs"], "cdate": 1485287545937}}}, {"tddate": null, "tmdate": 1478554146252, "tcdate": 1478551277643, "number": 1, "id": "r1Ugwv0xx", "invitation": "ICLR.cc/2017/conference/-/paper510/public/comment", "forum": "rJ0-tY5xe", "replyto": "rJ0-tY5xe", "signatures": ["~Tara_N_Sainath1"], "readers": ["everyone"], "writers": ["~Tara_N_Sainath1"], "content": {"title": "ICLR Paper Format", "comment": "Dear Authors,\n\nPlease resubmit your paper in the ICLR 2017 format with the correct font for your submission to be considered. Thank you!\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learning to Query, Reason, and Answer Questions On Ambiguous Texts", "abstract": "A key goal of research in conversational systems is to train an interactive agent to help a user with a task. Human conversation, however, is notoriously incomplete, ambiguous, and full of extraneous detail. To operate effectively, the agent must not only understand what was explicitly conveyed but also be able to reason in the presence of missing or unclear information. When unable to resolve ambiguities on its own, the agent must be able to ask the user for the necessary clarifications and incorporate the response in its reasoning. Motivated by this problem we introduce QRAQ (\"crack\"; Query, Reason, and Answer Questions), a new synthetic domain, in which a User gives an Agent a short story and asks a challenge question. These problems are designed to test the reasoning and interaction capabilities of a learning-based Agent in a setting that requires multiple conversational turns. A good Agent should ask only non-deducible, relevant questions until it has enough information to correctly answer the User's question. We use standard and improved reinforcement learning based memory-network architectures to solve QRAQ problems in the difficult setting where the reward signal only tells the Agent if its final answer to the challenge question is correct or not. To provide an upper-bound to the RL results we also train the same architectures using supervised information that tells the Agent during training which variables to query and the answer to the challenge question. We evaluate our architectures on four QRAQ dataset types, and scale the complexity for each along multiple dimensions.", "pdf": "/pdf/f3e3beec28f8af589ab294b451dacd73e524b4f5.pdf", "TL;DR": "A new dataset QRAQ of ambiguous stories in which an Agent must learn to reason and interact with a User to obtain important missing information needed to answer a challenge question.", "paperhash": "guo|learning_to_query_reason_and_answer_questions_on_ambiguous_texts", "keywords": ["Natural language processing", "Deep learning", "Reinforcement Learning"], "conflicts": ["cs.umich.edu", "ibm.com", "cs.umass.edu"], "authors": ["Xiaoxiao Guo", "Tim Klinger", "Clemens Rosenbaum", "Joseph P. Bigus", "Murray Campbell", "Ban Kawas", "Kartik Talamadupula", "Gerry Tesauro", "Satinder   Singh"], "authorids": ["tklinger@us.ibm.com", "guoxiao@umich.edu", "cgbr@cs.umass.edu", "jbigus@us.ibm.com", "mcam@us.ibm.com", "bkawas@us.ibm.com", "krtalamad@us.ibm.com", "gtesauro@us.ibm.com", "baveja@umich.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287545937, "id": "ICLR.cc/2017/conference/-/paper510/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "rJ0-tY5xe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper510/reviewers", "ICLR.cc/2017/conference/paper510/areachairs"], "cdate": 1485287545937}}}], "count": 15}