{"notes": [{"id": "SkGy6hjvPE", "original": "B1gJphoDPV", "number": 13, "cdate": 1552559287447, "ddate": null, "tcdate": 1552559287447, "tmdate": 1562082108533, "tddate": null, "forum": "SkGy6hjvPE", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "Disentangling Factors of Variations Using Few Labels", "authors": ["Francesco Locatello", "Michael Tschannen", "Stefan Bauer", "Gunnar R\u00a8\u00a8\u00e4tsch", "Bernhard Sch\u00f6lkopf", "Olivier Bachem"], "authorids": ["flocatello@tuebingen.mpg.de", "michaelt@nari.ee.ethz.ch", "stefan.bauer@tuebingen.mpg.de", "raetsch@inf.ethz.ch", "bs@tuebingen.mpg.de", "bachem@google.com"], "keywords": [], "abstract": "Learning disentangled representations is considered a promising research direction in representation learning. Recently, Locatello et al. (2018) demonstrated that the unsupervised learning of disentangled representations is theoretically impossible and that state-of-the-art methods, which are often unsupervised, require access to annotated examples to select good model runs. Yet, if we assume access to labels for model selection, it is not clear why we should not use them directly for training. In this paper, we first show that model selection using few labels is feasible. Then, as a proof-of-concept, we consider a simple semi-supervised method that directly uses the labels for training. We train more than 7000 models and empirically validate that collecting a handful of potentially noisy labels is sufficient to learn disentangled representations.", "pdf": "/pdf/d018b972b7d8c47f0cb552ab9934fed46f1533c0.pdf", "paperhash": "locatello|disentangling_factors_of_variations_using_few_labels"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "ICLR.cc/2019/Workshop/LLD"}, {"id": "H1gboOnDtE", "original": null, "number": 1, "cdate": 1554659480927, "ddate": null, "tcdate": 1554659480927, "tmdate": 1555512018210, "tddate": null, "forum": "SkGy6hjvPE", "replyto": "SkGy6hjvPE", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper13/Official_Review", "content": {"title": "Interesting observation and proof-of-concept", "review": "The authors of this work consider the problem of learning disentangled representations. They observe that if labeled data are used for model selection, than using them for training can lead to interesting results. They propose to regularize beta-VAE with a cross entropy loss for a small portion of labeled data, and show improvement on the models that use labeled data only for model selection. The experimental results indeed validate the authors hypothesis and show that even a small set of partially of noisily labeled data can have an interesting impact on the training.\n\nThe observation and initial results are interesting, and the work is wort to be discussed in this workshop.", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper13/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper13/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Disentangling Factors of Variations Using Few Labels", "authors": ["Francesco Locatello", "Michael Tschannen", "Stefan Bauer", "Gunnar R\u00a8\u00a8\u00e4tsch", "Bernhard Sch\u00f6lkopf", "Olivier Bachem"], "authorids": ["flocatello@tuebingen.mpg.de", "michaelt@nari.ee.ethz.ch", "stefan.bauer@tuebingen.mpg.de", "raetsch@inf.ethz.ch", "bs@tuebingen.mpg.de", "bachem@google.com"], "keywords": [], "abstract": "Learning disentangled representations is considered a promising research direction in representation learning. Recently, Locatello et al. (2018) demonstrated that the unsupervised learning of disentangled representations is theoretically impossible and that state-of-the-art methods, which are often unsupervised, require access to annotated examples to select good model runs. Yet, if we assume access to labels for model selection, it is not clear why we should not use them directly for training. In this paper, we first show that model selection using few labels is feasible. Then, as a proof-of-concept, we consider a simple semi-supervised method that directly uses the labels for training. We train more than 7000 models and empirically validate that collecting a handful of potentially noisy labels is sufficient to learn disentangled representations.", "pdf": "/pdf/d018b972b7d8c47f0cb552ab9934fed46f1533c0.pdf", "paperhash": "locatello|disentangling_factors_of_variations_using_few_labels"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper13/Official_Review", "cdate": 1553713420289, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "SkGy6hjvPE", "replyto": "SkGy6hjvPE", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper13/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper13/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713420289, "tmdate": 1555511818054, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper13/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "ryxgDPLFF4", "original": null, "number": 2, "cdate": 1554765655778, "ddate": null, "tcdate": 1554765655778, "tmdate": 1555511881652, "tddate": null, "forum": "SkGy6hjvPE", "replyto": "SkGy6hjvPE", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper13/Official_Review", "content": {"title": "Semisupervised learning by introducing observed labels in unsupervised learning methods yields non trivial results for few labels", "review": "The papers propose a model in which some of the latent variables of an unsupervised model are associated with a small number of user defined labels. This increases the discriminativity of the model and enable it to separate factors of variation associated with those labels. \nThe introduction of the new term in the objective essentially places the model withing the domain of supervised models (or at least semisupervised). However, all the numerical test appear to be against unsupervised models. Improvement by those standards seems trivial to me. I would urge the authors to include comparisons against other semisupervised methods that work on similar numbers of labeled data", "rating": "3: Marginally above acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper13/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper13/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Disentangling Factors of Variations Using Few Labels", "authors": ["Francesco Locatello", "Michael Tschannen", "Stefan Bauer", "Gunnar R\u00a8\u00a8\u00e4tsch", "Bernhard Sch\u00f6lkopf", "Olivier Bachem"], "authorids": ["flocatello@tuebingen.mpg.de", "michaelt@nari.ee.ethz.ch", "stefan.bauer@tuebingen.mpg.de", "raetsch@inf.ethz.ch", "bs@tuebingen.mpg.de", "bachem@google.com"], "keywords": [], "abstract": "Learning disentangled representations is considered a promising research direction in representation learning. Recently, Locatello et al. (2018) demonstrated that the unsupervised learning of disentangled representations is theoretically impossible and that state-of-the-art methods, which are often unsupervised, require access to annotated examples to select good model runs. Yet, if we assume access to labels for model selection, it is not clear why we should not use them directly for training. In this paper, we first show that model selection using few labels is feasible. Then, as a proof-of-concept, we consider a simple semi-supervised method that directly uses the labels for training. We train more than 7000 models and empirically validate that collecting a handful of potentially noisy labels is sufficient to learn disentangled representations.", "pdf": "/pdf/d018b972b7d8c47f0cb552ab9934fed46f1533c0.pdf", "paperhash": "locatello|disentangling_factors_of_variations_using_few_labels"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper13/Official_Review", "cdate": 1553713420289, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "SkGy6hjvPE", "replyto": "SkGy6hjvPE", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper13/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper13/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713420289, "tmdate": 1555511818054, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper13/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "r1lcX2nz94", "original": null, "number": 1, "cdate": 1555381282027, "ddate": null, "tcdate": 1555381282027, "tmdate": 1555510978349, "tddate": null, "forum": "SkGy6hjvPE", "replyto": "SkGy6hjvPE", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper13/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Disentangling Factors of Variations Using Few Labels", "authors": ["Francesco Locatello", "Michael Tschannen", "Stefan Bauer", "Gunnar R\u00a8\u00a8\u00e4tsch", "Bernhard Sch\u00f6lkopf", "Olivier Bachem"], "authorids": ["flocatello@tuebingen.mpg.de", "michaelt@nari.ee.ethz.ch", "stefan.bauer@tuebingen.mpg.de", "raetsch@inf.ethz.ch", "bs@tuebingen.mpg.de", "bachem@google.com"], "keywords": [], "abstract": "Learning disentangled representations is considered a promising research direction in representation learning. Recently, Locatello et al. (2018) demonstrated that the unsupervised learning of disentangled representations is theoretically impossible and that state-of-the-art methods, which are often unsupervised, require access to annotated examples to select good model runs. Yet, if we assume access to labels for model selection, it is not clear why we should not use them directly for training. In this paper, we first show that model selection using few labels is feasible. Then, as a proof-of-concept, we consider a simple semi-supervised method that directly uses the labels for training. We train more than 7000 models and empirically validate that collecting a handful of potentially noisy labels is sufficient to learn disentangled representations.", "pdf": "/pdf/d018b972b7d8c47f0cb552ab9934fed46f1533c0.pdf", "paperhash": "locatello|disentangling_factors_of_variations_using_few_labels"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper13/Decision", "cdate": 1554736069235, "reply": {"forum": "SkGy6hjvPE", "replyto": "SkGy6hjvPE", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736069235, "tmdate": 1555510969459, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 4}