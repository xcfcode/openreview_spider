{"notes": [{"id": "ByeqyxBKvS", "original": "HklMxokKwB", "number": 2071, "cdate": 1569439713570, "ddate": null, "tcdate": 1569439713570, "tmdate": 1577168282451, "tddate": null, "forum": "ByeqyxBKvS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Quantum Semi-Supervised Kernel Learning", "authors": ["Seyran Saeedi", "Aliakbar Panahi", "Tom Arodz"], "authorids": ["saeedis@vcu.edu", "panahia@vcu.edu", "tarodz@vcu.edu"], "keywords": ["quantum machine learning", "semi-supervised learning", "support vector machines"], "TL;DR": "We extend quantum SVMs to semi-supervised setting, to deal with the likely problem of many missing class labels in huge datasets.", "abstract": "Quantum machine learning methods have the potential to facilitate learning using extremely large datasets. While the availability of data for training machine learning models is steadily increasing, oftentimes it is much easier to collect feature vectors that to obtain the corresponding labels. One of the approaches for addressing this issue is to use semi-supervised learning, which leverages not only the labeled samples, but also unlabeled feature vectors. Here, we present a quantum machine learning algorithm for training Semi-Supervised Kernel Support Vector Machines. The algorithm uses recent advances in quantum sample-based Hamiltonian simulation to extend the existing Quantum LS-SVM algorithm to handle the semi-supervised term in the loss, while maintaining the same quantum speedup as the Quantum LS-SVM.", "pdf": "/pdf/aa9656e2876a9f29763607469789faa5f5c0e92c.pdf", "paperhash": "saeedi|quantum_semisupervised_kernel_learning", "original_pdf": "/attachment/2874d2eaa0d5a2685c2d25180491ae799aa61a14.pdf", "_bibtex": "@misc{\nsaeedi2020quantum,\ntitle={Quantum Semi-Supervised Kernel Learning},\nauthor={Seyran Saeedi and Aliakbar Panahi and Tom Arodz},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeqyxBKvS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "kM1GckIAm5", "original": null, "number": 1, "cdate": 1576798739764, "ddate": null, "tcdate": 1576798739764, "tmdate": 1576800896513, "tddate": null, "forum": "ByeqyxBKvS", "replyto": "ByeqyxBKvS", "invitation": "ICLR.cc/2020/Conference/Paper2071/-/Decision", "content": {"decision": "Reject", "comment": "Three reviewers have assessed this paper and they have scored it 6/6/6 after rebuttal with one reviewer hesitating about the appropriateness of this submission to ML venues. The reviewers have raised a number of criticisms such as an incremental nature of the paper (HHL and LMR algorithms) and the main contributions lying more within the field of quantum computing than ML. The paper was discussed with reviewers, buddy AC and chairs. On balance, it was concluded that this paper is minimally below the acceptance threshold. We encourage authors to consider all criticism, improve the paper and resubmit to another venue as there is some merit to the proposed idea.\n", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Quantum Semi-Supervised Kernel Learning", "authors": ["Seyran Saeedi", "Aliakbar Panahi", "Tom Arodz"], "authorids": ["saeedis@vcu.edu", "panahia@vcu.edu", "tarodz@vcu.edu"], "keywords": ["quantum machine learning", "semi-supervised learning", "support vector machines"], "TL;DR": "We extend quantum SVMs to semi-supervised setting, to deal with the likely problem of many missing class labels in huge datasets.", "abstract": "Quantum machine learning methods have the potential to facilitate learning using extremely large datasets. While the availability of data for training machine learning models is steadily increasing, oftentimes it is much easier to collect feature vectors that to obtain the corresponding labels. One of the approaches for addressing this issue is to use semi-supervised learning, which leverages not only the labeled samples, but also unlabeled feature vectors. Here, we present a quantum machine learning algorithm for training Semi-Supervised Kernel Support Vector Machines. The algorithm uses recent advances in quantum sample-based Hamiltonian simulation to extend the existing Quantum LS-SVM algorithm to handle the semi-supervised term in the loss, while maintaining the same quantum speedup as the Quantum LS-SVM.", "pdf": "/pdf/aa9656e2876a9f29763607469789faa5f5c0e92c.pdf", "paperhash": "saeedi|quantum_semisupervised_kernel_learning", "original_pdf": "/attachment/2874d2eaa0d5a2685c2d25180491ae799aa61a14.pdf", "_bibtex": "@misc{\nsaeedi2020quantum,\ntitle={Quantum Semi-Supervised Kernel Learning},\nauthor={Seyran Saeedi and Aliakbar Panahi and Tom Arodz},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeqyxBKvS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "ByeqyxBKvS", "replyto": "ByeqyxBKvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795708567, "tmdate": 1576800257037, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2071/-/Decision"}}}, {"id": "HJxO2en0tH", "original": null, "number": 1, "cdate": 1571893424436, "ddate": null, "tcdate": 1571893424436, "tmdate": 1574812071220, "tddate": null, "forum": "ByeqyxBKvS", "replyto": "ByeqyxBKvS", "invitation": "ICLR.cc/2020/Conference/Paper2071/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "N/A", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #3", "review": "This paper proposes to extend a quantum-computing based solution of least-squares support-vector-machine to include use of unlabeled samples.  The formulation is analogous to the classical-computing case, in which semi-supervised learning introduces an additional term in the system of equations, which the authors show how to compute in the quantum setting without degrading big-O complexity.\n\nI would lean toward rejecting this paper,  primarily on account of how the contribution relates to the publication venue.  The primary contribution lies in the procedure for preparing and propagating the quantum mechanical states needed to compute on the additional term.  Although the application is machine learning, the technique itself is still rather afar from this topic and would not appear to be of general benefit to conference-goers outside of quantum computing.  The overwhelming majority of quantum machine learning references in this paper appear in physics journals (all but one, which was ICML 2019).  Most of this paper is background material, which yet remains inadequate to convey insights into design decisions in the details of their main contribution, the derivations in section 3.2.  (I have a background in physics but not quantum computing.)   \n\nPerhaps a paper organization more amenable to this venue would be to shift some of the lengthier equations into an appendix and use the space of the paper to discuss a more conceptual and contextual understanding of why this technique is desirable, at each step, relative to other possible quantum techniques.  For example, Figure 1 is not explained, and is not decipherable to someone outside the field, so doesn't itself add to the story.\n\nCould be really good work, but the presentation doesn't quite come across.\n\n\nEDIT:  See comments to do with paper revision, which significantly improved the presentation.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper2071/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2071/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Quantum Semi-Supervised Kernel Learning", "authors": ["Seyran Saeedi", "Aliakbar Panahi", "Tom Arodz"], "authorids": ["saeedis@vcu.edu", "panahia@vcu.edu", "tarodz@vcu.edu"], "keywords": ["quantum machine learning", "semi-supervised learning", "support vector machines"], "TL;DR": "We extend quantum SVMs to semi-supervised setting, to deal with the likely problem of many missing class labels in huge datasets.", "abstract": "Quantum machine learning methods have the potential to facilitate learning using extremely large datasets. While the availability of data for training machine learning models is steadily increasing, oftentimes it is much easier to collect feature vectors that to obtain the corresponding labels. One of the approaches for addressing this issue is to use semi-supervised learning, which leverages not only the labeled samples, but also unlabeled feature vectors. Here, we present a quantum machine learning algorithm for training Semi-Supervised Kernel Support Vector Machines. The algorithm uses recent advances in quantum sample-based Hamiltonian simulation to extend the existing Quantum LS-SVM algorithm to handle the semi-supervised term in the loss, while maintaining the same quantum speedup as the Quantum LS-SVM.", "pdf": "/pdf/aa9656e2876a9f29763607469789faa5f5c0e92c.pdf", "paperhash": "saeedi|quantum_semisupervised_kernel_learning", "original_pdf": "/attachment/2874d2eaa0d5a2685c2d25180491ae799aa61a14.pdf", "_bibtex": "@misc{\nsaeedi2020quantum,\ntitle={Quantum Semi-Supervised Kernel Learning},\nauthor={Seyran Saeedi and Aliakbar Panahi and Tom Arodz},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeqyxBKvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ByeqyxBKvS", "replyto": "ByeqyxBKvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2071/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2071/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575736306535, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2071/Reviewers"], "noninvitees": [], "tcdate": 1570237728108, "tmdate": 1575736306548, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2071/-/Official_Review"}}}, {"id": "HkxAav4nor", "original": null, "number": 3, "cdate": 1573828549801, "ddate": null, "tcdate": 1573828549801, "tmdate": 1573828549801, "tddate": null, "forum": "ByeqyxBKvS", "replyto": "HJxO2en0tH", "invitation": "ICLR.cc/2020/Conference/Paper2071/-/Official_Comment", "content": {"title": "Response", "comment": "Thank you for your insightful comment! \n\nIndeed, quantum machine learning papers traditionally emerged from the physics community. However, we can currently observe beginnings of a trend of publishing QML papers at traditional ML conferences (the ICML paper we mentioned, a NeurIPS\u201919 paper on q-means by Kerenidis et al.), indicating there is an increasing emerging audience, providing potential for shifting the focus in QML to more advanced methods from the classical ML repertoire. We hope that more machine learning experts take note of recent developments in quantum computing that focus on continuous problems instead of discrete problems like search algorithms or factoring. The techniques we use in our paper are based on one such development, the introduction of quantum linear algebra tools involving density matrices. \n\nTo make our paper more accessible to the machine learning community, we have expanded \"Quantum Linear Systems of Equations\" paragraph to include explanation of basics of HHL using classical linear algebra notation and the \"LMR Technique for Density Operator Exponentiation\" paragraph to provide more details on this fundamental technique in quantum linear algebra. We have also expanded Section 3.2 to provide more intuition behind the proposed approach for solving the semi-supervised SVM using generalized LMR technique.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper2071/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2071/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Quantum Semi-Supervised Kernel Learning", "authors": ["Seyran Saeedi", "Aliakbar Panahi", "Tom Arodz"], "authorids": ["saeedis@vcu.edu", "panahia@vcu.edu", "tarodz@vcu.edu"], "keywords": ["quantum machine learning", "semi-supervised learning", "support vector machines"], "TL;DR": "We extend quantum SVMs to semi-supervised setting, to deal with the likely problem of many missing class labels in huge datasets.", "abstract": "Quantum machine learning methods have the potential to facilitate learning using extremely large datasets. While the availability of data for training machine learning models is steadily increasing, oftentimes it is much easier to collect feature vectors that to obtain the corresponding labels. One of the approaches for addressing this issue is to use semi-supervised learning, which leverages not only the labeled samples, but also unlabeled feature vectors. Here, we present a quantum machine learning algorithm for training Semi-Supervised Kernel Support Vector Machines. The algorithm uses recent advances in quantum sample-based Hamiltonian simulation to extend the existing Quantum LS-SVM algorithm to handle the semi-supervised term in the loss, while maintaining the same quantum speedup as the Quantum LS-SVM.", "pdf": "/pdf/aa9656e2876a9f29763607469789faa5f5c0e92c.pdf", "paperhash": "saeedi|quantum_semisupervised_kernel_learning", "original_pdf": "/attachment/2874d2eaa0d5a2685c2d25180491ae799aa61a14.pdf", "_bibtex": "@misc{\nsaeedi2020quantum,\ntitle={Quantum Semi-Supervised Kernel Learning},\nauthor={Seyran Saeedi and Aliakbar Panahi and Tom Arodz},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeqyxBKvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByeqyxBKvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2071/Authors", "ICLR.cc/2020/Conference/Paper2071/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2071/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2071/Reviewers", "ICLR.cc/2020/Conference/Paper2071/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2071/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2071/Authors|ICLR.cc/2020/Conference/Paper2071/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504146755, "tmdate": 1576860534498, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2071/Authors", "ICLR.cc/2020/Conference/Paper2071/Reviewers", "ICLR.cc/2020/Conference/Paper2071/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2071/-/Official_Comment"}}}, {"id": "rkehDQNhjS", "original": null, "number": 2, "cdate": 1573827427648, "ddate": null, "tcdate": 1573827427648, "tmdate": 1573827427648, "tddate": null, "forum": "ByeqyxBKvS", "replyto": "rJedR_MxqS", "invitation": "ICLR.cc/2020/Conference/Paper2071/-/Official_Comment", "content": {"title": "Response", "comment": "Thank you for your comments and suggestions!\n\nWe have eliminated introductory material on RKHS, and instead expanded:\n-  Section 2.2 paragraph \"Quantum Linear Systems of Equations\" to offer more insight into the HHL algorithm that underpins the original quantum SVM and our semi-supervised quantum SVM\n- Section 2.2 paragraph \"LMR Technique for Density Operator Exponentiation\" with the method that is used in HHL to work with density matrices such as the kernel matrix\n- Section 3.2, the main contribution of the manuscript.\nWe aimed to make these more accessible to the machine learning community."}, "signatures": ["ICLR.cc/2020/Conference/Paper2071/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2071/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Quantum Semi-Supervised Kernel Learning", "authors": ["Seyran Saeedi", "Aliakbar Panahi", "Tom Arodz"], "authorids": ["saeedis@vcu.edu", "panahia@vcu.edu", "tarodz@vcu.edu"], "keywords": ["quantum machine learning", "semi-supervised learning", "support vector machines"], "TL;DR": "We extend quantum SVMs to semi-supervised setting, to deal with the likely problem of many missing class labels in huge datasets.", "abstract": "Quantum machine learning methods have the potential to facilitate learning using extremely large datasets. While the availability of data for training machine learning models is steadily increasing, oftentimes it is much easier to collect feature vectors that to obtain the corresponding labels. One of the approaches for addressing this issue is to use semi-supervised learning, which leverages not only the labeled samples, but also unlabeled feature vectors. Here, we present a quantum machine learning algorithm for training Semi-Supervised Kernel Support Vector Machines. The algorithm uses recent advances in quantum sample-based Hamiltonian simulation to extend the existing Quantum LS-SVM algorithm to handle the semi-supervised term in the loss, while maintaining the same quantum speedup as the Quantum LS-SVM.", "pdf": "/pdf/aa9656e2876a9f29763607469789faa5f5c0e92c.pdf", "paperhash": "saeedi|quantum_semisupervised_kernel_learning", "original_pdf": "/attachment/2874d2eaa0d5a2685c2d25180491ae799aa61a14.pdf", "_bibtex": "@misc{\nsaeedi2020quantum,\ntitle={Quantum Semi-Supervised Kernel Learning},\nauthor={Seyran Saeedi and Aliakbar Panahi and Tom Arodz},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeqyxBKvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByeqyxBKvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2071/Authors", "ICLR.cc/2020/Conference/Paper2071/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2071/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2071/Reviewers", "ICLR.cc/2020/Conference/Paper2071/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2071/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2071/Authors|ICLR.cc/2020/Conference/Paper2071/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504146755, "tmdate": 1576860534498, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2071/Authors", "ICLR.cc/2020/Conference/Paper2071/Reviewers", "ICLR.cc/2020/Conference/Paper2071/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2071/-/Official_Comment"}}}, {"id": "SJeQlM42iS", "original": null, "number": 1, "cdate": 1573827051274, "ddate": null, "tcdate": 1573827051274, "tmdate": 1573827051274, "tddate": null, "forum": "ByeqyxBKvS", "replyto": "BJxnkesP5H", "invitation": "ICLR.cc/2020/Conference/Paper2071/-/Official_Comment", "content": {"title": "Response", "comment": "Thank you for the review and comments!\n\n>> Minor issues: Can any experimental study or applications be demonstrated, or only theoretical computational complexity can be compared? \n\nCurrently, in the absence of large-scale universal quantum computers, quantum speedups for quantum machine learning algorithms are distinguished using complexity theory measures. While there are simulators such as cirq and quiskit, we have not seen them being used in quantum machine learning papers.\n\nBased on our knowledge we introduced the first quantum semi-supervised machine learning algorithm with offering an equivalent computational complexity as quantum LS_SVM algorithm. The quantum LS-SVM in offers exponential speedup $O(\\log mp)$ over the classical time complexity for solving SVM as a quadratic problem, which requires time $O(log(\\epsilon^{-1})poly(p,m))$, where $\\epsilon$ is the desired error.\n\n>> 2. In Section 1.1, L is defined as L = G_I G^T_I. In this definition, whether and how the edge weights are considered? Please clarify. \n\nCurrently, we have not considered edge weights. However, the approach we propose can be extended in a straightforward way by making the incidence matrix G_I contain nonnegative weights instead of 0/1 values, and calculating L in a similar way as calculating kernel matrix over samples, using partial trace."}, "signatures": ["ICLR.cc/2020/Conference/Paper2071/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2071/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Quantum Semi-Supervised Kernel Learning", "authors": ["Seyran Saeedi", "Aliakbar Panahi", "Tom Arodz"], "authorids": ["saeedis@vcu.edu", "panahia@vcu.edu", "tarodz@vcu.edu"], "keywords": ["quantum machine learning", "semi-supervised learning", "support vector machines"], "TL;DR": "We extend quantum SVMs to semi-supervised setting, to deal with the likely problem of many missing class labels in huge datasets.", "abstract": "Quantum machine learning methods have the potential to facilitate learning using extremely large datasets. While the availability of data for training machine learning models is steadily increasing, oftentimes it is much easier to collect feature vectors that to obtain the corresponding labels. One of the approaches for addressing this issue is to use semi-supervised learning, which leverages not only the labeled samples, but also unlabeled feature vectors. Here, we present a quantum machine learning algorithm for training Semi-Supervised Kernel Support Vector Machines. The algorithm uses recent advances in quantum sample-based Hamiltonian simulation to extend the existing Quantum LS-SVM algorithm to handle the semi-supervised term in the loss, while maintaining the same quantum speedup as the Quantum LS-SVM.", "pdf": "/pdf/aa9656e2876a9f29763607469789faa5f5c0e92c.pdf", "paperhash": "saeedi|quantum_semisupervised_kernel_learning", "original_pdf": "/attachment/2874d2eaa0d5a2685c2d25180491ae799aa61a14.pdf", "_bibtex": "@misc{\nsaeedi2020quantum,\ntitle={Quantum Semi-Supervised Kernel Learning},\nauthor={Seyran Saeedi and Aliakbar Panahi and Tom Arodz},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeqyxBKvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ByeqyxBKvS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper2071/Authors", "ICLR.cc/2020/Conference/Paper2071/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper2071/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper2071/Reviewers", "ICLR.cc/2020/Conference/Paper2071/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper2071/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper2071/Authors|ICLR.cc/2020/Conference/Paper2071/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504146755, "tmdate": 1576860534498, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper2071/Authors", "ICLR.cc/2020/Conference/Paper2071/Reviewers", "ICLR.cc/2020/Conference/Paper2071/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper2071/-/Official_Comment"}}}, {"id": "rJedR_MxqS", "original": null, "number": 2, "cdate": 1571985616322, "ddate": null, "tcdate": 1571985616322, "tmdate": 1572972386784, "tddate": null, "forum": "ByeqyxBKvS", "replyto": "ByeqyxBKvS", "invitation": "ICLR.cc/2020/Conference/Paper2071/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "N/A", "review_assessment:_checking_correctness_of_experiments": "N/A", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper proposes a quantum computer-based algorithm for semi-supervised least squared kernel SVM. This work builds upon LS-SVM of Rebentrost et al (2014b) which developed a quantum algorithm for the supervised version of the problem. While the main selling point of quantum LS-SVM is that it scales logarithmically with data size, supervised algorithms shall not fully enjoy logarithmic scaling unless the cost for collecting labeled data is also logarithmic, which is unlikely. Therefore, semi-supervised setting is certainly appealing. Technically, there are two main contributions. The first is the method of providing Laplacian as an input to the quantum computer. The second contribution, which is about the computation of matrix inverse (K + KLK)^{-1}, is a bit more technical, and could be considered as the main contribution of the paper.\n\nMy main concern about the paper is on its organization. The paper provides a very gentle introduction to both semi-supervised LS SVM and quantum LS-SVM. While this helps readers to be equipped with relevant background, it is at the cost of having less space for the main contribution in Section 3.2. I would suggest to remove the content in page 2; most results about kernel methods are not really relevant to this paper. For a machine learning conference paper, one shall safely start with half-page intro in page 3. Some background in quantum computing offered in page 3, 4, 5 are quite nice, but for a conference paper, I think this is an overkill. I recommend providing the very minimal content needed to discuss Section 3.2, and then use more space to discuss the idea in 3.2 better. Specifically, Generalized LMR technique and Hermitian polynomials in Kimmel et al. (2017) could be discussed in more detail. "}, "signatures": ["ICLR.cc/2020/Conference/Paper2071/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2071/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Quantum Semi-Supervised Kernel Learning", "authors": ["Seyran Saeedi", "Aliakbar Panahi", "Tom Arodz"], "authorids": ["saeedis@vcu.edu", "panahia@vcu.edu", "tarodz@vcu.edu"], "keywords": ["quantum machine learning", "semi-supervised learning", "support vector machines"], "TL;DR": "We extend quantum SVMs to semi-supervised setting, to deal with the likely problem of many missing class labels in huge datasets.", "abstract": "Quantum machine learning methods have the potential to facilitate learning using extremely large datasets. While the availability of data for training machine learning models is steadily increasing, oftentimes it is much easier to collect feature vectors that to obtain the corresponding labels. One of the approaches for addressing this issue is to use semi-supervised learning, which leverages not only the labeled samples, but also unlabeled feature vectors. Here, we present a quantum machine learning algorithm for training Semi-Supervised Kernel Support Vector Machines. The algorithm uses recent advances in quantum sample-based Hamiltonian simulation to extend the existing Quantum LS-SVM algorithm to handle the semi-supervised term in the loss, while maintaining the same quantum speedup as the Quantum LS-SVM.", "pdf": "/pdf/aa9656e2876a9f29763607469789faa5f5c0e92c.pdf", "paperhash": "saeedi|quantum_semisupervised_kernel_learning", "original_pdf": "/attachment/2874d2eaa0d5a2685c2d25180491ae799aa61a14.pdf", "_bibtex": "@misc{\nsaeedi2020quantum,\ntitle={Quantum Semi-Supervised Kernel Learning},\nauthor={Seyran Saeedi and Aliakbar Panahi and Tom Arodz},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeqyxBKvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ByeqyxBKvS", "replyto": "ByeqyxBKvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2071/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2071/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575736306535, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2071/Reviewers"], "noninvitees": [], "tcdate": 1570237728108, "tmdate": 1575736306548, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2071/-/Official_Review"}}}, {"id": "BJxnkesP5H", "original": null, "number": 3, "cdate": 1572478947700, "ddate": null, "tcdate": 1572478947700, "tmdate": 1572972386674, "tddate": null, "forum": "ByeqyxBKvS", "replyto": "ByeqyxBKvS", "invitation": "ICLR.cc/2020/Conference/Paper2071/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "N/A", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper developes a quantum algorithm for kernel-based support vector machine working in a semi-supervised learning setting. The motivation is to utilise the significant advantage of quantum computation to train machine learning models on large-scale datasets efficiently. This paper reviews the existing work on using quantum computing for least-squares svm (via solving quantum linear systems of equations) and then extends it to deal with kernel svm in a semi-supervised setting. \n\nStrengths: This is an interesting emerging research topic that has its significance. Also, this paper prodives a nice tutorial on the key ideas of quantum machine learning and provides detailed derivations and analysis on the proposed algorithm.\n\nWeaknesses: The novelty of this work seems to be incremental. It largely extends the existing algorithms such as HHL and LMR. \n\nMinor issues:\n\n1. Can any experimental study or applications be demonstrated, or only theoretical comptuational complexity can be compared? \n2. In Section 1.1, L is defined as L = G_I G^T_I. In this definition, whether and how the edge weights are considered? Please clarify.   "}, "signatures": ["ICLR.cc/2020/Conference/Paper2071/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper2071/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Quantum Semi-Supervised Kernel Learning", "authors": ["Seyran Saeedi", "Aliakbar Panahi", "Tom Arodz"], "authorids": ["saeedis@vcu.edu", "panahia@vcu.edu", "tarodz@vcu.edu"], "keywords": ["quantum machine learning", "semi-supervised learning", "support vector machines"], "TL;DR": "We extend quantum SVMs to semi-supervised setting, to deal with the likely problem of many missing class labels in huge datasets.", "abstract": "Quantum machine learning methods have the potential to facilitate learning using extremely large datasets. While the availability of data for training machine learning models is steadily increasing, oftentimes it is much easier to collect feature vectors that to obtain the corresponding labels. One of the approaches for addressing this issue is to use semi-supervised learning, which leverages not only the labeled samples, but also unlabeled feature vectors. Here, we present a quantum machine learning algorithm for training Semi-Supervised Kernel Support Vector Machines. The algorithm uses recent advances in quantum sample-based Hamiltonian simulation to extend the existing Quantum LS-SVM algorithm to handle the semi-supervised term in the loss, while maintaining the same quantum speedup as the Quantum LS-SVM.", "pdf": "/pdf/aa9656e2876a9f29763607469789faa5f5c0e92c.pdf", "paperhash": "saeedi|quantum_semisupervised_kernel_learning", "original_pdf": "/attachment/2874d2eaa0d5a2685c2d25180491ae799aa61a14.pdf", "_bibtex": "@misc{\nsaeedi2020quantum,\ntitle={Quantum Semi-Supervised Kernel Learning},\nauthor={Seyran Saeedi and Aliakbar Panahi and Tom Arodz},\nyear={2020},\nurl={https://openreview.net/forum?id=ByeqyxBKvS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ByeqyxBKvS", "replyto": "ByeqyxBKvS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper2071/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper2071/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575736306535, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper2071/Reviewers"], "noninvitees": [], "tcdate": 1570237728108, "tmdate": 1575736306548, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper2071/-/Official_Review"}}}], "count": 8}