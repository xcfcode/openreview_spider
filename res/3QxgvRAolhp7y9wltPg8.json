{"notes": [{"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1457966679992, "tcdate": 1457966679992, "id": "3Qx4ngyL0cp7y9wltPvM", "invitation": "ICLR.cc/2016/workshop/-/paper/82/comment", "forum": "3QxgvRAolhp7y9wltPg8", "replyto": "BNYVDXoYzt7PwR1riX1N", "signatures": ["~Pengcheng_Yin1"], "readers": ["everyone"], "writers": ["~Pengcheng_Yin1"], "content": {"title": "Response to Reviewer 12", "comment": "Thank you for your insightful comments!\n\nDue to the limited space we cannot cover all the details in the extended abstract. \n\nFirst of all, we would like to remark that Neural Enquirer is targeting natural language (NL) question answering on tables. We provide SQL-like logical forms in the paper just to illustrate the semantics and complexity of our synthetic NL questions, and those logical forms are unknown by the model.\n\n+ [Why synthetic dataset]\n* Our contribution is to explore the capabilities of an end-to-end, fully-neural system in natural language semantic parsing and symbolic query execution.  As the first step, we focus on the algorithmic foundation of such an approach and conduct experiments on synthetic data as a proof-of-concept, which is a common practice adopted by previous works on neural-network-based table QA [Neelakantan et al., 2015]. \n\nIn our synthetic QA task, each of the 10 predicates has 3~4 NL patterns, whose combination yields reasonable coverages on representative types of questions that can be generated from the Olympic Games schema. We will release our dataset for future research.\n\nAdditionally, since Neural Enquirer learns symbolic operations from training data, it requires a large training dataset. WikiTableQuestions has only 14K training examples, which is relatively small for our purpose. We are carrying out experiments on WikiTableQuestions and are getting promising results.\n\n+ [Comparison with SEMPRE]\n* We train/evaluate SEMPRE using the official system and tuning scripts used in [Pasupat and Liang, 2015] (https://worksheets.codalab.org/worksheets/0xf26cd79d4d734287868923ad1067cf4c/), which is shipped with all the grammar/features and has been optimized by the authors for table QA scenario. This might be different with the official SEMPRE framework (https://github.com/percyliang/sempre).\n\nWe find SEMPRE generates too many candidate logical forms for complex NL queries like WHERE_SUPERLATIVE and NEST, which makes it difficult to identify the correct ones and rank them to the top. This might be due to the intractable search space incurred by the flexibility of the float parsing algorithm. We show that SEMPRE handles simple queries as well as Neural Enquirer, but our model excels in answering complex queries. \n\n+ [Why end-to-end neural network training]\n* We are especially interested in the capabilities of a neural system in learning symbolic operations without a formal specification in an end-to-end, data-driven fashion. Our experiments on a synthetic dataset demonstrate that Neural Enquirer is capable of learning to execute compositional NL queries up to a fairly high level of complexity.\n\n+ [Which queries can be handled by the approach and which cannot]\n* Neural Enquirer learns to execute queries purely in a data driven approach, and could answer a large variety of NL questions involving compositional \u201cselect/where/argmax/argmin\u201d operations. But our current implementation cannot handle arithmetical queries like \u201cwhat is the SUM of all numbers of participants\u201d, which we leave as future work.\n\n+ [Misc]\n* We will revise some of the claims we made and add more related works/references. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Neural Enquirer: Learning to Query Tables in Natural Language", "abstract": "We propose Neural Enquirer \u2014 a neural network architecture for answering natural language (NL) questions given a knowledge base (KB) table. Unlike previous work on end-to-end training of semantic parsers, Neural Enquirer is fully \u201cneuralized\u201d: it gives distributed representations of queries and KB tables, and executes queries through a series of differentiable operations. The model can be trained with gradient descent using both end-to-end and step-by-step supervision. During training the representations of queries and the KB table are jointly optimized with the query execution logic. Our experiments show that the model can learn to execute complex NL queries on KB tables with rich structures.", "pdf": "/pdf/3QxgvRAolhp7y9wltPg8.pdf", "paperhash": "yin|neural_enquirer_learning_to_query_tables_in_natural_language", "conflicts": ["cs.hku.hk", "huawei.com"], "authors": ["Pengcheng Yin", "Zhengdong Lu", "Hang Li", "Ben Kao"], "authorids": ["pcyin@cs.hku.hk", "Lu.Zhengdong@huawei.com", "HangLi.HL@huawei.com", "kao@cs.hku.hk"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "tmdate": null, "cdate": 1455783041541, "ddate": null, "super": null, "final": null, "tcdate": 1455783041541, "id": "ICLR.cc/2016/workshop/-/paper/82/comment", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "readers": ["everyone"], "reply": {"pdf": null, "replyto": null, "writers": {"values-regex": "~.*"}, "forum": "3QxgvRAolhp7y9wltPg8", "signatures": {"values-regex": "~.*", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "invitees": ["~", "ICLR.cc/2016/workshop/paper/82/reviewer/10"], "nonreaders": [], "noninvitees": []}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1457677127498, "tcdate": 1457677127498, "id": "BNYVDXoYzt7PwR1riX1N", "invitation": "ICLR.cc/2016/workshop/-/paper/82/review/12", "forum": "3QxgvRAolhp7y9wltPg8", "replyto": "3QxgvRAolhp7y9wltPg8", "signatures": ["ICLR.cc/2016/workshop/paper/82/reviewer/12"], "readers": ["everyone"], "writers": ["ICLR.cc/2016/workshop/paper/82/reviewer/12"], "content": {"title": "This paper presents a neural network architecture that can take in natural language utterances and \"execute\" them to answer questions on tables.  Preliminary experiments on a synthetic dataset are provided.  The idea of learning to execute SQL-like queries on tables using a neural network is intriguing, but I think the paper suffers from several weaknesses, detailed below.", "rating": "5: Marginally below acceptance threshold", "review": "First, it does not clearly state what problem end-to-end neural network training of querying is solving, and presumes that it desirable.  It is not clear that this approach is really a viable option for much larger and more complex queries.  The paper also does not explicitly say which queries can be handled by the approach and which cannot (I doubt you can do SQL statements of arbitrary depth).\n\nThe synthetic dataset is not convincing from an NLP perspective, because the core difficulty in language understanding is handling the linguistic variation, of which there is presumably little of in the synthetic dataset.  It's unclear whether solving this dataset will actually help with real datasets like WikiTableQuestions.  Furthermore, the details of how the natural language for the QA task was generated is not clear.  From Table 1, I can't tell how much linguistic variation there is, which has a strong influence on how difficult the task is.\n\nThe comparison with SEMPRE is unsatisfying.  There are no details on how SEMPRE was used.  SEMPRE is a semantic parsing framework which does not specify the features, the grammar, etc., which have a huge effect on performance.  It's like saying that you used a neural network without specifying the architecture.  Also, is SEMPRE not working well because it needs to consider too many hypotheses?  Presumably if computation weren't the issue, SEMPRE would be better since the underlying function that one is trying to learn is actually a logical one, so SEMPRE would be a better fit.\n\nThe first sentence is a bit off: there is much work on question answering on knowledge bases prior to the cited works.  Even without going all the way back to classic AI systems such as LUNAR and CHAT-80, it would be good to mention classic statistical semantic parsing methods (Zelle & Mooney, 1996; Zettlemoyer & Collins, 2005), etc.\n\nThe last sentence of the first paragraph makes very little sense: \"This approach, however, is greatly hindered by the fact that traditional semantic parsing mostly involves rule-based features and symbolic manipulation, leaving only a handful of tunable parameters to cater to the great flexibility of natural language.\"  One might argue that traditional semantic parsing suffers from combinatorial explosion.  There are many parameters in traditional semantic parsers, not just \"a handful\".", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Neural Enquirer: Learning to Query Tables in Natural Language", "abstract": "We propose Neural Enquirer \u2014 a neural network architecture for answering natural language (NL) questions given a knowledge base (KB) table. Unlike previous work on end-to-end training of semantic parsers, Neural Enquirer is fully \u201cneuralized\u201d: it gives distributed representations of queries and KB tables, and executes queries through a series of differentiable operations. The model can be trained with gradient descent using both end-to-end and step-by-step supervision. During training the representations of queries and the KB table are jointly optimized with the query execution logic. Our experiments show that the model can learn to execute complex NL queries on KB tables with rich structures.", "pdf": "/pdf/3QxgvRAolhp7y9wltPg8.pdf", "paperhash": "yin|neural_enquirer_learning_to_query_tables_in_natural_language", "conflicts": ["cs.hku.hk", "huawei.com"], "authors": ["Pengcheng Yin", "Zhengdong Lu", "Hang Li", "Ben Kao"], "authorids": ["pcyin@cs.hku.hk", "Lu.Zhengdong@huawei.com", "HangLi.HL@huawei.com", "kao@cs.hku.hk"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456579942097, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456579942097, "id": "ICLR.cc/2016/workshop/-/paper/82/review/12", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "3QxgvRAolhp7y9wltPg8", "replyto": "3QxgvRAolhp7y9wltPg8", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/82/reviewer/12", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "ddate": null, "cdate": null, "tmdate": 1457486035282, "tcdate": 1457486035282, "id": "r8lL3q1Jki8wknpYt548", "invitation": "ICLR.cc/2016/workshop/-/paper/82/review/11", "forum": "3QxgvRAolhp7y9wltPg8", "replyto": "3QxgvRAolhp7y9wltPg8", "readers": ["everyone"], "content": {"title": "A good workshop contribution", "rating": "8: Top 50% of accepted papers, clear accept", "review": "This submission presents an end-to-end neural model with attention mechanisms that is able to answer natural language questions against a knowledge base, after being trained by gradient descent on a set of question / answer pairs. One key idea is the hierarchical combination of so-called \"executors\", each performing one step of the query.\n\nThis looks pretty cool and should definitely be accepted for the workshop track (interesting idea and promising results). I wonder if this model could be extended to answer questions that require combining answers from multiple rows? (ex: \"what is the average duration of olympic games?\") Right now it seems a bit limited since it can only find answers that can be found in a single row.\n\nMinor remarks:\n- DNN_0 does not appear to be actually deep (it is made of a single tanh layer)\n- F_T is not defined in eq. 1", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "signatures": ["~Olivier_Delalleau1", "ICLR.cc/2016/workshop/paper/82/reviewer/11"], "writers": ["~Olivier_Delalleau1", "ICLR.cc/2016/workshop/paper/82/reviewer/11"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"CMT_id": "", "title": "Neural Enquirer: Learning to Query Tables in Natural Language", "abstract": "We propose Neural Enquirer \u2014 a neural network architecture for answering natural language (NL) questions given a knowledge base (KB) table. Unlike previous work on end-to-end training of semantic parsers, Neural Enquirer is fully \u201cneuralized\u201d: it gives distributed representations of queries and KB tables, and executes queries through a series of differentiable operations. The model can be trained with gradient descent using both end-to-end and step-by-step supervision. During training the representations of queries and the KB table are jointly optimized with the query execution logic. Our experiments show that the model can learn to execute complex NL queries on KB tables with rich structures.", "pdf": "/pdf/3QxgvRAolhp7y9wltPg8.pdf", "paperhash": "yin|neural_enquirer_learning_to_query_tables_in_natural_language", "conflicts": ["cs.hku.hk", "huawei.com"], "authors": ["Pengcheng Yin", "Zhengdong Lu", "Hang Li", "Ben Kao"], "authorids": ["pcyin@cs.hku.hk", "Lu.Zhengdong@huawei.com", "HangLi.HL@huawei.com", "kao@cs.hku.hk"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1456579942690, "ddate": null, "super": null, "final": null, "duedate": 1460725200000, "tcdate": 1456579942690, "id": "ICLR.cc/2016/workshop/-/paper/82/review/11", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "reply": {"pdf": null, "forum": "3QxgvRAolhp7y9wltPg8", "replyto": "3QxgvRAolhp7y9wltPg8", "writers": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)"}, "signatures": {"values-regex": "(~.*)|ICLR.cc/2016/workshop/paper/[0-9]+/reviewer/[0-9]+)", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "readers": ["everyone", "ICLR.cc/2016/workshop/paper/82/reviewer/11", "ICLR.cc/2016/workshop"], "expdate": 1468501200000}}}, {"tddate": null, "number": null, "replyto": null, "ddate": null, "cdate": null, "tmdate": 1455783038779, "tcdate": 1455783038779, "id": "3QxgvRAolhp7y9wltPg8", "invitation": "ICLR.cc/2016/workshop/-/submission", "forum": "3QxgvRAolhp7y9wltPg8", "signatures": ["~Pengcheng_Yin1"], "readers": ["everyone"], "writers": ["~Pengcheng_Yin1"], "content": {"CMT_id": "", "title": "Neural Enquirer: Learning to Query Tables in Natural Language", "abstract": "We propose Neural Enquirer \u2014 a neural network architecture for answering natural language (NL) questions given a knowledge base (KB) table. Unlike previous work on end-to-end training of semantic parsers, Neural Enquirer is fully \u201cneuralized\u201d: it gives distributed representations of queries and KB tables, and executes queries through a series of differentiable operations. The model can be trained with gradient descent using both end-to-end and step-by-step supervision. During training the representations of queries and the KB table are jointly optimized with the query execution logic. Our experiments show that the model can learn to execute complex NL queries on KB tables with rich structures.", "pdf": "/pdf/3QxgvRAolhp7y9wltPg8.pdf", "paperhash": "yin|neural_enquirer_learning_to_query_tables_in_natural_language", "conflicts": ["cs.hku.hk", "huawei.com"], "authors": ["Pengcheng Yin", "Zhengdong Lu", "Hang Li", "Ben Kao"], "authorids": ["pcyin@cs.hku.hk", "Lu.Zhengdong@huawei.com", "HangLi.HL@huawei.com", "kao@cs.hku.hk"]}, "nonreaders": [], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "tmdate": null, "cdate": 1454464564200, "ddate": null, "super": null, "final": null, "duedate": 1455833700000, "tcdate": 1454464564200, "id": "ICLR.cc/2016/workshop/-/submission", "writers": ["ICLR.cc/2016/workshop"], "signatures": ["ICLR.cc/2016/workshop"], "readers": ["everyone"], "reply": {"pdf": null, "forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"order": 4, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv.", "value-regex": "upload|http://arxiv.org/pdf/.+"}, "title": {"order": 3, "description": "Title of paper.", "value-regex": ".{0,500}"}, "abstract": {"order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"order": 1, "description": "Comma separated list of author names, as they appear in the paper.", "value-regex": "[^,\\n]+(,[^,\\n]+)*"}, "author_emails": {"order": 2, "description": "Comma separated list of author email addresses, in the same order as above.", "value-regex": "[^,\\n]+(,[^,\\n]+)*"}, "conflicts": {"order": 100, "description": "Semi-colon separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.).", "value-regex": "^([a-zA-Z0-9][a-zA-Z0-9-_]{0,61}[a-zA-Z0-9]{0,1}\\.([a-zA-Z]{1,6}|[a-zA-Z0-9-]{1,30}\\.[a-zA-Z]{2,3}))+(;[a-zA-Z0-9][a-zA-Z0-9-_]{0,61}[a-zA-Z0-9]{0,1}\\.([a-zA-Z]{1,6}|[a-zA-Z0-9-]{1,30}\\.[a-zA-Z]{2,3}))*$"}, "CMT_id": {"order": 5, "value-regex": ".*", "description": "If the paper is a resubmission from the ICLR 2016 Conference Track, enter its CMT ID; otherwise, leave blank."}}}, "invitees": [], "nonreaders": [], "noninvitees": [], "expdate": 1463609700000}}}], "count": 4}