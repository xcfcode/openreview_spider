{"notes": [{"tddate": null, "ddate": null, "cdate": null, "original": null, "tmdate": 1490028560619, "tcdate": 1490028560619, "number": 1, "id": "B1YMuKTjl", "invitation": "ICLR.cc/2017/workshop/-/paper31/acceptance", "forum": "HJC88BzFl", "replyto": "HJC88BzFl", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Accept", "title": "ICLR committee final decision"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Precise Recovery of Latent Vectors from Generative Adversarial Networks", "abstract": "Generative adversarial networks (GANs) transform latent vectors into visually plausible images.  It is generally thought that the original GAN formulation gives no out-of-the-box method to reverse the mapping, projecting images back into latent space. We introduce a simple, gradient-based technique called stochastic clipping. In experiments, for images generated by the GAN, we exactly recover their latent vector pre-images 100% of the time. Additional experiments demonstrate that this method is robust to noise. Finally, we show that even for unseen images, our method appears to recover unique encodings.", "pdf": "/pdf/ce41138e9286de875eb0b317bcc4565496f87a28.pdf", "TL;DR": "In practice, a simple algorithm precisely recovers the z used to generate an image G(z) 100% of the time.", "paperhash": "lipton|precise_recovery_of_latent_vectors_from_generative_adversarial_networks", "conflicts": ["cs.ucsd.edu"], "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning"], "authors": ["Zachary C. Lipton", "Subarna Tripathi"], "authorids": ["zlipton@cs.ucsd.edu", "stripathi@ucsd.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1490028561224, "id": "ICLR.cc/2017/workshop/-/paper31/acceptance", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "HJC88BzFl", "replyto": "HJC88BzFl", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept", "Reject"]}}}, "nonreaders": [], "cdate": 1490028561224}}}, {"tddate": null, "tmdate": 1489502420239, "tcdate": 1489502420239, "number": 2, "id": "Hk20xYSig", "invitation": "ICLR.cc/2017/workshop/-/paper31/official/review", "forum": "HJC88BzFl", "replyto": "HJC88BzFl", "signatures": ["ICLR.cc/2017/workshop/paper31/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper31/AnonReviewer1"], "content": {"title": "Review", "rating": "7: Good paper, accept", "review": "The paper proposes a method to reconstruct the latent code vector corresponding to a given observation under a GAN generative model. Unlike BiGAN and ALI, this does not require a different training procedure or an additional inference network. Instead, projected gradient descent in code space is used, with an additional heuristic called \"stochastic clipping\" that randomly resets code components that hit the boundary.\n\nThe proposed technique is simple, but the fidelity of the reconstructed images looks good. The \"stochastic clipping\" technique is interesting, but quite ad-hoc. \n\nIf the goal is to simply keep codes away from the boundary, the authors could also try a simple entropy regularization term (map each code coordinate to [0,1] and use a Bernoulli entropy), as a barrier function for the constraint set. Additionally, one could combine this entropy regularization and the projection step by using exponentiated gradient (Warmuth, 1997), a.k.a. entropic mirror descent (Beck and Teboulle, 2003), which might simplify the algorithm.\n\nFor a full conference submission, the authors should explore these things as well as evaluate on more tasks than reconstruction, like classification on the code vectors (as explored in the BiGAN and ALI papers).\n\nSmall notes: in Section 2, many uses of the plural term \"minima\" where the singular term \"minimum\" should be used.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Precise Recovery of Latent Vectors from Generative Adversarial Networks", "abstract": "Generative adversarial networks (GANs) transform latent vectors into visually plausible images.  It is generally thought that the original GAN formulation gives no out-of-the-box method to reverse the mapping, projecting images back into latent space. We introduce a simple, gradient-based technique called stochastic clipping. In experiments, for images generated by the GAN, we exactly recover their latent vector pre-images 100% of the time. Additional experiments demonstrate that this method is robust to noise. Finally, we show that even for unseen images, our method appears to recover unique encodings.", "pdf": "/pdf/ce41138e9286de875eb0b317bcc4565496f87a28.pdf", "TL;DR": "In practice, a simple algorithm precisely recovers the z used to generate an image G(z) 100% of the time.", "paperhash": "lipton|precise_recovery_of_latent_vectors_from_generative_adversarial_networks", "conflicts": ["cs.ucsd.edu"], "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning"], "authors": ["Zachary C. Lipton", "Subarna Tripathi"], "authorids": ["zlipton@cs.ucsd.edu", "stripathi@ucsd.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489502420955, "id": "ICLR.cc/2017/workshop/-/paper31/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper31/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper31/AnonReviewer2", "ICLR.cc/2017/workshop/paper31/AnonReviewer1"], "reply": {"forum": "HJC88BzFl", "replyto": "HJC88BzFl", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper31/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper31/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489502420955}}}, {"tddate": null, "nonreaders": null, "tmdate": 1489126674154, "tcdate": 1489126640734, "number": 1, "id": "HytgSTJog", "invitation": "ICLR.cc/2017/workshop/-/paper31/public/comment", "forum": "HJC88BzFl", "replyto": "HkaS3Woqx", "signatures": ["~Zachary_Chase_Lipton1"], "readers": ["everyone"], "writers": ["~Zachary_Chase_Lipton1"], "content": {"title": "Revisions made", "comment": "Dear reviewer,\n\nThanks for the pointers on related work. While we had referred to the BiGAN paper, it wasn't previously mentioned in the related work section.  We have dutifully mentioned each paper in related work and highlighted the similarities and differences to the method presented here.\n\nWe agree with your judgment on terminology and have accordingly changed all mentions of \"standard clipping\" to \"projected gradient\" to better agree with the optimization literature. \n\nAdditionally, we will run new experiments to a stricter measure of accuracy and include the updated results in an updated draft when ready. Already, we've expanded the experiments on reconstruction from noisy images, showing that the method continues to work well up to greater degrees of noise than previously reported. \n\n[updated version posted as revision]\n"}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Precise Recovery of Latent Vectors from Generative Adversarial Networks", "abstract": "Generative adversarial networks (GANs) transform latent vectors into visually plausible images.  It is generally thought that the original GAN formulation gives no out-of-the-box method to reverse the mapping, projecting images back into latent space. We introduce a simple, gradient-based technique called stochastic clipping. In experiments, for images generated by the GAN, we exactly recover their latent vector pre-images 100% of the time. Additional experiments demonstrate that this method is robust to noise. Finally, we show that even for unseen images, our method appears to recover unique encodings.", "pdf": "/pdf/ce41138e9286de875eb0b317bcc4565496f87a28.pdf", "TL;DR": "In practice, a simple algorithm precisely recovers the z used to generate an image G(z) 100% of the time.", "paperhash": "lipton|precise_recovery_of_latent_vectors_from_generative_adversarial_networks", "conflicts": ["cs.ucsd.edu"], "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning"], "authors": ["Zachary C. Lipton", "Subarna Tripathi"], "authorids": ["zlipton@cs.ucsd.edu", "stripathi@ucsd.edu"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487193686398, "tcdate": 1487193686398, "id": "ICLR.cc/2017/workshop/-/paper31/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper31/reviewers"], "reply": {"forum": "HJC88BzFl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487193686398}}}, {"tddate": null, "replyto": null, "nonreaders": null, "ddate": null, "tmdate": 1489126120058, "tcdate": 1487193685678, "number": 31, "id": "HJC88BzFl", "invitation": "ICLR.cc/2017/workshop/-/submission", "forum": "HJC88BzFl", "signatures": ["~Zachary_Chase_Lipton1"], "readers": ["everyone"], "content": {"title": "Precise Recovery of Latent Vectors from Generative Adversarial Networks", "abstract": "Generative adversarial networks (GANs) transform latent vectors into visually plausible images.  It is generally thought that the original GAN formulation gives no out-of-the-box method to reverse the mapping, projecting images back into latent space. We introduce a simple, gradient-based technique called stochastic clipping. In experiments, for images generated by the GAN, we exactly recover their latent vector pre-images 100% of the time. Additional experiments demonstrate that this method is robust to noise. Finally, we show that even for unseen images, our method appears to recover unique encodings.", "pdf": "/pdf/ce41138e9286de875eb0b317bcc4565496f87a28.pdf", "TL;DR": "In practice, a simple algorithm precisely recovers the z used to generate an image G(z) 100% of the time.", "paperhash": "lipton|precise_recovery_of_latent_vectors_from_generative_adversarial_networks", "conflicts": ["cs.ucsd.edu"], "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning"], "authors": ["Zachary C. Lipton", "Subarna Tripathi"], "authorids": ["zlipton@cs.ucsd.edu", "stripathi@ucsd.edu"]}, "writers": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1487690420000, "tmdate": 1484242559574, "id": "ICLR.cc/2017/workshop/-/submission", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1495466420000, "cdate": 1484242559574}}}, {"tddate": null, "nonreaders": null, "tmdate": 1488819639451, "tcdate": 1488817220803, "number": 1, "id": "HkaS3Woqx", "invitation": "ICLR.cc/2017/workshop/-/paper31/official/review", "forum": "HJC88BzFl", "replyto": "HJC88BzFl", "signatures": ["ICLR.cc/2017/workshop/paper31/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper31/AnonReviewer2"], "content": {"title": "Nice simple heuristic", "rating": "6: Marginally above acceptance threshold", "review": "The authors present a heuristic for reliably recovering the latent state vector that generates a GAN sample. It seems to work well in practice, providing accurate recovery up to the level of accuracy measured.\n\nSpecific comments:\nOn the topic of reconstructing latent states from GAN samples, the authors should probably include references to BiGAN and adversarially-learned inference, which are slightly different but still closely related. Metz, Poole, Pfau and Sohl-Dickstein (2017) also reconstruct latent states from pixels, but are more focused on accurately generating out-of-sample images than reconstructing the latent state.\n\nThe clipping heuristic used is more formally known as a case of projected or proximal gradient descent in the optimization literature. Probably worth putting it in the right context. The heuristic of randomly resetting any index that goes out of bounds is novel as far as I know.\n\nGiven regular gradient descent with no clipping is still 98% effective according to their metrics, a more stringent measure of accuracy which more clearly demonstrates the gap between the baseline and the proposed method would be helpful.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Precise Recovery of Latent Vectors from Generative Adversarial Networks", "abstract": "Generative adversarial networks (GANs) transform latent vectors into visually plausible images.  It is generally thought that the original GAN formulation gives no out-of-the-box method to reverse the mapping, projecting images back into latent space. We introduce a simple, gradient-based technique called stochastic clipping. In experiments, for images generated by the GAN, we exactly recover their latent vector pre-images 100% of the time. Additional experiments demonstrate that this method is robust to noise. Finally, we show that even for unseen images, our method appears to recover unique encodings.", "pdf": "/pdf/ce41138e9286de875eb0b317bcc4565496f87a28.pdf", "TL;DR": "In practice, a simple algorithm precisely recovers the z used to generate an image G(z) 100% of the time.", "paperhash": "lipton|precise_recovery_of_latent_vectors_from_generative_adversarial_networks", "conflicts": ["cs.ucsd.edu"], "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning"], "authors": ["Zachary C. Lipton", "Subarna Tripathi"], "authorids": ["zlipton@cs.ucsd.edu", "stripathi@ucsd.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489502420955, "id": "ICLR.cc/2017/workshop/-/paper31/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper31/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper31/AnonReviewer2", "ICLR.cc/2017/workshop/paper31/AnonReviewer1"], "reply": {"forum": "HJC88BzFl", "replyto": "HJC88BzFl", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper31/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper31/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489502420955}}}], "count": 5}