{"notes": [{"id": "B1xcLJrYwH", "original": "Sylm6PTdvH", "number": 1739, "cdate": 1569439569879, "ddate": null, "tcdate": 1569439569879, "tmdate": 1577168261045, "tddate": null, "forum": "B1xcLJrYwH", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Lean Images for Geo-Localization", "authors": ["Moti Kadosh", "Yael Moses", "Ariel Shamir"], "authorids": ["arik@idc.ac.il", "yael@idc.ac.il"], "keywords": ["Geo Localization", "Deep Learning", "Computer Vision", "Camera Localization"], "abstract": "Most computer vision tasks use textured images. In this paper we consider the geo-localization task - finding the pose of a camera in a large 3D scene from a single lean image, i.e. an image with no texture.  We aim to experimentally explore whether texture and correlation between nearby images are necessary in a CNN-based solution for this task. Our results may give insight to the role of geometry (as opposed to textures) in a CNN-based geo-localization solution.  Lean images are projections of a simple 3D model of a city. They contain solely information that relates to the geometry of the scene viewed (edges, faces, or relative depth). We find that the network is capable of estimating the camera pose from lean images for a relatively large number of locations (order of hundreds of thousands of images). The main contributions of this paper are: (i) demonstrating the power of CNNs for recovering camera pose using lean images; and (ii) providing insight into the role of geometry in the CNN learning process;", "pdf": "/pdf/21a3387c16e942511f56f3c4f624ba176e5b19b7.pdf", "paperhash": "kadosh|lean_images_for_geolocalization", "original_pdf": "/attachment/21a3387c16e942511f56f3c4f624ba176e5b19b7.pdf", "_bibtex": "@misc{\nkadosh2020lean,\ntitle={Lean Images for Geo-Localization},\nauthor={Moti Kadosh and Yael Moses and Ariel Shamir},\nyear={2020},\nurl={https://openreview.net/forum?id=B1xcLJrYwH}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "ky2WhDr-Xz", "original": null, "number": 1, "cdate": 1576798731257, "ddate": null, "tcdate": 1576798731257, "tmdate": 1576800905208, "tddate": null, "forum": "B1xcLJrYwH", "replyto": "B1xcLJrYwH", "invitation": "ICLR.cc/2020/Conference/Paper1739/-/Decision", "content": {"decision": "Reject", "comment": "The submission studies the problem of geolocalizing a city based on geometric information encoded in so called \"lean\" images.  The reviewers were unanimous in their opinion that the submission does not meet the threshold for publication at ICLR.  Concerns included quality of writing, novelty with respect to existing literature (in particular see Review #2), and limited validation on one geographic area.  No rebuttal was provided.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Lean Images for Geo-Localization", "authors": ["Moti Kadosh", "Yael Moses", "Ariel Shamir"], "authorids": ["arik@idc.ac.il", "yael@idc.ac.il"], "keywords": ["Geo Localization", "Deep Learning", "Computer Vision", "Camera Localization"], "abstract": "Most computer vision tasks use textured images. In this paper we consider the geo-localization task - finding the pose of a camera in a large 3D scene from a single lean image, i.e. an image with no texture.  We aim to experimentally explore whether texture and correlation between nearby images are necessary in a CNN-based solution for this task. Our results may give insight to the role of geometry (as opposed to textures) in a CNN-based geo-localization solution.  Lean images are projections of a simple 3D model of a city. They contain solely information that relates to the geometry of the scene viewed (edges, faces, or relative depth). We find that the network is capable of estimating the camera pose from lean images for a relatively large number of locations (order of hundreds of thousands of images). The main contributions of this paper are: (i) demonstrating the power of CNNs for recovering camera pose using lean images; and (ii) providing insight into the role of geometry in the CNN learning process;", "pdf": "/pdf/21a3387c16e942511f56f3c4f624ba176e5b19b7.pdf", "paperhash": "kadosh|lean_images_for_geolocalization", "original_pdf": "/attachment/21a3387c16e942511f56f3c4f624ba176e5b19b7.pdf", "_bibtex": "@misc{\nkadosh2020lean,\ntitle={Lean Images for Geo-Localization},\nauthor={Moti Kadosh and Yael Moses and Ariel Shamir},\nyear={2020},\nurl={https://openreview.net/forum?id=B1xcLJrYwH}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "B1xcLJrYwH", "replyto": "B1xcLJrYwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795726284, "tmdate": 1576800278390, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1739/-/Decision"}}}, {"id": "SklaSE3uKB", "original": null, "number": 1, "cdate": 1571501125036, "ddate": null, "tcdate": 1571501125036, "tmdate": 1572972429830, "tddate": null, "forum": "B1xcLJrYwH", "replyto": "B1xcLJrYwH", "invitation": "ICLR.cc/2020/Conference/Paper1739/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper evaluates the performances of Deep Learning for geo-localization tasks in a world of images without textures (\"lean images\"). More exactly, the lean images are images rendered from a 3D model of a city. made of the depth and/or the buildings' edges and/or the buildings' faces. For the purpose of the evaluation, no real images are used,  only lean images both at training and test times. Many lean images are generated for training a network to predict the camera pose (2 translation parameters,  two angles), as a classification problem or a regression problem.\n\nThe motivation for the study is to understand the use of geometric aspects by a deep network to solve the task. However, as the paper presents mostly the results of the quantitative evaluation, it is not clear what we really learn about the mechanisms of the deep network. I think the empirical results can be interesting for people working on geo-localization, but probably not for the audience of ICLR.\n\nI suspect the authors have in mind for the future to learn to predict a lean image from a real image. I would find this aspect very interesting. It would also be interesting to evaluate the performance on the  geo-localization task when noisy images are used as input.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1739/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1739/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Lean Images for Geo-Localization", "authors": ["Moti Kadosh", "Yael Moses", "Ariel Shamir"], "authorids": ["arik@idc.ac.il", "yael@idc.ac.il"], "keywords": ["Geo Localization", "Deep Learning", "Computer Vision", "Camera Localization"], "abstract": "Most computer vision tasks use textured images. In this paper we consider the geo-localization task - finding the pose of a camera in a large 3D scene from a single lean image, i.e. an image with no texture.  We aim to experimentally explore whether texture and correlation between nearby images are necessary in a CNN-based solution for this task. Our results may give insight to the role of geometry (as opposed to textures) in a CNN-based geo-localization solution.  Lean images are projections of a simple 3D model of a city. They contain solely information that relates to the geometry of the scene viewed (edges, faces, or relative depth). We find that the network is capable of estimating the camera pose from lean images for a relatively large number of locations (order of hundreds of thousands of images). The main contributions of this paper are: (i) demonstrating the power of CNNs for recovering camera pose using lean images; and (ii) providing insight into the role of geometry in the CNN learning process;", "pdf": "/pdf/21a3387c16e942511f56f3c4f624ba176e5b19b7.pdf", "paperhash": "kadosh|lean_images_for_geolocalization", "original_pdf": "/attachment/21a3387c16e942511f56f3c4f624ba176e5b19b7.pdf", "_bibtex": "@misc{\nkadosh2020lean,\ntitle={Lean Images for Geo-Localization},\nauthor={Moti Kadosh and Yael Moses and Ariel Shamir},\nyear={2020},\nurl={https://openreview.net/forum?id=B1xcLJrYwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "B1xcLJrYwH", "replyto": "B1xcLJrYwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1739/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1739/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575843414106, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1739/Reviewers"], "noninvitees": [], "tcdate": 1570237732993, "tmdate": 1575843414119, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1739/-/Official_Review"}}}, {"id": "BJxZfI20KB", "original": null, "number": 2, "cdate": 1571894793468, "ddate": null, "tcdate": 1571894793468, "tmdate": 1572972429796, "tddate": null, "forum": "B1xcLJrYwH", "replyto": "B1xcLJrYwH", "invitation": "ICLR.cc/2020/Conference/Paper1739/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "The paper tackles the problem of geolocating an image from a 3D model of a city. This is an interesting and challenging problem since it involves solving the matching under 3D transformations at large scale.\n\nThe proposed approach is to use geometric features such as edges, faces and depths of the image, which is called \"lean image\" by the paper. The paper demonstrate that by using the \"lean image\" a neural network can recognize its geolocation with substantial accuracy. However, the idea of using geometric features has been investigated in quite a few previous literature and the paper fails to discuss relevant works, e.g., [1,2,3] and distinguish their differences.\n[1] Li et al. Planar Structure Matching Under Projective Uncertainty for Geolocation. ECCV 2014.\n[2] Mousavian and Kosecka. Semantic Image Based Geolocation Given a Map. ArXiv 2016.\n[3] Kim et al. Learned Contextual Feature Reweighting for Image Geo-Localization. CVPR 2018.\n\nThe paper contains mostly empirical evaluations however the provided experiments do not well support the claim that CNN works well with geometric structures in geolocalization. The paper should compare with CNN on RGB images on the same data in order to demonstrate its effectiveness.\n\nReview:\n## Contribution of the paper:\n1. The paper argues that \"lean images\" (geometric structure of a 2D scene) contains sufficient information for solving the memorization of geolocation tasks.\n2. The paper provide an approach to evaluate the argument.\n3. The paper provide experimental validation that the proposed method works fairly on a certain Berlin dataset.\n\n## Feedback\nThe paper is interesting but it does not meet the standard of this conference. There are some key reasons:\n1. The writing is poor. The paper is hard to follow. There are also missing references. The importance of geometry in geolocation has been studied in many previous works.\n2. The paper is empirical so it has to provide strong empirical evidence to support the claim. The experiment is only conducted in Berlin data whose scope is fairly small. Without large scale experiments, it is hard to convince readers that CNN is able to \"memorize\" all the locations using just geometric features. Without comparing to RGB baseline or other existing approaches, it is hard to convince readers that the proposed approach works fairly well. It also seems the input images are just 2D projections so without experiments using real 2D images, it is hard to say the approach is effective.\n\n## Improvements that could be done\n1. Please make sure everything in the tables are clearly explained. The metrics should be explained somewhere in the caption. It is hard to find the meaning of some notations in the table such as \"37K images\", \"Area 400x400\". Please clearly state the unit.\n2. Please include some baseline results into the tables so that readers know how much improvments achieved by your approach.\n3. Please reorganize the paper to make it more clear. \n4. Please provide more literature review and discuss the difference of your work to existing ones.\n\n\n## Questions\n1. How large is the Berlin data?\n2. How would your method work when there is only a street image? How would you method scale when 3D model is not always available.\n3. How would you method work when there is some places without much structure? Rural area could be an example."}, "signatures": ["ICLR.cc/2020/Conference/Paper1739/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1739/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Lean Images for Geo-Localization", "authors": ["Moti Kadosh", "Yael Moses", "Ariel Shamir"], "authorids": ["arik@idc.ac.il", "yael@idc.ac.il"], "keywords": ["Geo Localization", "Deep Learning", "Computer Vision", "Camera Localization"], "abstract": "Most computer vision tasks use textured images. In this paper we consider the geo-localization task - finding the pose of a camera in a large 3D scene from a single lean image, i.e. an image with no texture.  We aim to experimentally explore whether texture and correlation between nearby images are necessary in a CNN-based solution for this task. Our results may give insight to the role of geometry (as opposed to textures) in a CNN-based geo-localization solution.  Lean images are projections of a simple 3D model of a city. They contain solely information that relates to the geometry of the scene viewed (edges, faces, or relative depth). We find that the network is capable of estimating the camera pose from lean images for a relatively large number of locations (order of hundreds of thousands of images). The main contributions of this paper are: (i) demonstrating the power of CNNs for recovering camera pose using lean images; and (ii) providing insight into the role of geometry in the CNN learning process;", "pdf": "/pdf/21a3387c16e942511f56f3c4f624ba176e5b19b7.pdf", "paperhash": "kadosh|lean_images_for_geolocalization", "original_pdf": "/attachment/21a3387c16e942511f56f3c4f624ba176e5b19b7.pdf", "_bibtex": "@misc{\nkadosh2020lean,\ntitle={Lean Images for Geo-Localization},\nauthor={Moti Kadosh and Yael Moses and Ariel Shamir},\nyear={2020},\nurl={https://openreview.net/forum?id=B1xcLJrYwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "B1xcLJrYwH", "replyto": "B1xcLJrYwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1739/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1739/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575843414106, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1739/Reviewers"], "noninvitees": [], "tcdate": 1570237732993, "tmdate": 1575843414119, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1739/-/Official_Review"}}}, {"id": "S1gCdj5T9H", "original": null, "number": 3, "cdate": 1572871030175, "ddate": null, "tcdate": 1572871030175, "tmdate": 1572972429752, "tddate": null, "forum": "B1xcLJrYwH", "replyto": "B1xcLJrYwH", "invitation": "ICLR.cc/2020/Conference/Paper1739/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #4", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "The paper evaluates a geo-localization task based on \"lean\" images only, obtained by projection of 3d models without texture information. Multiple levels of granularity of the lean images (edges/edges+faces/edges+faces+depth) are compared for the learning, both in a \"memorization\" setting and in a \"generalization to unseen poses\" setting. Moreover, the behavior of the learning when labels are shuffled is evaluated.\n\nThe paper is motivated by identifying lean images with \"pure geometrical\" representation, and argues that the study is a demonstration that the network can learn some spatial map. I do not share this analysis: the edges, shapes and colors of the lean images still create some characteristic shapes that do not have to be linked with the 3D map in order to be detected; it is not clear why the detection from lean images is more geometrical in essence w.r.t. textured images. The motivation of the paper is therefore not compelling, and the study would have more relevance as an ablation study of a method using both geometry and texture. Can you give more compelling arguments for the problem setup, rather than a mere thought experiment?\n\nOther than this particular setup of geo-localizing based on lean images only, the novelty of the paper and the approach seem limited and does not offer new insights in geo-interpolation methods, geometry-aware neural networks, or memorization. Therefore, I believe the paper does not meet the standards of ICLR.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1739/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1739/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Lean Images for Geo-Localization", "authors": ["Moti Kadosh", "Yael Moses", "Ariel Shamir"], "authorids": ["arik@idc.ac.il", "yael@idc.ac.il"], "keywords": ["Geo Localization", "Deep Learning", "Computer Vision", "Camera Localization"], "abstract": "Most computer vision tasks use textured images. In this paper we consider the geo-localization task - finding the pose of a camera in a large 3D scene from a single lean image, i.e. an image with no texture.  We aim to experimentally explore whether texture and correlation between nearby images are necessary in a CNN-based solution for this task. Our results may give insight to the role of geometry (as opposed to textures) in a CNN-based geo-localization solution.  Lean images are projections of a simple 3D model of a city. They contain solely information that relates to the geometry of the scene viewed (edges, faces, or relative depth). We find that the network is capable of estimating the camera pose from lean images for a relatively large number of locations (order of hundreds of thousands of images). The main contributions of this paper are: (i) demonstrating the power of CNNs for recovering camera pose using lean images; and (ii) providing insight into the role of geometry in the CNN learning process;", "pdf": "/pdf/21a3387c16e942511f56f3c4f624ba176e5b19b7.pdf", "paperhash": "kadosh|lean_images_for_geolocalization", "original_pdf": "/attachment/21a3387c16e942511f56f3c4f624ba176e5b19b7.pdf", "_bibtex": "@misc{\nkadosh2020lean,\ntitle={Lean Images for Geo-Localization},\nauthor={Moti Kadosh and Yael Moses and Ariel Shamir},\nyear={2020},\nurl={https://openreview.net/forum?id=B1xcLJrYwH}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "B1xcLJrYwH", "replyto": "B1xcLJrYwH", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1739/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1739/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575843414106, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1739/Reviewers"], "noninvitees": [], "tcdate": 1570237732993, "tmdate": 1575843414119, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1739/-/Official_Review"}}}], "count": 5}