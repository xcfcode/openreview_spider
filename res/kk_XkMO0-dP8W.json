{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1362989220000, "tcdate": 1362989220000, "number": 3, "id": "WWycbHg8XRWuv", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "kk_XkMO0-dP8W", "replyto": "kk_XkMO0-dP8W", "signatures": ["Mike Seltzer"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "We\u2019d like to thank the reviewers for their comments. \r\n\r\nWe have uploaded a revised version of the paper which we believe addresses reviewers\u2019 concerns as well as the grammatical issues and typos. \r\n \r\nWe have revised the abstract and introduction to better establish the purpose of the paper. Our goal is to demonstrate that deep neural networks can learn internal representations that are robust to variability in the input, and that this robustness is maintained when large amounts of training data are used. Much work in DNNs has been on smaller data sets and historically, in speech recognition, large improvements observed on small systems usually do not translate when applied to large-scale state-of-the-art systems. \r\n \r\nIn addition, the paper contrasts DNN-based systems and their \u201cbuilt in\u201d invariance to a wide variety of variability, to GMM-based systems, where algorithms have been designed to combat unwanted variability in a source-specific manner, i.e. they are designed to address a particular mismatch, such as the speaker or the environment. \r\n \r\nWe also believe there is also a practical implication of these results: algorithms for addressing this acoustic mismatch in speaker, environment, or other factors, which are standard and essential for GMM-based recognizers, become far less critical and potentially unnecessary for DNN-based recognizers. We think this is important for both setting future research directions and deploying large-scale systems. \r\n \r\nFinally, while some of the results have been published previously, we believe the inherent robustness of  DNNs to such diverse sources of variability is quite interesting, and is a point that might allude readers unless these results are combined and presented together. We also want to point out that the analysis of sensitivity to the input perturbation and all of the results in Section 6 on environmental robustness are new and previously unpublished. \r\n\r\nWe hope by putting together all these analyses and results in one paper we can provide some insights on the strengths and weaknesses of using a DNN for speech recognition when trained with real world data."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Learning in Deep Neural Networks - A Study on Speech Recognition\r\n    Tasks", "decision": "conferenceOral-iclr2013-conference", "abstract": "Recent studies have shown that deep neural networks (DNNs) perform significantly better than shallow networks and Gaussian mixture models (GMMs) on large vocabulary speech recognition tasks. In this paper we argue that the difficulty in speech recognition is primarily caused by the high variability in speech signals. DNNs, which can be considered a joint model of a nonlinear feature transform and a log-linear classifier, achieve improved recognition accuracy by extracting discriminative internal representations that are less sensitive to small perturbations in the input features. However, if test samples are very dissimilar to training samples, DNNs perform poorly. We demonstrate these properties empirically using a series of recognition experiments on mixed narrowband and wideband speech and speech distorted by environmental noise.", "pdf": "https://arxiv.org/abs/1301.3605", "paperhash": "yu|feature_learning_in_deep_neural_networks_a_study_on_speech_recognition_tasks", "keywords": [], "conflicts": [], "authors": ["Dong Yu", "Mike Seltzer", "Jinyu Li", "Jui-Ting Huang", "Frank Seide"], "authorids": ["dongyu888@gmail.com", "mike.seltzer@gmail.com", "jinyli@microsoft.com", "jthuang@microsoft.com", "fseide@microsoft.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362161880000, "tcdate": 1362161880000, "number": 4, "id": "ySpzfXa4-ryCM", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "kk_XkMO0-dP8W", "replyto": "kk_XkMO0-dP8W", "signatures": ["anonymous reviewer 778f"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Feature Learning in Deep Neural Networks - A Study on Speech Recognition\r\n    Tasks", "review": "* Comments\r\n** Summary\r\n   The paper uses examples from speech recognition to make the\r\n   following points about feature learning in deep neural networks:\r\n   1. Speech recognition performance improves with deeper networks,\r\n      but the gain per layer diminishes.\r\n   2. The internal representations in a trained deep network become\r\n      increasingly insensitive to small perturbations in the input\r\n      with depth.\r\n   3. Deep networks are unable to extrapolate to test samples that are\r\n      substantially different from the training samples.\r\n\r\n   The paper then shows that deep neural networks are able to learn\r\n   representations that are comparatively invariant to two important\r\n   sources of variability in speech:  speaker variability and\r\n   environmental distortions.\r\n\r\n** Pluses\r\n   - The work here is an important contribution because it comes from\r\n     the application of deep learning to real-world problems in speech\r\n     recognition, and it compares deep learning to classical\r\n     state-of-the-art approaches including discriminatively trained\r\n     GMM-HMM models, vocal tract length normalization, feature-space\r\n     maximum likelihood linear regression, noise-adaptive training,\r\n     and vector Taylor series compensation.\r\n   - In the machine learning community, the deep learning literature\r\n     has been dominated by computer vision applications.  It is good\r\n     to show applications in other domains that have different\r\n     characteristics.  For example, speech recognition is inherently a\r\n     structured classification problem, while many vision applications\r\n     are simple classification problems.\r\n\r\n** Minuses\r\n   - There is not a lot of new material here.  Most of the results\r\n     have been published elsewhere.\r\n\r\n** Recommendation\r\n   I'd like to see this paper accepted because\r\n   1. it makes important points about both the advantages and\r\n      limitations of current approaches to deep learning, illustrating\r\n      them with practical examples from speech recognition and\r\n      comparing deep learning against solid baselines; and\r\n   2. it brings speech recognition into the broader conversation on\r\n      deep learning.\r\n\r\n* Minor Issues\r\n  - The first (unnumbered) equation is correct; however, I don't\r\n    think that viewing the internal layers as computing posterior\r\n    probabilities over hidden binary vectors provides any useful\r\n    insights.\r\n  - There is an error in the right hand side of the unnumbered\r\n    equation preceding Equation 4:  it should be sigma prime (the\r\n    derivative), not sigma.\r\n  - 'Senones' is jargon that is very specific to speech recognition\r\n    and may not be understood by a broader machine learning audience.\r\n  - The VTS acronym for vector Taylor series compensation is never\r\n    defined in the paper.\r\n\r\n* Proofreading\r\n  the performance of the ASR systems -> the performance of ASR systems\r\n\r\n  By using the context-dependent deep neural network -> By using context-dependent deep neural network\r\n\r\n  the feature learning interpretations of DNNs -> the feature learning interpretation of DNNs\r\n\r\n  a DNN can interpreted as -> a DNN can be interpreted as\r\n\r\n  whose senone alignment label was generated -> whose HMM state alignment labels were generated\r\n\r\n  the deep models consistently outperforms the shallow -> the deep models consistently outperform the shallow\r\n\r\n  This is reflected in right column -> This is reflected in the right column\r\n\r\n  3.2 DNN learns more invariant features -> 3.2 DNNs learn more invariant features\r\n\r\n  is that DNN learns more invariant -> is that DNNs learn more invariant\r\n\r\n  since the differences needs to be -> since the differences need to be\r\n\r\n  that the small perturbations in the input -> that small perturbations in the input\r\n\r\n  with the central frequency of the first higher filter bank at 4 kHz -> with the center frequency of the first filter in the higher filter bank at 4 kHz\r\n\r\n  between p_y|x(s_j|x_wb) and p_y|x(s_j|x_nb -> between p_y|x(s_j|x_wb) and p_y|x(s_j|x_nb)\r\n\r\n  Note that the transform is applied before augmenting neighbor frames. -> Note that the transform is applied to individual frames, prior to concatentation.\r\n\r\n  demonstrated through a speech recognition experiments -> demonstrated through speech recognition experiments"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Learning in Deep Neural Networks - A Study on Speech Recognition\r\n    Tasks", "decision": "conferenceOral-iclr2013-conference", "abstract": "Recent studies have shown that deep neural networks (DNNs) perform significantly better than shallow networks and Gaussian mixture models (GMMs) on large vocabulary speech recognition tasks. In this paper we argue that the difficulty in speech recognition is primarily caused by the high variability in speech signals. DNNs, which can be considered a joint model of a nonlinear feature transform and a log-linear classifier, achieve improved recognition accuracy by extracting discriminative internal representations that are less sensitive to small perturbations in the input features. However, if test samples are very dissimilar to training samples, DNNs perform poorly. We demonstrate these properties empirically using a series of recognition experiments on mixed narrowband and wideband speech and speech distorted by environmental noise.", "pdf": "https://arxiv.org/abs/1301.3605", "paperhash": "yu|feature_learning_in_deep_neural_networks_a_study_on_speech_recognition_tasks", "keywords": [], "conflicts": [], "authors": ["Dong Yu", "Mike Seltzer", "Jinyu Li", "Jui-Ting Huang", "Frank Seide"], "authorids": ["dongyu888@gmail.com", "mike.seltzer@gmail.com", "jinyli@microsoft.com", "jthuang@microsoft.com", "fseide@microsoft.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1362128940000, "tcdate": 1362128940000, "number": 1, "id": "eMmX26-PXaMJN", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "kk_XkMO0-dP8W", "replyto": "kk_XkMO0-dP8W", "signatures": ["anonymous reviewer cf74"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Feature Learning in Deep Neural Networks - A Study on Speech Recognition\r\n    Tasks", "review": "The paper presents an analysis of performance of DNN acoustic models in tasks where there is a mis-match between training and test data. Most of the results do not seem to be novel, and were published in several papers already. The paper is well written and mostly easy to follow.\r\n\r\nPros:\r\nAlthough there is nothing surprising in the paper, the study may motivate others to investigate DNNs.\r\n\r\nCons:\r\nAuthors could have been more bold in ideas and experiments.\r\n\r\nComments:\r\n\r\nTable 1: it would be more convincing to show L x N for variable L and N, such as N=4096, if one wants to prove that many (9) hidden layers are needed to achieve top performance (I'd expect that accuracy saturation would occur with less hidden layers, if N would increase); moreover, one can investigate architectures that would have the same number of parameters, but would be more shallow - for example, first and last hidden layers can have N=2048, and the hidden layer in between can have N=8192 - this would be more fair to show if one wants to claim that 9 hidden layers are better than 3 (as obviously, adding more parameters helps and the current comparison with 1-hidden layer NN is completely unfair as input and output layers have different dimensionality, but one can apply other tricks there to reduce complexity - for example hierarchical softmax in the output layer etc.)\r\n\r\n'Note that the magnitude of the majority of the weights is typically very small' - note that this is also related to sizes of the hidden layers; if hidden layers were very small, the weights would be larger (output of neuron is non-linear function of weighted sum of inputs; if there are 2048 inputs that are in range (0,1), then we can naturally expect the weights to be very small)\r\n\r\nSection 3 rather shows that neural networks are good at representing smooth functions, which is the opposite to what deep architectures were proposed for. Another reason to believe that 9 hidden layers are not needed.\r\n\r\nThe results where DNN models perform poorly on data that were not seen during training are not really striking or novel; it would be actually good if authors would try to overcome this problem in a novel way. For example, one can try to make DNNs more robust by allowing some kind of simple cheap adaptation during test time. When it comes to capturing VTLN / speaker characteristics, it would be interesting to use longer-context information, either through recurrence, or by using features derived from long contexts (such as previous 2-10 seconds).\r\n\r\nTable 4 compares relative reductions of WER: however, note that 0% is not reachable on Switchboard. If we would assume that human performance is around 5-10% WER, then the difference in relative improvements would be significantly smaller. Also, it is very common that the better the baseline is, the harder it is to gain improvements (as many different techniques actually address the same problems).\r\n\r\nAlso, it is possible that DNNs can learn some weak VTLN, as they typically see longer context information; it would be interesting to see an experiment where DNN would be trained with limited context information (I would expect WER to increase, but also the relative gain from VTLN should increase)."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Learning in Deep Neural Networks - A Study on Speech Recognition\r\n    Tasks", "decision": "conferenceOral-iclr2013-conference", "abstract": "Recent studies have shown that deep neural networks (DNNs) perform significantly better than shallow networks and Gaussian mixture models (GMMs) on large vocabulary speech recognition tasks. In this paper we argue that the difficulty in speech recognition is primarily caused by the high variability in speech signals. DNNs, which can be considered a joint model of a nonlinear feature transform and a log-linear classifier, achieve improved recognition accuracy by extracting discriminative internal representations that are less sensitive to small perturbations in the input features. However, if test samples are very dissimilar to training samples, DNNs perform poorly. We demonstrate these properties empirically using a series of recognition experiments on mixed narrowband and wideband speech and speech distorted by environmental noise.", "pdf": "https://arxiv.org/abs/1301.3605", "paperhash": "yu|feature_learning_in_deep_neural_networks_a_study_on_speech_recognition_tasks", "keywords": [], "conflicts": [], "authors": ["Dong Yu", "Mike Seltzer", "Jinyu Li", "Jui-Ting Huang", "Frank Seide"], "authorids": ["dongyu888@gmail.com", "mike.seltzer@gmail.com", "jinyli@microsoft.com", "jthuang@microsoft.com", "fseide@microsoft.com"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1361169180000, "tcdate": 1361169180000, "number": 2, "id": "NFxrNAiI-clI8", "invitation": "ICLR.cc/2013/-/submission/review", "forum": "kk_XkMO0-dP8W", "replyto": "kk_XkMO0-dP8W", "signatures": ["anonymous reviewer 1860"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Feature Learning in Deep Neural Networks - A Study on Speech Recognition\r\n    Tasks", "review": "This paper is by the group that did the first large-scale speech recognition experiments on deep neural nets, and popularized the technique.  It contains various analysis and experiments relating to this setup.\r\n  Ultimately I was not really sure what was the main point of the paper.  There is some analysis of whether the network amplifies or reduces differences in inputs as we go through the layers; there are some experiments relating to features normalization techniques (such as VTLN) and how they interact with neural nets, and there were some experiments showing that the neural network does not do very well on narrowband data unless it has been trained on narrowband data in addition to wideband data; and also showing (by looking at the intermediate activations) that the network learns to be invariant to wideband/narrowband differences, if it is trained on both kinds of input.\r\n  Although the paper itself is kind of scattered, and I'm not really sure that it makes any major contributions, I would suggest the conference organizers to strongly consider accepting it, because unlike (I imagine) many of the other papers, it comes from a group who are applying these techniques to real world problems and is having considerable success.  I think their perspective would be valuable, and accepting it would send the message that this conference values serious, real-world applications, which I think would be a good thing.\r\n\r\n--\r\nBelow are some suggestions for minor fixes to the paper.\r\n\r\neq. 4, prime ( ') missing after sigma on top right.\r\n\r\nsec. 3.2, you do not explain the difference between average norm and maximum norm.\r\nWhat type of matrix norm do you mean, and what are the average and maximum taken over?\r\n\r\nafter 'narrowband input feature pairs', one of your subscripts needs to be changed."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Feature Learning in Deep Neural Networks - A Study on Speech Recognition\r\n    Tasks", "decision": "conferenceOral-iclr2013-conference", "abstract": "Recent studies have shown that deep neural networks (DNNs) perform significantly better than shallow networks and Gaussian mixture models (GMMs) on large vocabulary speech recognition tasks. In this paper we argue that the difficulty in speech recognition is primarily caused by the high variability in speech signals. DNNs, which can be considered a joint model of a nonlinear feature transform and a log-linear classifier, achieve improved recognition accuracy by extracting discriminative internal representations that are less sensitive to small perturbations in the input features. However, if test samples are very dissimilar to training samples, DNNs perform poorly. We demonstrate these properties empirically using a series of recognition experiments on mixed narrowband and wideband speech and speech distorted by environmental noise.", "pdf": "https://arxiv.org/abs/1301.3605", "paperhash": "yu|feature_learning_in_deep_neural_networks_a_study_on_speech_recognition_tasks", "keywords": [], "conflicts": [], "authors": ["Dong Yu", "Mike Seltzer", "Jinyu Li", "Jui-Ting Huang", "Frank Seide"], "authorids": ["dongyu888@gmail.com", "mike.seltzer@gmail.com", "jinyli@microsoft.com", "jthuang@microsoft.com", "fseide@microsoft.com"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1358404200000, "tcdate": 1358404200000, "number": 43, "id": "kk_XkMO0-dP8W", "invitation": "ICLR.cc/2013/conference/-/submission", "forum": "kk_XkMO0-dP8W", "signatures": ["dongyu888@gmail.com"], "readers": ["everyone"], "content": {"title": "Feature Learning in Deep Neural Networks - A Study on Speech Recognition\r\n    Tasks", "decision": "conferenceOral-iclr2013-conference", "abstract": "Recent studies have shown that deep neural networks (DNNs) perform significantly better than shallow networks and Gaussian mixture models (GMMs) on large vocabulary speech recognition tasks. In this paper we argue that the difficulty in speech recognition is primarily caused by the high variability in speech signals. DNNs, which can be considered a joint model of a nonlinear feature transform and a log-linear classifier, achieve improved recognition accuracy by extracting discriminative internal representations that are less sensitive to small perturbations in the input features. However, if test samples are very dissimilar to training samples, DNNs perform poorly. We demonstrate these properties empirically using a series of recognition experiments on mixed narrowband and wideband speech and speech distorted by environmental noise.", "pdf": "https://arxiv.org/abs/1301.3605", "paperhash": "yu|feature_learning_in_deep_neural_networks_a_study_on_speech_recognition_tasks", "keywords": [], "conflicts": [], "authors": ["Dong Yu", "Mike Seltzer", "Jinyu Li", "Jui-Ting Huang", "Frank Seide"], "authorids": ["dongyu888@gmail.com", "mike.seltzer@gmail.com", "jinyli@microsoft.com", "jthuang@microsoft.com", "fseide@microsoft.com"]}, "writers": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496673673639, "cdate": 1496673673639, "tcdate": 1496673673639, "id": "ICLR.cc/2013/conference/-/submission", "writers": ["ICLR.cc/2013"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717}}}], "count": 5}