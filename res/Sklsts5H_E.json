{"notes": [{"id": "Sklsts5H_E", "original": "Syx6OK5rdE", "number": 66, "cdate": 1553472386714, "ddate": null, "tcdate": 1553472386714, "tmdate": 1562082111260, "tddate": null, "forum": "Sklsts5H_E", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "Deep Generative Inpainting with Comparative Sample Augmentation", "authors": ["Boli Fang", "Miao Jiang", "Jerry Shen", "Bjord Stenger"], "authorids": ["bfang@iu.edu", "miajiang@iu.edu", "hashen@iu.edu", "bjord.stenger@rakuten.com"], "keywords": ["Image Inpainting", "Various Datasets"], "TL;DR": "We introduced a strategy which enables inpainting models on datasets of various sizes", "abstract": "Recent advancements in deep learning techniques such as Convolutional Neural Networks(CNN) and Generative Adversarial Networks(GAN) have achieved breakthroughs in the problem of semantic image inpainting, the task of reconstructing missing pixels in given images. While much more effective than conventional approaches, deep learning models require large datasets and great computational resources for training, and inpainting quality varies considerably when training data vary in size and diversity. To address these problems, we present in this paper a inpainting strategy of \\textit{Comparative Sample Augmentation}, which enhances the quality of training set by filtering out irrelevant images and constructing additional images using information about the surrounding regions of the images to be inpainted. Experiments on multiple datasets demonstrate that our method extends the applicability of deep inpainting models to training sets with varying sizes, while maintaining inpainting quality as measured by qualitative and quantitative metrics for a large class of deep models, with little need for model-specific consideration.", "pdf": "/pdf/78c1ab4cbf3df45e5bb44b2f3307fe47842c57b1.pdf", "paperhash": "fang|deep_generative_inpainting_with_comparative_sample_augmentation"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "OpenReview.net"}, {"id": "HJxnwMG8FE", "original": null, "number": 1, "cdate": 1554551396242, "ddate": null, "tcdate": 1554551396242, "tmdate": 1555512024423, "tddate": null, "forum": "Sklsts5H_E", "replyto": "Sklsts5H_E", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper66/Official_Review", "content": {"title": "Not clear contributions; not even clear method", "review": "The authors propose an augmentation method for image inpainting; the core idea lies in filtering out irrelevant images and augmenting the images by adding random normal noise in the pixel space. \n\nEven though potentially, the method has its merits, the method is not clearly written, while the paper is rather confusing (please see below). \n\nMajor points: \n\n1) There is no formal definition of the task in the paper (i.e. they interchangeably just mention inpainting or semantic inpainting without any definition). In conjunction with the lack of clear explanation of their method, understanding the contributions is challenging. \n\n2) It is not clear what type of GAN the authors use. They mention WGAN-GP (Gulrajani et al), but it is not mentioned whether they generate from scratch the images or whether this is a conditional GAN (as traditional inpainting methods). Therefore, it is not clear how GAN is used in this work.\n\n3) The comparative augmentation filter seems like a KNN in the pixel-space; given question 2, it is not clear where this filter fits in the training method.\n\n4) The authors mention that their method 'extends the applicability of deep inpainting methods', but in the end only experiment in a 'restricted-CIFAR'; the rest experiments of Celeb-A and Places are not included. \n\n5) The propose augmentation method, i.e. adding random normal noise per pixel is not novel; in addition, there is no ablation experiment demonstrating the benefits experimentally.\n\n6) Why do the authors propose to filter the images in the pixel space and not a perceptual space as popular the last few years? \n\n\nMinor points: \n1) The following expressions should be more rigorous: \n   - 'becomes 0 if and only if P = Q almost surely'.\n   - 'produces better or on-par images no later than the original GAN'.\n   - 'and ones that utilize [...] latent space.'\n\n2) The authors mention that Yu et al 'fail at more complex inpainting images such as faces and natural scenery'. Do they have some visual examples that contradict the original paper? Because in the original paper, the methods perform well in both domains. \n\n3) In Fig. 1 and 2, what is the '/workshop_format/[...].png'? \n\n4) In table 1, l1 and l2 errors are mentioned, but there is a single number; which also includes an undefined percentage. Could the authors clarify what they mean? \n\n5) The authors do not mention how much they augment their original images, i.e. for every original image how many images are used during training? Is the noise sampled per image or per batch? \n\nGiven the major improvement points; the paper should be re-written before being accepted to the workshop. \n\n\n\n", "rating": "2: Marginally below acceptance threshold", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper66/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper66/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Generative Inpainting with Comparative Sample Augmentation", "authors": ["Boli Fang", "Miao Jiang", "Jerry Shen", "Bjord Stenger"], "authorids": ["bfang@iu.edu", "miajiang@iu.edu", "hashen@iu.edu", "bjord.stenger@rakuten.com"], "keywords": ["Image Inpainting", "Various Datasets"], "TL;DR": "We introduced a strategy which enables inpainting models on datasets of various sizes", "abstract": "Recent advancements in deep learning techniques such as Convolutional Neural Networks(CNN) and Generative Adversarial Networks(GAN) have achieved breakthroughs in the problem of semantic image inpainting, the task of reconstructing missing pixels in given images. While much more effective than conventional approaches, deep learning models require large datasets and great computational resources for training, and inpainting quality varies considerably when training data vary in size and diversity. To address these problems, we present in this paper a inpainting strategy of \\textit{Comparative Sample Augmentation}, which enhances the quality of training set by filtering out irrelevant images and constructing additional images using information about the surrounding regions of the images to be inpainted. Experiments on multiple datasets demonstrate that our method extends the applicability of deep inpainting models to training sets with varying sizes, while maintaining inpainting quality as measured by qualitative and quantitative metrics for a large class of deep models, with little need for model-specific consideration.", "pdf": "/pdf/78c1ab4cbf3df45e5bb44b2f3307fe47842c57b1.pdf", "paperhash": "fang|deep_generative_inpainting_with_comparative_sample_augmentation"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper66/Official_Review", "cdate": 1553713410352, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "Sklsts5H_E", "replyto": "Sklsts5H_E", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper66/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper66/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713410352, "tmdate": 1555511820525, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper66/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "HJlBSMjwYN", "original": null, "number": 2, "cdate": 1554653757005, "ddate": null, "tcdate": 1554653757005, "tmdate": 1555512019990, "tddate": null, "forum": "Sklsts5H_E", "replyto": "Sklsts5H_E", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper66/Official_Review", "content": {"title": "Requires better justification, analysis, and experiments", "review": "Summary:\n\nHelp image inpainting using GANs by two strategies:\n\n1) Comparative Augmenting filter: choose images from a training dataset whose histogram is similar to the image in consideration. Histogram matching is an old trick in the computer vision community.\n\n2) Self-Enrichment: add random noise to each pixel. This seems to be the same as \"Instance Noise\" [1], which the authors did not cite but claim as their own.\n\nThe authors motivate their strategy by saying older methods don't work well in case of non-repetitive backgrounds such as faces, but themselves rely on a global similarity like histogram matching. Highly doubt if this can theoretically work.  Results in the paper show that practically the improvement is negligible.\n\nAuthors mention 3 contributions but do not justify their claims:\n1) Histogram matching - authors don't mention that it is an old trick, and don't justify why this could work. Also, practical results show that it doesn't.\n2) Instance noise - authors don't cite an older paper that proposed the same. Also, practical results show that it doesn't.\n3) Authors mention \"detailed set of experiments\" in the introduction but only include 1 in the experiment section, and say they could not add more due to time constraints.\n\nLiterary errors:\nThere are quite a few word-level errors such as word redundancy, sentence errors, spelling mistakes that make the paper difficult to read.\n\n[1]  \"Instance Noise: A trick for stabilising GAN training\" https://arxiv.org/abs/1610.04490\n", "rating": "1: Strong rejection", "confidence": "3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper66/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper66/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Generative Inpainting with Comparative Sample Augmentation", "authors": ["Boli Fang", "Miao Jiang", "Jerry Shen", "Bjord Stenger"], "authorids": ["bfang@iu.edu", "miajiang@iu.edu", "hashen@iu.edu", "bjord.stenger@rakuten.com"], "keywords": ["Image Inpainting", "Various Datasets"], "TL;DR": "We introduced a strategy which enables inpainting models on datasets of various sizes", "abstract": "Recent advancements in deep learning techniques such as Convolutional Neural Networks(CNN) and Generative Adversarial Networks(GAN) have achieved breakthroughs in the problem of semantic image inpainting, the task of reconstructing missing pixels in given images. While much more effective than conventional approaches, deep learning models require large datasets and great computational resources for training, and inpainting quality varies considerably when training data vary in size and diversity. To address these problems, we present in this paper a inpainting strategy of \\textit{Comparative Sample Augmentation}, which enhances the quality of training set by filtering out irrelevant images and constructing additional images using information about the surrounding regions of the images to be inpainted. Experiments on multiple datasets demonstrate that our method extends the applicability of deep inpainting models to training sets with varying sizes, while maintaining inpainting quality as measured by qualitative and quantitative metrics for a large class of deep models, with little need for model-specific consideration.", "pdf": "/pdf/78c1ab4cbf3df45e5bb44b2f3307fe47842c57b1.pdf", "paperhash": "fang|deep_generative_inpainting_with_comparative_sample_augmentation"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper66/Official_Review", "cdate": 1553713410352, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "Sklsts5H_E", "replyto": "Sklsts5H_E", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper66/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper66/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713410352, "tmdate": 1555511820525, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper66/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "Hygihr1FKN", "original": null, "number": 1, "cdate": 1554736563455, "ddate": null, "tcdate": 1554736563455, "tmdate": 1555510988250, "tddate": null, "forum": "Sklsts5H_E", "replyto": "Sklsts5H_E", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper66/Decision", "content": {"title": "Acceptance Decision", "decision": "Reject"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Generative Inpainting with Comparative Sample Augmentation", "authors": ["Boli Fang", "Miao Jiang", "Jerry Shen", "Bjord Stenger"], "authorids": ["bfang@iu.edu", "miajiang@iu.edu", "hashen@iu.edu", "bjord.stenger@rakuten.com"], "keywords": ["Image Inpainting", "Various Datasets"], "TL;DR": "We introduced a strategy which enables inpainting models on datasets of various sizes", "abstract": "Recent advancements in deep learning techniques such as Convolutional Neural Networks(CNN) and Generative Adversarial Networks(GAN) have achieved breakthroughs in the problem of semantic image inpainting, the task of reconstructing missing pixels in given images. While much more effective than conventional approaches, deep learning models require large datasets and great computational resources for training, and inpainting quality varies considerably when training data vary in size and diversity. To address these problems, we present in this paper a inpainting strategy of \\textit{Comparative Sample Augmentation}, which enhances the quality of training set by filtering out irrelevant images and constructing additional images using information about the surrounding regions of the images to be inpainted. Experiments on multiple datasets demonstrate that our method extends the applicability of deep inpainting models to training sets with varying sizes, while maintaining inpainting quality as measured by qualitative and quantitative metrics for a large class of deep models, with little need for model-specific consideration.", "pdf": "/pdf/78c1ab4cbf3df45e5bb44b2f3307fe47842c57b1.pdf", "paperhash": "fang|deep_generative_inpainting_with_comparative_sample_augmentation"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper66/Decision", "cdate": 1554736071816, "reply": {"forum": "Sklsts5H_E", "replyto": "Sklsts5H_E", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736071816, "tmdate": 1555510967001, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 4}