{"notes": [{"id": "ryex8CEKPr", "original": "HJx_6aIOwB", "number": 1125, "cdate": 1569439303527, "ddate": null, "tcdate": 1569439303527, "tmdate": 1577168239986, "tddate": null, "forum": "ryex8CEKPr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Knockoff-Inspired Feature Selection via Generative Models", "authors": ["Marco F. Duarte", "Siwei Feng"], "authorids": ["mduarte@ecs.umass.edu", "siwei@umass.edu"], "keywords": ["feature selection", "variable selection", "knockoff variables", "supervised learning"], "TL;DR": "We propose a feature selection algorithm for supervised learning inspired by the recently introduced  knockoff framework for variable selection in statistical regression.", "abstract": "We propose a feature selection algorithm for supervised learning inspired by the recently introduced \nknockoff framework for variable selection in statistical regression. While variable selection in statistics aims \nto distinguish between true and false predictors, feature selection in machine learning aims to reduce the \ndimensionality of the data while preserving the performance of the learning method. The knockoff framework \nhas attracted significant interest due to its strong control of false discoveries while preserving predictive \npower. In contrast to the original approach and later variants that assume a given probabilistic model for the \nvariables, our proposed approach relies on data-driven generative models that learn mappings from data \nspace to a parametric space that characterizes the probability distribution of the data. Our approach \nrequires only the availability of mappings from data space to a distribution in parametric space and from \nparametric space to a distribution in data space; thus, it can be integrated with multiple popular generative \nmodels from machine learning. We provide example knockoff designs using a variational autoencoder and \na Gaussian process latent variable model. We also propose a knockoff score metric for a softmax classifier \nthat accounts for the contribution of each feature and its knockoff during supervised learning. Experimental \nresults with multiple benchmark datasets for feature selection showcase the advantages of our knockoff \ndesigns and the knockoff framework with respect to existing approaches.", "pdf": "/pdf/0a4d33f04ee56e8abf99ca4f5d103880dbd7313e.pdf", "paperhash": "duarte|knockoffinspired_feature_selection_via_generative_models", "original_pdf": "/attachment/69dd43c9fc13a4b04ad45750ab3fae1994cf7c31.pdf", "_bibtex": "@misc{\nduarte2020knockoffinspired,\ntitle={Knockoff-Inspired Feature Selection via Generative Models},\nauthor={Marco F. Duarte and Siwei Feng},\nyear={2020},\nurl={https://openreview.net/forum?id=ryex8CEKPr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "OnGRdBQk4G", "original": null, "number": 1, "cdate": 1576798715152, "ddate": null, "tcdate": 1576798715152, "tmdate": 1576800921384, "tddate": null, "forum": "ryex8CEKPr", "replyto": "ryex8CEKPr", "invitation": "ICLR.cc/2020/Conference/Paper1125/-/Decision", "content": {"decision": "Reject", "comment": "This manuscript proposes feature selection inspired by knockoffs, where the generative models are implemented using modern deep generative techniques. The resulting procedure is evaluated in a variety of empirical settings and shown to improve performance.\n\nThe reviewers and AC agree that the problem studied is timely and interesting, as knockoffs combined with generative models have recently shown promise for inferential problems. However, the reviewers were unconvinced about the motivation of the work, and the strength of the empirical evaluation results. In the option of the AC, this work might be improved by focusing (both conceptually and empirically) on applications where inferential variable selection is most relevant e.g. causal settings, healthcare applications, and so on.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Knockoff-Inspired Feature Selection via Generative Models", "authors": ["Marco F. Duarte", "Siwei Feng"], "authorids": ["mduarte@ecs.umass.edu", "siwei@umass.edu"], "keywords": ["feature selection", "variable selection", "knockoff variables", "supervised learning"], "TL;DR": "We propose a feature selection algorithm for supervised learning inspired by the recently introduced  knockoff framework for variable selection in statistical regression.", "abstract": "We propose a feature selection algorithm for supervised learning inspired by the recently introduced \nknockoff framework for variable selection in statistical regression. While variable selection in statistics aims \nto distinguish between true and false predictors, feature selection in machine learning aims to reduce the \ndimensionality of the data while preserving the performance of the learning method. The knockoff framework \nhas attracted significant interest due to its strong control of false discoveries while preserving predictive \npower. In contrast to the original approach and later variants that assume a given probabilistic model for the \nvariables, our proposed approach relies on data-driven generative models that learn mappings from data \nspace to a parametric space that characterizes the probability distribution of the data. Our approach \nrequires only the availability of mappings from data space to a distribution in parametric space and from \nparametric space to a distribution in data space; thus, it can be integrated with multiple popular generative \nmodels from machine learning. We provide example knockoff designs using a variational autoencoder and \na Gaussian process latent variable model. We also propose a knockoff score metric for a softmax classifier \nthat accounts for the contribution of each feature and its knockoff during supervised learning. Experimental \nresults with multiple benchmark datasets for feature selection showcase the advantages of our knockoff \ndesigns and the knockoff framework with respect to existing approaches.", "pdf": "/pdf/0a4d33f04ee56e8abf99ca4f5d103880dbd7313e.pdf", "paperhash": "duarte|knockoffinspired_feature_selection_via_generative_models", "original_pdf": "/attachment/69dd43c9fc13a4b04ad45750ab3fae1994cf7c31.pdf", "_bibtex": "@misc{\nduarte2020knockoffinspired,\ntitle={Knockoff-Inspired Feature Selection via Generative Models},\nauthor={Marco F. Duarte and Siwei Feng},\nyear={2020},\nurl={https://openreview.net/forum?id=ryex8CEKPr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "ryex8CEKPr", "replyto": "ryex8CEKPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795722436, "tmdate": 1576800273734, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1125/-/Decision"}}}, {"id": "rJgnuG3BsS", "original": null, "number": 4, "cdate": 1573401203986, "ddate": null, "tcdate": 1573401203986, "tmdate": 1573401203986, "tddate": null, "forum": "ryex8CEKPr", "replyto": "Hye4vzrzFS", "invitation": "ICLR.cc/2020/Conference/Paper1125/-/Official_Comment", "content": {"title": "Response to Blind Review #3", "comment": "Thank you for your thoughtful comments and careful reading of the manuscript. We have posted a revision to address some of your questions and provide some responses below (matching the order of the comments).\n\nWe agree with the reviewer that the statistical guarantees from the original knockoff variable framework from variable selection does not translate to feature selection, because in machine learning it is seldom the case that the label is independent from a large set of entries of the input vector. Nonetheless, we believe that there is a contribution in applying the knockoff framework to the long-standing feature selection problem in machine learning.\n\nWe relied on datasets and algorithms that have been used in the feature selection literature for the numerical comparison - see the references by J. Li et al. It is apparent that some of these datasets provide significant challenges to all tested feature selection methods, and it is not surprising to us that in some cases one cannot perform feature selection without undergoing significant loss in performance.\n\nThe typo has been corrected."}, "signatures": ["ICLR.cc/2020/Conference/Paper1125/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1125/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Knockoff-Inspired Feature Selection via Generative Models", "authors": ["Marco F. Duarte", "Siwei Feng"], "authorids": ["mduarte@ecs.umass.edu", "siwei@umass.edu"], "keywords": ["feature selection", "variable selection", "knockoff variables", "supervised learning"], "TL;DR": "We propose a feature selection algorithm for supervised learning inspired by the recently introduced  knockoff framework for variable selection in statistical regression.", "abstract": "We propose a feature selection algorithm for supervised learning inspired by the recently introduced \nknockoff framework for variable selection in statistical regression. While variable selection in statistics aims \nto distinguish between true and false predictors, feature selection in machine learning aims to reduce the \ndimensionality of the data while preserving the performance of the learning method. The knockoff framework \nhas attracted significant interest due to its strong control of false discoveries while preserving predictive \npower. In contrast to the original approach and later variants that assume a given probabilistic model for the \nvariables, our proposed approach relies on data-driven generative models that learn mappings from data \nspace to a parametric space that characterizes the probability distribution of the data. Our approach \nrequires only the availability of mappings from data space to a distribution in parametric space and from \nparametric space to a distribution in data space; thus, it can be integrated with multiple popular generative \nmodels from machine learning. We provide example knockoff designs using a variational autoencoder and \na Gaussian process latent variable model. We also propose a knockoff score metric for a softmax classifier \nthat accounts for the contribution of each feature and its knockoff during supervised learning. Experimental \nresults with multiple benchmark datasets for feature selection showcase the advantages of our knockoff \ndesigns and the knockoff framework with respect to existing approaches.", "pdf": "/pdf/0a4d33f04ee56e8abf99ca4f5d103880dbd7313e.pdf", "paperhash": "duarte|knockoffinspired_feature_selection_via_generative_models", "original_pdf": "/attachment/69dd43c9fc13a4b04ad45750ab3fae1994cf7c31.pdf", "_bibtex": "@misc{\nduarte2020knockoffinspired,\ntitle={Knockoff-Inspired Feature Selection via Generative Models},\nauthor={Marco F. Duarte and Siwei Feng},\nyear={2020},\nurl={https://openreview.net/forum?id=ryex8CEKPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryex8CEKPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1125/Authors", "ICLR.cc/2020/Conference/Paper1125/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1125/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1125/Reviewers", "ICLR.cc/2020/Conference/Paper1125/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1125/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1125/Authors|ICLR.cc/2020/Conference/Paper1125/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504160857, "tmdate": 1576860551189, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1125/Authors", "ICLR.cc/2020/Conference/Paper1125/Reviewers", "ICLR.cc/2020/Conference/Paper1125/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1125/-/Official_Comment"}}}, {"id": "HkexfMnHir", "original": null, "number": 3, "cdate": 1573401095958, "ddate": null, "tcdate": 1573401095958, "tmdate": 1573401117491, "tddate": null, "forum": "ryex8CEKPr", "replyto": "Hke1qd36Yr", "invitation": "ICLR.cc/2020/Conference/Paper1125/-/Official_Comment", "content": {"title": "Response to Blind Review #2", "comment": "Thank you for your thoughtful comments and careful reading of the manuscript. We have posted a revision to address some of your questions and provide some responses below (matching the order of the comments).\n\nWe relied on datasets and algorithms that have been used in the feature selection literature for the numerical comparison - see the references by J. Li et al.\n\nThe knockoffs used here can be also used with relevance metrics defined elsewhere for regression and estimation. Furthermore, the DeepPINK relevance scores by Lu et al. (2018) can be adapted to other applications of deep networks in supervised learning. We will attempt to collect results for the same datasets and feature selection schemes using a deep learning classifier with the DeepPINK scores, and will provide updated results (e.g., in an appendix) if results are available by the end of the discussion period.\n\nThe probability statement questioned has been removed as we have changed Lemma 1, but it can be simplified to $p(a,b|c) = p(a|b,c) \\cdot p(b|c)$.\n\nRegarding the independence between knockoff and variables described in p. 2, we make a correction to \u201cthe knockoffs must be independent from the labels to be predicted given the original variables.\u201d\n\nWe slightly changed the description of Step 3 in Algorithm 1, as well as the referenced sentence in Page 5.\n\nThe notation $\\tilde{\\mathbf{x}}_n$ refers to the knockoff vector for the sample $\\mathbf{x}_n$. Non-bold would refer to an entry of a vector $\\mathbf{x}$; we use $\\tilde{x}_{n,j}$ for entries of the former vector. Typos have been corrected. References to Figs. 1(g-h) have been corrected to Figs. 1(d-e). "}, "signatures": ["ICLR.cc/2020/Conference/Paper1125/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1125/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Knockoff-Inspired Feature Selection via Generative Models", "authors": ["Marco F. Duarte", "Siwei Feng"], "authorids": ["mduarte@ecs.umass.edu", "siwei@umass.edu"], "keywords": ["feature selection", "variable selection", "knockoff variables", "supervised learning"], "TL;DR": "We propose a feature selection algorithm for supervised learning inspired by the recently introduced  knockoff framework for variable selection in statistical regression.", "abstract": "We propose a feature selection algorithm for supervised learning inspired by the recently introduced \nknockoff framework for variable selection in statistical regression. While variable selection in statistics aims \nto distinguish between true and false predictors, feature selection in machine learning aims to reduce the \ndimensionality of the data while preserving the performance of the learning method. The knockoff framework \nhas attracted significant interest due to its strong control of false discoveries while preserving predictive \npower. In contrast to the original approach and later variants that assume a given probabilistic model for the \nvariables, our proposed approach relies on data-driven generative models that learn mappings from data \nspace to a parametric space that characterizes the probability distribution of the data. Our approach \nrequires only the availability of mappings from data space to a distribution in parametric space and from \nparametric space to a distribution in data space; thus, it can be integrated with multiple popular generative \nmodels from machine learning. We provide example knockoff designs using a variational autoencoder and \na Gaussian process latent variable model. We also propose a knockoff score metric for a softmax classifier \nthat accounts for the contribution of each feature and its knockoff during supervised learning. Experimental \nresults with multiple benchmark datasets for feature selection showcase the advantages of our knockoff \ndesigns and the knockoff framework with respect to existing approaches.", "pdf": "/pdf/0a4d33f04ee56e8abf99ca4f5d103880dbd7313e.pdf", "paperhash": "duarte|knockoffinspired_feature_selection_via_generative_models", "original_pdf": "/attachment/69dd43c9fc13a4b04ad45750ab3fae1994cf7c31.pdf", "_bibtex": "@misc{\nduarte2020knockoffinspired,\ntitle={Knockoff-Inspired Feature Selection via Generative Models},\nauthor={Marco F. Duarte and Siwei Feng},\nyear={2020},\nurl={https://openreview.net/forum?id=ryex8CEKPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryex8CEKPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1125/Authors", "ICLR.cc/2020/Conference/Paper1125/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1125/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1125/Reviewers", "ICLR.cc/2020/Conference/Paper1125/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1125/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1125/Authors|ICLR.cc/2020/Conference/Paper1125/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504160857, "tmdate": 1576860551189, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1125/Authors", "ICLR.cc/2020/Conference/Paper1125/Reviewers", "ICLR.cc/2020/Conference/Paper1125/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1125/-/Official_Comment"}}}, {"id": "HyeQfbhrjH", "original": null, "number": 2, "cdate": 1573400842891, "ddate": null, "tcdate": 1573400842891, "tmdate": 1573400842891, "tddate": null, "forum": "ryex8CEKPr", "replyto": "SJgD5mIQqH", "invitation": "ICLR.cc/2020/Conference/Paper1125/-/Official_Comment", "content": {"title": "Response to Blind Review 1", "comment": "Thank you for your thoughtful comments and careful reading of the manuscript. We have posted a revision to address some of your questions and provide some responses below (matching the order of the comments).\n\nThere are cases where selecting dimensions of the original data, rather than processing them, is desirable - e.g., if the dimensions of the data have semantic meaning or the application benefits from explainability in the decision making process.\n\nRegarding images (and other signals), we do agree it would make sense to provide a comparison with downsampled input vectors. Thus, we have tested regular-interval downsampling as an alternative to data-dependent feature selection.\n\nThanks for pointing out the mistake in Lemma 1. We have changed the lemma to better motivate the choice of marginalization in the VAE.\n\nNote that Lu et al. (2018) does not introduce a knockoff variable construction, but rather introduces a relevance score designed for deep learning-based estimation. The score proposed here for a softmax classifier is similar in spirit to that of Lu et al.\n\nThe latent dimensionalities of the models tested were selected by evaluation of the quality of the reconstructions obtained from the original data. We have added this information to the manuscript.\n\nIn the first sentence of the introduction, we replace \u201cprevalence\u201d by \u201cavailability\u201d. We also corrected typos. \n\nWe conjecture that GPLVM requires a more dense sampling of the assumed data manifold in order to provide good generalizations for some of the datasets used."}, "signatures": ["ICLR.cc/2020/Conference/Paper1125/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1125/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Knockoff-Inspired Feature Selection via Generative Models", "authors": ["Marco F. Duarte", "Siwei Feng"], "authorids": ["mduarte@ecs.umass.edu", "siwei@umass.edu"], "keywords": ["feature selection", "variable selection", "knockoff variables", "supervised learning"], "TL;DR": "We propose a feature selection algorithm for supervised learning inspired by the recently introduced  knockoff framework for variable selection in statistical regression.", "abstract": "We propose a feature selection algorithm for supervised learning inspired by the recently introduced \nknockoff framework for variable selection in statistical regression. While variable selection in statistics aims \nto distinguish between true and false predictors, feature selection in machine learning aims to reduce the \ndimensionality of the data while preserving the performance of the learning method. The knockoff framework \nhas attracted significant interest due to its strong control of false discoveries while preserving predictive \npower. In contrast to the original approach and later variants that assume a given probabilistic model for the \nvariables, our proposed approach relies on data-driven generative models that learn mappings from data \nspace to a parametric space that characterizes the probability distribution of the data. Our approach \nrequires only the availability of mappings from data space to a distribution in parametric space and from \nparametric space to a distribution in data space; thus, it can be integrated with multiple popular generative \nmodels from machine learning. We provide example knockoff designs using a variational autoencoder and \na Gaussian process latent variable model. We also propose a knockoff score metric for a softmax classifier \nthat accounts for the contribution of each feature and its knockoff during supervised learning. Experimental \nresults with multiple benchmark datasets for feature selection showcase the advantages of our knockoff \ndesigns and the knockoff framework with respect to existing approaches.", "pdf": "/pdf/0a4d33f04ee56e8abf99ca4f5d103880dbd7313e.pdf", "paperhash": "duarte|knockoffinspired_feature_selection_via_generative_models", "original_pdf": "/attachment/69dd43c9fc13a4b04ad45750ab3fae1994cf7c31.pdf", "_bibtex": "@misc{\nduarte2020knockoffinspired,\ntitle={Knockoff-Inspired Feature Selection via Generative Models},\nauthor={Marco F. Duarte and Siwei Feng},\nyear={2020},\nurl={https://openreview.net/forum?id=ryex8CEKPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryex8CEKPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1125/Authors", "ICLR.cc/2020/Conference/Paper1125/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1125/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1125/Reviewers", "ICLR.cc/2020/Conference/Paper1125/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1125/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1125/Authors|ICLR.cc/2020/Conference/Paper1125/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504160857, "tmdate": 1576860551189, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1125/Authors", "ICLR.cc/2020/Conference/Paper1125/Reviewers", "ICLR.cc/2020/Conference/Paper1125/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1125/-/Official_Comment"}}}, {"id": "Hye4vzrzFS", "original": null, "number": 1, "cdate": 1571078747977, "ddate": null, "tcdate": 1571078747977, "tmdate": 1572972509584, "tddate": null, "forum": "ryex8CEKPr", "replyto": "ryex8CEKPr", "invitation": "ICLR.cc/2020/Conference/Paper1125/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published one or two papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper proposes a new feature selection method by integrating the knockoff procedure and generative models.\nThe paper is clearly written and easy to read. However, I have the following concerns:\n\n- The motivation is not clear. The advantage of the knockoff procedure is that it can find relevant features (variables) with statistical guarantees such as FDRs, which is clearly discussed in the paper.\n    However, the objective of this paper is to design a better feature selection method for prediction, where the statistical guarantee is usually not important.\n    Hence the advantage of using the knockoff procedure is not clear.\n- In addition to the above issue, the empirical performance of the proposed method is not convincing.\n    In experiments, Figure 2 shows that the proposed approach does not have significant advantage compared to existing methods.\n    It seems that this is a natural consequence as the knockoff procedure is not designed for feature selection.\n    Thus, in its current state, the advantage of the proposed approach is not well presented.\n- Also, the proposed approach is not theoretically analyzed.\n    Since the proposed method is based on the knockoff procedure, it would be interesting if there is some statistical guarantee for the selected features.\n\nMinor comments:\n- P.5, L.-4: \"SInce\" -> \"Since\"\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1125/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1125/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Knockoff-Inspired Feature Selection via Generative Models", "authors": ["Marco F. Duarte", "Siwei Feng"], "authorids": ["mduarte@ecs.umass.edu", "siwei@umass.edu"], "keywords": ["feature selection", "variable selection", "knockoff variables", "supervised learning"], "TL;DR": "We propose a feature selection algorithm for supervised learning inspired by the recently introduced  knockoff framework for variable selection in statistical regression.", "abstract": "We propose a feature selection algorithm for supervised learning inspired by the recently introduced \nknockoff framework for variable selection in statistical regression. While variable selection in statistics aims \nto distinguish between true and false predictors, feature selection in machine learning aims to reduce the \ndimensionality of the data while preserving the performance of the learning method. The knockoff framework \nhas attracted significant interest due to its strong control of false discoveries while preserving predictive \npower. In contrast to the original approach and later variants that assume a given probabilistic model for the \nvariables, our proposed approach relies on data-driven generative models that learn mappings from data \nspace to a parametric space that characterizes the probability distribution of the data. Our approach \nrequires only the availability of mappings from data space to a distribution in parametric space and from \nparametric space to a distribution in data space; thus, it can be integrated with multiple popular generative \nmodels from machine learning. We provide example knockoff designs using a variational autoencoder and \na Gaussian process latent variable model. We also propose a knockoff score metric for a softmax classifier \nthat accounts for the contribution of each feature and its knockoff during supervised learning. Experimental \nresults with multiple benchmark datasets for feature selection showcase the advantages of our knockoff \ndesigns and the knockoff framework with respect to existing approaches.", "pdf": "/pdf/0a4d33f04ee56e8abf99ca4f5d103880dbd7313e.pdf", "paperhash": "duarte|knockoffinspired_feature_selection_via_generative_models", "original_pdf": "/attachment/69dd43c9fc13a4b04ad45750ab3fae1994cf7c31.pdf", "_bibtex": "@misc{\nduarte2020knockoffinspired,\ntitle={Knockoff-Inspired Feature Selection via Generative Models},\nauthor={Marco F. Duarte and Siwei Feng},\nyear={2020},\nurl={https://openreview.net/forum?id=ryex8CEKPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryex8CEKPr", "replyto": "ryex8CEKPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1125/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1125/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576134401742, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1125/Reviewers"], "noninvitees": [], "tcdate": 1570237742004, "tmdate": 1576134401757, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1125/-/Official_Review"}}}, {"id": "Hke1qd36Yr", "original": null, "number": 2, "cdate": 1571829895228, "ddate": null, "tcdate": 1571829895228, "tmdate": 1572972509548, "tddate": null, "forum": "ryex8CEKPr", "replyto": "ryex8CEKPr", "invitation": "ICLR.cc/2020/Conference/Paper1125/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "This paper presents an interesting use of a knockoff framework similar to that of model-X knockoffs (Candes et al., 2018) in generative models like VAE and GPLVM for feature selection in supervised learning. \n\nOn the flip side, it is really hard to tell from the experimental results (Fig. 2) what performance benefits their proposed designs bring over the state of the art. I would encourage the authors to provide a more detailed analysis of the conditions under which their proposed designs would outperform the state of the art (or not). The author should consider presenting their results through other means that can better highlight the performance benefits of their proposed designs.\n\nBesides applying their knockoff designs to a softmax classifier, can the authors provide examples of applications to other supervised learning models?\n \n\nProof of Lemma 1: Without further assumptions from that stated in the lemma, can the authors provide a derivation (or result that they've used) and explanation for the mean vector and covariance matrix of the joint probability p(z,x_n|x_{\u2212n}) = p(z|x)p(x_n|x_{\u2212n})? In particular, why are z and x_n conditionally independent given x_{-n}, as reflected in their zero covariance value?\n\n\nPage 2: The authors say that \"they must be independent from the labels to be predicted\". Shouldn't it be conditionally independent (2nd paragraph, page 3) instead?\n\n\n\nMinor issues\nPage 5: The notation of tilde{bold{x}}_n is ambiguous since the subscript is used to index the data sample (page 2). Is it intended to be without a bold?\n\nStep 3 of Algorithm 1: I would have preferred that it is stated consistently with that in the main text (step i in 2nd paragraph of Section 3).\n\nPage 5: This sentence is difficult to parse: \"the training dataset for the generative models used to compute new knockoffs sample values is trained over the original data samples\".\n\nPage 5: SInce?\n\nPage 6: I cannot find Figure 1(g) and Figure 1(h)."}, "signatures": ["ICLR.cc/2020/Conference/Paper1125/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1125/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Knockoff-Inspired Feature Selection via Generative Models", "authors": ["Marco F. Duarte", "Siwei Feng"], "authorids": ["mduarte@ecs.umass.edu", "siwei@umass.edu"], "keywords": ["feature selection", "variable selection", "knockoff variables", "supervised learning"], "TL;DR": "We propose a feature selection algorithm for supervised learning inspired by the recently introduced  knockoff framework for variable selection in statistical regression.", "abstract": "We propose a feature selection algorithm for supervised learning inspired by the recently introduced \nknockoff framework for variable selection in statistical regression. While variable selection in statistics aims \nto distinguish between true and false predictors, feature selection in machine learning aims to reduce the \ndimensionality of the data while preserving the performance of the learning method. The knockoff framework \nhas attracted significant interest due to its strong control of false discoveries while preserving predictive \npower. In contrast to the original approach and later variants that assume a given probabilistic model for the \nvariables, our proposed approach relies on data-driven generative models that learn mappings from data \nspace to a parametric space that characterizes the probability distribution of the data. Our approach \nrequires only the availability of mappings from data space to a distribution in parametric space and from \nparametric space to a distribution in data space; thus, it can be integrated with multiple popular generative \nmodels from machine learning. We provide example knockoff designs using a variational autoencoder and \na Gaussian process latent variable model. We also propose a knockoff score metric for a softmax classifier \nthat accounts for the contribution of each feature and its knockoff during supervised learning. Experimental \nresults with multiple benchmark datasets for feature selection showcase the advantages of our knockoff \ndesigns and the knockoff framework with respect to existing approaches.", "pdf": "/pdf/0a4d33f04ee56e8abf99ca4f5d103880dbd7313e.pdf", "paperhash": "duarte|knockoffinspired_feature_selection_via_generative_models", "original_pdf": "/attachment/69dd43c9fc13a4b04ad45750ab3fae1994cf7c31.pdf", "_bibtex": "@misc{\nduarte2020knockoffinspired,\ntitle={Knockoff-Inspired Feature Selection via Generative Models},\nauthor={Marco F. Duarte and Siwei Feng},\nyear={2020},\nurl={https://openreview.net/forum?id=ryex8CEKPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryex8CEKPr", "replyto": "ryex8CEKPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1125/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1125/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576134401742, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1125/Reviewers"], "noninvitees": [], "tcdate": 1570237742004, "tmdate": 1576134401757, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1125/-/Official_Review"}}}, {"id": "SJgD5mIQqH", "original": null, "number": 3, "cdate": 1572197262735, "ddate": null, "tcdate": 1572197262735, "tmdate": 1572972509505, "tddate": null, "forum": "ryex8CEKPr", "replyto": "ryex8CEKPr", "invitation": "ICLR.cc/2020/Conference/Paper1125/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes a way of employing modern generative models like VAEs and GPLVMs within the recently popular \u201cknockoff\u201d framework for variable/feature selection. Roughly speaking, the main idea of knockoffs is to construct a duplicate (\u201cknockoff\u201d) of each regression variable which matches its distributional properties but is independent of the response variable when conditioning on the true input variable the knockoff is based on. Under certain assumptions, fitting a model on top of both original and knocked-off features and observing the difference between the fitted coefficients for the true and the knockoff features can then be used for variable selection with guaranteed false discovery rate. The authors of this paper suggest that many of the current methods for construction of knockoffs may not be appropriate for image, text, and other types of datasets commonly used in modern ML, and suggest a heuristic way of employing VAEs and GPLVMs for this purpose. The paper concludes with an empirical study which shows that their algorithm is competitive with existing feature selections methods in terms of post-selection accuracy of the fitted model.\n\nI am currently leaning towards recommending rejection. While the paper is nicely written and does a good job of reviewing knockoffs, I see two main issues: (1) I am not sure about applications for the proposed algorithm; in particular, the authors allude to use on devices with limited memory and computational power, but do not discuss why the Johnson-Lindenstrauss transform or some of the many low-precision implementations of neural networks (binarised neural networks, xnor-nets, \u2026) cannot be used; furthermore, in the case of images, I am not sure why there is no comparison to simple downsampling to a smaller resolution; (2) The reported results do not show a reliable improvements over existing methods.\n\n\nMajor comments:\n\n- I am not entirely sure lemma 1 is correct. In particular, mu_{z | x} tends to be a function of the whole vector x including x_n. For example, if (a, b) are jointly distributed according to a bivariate normal, then E (b | a) = E(b) + Sigma_{ab} Sigma_{aa}^{-1} (a - E(a)) where Sigma is the corresponding covariance matrix. Hence claiming that the marginal distribution z | x_{-n} is N ( mu_{z|x} , Sigma_{z | x} ) seems wrong as mu_{z | x} will generally depend on x_n (similarly to how E(b | a) depends on \u201ca\u201d above) which cannot be the case when x_n is marginalised. If z depends linearly on x, there is a standard expression for the distribution you seek. However, with the non-linear dependence employed, e.g., within VAE, working out a closed form expression may be quite a challenge. Can you please clarify or drop this result from your paper if it indeed turns out incorrect?\n\n- Can you please clarify why don\u2019t you benchmark against the cited algorithm proposed in Lu et al. (2018)?\n\n- Can you please explain how was the latent dimensionality for the VAEs (5) and GPLVMs (10) selected? Also, for the algorithms where random seed plays a role (e.g., VAEs), how many random seeds were used (are the numbers reported in fig.2 a result of averaging over multiple seeds)? Relatedly, have you tested whether starting from different seeds results in the same subset of variables selected (e.g., when using VAEs)?\n\n\nMinor comments:\n\n- In the 1st sentence of the introduction, \u201cprevalence\u201d can be high or low, increase or decrease, etc. but \u201cbecoming increasingly pervasive\u201d does not sound right. Please consider rewording.\n\n- In fig.1e, do you know why GPLVM leads to such a significant mode collapse?\n\n- Just after the 1st display on p.5, \u201cSInce\u201d -> \u201cSince\u201d"}, "signatures": ["ICLR.cc/2020/Conference/Paper1125/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1125/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Knockoff-Inspired Feature Selection via Generative Models", "authors": ["Marco F. Duarte", "Siwei Feng"], "authorids": ["mduarte@ecs.umass.edu", "siwei@umass.edu"], "keywords": ["feature selection", "variable selection", "knockoff variables", "supervised learning"], "TL;DR": "We propose a feature selection algorithm for supervised learning inspired by the recently introduced  knockoff framework for variable selection in statistical regression.", "abstract": "We propose a feature selection algorithm for supervised learning inspired by the recently introduced \nknockoff framework for variable selection in statistical regression. While variable selection in statistics aims \nto distinguish between true and false predictors, feature selection in machine learning aims to reduce the \ndimensionality of the data while preserving the performance of the learning method. The knockoff framework \nhas attracted significant interest due to its strong control of false discoveries while preserving predictive \npower. In contrast to the original approach and later variants that assume a given probabilistic model for the \nvariables, our proposed approach relies on data-driven generative models that learn mappings from data \nspace to a parametric space that characterizes the probability distribution of the data. Our approach \nrequires only the availability of mappings from data space to a distribution in parametric space and from \nparametric space to a distribution in data space; thus, it can be integrated with multiple popular generative \nmodels from machine learning. We provide example knockoff designs using a variational autoencoder and \na Gaussian process latent variable model. We also propose a knockoff score metric for a softmax classifier \nthat accounts for the contribution of each feature and its knockoff during supervised learning. Experimental \nresults with multiple benchmark datasets for feature selection showcase the advantages of our knockoff \ndesigns and the knockoff framework with respect to existing approaches.", "pdf": "/pdf/0a4d33f04ee56e8abf99ca4f5d103880dbd7313e.pdf", "paperhash": "duarte|knockoffinspired_feature_selection_via_generative_models", "original_pdf": "/attachment/69dd43c9fc13a4b04ad45750ab3fae1994cf7c31.pdf", "_bibtex": "@misc{\nduarte2020knockoffinspired,\ntitle={Knockoff-Inspired Feature Selection via Generative Models},\nauthor={Marco F. Duarte and Siwei Feng},\nyear={2020},\nurl={https://openreview.net/forum?id=ryex8CEKPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryex8CEKPr", "replyto": "ryex8CEKPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1125/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1125/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576134401742, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1125/Reviewers"], "noninvitees": [], "tcdate": 1570237742004, "tmdate": 1576134401757, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1125/-/Official_Review"}}}], "count": 8}