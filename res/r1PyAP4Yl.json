{"notes": [{"tddate": null, "ddate": null, "cdate": null, "original": null, "tmdate": 1490028587025, "tcdate": 1490028587025, "number": 1, "id": "H1XN_FToe", "invitation": "ICLR.cc/2017/workshop/-/paper81/acceptance", "forum": "r1PyAP4Yl", "replyto": "r1PyAP4Yl", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Clustering: Concatenating Layers for Better Projections", "abstract": "Effective clustering can be achieved by mapping the input to an embedded space rather than clustering on the raw data itself. However, there is limited focus on transformation methods that improve clustering accuracies. In this paper, we introduce Neural Clustering, a simple yet effective unsupervised model to project data onto an embedded space where intermediate layers of a deep autoencoder are concatenated to generate high-dimensional representations. Optimization of the autoencoder via reconstruction error allows the layers in the network to learn semantic representations of different classes of data. Our experimental results yield significant improvements on other models and a robustness across different kinds of datasets.", "pdf": "/pdf/1eab8f0e25822eee6b981db6abdb5977f73c457c.pdf", "TL;DR": "We introduce a simple yet effective technique for projecting data that allows for better clustering.", "paperhash": "saito|neural_clustering_concatenating_layers_for_better_projections", "conflicts": ["u.yale-nus.edu.sg"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Sean Saito", "Robby T. Tan"], "authorids": ["sean.saito@u.yale-nus.edu.sg", "robby.tan@u.yale-nus.edu.sg"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1490028587556, "id": "ICLR.cc/2017/workshop/-/paper81/acceptance", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "r1PyAP4Yl", "replyto": "r1PyAP4Yl", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept", "Reject"]}}}, "nonreaders": [], "cdate": 1490028587556}}}, {"tddate": null, "tmdate": 1489186297090, "tcdate": 1489186297090, "number": 2, "id": "r1WW0iesg", "invitation": "ICLR.cc/2017/workshop/-/paper81/official/review", "forum": "r1PyAP4Yl", "replyto": "r1PyAP4Yl", "signatures": ["ICLR.cc/2017/workshop/paper81/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper81/AnonReviewer2"], "content": {"title": "", "rating": "4: Ok but not good enough - rejection", "review": "Even though I enjoy the main idea of concatenating multiple layer information into an embedding for the purpose of clustering, I think this papers needs more work before acceptance.\n\n- As I pointed out earlier, the presentation of the paper is a bit confusing.\n- Some of the experiments and some of the follow-up discussion does not seem faithful to the task of clustering. Directly passing concatenated embeddings to kNN might be used to measure the quality of those with respect to classification, but this skips clustering step entirely. Instead of this, one can use clustering performance directly (using appropriate metrics) or by clustering first into K clusters and then using cluster assignments as the instance representation used during classification.\n- Following the point above, when you say you don't need to know the number of clusters beforehand because you pass embeddings directly to the classification method, I don't follow. What constitutes a cluster in this instance?\n- I was also curious about how it would perform when you have only the topmost encoding layer (or an arbitrary one) compared to using all, since you claim in Section 2.2. this way yields more complex representations?", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Clustering: Concatenating Layers for Better Projections", "abstract": "Effective clustering can be achieved by mapping the input to an embedded space rather than clustering on the raw data itself. However, there is limited focus on transformation methods that improve clustering accuracies. In this paper, we introduce Neural Clustering, a simple yet effective unsupervised model to project data onto an embedded space where intermediate layers of a deep autoencoder are concatenated to generate high-dimensional representations. Optimization of the autoencoder via reconstruction error allows the layers in the network to learn semantic representations of different classes of data. Our experimental results yield significant improvements on other models and a robustness across different kinds of datasets.", "pdf": "/pdf/1eab8f0e25822eee6b981db6abdb5977f73c457c.pdf", "TL;DR": "We introduce a simple yet effective technique for projecting data that allows for better clustering.", "paperhash": "saito|neural_clustering_concatenating_layers_for_better_projections", "conflicts": ["u.yale-nus.edu.sg"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Sean Saito", "Robby T. Tan"], "authorids": ["sean.saito@u.yale-nus.edu.sg", "robby.tan@u.yale-nus.edu.sg"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489186297757, "id": "ICLR.cc/2017/workshop/-/paper81/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper81/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper81/AnonReviewer1", "ICLR.cc/2017/workshop/paper81/AnonReviewer2"], "reply": {"forum": "r1PyAP4Yl", "replyto": "r1PyAP4Yl", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper81/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper81/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489186297757}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1489039856533, "tcdate": 1487334878583, "number": 81, "id": "r1PyAP4Yl", "invitation": "ICLR.cc/2017/workshop/-/submission", "forum": "r1PyAP4Yl", "signatures": ["~Sean_Saito1"], "readers": ["everyone"], "content": {"title": "Neural Clustering: Concatenating Layers for Better Projections", "abstract": "Effective clustering can be achieved by mapping the input to an embedded space rather than clustering on the raw data itself. However, there is limited focus on transformation methods that improve clustering accuracies. In this paper, we introduce Neural Clustering, a simple yet effective unsupervised model to project data onto an embedded space where intermediate layers of a deep autoencoder are concatenated to generate high-dimensional representations. Optimization of the autoencoder via reconstruction error allows the layers in the network to learn semantic representations of different classes of data. Our experimental results yield significant improvements on other models and a robustness across different kinds of datasets.", "pdf": "/pdf/1eab8f0e25822eee6b981db6abdb5977f73c457c.pdf", "TL;DR": "We introduce a simple yet effective technique for projecting data that allows for better clustering.", "paperhash": "saito|neural_clustering_concatenating_layers_for_better_projections", "conflicts": ["u.yale-nus.edu.sg"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Sean Saito", "Robby T. Tan"], "authorids": ["sean.saito@u.yale-nus.edu.sg", "robby.tan@u.yale-nus.edu.sg"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1487690420000, "tmdate": 1484242559574, "id": "ICLR.cc/2017/workshop/-/submission", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1495466420000, "cdate": 1484242559574}}}, {"tddate": null, "nonreaders": null, "tmdate": 1489039830108, "tcdate": 1489037375554, "number": 5, "id": "BkvBdD0ce", "invitation": "ICLR.cc/2017/workshop/-/paper81/public/comment", "forum": "r1PyAP4Yl", "replyto": "SkuaTA6cl", "signatures": ["~Sean_Saito1"], "readers": ["everyone"], "writers": ["~Sean_Saito1"], "content": {"title": "Re: Follow Up", "comment": "Hi Jianwei & Reviewer,\n\nApologies for the late reply and thank you for the feedback/review.\n\nYes, I've somehow confused classification accuracy for clustering accuracy. k-NN is used for the former, and I would use NMI for the latter.\n\n>>> - What is k-means in Table 1? What is dec?\n\nFor K-Means I set k= # of classes. DEC is Deep Embedded Clustering, taken from this paper https://arxiv.org/abs/1511.06335.\n\n>>>- If you are passing your concatenated representations directly to k-NN which is a classification method, where do you achieve clustering?\n\nYes, the concatenated representations are used directly for classification. I will upload a revised version that hopefully clarifies the confusion.\n\nThank you.\n\nSean"}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Clustering: Concatenating Layers for Better Projections", "abstract": "Effective clustering can be achieved by mapping the input to an embedded space rather than clustering on the raw data itself. However, there is limited focus on transformation methods that improve clustering accuracies. In this paper, we introduce Neural Clustering, a simple yet effective unsupervised model to project data onto an embedded space where intermediate layers of a deep autoencoder are concatenated to generate high-dimensional representations. Optimization of the autoencoder via reconstruction error allows the layers in the network to learn semantic representations of different classes of data. Our experimental results yield significant improvements on other models and a robustness across different kinds of datasets.", "pdf": "/pdf/1eab8f0e25822eee6b981db6abdb5977f73c457c.pdf", "TL;DR": "We introduce a simple yet effective technique for projecting data that allows for better clustering.", "paperhash": "saito|neural_clustering_concatenating_layers_for_better_projections", "conflicts": ["u.yale-nus.edu.sg"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Sean Saito", "Robby T. Tan"], "authorids": ["sean.saito@u.yale-nus.edu.sg", "robby.tan@u.yale-nus.edu.sg"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487334879244, "tcdate": 1487334879244, "id": "ICLR.cc/2017/workshop/-/paper81/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper81/reviewers"], "reply": {"forum": "r1PyAP4Yl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487334879244}}}, {"tddate": null, "tmdate": 1489036509788, "tcdate": 1489036509788, "number": 1, "id": "ByLyBvRqg", "invitation": "ICLR.cc/2017/workshop/-/paper81/official/review", "forum": "r1PyAP4Yl", "replyto": "r1PyAP4Yl", "signatures": ["ICLR.cc/2017/workshop/paper81/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper81/AnonReviewer1"], "content": {"title": "more details on the experimentation required", "rating": "5: Marginally below acceptance threshold", "review": "The idea of using concatenation of layer outputs as input to deeper layers was introduced in supervised learning context in works like Highway Networks. They show that combination of representations from different layers can lead to better discriminative features resulting in better classification performance.\n\nIn this work a similar approach is used in the context of unsupervised clustering. A deep convolutional autoencoder is trained on the data and combination of multiple layer representations is used for clustering. The approach seems quite intuitive and straight forward. Regarding the experiments, I have following questions,\n\nassuming that the clustering accuracies is classification performance,\n\nIs the classifier in every experiment a k-NN?\nHow is k chosen for k-NN and k-means experiments?\nWhat is the performance when k-NN is applied on individual layer representations from convolutional autoencoder rather than on combination?\n\nAlso there are previous works which in detail talk of autoencoder methods as clustering approaches. for example,\nhttp://www.jmlr.org/proceedings/papers/v27/baldi12a/baldi12a.pdf\n\n\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Clustering: Concatenating Layers for Better Projections", "abstract": "Effective clustering can be achieved by mapping the input to an embedded space rather than clustering on the raw data itself. However, there is limited focus on transformation methods that improve clustering accuracies. In this paper, we introduce Neural Clustering, a simple yet effective unsupervised model to project data onto an embedded space where intermediate layers of a deep autoencoder are concatenated to generate high-dimensional representations. Optimization of the autoencoder via reconstruction error allows the layers in the network to learn semantic representations of different classes of data. Our experimental results yield significant improvements on other models and a robustness across different kinds of datasets.", "pdf": "/pdf/1eab8f0e25822eee6b981db6abdb5977f73c457c.pdf", "TL;DR": "We introduce a simple yet effective technique for projecting data that allows for better clustering.", "paperhash": "saito|neural_clustering_concatenating_layers_for_better_projections", "conflicts": ["u.yale-nus.edu.sg"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Sean Saito", "Robby T. Tan"], "authorids": ["sean.saito@u.yale-nus.edu.sg", "robby.tan@u.yale-nus.edu.sg"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1489183200000, "tmdate": 1489186297757, "id": "ICLR.cc/2017/workshop/-/paper81/official/review", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/workshop/paper81/reviewers"], "noninvitees": ["ICLR.cc/2017/workshop/paper81/AnonReviewer1", "ICLR.cc/2017/workshop/paper81/AnonReviewer2"], "reply": {"forum": "r1PyAP4Yl", "replyto": "r1PyAP4Yl", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper81/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper81/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,5000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1496959200000, "cdate": 1489186297757}}}, {"tddate": null, "tmdate": 1489002796265, "tcdate": 1489002796265, "number": 4, "id": "S14NZJC9g", "invitation": "ICLR.cc/2017/workshop/-/paper81/public/comment", "forum": "r1PyAP4Yl", "replyto": "r1PyAP4Yl", "signatures": ["~Pierre-Alexandre_Mattei1"], "readers": ["everyone"], "writers": ["~Pierre-Alexandre_Mattei1"], "content": {"title": "Convolutional autoencoder", "comment": "Hi, congrats for this thought-provoking work !\n\nWhat kind of architecture did you use regarding the deep convolutional autoencoder ?\n\nWe also submitted a \"deep clustering paper\" to this workshop, \"Deep Adversarial Gaussian Mixture Auto-Encoder for Clustering\". Another interesting paper on the subject is\n\n\"Variational Deep Embedding: A Generative Approach to Clustering\", Jiang et al. (arxiv.org/abs/1611.05148)\n\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Clustering: Concatenating Layers for Better Projections", "abstract": "Effective clustering can be achieved by mapping the input to an embedded space rather than clustering on the raw data itself. However, there is limited focus on transformation methods that improve clustering accuracies. In this paper, we introduce Neural Clustering, a simple yet effective unsupervised model to project data onto an embedded space where intermediate layers of a deep autoencoder are concatenated to generate high-dimensional representations. Optimization of the autoencoder via reconstruction error allows the layers in the network to learn semantic representations of different classes of data. Our experimental results yield significant improvements on other models and a robustness across different kinds of datasets.", "pdf": "/pdf/1eab8f0e25822eee6b981db6abdb5977f73c457c.pdf", "TL;DR": "We introduce a simple yet effective technique for projecting data that allows for better clustering.", "paperhash": "saito|neural_clustering_concatenating_layers_for_better_projections", "conflicts": ["u.yale-nus.edu.sg"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Sean Saito", "Robby T. Tan"], "authorids": ["sean.saito@u.yale-nus.edu.sg", "robby.tan@u.yale-nus.edu.sg"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487334879244, "tcdate": 1487334879244, "id": "ICLR.cc/2017/workshop/-/paper81/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper81/reviewers"], "reply": {"forum": "r1PyAP4Yl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487334879244}}}, {"tddate": null, "tmdate": 1489001919670, "tcdate": 1489001919670, "number": 1, "id": "SkuaTA6cl", "invitation": "ICLR.cc/2017/workshop/-/paper81/official/comment", "forum": "r1PyAP4Yl", "replyto": "B1bDrZqtx", "signatures": ["ICLR.cc/2017/workshop/paper81/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/workshop/paper81/AnonReviewer2"], "content": {"title": "Follow-up", "comment": "I have the same questions as Jianwei, I hope you can address these issues since it will constitute a major part of my review.\n\n- Clustering and classification seem to be used almost interchangeably throughout the paper. Can you clarify these concepts? What do you formally mean when you say clustering accuracy? How is it different than classification accuracy?\n\n- What is k-means in Table 1? What is dec?\n\n- If you are passing your concatenated representations directly to k-NN which is a classification method, where do you achieve clustering?\n\nThanks."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Clustering: Concatenating Layers for Better Projections", "abstract": "Effective clustering can be achieved by mapping the input to an embedded space rather than clustering on the raw data itself. However, there is limited focus on transformation methods that improve clustering accuracies. In this paper, we introduce Neural Clustering, a simple yet effective unsupervised model to project data onto an embedded space where intermediate layers of a deep autoencoder are concatenated to generate high-dimensional representations. Optimization of the autoencoder via reconstruction error allows the layers in the network to learn semantic representations of different classes of data. Our experimental results yield significant improvements on other models and a robustness across different kinds of datasets.", "pdf": "/pdf/1eab8f0e25822eee6b981db6abdb5977f73c457c.pdf", "TL;DR": "We introduce a simple yet effective technique for projecting data that allows for better clustering.", "paperhash": "saito|neural_clustering_concatenating_layers_for_better_projections", "conflicts": ["u.yale-nus.edu.sg"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Sean Saito", "Robby T. Tan"], "authorids": ["sean.saito@u.yale-nus.edu.sg", "robby.tan@u.yale-nus.edu.sg"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487334879235, "tcdate": 1487334879235, "id": "ICLR.cc/2017/workshop/-/paper81/official/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "reply": {"forum": "r1PyAP4Yl", "writers": {"values-regex": "ICLR.cc/2017/workshop/paper81/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/workshop/paper81/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2017/workshop/paper81/reviewers", "ICLR.cc/2017/workshop/paper81/areachairs"], "cdate": 1487334879235}}}, {"tddate": null, "nonreaders": null, "tmdate": 1487701367835, "tcdate": 1487701336607, "number": 3, "id": "B1bDrZqtx", "invitation": "ICLR.cc/2017/workshop/-/paper81/public/comment", "forum": "r1PyAP4Yl", "replyto": "r1q0OKtKg", "signatures": ["~Jianwei_Yang1"], "readers": ["everyone"], "writers": ["~Jianwei_Yang1"], "content": {"title": "Re: Re: Some comments, and comparison with one more relevant work", "comment": "Hi, Sean,\n\nThanks for your prompt reply. \n\n1) In the testing stage, we use a nearest-neighbor classifier. Hence I do not know the number of clusters even after training. Perhaps an agglomerative clustering algorithm could find the optimal number of clusters. What's interesting is that this method does not directly optimize clustering performance, yet can generate comparable results. Something I'm looking forward to exploring further.\n\n>> The 'Clustering Accuracy' is a bit confusing to me. For me, it means the clustering accuracy metric as used in previous literatures, by comparing the clustering label and the ground-truth label. To get the clustering labels, you need to know the number of clusters, right? In your case, it seems that you are using KNN as the classifier and evaluate the learnt representation on test set and report the classification accuracy? However, the confusion comes. In Table-1, both kmeans and  K-NN results are reported. But the former one is a clustering method and the second one is actually a classification method. How to compare them in the same line?\n\n\n2) & 3) Thank you for the suggestion. I will read your paper.\n\n>> Thanks, if you want to find the number of clustering accuracies, please refer to Table 10 and 11 in the paper. If you want to find the 1-NN classification accuracy based on the learnt representation, please refer to Table 13\n\nJianwei"}, "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Clustering: Concatenating Layers for Better Projections", "abstract": "Effective clustering can be achieved by mapping the input to an embedded space rather than clustering on the raw data itself. However, there is limited focus on transformation methods that improve clustering accuracies. In this paper, we introduce Neural Clustering, a simple yet effective unsupervised model to project data onto an embedded space where intermediate layers of a deep autoencoder are concatenated to generate high-dimensional representations. Optimization of the autoencoder via reconstruction error allows the layers in the network to learn semantic representations of different classes of data. Our experimental results yield significant improvements on other models and a robustness across different kinds of datasets.", "pdf": "/pdf/1eab8f0e25822eee6b981db6abdb5977f73c457c.pdf", "TL;DR": "We introduce a simple yet effective technique for projecting data that allows for better clustering.", "paperhash": "saito|neural_clustering_concatenating_layers_for_better_projections", "conflicts": ["u.yale-nus.edu.sg"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Sean Saito", "Robby T. Tan"], "authorids": ["sean.saito@u.yale-nus.edu.sg", "robby.tan@u.yale-nus.edu.sg"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487334879244, "tcdate": 1487334879244, "id": "ICLR.cc/2017/workshop/-/paper81/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper81/reviewers"], "reply": {"forum": "r1PyAP4Yl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487334879244}}}, {"tddate": null, "tmdate": 1487669458064, "tcdate": 1487669458064, "number": 2, "id": "r1q0OKtKg", "invitation": "ICLR.cc/2017/workshop/-/paper81/public/comment", "forum": "r1PyAP4Yl", "replyto": "Bkhbpkdte", "signatures": ["~Sean_Saito1"], "readers": ["everyone"], "writers": ["~Sean_Saito1"], "content": {"title": "Re: Some comments, and comparison with one more relevant work", "comment": "Hi Jianwei,\n\nThank you for the comments. Yes, the method is straightforward, and I am also quite surprised how effective it is across different datasets.\n\n1) In the testing stage, we use a nearest-neighbor classifier. Hence I do not know the number of clusters even after training. Perhaps an agglomerative clustering algorithm could find the optimal number of clusters. What's interesting is that this method does not directly optimize clustering performance, yet can generate comparable results. Something I'm looking forward to exploring further.\n\n2) & 3) Thank you for the suggestion. I will read your paper.\n\nThis is my first attempt at academic research, so I really appreciate the feedback. Thank you!\n\nBest,\nSean"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Clustering: Concatenating Layers for Better Projections", "abstract": "Effective clustering can be achieved by mapping the input to an embedded space rather than clustering on the raw data itself. However, there is limited focus on transformation methods that improve clustering accuracies. In this paper, we introduce Neural Clustering, a simple yet effective unsupervised model to project data onto an embedded space where intermediate layers of a deep autoencoder are concatenated to generate high-dimensional representations. Optimization of the autoencoder via reconstruction error allows the layers in the network to learn semantic representations of different classes of data. Our experimental results yield significant improvements on other models and a robustness across different kinds of datasets.", "pdf": "/pdf/1eab8f0e25822eee6b981db6abdb5977f73c457c.pdf", "TL;DR": "We introduce a simple yet effective technique for projecting data that allows for better clustering.", "paperhash": "saito|neural_clustering_concatenating_layers_for_better_projections", "conflicts": ["u.yale-nus.edu.sg"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Sean Saito", "Robby T. Tan"], "authorids": ["sean.saito@u.yale-nus.edu.sg", "robby.tan@u.yale-nus.edu.sg"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487334879244, "tcdate": 1487334879244, "id": "ICLR.cc/2017/workshop/-/paper81/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper81/reviewers"], "reply": {"forum": "r1PyAP4Yl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487334879244}}}, {"tddate": null, "tmdate": 1487564036314, "tcdate": 1487564036314, "number": 1, "id": "Bkhbpkdte", "invitation": "ICLR.cc/2017/workshop/-/paper81/public/comment", "forum": "r1PyAP4Yl", "replyto": "r1PyAP4Yl", "signatures": ["~Jianwei_Yang1"], "readers": ["everyone"], "writers": ["~Jianwei_Yang1"], "content": {"title": "Some comments, and comparison with one more relevant work", "comment": "Hi, I read your paper and found the proposed method is straightforward and interesting. I did not expect straightly learn auto-encoder would achieve such a good results, even on CIFAR-10.\n\nIn the paper, you mentioned: \n\n1) Our method does not depend on any heuristics such as the number of desired centroids or the target distribution of the embedded space. \n\n2) Note our method outperforms all other models and produces state-of-the-art results.\n\nHowever, I think it is not that accurate. \n\n1) Firstly, though you do not use the number of desired centroids during the training, you will use it during testing. So it is not totally independent on the cluster number, which differs from those methods that also predict the cluster numbers. As a result, I think it is more accurate to say \"does not depend on the number of desired centroids during training\". \n\n2) Secondly, though DEC used a target distribution of the embedded space as prior, there are some other works in the same line but without the usage of prior distributions, such as our paper \"Joint Unsupervised Learning of Deep Representations and Image Clusters\", CVPR 2016. In our paper, we simultaneously learn the image representation and cluster the images from scratch, and achieved very nice results.\n\n3) Thirdly, our method JULE achieved comparable clustering accuracy after applying K-means on the learnt representations on MNIST, and also significantly better  performance on many other image datasets. I think comparing with our method on more image datasets will make the paper more comprehensive and persuasive.\n\nThe code for our paper is available on: https://github.com/jwyang/JULE-Torch\n\nthanks,\nJianwei Yang\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neural Clustering: Concatenating Layers for Better Projections", "abstract": "Effective clustering can be achieved by mapping the input to an embedded space rather than clustering on the raw data itself. However, there is limited focus on transformation methods that improve clustering accuracies. In this paper, we introduce Neural Clustering, a simple yet effective unsupervised model to project data onto an embedded space where intermediate layers of a deep autoencoder are concatenated to generate high-dimensional representations. Optimization of the autoencoder via reconstruction error allows the layers in the network to learn semantic representations of different classes of data. Our experimental results yield significant improvements on other models and a robustness across different kinds of datasets.", "pdf": "/pdf/1eab8f0e25822eee6b981db6abdb5977f73c457c.pdf", "TL;DR": "We introduce a simple yet effective technique for projecting data that allows for better clustering.", "paperhash": "saito|neural_clustering_concatenating_layers_for_better_projections", "conflicts": ["u.yale-nus.edu.sg"], "keywords": ["Deep learning", "Unsupervised Learning"], "authors": ["Sean Saito", "Robby T. Tan"], "authorids": ["sean.saito@u.yale-nus.edu.sg", "robby.tan@u.yale-nus.edu.sg"]}, "tags": [], "invitation": {"tddate": null, "tmdate": 1487334879244, "tcdate": 1487334879244, "id": "ICLR.cc/2017/workshop/-/paper81/public/comment", "writers": ["ICLR.cc/2017/workshop"], "signatures": ["ICLR.cc/2017/workshop"], "readers": ["everyone"], "invitees": ["~"], "noninvitees": ["ICLR.cc/2017/workshop/paper81/reviewers"], "reply": {"forum": "r1PyAP4Yl", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/workshop/reviewers", "ICLR.cc/2017/pcs"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "cdate": 1487334879244}}}], "count": 10}