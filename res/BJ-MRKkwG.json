{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124438007, "tcdate": 1518472713238, "number": 340, "cdate": 1518472713238, "id": "BJ-MRKkwG", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "BJ-MRKkwG", "signatures": ["~Charles_Packer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Differentiable Neural Network Architecture Search", "abstract": "The successes of deep learning in recent years has been fueled by the development\nof innovative new neural network architectures. However, the design of a neural\nnetwork architecture remains a difficult problem, requiring significant human expertise\nas well as computational resources. In this paper, we propose a method\nfor transforming a discrete neural network architecture space into a continuous\nand differentiable form, which enables the use of standard gradient-based optimization\ntechniques for this problem, and allows us to learn the architecture and\nthe parameters simultaneously. We evaluate our methods on the Udacity steering\nangle prediction dataset, and show that our method can discover architectures\nwith similar or better predictive accuracy but significantly fewer parameters and\nsmaller computational cost.", "paperhash": "shin|differentiable_neural_network_architecture_search", "_bibtex": "@misc{\n  shin*2018differentiable,\n  title={Differentiable Neural Network Architecture Search},\n  author={Richard Shin* and Charles Packer* and Dawn Song},\n  year={2018},\n  url={https://openreview.net/forum?id=BJ-MRKkwG}\n}", "authorids": ["shin.richard@gmail.com", "cpacker@berkeley.edu", "dawnsong@berkeley.edu"], "authors": ["Richard Shin*", "Charles Packer*", "Dawn Song"], "keywords": ["architecture search"], "pdf": "/pdf/e10d31eaba519238a563c778334f1d0d6fa0a9d3.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582933672, "tcdate": 1520311878832, "number": 1, "cdate": 1520311878832, "id": "r1yLA9iuG", "invitation": "ICLR.cc/2018/Workshop/-/Paper340/Official_Review", "forum": "BJ-MRKkwG", "replyto": "BJ-MRKkwG", "signatures": ["ICLR.cc/2018/Workshop/Paper340/AnonReviewer4"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper340/AnonReviewer4"], "content": {"title": "Straightforward extension of the existing methods.", "rating": "4: Ok but not good enough - rejection", "review": "In this paper, the authors proposed using sparse regularization techniques to prune redundant filters in CNN thereby optimizing the network structure.\n\n[Clarity]\nGood. The authors described the basic idea clearly.\n\n[Quality, Originality]\nI think the idea of pruning redundant components with sparse regularizations is a common technique in machine learning.\nFor example, in multiple kernel learning, sparse regularizations are used to choose kernels.\nAs authors mentioned in introduction, similar ideas are also used in the neural network literatures.\nIt is therefore not clear how the proposed method is novel compared to those existing methods.\n\n[Significance]\nThe experimental evaluation is conducted only on the proposed method.\nIt is therefore not clear whether the proposed method is superior to the other existing methods in practice.\nBecause of this reason, I think the impact of this paper is low.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Differentiable Neural Network Architecture Search", "abstract": "The successes of deep learning in recent years has been fueled by the development\nof innovative new neural network architectures. However, the design of a neural\nnetwork architecture remains a difficult problem, requiring significant human expertise\nas well as computational resources. In this paper, we propose a method\nfor transforming a discrete neural network architecture space into a continuous\nand differentiable form, which enables the use of standard gradient-based optimization\ntechniques for this problem, and allows us to learn the architecture and\nthe parameters simultaneously. We evaluate our methods on the Udacity steering\nangle prediction dataset, and show that our method can discover architectures\nwith similar or better predictive accuracy but significantly fewer parameters and\nsmaller computational cost.", "paperhash": "shin|differentiable_neural_network_architecture_search", "_bibtex": "@misc{\n  shin*2018differentiable,\n  title={Differentiable Neural Network Architecture Search},\n  author={Richard Shin* and Charles Packer* and Dawn Song},\n  year={2018},\n  url={https://openreview.net/forum?id=BJ-MRKkwG}\n}", "authorids": ["shin.richard@gmail.com", "cpacker@berkeley.edu", "dawnsong@berkeley.edu"], "authors": ["Richard Shin*", "Charles Packer*", "Dawn Song"], "keywords": ["architecture search"], "pdf": "/pdf/e10d31eaba519238a563c778334f1d0d6fa0a9d3.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582933478, "id": "ICLR.cc/2018/Workshop/-/Paper340/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper340/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper340/AnonReviewer4", "ICLR.cc/2018/Workshop/Paper340/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper340/AnonReviewer2"], "reply": {"forum": "BJ-MRKkwG", "replyto": "BJ-MRKkwG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper340/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper340/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582933478}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582854681, "tcdate": 1520570317922, "number": 2, "cdate": 1520570317922, "id": "HJ8R1c1Kf", "invitation": "ICLR.cc/2018/Workshop/-/Paper340/Official_Review", "forum": "BJ-MRKkwG", "replyto": "BJ-MRKkwG", "signatures": ["ICLR.cc/2018/Workshop/Paper340/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper340/AnonReviewer1"], "content": {"title": "Differentiable NAS", "rating": "8: Top 50% of accepted papers, clear accept", "review": "The authors aim to perform neural architecture search, but unlike most recent work, don't treat it as a reinforcement learning problem -- instead, they treat it as a \"differentiable problem\", where the architecture and parameters can be trained jointly. They use a convolutional neural network as an example and discuss how to optimize filter size and number of channels for each layer. They show their results on an experiment using the Udacity dataset.\n\nI thought this was a good paper with novel contributions, as it looks at architecture search in a way that's different than most current methods. I would add that they should compare against more baselines such as standard architectures or other methods for architecture search to make the experiment stronger. Also, the number of layers seems like it has to be fixed -- how is this chosen in advance?", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Differentiable Neural Network Architecture Search", "abstract": "The successes of deep learning in recent years has been fueled by the development\nof innovative new neural network architectures. However, the design of a neural\nnetwork architecture remains a difficult problem, requiring significant human expertise\nas well as computational resources. In this paper, we propose a method\nfor transforming a discrete neural network architecture space into a continuous\nand differentiable form, which enables the use of standard gradient-based optimization\ntechniques for this problem, and allows us to learn the architecture and\nthe parameters simultaneously. We evaluate our methods on the Udacity steering\nangle prediction dataset, and show that our method can discover architectures\nwith similar or better predictive accuracy but significantly fewer parameters and\nsmaller computational cost.", "paperhash": "shin|differentiable_neural_network_architecture_search", "_bibtex": "@misc{\n  shin*2018differentiable,\n  title={Differentiable Neural Network Architecture Search},\n  author={Richard Shin* and Charles Packer* and Dawn Song},\n  year={2018},\n  url={https://openreview.net/forum?id=BJ-MRKkwG}\n}", "authorids": ["shin.richard@gmail.com", "cpacker@berkeley.edu", "dawnsong@berkeley.edu"], "authors": ["Richard Shin*", "Charles Packer*", "Dawn Song"], "keywords": ["architecture search"], "pdf": "/pdf/e10d31eaba519238a563c778334f1d0d6fa0a9d3.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582933478, "id": "ICLR.cc/2018/Workshop/-/Paper340/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper340/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper340/AnonReviewer4", "ICLR.cc/2018/Workshop/Paper340/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper340/AnonReviewer2"], "reply": {"forum": "BJ-MRKkwG", "replyto": "BJ-MRKkwG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper340/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper340/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582933478}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582822273, "tcdate": 1520611250736, "number": 3, "cdate": 1520611250736, "id": "ryohkExKM", "invitation": "ICLR.cc/2018/Workshop/-/Paper340/Official_Review", "forum": "BJ-MRKkwG", "replyto": "BJ-MRKkwG", "signatures": ["ICLR.cc/2018/Workshop/Paper340/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper340/AnonReviewer2"], "content": {"title": "Interesting idea but lack of explainations", "rating": "6: Marginally above acceptance threshold", "review": "This article tries to learn hyperparater during the main learning process, by using a global differentiable formulation. This paper belongs to the very attractive domain of meta-learning, which aims at making any ML algorithm to work at once, without a costly optimization of its structure/parameters. The authors explain that they focus on convnets and propose a group lasso optimization approch to optimize a group of filters. They also use large filters and rely on the regularization framwork to find the best actual filter size.\nDoing this, they obtain good results on the udacity self driving car dataset using either a reduced number of parameters or a reduced computation time in the optimization process.\n\nI do not catch the differentiable aspect of the architecture: filter are yet differentiable in classical CNN. I  do not get how padding max-sized filter with 0 make the size parameter differentiable.\nMore generally, what is the link between group lasso & differentiable architecture? \nThe authors claim that \"we propose a method for transforming a discrete neural network architecture space into a continuous\nand differentiable form\". I do not see clearly the contribution in that sense.\n\nThe article is interesting but some key information is missing to understand the contribution. ", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Differentiable Neural Network Architecture Search", "abstract": "The successes of deep learning in recent years has been fueled by the development\nof innovative new neural network architectures. However, the design of a neural\nnetwork architecture remains a difficult problem, requiring significant human expertise\nas well as computational resources. In this paper, we propose a method\nfor transforming a discrete neural network architecture space into a continuous\nand differentiable form, which enables the use of standard gradient-based optimization\ntechniques for this problem, and allows us to learn the architecture and\nthe parameters simultaneously. We evaluate our methods on the Udacity steering\nangle prediction dataset, and show that our method can discover architectures\nwith similar or better predictive accuracy but significantly fewer parameters and\nsmaller computational cost.", "paperhash": "shin|differentiable_neural_network_architecture_search", "_bibtex": "@misc{\n  shin*2018differentiable,\n  title={Differentiable Neural Network Architecture Search},\n  author={Richard Shin* and Charles Packer* and Dawn Song},\n  year={2018},\n  url={https://openreview.net/forum?id=BJ-MRKkwG}\n}", "authorids": ["shin.richard@gmail.com", "cpacker@berkeley.edu", "dawnsong@berkeley.edu"], "authors": ["Richard Shin*", "Charles Packer*", "Dawn Song"], "keywords": ["architecture search"], "pdf": "/pdf/e10d31eaba519238a563c778334f1d0d6fa0a9d3.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582933478, "id": "ICLR.cc/2018/Workshop/-/Paper340/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper340/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper340/AnonReviewer4", "ICLR.cc/2018/Workshop/Paper340/AnonReviewer1", "ICLR.cc/2018/Workshop/Paper340/AnonReviewer2"], "reply": {"forum": "BJ-MRKkwG", "replyto": "BJ-MRKkwG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper340/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper340/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582933478}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573573035, "tcdate": 1521573573035, "number": 132, "cdate": 1521573572695, "id": "ryp6RACKM", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "BJ-MRKkwG", "replyto": "BJ-MRKkwG", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Differentiable Neural Network Architecture Search", "abstract": "The successes of deep learning in recent years has been fueled by the development\nof innovative new neural network architectures. However, the design of a neural\nnetwork architecture remains a difficult problem, requiring significant human expertise\nas well as computational resources. In this paper, we propose a method\nfor transforming a discrete neural network architecture space into a continuous\nand differentiable form, which enables the use of standard gradient-based optimization\ntechniques for this problem, and allows us to learn the architecture and\nthe parameters simultaneously. We evaluate our methods on the Udacity steering\nangle prediction dataset, and show that our method can discover architectures\nwith similar or better predictive accuracy but significantly fewer parameters and\nsmaller computational cost.", "paperhash": "shin|differentiable_neural_network_architecture_search", "_bibtex": "@misc{\n  shin*2018differentiable,\n  title={Differentiable Neural Network Architecture Search},\n  author={Richard Shin* and Charles Packer* and Dawn Song},\n  year={2018},\n  url={https://openreview.net/forum?id=BJ-MRKkwG}\n}", "authorids": ["shin.richard@gmail.com", "cpacker@berkeley.edu", "dawnsong@berkeley.edu"], "authors": ["Richard Shin*", "Charles Packer*", "Dawn Song"], "keywords": ["architecture search"], "pdf": "/pdf/e10d31eaba519238a563c778334f1d0d6fa0a9d3.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}