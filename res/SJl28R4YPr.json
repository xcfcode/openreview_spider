{"notes": [{"id": "SJl28R4YPr", "original": "rkeMbNPuvB", "number": 1154, "cdate": 1569439316460, "ddate": null, "tcdate": 1569439316460, "tmdate": 1577168220077, "tddate": null, "forum": "SJl28R4YPr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"title": "Graph Neural Networks for Reasoning 2-Quantified Boolean Formulas", "authors": ["Fei Wang", "Zhanfu Yang", "Ziliang Chen", "Guannan Wei", "Tiark Rompf"], "authorids": ["wang603@purdue.edu", "yang1676@purdue.edu", "c.ziliang@yahoo.com", "wei220@purdue.edu", "tiark@purdue.edu"], "keywords": ["Graph Neural Networks", "2-Quantified Boolean Formula", "Symbolic Reasoning"], "TL;DR": "Learn GNN-based 2QBF solvers and GNN-based 2QBF heuristics", "abstract": "It is valuable yet remains challenging to apply neural networks in logical reasoning tasks. Despite some successes witnessed in learning SAT (Boolean Satisfiability) solvers for propositional logic via Graph Neural Networks (GNN),  there haven't been any successes in learning solvers for more complex predicate logic. In this paper, we target the QBF (Quantified Boolean Formula) satisfiability problem, the complexity of which is in-between propositional logic and predicate logic, and investigate the feasibility of learning GNN-based solvers and GNN-based heuristics for the cases with a universal-existential quantifier alternation (so-called 2QBF problems).\n\nWe conjecture, with empirical support, that GNNs have certain limitations in learning 2QBF solvers, primarily due to the inability to reason about a set of assignments. Then we show the potential of GNN-based heuristics in CEGAR-based solvers and explore the interesting challenges to generalize them to larger problem instances. In summary, this paper provides a comprehensive surveying view of applying GNN-based embeddings to 2QBF problems and aims to offer insights in applying machine learning tools to more complicated symbolic reasoning problems.\n", "pdf": "/pdf/15e242462984ff169e630d8595ca5336cae63ebd.pdf", "paperhash": "wang|graph_neural_networks_for_reasoning_2quantified_boolean_formulas", "original_pdf": "/attachment/15e242462984ff169e630d8595ca5336cae63ebd.pdf", "_bibtex": "@misc{\nwang2020graph,\ntitle={Graph Neural Networks for Reasoning 2-Quantified Boolean Formulas},\nauthor={Fei Wang and Zhanfu Yang and Ziliang Chen and Guannan Wei and Tiark Rompf},\nyear={2020},\nurl={https://openreview.net/forum?id=SJl28R4YPr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "oejiKPKQap", "original": null, "number": 1, "cdate": 1576798715936, "ddate": null, "tcdate": 1576798715936, "tmdate": 1576800920592, "tddate": null, "forum": "SJl28R4YPr", "replyto": "SJl28R4YPr", "invitation": "ICLR.cc/2020/Conference/Paper1154/-/Decision", "content": {"decision": "Reject", "comment": "This work investigates the use of graph NNs for solving 2QBF . The authors provide empirical evidence that for this type of satisfiability decision problem, GNNs are not able to provide solutions and claim this is due to the message passing mechanism that cannot afford for complex reasoning. Finally, the authors propose a number of heuristics that extend GNNs and show that these improve their performance.\n\n2-QBF problem is used as a playground since, as the authors also point, their complexity is in between  that of predicate and propositional logic. This on its own is not bad,  as it can be used as a minimal environment for the type of investigation the authors are interested. That being said, I find a number a number of flaws in the current form of the paper (some of them pointed by R3 as well), with the main issue being that of lack experimental rigor. Given the restricted set of problems the authors consider, I think the experiments on identifying pathologies of GNNs on this setup could have gone more in depth. Let me be specific. \n\n1) The bad performance is attributed to message-passing. However, this feels anecdotal at the moment and authors do not provide firm conclusions about that. The only evidence they provide is that performance becomes better with more message-passing iterations they allow. This is a hint though to dive deeper rather than a firm conclusion. For example do we know if the finding about sensitivity to  message-passing  is due to the small size of the network or the training procedure? \n2) To add on that, there is virtually no information on the paper about the specifics of the experimental setup, so the reader cannot be convinced that the negative results do not arise from a bad experimental configuration (e.g., small size of network).\n3) Moreover, the negative results here, as the authors point, seem to contradict previous work, providing negative results against GNNs.  Again, this is a valuable contribution if that is indeed the case, but again the paper does not provide enough evidence. In lieu of a convincing set of experiments, the paper could provide a proof (as also asked by R3). However with no proof and not strong empirical evidence that this result does not feel ready to get published at ICLR.\n\nOverall, I think this paper with a bit more rigor could be a very good submission for a later conference. However, as it stands I cannot recommend acceptance. \n", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Neural Networks for Reasoning 2-Quantified Boolean Formulas", "authors": ["Fei Wang", "Zhanfu Yang", "Ziliang Chen", "Guannan Wei", "Tiark Rompf"], "authorids": ["wang603@purdue.edu", "yang1676@purdue.edu", "c.ziliang@yahoo.com", "wei220@purdue.edu", "tiark@purdue.edu"], "keywords": ["Graph Neural Networks", "2-Quantified Boolean Formula", "Symbolic Reasoning"], "TL;DR": "Learn GNN-based 2QBF solvers and GNN-based 2QBF heuristics", "abstract": "It is valuable yet remains challenging to apply neural networks in logical reasoning tasks. Despite some successes witnessed in learning SAT (Boolean Satisfiability) solvers for propositional logic via Graph Neural Networks (GNN),  there haven't been any successes in learning solvers for more complex predicate logic. In this paper, we target the QBF (Quantified Boolean Formula) satisfiability problem, the complexity of which is in-between propositional logic and predicate logic, and investigate the feasibility of learning GNN-based solvers and GNN-based heuristics for the cases with a universal-existential quantifier alternation (so-called 2QBF problems).\n\nWe conjecture, with empirical support, that GNNs have certain limitations in learning 2QBF solvers, primarily due to the inability to reason about a set of assignments. Then we show the potential of GNN-based heuristics in CEGAR-based solvers and explore the interesting challenges to generalize them to larger problem instances. In summary, this paper provides a comprehensive surveying view of applying GNN-based embeddings to 2QBF problems and aims to offer insights in applying machine learning tools to more complicated symbolic reasoning problems.\n", "pdf": "/pdf/15e242462984ff169e630d8595ca5336cae63ebd.pdf", "paperhash": "wang|graph_neural_networks_for_reasoning_2quantified_boolean_formulas", "original_pdf": "/attachment/15e242462984ff169e630d8595ca5336cae63ebd.pdf", "_bibtex": "@misc{\nwang2020graph,\ntitle={Graph Neural Networks for Reasoning 2-Quantified Boolean Formulas},\nauthor={Fei Wang and Zhanfu Yang and Ziliang Chen and Guannan Wei and Tiark Rompf},\nyear={2020},\nurl={https://openreview.net/forum?id=SJl28R4YPr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "SJl28R4YPr", "replyto": "SJl28R4YPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795727579, "tmdate": 1576800279842, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1154/-/Decision"}}}, {"id": "HJgGOTcDtS", "original": null, "number": 1, "cdate": 1571429738386, "ddate": null, "tcdate": 1571429738386, "tmdate": 1572972505750, "tddate": null, "forum": "SJl28R4YPr", "replyto": "SJl28R4YPr", "invitation": "ICLR.cc/2020/Conference/Paper1154/-/Official_Review", "content": {"rating": "6: Weak Accept", "experience_assessment": "I do not know much about this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review": "This paper first presents GNN architectures to solve 2-QBFs. They show that similar GNN architectures which work for propositional logic do not transfer to 2-QBFs, and provide some explanation for the result. Finally, they show how GNN modules can be used to speed up existing 2-QBF solvers instead. I mostly like the paper. The claims of the paper are well presented and empirically validated. Here are some suggestions / complaints:\n\n1. It will be good to have more overview of 2-QBFs and existing solvers. How popular is CEGAR and why the improvements to its performance is important ?\n2. Dataset sizes are tiny compared to current standards. Is there a reason to use such small datasets ? From the results, I don't think any of the conclusions will change significantly from the dataset size, but still its better to use larger datasets.\n3. I think all tables should be self-explanatory. There are too many dataset splits and captions of tables do not provide any information. "}, "signatures": ["ICLR.cc/2020/Conference/Paper1154/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1154/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Neural Networks for Reasoning 2-Quantified Boolean Formulas", "authors": ["Fei Wang", "Zhanfu Yang", "Ziliang Chen", "Guannan Wei", "Tiark Rompf"], "authorids": ["wang603@purdue.edu", "yang1676@purdue.edu", "c.ziliang@yahoo.com", "wei220@purdue.edu", "tiark@purdue.edu"], "keywords": ["Graph Neural Networks", "2-Quantified Boolean Formula", "Symbolic Reasoning"], "TL;DR": "Learn GNN-based 2QBF solvers and GNN-based 2QBF heuristics", "abstract": "It is valuable yet remains challenging to apply neural networks in logical reasoning tasks. Despite some successes witnessed in learning SAT (Boolean Satisfiability) solvers for propositional logic via Graph Neural Networks (GNN),  there haven't been any successes in learning solvers for more complex predicate logic. In this paper, we target the QBF (Quantified Boolean Formula) satisfiability problem, the complexity of which is in-between propositional logic and predicate logic, and investigate the feasibility of learning GNN-based solvers and GNN-based heuristics for the cases with a universal-existential quantifier alternation (so-called 2QBF problems).\n\nWe conjecture, with empirical support, that GNNs have certain limitations in learning 2QBF solvers, primarily due to the inability to reason about a set of assignments. Then we show the potential of GNN-based heuristics in CEGAR-based solvers and explore the interesting challenges to generalize them to larger problem instances. In summary, this paper provides a comprehensive surveying view of applying GNN-based embeddings to 2QBF problems and aims to offer insights in applying machine learning tools to more complicated symbolic reasoning problems.\n", "pdf": "/pdf/15e242462984ff169e630d8595ca5336cae63ebd.pdf", "paperhash": "wang|graph_neural_networks_for_reasoning_2quantified_boolean_formulas", "original_pdf": "/attachment/15e242462984ff169e630d8595ca5336cae63ebd.pdf", "_bibtex": "@misc{\nwang2020graph,\ntitle={Graph Neural Networks for Reasoning 2-Quantified Boolean Formulas},\nauthor={Fei Wang and Zhanfu Yang and Ziliang Chen and Guannan Wei and Tiark Rompf},\nyear={2020},\nurl={https://openreview.net/forum?id=SJl28R4YPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJl28R4YPr", "replyto": "SJl28R4YPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1154/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1154/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576146157707, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1154/Reviewers"], "noninvitees": [], "tcdate": 1570237741566, "tmdate": 1576146157718, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1154/-/Official_Review"}}}, {"id": "B1xdwB9TKr", "original": null, "number": 2, "cdate": 1571820896492, "ddate": null, "tcdate": 1571820896492, "tmdate": 1572972505709, "tddate": null, "forum": "SJl28R4YPr", "replyto": "SJl28R4YPr", "invitation": "ICLR.cc/2020/Conference/Paper1154/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "8: Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper explores how graph neural networks can be applied to test satisfiability of 2QBF logical formulas. They show that a straightforward extension of a GNN-based SAT solver to 2QBF fails to outperform random chance, and argue that this is because proving either satisfiability or unsatisfiability of 2QBF requires reasoning over exponential sets of assignments. Instead, they show that GNNs can be useful as a heuristic candidate- or counterexample- ranking model which improves the efficiency of the CEGAR algorithm for solving 2QBF.\n\nThis is a clear, well-written, and well-structured paper, and I support accepting it to ICLR. That being said, I am not as familiar with the literature on neural solvers for logic problems, so I base my review on the content within the paper more than its context in the field.\n\nI can\u2019t find much to fault with the writing and arguments. The GNN architecture for 2QBF (Section 2) is simple, elegant, and well-motivated as a minimal extension of successful SAT solvers. The arguments in Section 3 are convincing, and make a good case for why an algorithm such as CEGAR is necessary. Finally, the metrics in Section 4 are clearly interpretable and well-justified. \n\nA couple questions and concerns:\nIn Section 3, The amount of training data (up to 160 pairs of formulas for predicting satisfiability) seems to be very small for a machine learning problem. By comparison, Selsam et al. 2019 says they train their GNN SAT solver on \u201cmillions of problems\u201d (Section 5). Is there a good reason for using a much smaller dataset, given that 2QBF is a harder class of problem?\nSection 4.2: how are the TraunU, TrainS, TestU, and TestS datasets generated?\nIn Section 4.6, are the models re-trained on these new distributions, or on the data described in Section 4.2? (If the latter, how does the GNN perform if re-trained on the larger-spec data?)\n\nAnd minor points on clarity:\n* \u201c-\u201d for the baseline seems a bit awkward; consider spelling out \u201cvanilla\u201d?\n* Are all the numbers in the tables iteration counts, unless specified otherwise? It would help to restate this in the captions. Similarly, I wonder if there could be more informative names for GNN1, GNN2, GNN3, and GNN4?\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1154/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1154/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Neural Networks for Reasoning 2-Quantified Boolean Formulas", "authors": ["Fei Wang", "Zhanfu Yang", "Ziliang Chen", "Guannan Wei", "Tiark Rompf"], "authorids": ["wang603@purdue.edu", "yang1676@purdue.edu", "c.ziliang@yahoo.com", "wei220@purdue.edu", "tiark@purdue.edu"], "keywords": ["Graph Neural Networks", "2-Quantified Boolean Formula", "Symbolic Reasoning"], "TL;DR": "Learn GNN-based 2QBF solvers and GNN-based 2QBF heuristics", "abstract": "It is valuable yet remains challenging to apply neural networks in logical reasoning tasks. Despite some successes witnessed in learning SAT (Boolean Satisfiability) solvers for propositional logic via Graph Neural Networks (GNN),  there haven't been any successes in learning solvers for more complex predicate logic. In this paper, we target the QBF (Quantified Boolean Formula) satisfiability problem, the complexity of which is in-between propositional logic and predicate logic, and investigate the feasibility of learning GNN-based solvers and GNN-based heuristics for the cases with a universal-existential quantifier alternation (so-called 2QBF problems).\n\nWe conjecture, with empirical support, that GNNs have certain limitations in learning 2QBF solvers, primarily due to the inability to reason about a set of assignments. Then we show the potential of GNN-based heuristics in CEGAR-based solvers and explore the interesting challenges to generalize them to larger problem instances. In summary, this paper provides a comprehensive surveying view of applying GNN-based embeddings to 2QBF problems and aims to offer insights in applying machine learning tools to more complicated symbolic reasoning problems.\n", "pdf": "/pdf/15e242462984ff169e630d8595ca5336cae63ebd.pdf", "paperhash": "wang|graph_neural_networks_for_reasoning_2quantified_boolean_formulas", "original_pdf": "/attachment/15e242462984ff169e630d8595ca5336cae63ebd.pdf", "_bibtex": "@misc{\nwang2020graph,\ntitle={Graph Neural Networks for Reasoning 2-Quantified Boolean Formulas},\nauthor={Fei Wang and Zhanfu Yang and Ziliang Chen and Guannan Wei and Tiark Rompf},\nyear={2020},\nurl={https://openreview.net/forum?id=SJl28R4YPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJl28R4YPr", "replyto": "SJl28R4YPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1154/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1154/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576146157707, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1154/Reviewers"], "noninvitees": [], "tcdate": 1570237741566, "tmdate": 1576146157718, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1154/-/Official_Review"}}}, {"id": "ByefKW4V5r", "original": null, "number": 3, "cdate": 1572254074309, "ddate": null, "tcdate": 1572254074309, "tmdate": 1572972505662, "tddate": null, "forum": "SJl28R4YPr", "replyto": "SJl28R4YPr", "invitation": "ICLR.cc/2020/Conference/Paper1154/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper investigated the GNN-based solvers for the 2-Quantified Boolean Formula satisfiability problem. This paper points out that GNN has limitations in reasoning about unsatisfiability of SAT problems possibly due to the simple message-passing scheme. To extend the GNN-based SAT solvers to 2-QBF solvers, this paper then turns to learn GNN-based heuristics that work with traditional decision procedure, and proposes a CEGAR-based 2QBF algorithm.\n\nOverall, the topic of combining logic reasoning and graph neural networks is interesting. But it is not clear how important is the targeted 2-QBF problem, except for testing and finding the limitations of GNN. In other words, this paper picks up a specific class of model for a very specific class of problem, which lacks sufficient and convincing motivations. Although GNN achieves success in solving SAT problems, it is not necessary that GNN is a must for solving the 2-QBF problems. Also, when analyzing the limitations of GNN, the paper makes conjecture only based on empirical results. It would be much more insightful to provide some theoretical analysis so that the paper can inspire other researchers working on different problems. Based on the above reasons, I would like to recommend a weak reject for this paper."}, "signatures": ["ICLR.cc/2020/Conference/Paper1154/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1154/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Neural Networks for Reasoning 2-Quantified Boolean Formulas", "authors": ["Fei Wang", "Zhanfu Yang", "Ziliang Chen", "Guannan Wei", "Tiark Rompf"], "authorids": ["wang603@purdue.edu", "yang1676@purdue.edu", "c.ziliang@yahoo.com", "wei220@purdue.edu", "tiark@purdue.edu"], "keywords": ["Graph Neural Networks", "2-Quantified Boolean Formula", "Symbolic Reasoning"], "TL;DR": "Learn GNN-based 2QBF solvers and GNN-based 2QBF heuristics", "abstract": "It is valuable yet remains challenging to apply neural networks in logical reasoning tasks. Despite some successes witnessed in learning SAT (Boolean Satisfiability) solvers for propositional logic via Graph Neural Networks (GNN),  there haven't been any successes in learning solvers for more complex predicate logic. In this paper, we target the QBF (Quantified Boolean Formula) satisfiability problem, the complexity of which is in-between propositional logic and predicate logic, and investigate the feasibility of learning GNN-based solvers and GNN-based heuristics for the cases with a universal-existential quantifier alternation (so-called 2QBF problems).\n\nWe conjecture, with empirical support, that GNNs have certain limitations in learning 2QBF solvers, primarily due to the inability to reason about a set of assignments. Then we show the potential of GNN-based heuristics in CEGAR-based solvers and explore the interesting challenges to generalize them to larger problem instances. In summary, this paper provides a comprehensive surveying view of applying GNN-based embeddings to 2QBF problems and aims to offer insights in applying machine learning tools to more complicated symbolic reasoning problems.\n", "pdf": "/pdf/15e242462984ff169e630d8595ca5336cae63ebd.pdf", "paperhash": "wang|graph_neural_networks_for_reasoning_2quantified_boolean_formulas", "original_pdf": "/attachment/15e242462984ff169e630d8595ca5336cae63ebd.pdf", "_bibtex": "@misc{\nwang2020graph,\ntitle={Graph Neural Networks for Reasoning 2-Quantified Boolean Formulas},\nauthor={Fei Wang and Zhanfu Yang and Ziliang Chen and Guannan Wei and Tiark Rompf},\nyear={2020},\nurl={https://openreview.net/forum?id=SJl28R4YPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "SJl28R4YPr", "replyto": "SJl28R4YPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1154/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1154/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1576146157707, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1154/Reviewers"], "noninvitees": [], "tcdate": 1570237741566, "tmdate": 1576146157718, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1154/-/Official_Review"}}}], "count": 5}