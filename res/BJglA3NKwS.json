{"notes": [{"id": "BJglA3NKwS", "original": "H1gV1h44vB", "number": 252, "cdate": 1569438920452, "ddate": null, "tcdate": 1569438920452, "tmdate": 1577168250199, "tddate": null, "forum": "BJglA3NKwS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"abstract": "Attention operators have been widely applied on data of various orders and dimensions such as texts, images, and videos. One challenge of applying attention operators is the excessive usage of computational resources. This is due to the usage of dot product and softmax operator when computing similarity scores. In this work, we propose the Siamese similarity function that uses a feed-forward network to compute similarity scores. This results in the Siamese attention operator (SAO). In particular, SAO leads to a dramatic reduction in the requirement of computational resources. Experimental results show that our SAO can save 94% memory usage and speed up the computation by a factor of 58 compared to the regular attention operator. The computational advantage of SAO is even larger on higher-order and higher-dimensional data. Results on image classification and restoration tasks demonstrate that networks with SAOs are as effective as models with regular attention operator, while significantly outperform those without attention operators.", "title": "Siamese Attention Networks", "keywords": [], "pdf": "/pdf/daae35ef79c7d2d28e65fa184da0b33a1ecd0846.pdf", "authors": ["Hongyang Gao", "Yaochen Xie", "Shuiwang Ji"], "authorids": ["hongyang.gao@tamu.edu", "ethanycx@tamu.edu", "sji@tamu.edu"], "paperhash": "gao|siamese_attention_networks", "original_pdf": "/attachment/fb5144032f2728665de4c840fe5c726bf0e19db2.pdf", "_bibtex": "@misc{\ngao2020siamese,\ntitle={Siamese Attention Networks},\nauthor={Hongyang Gao and Yaochen Xie and Shuiwang Ji},\nyear={2020},\nurl={https://openreview.net/forum?id=BJglA3NKwS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 6, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "1YUguJ4jxH", "original": null, "number": 1, "cdate": 1576798691477, "ddate": null, "tcdate": 1576798691477, "tmdate": 1576800943799, "tddate": null, "forum": "BJglA3NKwS", "replyto": "BJglA3NKwS", "invitation": "ICLR.cc/2020/Conference/Paper252/-/Decision", "content": {"decision": "Reject", "comment": "The submission presents a Siamese attention operator that lowers the computational costs of attention operators for applications such as image recognition. The reviews are split. R1 posted significant concerns with the content of the submission. The concerns remain after the authors' responses and revision. One of the concerns is the apparent dual submission with \"Kronecker Attention Networks\". The AC agrees with these concerns and recommends rejecting the submission.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "Attention operators have been widely applied on data of various orders and dimensions such as texts, images, and videos. One challenge of applying attention operators is the excessive usage of computational resources. This is due to the usage of dot product and softmax operator when computing similarity scores. In this work, we propose the Siamese similarity function that uses a feed-forward network to compute similarity scores. This results in the Siamese attention operator (SAO). In particular, SAO leads to a dramatic reduction in the requirement of computational resources. Experimental results show that our SAO can save 94% memory usage and speed up the computation by a factor of 58 compared to the regular attention operator. The computational advantage of SAO is even larger on higher-order and higher-dimensional data. Results on image classification and restoration tasks demonstrate that networks with SAOs are as effective as models with regular attention operator, while significantly outperform those without attention operators.", "title": "Siamese Attention Networks", "keywords": [], "pdf": "/pdf/daae35ef79c7d2d28e65fa184da0b33a1ecd0846.pdf", "authors": ["Hongyang Gao", "Yaochen Xie", "Shuiwang Ji"], "authorids": ["hongyang.gao@tamu.edu", "ethanycx@tamu.edu", "sji@tamu.edu"], "paperhash": "gao|siamese_attention_networks", "original_pdf": "/attachment/fb5144032f2728665de4c840fe5c726bf0e19db2.pdf", "_bibtex": "@misc{\ngao2020siamese,\ntitle={Siamese Attention Networks},\nauthor={Hongyang Gao and Yaochen Xie and Shuiwang Ji},\nyear={2020},\nurl={https://openreview.net/forum?id=BJglA3NKwS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "BJglA3NKwS", "replyto": "BJglA3NKwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795722210, "tmdate": 1576800273462, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper252/-/Decision"}}}, {"id": "B1lCtyTlqB", "original": null, "number": 3, "cdate": 1572028293536, "ddate": null, "tcdate": 1572028293536, "tmdate": 1574746037612, "tddate": null, "forum": "BJglA3NKwS", "replyto": "BJglA3NKwS", "invitation": "ICLR.cc/2020/Conference/Paper252/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #2", "review": "In this paper, the authors propose a new mechanism to perform the attention operators. The similarity between a key and a query is performed as the dot product between a trainable weight and the addition of the key and query.  The proposed Siamese attention operator is much more efficient than prior attention methods in terms of speed. The evaluation on a few computer vision tasks shows the presented method performs as well as the typical attention methods, but it runs much faster. \n\nFirst of all, I think this attention method should be quite useful for various neural networks. It is faster and performs equally well as other attention operators.  However, I do have some concerns about this method.\n\n- It is not clear to me why this method works. (a+b)^T*w is a strange expression to compute the similarity between a and b. No much explanation or intuition is given in the paper, and I have no clue why this works.\n\n- It seems to me that the proposed method performs slightly worse than the regular attention, according to Figure 6. \n\nMy overall rating is borderline. It would be great if the authors can resolve my concerns.\n\nOther questions:\n- Why SANet (MobileNetv2+SAO) has fewer parameters than MobileNetv2 in Table 3?\n- Is attention an operator that significantly slows the speed of the whole network? If not, the speedup of attention is not that important.\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper252/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper252/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "Attention operators have been widely applied on data of various orders and dimensions such as texts, images, and videos. One challenge of applying attention operators is the excessive usage of computational resources. This is due to the usage of dot product and softmax operator when computing similarity scores. In this work, we propose the Siamese similarity function that uses a feed-forward network to compute similarity scores. This results in the Siamese attention operator (SAO). In particular, SAO leads to a dramatic reduction in the requirement of computational resources. Experimental results show that our SAO can save 94% memory usage and speed up the computation by a factor of 58 compared to the regular attention operator. The computational advantage of SAO is even larger on higher-order and higher-dimensional data. Results on image classification and restoration tasks demonstrate that networks with SAOs are as effective as models with regular attention operator, while significantly outperform those without attention operators.", "title": "Siamese Attention Networks", "keywords": [], "pdf": "/pdf/daae35ef79c7d2d28e65fa184da0b33a1ecd0846.pdf", "authors": ["Hongyang Gao", "Yaochen Xie", "Shuiwang Ji"], "authorids": ["hongyang.gao@tamu.edu", "ethanycx@tamu.edu", "sji@tamu.edu"], "paperhash": "gao|siamese_attention_networks", "original_pdf": "/attachment/fb5144032f2728665de4c840fe5c726bf0e19db2.pdf", "_bibtex": "@misc{\ngao2020siamese,\ntitle={Siamese Attention Networks},\nauthor={Hongyang Gao and Yaochen Xie and Shuiwang Ji},\nyear={2020},\nurl={https://openreview.net/forum?id=BJglA3NKwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJglA3NKwS", "replyto": "BJglA3NKwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper252/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper252/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575250545731, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper252/Reviewers"], "noninvitees": [], "tcdate": 1570237754818, "tmdate": 1575250545743, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper252/-/Official_Review"}}}, {"id": "HylsrDYTtS", "original": null, "number": 1, "cdate": 1571817283328, "ddate": null, "tcdate": 1571817283328, "tmdate": 1574364307422, "tddate": null, "forum": "BJglA3NKwS", "replyto": "BJglA3NKwS", "invitation": "ICLR.cc/2020/Conference/Paper252/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #3", "review": "SUMMARY: A new similarity function replacing the dot product of key and query in attention modules - instead take a shared-weighted sum\n\nGood paper, sound theory, very clear explanations. Literature review was sufficient to explain the problem and underlying theory.\n\nResults look convincing, although they cannot be verified unless code is shared.\n\nReasonable direction of exploration - there are several possible similarity functions, this paper explores one of them that offers significantly less computational resources, which are essential for on-device applications. Thorough exploration of this idea was done and I am convinced this is a good alternative to regular attention.\n\nAll the rest of the paper was to incorporate this new method in different tasks in different architectures using or not using attention, and seeing the differences in terms of computational resources. Well thought experiments and results. Again, cannot be verified unless code is shared. ", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper252/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper252/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "Attention operators have been widely applied on data of various orders and dimensions such as texts, images, and videos. One challenge of applying attention operators is the excessive usage of computational resources. This is due to the usage of dot product and softmax operator when computing similarity scores. In this work, we propose the Siamese similarity function that uses a feed-forward network to compute similarity scores. This results in the Siamese attention operator (SAO). In particular, SAO leads to a dramatic reduction in the requirement of computational resources. Experimental results show that our SAO can save 94% memory usage and speed up the computation by a factor of 58 compared to the regular attention operator. The computational advantage of SAO is even larger on higher-order and higher-dimensional data. Results on image classification and restoration tasks demonstrate that networks with SAOs are as effective as models with regular attention operator, while significantly outperform those without attention operators.", "title": "Siamese Attention Networks", "keywords": [], "pdf": "/pdf/daae35ef79c7d2d28e65fa184da0b33a1ecd0846.pdf", "authors": ["Hongyang Gao", "Yaochen Xie", "Shuiwang Ji"], "authorids": ["hongyang.gao@tamu.edu", "ethanycx@tamu.edu", "sji@tamu.edu"], "paperhash": "gao|siamese_attention_networks", "original_pdf": "/attachment/fb5144032f2728665de4c840fe5c726bf0e19db2.pdf", "_bibtex": "@misc{\ngao2020siamese,\ntitle={Siamese Attention Networks},\nauthor={Hongyang Gao and Yaochen Xie and Shuiwang Ji},\nyear={2020},\nurl={https://openreview.net/forum?id=BJglA3NKwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJglA3NKwS", "replyto": "BJglA3NKwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper252/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper252/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575250545731, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper252/Reviewers"], "noninvitees": [], "tcdate": 1570237754818, "tmdate": 1575250545743, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper252/-/Official_Review"}}}, {"id": "SyeIqjBOir", "original": null, "number": 5, "cdate": 1573571470061, "ddate": null, "tcdate": 1573571470061, "tmdate": 1573571516700, "tddate": null, "forum": "BJglA3NKwS", "replyto": "BJglA3NKwS", "invitation": "ICLR.cc/2020/Conference/Paper252/-/Official_Comment", "content": {"title": "Comment on the new submission", "comment": "Dear reviewers,\n\nWe have updated our submission with following changes:\n\n1. We conduct experiments to compare our methods with Squeeze-and-Excite.\n\n2. We report the actual memory usage and time consumption of MobileNetV2, SANet, and AttnNet.\n\n3. We correct an error in Table 7."}, "signatures": ["ICLR.cc/2020/Conference/Paper252/Authors"], "readers": ["everyone", "ICLR.cc/2020/Conference/Paper252/Authors", "ICLR.cc/2020/Conference/Paper252/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper252/Reviewers", "ICLR.cc/2020/Conference/Paper252/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper252/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "Attention operators have been widely applied on data of various orders and dimensions such as texts, images, and videos. One challenge of applying attention operators is the excessive usage of computational resources. This is due to the usage of dot product and softmax operator when computing similarity scores. In this work, we propose the Siamese similarity function that uses a feed-forward network to compute similarity scores. This results in the Siamese attention operator (SAO). In particular, SAO leads to a dramatic reduction in the requirement of computational resources. Experimental results show that our SAO can save 94% memory usage and speed up the computation by a factor of 58 compared to the regular attention operator. The computational advantage of SAO is even larger on higher-order and higher-dimensional data. Results on image classification and restoration tasks demonstrate that networks with SAOs are as effective as models with regular attention operator, while significantly outperform those without attention operators.", "title": "Siamese Attention Networks", "keywords": [], "pdf": "/pdf/daae35ef79c7d2d28e65fa184da0b33a1ecd0846.pdf", "authors": ["Hongyang Gao", "Yaochen Xie", "Shuiwang Ji"], "authorids": ["hongyang.gao@tamu.edu", "ethanycx@tamu.edu", "sji@tamu.edu"], "paperhash": "gao|siamese_attention_networks", "original_pdf": "/attachment/fb5144032f2728665de4c840fe5c726bf0e19db2.pdf", "_bibtex": "@misc{\ngao2020siamese,\ntitle={Siamese Attention Networks},\nauthor={Hongyang Gao and Yaochen Xie and Shuiwang Ji},\nyear={2020},\nurl={https://openreview.net/forum?id=BJglA3NKwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJglA3NKwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper252/Authors", "ICLR.cc/2020/Conference/Paper252/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper252/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper252/Reviewers", "ICLR.cc/2020/Conference/Paper252/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper252/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper252/Authors|ICLR.cc/2020/Conference/Paper252/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504174141, "tmdate": 1576860547088, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper252/Authors", "ICLR.cc/2020/Conference/Paper252/Reviewers", "ICLR.cc/2020/Conference/Paper252/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper252/-/Official_Comment"}}}, {"id": "BJlnrz01jB", "original": null, "number": 1, "cdate": 1573016132331, "ddate": null, "tcdate": 1573016132331, "tmdate": 1573016132331, "tddate": null, "forum": "BJglA3NKwS", "replyto": "HylsrDYTtS", "invitation": "ICLR.cc/2020/Conference/Paper252/-/Official_Comment", "content": {"title": "Code release", "comment": "Thank you for your comments. We will release our code in the final version."}, "signatures": ["ICLR.cc/2020/Conference/Paper252/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper252/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "Attention operators have been widely applied on data of various orders and dimensions such as texts, images, and videos. One challenge of applying attention operators is the excessive usage of computational resources. This is due to the usage of dot product and softmax operator when computing similarity scores. In this work, we propose the Siamese similarity function that uses a feed-forward network to compute similarity scores. This results in the Siamese attention operator (SAO). In particular, SAO leads to a dramatic reduction in the requirement of computational resources. Experimental results show that our SAO can save 94% memory usage and speed up the computation by a factor of 58 compared to the regular attention operator. The computational advantage of SAO is even larger on higher-order and higher-dimensional data. Results on image classification and restoration tasks demonstrate that networks with SAOs are as effective as models with regular attention operator, while significantly outperform those without attention operators.", "title": "Siamese Attention Networks", "keywords": [], "pdf": "/pdf/daae35ef79c7d2d28e65fa184da0b33a1ecd0846.pdf", "authors": ["Hongyang Gao", "Yaochen Xie", "Shuiwang Ji"], "authorids": ["hongyang.gao@tamu.edu", "ethanycx@tamu.edu", "sji@tamu.edu"], "paperhash": "gao|siamese_attention_networks", "original_pdf": "/attachment/fb5144032f2728665de4c840fe5c726bf0e19db2.pdf", "_bibtex": "@misc{\ngao2020siamese,\ntitle={Siamese Attention Networks},\nauthor={Hongyang Gao and Yaochen Xie and Shuiwang Ji},\nyear={2020},\nurl={https://openreview.net/forum?id=BJglA3NKwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "BJglA3NKwS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper252/Authors", "ICLR.cc/2020/Conference/Paper252/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper252/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper252/Reviewers", "ICLR.cc/2020/Conference/Paper252/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper252/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper252/Authors|ICLR.cc/2020/Conference/Paper252/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504174141, "tmdate": 1576860547088, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper252/Authors", "ICLR.cc/2020/Conference/Paper252/Reviewers", "ICLR.cc/2020/Conference/Paper252/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper252/-/Official_Comment"}}}, {"id": "SkxmBKIRtS", "original": null, "number": 2, "cdate": 1571871034627, "ddate": null, "tcdate": 1571871034627, "tmdate": 1572972619182, "tddate": null, "forum": "BJglA3NKwS", "replyto": "BJglA3NKwS", "invitation": "ICLR.cc/2020/Conference/Paper252/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review": "The authors introduce a novel self-attention operator for neural networks. Their self-attention operator computes similarity between elements a and b as (a+b)^Tw where w is a learned parameter and does not use the softmax operator. This leads to improvements in space and time complexity compared to regular self-attention which uses the dot product (a^Tb).\nThey show that concatenating their operation with convolution brings improvements over the MobileNetv2 baseline on ImageNet classification and over U-Net on restoration tasks.\n\nAttention has been empirically shown to bring improvements in many visual tasks but certain methods (such as self-attention) can be quite expensive in computations and memory. Identifying cheaper attention mechanisms that obtain similar accuracy performance as expensive attention mechanisms is therefore an important direction for work.\n\nHowever, I take several crucial issues with this work and especially the evaluation/presentation of the methods:\n- Although this is the focus of the work, the authors do not report actual memory consumption and latency times for MobileNetv2, SANet and the other attention mechanisms. (There is no need for the simulated scenarios of Table 2 since we already know the theoretical complexities of the different methods).\n- The authors only compare their methods against regular self-attention (without or with pooling/softmax), and ignore a longstanding literature of other (potentially cheaper in terms of memory and computations) attention mechanisms in vision (see below). Without comparison to at least Squeeze-and-Excite, it is hard to evaluate the significance of the method presented in the draft.\n- The motivation for naming the method \"siamese\" is quite poor. Siamese networks typically are more complex than a single layer feed forward (which is just a dot-product). Furthermore, the siamese similarity (as introduced by the authors) does not respect the usual properties of similarity functions. For example siasim(a, 0) = a^tw = 1/2 siasim(a,a) can take arbitrary values including negative values (\"a can be dissimilar with itself\")\n- X vs Q, K, V? Self-attention is incorrectly described as \"a special case of the attention operator with Q = K = V\", instead of Q = XW^Q, K=XW^K, V = XW^V.\n- In Table 7, shouldn't SANet w/o params have less params than SANet?\n\nIn summary, the paper addresses an important challenge and proposes a technically sound method.  However, the current  draft has fundamental experimental flaws in its evaluation/presentation and lacks comparison against relevant cheap channelwise attention mechanisms (such as Squeeze-and-Excitation). I argue for rejection.\n\nRelevant literature:\n- channelwise attention: Squeeze-and-Excitation, Gather-Excite\n- Channelwise and spatial attention: Bottleneck Attention Module, Convolutional Block Attention Module\n- Relative Self-attention for vision: Attention Augmented Convolutional Networks, An Empirical Study of Spatial Attention Mechanisms in Deep Networks.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper252/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper252/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"abstract": "Attention operators have been widely applied on data of various orders and dimensions such as texts, images, and videos. One challenge of applying attention operators is the excessive usage of computational resources. This is due to the usage of dot product and softmax operator when computing similarity scores. In this work, we propose the Siamese similarity function that uses a feed-forward network to compute similarity scores. This results in the Siamese attention operator (SAO). In particular, SAO leads to a dramatic reduction in the requirement of computational resources. Experimental results show that our SAO can save 94% memory usage and speed up the computation by a factor of 58 compared to the regular attention operator. The computational advantage of SAO is even larger on higher-order and higher-dimensional data. Results on image classification and restoration tasks demonstrate that networks with SAOs are as effective as models with regular attention operator, while significantly outperform those without attention operators.", "title": "Siamese Attention Networks", "keywords": [], "pdf": "/pdf/daae35ef79c7d2d28e65fa184da0b33a1ecd0846.pdf", "authors": ["Hongyang Gao", "Yaochen Xie", "Shuiwang Ji"], "authorids": ["hongyang.gao@tamu.edu", "ethanycx@tamu.edu", "sji@tamu.edu"], "paperhash": "gao|siamese_attention_networks", "original_pdf": "/attachment/fb5144032f2728665de4c840fe5c726bf0e19db2.pdf", "_bibtex": "@misc{\ngao2020siamese,\ntitle={Siamese Attention Networks},\nauthor={Hongyang Gao and Yaochen Xie and Shuiwang Ji},\nyear={2020},\nurl={https://openreview.net/forum?id=BJglA3NKwS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "BJglA3NKwS", "replyto": "BJglA3NKwS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper252/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper252/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575250545731, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper252/Reviewers"], "noninvitees": [], "tcdate": 1570237754818, "tmdate": 1575250545743, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper252/-/Official_Review"}}}], "count": 7}