{"notes": [{"id": "HfnQjEN_ZC", "original": "HUl0ToOqgbsU", "number": 1999, "cdate": 1601308220203, "ddate": null, "tcdate": 1601308220203, "tmdate": 1614985636979, "tddate": null, "forum": "HfnQjEN_ZC", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Ballroom Dance Movement Recognition Using a Smart Watch and Representation Learning", "authorids": ["~Varun_Badrinath_Krishna1"], "authors": ["Varun Badrinath Krishna"], "keywords": ["ballroom", "sequence", "deep", "learning", "machine", "markov", "prior"], "abstract": "Smart watches are being increasingly used to detect human gestures and movements. Using a single smart watch, whole body movement recognition remains a hard problem because movements may not be adequately captured by the sensors in the watch. In this paper, we present a whole body movement detection study using a single smart watch in the context of ballroom dancing. Deep learning representations are used to classify well-defined sequences of movements, called \\emph{figures}. Those representations are found to outperform ensembles of random forests and hidden Markov models. The classification accuracy of 85.95\\% was improved to 92.31\\% by modeling a dance as a first-order Markov chain of figures.", "one-sentence_summary": "Deep learning combined with Markov priors are used ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "krishna|ballroom_dance_movement_recognition_using_a_smart_watch_and_representation_learning", "pdf": "/pdf/146e4cd8da3bf1cd841042a3b7aa15dc42d0002a.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=iKkziHi07h", "_bibtex": "@misc{\nkrishna2021ballroom,\ntitle={Ballroom Dance Movement Recognition Using a Smart Watch and Representation Learning},\nauthor={Varun Badrinath Krishna},\nyear={2021},\nurl={https://openreview.net/forum?id=HfnQjEN_ZC}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "Lz1zmGO95NI", "original": null, "number": 1, "cdate": 1610040524521, "ddate": null, "tcdate": 1610040524521, "tmdate": 1610474133578, "tddate": null, "forum": "HfnQjEN_ZC", "replyto": "HfnQjEN_ZC", "invitation": "ICLR.cc/2021/Conference/Paper1999/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "This paper initially received three negative reviews: 4,4,4. The main concerns of the reviewers included limited methodological novelty and an oversimplistic experimental setup. The authors did not submit their responses.\nAs a result, the final recommendation is reject."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Ballroom Dance Movement Recognition Using a Smart Watch and Representation Learning", "authorids": ["~Varun_Badrinath_Krishna1"], "authors": ["Varun Badrinath Krishna"], "keywords": ["ballroom", "sequence", "deep", "learning", "machine", "markov", "prior"], "abstract": "Smart watches are being increasingly used to detect human gestures and movements. Using a single smart watch, whole body movement recognition remains a hard problem because movements may not be adequately captured by the sensors in the watch. In this paper, we present a whole body movement detection study using a single smart watch in the context of ballroom dancing. Deep learning representations are used to classify well-defined sequences of movements, called \\emph{figures}. Those representations are found to outperform ensembles of random forests and hidden Markov models. The classification accuracy of 85.95\\% was improved to 92.31\\% by modeling a dance as a first-order Markov chain of figures.", "one-sentence_summary": "Deep learning combined with Markov priors are used ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "krishna|ballroom_dance_movement_recognition_using_a_smart_watch_and_representation_learning", "pdf": "/pdf/146e4cd8da3bf1cd841042a3b7aa15dc42d0002a.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=iKkziHi07h", "_bibtex": "@misc{\nkrishna2021ballroom,\ntitle={Ballroom Dance Movement Recognition Using a Smart Watch and Representation Learning},\nauthor={Varun Badrinath Krishna},\nyear={2021},\nurl={https://openreview.net/forum?id=HfnQjEN_ZC}\n}"}, "tags": [], "invitation": {"reply": {"forum": "HfnQjEN_ZC", "replyto": "HfnQjEN_ZC", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040524507, "tmdate": 1610474133562, "id": "ICLR.cc/2021/Conference/Paper1999/-/Decision"}}}, {"id": "4ac3H-dj8LB", "original": null, "number": 2, "cdate": 1603909994798, "ddate": null, "tcdate": 1603909994798, "tmdate": 1605024310624, "tddate": null, "forum": "HfnQjEN_ZC", "replyto": "HfnQjEN_ZC", "invitation": "ICLR.cc/2021/Conference/Paper1999/-/Official_Review", "content": {"title": "Official Review of Paper 1999 (ICLR 2021)", "review": "Authors propose an approach to perform classification of ballroom dance movements (called figures) captured by the sensing mechanism of a smartwatch and discriminated via different ANN architectures. The sequence of figures are modelled as a Marlov chain, which work in  a generative+discriminative fashion to output the final prediction of the model. Authors also present a dataset collected specifically for this work, to perform the inference of the algorithms included in the evaluation. Results show a remarkable accuracy, but are not compared to any existing state of art due to limited related work.\n\n-------------------------------------------------\nContributions\n\nThe paper addresses an application of HAR which I see can be of interest for the community due to its novelty. The dance recognition it\u2019s not a common domain and its analysis in terms of feature representation can fit correctly within the scope of the conference.\n\nThe paper is well written and easy to read. The state of art is adequate and gives enough background on the domain\n\n-------------------------------------------------\nPoints to improve\n\nThe principal flaw of the work, and main reason why I do not recommend its acceptance in the proceddings is its weak experimental setup and overall evaluation. Other, but less important, reasons for my recommendation are the lack of comprehensive reproducibility details and the weak findings included in the conclusions.\n\n-------------------------------------------------\nRecommendations\n\nA single dance (one type of sequence), performed by a single couple (lack of variability in the data collected) and a predefined sensor system (lack of multimodal/multilocation setup) is not sufficient to achieve solid results for the type of algorithm the authors want to evaluate. I understand it\u2019s difficult to collect high quality data, so I\u2019d suggest the authors to add data from related domains where the same representation learning can be employed or augment its own data expanding the sensory system (which in principle should be cheaper).\n\nThe value of the paper could be not just to address a specific application (ballroom dance recognition) using well known feature representations and algorithmic approaches. Honestly a more interesting motivation for me would be to explore how the type of data representation employed may help overcome effects of limited information when exploring domains where only scarce data is available. Specifically in the domain of HAR, where quality datasets are very expensive to collect. For me it\u2019d be very interesting to know which sensors, located in which part of the dances, and modelled under which representation can perform better. As I say an interesting approach could be to augment the sensory infrastructure to characterize the minimum amount of sensor data required based on different representations.\n\nFollowing my last comment, the Markov chain wrapping the figure classifier does not offer a significant contribution in my opinion. Its contribution is limited to just chain predictions from models which are translating sensor signals to human movements, that last part is where (in my opinion) the contribution is. The sequence modelling could be perfectly covered by the ANN using a different network topology.\n\nAlso, when the authors claim to perform sensor classification \u201cin real time\u201d I expect to see some experiments covering that claim. I\u2019m mean, there are no experiments addressing either the timing performance of the models or their power requirements. I\u2019d recommend including in the experimentation some test of the performance of the methods, not just their accuracy.\n\nI know it\u2019s not possible with the current dataset, but when cross validating in HAR it\u2019s more correct to do the splitting by user. Cross-validation based on the subjects offer a stronger vision of the generalization power of the method\n\nTo improve the reproducibility I\u2019d recommend further info. The sensor signal was downsampled to 100 samples, but what was the original resolution? From the rotation sensor only yaw channel is used (because is \u201cbased on prior knowledge that roll and pitch are insignificant in the waltz figures included in the study), please improve this explanation. A figure explicitly addressing the input representation would be useful.\n\nThe legend of the figures should be enough to understand the figure as a whole. Please improve theIt\u2019s honestly quite surprising that decision trees can work so well with raw features. Derived features (max, min, avg, kurtosis, skew ) tend to work better for these type of algorithms and are more commonly used.\n\n-------------------------------------------------\nMinor\n\nUsing the same terminology from sampling rate (in \u201c2.1 Data Collection\u201d relates to the frequency domain) and what later becomes the observation/instance (size 4x100) of a figure is a bit confusing in my opinion.\n\n The probability of observing the next figure is really independente of past figures sequence? Does not a dance require to include a number of figures during its execution? I\u2019ve the feeling that the accumulated number of figures also work as a prior for the next figure.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper1999/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1999/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Ballroom Dance Movement Recognition Using a Smart Watch and Representation Learning", "authorids": ["~Varun_Badrinath_Krishna1"], "authors": ["Varun Badrinath Krishna"], "keywords": ["ballroom", "sequence", "deep", "learning", "machine", "markov", "prior"], "abstract": "Smart watches are being increasingly used to detect human gestures and movements. Using a single smart watch, whole body movement recognition remains a hard problem because movements may not be adequately captured by the sensors in the watch. In this paper, we present a whole body movement detection study using a single smart watch in the context of ballroom dancing. Deep learning representations are used to classify well-defined sequences of movements, called \\emph{figures}. Those representations are found to outperform ensembles of random forests and hidden Markov models. The classification accuracy of 85.95\\% was improved to 92.31\\% by modeling a dance as a first-order Markov chain of figures.", "one-sentence_summary": "Deep learning combined with Markov priors are used ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "krishna|ballroom_dance_movement_recognition_using_a_smart_watch_and_representation_learning", "pdf": "/pdf/146e4cd8da3bf1cd841042a3b7aa15dc42d0002a.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=iKkziHi07h", "_bibtex": "@misc{\nkrishna2021ballroom,\ntitle={Ballroom Dance Movement Recognition Using a Smart Watch and Representation Learning},\nauthor={Varun Badrinath Krishna},\nyear={2021},\nurl={https://openreview.net/forum?id=HfnQjEN_ZC}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "HfnQjEN_ZC", "replyto": "HfnQjEN_ZC", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1999/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538106175, "tmdate": 1606915806987, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1999/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1999/-/Official_Review"}}}, {"id": "QeF9s_iwavE", "original": null, "number": 3, "cdate": 1604058975402, "ddate": null, "tcdate": 1604058975402, "tmdate": 1605024310560, "tddate": null, "forum": "HfnQjEN_ZC", "replyto": "HfnQjEN_ZC", "invitation": "ICLR.cc/2021/Conference/Paper1999/-/Official_Review", "content": {"title": "Explores some aspects of the recognition of dance figures in a sort of idealised scenario", "review": "This paper describes a system to classify dance figures using a wrist-worn device, exploring a number of different classifiers, and incorporating prior knowledge about dance to improve overall performance.\n\nWeaknesses / comments / suggestions:\n* Motivation / problem setting. The authors envision a scenario where the audience is informed about the individual dance moves through automated recognition. To motivate the use of ML in this setting this could be extended to illustrate the potential of ML in this area, particularly when it comes to amateurs. For example, representation learning would have the potential to allow assessment of the quality of individual moves, or the characterisation of an overall routine w.r.t. variety, where it could be used as a training aid.\n* Automatic segmentation of dance moves is not explored. The authors are significantly simplifying the problem by (manually) segmenting each individual figure in the data-set, and by removing any \"non-dancing\" behaviour from the boundaries. I believe in a practical setting, as envisioned by the authors, this information wouldn't be readily available. Also, it would make for an interesting problem - can you recover the boundaries between the different figures if presented with a continuous signal and potentially features from an audio stream?\n* Learning representations vs classification. While it is true that the NN-based approaches implicitly learn a representation of the data, they are exclusively used as classifiers in this work. It would be interesting to explore what these representations (e.g. activations in penultimate layer) actually look like, and if e.g. the dance moves that start with the same foot are similar in that representation space. \"Trajectories\" in that representation space would further be interesting to potentially 1) segment individual figures an 2) characterise the overall performance / variety of a complete routine.\n* Related work: While this application might be novel it is nevertheless closely related to other applications of human activity recognition. The literature on this is extensive, and the paper would benefit from characterising how the problem investigated differs from settings explored in related work, e.g. for other somewhat related sports (e.g. martial arts, rock climbing).\n\nIn summary, this paper explores some aspects of the recognition of dance figures in a sort of idealised scenario. Overall the paper is clearly written, albeit for a different audience than what is typically found at ICLR. The paper describes and motivates an application, describes data collection and explores a number of (standard) methods. While it is a nice application, the suitability for this community is limited as it will be difficult to transfer findings to other application settings and there is limited technical novelty / insight.", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2021/Conference/Paper1999/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1999/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Ballroom Dance Movement Recognition Using a Smart Watch and Representation Learning", "authorids": ["~Varun_Badrinath_Krishna1"], "authors": ["Varun Badrinath Krishna"], "keywords": ["ballroom", "sequence", "deep", "learning", "machine", "markov", "prior"], "abstract": "Smart watches are being increasingly used to detect human gestures and movements. Using a single smart watch, whole body movement recognition remains a hard problem because movements may not be adequately captured by the sensors in the watch. In this paper, we present a whole body movement detection study using a single smart watch in the context of ballroom dancing. Deep learning representations are used to classify well-defined sequences of movements, called \\emph{figures}. Those representations are found to outperform ensembles of random forests and hidden Markov models. The classification accuracy of 85.95\\% was improved to 92.31\\% by modeling a dance as a first-order Markov chain of figures.", "one-sentence_summary": "Deep learning combined with Markov priors are used ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "krishna|ballroom_dance_movement_recognition_using_a_smart_watch_and_representation_learning", "pdf": "/pdf/146e4cd8da3bf1cd841042a3b7aa15dc42d0002a.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=iKkziHi07h", "_bibtex": "@misc{\nkrishna2021ballroom,\ntitle={Ballroom Dance Movement Recognition Using a Smart Watch and Representation Learning},\nauthor={Varun Badrinath Krishna},\nyear={2021},\nurl={https://openreview.net/forum?id=HfnQjEN_ZC}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "HfnQjEN_ZC", "replyto": "HfnQjEN_ZC", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1999/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538106175, "tmdate": 1606915806987, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1999/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1999/-/Official_Review"}}}, {"id": "3vOHlZO_UxK", "original": null, "number": 1, "cdate": 1603896993148, "ddate": null, "tcdate": 1603896993148, "tmdate": 1605024310495, "tddate": null, "forum": "HfnQjEN_ZC", "replyto": "HfnQjEN_ZC", "invitation": "ICLR.cc/2021/Conference/Paper1999/-/Official_Review", "content": {"title": "Interesting application but not enough novelty ", "review": "The paper presents some classification results for ballroom dancing movements, as measured by inertial sensors on a smartwatch.  The motivation is mixed - as a guide to dancers themselves and as an automatic grading mechanism for competition judges. However the sensors used can only measure a very limited aspect of the dance, and there is no 'gold standard' data describing the full motion of the dancers that can then be compared with the limited data actually measured, to be able to contrast variations in the full body motion with variations in the intertial sensors on the smartwatch.  Describing the project as a study of whole body movement seems a bit brave given that you measure only hand movements. The restriction to the yaw axis will make results very sensitive to how the hand is held.\n\nThe paper is fairly clearly described, but the work uses fairly standard model structures and a very limited training set, so I'm not sure the reader really learns anything novel from the paper. In my opinion, it is below the level of technical challenge and novelty of solution usually associated with an ICLR paper\n\nIt is unclear whether cross-validation splitting was done randomly rather than breaking the time-series into a number of contiguous sections and working with these. If randomly from whole set, then I would worry about  effective independence. The training data seems to be very limited, with little variability in individuals, so it is hard to know whether the results are of any practical use.\n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper1999/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper1999/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Ballroom Dance Movement Recognition Using a Smart Watch and Representation Learning", "authorids": ["~Varun_Badrinath_Krishna1"], "authors": ["Varun Badrinath Krishna"], "keywords": ["ballroom", "sequence", "deep", "learning", "machine", "markov", "prior"], "abstract": "Smart watches are being increasingly used to detect human gestures and movements. Using a single smart watch, whole body movement recognition remains a hard problem because movements may not be adequately captured by the sensors in the watch. In this paper, we present a whole body movement detection study using a single smart watch in the context of ballroom dancing. Deep learning representations are used to classify well-defined sequences of movements, called \\emph{figures}. Those representations are found to outperform ensembles of random forests and hidden Markov models. The classification accuracy of 85.95\\% was improved to 92.31\\% by modeling a dance as a first-order Markov chain of figures.", "one-sentence_summary": "Deep learning combined with Markov priors are used ", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "krishna|ballroom_dance_movement_recognition_using_a_smart_watch_and_representation_learning", "pdf": "/pdf/146e4cd8da3bf1cd841042a3b7aa15dc42d0002a.pdf", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=iKkziHi07h", "_bibtex": "@misc{\nkrishna2021ballroom,\ntitle={Ballroom Dance Movement Recognition Using a Smart Watch and Representation Learning},\nauthor={Varun Badrinath Krishna},\nyear={2021},\nurl={https://openreview.net/forum?id=HfnQjEN_ZC}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "HfnQjEN_ZC", "replyto": "HfnQjEN_ZC", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper1999/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538106175, "tmdate": 1606915806987, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper1999/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper1999/-/Official_Review"}}}], "count": 5}