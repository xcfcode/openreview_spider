{"notes": [{"id": "WDVD4lUCTzU", "original": "-FFASXeKFw4", "number": 3639, "cdate": 1601308405000, "ddate": null, "tcdate": 1601308405000, "tmdate": 1614985694744, "tddate": null, "forum": "WDVD4lUCTzU", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Universal Sentence Representations Learning with Conditional Masked Language Model", "authorids": ["~Ziyi_Yang1", "~Yinfei_Yang1", "~Daniel_M_Cer1", "jaxlaw@google.com", "~Eric_Darve1"], "authors": ["Ziyi Yang", "Yinfei Yang", "Daniel M Cer", "Jax Law", "Eric Darve"], "keywords": ["multilingual representations", "sentence embeddings"], "abstract": "This paper presents a novel training method, Conditional Masked Language Modeling (CMLM), to effectively learn sentence representations on large scale unlabeled corpora. CMLM integrates sentence representation learning into MLM training by conditioning on the encoded vectors of adjacent sentences. Our English CMLM model achieves state-of-the-art performance on SentEval, even outperforming models learned using (semi-)supervised signals. As a fully unsupervised learning method, CMLM can be conveniently extended to a broad range of languages and domains. We find that a multilingual CMLM model co-trained with bitext retrieval~(BR) and natural language inference~(NLI) tasks outperforms the previous state-of-the-art multilingual models by a large margin. We explore the same language bias of the learned representations, and propose a principle component based approach to remove the language identifying information from the representation while still retaining sentence semantics.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yang|universal_sentence_representations_learning_with_conditional_masked_language_model", "pdf": "/pdf/10ac053dee69fab838499a6f3adf6405aad2491b.pdf", "supplementary_material": "/attachment/b3d7e445b0b071ba7541985d42cd50b14d69331a.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=BxexEz_vPH", "_bibtex": "@misc{\nyang2021universal,\ntitle={Universal Sentence Representations Learning with Conditional Masked Language Model},\nauthor={Ziyi Yang and Yinfei Yang and Daniel M Cer and Jax Law and Eric Darve},\nyear={2021},\nurl={https://openreview.net/forum?id=WDVD4lUCTzU}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 12, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "0EpVC3wT3F0", "original": null, "number": 1, "cdate": 1610040452881, "ddate": null, "tcdate": 1610040452881, "tmdate": 1610474055219, "tddate": null, "forum": "WDVD4lUCTzU", "replyto": "WDVD4lUCTzU", "invitation": "ICLR.cc/2021/Conference/Paper3639/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "This paper proposes a Conditional Masked Language Modeling (CMLM) method to enhance the MLM by conditioning on the contextual information. \n\nAll of the reviewers think the results are good. However, the reviewers also think the intuition and experiments are not so convincing. The responses and revisions still not satisfy all the reviewers' major concern."}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Universal Sentence Representations Learning with Conditional Masked Language Model", "authorids": ["~Ziyi_Yang1", "~Yinfei_Yang1", "~Daniel_M_Cer1", "jaxlaw@google.com", "~Eric_Darve1"], "authors": ["Ziyi Yang", "Yinfei Yang", "Daniel M Cer", "Jax Law", "Eric Darve"], "keywords": ["multilingual representations", "sentence embeddings"], "abstract": "This paper presents a novel training method, Conditional Masked Language Modeling (CMLM), to effectively learn sentence representations on large scale unlabeled corpora. CMLM integrates sentence representation learning into MLM training by conditioning on the encoded vectors of adjacent sentences. Our English CMLM model achieves state-of-the-art performance on SentEval, even outperforming models learned using (semi-)supervised signals. As a fully unsupervised learning method, CMLM can be conveniently extended to a broad range of languages and domains. We find that a multilingual CMLM model co-trained with bitext retrieval~(BR) and natural language inference~(NLI) tasks outperforms the previous state-of-the-art multilingual models by a large margin. We explore the same language bias of the learned representations, and propose a principle component based approach to remove the language identifying information from the representation while still retaining sentence semantics.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yang|universal_sentence_representations_learning_with_conditional_masked_language_model", "pdf": "/pdf/10ac053dee69fab838499a6f3adf6405aad2491b.pdf", "supplementary_material": "/attachment/b3d7e445b0b071ba7541985d42cd50b14d69331a.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=BxexEz_vPH", "_bibtex": "@misc{\nyang2021universal,\ntitle={Universal Sentence Representations Learning with Conditional Masked Language Model},\nauthor={Ziyi Yang and Yinfei Yang and Daniel M Cer and Jax Law and Eric Darve},\nyear={2021},\nurl={https://openreview.net/forum?id=WDVD4lUCTzU}\n}"}, "tags": [], "invitation": {"reply": {"forum": "WDVD4lUCTzU", "replyto": "WDVD4lUCTzU", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040452868, "tmdate": 1610474055202, "id": "ICLR.cc/2021/Conference/Paper3639/-/Decision"}}}, {"id": "FdjrveSXho", "original": null, "number": 4, "cdate": 1604161002236, "ddate": null, "tcdate": 1604161002236, "tmdate": 1606823321903, "tddate": null, "forum": "WDVD4lUCTzU", "replyto": "WDVD4lUCTzU", "invitation": "ICLR.cc/2021/Conference/Paper3639/-/Official_Review", "content": {"title": "The results are good but mainly empirical", "review": "This paper presents Conditional Masked Language Modeling (CMLM), which integrates sentence representation learning into MLM training by conditioning on the encoded vectors of adjacent sentences. It is shown that the English CMLM model achieves strong performance on SentEval, and outperforms models learned using (semi-)supervised signals. It is also found that a multilingual CMLM model co-trained with bitext retrieval (BR) and natural language inference (NLI) tasks outperforms the previous state-of-the-art multilingual models by a large margin. The paper further proposes a principle component based approach to remove the language identifying information from the representation while still retaining sentence semantics.\n\n-Strengths\n\nLearning sentence representations on large scale unlabeled corpora is an important research problem. This paper presents a heavily empirical study, with a series of experiments to evaluate the proposed sentence representation learning method. Multilingual experiments are conducted, with interesting results on language agnostic.\n\nThe proposed method, as shown in Figure 1, is somewhat new.\n\n-Weaknesses\n\nThe study is mainly empirical.\nThe authors should provide more details about the three-layer neural network as the projection P (\u00b7).\nAnother concern is that the contribution of this paper to research community may be weak, if the code is not released and the results are not easily reproduced.\n\n--------update after reading the response-----------\n\nThanks for the authors' response. Mainly empirical and limited in methodology novelty. So I tend to keep the score.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3639/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3639/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Universal Sentence Representations Learning with Conditional Masked Language Model", "authorids": ["~Ziyi_Yang1", "~Yinfei_Yang1", "~Daniel_M_Cer1", "jaxlaw@google.com", "~Eric_Darve1"], "authors": ["Ziyi Yang", "Yinfei Yang", "Daniel M Cer", "Jax Law", "Eric Darve"], "keywords": ["multilingual representations", "sentence embeddings"], "abstract": "This paper presents a novel training method, Conditional Masked Language Modeling (CMLM), to effectively learn sentence representations on large scale unlabeled corpora. CMLM integrates sentence representation learning into MLM training by conditioning on the encoded vectors of adjacent sentences. Our English CMLM model achieves state-of-the-art performance on SentEval, even outperforming models learned using (semi-)supervised signals. As a fully unsupervised learning method, CMLM can be conveniently extended to a broad range of languages and domains. We find that a multilingual CMLM model co-trained with bitext retrieval~(BR) and natural language inference~(NLI) tasks outperforms the previous state-of-the-art multilingual models by a large margin. We explore the same language bias of the learned representations, and propose a principle component based approach to remove the language identifying information from the representation while still retaining sentence semantics.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yang|universal_sentence_representations_learning_with_conditional_masked_language_model", "pdf": "/pdf/10ac053dee69fab838499a6f3adf6405aad2491b.pdf", "supplementary_material": "/attachment/b3d7e445b0b071ba7541985d42cd50b14d69331a.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=BxexEz_vPH", "_bibtex": "@misc{\nyang2021universal,\ntitle={Universal Sentence Representations Learning with Conditional Masked Language Model},\nauthor={Ziyi Yang and Yinfei Yang and Daniel M Cer and Jax Law and Eric Darve},\nyear={2021},\nurl={https://openreview.net/forum?id=WDVD4lUCTzU}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "WDVD4lUCTzU", "replyto": "WDVD4lUCTzU", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3639/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538072323, "tmdate": 1606915787511, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3639/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3639/-/Official_Review"}}}, {"id": "I_H2kz-72M", "original": null, "number": 2, "cdate": 1603988938738, "ddate": null, "tcdate": 1603988938738, "tmdate": 1606447047848, "tddate": null, "forum": "WDVD4lUCTzU", "replyto": "WDVD4lUCTzU", "invitation": "ICLR.cc/2021/Conference/Paper3639/-/Official_Review", "content": {"title": "A reasonable work, but a bit limited in terms of technical contribution, particularly considering that there is not a good intuition explanation.", "review": "I appreciate the response from the authors to my review, as well as to others. \n\nMy concerns on the intuition are most not solved. Although in this DNN dominating era, we cannot expect the explainability as we had before, I still believe that a solid work should be grounded on a reasonable basis, which could be in a high level, such as BERT and SBERT. Let's refer to the example given in the model architecture. The projection of the sentence vector of \"Life is a box of chocolates\" is left-concatenated with the masked embeddings of the second sentence. This operation is very much lacking in intuition, how come the projection of a sentence representation can be concatenated with the embeddings? In addition, \"The second encoder shares the same weights with the encoder used to embed s1\", considering their inputs are very different, weight sharing for the two encoders are also problematic.\n\nAnother point I just noticed, although the authors claimed that their model is better than SBERT, and did a comparison with SBERT-large, they did not compare with SBERT-base, which makes the conclusion unreliable.\n\n---------------------------------------------------------------------------------------------------------------------------\nThis paper proposes a method called \"Conditional Masked Language Model\" for unsupervised sentence representation learning. The method involves two-sentence encoder, where one sentence depends on the encoded sentence level representation of the adjacent sentence. The experimental results are good overall, as the proposed method tends to give the best results across monolingual and multilingual benchmark datasets.\n\nThere are still some concerns about the novelty of this paper.  First, I think the explanations for the intuition of the proposed model can be clarified, especially in the introduction section. Second, the baselines used for comparison are not complete, which makes me concern about the effectiveness of the model. The proposed model is the combination of Skip-Thought (Kiros et al., 2015) and BERT masked LM (Devlin et al., 2019).  Their experimental results show a detailed comparison of BERT but ignore much about the Skip-Thought. Although the authors mentioned the results of the Skip-Thought model on the SentEval benchmark, the encoder used in the Skip-Thought (Kiros et al., 2015) is RNN while the author used the Transformer Encoder.  I would appreciate a better and fair comparison of the Skip-Thought model by using same transformer encoder and same training corpus.\n\nI am not sure why you used the concatenation when you do the masked LM.  Are there any other ways to do that?  It can be more convincing to see some analysis or results here. Additionally, there is another work titled \u201cDeCLUTR: Deep Contrastive Learning for Unsupervised Textual Representations\u201d, which also focuses on unsupervised sentence representation learning.  Although it is from arxiv, it would be nice that the authors can mention this work.\n\nIt seems good that the authors performed many experiments over many different datasets across monolingual and multilingual.  The exploration of the same language bias of the learned representations is also very interesting.\n\nTo summarize, the paper is a bit limited in terms of technical contribution, particularly considering that there is not a good intuition explanation, but some analysis in this paper looks good.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3639/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3639/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Universal Sentence Representations Learning with Conditional Masked Language Model", "authorids": ["~Ziyi_Yang1", "~Yinfei_Yang1", "~Daniel_M_Cer1", "jaxlaw@google.com", "~Eric_Darve1"], "authors": ["Ziyi Yang", "Yinfei Yang", "Daniel M Cer", "Jax Law", "Eric Darve"], "keywords": ["multilingual representations", "sentence embeddings"], "abstract": "This paper presents a novel training method, Conditional Masked Language Modeling (CMLM), to effectively learn sentence representations on large scale unlabeled corpora. CMLM integrates sentence representation learning into MLM training by conditioning on the encoded vectors of adjacent sentences. Our English CMLM model achieves state-of-the-art performance on SentEval, even outperforming models learned using (semi-)supervised signals. As a fully unsupervised learning method, CMLM can be conveniently extended to a broad range of languages and domains. We find that a multilingual CMLM model co-trained with bitext retrieval~(BR) and natural language inference~(NLI) tasks outperforms the previous state-of-the-art multilingual models by a large margin. We explore the same language bias of the learned representations, and propose a principle component based approach to remove the language identifying information from the representation while still retaining sentence semantics.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yang|universal_sentence_representations_learning_with_conditional_masked_language_model", "pdf": "/pdf/10ac053dee69fab838499a6f3adf6405aad2491b.pdf", "supplementary_material": "/attachment/b3d7e445b0b071ba7541985d42cd50b14d69331a.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=BxexEz_vPH", "_bibtex": "@misc{\nyang2021universal,\ntitle={Universal Sentence Representations Learning with Conditional Masked Language Model},\nauthor={Ziyi Yang and Yinfei Yang and Daniel M Cer and Jax Law and Eric Darve},\nyear={2021},\nurl={https://openreview.net/forum?id=WDVD4lUCTzU}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "WDVD4lUCTzU", "replyto": "WDVD4lUCTzU", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3639/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538072323, "tmdate": 1606915787511, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3639/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3639/-/Official_Review"}}}, {"id": "RUu_AFkp7jK", "original": null, "number": 6, "cdate": 1606013529795, "ddate": null, "tcdate": 1606013529795, "tmdate": 1606298416827, "tddate": null, "forum": "WDVD4lUCTzU", "replyto": "I_H2kz-72M", "invitation": "ICLR.cc/2021/Conference/Paper3639/-/Official_Comment", "content": {"title": "Response to Reviewer 3", "comment": "Thanks for your review and valuable comments! Please find our responses below:\n\n**1. \"What is the intuition for the proposed Model?\"**\n\n- As mentioned in the second paragraph in section 2, the intuition behind CMLM is \"to make the encoder produce an effective sentence level embedding of the first sentence for better MLM prediction of the second sentence\". We followed your suggestion by modifying the introduction section, especially the second paragraph, to make the intuition behind CMLM clearer.\n- The intuition for bitext retrieval (BR) is to make the multilingual representation language agnostic, which is confirmed by the outstanding zero-shot cross lingual performance on Amazon Reviews (Table 4) and high cross lingual accuracy on Tatoeba (Table 5).\n- The intuition for cross lingual NLI finetuning is to provide supervised learning signals and improve the quality of sentence representations. This is supported by the significant improvements from NLI finetuning on Amazon Reviews Dataset (Tabel 5, between rows \u201cCMLM+BR\u201d and \u201cCMLM+BR+NLI\u201d) and XEVAL (Table 3, between rows \u201cS3\u201d and row \u201cS3+NLI\u201d).\n\n**2. \"CMLM looks similar to SkipThought. The baselines used for comparison are not complete since authors should compare with baselines (e.g. SkipThought) using Transformer.\"**\n\nFollowing your suggestion, we implement QuickThought (a more recent and better unsupervised sentence representation learning model than SkipThought) with Transformer and train with our data. It is denoted as \u201cQuickThought (CC)\u201d in Table 1. Leveraging our data or Transformer does not make QuickThought better than our models.\n\nAlso note that our model differs from SkipThought in the following aspects:\n+ SkipThought relies on an extra decoder network while CMLM only has the encoder. \n+ SkipThought predicts the entire sentence while CMLM predicts masked tokens only so the predictions can be done in parallel.\n\nThese two differences make CMLM more efficient to train when compared with SkipThought.\n\n**3. \"Are there any other ways besides using \"concatenation\" in CMLM? It can be more convincing to see some analysis or results here.\".** \n\nYes. And analysis and results were already in the paper. We are sorry if results were not presented more explicitly. Concretely, besides the \u201cconcatenation\u201d, we also tried the \u201cskip connection\u201d configuration in CMLM. Results using this \u201cskip connection\u201d are presented in Table 7, row \u201cskip\u201d. The model architecture of \u201cskip connection\u201d is as follows. Given two sentences $s_1$ and $s_2$. By inputting $s_2$ to the transformer encoder, we obtain an output $M \\in R^{H \\times L}$, where H denotes the hidden size and L denotes the maximum token length. Recall the sentence representation of s1 is computed as $v \\in R^{H}$. We then concatenate $v$ to each column $m_i$ ($i = 1,2,\\dots,L$) in $M$. The concatenated tensor $M'$ is of size $2H\\times L$, We then use $M\u2019$ as the input for masked token prediction in $s_2$. As shown in table 2, our current configuration \u201cconcatenation\u201d is better.\n\n**4. Citations.**\n\nThanks for pointing out this paper! We\u2019ve cited the DeCLUTR paper as suggested.\n\n**5. We add extra experiments on Tatoeba Semantic Retrieval Dataset to the paper.**\n\nWe further evaluate our models on the Tatoeba dataset, as shown in Table 5. Our models \u201cCMLM+BR\u201d outperforms all baseline models by a significant margin in terms of the average performance. It also has the highest accuracy in 30 out of 36 languages.\n"}, "signatures": ["ICLR.cc/2021/Conference/Paper3639/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3639/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Universal Sentence Representations Learning with Conditional Masked Language Model", "authorids": ["~Ziyi_Yang1", "~Yinfei_Yang1", "~Daniel_M_Cer1", "jaxlaw@google.com", "~Eric_Darve1"], "authors": ["Ziyi Yang", "Yinfei Yang", "Daniel M Cer", "Jax Law", "Eric Darve"], "keywords": ["multilingual representations", "sentence embeddings"], "abstract": "This paper presents a novel training method, Conditional Masked Language Modeling (CMLM), to effectively learn sentence representations on large scale unlabeled corpora. CMLM integrates sentence representation learning into MLM training by conditioning on the encoded vectors of adjacent sentences. Our English CMLM model achieves state-of-the-art performance on SentEval, even outperforming models learned using (semi-)supervised signals. As a fully unsupervised learning method, CMLM can be conveniently extended to a broad range of languages and domains. We find that a multilingual CMLM model co-trained with bitext retrieval~(BR) and natural language inference~(NLI) tasks outperforms the previous state-of-the-art multilingual models by a large margin. We explore the same language bias of the learned representations, and propose a principle component based approach to remove the language identifying information from the representation while still retaining sentence semantics.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yang|universal_sentence_representations_learning_with_conditional_masked_language_model", "pdf": "/pdf/10ac053dee69fab838499a6f3adf6405aad2491b.pdf", "supplementary_material": "/attachment/b3d7e445b0b071ba7541985d42cd50b14d69331a.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=BxexEz_vPH", "_bibtex": "@misc{\nyang2021universal,\ntitle={Universal Sentence Representations Learning with Conditional Masked Language Model},\nauthor={Ziyi Yang and Yinfei Yang and Daniel M Cer and Jax Law and Eric Darve},\nyear={2021},\nurl={https://openreview.net/forum?id=WDVD4lUCTzU}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "WDVD4lUCTzU", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3639/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3639/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3639/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3639/Authors|ICLR.cc/2021/Conference/Paper3639/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3639/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923835440, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3639/-/Official_Comment"}}}, {"id": "W0yDIwgcCIn", "original": null, "number": 8, "cdate": 1606207514441, "ddate": null, "tcdate": 1606207514441, "tmdate": 1606247025243, "tddate": null, "forum": "WDVD4lUCTzU", "replyto": "1jVUti2kkB4", "invitation": "ICLR.cc/2021/Conference/Paper3639/-/Official_Comment", "content": {"title": "Response to Reviewer 1\u2019s reply", "comment": "We appreciate Reviewer 1\u2019s timely response to our rebuttals. Thank you! Please find below our answers to questions raised Reviewer 1.\n\n**\u201cThe paper would be far more compelling if the authors can provide strong evidence that the sentence embeddings do well on tasks where using a BERT model is either less effective due to performance or computational reasons.\u201d**\n\nWe actually have provided results on such tasks that Reviewer 1 asks for:\n\n- On Amazon Review Dataset, we did try finetuning BERT (Table 4, \u201cEncoder parameters are trained during finetuning\u201d) with in-domain data. In all 4 languages, our models (CMLM, CMLM+BR, CMLM+BR+NLI) have much better performance than finetuned BERT (e.g., 88.6% v.s. 74.0% classification accuracy on Japanese). Especially note that CMLM without finetuning (row \u201cCMLM\u201d in the first group in Table 4) even outperforms finetuned mBERT (row \u201cmBERT\u201d in the second group). This shows that finetuning is not necessarily the only way to produce good embeddings; a well-pretrained sentence representation like CMLM can generate powerful representations..\n\n- We further evaluate languages in the Tatoeba Dataset (table 5). In all 36 languages, our models outperform BERT by significant margins. Concretely, the average retrieval accuracy of our model is 94.7% v.s. 38.7% of mBERT. We believe these two evaluations reflect the case where \u201ca BERT model is less effective due to performance (than CMLM)\u201d.\n\n\n**\u201cWhile SentEval is a useful benchmark to evaluate sentence representations, it doesn't reflect well how these representations will be used in practice. A fine-tuned BERT model will likely perform strongly on these tasks.\u201d**\n\nIn practice, there are many use cases where sentence representations are needed. For example, pre-encoding sentences for retrieval (text records search). Sentence embeddings are still one of the best choices for clustering, retrieval, and modular use of text representations for downstream tasks.\n\n**From these questions raised by Reviewer 1, we feel like the reviewer may have a concern about the research direction of sentence embeddings. Is sentence representation a research direction worth studying when we already have BERT? Why not just finetune BERT?**\n\n- In cases where supervised data are unavailable and you cannot finetune BERT, e.g., clustering and retrieval, having a general-purpose sentence encoding system is crucial for problems.\n\n- Actually in practice, finetuning BERT can result in a drop in performance. In some in-house applications, we observe that finetuning BERT actually yields worse results, e.g. tasks with a single sentence as input. Maybe this is because finetuning makes BERT forget what it learns in pretraining. But in the BERT original paper, the GLUE tasks that BERT shows obvious advantage are those with pair-wised inputs, where BERT-style fine-grained interactions in the finetuning are at advantage. For tasks with single input, there is no strong evidence that a sentence encoding system cannot perform as well as BERT.\n\n- In many non-NLP fields, sentence representations are pre-fixed input features to other systems, which is the same setting that SentEval holds. For example, in Biology [4] and Social Network Analysis [5, 6]. That\u2019s part of why sentence encodings systems like USE (one of most downloaded pre-trained text modules in Tensorflow Hub) and InferSent are still widely used, even after BERT is introduced.\n\n- \u201cHow much information and what information we can encode into one sentence\u201d is still an open-ended research problem in NLP [1]. CMLM and explorations on language-agnosticism in this paper provide some insight to this research question.\n\nReference:\n\n[1] Conneau, Alexis, et al. \"What you can cram into a single $ &!#* vector: Probing sentence embeddings for linguistic properties.\" ACL, 2018.\n\n[2] Cer, et al. \"Universal sentence encoder.\" arXiv preprint arXiv:1803.11175 (2018).\n\n[3] Conneau, Alexis, et al. \"Supervised Learning of Universal Sentence Representations from Natural Language Inference Data.\" EMNLP 2017.\n\n[4] Chen, Qingyu, Yifan Peng, and Zhiyong Lu. \"BioSentVec: creating sentence embeddings for biomedical texts.\" 2019 IEEE International Conference on Healthcare Informatics (ICHI). IEEE, 2019.\n\n[5] Mishra, Rohan, et al. \"SNAP-BATNET: Cascading author profiling and social network graphs for suicide ideation detection on social media.\" Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop. 2019.\n\n[6] Wang, Qiaozhi, et al. \"# DontTweetThis: Scoring Private Information in Social Networks.\" Proceedings on Privacy Enhancing Technologies 2019.4 (2019): 72-92."}, "signatures": ["ICLR.cc/2021/Conference/Paper3639/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3639/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Universal Sentence Representations Learning with Conditional Masked Language Model", "authorids": ["~Ziyi_Yang1", "~Yinfei_Yang1", "~Daniel_M_Cer1", "jaxlaw@google.com", "~Eric_Darve1"], "authors": ["Ziyi Yang", "Yinfei Yang", "Daniel M Cer", "Jax Law", "Eric Darve"], "keywords": ["multilingual representations", "sentence embeddings"], "abstract": "This paper presents a novel training method, Conditional Masked Language Modeling (CMLM), to effectively learn sentence representations on large scale unlabeled corpora. CMLM integrates sentence representation learning into MLM training by conditioning on the encoded vectors of adjacent sentences. Our English CMLM model achieves state-of-the-art performance on SentEval, even outperforming models learned using (semi-)supervised signals. As a fully unsupervised learning method, CMLM can be conveniently extended to a broad range of languages and domains. We find that a multilingual CMLM model co-trained with bitext retrieval~(BR) and natural language inference~(NLI) tasks outperforms the previous state-of-the-art multilingual models by a large margin. We explore the same language bias of the learned representations, and propose a principle component based approach to remove the language identifying information from the representation while still retaining sentence semantics.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yang|universal_sentence_representations_learning_with_conditional_masked_language_model", "pdf": "/pdf/10ac053dee69fab838499a6f3adf6405aad2491b.pdf", "supplementary_material": "/attachment/b3d7e445b0b071ba7541985d42cd50b14d69331a.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=BxexEz_vPH", "_bibtex": "@misc{\nyang2021universal,\ntitle={Universal Sentence Representations Learning with Conditional Masked Language Model},\nauthor={Ziyi Yang and Yinfei Yang and Daniel M Cer and Jax Law and Eric Darve},\nyear={2021},\nurl={https://openreview.net/forum?id=WDVD4lUCTzU}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "WDVD4lUCTzU", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3639/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3639/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3639/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3639/Authors|ICLR.cc/2021/Conference/Paper3639/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3639/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923835440, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3639/-/Official_Comment"}}}, {"id": "1jVUti2kkB4", "original": null, "number": 1, "cdate": 1603802693484, "ddate": null, "tcdate": 1603802693484, "tmdate": 1606170148483, "tddate": null, "forum": "WDVD4lUCTzU", "replyto": "WDVD4lUCTzU", "invitation": "ICLR.cc/2021/Conference/Paper3639/-/Official_Review", "content": {"title": "Low significance, issues in experiments and setup", "review": "----------\n\nI appreciate the response from authors and the additional experiments. I do think the semantic search task adds value to the paper. However, the paper continues to be centered around the SentEval benchmark results. While SentEval is a useful benchmark to evaluate sentence representations, it doesn't reflect well how these representations will be used in practice. A fine-tuned BERT model will likely perform strongly on these tasks. The paper would be far more compelling if the authors can provide strong evidence that the sentence embeddings do well on tasks where using a BERT model is either less effective due to performance or computational reasons. \n\nI prefer to keep my score. \n\n------------\n\nThis work proposes a self-supervised training objective called CMLM (conditional masked language model) for learning sentence representations. An encoder produces multiple fixed length representations of a given sentence and a decoder reconstructs the adjacent sentence given it\u2019s masked version and the encoded representations. CMLM performs well on the SentEval benchmark. CMLM is further extended to the multilingual setting via bi-text retrieval contrastive training and training on NLI data. The multilingual version is shown to work well on multiple translated versions of the SentEval benchmark (SentEval data translated into other languages using an off the shelf translation system) and Amazon reviews (sentiment classification).   \n\n\nPros\n* This work addresses the important problem of (unsupervised) sentence representation learning. Extracting fixed-length sentence representations from popular language model based encoders is a non-trivial problem and this work attempts to provide a solution.\n* Experiments go beyond the standard English setting and evaluate sentence representations in the multilingual setting as well. \n* Interesting modeling approaches.\n\nCons\n* Experiments are weak. It is unclear to what extent the tasks + evaluation protocol considered here are reflective of language understanding. I don\u2019t think strong baselines were considered. Some of the evaluation benchmarks considered seem arbitrary.\n* Model is largely based on prior work. The main contribution is not clear. There are many settings considered in the paper and it is unclear if the proposed contributions are truly significant due to weak baselines are differences in data used for training different methods.\n\nThere are several issues with the experimental setup.\n* Evaluation protocol: It is unclear if the evaluation protocol considered is measuring language understanding capability well. Representations from the encoders are held fixed and linear classifiers are trained on top of these fixed representations on downstream tasks using labelled data. To me, this is not a setting that demands sentence vectors. It only shows that the sentence vectors capture useful features. I would suggest focusing on a setting where the advantage of the sentence vectors can be demonstrated such as a retrieval problem.\n* Baselines: It is unfair to compare the proposed method against baselines like BERT which are not designed to produce fixed length encodings. \n* Data used for pre-training: It is difficult to gauge how good the method is in comparison to other models due to differences in the data used for pre-training. Ideally, there should be a table comparing models that use the exact same resources. In Table 1, although BERT-base/large is trained on the same data, it is not a strong baseline since mean pooled representations from the encoder are treated as a sentence representation. Ideally, the model should be compared against a skip-thought baseline or an unsupervised sentence representation learning method that uses the same resources for training. \n\nI would have expected the authors to evaluate multilingual representations on existing benchmarks as well. I don\u2019t find the proposed benchmark XEVAL very convincing. Claims would have been stronger if authors had also included results on existing benchmarks. \n\nThe authors need to make it clear exactly what resources are used for training each method. \n\nPresentation can be improved, especially the organization of the paper. It is difficult to follow the paper and identify the main contributions in the current presentation. \n\nThe paper touches upon several things - conditional masked language modeling, bitext retrieval, NLI training, language agnosticism, etc, and I find the paper quite incoherent. I suggest the authors make a focused contribution and provide strong experimental evidence to support that contribution. Right now there\u2019s too many things which makes it hard to make sense of the paper as whole.\n\nWhile the approaches considered in the paper have some merit, the significance of this work is unclear due to issues in the evaluation. \n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3639/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3639/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Universal Sentence Representations Learning with Conditional Masked Language Model", "authorids": ["~Ziyi_Yang1", "~Yinfei_Yang1", "~Daniel_M_Cer1", "jaxlaw@google.com", "~Eric_Darve1"], "authors": ["Ziyi Yang", "Yinfei Yang", "Daniel M Cer", "Jax Law", "Eric Darve"], "keywords": ["multilingual representations", "sentence embeddings"], "abstract": "This paper presents a novel training method, Conditional Masked Language Modeling (CMLM), to effectively learn sentence representations on large scale unlabeled corpora. CMLM integrates sentence representation learning into MLM training by conditioning on the encoded vectors of adjacent sentences. Our English CMLM model achieves state-of-the-art performance on SentEval, even outperforming models learned using (semi-)supervised signals. As a fully unsupervised learning method, CMLM can be conveniently extended to a broad range of languages and domains. We find that a multilingual CMLM model co-trained with bitext retrieval~(BR) and natural language inference~(NLI) tasks outperforms the previous state-of-the-art multilingual models by a large margin. We explore the same language bias of the learned representations, and propose a principle component based approach to remove the language identifying information from the representation while still retaining sentence semantics.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yang|universal_sentence_representations_learning_with_conditional_masked_language_model", "pdf": "/pdf/10ac053dee69fab838499a6f3adf6405aad2491b.pdf", "supplementary_material": "/attachment/b3d7e445b0b071ba7541985d42cd50b14d69331a.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=BxexEz_vPH", "_bibtex": "@misc{\nyang2021universal,\ntitle={Universal Sentence Representations Learning with Conditional Masked Language Model},\nauthor={Ziyi Yang and Yinfei Yang and Daniel M Cer and Jax Law and Eric Darve},\nyear={2021},\nurl={https://openreview.net/forum?id=WDVD4lUCTzU}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "WDVD4lUCTzU", "replyto": "WDVD4lUCTzU", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3639/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538072323, "tmdate": 1606915787511, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3639/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3639/-/Official_Review"}}}, {"id": "geo0tdb3NW-", "original": null, "number": 3, "cdate": 1604004712556, "ddate": null, "tcdate": 1604004712556, "tmdate": 1606139633724, "tddate": null, "forum": "WDVD4lUCTzU", "replyto": "WDVD4lUCTzU", "invitation": "ICLR.cc/2021/Conference/Paper3639/-/Official_Review", "content": {"title": "SkipThought + MLM: worth exploring, more details would improve the article", "review": "The authors present conditional masked language modeling (CMLM), a new method for unsupervised pretraining, in which the skip-thought notion of conditioning on neighboring sentences is adopted for masked language modeling. The upshot of the proposed approach is that it generates single sentence embeddings that perform competitively on SentEval. In the multilingual setting, the authors combine their CMLM method with a bitext retrieval objective (selecting a sentence\u2019s translation from the other sentences of the language in the batch) that increases performance on a version of the SentEval tasks translated into 14 other languages. In their analysis, the authors make further claims about multilingual embeddings capturing language ID information in their first principle components, a conclusion somewhat substantiated by their results. The authors provide a small amount of ablation experiments for experimental/model design choices.\n\nThe underlying idea is worth pursuing, the execution and description could be improved, people will be interested in the results that are present (but then have questions).\n\n\nOverall\n\nWhy only a subset of SentEval for the English experiments (3.2) but then the full SentEval in the multilingual XEval experiment (4.5.1)?  Especially if you are trying to make a single-sentence encoder but then evaluating on SICK-E instead of SICK-R, which is arguably a more applicable eval set. \n\nWhy no XLM-R in the amazon reviews analysis (4.5.2)?\n\nSec 1.\nFig 1: box of chocolate*s*\n\n\nSec 2.\n--\u201cconditional\u201d, \u2192  \u201cconditional,\u201d\n\n--no quantitative comparison of using max vs mean pool vs CLS embedding\n\n--first sentence is feed \u2192 first sentence is fed\n\n--three-layer neural network \u2192 three-layer MLP\n\n--refer to using the same set of encoder weights for different inputs as siamese networks, as done in the sentence-bert paper https://en.wikipedia.org/wiki/Siamese_neural_network\n\n-- v_d is used but not defined\n\n\nSec 3.\n--Skip-thought originally used a sentence to predict the generation of both the preceding and succeeding sentences. This is functionally equivalent to your flip-flopping the order of the consecutive sequences. I would make the point that these steps are equivalent.  Note that this is also not necessarily making the task \u201cmore challenging\u201d (and moreover I am not sure why \u201cmore challenging\u201d equates with \u201cbetter pretraining method for language understanding\u201d -- and an ablation of this step is not included to show that it is in fact necessary and useful).\n\n-- similarly, no analysis of masking rate, nor explanation for why \u2018more challenging\u2019 is better.\n\n-- \u201cWe explore two transformer configurations, base and large, same as in the original BERT paper.\u201d \u2013 fragmented\n\n-- The number of projections N = 15. \u2013 fragmented\n\n-- SentBERT \u2192 SentenceBERT or SBERT\n\n-- On the specific subset of SentEval tasks you\u2019ve selected, the majority of the performance discrepancy is in the SICK-E  task--otherwise, the overall #\u2019s are rather interchangeable. How does this change if you add in the rest of the SentEval tasks, and why were they omitted? Analysis/exploration for why you get such a performance boost only on SICK-E would also be useful.\n\n-- \u201cthe length \u2026 set to be 256 tokens\u201d: please clarify whether the \u201clength\u201d refers to the maximum length, or each sentence is a fixed-length chunk consisting of 256 tokens\n\n--typo:  \u201cwe also exploring\u201d\n\n\nSec 4.\n--If your introduced bitext retrieval objective uses batch size, experiments comparing the effect of batch size is necessary. \n\n-- Please specify the value of the margin m being used in the experiments\n\n--Choice of number of projections is also not motivated (and in fact contradicted by the ablation  experiment finding that 15 is better)\n\n-- the motivation and contribution for XEVAL are great-- the explanation of the dataset is lacking. What translation API was used? How was the XEVAL score computed for each language? Is it the full set of SentEval downstream tasks?\n\n-- cite precedent for using the concatenation of u,v, u-v and u*v. (or show its effect via ablation)\n\n-- BR  \u2192 CMLM+BR configuration not evaluated\n\n-- choice of different training step #\u2019s in each configuration is not particularly motivated.\n\n-- \u201cafter exploring options including [CLS] representations and max pooling.\u201d what was the performance drop?\n\n-- typo: \u201chas a significant upon mBERT\u201d\n\n\nSec 5.\n--It is not clear that you can make the claim that the first PC *only* encodes language-identification information?\n\n--I assume Figure 3 is 2-dimensional TSNE (needs a cite), which comes with its own set of caveats as a visualization tool. Quantitative clustering analysis such as silhouette coefficient might be more appropriate than a plot.  If Figure 3 is not t-SNE, please specify the meaning of X and Y axes.\n\n-- did not try higher than n=15 projections but claimed it was optimal\n\n-- The description of the \u201cskip\u201d ablation is unclear: please clarify what is meant by \u201cconcatenated with the sequence outputs of s2\u201d.\n\n-- typos: \u201cremoving the first principal component \u2026 effectively eliminate\u201d, \u201cfor both two models\u201d, \u201crepresentations \u2026 generally exhibits\u201d", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3639/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3639/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Universal Sentence Representations Learning with Conditional Masked Language Model", "authorids": ["~Ziyi_Yang1", "~Yinfei_Yang1", "~Daniel_M_Cer1", "jaxlaw@google.com", "~Eric_Darve1"], "authors": ["Ziyi Yang", "Yinfei Yang", "Daniel M Cer", "Jax Law", "Eric Darve"], "keywords": ["multilingual representations", "sentence embeddings"], "abstract": "This paper presents a novel training method, Conditional Masked Language Modeling (CMLM), to effectively learn sentence representations on large scale unlabeled corpora. CMLM integrates sentence representation learning into MLM training by conditioning on the encoded vectors of adjacent sentences. Our English CMLM model achieves state-of-the-art performance on SentEval, even outperforming models learned using (semi-)supervised signals. As a fully unsupervised learning method, CMLM can be conveniently extended to a broad range of languages and domains. We find that a multilingual CMLM model co-trained with bitext retrieval~(BR) and natural language inference~(NLI) tasks outperforms the previous state-of-the-art multilingual models by a large margin. We explore the same language bias of the learned representations, and propose a principle component based approach to remove the language identifying information from the representation while still retaining sentence semantics.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yang|universal_sentence_representations_learning_with_conditional_masked_language_model", "pdf": "/pdf/10ac053dee69fab838499a6f3adf6405aad2491b.pdf", "supplementary_material": "/attachment/b3d7e445b0b071ba7541985d42cd50b14d69331a.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=BxexEz_vPH", "_bibtex": "@misc{\nyang2021universal,\ntitle={Universal Sentence Representations Learning with Conditional Masked Language Model},\nauthor={Ziyi Yang and Yinfei Yang and Daniel M Cer and Jax Law and Eric Darve},\nyear={2021},\nurl={https://openreview.net/forum?id=WDVD4lUCTzU}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "WDVD4lUCTzU", "replyto": "WDVD4lUCTzU", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3639/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538072323, "tmdate": 1606915787511, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3639/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3639/-/Official_Review"}}}, {"id": "vpFoFpu2UF", "original": null, "number": 3, "cdate": 1606012460663, "ddate": null, "tcdate": 1606012460663, "tmdate": 1606090603416, "tddate": null, "forum": "WDVD4lUCTzU", "replyto": "FdjrveSXho", "invitation": "ICLR.cc/2021/Conference/Paper3639/-/Official_Comment", "content": {"title": "Response to Reviewer 2", "comment": "Thank you for your review and valuable suggestions! Please find our responses below:\n\n1. The architecture of the 3-layer MLP projection $P$ is as follows. Let h denote the dimension of the input sentence vector (e.g. h = $768$ in BERT base; $h = 1024$ in BERT large). Let FC ($a$, $b$, $c$) denote a fully connected layer with input dimension $a$, output dimension $b$ and nonlinearity function $c$. The three layers are FC($h$, $2h$, ReLU), FC($2h$, $2h$, ReLU), FC($2h$, $h$, None). The information has been added to the appendix. \n\n2. Code and reproduction: we are working on making the code available publicly. Also we will release pretrained models to the public so that researchers can reproduce the results and leverage the model for their own projects. Links will be posted here once available.\n\n3. To have a more thorough understanding of the sentence representations learnt by our models, we have included an additional experiment on the Tatoeba task from XTREME benchmark [1] that covers 36 languages, shown in Table 5. Our model \u201cCLM+BR\u201d has the highest average performance and outperforms all baseline models on 30 out of 36 languages. \n\nIf you have any other questions, please let us know!\n\nReferences:\n\n[1] Hu, Junjie, et al. \"Xtreme: A massively multilingual multi-task benchmark for evaluating cross-lingual generalization.\" ICML 2020."}, "signatures": ["ICLR.cc/2021/Conference/Paper3639/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3639/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Universal Sentence Representations Learning with Conditional Masked Language Model", "authorids": ["~Ziyi_Yang1", "~Yinfei_Yang1", "~Daniel_M_Cer1", "jaxlaw@google.com", "~Eric_Darve1"], "authors": ["Ziyi Yang", "Yinfei Yang", "Daniel M Cer", "Jax Law", "Eric Darve"], "keywords": ["multilingual representations", "sentence embeddings"], "abstract": "This paper presents a novel training method, Conditional Masked Language Modeling (CMLM), to effectively learn sentence representations on large scale unlabeled corpora. CMLM integrates sentence representation learning into MLM training by conditioning on the encoded vectors of adjacent sentences. Our English CMLM model achieves state-of-the-art performance on SentEval, even outperforming models learned using (semi-)supervised signals. As a fully unsupervised learning method, CMLM can be conveniently extended to a broad range of languages and domains. We find that a multilingual CMLM model co-trained with bitext retrieval~(BR) and natural language inference~(NLI) tasks outperforms the previous state-of-the-art multilingual models by a large margin. We explore the same language bias of the learned representations, and propose a principle component based approach to remove the language identifying information from the representation while still retaining sentence semantics.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yang|universal_sentence_representations_learning_with_conditional_masked_language_model", "pdf": "/pdf/10ac053dee69fab838499a6f3adf6405aad2491b.pdf", "supplementary_material": "/attachment/b3d7e445b0b071ba7541985d42cd50b14d69331a.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=BxexEz_vPH", "_bibtex": "@misc{\nyang2021universal,\ntitle={Universal Sentence Representations Learning with Conditional Masked Language Model},\nauthor={Ziyi Yang and Yinfei Yang and Daniel M Cer and Jax Law and Eric Darve},\nyear={2021},\nurl={https://openreview.net/forum?id=WDVD4lUCTzU}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "WDVD4lUCTzU", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3639/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3639/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3639/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3639/Authors|ICLR.cc/2021/Conference/Paper3639/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3639/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923835440, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3639/-/Official_Comment"}}}, {"id": "BqWIXVyTp3", "original": null, "number": 7, "cdate": 1606013623027, "ddate": null, "tcdate": 1606013623027, "tmdate": 1606090524012, "tddate": null, "forum": "WDVD4lUCTzU", "replyto": "1jVUti2kkB4", "invitation": "ICLR.cc/2021/Conference/Paper3639/-/Official_Comment", "content": {"title": "Response to Reviewer 1", "comment": "Thanks for your review and valuable feedback! Please find our responses below:\n\n**1. About \"experiments are weak\".**\n\nThe evaluation benchmarks in our paper are widely adopted in previous text representation learning works. For example, SentEval [1,2,3], Amazon Reviews [4,5,6] and Tatoeba [7, 8]. The benchmarks i the paper thoroughly examine the capability of a representation system, including semantic alignment (Tatoeba), transfer learning to various kinds of downstream tasks (sentiment analysis (SST, MR, CR), semantic classification, NLI (SICK-E), text similarity (SICK-R) and paraphrase detection (MRPC) in SentEval, XEVAL) and zero-shot cross-lingual transfer learning (Amazon Reviews). Our models consistently show strong performance across these benchmarks. We believe our evaluations are detailed and in-depth.\n\n**2. About \"Model is largely based on prior work...\"**\n\nWe provide a summary of main contributions of this paper in the last paragraph in the introduction section. To reiterate, we propose an unsupervised sentence representation learning method CMLM. To the best of our knowledge, CMLM is a novel model architecture proposed for the first time.\n\n**3. About \"Weak Baselines\".**\n\nBaseline models considered in the paper include many SOTA sentence representation models: SkipThought, QuickThought, InferSent, USE and LASER. As shown in Table 1-5, CMLM consistently outperform baseline models. To address the effects from differences in training data, we train multiple baselines with the same training data of CMLM, e.g. QuickThought (CC), English BERT large/base (CC). As shown in table 1, CMLM outperform these baselines that are  trained with the same data resources.\n\n**4. About \"Evaluation protocol\".**\n\nFollowing your suggestion, we evaluate our models on Tatoeba [7, 8], a multilingual retrieval benchmark, as shown in Table 5. Our models \u201cCMLM+BR\u201d outperforms all baseline models by a significant margin in terms of the average performance. It has the highest accuracy in 30 out of 36 languages.\n\n**5. About \"Data used for pretraining: It is difficult to ...\"**\n\nFollowing your suggestion, we train QuickThought, an unsupervised sentence representation learning method, using the same Common Crawl dumps that our models are trained on. To address the possible advantage coming from the Transformer, we use a transformer encoder in QuickThought instead of a GRU (RNN) in the original QuickThought implementation. The model is denoted as QuickThought (CC) in Table 1. Using a transformer encoder and Common Crawl does not make QuickThought better than our model. Also notice that the model XLM-R also uses Common Crawl corpora. Results in Table 2 and 4 shows that our model CMLM still outperforms XLM-R.\n\n**6. About \"paper presentation and organization\".**\n\nThanks for the suggestion! We\u2019ve edited the paper to make the story more coherent following your suggestion. Especially, we added a paragraph in the introduction section (the second last one) to describe how the paper is organized.\n\n**7. Extra evaluations for multilingual representations on existing benchmarks.**\n\nThis is a good idea! As mentioned above, we\u2019ve evaluated on the Tatoeba dataset (table 5). Besides XEVAL, the multilingual representations are also evaluated on Amazon Reviews. On both Amazon Reviews and Tatoeba, our models outperform all baseline models.\n\n**8. About \"What resources are used to train each method\".**\n+ For English and Multilingual CMLM, training data (sec. 3 and sec. 4.1) are generated from three Common Crawl dumps (2020-05, 2020-10, 2020-16, see https://commoncrawl.org/the-data/get-started/). English CMLM takes ~5 days using 64 Cloud TPUs (128 TPU chips total). Training Multilingual CMLM takes ~12 days using 64 Cloud TPUs.\n+ Multitask co-training CMLM+BR takes ~5 days 64 Cloud TPUs. Information about BR training data can be found at sec. 4.2.\n+ Cross-lingual NLI finetuning takes ~12 hours using 8 cloud TPUs. Information about data used for cross-lingual finetuning can be found at sec. 4.3. \n\nReferences:\n\n[1] Cer, et al. \"Universal sentence encoder.\" arXiv preprint arXiv:1803.11175 (2018).\n\n[2] Conneau, Alexis, et al. \"Supervised Learning of Universal Sentence Representations from Natural Language Inference Data.\" EMNLP 2017.\n\n[3] Yang, et al. . \"Parameter-free Sentence Embedding via Orthogonal Basis.\" EMNLP-IJCNLP 2019.\n\n[4] Zhou, et al. \"Cross-lingual sentiment classification with bilingual document representation learning.\" ACL 2016.\n\n[5] Chidambaram, et al. \"Learning Cross-Lingual Sentence Representations via a Multi-task Dual-Encoder Model.\" RepL4NLP-2019. 2019.\n\n[6] Xu, et al. \"Cross-lingual Distillation for Text Classification.\" ACL 2017.\n\n[7] Artetxe, et al. \"Massively multilingual sentence embeddings for zero-shot cross-lingual transfer and beyond.\" ACL 2019.\n\n[8] Hu, et al. \"Xtreme: A massively multilingual multi-task benchmark for evaluating cross-lingual generalization.\" ICML 2020."}, "signatures": ["ICLR.cc/2021/Conference/Paper3639/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3639/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Universal Sentence Representations Learning with Conditional Masked Language Model", "authorids": ["~Ziyi_Yang1", "~Yinfei_Yang1", "~Daniel_M_Cer1", "jaxlaw@google.com", "~Eric_Darve1"], "authors": ["Ziyi Yang", "Yinfei Yang", "Daniel M Cer", "Jax Law", "Eric Darve"], "keywords": ["multilingual representations", "sentence embeddings"], "abstract": "This paper presents a novel training method, Conditional Masked Language Modeling (CMLM), to effectively learn sentence representations on large scale unlabeled corpora. CMLM integrates sentence representation learning into MLM training by conditioning on the encoded vectors of adjacent sentences. Our English CMLM model achieves state-of-the-art performance on SentEval, even outperforming models learned using (semi-)supervised signals. As a fully unsupervised learning method, CMLM can be conveniently extended to a broad range of languages and domains. We find that a multilingual CMLM model co-trained with bitext retrieval~(BR) and natural language inference~(NLI) tasks outperforms the previous state-of-the-art multilingual models by a large margin. We explore the same language bias of the learned representations, and propose a principle component based approach to remove the language identifying information from the representation while still retaining sentence semantics.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yang|universal_sentence_representations_learning_with_conditional_masked_language_model", "pdf": "/pdf/10ac053dee69fab838499a6f3adf6405aad2491b.pdf", "supplementary_material": "/attachment/b3d7e445b0b071ba7541985d42cd50b14d69331a.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=BxexEz_vPH", "_bibtex": "@misc{\nyang2021universal,\ntitle={Universal Sentence Representations Learning with Conditional Masked Language Model},\nauthor={Ziyi Yang and Yinfei Yang and Daniel M Cer and Jax Law and Eric Darve},\nyear={2021},\nurl={https://openreview.net/forum?id=WDVD4lUCTzU}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "WDVD4lUCTzU", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3639/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3639/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3639/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3639/Authors|ICLR.cc/2021/Conference/Paper3639/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3639/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923835440, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3639/-/Official_Comment"}}}, {"id": "0vG2tl203W", "original": null, "number": 4, "cdate": 1606013276372, "ddate": null, "tcdate": 1606013276372, "tmdate": 1606089917098, "tddate": null, "forum": "WDVD4lUCTzU", "replyto": "geo0tdb3NW-", "invitation": "ICLR.cc/2021/Conference/Paper3639/-/Official_Comment", "content": {"title": "Response to Reviewer 4, Part 2", "comment": "**Sec 5**\n\n1. Our claim in the paper is \u201cthe first principal components in each monolingual space **primarily** encodes language information\u201d, not \u201conly encodes\u201d. It does not only encode language identification information because note in Table 6, in most cases PCR yields better retrieval performance. For some languages, PCR makes the retrieval performance drop a bit, which indicates that principal components can still contain semantic information.\n\n2. Figure 3 is a 2D PCA. The x and y axis is the direction of first and second maximum variation through the data. Using silhouette coefficient is a good idea! We\u2019ll add that in the final version.\n\n3. Explanation for \u201cConcatenated with the sequence outputs of $s_2$\u201d: Given two sentences $s_1$ and $s_2$. By inputting $s_2$ to the transformer encoder, we obtain an output matrix $M \\in R^{H\\times L}$, where $H$ denotes the hidden size and $L$ denotes the maximum token length. Recall the sentence representation of $s_1$ is computed as $v$ (of size $H$). We then concatenate $v$ to each column vector $m_i$ ($i = 1,2,\\dots,L$) in $M$. The concatenated tensor $M\u2019$ is of size $2H\\times L$, We then use $M\u2019$ as the input for masked token prediction in $s_2$."}, "signatures": ["ICLR.cc/2021/Conference/Paper3639/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3639/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Universal Sentence Representations Learning with Conditional Masked Language Model", "authorids": ["~Ziyi_Yang1", "~Yinfei_Yang1", "~Daniel_M_Cer1", "jaxlaw@google.com", "~Eric_Darve1"], "authors": ["Ziyi Yang", "Yinfei Yang", "Daniel M Cer", "Jax Law", "Eric Darve"], "keywords": ["multilingual representations", "sentence embeddings"], "abstract": "This paper presents a novel training method, Conditional Masked Language Modeling (CMLM), to effectively learn sentence representations on large scale unlabeled corpora. CMLM integrates sentence representation learning into MLM training by conditioning on the encoded vectors of adjacent sentences. Our English CMLM model achieves state-of-the-art performance on SentEval, even outperforming models learned using (semi-)supervised signals. As a fully unsupervised learning method, CMLM can be conveniently extended to a broad range of languages and domains. We find that a multilingual CMLM model co-trained with bitext retrieval~(BR) and natural language inference~(NLI) tasks outperforms the previous state-of-the-art multilingual models by a large margin. We explore the same language bias of the learned representations, and propose a principle component based approach to remove the language identifying information from the representation while still retaining sentence semantics.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yang|universal_sentence_representations_learning_with_conditional_masked_language_model", "pdf": "/pdf/10ac053dee69fab838499a6f3adf6405aad2491b.pdf", "supplementary_material": "/attachment/b3d7e445b0b071ba7541985d42cd50b14d69331a.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=BxexEz_vPH", "_bibtex": "@misc{\nyang2021universal,\ntitle={Universal Sentence Representations Learning with Conditional Masked Language Model},\nauthor={Ziyi Yang and Yinfei Yang and Daniel M Cer and Jax Law and Eric Darve},\nyear={2021},\nurl={https://openreview.net/forum?id=WDVD4lUCTzU}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "WDVD4lUCTzU", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3639/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3639/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3639/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3639/Authors|ICLR.cc/2021/Conference/Paper3639/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3639/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923835440, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3639/-/Official_Comment"}}}, {"id": "4bJBmzhP0EO", "original": null, "number": 5, "cdate": 1606013386682, "ddate": null, "tcdate": 1606013386682, "tmdate": 1606089883561, "tddate": null, "forum": "WDVD4lUCTzU", "replyto": "geo0tdb3NW-", "invitation": "ICLR.cc/2021/Conference/Paper3639/-/Official_Comment", "content": {"title": "Response to Reviewer 4, Part 1", "comment": "Thank you for the detailed comments and insightful suggestions! Please find our responses below:\n\n**Overall:**\n1. About SentEval: we\u2019ve added results on SICK-R in Table 1. All the numbers in Table 2 and Table 3 are updated by including SICK-R performance on XEVAL.\n\n2. We\u2019ve added XLM-R performance on Amazon Reviews (Table 4). We also manage to improve the multilingual sentence representations by applying smoothing of the volume of data per language during pretraining (Table 2,3,4).\n\n3. To have a more thorough understanding of the sentence representations learnt by our models, we added another experiment using the Tatoeba task from the XTREME benchmark (Hu. etc, 2020) dataset that covers 36 languages, shown in Table 5. Our models \u201cCMLM+BR\u201d outperforms all baseline models by a significant margin in terms of the average performance. It also has the highest accuracy in 30 out of 36 languages.\n\n4. Thanks for pointing out the typos and SBERT naming suggestions! We\u2019ve corrected them in the paper.\n\n**Sec 1, Sec2:**\n\n1. The quantitative comparison of using MEAN, MAX and CLS is included in the appendix (Table 8).\n\n2. About siamese networks: we\u2019ve added a footnote on page 3 regarding the name.\n\n3. $v_d$ should be $v_p$. We\u2019ve corrected this typo in the revision.\n\n**Sec 3:**\n\n1. About \u201cflip-flopping\u201d and \u201cchallenging\u201d: We\u2019ve removed the description of \u201cmore challenging\u201d in the first paragraph of section 2. We also add a sentence in the same paragraph to point out the connection between the \u201corder-swapping\u201d in our model and Skip-Thought predictions.\n\n2. About masking rates: We add analysis on the ablation study of masking ratios in the appendix (Table 9). By \u201cchallenging is better\u201d, we mean though low masking ratios yield higher CMLM accuracy in training, it doesn't produce better sentence representations.\n\n3. About SentEval \u201csubset selection\u201d and SBERT: We\u2019ve included SICK-R results following your suggestion. We\u2019ve included the SentEval tasks that SBERT presented in their original paper (see section 5 in SBERT paper). Also notice that CMLM is only trained on unlabeled corpora while SBERT also uses supervised NLI data. Even so CMLM achieves competitive results. This indicates that CMLM, as an unsupervised sentence representation learning model, is able to obtain sentence representations as good as (if not better) supervised learning models.\n\n4. About the length 256: The length refers to the maximum length.\n\n**Sec 4:**\n\n1. About batch size in BR: In general, larger batch sizes improve performance until we reach ~2048, since each example will see more \u201cmismatched\u201d examples. After 2048, we don\u2019t see obvious improvements in performance from increasing batch size. We\u2019ll add detailed results on this in the final version.\n\n2. The margin m is set to be 0.3. We\u2019ve added this in the paper.\n\n3. About the number of projections: We\u2019ve included results of N=20 in Table 7. It shows N=15 has a better overall performance than N=20.\n\n4. The translation is done by Google Translate. The score for each language in XEVAL is computed as the average of performance on tasks MR, CR, SUBJ, MPQA, SST, TREC, MRPC, SICK-E and SICK-R as in the evaluations for English models.\n\n5. About using the concatenation of u,v, u-v and u*v: We\u2019ve cited previous works using this method.\n\n6. About BR \u2192 CMLM+BR: The suggested path is a great addition. We\u2019ll include the results in the final version. We choose to experiment with CMLM\u2192 CMLM+BR because we notice that BR converges faster than CMLM, therefore we train CMLM first.\n\n7. About how training step is determined: The training step is determined by the masked token prediction accuracy (CMLM) and retrieval accuracy (BR) on the validation set.\n\n8. About [CLS] and max-pooling representations: The performance drop of mBERT and XLM-R using [CLS] and max-pooling is very similar to the trend in Table 8 (in appendix)"}, "signatures": ["ICLR.cc/2021/Conference/Paper3639/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3639/Authors"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Universal Sentence Representations Learning with Conditional Masked Language Model", "authorids": ["~Ziyi_Yang1", "~Yinfei_Yang1", "~Daniel_M_Cer1", "jaxlaw@google.com", "~Eric_Darve1"], "authors": ["Ziyi Yang", "Yinfei Yang", "Daniel M Cer", "Jax Law", "Eric Darve"], "keywords": ["multilingual representations", "sentence embeddings"], "abstract": "This paper presents a novel training method, Conditional Masked Language Modeling (CMLM), to effectively learn sentence representations on large scale unlabeled corpora. CMLM integrates sentence representation learning into MLM training by conditioning on the encoded vectors of adjacent sentences. Our English CMLM model achieves state-of-the-art performance on SentEval, even outperforming models learned using (semi-)supervised signals. As a fully unsupervised learning method, CMLM can be conveniently extended to a broad range of languages and domains. We find that a multilingual CMLM model co-trained with bitext retrieval~(BR) and natural language inference~(NLI) tasks outperforms the previous state-of-the-art multilingual models by a large margin. We explore the same language bias of the learned representations, and propose a principle component based approach to remove the language identifying information from the representation while still retaining sentence semantics.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yang|universal_sentence_representations_learning_with_conditional_masked_language_model", "pdf": "/pdf/10ac053dee69fab838499a6f3adf6405aad2491b.pdf", "supplementary_material": "/attachment/b3d7e445b0b071ba7541985d42cd50b14d69331a.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=BxexEz_vPH", "_bibtex": "@misc{\nyang2021universal,\ntitle={Universal Sentence Representations Learning with Conditional Masked Language Model},\nauthor={Ziyi Yang and Yinfei Yang and Daniel M Cer and Jax Law and Eric Darve},\nyear={2021},\nurl={https://openreview.net/forum?id=WDVD4lUCTzU}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "WDVD4lUCTzU", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3639/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3639/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3639/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3639/Authors|ICLR.cc/2021/Conference/Paper3639/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3639/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923835440, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3639/-/Official_Comment"}}}, {"id": "O1lJjJzcIbi", "original": null, "number": 2, "cdate": 1605963711227, "ddate": null, "tcdate": 1605963711227, "tmdate": 1605964154101, "tddate": null, "forum": "WDVD4lUCTzU", "replyto": "WDVD4lUCTzU", "invitation": "ICLR.cc/2021/Conference/Paper3639/-/Official_Comment", "content": {"title": "The discussion stage is open!", "comment": "Dear Reviewers:\n\nThanks for your insightful reviews! Now the discussion stage is open and the authors have posted their responses. We will appreciate that the following things-to-do can be done by Tues, Nov 24.\n\n1 Acknowledge explicitly that you have read the responses.\n\n2 Modify your review if necessary.\n\n3 Communicate with the authors/reviewers/AC by adding/responding to the comments if necessary.\n\nThanks a lot!"}, "signatures": ["ICLR.cc/2021/Conference/Paper3639/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3639/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Universal Sentence Representations Learning with Conditional Masked Language Model", "authorids": ["~Ziyi_Yang1", "~Yinfei_Yang1", "~Daniel_M_Cer1", "jaxlaw@google.com", "~Eric_Darve1"], "authors": ["Ziyi Yang", "Yinfei Yang", "Daniel M Cer", "Jax Law", "Eric Darve"], "keywords": ["multilingual representations", "sentence embeddings"], "abstract": "This paper presents a novel training method, Conditional Masked Language Modeling (CMLM), to effectively learn sentence representations on large scale unlabeled corpora. CMLM integrates sentence representation learning into MLM training by conditioning on the encoded vectors of adjacent sentences. Our English CMLM model achieves state-of-the-art performance on SentEval, even outperforming models learned using (semi-)supervised signals. As a fully unsupervised learning method, CMLM can be conveniently extended to a broad range of languages and domains. We find that a multilingual CMLM model co-trained with bitext retrieval~(BR) and natural language inference~(NLI) tasks outperforms the previous state-of-the-art multilingual models by a large margin. We explore the same language bias of the learned representations, and propose a principle component based approach to remove the language identifying information from the representation while still retaining sentence semantics.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "yang|universal_sentence_representations_learning_with_conditional_masked_language_model", "pdf": "/pdf/10ac053dee69fab838499a6f3adf6405aad2491b.pdf", "supplementary_material": "/attachment/b3d7e445b0b071ba7541985d42cd50b14d69331a.zip", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=BxexEz_vPH", "_bibtex": "@misc{\nyang2021universal,\ntitle={Universal Sentence Representations Learning with Conditional Masked Language Model},\nauthor={Ziyi Yang and Yinfei Yang and Daniel M Cer and Jax Law and Eric Darve},\nyear={2021},\nurl={https://openreview.net/forum?id=WDVD4lUCTzU}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq", "required": true, "markdown": true}}, "forum": "WDVD4lUCTzU", "readers": {"description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response", "values-dropdown": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3639/Area_Chairs"], "default": ["ICLR.cc/2021/Conference/Program_Chairs", "ICLR.cc/2021/Conference/Paper3639/Area_Chairs"]}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"]}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3639/AnonReviewer[0-9]+|ICLR.cc/2021/Conference/Paper3639/Authors|ICLR.cc/2021/Conference/Paper3639/Area_Chair[0-9]+|ICLR.cc/2021/Conference/Program_Chairs", "description": "How your identity will be displayed."}}, "expdate": 1610649480000, "final": [], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3639/Area_Chairs", "ICLR.cc/2021/Conference/Program_Chairs", "OpenReview.net/Support"], "noninvitees": [], "tcdate": 1601923835440, "tmdate": 1610649509835, "super": "ICLR.cc/2021/Conference/-/Comment", "signatures": ["ICLR.cc/2021/Conference"], "writers": ["ICLR.cc/2021/Conference"], "id": "ICLR.cc/2021/Conference/Paper3639/-/Official_Comment"}}}], "count": 13}