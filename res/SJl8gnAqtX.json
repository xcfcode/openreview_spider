{"notes": [{"id": "SJl8gnAqtX", "original": "SkeKwpQuKX", "number": 1081, "cdate": 1538087918482, "ddate": null, "tcdate": 1538087918482, "tmdate": 1545355435857, "tddate": null, "forum": "SJl8gnAqtX", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring", "abstract": "We propose a new application of embedding techniques to problem retrieval in adaptive tutoring. The objective is to retrieve problems similar in mathematical concepts. There are two challenges: First, like sentences, problems helpful to tutoring are never exactly the same in terms of the underlying concepts. Instead, good problems mix concepts in innovative ways, while still displaying continuity in their relationships. Second, it is difficult for humans to determine a similarity score consistent across a large enough training set. We propose a hierarchical problem embedding algorithm, called Prob2Vec, that consists of an abstraction and an embedding step. Prob2Vec achieves 96.88\\% accuracy on a problem similarity test, in contrast to 75\\% from directly applying state-of-the-art sentence embedding methods. It is surprising that Prob2Vec is able to distinguish very fine-grained differences among problems, an ability humans need time and effort to acquire. In addition, the sub-problem of concept labeling with imbalanced training data set is interesting in its own right. It is a multi-label problem suffering from dimensionality explosion, which we propose ways to ameliorate. We propose the novel negative pre-training algorithm that dramatically reduces false negative and positive ratios for classification, using an imbalanced training data set.", "keywords": ["personalized learning", "e-learning", "text embedding", "Skip-gram", "imbalanced data set", "data level classification methods"], "authorids": ["dusu3@illinois.edu", "yekkehk2@illinois.edu", "yilu4@illinois.edu", "wenmiao.lu@gmail.com"], "authors": ["Du Su", "Ali Yekkehkhany", "Yi Lu", "Wenmiao Lu"], "TL;DR": "We propose the Prob2Vec method for problem embedding used in a personalized e-learning tool in addition to a data level classification method, called negative pre-training, for cases where the training data set is imbalanced.", "pdf": "/pdf/94550a8d889861f60e4f5d79a43db74c8cb7ba7a.pdf", "paperhash": "su|prob2vec_mathematical_semantic_embedding_for_problem_retrieval_in_adaptive_tutoring", "_bibtex": "@misc{\nsu2019probvec,\ntitle={Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring},\nauthor={Du Su and Ali Yekkehkhany and Yi Lu and Wenmiao Lu},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl8gnAqtX},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 11, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "HyglQStBxV", "original": null, "number": 1, "cdate": 1545078039720, "ddate": null, "tcdate": 1545078039720, "tmdate": 1545354481017, "tddate": null, "forum": "SJl8gnAqtX", "replyto": "SJl8gnAqtX", "invitation": "ICLR.cc/2019/Conference/-/Paper1081/Meta_Review", "content": {"metareview": "I tend to agree with reviewers. This is a bit more of an applied type of work and does not lead to new insights in learning representations. \nLack of technical novelty\nDataset too small", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "Lack of technical novelty"}, "signatures": ["ICLR.cc/2019/Conference/Paper1081/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1081/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring", "abstract": "We propose a new application of embedding techniques to problem retrieval in adaptive tutoring. The objective is to retrieve problems similar in mathematical concepts. There are two challenges: First, like sentences, problems helpful to tutoring are never exactly the same in terms of the underlying concepts. Instead, good problems mix concepts in innovative ways, while still displaying continuity in their relationships. Second, it is difficult for humans to determine a similarity score consistent across a large enough training set. We propose a hierarchical problem embedding algorithm, called Prob2Vec, that consists of an abstraction and an embedding step. Prob2Vec achieves 96.88\\% accuracy on a problem similarity test, in contrast to 75\\% from directly applying state-of-the-art sentence embedding methods. It is surprising that Prob2Vec is able to distinguish very fine-grained differences among problems, an ability humans need time and effort to acquire. In addition, the sub-problem of concept labeling with imbalanced training data set is interesting in its own right. It is a multi-label problem suffering from dimensionality explosion, which we propose ways to ameliorate. We propose the novel negative pre-training algorithm that dramatically reduces false negative and positive ratios for classification, using an imbalanced training data set.", "keywords": ["personalized learning", "e-learning", "text embedding", "Skip-gram", "imbalanced data set", "data level classification methods"], "authorids": ["dusu3@illinois.edu", "yekkehk2@illinois.edu", "yilu4@illinois.edu", "wenmiao.lu@gmail.com"], "authors": ["Du Su", "Ali Yekkehkhany", "Yi Lu", "Wenmiao Lu"], "TL;DR": "We propose the Prob2Vec method for problem embedding used in a personalized e-learning tool in addition to a data level classification method, called negative pre-training, for cases where the training data set is imbalanced.", "pdf": "/pdf/94550a8d889861f60e4f5d79a43db74c8cb7ba7a.pdf", "paperhash": "su|prob2vec_mathematical_semantic_embedding_for_problem_retrieval_in_adaptive_tutoring", "_bibtex": "@misc{\nsu2019probvec,\ntitle={Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring},\nauthor={Du Su and Ali Yekkehkhany and Yi Lu and Wenmiao Lu},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl8gnAqtX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1081/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352973105, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJl8gnAqtX", "replyto": "SJl8gnAqtX", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1081/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1081/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1081/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352973105}}}, {"id": "B1l3_3TepQ", "original": null, "number": 5, "cdate": 1541622900267, "ddate": null, "tcdate": 1541622900267, "tmdate": 1541632806805, "tddate": null, "forum": "SJl8gnAqtX", "replyto": "Syxz3gT_2Q", "invitation": "ICLR.cc/2019/Conference/-/Paper1081/Official_Comment", "content": {"title": "Response to Reviewer2", "comment": "\n1- The idea of using concepts to represent a problem is simple, but using it along with neural network based embedding gives us the opportunity to gain concept continuity as discussed on the last paragraph on page 7 and table 2, which is an active field of research in education.\n\nThe focus of this work is on problem embedding and its application in a recommendation system that uses problem embedding to project students\u2019 performance for the problems they solved onto the problems that they have not solved yet. Using the evaluation on unseen problems, a problem is recommended that is within the capacity of students close to their boundary to help them learn, and at the same time we cover all the concepts necessary for them to learn. In the meanwhile, we got the interesting idea of negative pre-training on training with imbalanced training data and tested our hypothesis and included in the paper. Due to space limit, we did not include the literature review and comparison of other methods in terms of memory use and training complexity, but you can find them in the response of a previous comment below titled \u201cResponse to Question on Negative Pre-Training\u201d on this page to see the comparison. We can include the literature review for training on imbalanced data sets as well as comparison of other methods with negative pre-training in terms of memory use and training complexity in the final version. In summary, a) oversampling extremely suffers from over-fitting, b) SMOTE method that generates synthetic data sample is not feasible in word space, so the generated synthetic data (that are mathematical problems) are not of use for our training purpose, c) borderline-SMOTE both suffers from the same issue as SMOTE and its high complexity for finding the pairwise distance between all data samples, which is a burden in high dimensional data, and d) hybrid methods need m >> 1 weak learners in contrast to negative pre-training that uses a single learner. Memory use and training time is an issue for hybrid method when the weak learners are deep neural networks with too many parameters. We are currently running a broader experiment for negative pre-training on other data sets to gain more insight on it, but for the purpose of the task proposed in this work, it outperforms one-shot learning, which cannot be said that is the state-of-the art, but is a common practice. There is no notion of state-of-the-art in training on imbalanced data sets since due to our best knowledge, there is no method that outperforms all the other ones, and the performance of different methods depends more on the nature of the data set.\n\n2- The data set being small is the nature of the application since creating mathematical problems is a creative process, so it is hard to have a very big data set. The Prob2Vec method is performing well on this not relatively big data set, which is our goal, but if we have a bigger data set (as we have right now with more than 2400 problems), Prob2Vec may even have a better performance since with more data we can have a more precise concept and problem embedding.\n\n3- Thanks for your suggestion.\n\n4- It is difficult for humans to determine a similarity score consistent across a large enough training set, so it is not feasible to simply apply supervised methods to learn a similarity score for problems. Even if problem-problem similarity annotation is feasible, a lot of effort should go into the annotation, which is not scalable.\n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1081/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1081/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1081/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring", "abstract": "We propose a new application of embedding techniques to problem retrieval in adaptive tutoring. The objective is to retrieve problems similar in mathematical concepts. There are two challenges: First, like sentences, problems helpful to tutoring are never exactly the same in terms of the underlying concepts. Instead, good problems mix concepts in innovative ways, while still displaying continuity in their relationships. Second, it is difficult for humans to determine a similarity score consistent across a large enough training set. We propose a hierarchical problem embedding algorithm, called Prob2Vec, that consists of an abstraction and an embedding step. Prob2Vec achieves 96.88\\% accuracy on a problem similarity test, in contrast to 75\\% from directly applying state-of-the-art sentence embedding methods. It is surprising that Prob2Vec is able to distinguish very fine-grained differences among problems, an ability humans need time and effort to acquire. In addition, the sub-problem of concept labeling with imbalanced training data set is interesting in its own right. It is a multi-label problem suffering from dimensionality explosion, which we propose ways to ameliorate. We propose the novel negative pre-training algorithm that dramatically reduces false negative and positive ratios for classification, using an imbalanced training data set.", "keywords": ["personalized learning", "e-learning", "text embedding", "Skip-gram", "imbalanced data set", "data level classification methods"], "authorids": ["dusu3@illinois.edu", "yekkehk2@illinois.edu", "yilu4@illinois.edu", "wenmiao.lu@gmail.com"], "authors": ["Du Su", "Ali Yekkehkhany", "Yi Lu", "Wenmiao Lu"], "TL;DR": "We propose the Prob2Vec method for problem embedding used in a personalized e-learning tool in addition to a data level classification method, called negative pre-training, for cases where the training data set is imbalanced.", "pdf": "/pdf/94550a8d889861f60e4f5d79a43db74c8cb7ba7a.pdf", "paperhash": "su|prob2vec_mathematical_semantic_embedding_for_problem_retrieval_in_adaptive_tutoring", "_bibtex": "@misc{\nsu2019probvec,\ntitle={Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring},\nauthor={Du Su and Ali Yekkehkhany and Yi Lu and Wenmiao Lu},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl8gnAqtX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1081/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621625360, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJl8gnAqtX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1081/Authors", "ICLR.cc/2019/Conference/Paper1081/Reviewers", "ICLR.cc/2019/Conference/Paper1081/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1081/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1081/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1081/Authors|ICLR.cc/2019/Conference/Paper1081/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1081/Reviewers", "ICLR.cc/2019/Conference/Paper1081/Authors", "ICLR.cc/2019/Conference/Paper1081/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621625360}}}, {"id": "r1eU8lgW67", "original": null, "number": 6, "cdate": 1541632078336, "ddate": null, "tcdate": 1541632078336, "tmdate": 1541632078336, "tddate": null, "forum": "SJl8gnAqtX", "replyto": "Skgof-pjiX", "invitation": "ICLR.cc/2019/Conference/-/Paper1081/Official_Comment", "content": {"title": "Response to Reviewer3", "comment": "\n1- We briefly mentioned the way problem embedding with similarity metric is used in the recommendation system in this work, but here is more explanation on that. The most similar problem is not necessarily recommended to a student. On a high level, if a student performs well on problems, we assume he/she performs well on similar problems as well, so we recommend a dissimilar problem and vice versa. More specifically, we project the performance of students on problems they solved onto the problems that they have not solved. This way, we have an evaluation of the performance of students on unseen problems. A problem is recommended that is within the capacity of students close to their boundary to help them learn, and at the same time recommendation is done so that all the concepts necessary for students are practiced by them.\nAn evaluation on real students is presented in part 2 of the comment titled \u201cResponse to questions about Prob2Vec\u201d on this page, and we observed that similar problems are more likely to be solved correctly at the same time or wrong at the same time.\nThe math expressions are not ignored in our proposed Prob2Vec method. In the example given in the last paragraph on page 3 for example, math expressions are used to extract the concept n-choose-k. We both use math expressions and text to label problems with appropriate concepts.\n\n2- Prob2Vec only uses expert knowledge for rule-based concept extractor, but does not use selected informative words. The effort put for rule-based concept extractor is negligible compared to effort needed for annotation of all problems with their corresponding concepts. We both annotated all problems manually and used rule-based concept extractor for annotation. In the former method, we observed 100% accuracy in the similarity detection test and observed 96.88% accuracy in the latter method. However, the rule-based concept extractor needs much less manual effort than manual problem annotation and is capable to provide us with relatively high level of accuracy we need in our application. Note that our method is scalable as long as problems are in the same domain as the rule-based concept extractor is automated for a single domain, but for the case that problems span many different domains, it is the natural complexity of the data set that requires a more sophisticated rule-based concept extractor. Furthermore, in most realistic cases for education purposes, problems span a single domain not multiple ones.\n\nWe also like to grab your attention to the negative pre-training method proposed for training on imbalanced data sets. You may want to refer to part 2 of comment titled \u201cResponse to Question on Negative Pre-Training\u201d and part 1 of our response to reviewer2."}, "signatures": ["ICLR.cc/2019/Conference/Paper1081/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1081/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1081/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring", "abstract": "We propose a new application of embedding techniques to problem retrieval in adaptive tutoring. The objective is to retrieve problems similar in mathematical concepts. There are two challenges: First, like sentences, problems helpful to tutoring are never exactly the same in terms of the underlying concepts. Instead, good problems mix concepts in innovative ways, while still displaying continuity in their relationships. Second, it is difficult for humans to determine a similarity score consistent across a large enough training set. We propose a hierarchical problem embedding algorithm, called Prob2Vec, that consists of an abstraction and an embedding step. Prob2Vec achieves 96.88\\% accuracy on a problem similarity test, in contrast to 75\\% from directly applying state-of-the-art sentence embedding methods. It is surprising that Prob2Vec is able to distinguish very fine-grained differences among problems, an ability humans need time and effort to acquire. In addition, the sub-problem of concept labeling with imbalanced training data set is interesting in its own right. It is a multi-label problem suffering from dimensionality explosion, which we propose ways to ameliorate. We propose the novel negative pre-training algorithm that dramatically reduces false negative and positive ratios for classification, using an imbalanced training data set.", "keywords": ["personalized learning", "e-learning", "text embedding", "Skip-gram", "imbalanced data set", "data level classification methods"], "authorids": ["dusu3@illinois.edu", "yekkehk2@illinois.edu", "yilu4@illinois.edu", "wenmiao.lu@gmail.com"], "authors": ["Du Su", "Ali Yekkehkhany", "Yi Lu", "Wenmiao Lu"], "TL;DR": "We propose the Prob2Vec method for problem embedding used in a personalized e-learning tool in addition to a data level classification method, called negative pre-training, for cases where the training data set is imbalanced.", "pdf": "/pdf/94550a8d889861f60e4f5d79a43db74c8cb7ba7a.pdf", "paperhash": "su|prob2vec_mathematical_semantic_embedding_for_problem_retrieval_in_adaptive_tutoring", "_bibtex": "@misc{\nsu2019probvec,\ntitle={Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring},\nauthor={Du Su and Ali Yekkehkhany and Yi Lu and Wenmiao Lu},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl8gnAqtX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1081/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621625360, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJl8gnAqtX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1081/Authors", "ICLR.cc/2019/Conference/Paper1081/Reviewers", "ICLR.cc/2019/Conference/Paper1081/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1081/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1081/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1081/Authors|ICLR.cc/2019/Conference/Paper1081/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1081/Reviewers", "ICLR.cc/2019/Conference/Paper1081/Authors", "ICLR.cc/2019/Conference/Paper1081/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621625360}}}, {"id": "S1etFWjga7", "original": null, "number": 4, "cdate": 1541611904722, "ddate": null, "tcdate": 1541611904722, "tmdate": 1541622939028, "tddate": null, "forum": "SJl8gnAqtX", "replyto": "BkeXRoYqhm", "invitation": "ICLR.cc/2019/Conference/-/Paper1081/Official_Comment", "content": {"title": "Response to Reviewer3", "comment": "\n1- There are two reasons that concept and problem embedding are performed in this work. Considering concept continuity is an important matter in education. Having concept embedding, concept continuity can be reached as is discussed in the last paragraph on page 7 and some other examples are given in table 2. By just having the most sophisticated concept extractor, the concept continuity cannot be retrieved. Furthermore, problem embedding is used by the recommender system to project the performance of students on the problems they solved onto other problems that they have not solved. This way, we have an idea of what problems should be recommended to them and which problems should not by having an evaluation of their ability to solve unseen problems and recommend problems in the boundary of their capacity, not way beyond, and to recommend problems in a way that covers all concepts necessary for students to learn. We have observed interesting patterns, e.g. similar problems are more likely to be solved correctly at the same time or wrong at the same time. Note that by just having the concepts of problems that are not in numerical form, performance projection may not be feasible and there is a need for using other methods like embedding.\n\n2- The data size being small is just the nature of the application. Creating new problems is a creative process and is not easy, given that with the insight we have on the application, the data size seems to suffice. Furthermore, since Prob2Vec is performing well for not a relatively big data set, it would definitely do well for big data sets since the more data we have, the more precise the concept and problem embedding are. The easy-tough-to-beat method proposed by Arora et al. is the state of the art in unsupervised sentence embedding that we compared our algorithm with. Please let us know if we missed anything.\n\nPre-training is a common practice in transfer learning (one-shot learning). The objective function does not differ from the objective function used for post training. Training on only negative samples with lower training epochs than the training epochs in post training just adjusts the weights of the neural network to a better starting point. If the training epochs in pre-training is relatively smaller than the training epochs in post training, due to curse of dimensionality, the warm start for post training results in better performance for NN classifier. To make it more clear what it means to train the neural network on a pure set of negative data samples, think about batch training. It's not likely, but possible, that a batch only has negative or positive samples. In the pre-training phase of our method, we intentionally used a pure set of negative samples (with fewer training epochs) to have a warm start for post training. As table 3 shows, our proposed method outperforms one-shot learning. Please look at part 1 of our response to reviewer2 and part 2 of comment titled \"Response to Question on Negative Pre-Training\" below."}, "signatures": ["ICLR.cc/2019/Conference/Paper1081/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1081/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1081/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring", "abstract": "We propose a new application of embedding techniques to problem retrieval in adaptive tutoring. The objective is to retrieve problems similar in mathematical concepts. There are two challenges: First, like sentences, problems helpful to tutoring are never exactly the same in terms of the underlying concepts. Instead, good problems mix concepts in innovative ways, while still displaying continuity in their relationships. Second, it is difficult for humans to determine a similarity score consistent across a large enough training set. We propose a hierarchical problem embedding algorithm, called Prob2Vec, that consists of an abstraction and an embedding step. Prob2Vec achieves 96.88\\% accuracy on a problem similarity test, in contrast to 75\\% from directly applying state-of-the-art sentence embedding methods. It is surprising that Prob2Vec is able to distinguish very fine-grained differences among problems, an ability humans need time and effort to acquire. In addition, the sub-problem of concept labeling with imbalanced training data set is interesting in its own right. It is a multi-label problem suffering from dimensionality explosion, which we propose ways to ameliorate. We propose the novel negative pre-training algorithm that dramatically reduces false negative and positive ratios for classification, using an imbalanced training data set.", "keywords": ["personalized learning", "e-learning", "text embedding", "Skip-gram", "imbalanced data set", "data level classification methods"], "authorids": ["dusu3@illinois.edu", "yekkehk2@illinois.edu", "yilu4@illinois.edu", "wenmiao.lu@gmail.com"], "authors": ["Du Su", "Ali Yekkehkhany", "Yi Lu", "Wenmiao Lu"], "TL;DR": "We propose the Prob2Vec method for problem embedding used in a personalized e-learning tool in addition to a data level classification method, called negative pre-training, for cases where the training data set is imbalanced.", "pdf": "/pdf/94550a8d889861f60e4f5d79a43db74c8cb7ba7a.pdf", "paperhash": "su|prob2vec_mathematical_semantic_embedding_for_problem_retrieval_in_adaptive_tutoring", "_bibtex": "@misc{\nsu2019probvec,\ntitle={Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring},\nauthor={Du Su and Ali Yekkehkhany and Yi Lu and Wenmiao Lu},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl8gnAqtX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1081/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621625360, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJl8gnAqtX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1081/Authors", "ICLR.cc/2019/Conference/Paper1081/Reviewers", "ICLR.cc/2019/Conference/Paper1081/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1081/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1081/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1081/Authors|ICLR.cc/2019/Conference/Paper1081/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1081/Reviewers", "ICLR.cc/2019/Conference/Paper1081/Authors", "ICLR.cc/2019/Conference/Paper1081/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621625360}}}, {"id": "BkeXRoYqhm", "original": null, "number": 3, "cdate": 1541213131122, "ddate": null, "tcdate": 1541213131122, "tmdate": 1541533439974, "tddate": null, "forum": "SJl8gnAqtX", "replyto": "SJl8gnAqtX", "invitation": "ICLR.cc/2019/Conference/-/Paper1081/Official_Review", "content": {"title": "small technical contribution", "review": "The paper proposed a hierarchical framework for problem embedding and intended to apply it to adaptive tutoring. The system first used a rule-based method to extract the concepts for problems and then learned the concept embeddings and used them for problem representation. In addition, the paper further proposed negative pre-training for training with imbalanced data sets to decrease false negatives and positives. The methods are compared with some other word-embedding based methods and showed 100% accuracy in a similarity detection test on a very small dataset. \n\nIn sum, the paper has a very good application but not good enough as a research paper. Some of the problems are listed as follows:\n1.\tLack of technical novelty.  It seems to me just a combination of several mature techniques. I do not see much insight into the problem. For example, if the rule-based concept extractor can already extract concepts very well, the \u201cproblem retrieval\u201d should be solved by searching with the concepts as queries. Why should we use embedding to compare the similarity? Also, the title of the paper is about problem retrieval but the experiments are about similarity comparison, there seems a gap. \n2.\tData size is too small, and the baselines are not state-of-the-art. There are some unsupervised sentence embedding methods other than the word-embedding based models. \nSome clarity issues. For example, Page 6. \u201cis pre-trained on a pure set of negative samples\u201d\u2014 what is the objective function? How to train on only negative samples?\n", "rating": "3: Clear rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1081/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring", "abstract": "We propose a new application of embedding techniques to problem retrieval in adaptive tutoring. The objective is to retrieve problems similar in mathematical concepts. There are two challenges: First, like sentences, problems helpful to tutoring are never exactly the same in terms of the underlying concepts. Instead, good problems mix concepts in innovative ways, while still displaying continuity in their relationships. Second, it is difficult for humans to determine a similarity score consistent across a large enough training set. We propose a hierarchical problem embedding algorithm, called Prob2Vec, that consists of an abstraction and an embedding step. Prob2Vec achieves 96.88\\% accuracy on a problem similarity test, in contrast to 75\\% from directly applying state-of-the-art sentence embedding methods. It is surprising that Prob2Vec is able to distinguish very fine-grained differences among problems, an ability humans need time and effort to acquire. In addition, the sub-problem of concept labeling with imbalanced training data set is interesting in its own right. It is a multi-label problem suffering from dimensionality explosion, which we propose ways to ameliorate. We propose the novel negative pre-training algorithm that dramatically reduces false negative and positive ratios for classification, using an imbalanced training data set.", "keywords": ["personalized learning", "e-learning", "text embedding", "Skip-gram", "imbalanced data set", "data level classification methods"], "authorids": ["dusu3@illinois.edu", "yekkehk2@illinois.edu", "yilu4@illinois.edu", "wenmiao.lu@gmail.com"], "authors": ["Du Su", "Ali Yekkehkhany", "Yi Lu", "Wenmiao Lu"], "TL;DR": "We propose the Prob2Vec method for problem embedding used in a personalized e-learning tool in addition to a data level classification method, called negative pre-training, for cases where the training data set is imbalanced.", "pdf": "/pdf/94550a8d889861f60e4f5d79a43db74c8cb7ba7a.pdf", "paperhash": "su|prob2vec_mathematical_semantic_embedding_for_problem_retrieval_in_adaptive_tutoring", "_bibtex": "@misc{\nsu2019probvec,\ntitle={Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring},\nauthor={Du Su and Ali Yekkehkhany and Yi Lu and Wenmiao Lu},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl8gnAqtX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1081/Official_Review", "cdate": 1542234310637, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJl8gnAqtX", "replyto": "SJl8gnAqtX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1081/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335868451, "tmdate": 1552335868451, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1081/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "Syxz3gT_2Q", "original": null, "number": 2, "cdate": 1541095594156, "ddate": null, "tcdate": 1541095594156, "tmdate": 1541533439768, "tddate": null, "forum": "SJl8gnAqtX", "replyto": "SJl8gnAqtX", "invitation": "ICLR.cc/2019/Conference/-/Paper1081/Official_Review", "content": {"title": "Proposes a method for mathematical problem embedding but the contribution is not strong", "review": "This paper proposes a method for mathematical problem embedding, which firstly decomposes problems into concepts by an abstraction step and then trains a skip-gram model to learn concept embedding. A problem can be represented as the average concept (corresponding to those in the problem) embeddings. To handle the imbalanced dataset, a negative pre-training method is proposed to decrease false and false positives. Experimental results show that the proposed method works much better than baselines in similar problem detection, on an undergraduate probability data set. \nStrong points:\n(1)\tThe idea of decomposing problems into concepts is interesting and also makes sense. \n(2)\tThe training method for imbalanced datasets is impressive. \nConcerns or suggestions:\n1.\tThe main idea of using contents to represent a problem is quite simple and straightforward. The contribution of this paper seems more on the training method for imbalanced data sets. But there are no comparisons between the proposed training method and previous related works. Actually, imbalance data sets are common in machine learning problems and there are many related works. The comparisons are also absent in experiments.\n2.\tThe experimental data set is too small, with only 635 problems. It is difficult to judge the performance of the proposed model based on so small data set. \n3.\tThe proposed method, which decomposes a problem into multiple concepts, looks general for many problem settings. For example, representing a movie or news article by tags or topics. In this way, the proposed method can be tested in a broader domain and on larger datasets.\n4.\tFor the final purpose, comparing problem similarity, I am wondering what the result will be if we train a supervised model based problem-problem similarity labels?", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1081/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring", "abstract": "We propose a new application of embedding techniques to problem retrieval in adaptive tutoring. The objective is to retrieve problems similar in mathematical concepts. There are two challenges: First, like sentences, problems helpful to tutoring are never exactly the same in terms of the underlying concepts. Instead, good problems mix concepts in innovative ways, while still displaying continuity in their relationships. Second, it is difficult for humans to determine a similarity score consistent across a large enough training set. We propose a hierarchical problem embedding algorithm, called Prob2Vec, that consists of an abstraction and an embedding step. Prob2Vec achieves 96.88\\% accuracy on a problem similarity test, in contrast to 75\\% from directly applying state-of-the-art sentence embedding methods. It is surprising that Prob2Vec is able to distinguish very fine-grained differences among problems, an ability humans need time and effort to acquire. In addition, the sub-problem of concept labeling with imbalanced training data set is interesting in its own right. It is a multi-label problem suffering from dimensionality explosion, which we propose ways to ameliorate. We propose the novel negative pre-training algorithm that dramatically reduces false negative and positive ratios for classification, using an imbalanced training data set.", "keywords": ["personalized learning", "e-learning", "text embedding", "Skip-gram", "imbalanced data set", "data level classification methods"], "authorids": ["dusu3@illinois.edu", "yekkehk2@illinois.edu", "yilu4@illinois.edu", "wenmiao.lu@gmail.com"], "authors": ["Du Su", "Ali Yekkehkhany", "Yi Lu", "Wenmiao Lu"], "TL;DR": "We propose the Prob2Vec method for problem embedding used in a personalized e-learning tool in addition to a data level classification method, called negative pre-training, for cases where the training data set is imbalanced.", "pdf": "/pdf/94550a8d889861f60e4f5d79a43db74c8cb7ba7a.pdf", "paperhash": "su|prob2vec_mathematical_semantic_embedding_for_problem_retrieval_in_adaptive_tutoring", "_bibtex": "@misc{\nsu2019probvec,\ntitle={Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring},\nauthor={Du Su and Ali Yekkehkhany and Yi Lu and Wenmiao Lu},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl8gnAqtX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1081/Official_Review", "cdate": 1542234310637, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJl8gnAqtX", "replyto": "SJl8gnAqtX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1081/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335868451, "tmdate": 1552335868451, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1081/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "Skgof-pjiX", "original": null, "number": 1, "cdate": 1540243731354, "ddate": null, "tcdate": 1540243731354, "tmdate": 1541533439556, "tddate": null, "forum": "SJl8gnAqtX", "replyto": "SJl8gnAqtX", "invitation": "ICLR.cc/2019/Conference/-/Paper1081/Official_Review", "content": {"title": "Review of \"Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring\"", "review": "This paper proposes a new application of embedding techniques for mathematical problem retrieval in adaptive tutoring. The proposed method performs much better than baseline sentence embedding methods. Another contribution is on using negative pre-training to deal with an imbalanced training dataset. \n\nTo me this paper is just not good enough - the method essentially i) use \"a professor and two teaching assistants\" to build a \"rule-based concept extractor\" for problems, then ii) map problems into this \"concept space\" and simply treat them as words. There are several problems with this approach. \n\nFirst, doing so does not touch the core of the proposed application. For tutoring applications, the most important thing is to select a problem that can help students improve; even if you can indeed select a problem that is the most similar to another problem, is it the best one to show a student? There are no evaluations on real students in the paper. Moreover, the main difference between math problems and other problems is that there are math expressions; I do not think that using words/concept labels only is enough without touching on the math expressions.\n\nSecond, the proposed method does not sound scalable - the use of a professor and two teaching assistants to construct the concept extractor, and the use of an expert TA to select a small set of informative words. I am not sure how this will generalize to a larger number of problem spanning many different domains.\n\nI also had a hard time going through the paper - there aren't many details. Section 2.1 is where the method is proposed, yet most of the descriptions there are unclear. Without these details it is impossible to judge the novelty of the \"rule-based concept extractor\", which is the key technical innovation.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1081/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring", "abstract": "We propose a new application of embedding techniques to problem retrieval in adaptive tutoring. The objective is to retrieve problems similar in mathematical concepts. There are two challenges: First, like sentences, problems helpful to tutoring are never exactly the same in terms of the underlying concepts. Instead, good problems mix concepts in innovative ways, while still displaying continuity in their relationships. Second, it is difficult for humans to determine a similarity score consistent across a large enough training set. We propose a hierarchical problem embedding algorithm, called Prob2Vec, that consists of an abstraction and an embedding step. Prob2Vec achieves 96.88\\% accuracy on a problem similarity test, in contrast to 75\\% from directly applying state-of-the-art sentence embedding methods. It is surprising that Prob2Vec is able to distinguish very fine-grained differences among problems, an ability humans need time and effort to acquire. In addition, the sub-problem of concept labeling with imbalanced training data set is interesting in its own right. It is a multi-label problem suffering from dimensionality explosion, which we propose ways to ameliorate. We propose the novel negative pre-training algorithm that dramatically reduces false negative and positive ratios for classification, using an imbalanced training data set.", "keywords": ["personalized learning", "e-learning", "text embedding", "Skip-gram", "imbalanced data set", "data level classification methods"], "authorids": ["dusu3@illinois.edu", "yekkehk2@illinois.edu", "yilu4@illinois.edu", "wenmiao.lu@gmail.com"], "authors": ["Du Su", "Ali Yekkehkhany", "Yi Lu", "Wenmiao Lu"], "TL;DR": "We propose the Prob2Vec method for problem embedding used in a personalized e-learning tool in addition to a data level classification method, called negative pre-training, for cases where the training data set is imbalanced.", "pdf": "/pdf/94550a8d889861f60e4f5d79a43db74c8cb7ba7a.pdf", "paperhash": "su|prob2vec_mathematical_semantic_embedding_for_problem_retrieval_in_adaptive_tutoring", "_bibtex": "@misc{\nsu2019probvec,\ntitle={Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring},\nauthor={Du Su and Ali Yekkehkhany and Yi Lu and Wenmiao Lu},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl8gnAqtX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1081/Official_Review", "cdate": 1542234310637, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJl8gnAqtX", "replyto": "SJl8gnAqtX", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1081/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335868451, "tmdate": 1552335868451, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1081/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "Skxyj9mRom", "original": null, "number": 2, "cdate": 1540401814629, "ddate": null, "tcdate": 1540401814629, "tmdate": 1540401814629, "tddate": null, "forum": "SJl8gnAqtX", "replyto": "r1lDqoAiiX", "invitation": "ICLR.cc/2019/Conference/-/Paper1081/Official_Comment", "content": {"title": "Response to questions about Prob2Vec", "comment": "1-\tWe believe that it is easier to keep consistency in concept labeling than similarity annotation for a set of training problems. Furthermore, concept labeling in Prob2Vec is automated by a rule-based concept extractor, where the rules for concept extraction are relatively easy to find for experts. However, similarity annotation requires much more expert effort to prepare a relatively large training data set. In general, it is difficult to determine a similarity score consistent across a large enough training set, so it is not feasible to simply apply supervised methods to learn a similarity score for problems.\n\n2-\tWe divided the probability course into 26 modules, where each module is on a specific topic. About 300 students who practiced on our platform were asked about the performance of the recommendation system after they practiced for each module (some students practiced a module for more than once at their own will). Hence, we got around 7000 feedback, where about 76% of them had positive responses on the performance of the recommender system. Furthermore, we observed that similar problems are likely to be done correctly at the same time or wrong at the same time by students."}, "signatures": ["ICLR.cc/2019/Conference/Paper1081/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1081/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1081/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring", "abstract": "We propose a new application of embedding techniques to problem retrieval in adaptive tutoring. The objective is to retrieve problems similar in mathematical concepts. There are two challenges: First, like sentences, problems helpful to tutoring are never exactly the same in terms of the underlying concepts. Instead, good problems mix concepts in innovative ways, while still displaying continuity in their relationships. Second, it is difficult for humans to determine a similarity score consistent across a large enough training set. We propose a hierarchical problem embedding algorithm, called Prob2Vec, that consists of an abstraction and an embedding step. Prob2Vec achieves 96.88\\% accuracy on a problem similarity test, in contrast to 75\\% from directly applying state-of-the-art sentence embedding methods. It is surprising that Prob2Vec is able to distinguish very fine-grained differences among problems, an ability humans need time and effort to acquire. In addition, the sub-problem of concept labeling with imbalanced training data set is interesting in its own right. It is a multi-label problem suffering from dimensionality explosion, which we propose ways to ameliorate. We propose the novel negative pre-training algorithm that dramatically reduces false negative and positive ratios for classification, using an imbalanced training data set.", "keywords": ["personalized learning", "e-learning", "text embedding", "Skip-gram", "imbalanced data set", "data level classification methods"], "authorids": ["dusu3@illinois.edu", "yekkehk2@illinois.edu", "yilu4@illinois.edu", "wenmiao.lu@gmail.com"], "authors": ["Du Su", "Ali Yekkehkhany", "Yi Lu", "Wenmiao Lu"], "TL;DR": "We propose the Prob2Vec method for problem embedding used in a personalized e-learning tool in addition to a data level classification method, called negative pre-training, for cases where the training data set is imbalanced.", "pdf": "/pdf/94550a8d889861f60e4f5d79a43db74c8cb7ba7a.pdf", "paperhash": "su|prob2vec_mathematical_semantic_embedding_for_problem_retrieval_in_adaptive_tutoring", "_bibtex": "@misc{\nsu2019probvec,\ntitle={Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring},\nauthor={Du Su and Ali Yekkehkhany and Yi Lu and Wenmiao Lu},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl8gnAqtX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1081/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621625360, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJl8gnAqtX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1081/Authors", "ICLR.cc/2019/Conference/Paper1081/Reviewers", "ICLR.cc/2019/Conference/Paper1081/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1081/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1081/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1081/Authors|ICLR.cc/2019/Conference/Paper1081/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1081/Reviewers", "ICLR.cc/2019/Conference/Paper1081/Authors", "ICLR.cc/2019/Conference/Paper1081/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621625360}}}, {"id": "r1lDqoAiiX", "original": null, "number": 2, "cdate": 1540250511103, "ddate": null, "tcdate": 1540250511103, "tmdate": 1540250511103, "tddate": null, "forum": "SJl8gnAqtX", "replyto": "SJl8gnAqtX", "invitation": "ICLR.cc/2019/Conference/-/Paper1081/Public_Comment", "content": {"comment": "My background on natural language processing suggests that you could\u2019ve also annotated similarity among a set of training problems and trained a supervised machine learning model to predict the similarity of the unseen problems in the test set. Do you have any ideas if this can result in a better or comparable performance to Prob2Vec in your similarity detection test?\n\nHave you surveyed the performance of your proposed recommendation system based on Prob2Vec and fluency projection on problems based on their similarity scores to see how it works besides having good performance on the similarity detection test?", "title": "General questions about Prob2Vec"}, "signatures": ["(anonymous)"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1081/Reviewers/Unsubmitted"], "writers": ["(anonymous)", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring", "abstract": "We propose a new application of embedding techniques to problem retrieval in adaptive tutoring. The objective is to retrieve problems similar in mathematical concepts. There are two challenges: First, like sentences, problems helpful to tutoring are never exactly the same in terms of the underlying concepts. Instead, good problems mix concepts in innovative ways, while still displaying continuity in their relationships. Second, it is difficult for humans to determine a similarity score consistent across a large enough training set. We propose a hierarchical problem embedding algorithm, called Prob2Vec, that consists of an abstraction and an embedding step. Prob2Vec achieves 96.88\\% accuracy on a problem similarity test, in contrast to 75\\% from directly applying state-of-the-art sentence embedding methods. It is surprising that Prob2Vec is able to distinguish very fine-grained differences among problems, an ability humans need time and effort to acquire. In addition, the sub-problem of concept labeling with imbalanced training data set is interesting in its own right. It is a multi-label problem suffering from dimensionality explosion, which we propose ways to ameliorate. We propose the novel negative pre-training algorithm that dramatically reduces false negative and positive ratios for classification, using an imbalanced training data set.", "keywords": ["personalized learning", "e-learning", "text embedding", "Skip-gram", "imbalanced data set", "data level classification methods"], "authorids": ["dusu3@illinois.edu", "yekkehk2@illinois.edu", "yilu4@illinois.edu", "wenmiao.lu@gmail.com"], "authors": ["Du Su", "Ali Yekkehkhany", "Yi Lu", "Wenmiao Lu"], "TL;DR": "We propose the Prob2Vec method for problem embedding used in a personalized e-learning tool in addition to a data level classification method, called negative pre-training, for cases where the training data set is imbalanced.", "pdf": "/pdf/94550a8d889861f60e4f5d79a43db74c8cb7ba7a.pdf", "paperhash": "su|prob2vec_mathematical_semantic_embedding_for_problem_retrieval_in_adaptive_tutoring", "_bibtex": "@misc{\nsu2019probvec,\ntitle={Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring},\nauthor={Du Su and Ali Yekkehkhany and Yi Lu and Wenmiao Lu},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl8gnAqtX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1081/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311683443, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "SJl8gnAqtX", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1081/Authors", "ICLR.cc/2019/Conference/Paper1081/Reviewers", "ICLR.cc/2019/Conference/Paper1081/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1081/Authors", "ICLR.cc/2019/Conference/Paper1081/Reviewers", "ICLR.cc/2019/Conference/Paper1081/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311683443}}}, {"id": "HkeZu1ho9Q", "original": null, "number": 1, "cdate": 1539190632761, "ddate": null, "tcdate": 1539190632761, "tmdate": 1539710386881, "tddate": null, "forum": "SJl8gnAqtX", "replyto": "B1gv_Bz_cX", "invitation": "ICLR.cc/2019/Conference/-/Paper1081/Official_Comment", "content": {"title": "Response to Question on Negative Pre-Training", "comment": "Thanks for your comment. Here are the responses to your two questions:\n\n1- The ratio of the number of training epochs in the first and second phases of the negative pre-training method is a hyper-parameter of this method. In our simulations, the number of training epochs in the first phase is half of those in the second phase. Note that if the number of training epochs in the first phase goes to zero, negative pre-training would become a pure down sampling. On the other hand, if the number of training epochs in the first phase is much larger than those in the second phase, the neural network cannot learn the structure of data in the second phase. Hence, we believe the ratio should not be large, but relatively small.\n\n2- As you mentioned, it is not feasible to rank methods for classification over unbalanced data sets, but their complexity in memory use and training time can definitely be discussed. Based on our extensive literature review on classification on unbalanced data sets, we found the following methods that are compared in complexity with negative pre-training below:\n\na) Under/Over sampling: under sampling (down sampling) has its own benefits of very low complexity and high speed, but as we see in our paper, the cost is low performance. Over sampling usually suffers from over-fitting specially when the imbalance in data set is high. In our case, if we want to use over sampling, we need to at least replicate each positive data sample for 50 times which is prone to extreme suffer from over-fitting. Negative pre-training obviously has more training time than under sampling (but gives better performance), but it needs about half memory and training time compared to over sampling (in case that over sampling is done to completely balance the training data set).\n\nb) SMOTE: this method generates synthetic data in order to bring balance for negative and positive data samples. For extreme imbalance in training data, this method can be prone to over-fitting as well. Regarding memory usage and training time, negative pre-training needs about half of those compared to SMOTE (in case that SMOTE is used to completely balance the training data set).\n\nc) Borderline-SMOTE: this method is in nature similar to SMOTE, but adds synthetic data in the border of the negative and positive sample. The method that is used to find the data samples in the border has high complexity, where the pairwise distance between the positive samples and all other samples should be measure (which can be hard for high dimensional data). Hence, although this method outperforms SMOTE, it needs strictly two times more memory and training time compared to negative pre-training, but for data with high dimension, it can be much worse or even impossible to find the pairwise distances between all data samples.\n\nd) Hybrid method: in this method, different weak learners are trained over the unbalanced training data set, then Adaboost method is used to combine the weak learners into a weighted sum that represents the boosted classifier. The comparison of hybrid method with negative pre-training in terms of memory usage and training time depends on how many weak learners we want to have and train. For m weak learners, we need to train m distinct neural networks, while we only have a single neural network in negative pre-training. Hence, this method is more complex than our proposed method and needs to store the weights of m neural networks that can be infeasible for deep networks (it is usually the case that m >> 1)."}, "signatures": ["ICLR.cc/2019/Conference/Paper1081/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1081/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1081/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring", "abstract": "We propose a new application of embedding techniques to problem retrieval in adaptive tutoring. The objective is to retrieve problems similar in mathematical concepts. There are two challenges: First, like sentences, problems helpful to tutoring are never exactly the same in terms of the underlying concepts. Instead, good problems mix concepts in innovative ways, while still displaying continuity in their relationships. Second, it is difficult for humans to determine a similarity score consistent across a large enough training set. We propose a hierarchical problem embedding algorithm, called Prob2Vec, that consists of an abstraction and an embedding step. Prob2Vec achieves 96.88\\% accuracy on a problem similarity test, in contrast to 75\\% from directly applying state-of-the-art sentence embedding methods. It is surprising that Prob2Vec is able to distinguish very fine-grained differences among problems, an ability humans need time and effort to acquire. In addition, the sub-problem of concept labeling with imbalanced training data set is interesting in its own right. It is a multi-label problem suffering from dimensionality explosion, which we propose ways to ameliorate. We propose the novel negative pre-training algorithm that dramatically reduces false negative and positive ratios for classification, using an imbalanced training data set.", "keywords": ["personalized learning", "e-learning", "text embedding", "Skip-gram", "imbalanced data set", "data level classification methods"], "authorids": ["dusu3@illinois.edu", "yekkehk2@illinois.edu", "yilu4@illinois.edu", "wenmiao.lu@gmail.com"], "authors": ["Du Su", "Ali Yekkehkhany", "Yi Lu", "Wenmiao Lu"], "TL;DR": "We propose the Prob2Vec method for problem embedding used in a personalized e-learning tool in addition to a data level classification method, called negative pre-training, for cases where the training data set is imbalanced.", "pdf": "/pdf/94550a8d889861f60e4f5d79a43db74c8cb7ba7a.pdf", "paperhash": "su|prob2vec_mathematical_semantic_embedding_for_problem_retrieval_in_adaptive_tutoring", "_bibtex": "@misc{\nsu2019probvec,\ntitle={Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring},\nauthor={Du Su and Ali Yekkehkhany and Yi Lu and Wenmiao Lu},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl8gnAqtX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1081/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621625360, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJl8gnAqtX", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1081/Authors", "ICLR.cc/2019/Conference/Paper1081/Reviewers", "ICLR.cc/2019/Conference/Paper1081/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1081/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1081/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1081/Authors|ICLR.cc/2019/Conference/Paper1081/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1081/Reviewers", "ICLR.cc/2019/Conference/Paper1081/Authors", "ICLR.cc/2019/Conference/Paper1081/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621625360}}}, {"id": "B1gv_Bz_cX", "original": null, "number": 1, "cdate": 1538954606977, "ddate": null, "tcdate": 1538954606977, "tmdate": 1538954606977, "tddate": null, "forum": "SJl8gnAqtX", "replyto": "SJl8gnAqtX", "invitation": "ICLR.cc/2019/Conference/-/Paper1081/Public_Comment", "content": {"comment": "I have two questions on your proposed negative pre-training algorithm as follows:\n\n1- Do you use the same number of training epochs for the first and second phases of negative pre-training? If yes, why, if no, what's the intuition behind it?\n\n2- I know it's not applicable to compare the performance of your negative pre-training method with all other existing methods for classification with having imbalanced training data sets, and there is not such a notion of state-of-the-art algorithm for such methods, and probably the most prominent one is down sampling to avoid training complexity and over-fitting, but do you have any comparison of training complexity in terms of memory use and rough training time of negative pre-training and other algorithms for classification with having imbalanced training data sets?", "title": "Negative Pre-Training Details"}, "signatures": ["~Mohammadamir_Kavousi1"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1081/Reviewers/Unsubmitted"], "writers": ["~Mohammadamir_Kavousi1", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring", "abstract": "We propose a new application of embedding techniques to problem retrieval in adaptive tutoring. The objective is to retrieve problems similar in mathematical concepts. There are two challenges: First, like sentences, problems helpful to tutoring are never exactly the same in terms of the underlying concepts. Instead, good problems mix concepts in innovative ways, while still displaying continuity in their relationships. Second, it is difficult for humans to determine a similarity score consistent across a large enough training set. We propose a hierarchical problem embedding algorithm, called Prob2Vec, that consists of an abstraction and an embedding step. Prob2Vec achieves 96.88\\% accuracy on a problem similarity test, in contrast to 75\\% from directly applying state-of-the-art sentence embedding methods. It is surprising that Prob2Vec is able to distinguish very fine-grained differences among problems, an ability humans need time and effort to acquire. In addition, the sub-problem of concept labeling with imbalanced training data set is interesting in its own right. It is a multi-label problem suffering from dimensionality explosion, which we propose ways to ameliorate. We propose the novel negative pre-training algorithm that dramatically reduces false negative and positive ratios for classification, using an imbalanced training data set.", "keywords": ["personalized learning", "e-learning", "text embedding", "Skip-gram", "imbalanced data set", "data level classification methods"], "authorids": ["dusu3@illinois.edu", "yekkehk2@illinois.edu", "yilu4@illinois.edu", "wenmiao.lu@gmail.com"], "authors": ["Du Su", "Ali Yekkehkhany", "Yi Lu", "Wenmiao Lu"], "TL;DR": "We propose the Prob2Vec method for problem embedding used in a personalized e-learning tool in addition to a data level classification method, called negative pre-training, for cases where the training data set is imbalanced.", "pdf": "/pdf/94550a8d889861f60e4f5d79a43db74c8cb7ba7a.pdf", "paperhash": "su|prob2vec_mathematical_semantic_embedding_for_problem_retrieval_in_adaptive_tutoring", "_bibtex": "@misc{\nsu2019probvec,\ntitle={Prob2Vec: Mathematical Semantic Embedding for Problem Retrieval in Adaptive Tutoring},\nauthor={Du Su and Ali Yekkehkhany and Yi Lu and Wenmiao Lu},\nyear={2019},\nurl={https://openreview.net/forum?id=SJl8gnAqtX},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1081/Public_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1542311683443, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed."}, "nonreaders": {"values": []}, "forum": "SJl8gnAqtX", "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1081/Authors", "ICLR.cc/2019/Conference/Paper1081/Reviewers", "ICLR.cc/2019/Conference/Paper1081/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "replyto": null, "content": {"comment": {"value-regex": "[\\S\\s]{1,5000}", "required": true, "order": 1, "description": "Your comment or reply (max 5000 characters)."}, "title": {"value-regex": ".{1,500}", "required": true, "order": 0, "description": "Brief summary of your comment."}}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": ["ICLR.cc/2019/Conference/Paper1081/Authors", "ICLR.cc/2019/Conference/Paper1081/Reviewers", "ICLR.cc/2019/Conference/Paper1081/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1542311683443}}}], "count": 12}