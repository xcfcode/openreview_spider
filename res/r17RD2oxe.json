{"notes": [{"tddate": null, "ddate": null, "cdate": null, "tmdate": 1486396685971, "tcdate": 1486396685971, "number": 1, "id": "HkLG6GI_x", "invitation": "ICLR.cc/2017/conference/-/paper577/acceptance", "forum": "r17RD2oxe", "replyto": "r17RD2oxe", "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/pcs"], "content": {"decision": "Reject", "title": "ICLR committee final decision", "comment": "The reviewers agree that the paper provides a creative idea of using Computer Vision in Biology by building \"the tree of life\". However, they also agree that the paper in its current form is not ready for publication due to limited novelty and unclear impact/application. The authors did not post a rebuttal to address the concerns. The AC agrees with the reviewers', and encourages the authors to improve their manuscript as per reviewers' suggestions, and submit to a future conference."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Neural Networks and the Tree of Life", "abstract": "In Evolutionary Biology, species close in the tree of evolution are identified by similar visual features. In computer vision, deep neural networks perform image classification by learning to identify similar visual features. This leads to an interesting question: is it possible to leverage the advantage of deep networks to construct a tree of life? In this paper, we make the first attempt at building the phylogenetic tree diagram by leveraging the high-level features learned by deep neural networks. Our method is based on the intuition that if two species share similar features, then their cross activations in the softmax layer should be high. Based on the deep representation of convolutional neural networks trained for image classification, we build a tree of life for species in the image categories of ImageNet. Further, for species not in the ImageNet categories that are visually similar to some category, the cosine similarity of their activation vectors in the same layer should be high. By applying the inner product similarity of the activation vectors at the last fully connected layer for different species, we can roughly build their tree of life. Our work provides a new perspective to the deep representation and sheds light on possible novel applications of deep representation to other areas like Bioinformatics.\n", "pdf": "/pdf/2a7c18802f86269398c44a4638552d8895a44611.pdf", "TL;DR": "Provideing a potential solution to the important problem of constructing a biology evolutionary tree; Giving insight into the representations produced by deep neural networks", "paperhash": "wang|deep_neural_networks_and_the_tree_of_life", "authors": ["Yan Wang", "Kun He", "John E. Hopcroft", "Yu Sun"], "keywords": ["Deep learning", "Computer vision", "Applications"], "conflicts": ["cs.cornell.edu", "hust.edu.cn"], "authorids": ["yanwang@hust.edu.cn", "brooklet60@hust.edu.cn", "jeh@cs.cornell.edu", "ys646@cornell.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1486396686529, "id": "ICLR.cc/2017/conference/-/paper577/acceptance", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/pcs"], "noninvitees": ["ICLR.cc/2017/pcs"], "reply": {"forum": "r17RD2oxe", "replyto": "r17RD2oxe", "writers": {"values-regex": "ICLR.cc/2017/pcs"}, "signatures": {"values-regex": "ICLR.cc/2017/pcs", "description": "Your displayed identity associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your decision.", "value": "ICLR committee final decision"}, "comment": {"required": true, "order": 2, "description": "Decision comments.", "value-regex": "[\\S\\s]{1,5000}"}, "decision": {"required": true, "order": 3, "value-radio": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "nonreaders": [], "cdate": 1486396686529}}}, {"tddate": null, "tmdate": 1482198405093, "tcdate": 1482198405093, "number": 3, "id": "HkptTW8Vl", "invitation": "ICLR.cc/2017/conference/-/paper577/official/review", "forum": "r17RD2oxe", "replyto": "r17RD2oxe", "signatures": ["ICLR.cc/2017/conference/paper577/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper577/AnonReviewer3"], "content": {"title": "concerns about both contributions", "rating": "3: Clear rejection", "review": "The paper presents a simple method for constructing a visual hierarchy of ImageNet classes based on a CNN trained on discriminate between the classes. It investigates two metrics for measuring inter-class similarity: (1) softmax probability outputs, i.e., the class confusion matrix, and (2) L2 distance between fc7 features, along with three methods for constructing the hierarchy given the distance matrix: (1) approximation central point, (2) minimal spanning tree, and (3) multidimensional scaling of Borg&Groenen 2005.\n\nThere are two claimed contributions: (1) Constructs a biology evolutionary tree, and (2) Gives insight into the representations produced by deep networks. \n\nRegarding (1), while the motivation of the work is grounded in biology, in practice the method is based only on visual similarity. The constructed trees thus can\u2019t be expected to reflect the evolutionary hierarchy, and in fact there are no quantitative experiments that demonstrate that they do. \n\nRegarding (2), the technical depth of the exploration is not sufficient for ICLR. I\u2019m not sure what we can conclude from the paper beyond the fact that CNNs are able to group categories together based on visual similarities, and deeper networks are able to do this better than more shallow networks (Fig 2).\n\nIn summary, this paper is unfortunately not ready for publication at this time. ", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Neural Networks and the Tree of Life", "abstract": "In Evolutionary Biology, species close in the tree of evolution are identified by similar visual features. In computer vision, deep neural networks perform image classification by learning to identify similar visual features. This leads to an interesting question: is it possible to leverage the advantage of deep networks to construct a tree of life? In this paper, we make the first attempt at building the phylogenetic tree diagram by leveraging the high-level features learned by deep neural networks. Our method is based on the intuition that if two species share similar features, then their cross activations in the softmax layer should be high. Based on the deep representation of convolutional neural networks trained for image classification, we build a tree of life for species in the image categories of ImageNet. Further, for species not in the ImageNet categories that are visually similar to some category, the cosine similarity of their activation vectors in the same layer should be high. By applying the inner product similarity of the activation vectors at the last fully connected layer for different species, we can roughly build their tree of life. Our work provides a new perspective to the deep representation and sheds light on possible novel applications of deep representation to other areas like Bioinformatics.\n", "pdf": "/pdf/2a7c18802f86269398c44a4638552d8895a44611.pdf", "TL;DR": "Provideing a potential solution to the important problem of constructing a biology evolutionary tree; Giving insight into the representations produced by deep neural networks", "paperhash": "wang|deep_neural_networks_and_the_tree_of_life", "authors": ["Yan Wang", "Kun He", "John E. Hopcroft", "Yu Sun"], "keywords": ["Deep learning", "Computer vision", "Applications"], "conflicts": ["cs.cornell.edu", "hust.edu.cn"], "authorids": ["yanwang@hust.edu.cn", "brooklet60@hust.edu.cn", "jeh@cs.cornell.edu", "ys646@cornell.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512536162, "id": "ICLR.cc/2017/conference/-/paper577/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper577/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper577/AnonReviewer1", "ICLR.cc/2017/conference/paper577/AnonReviewer2", "ICLR.cc/2017/conference/paper577/AnonReviewer3"], "reply": {"forum": "r17RD2oxe", "replyto": "r17RD2oxe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper577/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper577/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512536162}}}, {"tddate": null, "tmdate": 1482185587233, "tcdate": 1482185587233, "number": 2, "id": "rJi_oCBVx", "invitation": "ICLR.cc/2017/conference/-/paper577/official/review", "forum": "r17RD2oxe", "replyto": "r17RD2oxe", "signatures": ["ICLR.cc/2017/conference/paper577/AnonReviewer2"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper577/AnonReviewer2"], "content": {"title": "Nice application of using deep features but lack technical novelty", "rating": "4: Ok but not good enough - rejection", "review": "This paper introduces a hierarchical clustering method using learned CNN features to build 'the tree of life'. The assumption is that the feature similarity indicates the distance in the tree. The authors tried three different ways to construct the tree: 1) approximation central point 2) minimum spanning tree and 3) multidimensional scaling based method. Out of them, MDS works the best. It is a nice application of using deep features. However, I lean toward rejecting the paper because the following reasons:\n\n1) All experiments are conducted in very small scale. The experiments include 6 fish species, 11 canine species, 8 vehicle classes. There are no quantitative results, only by visualizing the generated tree versus the wordNet tree. Moreover, the assumption of using wordNet is not quite valid. WordNet is not designed for biology purpose and it might not reflect the true evolutionary relationship between species. \n2) Limited technical novelty. Most parts of the pipeline are standard, e.g. use pretrained model for feature extraction, use previous methods to construct hierarchical clustering. I think the technical contribution of this paper is very limited. \n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Neural Networks and the Tree of Life", "abstract": "In Evolutionary Biology, species close in the tree of evolution are identified by similar visual features. In computer vision, deep neural networks perform image classification by learning to identify similar visual features. This leads to an interesting question: is it possible to leverage the advantage of deep networks to construct a tree of life? In this paper, we make the first attempt at building the phylogenetic tree diagram by leveraging the high-level features learned by deep neural networks. Our method is based on the intuition that if two species share similar features, then their cross activations in the softmax layer should be high. Based on the deep representation of convolutional neural networks trained for image classification, we build a tree of life for species in the image categories of ImageNet. Further, for species not in the ImageNet categories that are visually similar to some category, the cosine similarity of their activation vectors in the same layer should be high. By applying the inner product similarity of the activation vectors at the last fully connected layer for different species, we can roughly build their tree of life. Our work provides a new perspective to the deep representation and sheds light on possible novel applications of deep representation to other areas like Bioinformatics.\n", "pdf": "/pdf/2a7c18802f86269398c44a4638552d8895a44611.pdf", "TL;DR": "Provideing a potential solution to the important problem of constructing a biology evolutionary tree; Giving insight into the representations produced by deep neural networks", "paperhash": "wang|deep_neural_networks_and_the_tree_of_life", "authors": ["Yan Wang", "Kun He", "John E. Hopcroft", "Yu Sun"], "keywords": ["Deep learning", "Computer vision", "Applications"], "conflicts": ["cs.cornell.edu", "hust.edu.cn"], "authorids": ["yanwang@hust.edu.cn", "brooklet60@hust.edu.cn", "jeh@cs.cornell.edu", "ys646@cornell.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512536162, "id": "ICLR.cc/2017/conference/-/paper577/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper577/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper577/AnonReviewer1", "ICLR.cc/2017/conference/paper577/AnonReviewer2", "ICLR.cc/2017/conference/paper577/AnonReviewer3"], "reply": {"forum": "r17RD2oxe", "replyto": "r17RD2oxe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper577/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper577/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512536162}}}, {"tddate": null, "tmdate": 1482174815836, "tcdate": 1482174815836, "number": 3, "id": "r1_vW2HVx", "invitation": "ICLR.cc/2017/conference/-/paper577/public/comment", "forum": "r17RD2oxe", "replyto": "r17RD2oxe", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Is this something useful for biologist ? or for computer vision researcher ?", "comment": "I think the idea is interesting, but is that something useful to construct the tree based on visual features? \n\nMoreover, in the paper, you mentioned that, it is based on the conjecture that,\n\"if images of two training categories share some similar features, then their cross activations in the softmax layer should be high\".\n\nTo me , this is something like the Neural style transfer, \nhttps://arxiv.org/abs/1508.06576\nIt is calculating the correlations between features.\n\nThen what is the real application for this ?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Neural Networks and the Tree of Life", "abstract": "In Evolutionary Biology, species close in the tree of evolution are identified by similar visual features. In computer vision, deep neural networks perform image classification by learning to identify similar visual features. This leads to an interesting question: is it possible to leverage the advantage of deep networks to construct a tree of life? In this paper, we make the first attempt at building the phylogenetic tree diagram by leveraging the high-level features learned by deep neural networks. Our method is based on the intuition that if two species share similar features, then their cross activations in the softmax layer should be high. Based on the deep representation of convolutional neural networks trained for image classification, we build a tree of life for species in the image categories of ImageNet. Further, for species not in the ImageNet categories that are visually similar to some category, the cosine similarity of their activation vectors in the same layer should be high. By applying the inner product similarity of the activation vectors at the last fully connected layer for different species, we can roughly build their tree of life. Our work provides a new perspective to the deep representation and sheds light on possible novel applications of deep representation to other areas like Bioinformatics.\n", "pdf": "/pdf/2a7c18802f86269398c44a4638552d8895a44611.pdf", "TL;DR": "Provideing a potential solution to the important problem of constructing a biology evolutionary tree; Giving insight into the representations produced by deep neural networks", "paperhash": "wang|deep_neural_networks_and_the_tree_of_life", "authors": ["Yan Wang", "Kun He", "John E. Hopcroft", "Yu Sun"], "keywords": ["Deep learning", "Computer vision", "Applications"], "conflicts": ["cs.cornell.edu", "hust.edu.cn"], "authorids": ["yanwang@hust.edu.cn", "brooklet60@hust.edu.cn", "jeh@cs.cornell.edu", "ys646@cornell.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287514817, "id": "ICLR.cc/2017/conference/-/paper577/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "r17RD2oxe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper577/reviewers", "ICLR.cc/2017/conference/paper577/areachairs"], "cdate": 1485287514817}}}, {"tddate": null, "tmdate": 1481958763737, "tcdate": 1481958763737, "number": 2, "id": "HyEuBvMNx", "invitation": "ICLR.cc/2017/conference/-/paper577/public/comment", "forum": "r17RD2oxe", "replyto": "BkLWp70zx", "signatures": ["~Kun_He1"], "readers": ["everyone"], "writers": ["~Kun_He1"], "content": {"title": "feedback", "comment": "Thank you for your comments and questions.We agree that \"tree of life\", semantic hierarchy and visual hierarchy are different concepts. We agree with your summarize that we have created a visual hierarchy evaluated on a hierarchy. We do no claim that we are building a \"tree of life\" and should make that very clear.The works that you mentioned are relevant and we will cite and compare them. The paper by Deng et. al focuses image classification; more specifically, your referred section attempts to make classification results more reasonable when placed in an existing hierarchy. They do not attempt the task of generating a new visual hierarchy. The paper by Griffin and Perona al also explores the problem from a classification perspective, while their hierarchy of classifiers can be viewed as analogous to our hierarchy of images. We will also point these out. The paper by Marsza\u0142ek and Schmid should be an interesting baseline for our method, and we hope to conduct this experiment soon."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Neural Networks and the Tree of Life", "abstract": "In Evolutionary Biology, species close in the tree of evolution are identified by similar visual features. In computer vision, deep neural networks perform image classification by learning to identify similar visual features. This leads to an interesting question: is it possible to leverage the advantage of deep networks to construct a tree of life? In this paper, we make the first attempt at building the phylogenetic tree diagram by leveraging the high-level features learned by deep neural networks. Our method is based on the intuition that if two species share similar features, then their cross activations in the softmax layer should be high. Based on the deep representation of convolutional neural networks trained for image classification, we build a tree of life for species in the image categories of ImageNet. Further, for species not in the ImageNet categories that are visually similar to some category, the cosine similarity of their activation vectors in the same layer should be high. By applying the inner product similarity of the activation vectors at the last fully connected layer for different species, we can roughly build their tree of life. Our work provides a new perspective to the deep representation and sheds light on possible novel applications of deep representation to other areas like Bioinformatics.\n", "pdf": "/pdf/2a7c18802f86269398c44a4638552d8895a44611.pdf", "TL;DR": "Provideing a potential solution to the important problem of constructing a biology evolutionary tree; Giving insight into the representations produced by deep neural networks", "paperhash": "wang|deep_neural_networks_and_the_tree_of_life", "authors": ["Yan Wang", "Kun He", "John E. Hopcroft", "Yu Sun"], "keywords": ["Deep learning", "Computer vision", "Applications"], "conflicts": ["cs.cornell.edu", "hust.edu.cn"], "authorids": ["yanwang@hust.edu.cn", "brooklet60@hust.edu.cn", "jeh@cs.cornell.edu", "ys646@cornell.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287514817, "id": "ICLR.cc/2017/conference/-/paper577/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "r17RD2oxe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper577/reviewers", "ICLR.cc/2017/conference/paper577/areachairs"], "cdate": 1485287514817}}}, {"tddate": null, "tmdate": 1481958735405, "tcdate": 1481958735405, "number": 1, "id": "r1PIHPMNx", "invitation": "ICLR.cc/2017/conference/-/paper577/public/comment", "forum": "r17RD2oxe", "replyto": "rkXjqEqQl", "signatures": ["~Kun_He1"], "readers": ["everyone"], "writers": ["~Kun_He1"], "content": {"title": "feedback", "comment": "Our methods creates a particular taxonomy, which may contain information on ancestry. Yes, many complex phenomena factor into the determination of ancestry, which is even difficult for biologists. We do not claim that we have recovered the ancestry relationship.We are claiming that the features learned by the current generation of networks are capable of learning a very reasonable hierarchy. Yes, previous feature extractors are also fitting for this task, but we did not experiment with them simply because we wanted to use modern models."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Neural Networks and the Tree of Life", "abstract": "In Evolutionary Biology, species close in the tree of evolution are identified by similar visual features. In computer vision, deep neural networks perform image classification by learning to identify similar visual features. This leads to an interesting question: is it possible to leverage the advantage of deep networks to construct a tree of life? In this paper, we make the first attempt at building the phylogenetic tree diagram by leveraging the high-level features learned by deep neural networks. Our method is based on the intuition that if two species share similar features, then their cross activations in the softmax layer should be high. Based on the deep representation of convolutional neural networks trained for image classification, we build a tree of life for species in the image categories of ImageNet. Further, for species not in the ImageNet categories that are visually similar to some category, the cosine similarity of their activation vectors in the same layer should be high. By applying the inner product similarity of the activation vectors at the last fully connected layer for different species, we can roughly build their tree of life. Our work provides a new perspective to the deep representation and sheds light on possible novel applications of deep representation to other areas like Bioinformatics.\n", "pdf": "/pdf/2a7c18802f86269398c44a4638552d8895a44611.pdf", "TL;DR": "Provideing a potential solution to the important problem of constructing a biology evolutionary tree; Giving insight into the representations produced by deep neural networks", "paperhash": "wang|deep_neural_networks_and_the_tree_of_life", "authors": ["Yan Wang", "Kun He", "John E. Hopcroft", "Yu Sun"], "keywords": ["Deep learning", "Computer vision", "Applications"], "conflicts": ["cs.cornell.edu", "hust.edu.cn"], "authorids": ["yanwang@hust.edu.cn", "brooklet60@hust.edu.cn", "jeh@cs.cornell.edu", "ys646@cornell.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "tmdate": 1485287514817, "id": "ICLR.cc/2017/conference/-/paper577/public/comment", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": "r17RD2oxe", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2017/conference/organizers", "ICLR.cc/2017/conference/ACs_and_organizers", "ICLR.cc/2017/conference/reviewers_and_ACS_and_organizers"]}, "content": {"title": {"order": 1, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"order": 2, "description": "Your comment or reply.", "value-regex": "[\\S\\s]{1,20000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2017/conference/paper577/reviewers", "ICLR.cc/2017/conference/paper577/areachairs"], "cdate": 1485287514817}}}, {"tddate": null, "tmdate": 1481943694468, "tcdate": 1481943612185, "number": 1, "id": "rkVScXzEl", "invitation": "ICLR.cc/2017/conference/-/paper577/official/review", "forum": "r17RD2oxe", "replyto": "r17RD2oxe", "signatures": ["ICLR.cc/2017/conference/paper577/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper577/AnonReviewer1"], "content": {"title": "Intellectually interesting but I'm not sure what the real contribution is", "rating": "4: Ok but not good enough - rejection", "review": "I like this paper in that it is a creative application of computer vision to Biology. Or, at least, that would be a good narrative but I'm not confident biologists would actually care about the \"Tree of Life\" built from this method. There's not really any biology in this paper, either in methodology or evaluation. It boils down to a hierarchical clustering of visual categories with ground truth assumed to be the WordNet hierarchy (which may or may not be the biological ground truth inheritance relationships between species, if that is even possible to define -- it probably isn't for dog species which interbreed and it definitely isn't for vehicles) or the actual biological inheritance tree or what humans would do in the same task. If we're just worried about visual relationships and not inheritance relationships then a graph is the right structure, not a tree. A tree is needlessly lossy and imposes weird relationships (e.g. ImageNet has a photo of a \"toy rabbit\" and by tree distance it is maximally distant from \"rabbit\" because the toy is in the devices top level hierarchy and the real rabbit is in the animal branch. Are those two images really as semantically unrelated as is possible?). Our visual world is not a hierarchy. Our biological world can reasonably be defined as one. One could define the task of trying to recover the biological inheritance tree from visual inputs, although we know that would be tough to do because of situations like convergent evolution. Still, one could evaluate how well various visual features can recover the hierarchical relationship of biological organisms. This paper doesn't quite do that. And even if it did, it would still feel like a bit of a solution in search of a problem. The paper says that this type of exercise can help us understand deep features, but I'm not sure sure how much it reveals. I guess it's a fair question to ask if a particular feature produces meaningful class-to-class distances, but it's not clear that the biological tree of life or the wordnet hierarchy is the right ground truth for that (I'd argue it's not).\n\nFinally, the paper mentions human baselines in a few places but I'm not really seeing it. \"Experiments show that the proposed method using deep representation is very competitive to human beings in building the tree of life based on the visual similarity of the species.\" and then later \"The reconstructed quality is as good as what human beings could reconstruct based on the visual similarity.\" That's the extent of the experiment? A qualitative result and the declaration that it's as good as humans could do? ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Neural Networks and the Tree of Life", "abstract": "In Evolutionary Biology, species close in the tree of evolution are identified by similar visual features. In computer vision, deep neural networks perform image classification by learning to identify similar visual features. This leads to an interesting question: is it possible to leverage the advantage of deep networks to construct a tree of life? In this paper, we make the first attempt at building the phylogenetic tree diagram by leveraging the high-level features learned by deep neural networks. Our method is based on the intuition that if two species share similar features, then their cross activations in the softmax layer should be high. Based on the deep representation of convolutional neural networks trained for image classification, we build a tree of life for species in the image categories of ImageNet. Further, for species not in the ImageNet categories that are visually similar to some category, the cosine similarity of their activation vectors in the same layer should be high. By applying the inner product similarity of the activation vectors at the last fully connected layer for different species, we can roughly build their tree of life. Our work provides a new perspective to the deep representation and sheds light on possible novel applications of deep representation to other areas like Bioinformatics.\n", "pdf": "/pdf/2a7c18802f86269398c44a4638552d8895a44611.pdf", "TL;DR": "Provideing a potential solution to the important problem of constructing a biology evolutionary tree; Giving insight into the representations produced by deep neural networks", "paperhash": "wang|deep_neural_networks_and_the_tree_of_life", "authors": ["Yan Wang", "Kun He", "John E. Hopcroft", "Yu Sun"], "keywords": ["Deep learning", "Computer vision", "Applications"], "conflicts": ["cs.cornell.edu", "hust.edu.cn"], "authorids": ["yanwang@hust.edu.cn", "brooklet60@hust.edu.cn", "jeh@cs.cornell.edu", "ys646@cornell.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1481932799000, "tmdate": 1482512536162, "id": "ICLR.cc/2017/conference/-/paper577/official/review", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper577/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper577/AnonReviewer1", "ICLR.cc/2017/conference/paper577/AnonReviewer2", "ICLR.cc/2017/conference/paper577/AnonReviewer3"], "reply": {"forum": "r17RD2oxe", "replyto": "r17RD2oxe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper577/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper577/AnonReviewer[0-9]+"}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,20000}"}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1489708799000, "cdate": 1482512536162}}}, {"tddate": null, "tmdate": 1481423515023, "tcdate": 1481423515018, "number": 2, "id": "rkXjqEqQl", "invitation": "ICLR.cc/2017/conference/-/paper577/pre-review/question", "forum": "r17RD2oxe", "replyto": "r17RD2oxe", "signatures": ["ICLR.cc/2017/conference/paper577/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper577/AnonReviewer1"], "content": {"title": "Pre-review concerns", "question": "I don't have any clarification questions so I'm left with big picture stuff:\n\nDon't biologists primarily want a tree of life hierarchy based on actual ancestry? Is the proposed work supposed to approximate that? Because visual similarity seems like a poor proxy. You have phenomena such as convergent evolution ( https://en.wikipedia.org/wiki/Convergent_evolution ) that will fool a visual classifier. Or maybe ancestry isn't the only way to organize the tree of life. But in that case, it probably shouldn't be a tree, right? Probably more of a graph. A tree makes sense only with ancestry.\n\nCouldn't you do this with any previous (including non-deep) visual feature + classifier? Won't the next generation of better deep networks provide yet another arrangement? Won't human perceptual ratings provide yet another? How would this actually be used?"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Neural Networks and the Tree of Life", "abstract": "In Evolutionary Biology, species close in the tree of evolution are identified by similar visual features. In computer vision, deep neural networks perform image classification by learning to identify similar visual features. This leads to an interesting question: is it possible to leverage the advantage of deep networks to construct a tree of life? In this paper, we make the first attempt at building the phylogenetic tree diagram by leveraging the high-level features learned by deep neural networks. Our method is based on the intuition that if two species share similar features, then their cross activations in the softmax layer should be high. Based on the deep representation of convolutional neural networks trained for image classification, we build a tree of life for species in the image categories of ImageNet. Further, for species not in the ImageNet categories that are visually similar to some category, the cosine similarity of their activation vectors in the same layer should be high. By applying the inner product similarity of the activation vectors at the last fully connected layer for different species, we can roughly build their tree of life. Our work provides a new perspective to the deep representation and sheds light on possible novel applications of deep representation to other areas like Bioinformatics.\n", "pdf": "/pdf/2a7c18802f86269398c44a4638552d8895a44611.pdf", "TL;DR": "Provideing a potential solution to the important problem of constructing a biology evolutionary tree; Giving insight into the representations produced by deep neural networks", "paperhash": "wang|deep_neural_networks_and_the_tree_of_life", "authors": ["Yan Wang", "Kun He", "John E. Hopcroft", "Yu Sun"], "keywords": ["Deep learning", "Computer vision", "Applications"], "conflicts": ["cs.cornell.edu", "hust.edu.cn"], "authorids": ["yanwang@hust.edu.cn", "brooklet60@hust.edu.cn", "jeh@cs.cornell.edu", "ys646@cornell.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481423515555, "id": "ICLR.cc/2017/conference/-/paper577/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper577/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper577/AnonReviewer3", "ICLR.cc/2017/conference/paper577/AnonReviewer1"], "reply": {"forum": "r17RD2oxe", "replyto": "r17RD2oxe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper577/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper577/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481423515555}}}, {"tddate": null, "tmdate": 1480633597659, "tcdate": 1480633597652, "number": 1, "id": "BkLWp70zx", "invitation": "ICLR.cc/2017/conference/-/paper577/pre-review/question", "forum": "r17RD2oxe", "replyto": "r17RD2oxe", "signatures": ["ICLR.cc/2017/conference/paper577/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2017/conference/paper577/AnonReviewer3"], "content": {"title": "Types of hierarchy", "question": "Would you please comment on the similarities and differences between \u201ctree of life,\u201d \u201csemantic hierarchy\u201d and \u201cvisual similarity hierarchy\u201d? It appears that the algorithm is claimed to be learning a \u201ctree of life\u201d but in practice is just building a \u201cvisual hierarchy\u201d evaluated with a \u201csemantic hierarchy\u201d (i.e., WordNet).\n\nWould you please also place this work in the context of computer vision literature on constructing visual hierarchies: for example, (1) the findings of Section 6 of \u201cWhat Does Classifying More Than 10,000 Image Categories Tell Us?\u201d Deng et al. ECCV 2010 about the relationship between classification confusion and the WordNet hierarchy,  as well as works such as (2) Griffin, G., Perona, P.: Learning and using taxonomies for fast visual categorization. In: CVPR 2008, or (3) \u201cConstructing category hierarchies for visual recognition\u201d M Marsza\u0142ek, C Schmid - European Conference on Computer Vision, 2008, etc. "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Deep Neural Networks and the Tree of Life", "abstract": "In Evolutionary Biology, species close in the tree of evolution are identified by similar visual features. In computer vision, deep neural networks perform image classification by learning to identify similar visual features. This leads to an interesting question: is it possible to leverage the advantage of deep networks to construct a tree of life? In this paper, we make the first attempt at building the phylogenetic tree diagram by leveraging the high-level features learned by deep neural networks. Our method is based on the intuition that if two species share similar features, then their cross activations in the softmax layer should be high. Based on the deep representation of convolutional neural networks trained for image classification, we build a tree of life for species in the image categories of ImageNet. Further, for species not in the ImageNet categories that are visually similar to some category, the cosine similarity of their activation vectors in the same layer should be high. By applying the inner product similarity of the activation vectors at the last fully connected layer for different species, we can roughly build their tree of life. Our work provides a new perspective to the deep representation and sheds light on possible novel applications of deep representation to other areas like Bioinformatics.\n", "pdf": "/pdf/2a7c18802f86269398c44a4638552d8895a44611.pdf", "TL;DR": "Provideing a potential solution to the important problem of constructing a biology evolutionary tree; Giving insight into the representations produced by deep neural networks", "paperhash": "wang|deep_neural_networks_and_the_tree_of_life", "authors": ["Yan Wang", "Kun He", "John E. Hopcroft", "Yu Sun"], "keywords": ["Deep learning", "Computer vision", "Applications"], "conflicts": ["cs.cornell.edu", "hust.edu.cn"], "authorids": ["yanwang@hust.edu.cn", "brooklet60@hust.edu.cn", "jeh@cs.cornell.edu", "ys646@cornell.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1480741199000, "tmdate": 1481423515555, "id": "ICLR.cc/2017/conference/-/paper577/pre-review/question", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2017/conference/paper577/reviewers"], "noninvitees": ["ICLR.cc/2017/conference/paper577/AnonReviewer3", "ICLR.cc/2017/conference/paper577/AnonReviewer1"], "reply": {"forum": "r17RD2oxe", "replyto": "r17RD2oxe", "writers": {"values-regex": "ICLR.cc/2017/conference/paper577/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2017/conference/paper577/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"order": 1, "description": "Brief summary of your question.", "value-regex": ".{1,500}"}, "question": {"order": 2, "description": "Your question", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "expdate": 1488517199000, "cdate": 1481423515555}}}, {"tddate": null, "replyto": null, "ddate": null, "tmdate": 1478516512302, "tcdate": 1478375371321, "number": 577, "id": "r17RD2oxe", "invitation": "ICLR.cc/2017/conference/-/submission", "forum": "r17RD2oxe", "signatures": ["~Kun_He1"], "readers": ["everyone"], "content": {"title": "Deep Neural Networks and the Tree of Life", "abstract": "In Evolutionary Biology, species close in the tree of evolution are identified by similar visual features. In computer vision, deep neural networks perform image classification by learning to identify similar visual features. This leads to an interesting question: is it possible to leverage the advantage of deep networks to construct a tree of life? In this paper, we make the first attempt at building the phylogenetic tree diagram by leveraging the high-level features learned by deep neural networks. Our method is based on the intuition that if two species share similar features, then their cross activations in the softmax layer should be high. Based on the deep representation of convolutional neural networks trained for image classification, we build a tree of life for species in the image categories of ImageNet. Further, for species not in the ImageNet categories that are visually similar to some category, the cosine similarity of their activation vectors in the same layer should be high. By applying the inner product similarity of the activation vectors at the last fully connected layer for different species, we can roughly build their tree of life. Our work provides a new perspective to the deep representation and sheds light on possible novel applications of deep representation to other areas like Bioinformatics.\n", "pdf": "/pdf/2a7c18802f86269398c44a4638552d8895a44611.pdf", "TL;DR": "Provideing a potential solution to the important problem of constructing a biology evolutionary tree; Giving insight into the representations produced by deep neural networks", "paperhash": "wang|deep_neural_networks_and_the_tree_of_life", "authors": ["Yan Wang", "Kun He", "John E. Hopcroft", "Yu Sun"], "keywords": ["Deep learning", "Computer vision", "Applications"], "conflicts": ["cs.cornell.edu", "hust.edu.cn"], "authorids": ["yanwang@hust.edu.cn", "brooklet60@hust.edu.cn", "jeh@cs.cornell.edu", "ys646@cornell.edu"]}, "writers": [], "nonreaders": [], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "duedate": 1475686800000, "tmdate": 1478287705855, "id": "ICLR.cc/2017/conference/-/submission", "writers": ["ICLR.cc/2017/conference"], "signatures": ["ICLR.cc/2017/pcs"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": ["Theory", "Computer vision", "Speech", "Natural language processing", "Deep learning", "Unsupervised Learning", "Supervised Learning", "Semi-Supervised Learning", "Reinforcement Learning", "Transfer Learning", "Multi-modal learning", "Applications", "Optimization", "Structured prediction", "Games"]}, "TL;DR": {"required": false, "order": 3, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,250}"}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1483462800000, "cdate": 1478287705855}}}], "count": 10}