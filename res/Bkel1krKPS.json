{"notes": [{"id": "Bkel1krKPS", "original": "B1ehjoqdwB", "number": 1456, "cdate": 1569439448510, "ddate": null, "tcdate": 1569439448510, "tmdate": 1577168227774, "tddate": null, "forum": "Bkel1krKPS", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["l.hahne@stud.uni-goettingen.de", "timo.lueddecke@phys.uni-goettingen.de", "worgott@gwdg.de", "david.kappel@phys.uni-goettingen.de"], "title": "Attention on Abstract Visual Reasoning", "authors": ["Lukas Hahne", "Timo L\u00fcddecke", "Florentin W\u00f6rg\u00f6tter", "David Kappel"], "pdf": "/pdf/0829320eaecb985379f33f6975ab658e5d090ae7.pdf", "TL;DR": "Introducing Attention Relation Network (ARNe) that combines features from WReN and Transformer Networks.", "abstract": "Attention mechanisms have been boosting the performance of deep learning models on a wide range of applications, ranging from speech understanding to program induction.  However, despite experiments from psychology which suggest that attention plays an essential role in visual reasoning, the full potential of attention mechanisms has so far not been explored to solve abstract cognitive tasks on image data. In this work, we propose a hybrid network architecture, grounded on self-attention and relational reasoning. We call this new model Attention Relation Network (ARNe). ARNe combines features from the recently introduced Transformer and the Wild Relation Network (WReN). We test ARNe on the Procedurally Generated Matrices (PGMs) datasets for abstract visual reasoning. ARNe excels the WReN model on this task by 11.28 ppt. Relational concepts between objects are efficiently learned demanding only 35% of the training samples to surpass reported accuracy of the base line model. Our proposed hybrid model, represents an alternative on learning abstract relations using self-attention and demonstrates that the Transformer network is also well suited for abstract visual reasoning.", "code": "https://drive.google.com/file/d/19fNqoqULy1rPOf38YQ2OsOFkDlzhec-i/view?usp=sharing", "keywords": ["Transformer Networks", "Self-Attention", "Wild Relation Networks", "Procedurally Generated Matrices"], "paperhash": "hahne|attention_on_abstract_visual_reasoning", "original_pdf": "/attachment/99788644d900212babae315dccf35c4242c75115.pdf", "_bibtex": "@misc{\nhahne2020attention,\ntitle={Attention on Abstract Visual Reasoning},\nauthor={Lukas Hahne and Timo L{\\\"u}ddecke and Florentin W{\\\"o}rg{\\\"o}tter and David Kappel},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkel1krKPS}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "ZQkRCxJ3HQ", "original": null, "number": 1, "cdate": 1576798723763, "ddate": null, "tcdate": 1576798723763, "tmdate": 1576800912762, "tddate": null, "forum": "Bkel1krKPS", "replyto": "Bkel1krKPS", "invitation": "ICLR.cc/2020/Conference/Paper1456/-/Decision", "content": {"decision": "Reject", "comment": "This work proposes a new architecture for abstract visual reasoning called \"Attention Relation Network\" (ARNe), based on Transformer-style soft attention and relation networks, which the authors show to improve on the \"Wild Relation Network\" (WReN). The authors test their network on the PGM dataset, and demonstrate a non-trivial improvement over previously reported baselines. \n\nThe paper is well written and makes an interesting contribution, but the reviewers expressed some criticisms, including technical novelty, unfinished experiments (and lack of experimental details), and somewhat weak experimental results, which suggest that the proposed ARNe model does not work well when training with weaker supervision without meta-targets. Even though the authors addressed some concerns in their revised version (namely, they added new experiments in the extrapolation split of PGM and experiments on the new RAVEN dataset), I feel the paper is not yet ready for publication at ICLR. \n", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["l.hahne@stud.uni-goettingen.de", "timo.lueddecke@phys.uni-goettingen.de", "worgott@gwdg.de", "david.kappel@phys.uni-goettingen.de"], "title": "Attention on Abstract Visual Reasoning", "authors": ["Lukas Hahne", "Timo L\u00fcddecke", "Florentin W\u00f6rg\u00f6tter", "David Kappel"], "pdf": "/pdf/0829320eaecb985379f33f6975ab658e5d090ae7.pdf", "TL;DR": "Introducing Attention Relation Network (ARNe) that combines features from WReN and Transformer Networks.", "abstract": "Attention mechanisms have been boosting the performance of deep learning models on a wide range of applications, ranging from speech understanding to program induction.  However, despite experiments from psychology which suggest that attention plays an essential role in visual reasoning, the full potential of attention mechanisms has so far not been explored to solve abstract cognitive tasks on image data. In this work, we propose a hybrid network architecture, grounded on self-attention and relational reasoning. We call this new model Attention Relation Network (ARNe). ARNe combines features from the recently introduced Transformer and the Wild Relation Network (WReN). We test ARNe on the Procedurally Generated Matrices (PGMs) datasets for abstract visual reasoning. ARNe excels the WReN model on this task by 11.28 ppt. Relational concepts between objects are efficiently learned demanding only 35% of the training samples to surpass reported accuracy of the base line model. Our proposed hybrid model, represents an alternative on learning abstract relations using self-attention and demonstrates that the Transformer network is also well suited for abstract visual reasoning.", "code": "https://drive.google.com/file/d/19fNqoqULy1rPOf38YQ2OsOFkDlzhec-i/view?usp=sharing", "keywords": ["Transformer Networks", "Self-Attention", "Wild Relation Networks", "Procedurally Generated Matrices"], "paperhash": "hahne|attention_on_abstract_visual_reasoning", "original_pdf": "/attachment/99788644d900212babae315dccf35c4242c75115.pdf", "_bibtex": "@misc{\nhahne2020attention,\ntitle={Attention on Abstract Visual Reasoning},\nauthor={Lukas Hahne and Timo L{\\\"u}ddecke and Florentin W{\\\"o}rg{\\\"o}tter and David Kappel},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkel1krKPS}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "Bkel1krKPS", "replyto": "Bkel1krKPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795705369, "tmdate": 1576800253132, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1456/-/Decision"}}}, {"id": "BklsYnBhoB", "original": null, "number": 2, "cdate": 1573833859021, "ddate": null, "tcdate": 1573833859021, "tmdate": 1573833859021, "tddate": null, "forum": "Bkel1krKPS", "replyto": "Bkel1krKPS", "invitation": "ICLR.cc/2020/Conference/Paper1456/-/Official_Comment", "content": {"title": "Reply to Reviewers", "comment": "We thank the reviewers for their comments and suggestions. Based on the reviews, we made the following changes to the paper:\n- We added an evaluation of the model's performance on the extrapolation split.\n- We conducted experiments on the new RAVEN dataset and report the results\n\nResponse to the key criticism:\n- Of course, the dependency of the ARNe model on labeled data is a limitation. However, this requirement only affects training. At test time, the model does not need auxiliary labels. \n- The neutral split of the PGM dataset was used by [1] to compare with other models. Therefore the argument that the neutral split was not intended to be an interesting challenge seems misplaced. Nonetheless, the performance on other splits is interesting. Hence, we added results on the extrapolation split (more splits were not possible in this rebuttal period due to time constraints).\n- We agree that additional datasets could strengthen the paper. A small experiment on RAVEN was added.\n\n[1] Santoro et al., 2018: Measuring abstract reasoning in neural networks"}, "signatures": ["ICLR.cc/2020/Conference/Paper1456/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1456/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["l.hahne@stud.uni-goettingen.de", "timo.lueddecke@phys.uni-goettingen.de", "worgott@gwdg.de", "david.kappel@phys.uni-goettingen.de"], "title": "Attention on Abstract Visual Reasoning", "authors": ["Lukas Hahne", "Timo L\u00fcddecke", "Florentin W\u00f6rg\u00f6tter", "David Kappel"], "pdf": "/pdf/0829320eaecb985379f33f6975ab658e5d090ae7.pdf", "TL;DR": "Introducing Attention Relation Network (ARNe) that combines features from WReN and Transformer Networks.", "abstract": "Attention mechanisms have been boosting the performance of deep learning models on a wide range of applications, ranging from speech understanding to program induction.  However, despite experiments from psychology which suggest that attention plays an essential role in visual reasoning, the full potential of attention mechanisms has so far not been explored to solve abstract cognitive tasks on image data. In this work, we propose a hybrid network architecture, grounded on self-attention and relational reasoning. We call this new model Attention Relation Network (ARNe). ARNe combines features from the recently introduced Transformer and the Wild Relation Network (WReN). We test ARNe on the Procedurally Generated Matrices (PGMs) datasets for abstract visual reasoning. ARNe excels the WReN model on this task by 11.28 ppt. Relational concepts between objects are efficiently learned demanding only 35% of the training samples to surpass reported accuracy of the base line model. Our proposed hybrid model, represents an alternative on learning abstract relations using self-attention and demonstrates that the Transformer network is also well suited for abstract visual reasoning.", "code": "https://drive.google.com/file/d/19fNqoqULy1rPOf38YQ2OsOFkDlzhec-i/view?usp=sharing", "keywords": ["Transformer Networks", "Self-Attention", "Wild Relation Networks", "Procedurally Generated Matrices"], "paperhash": "hahne|attention_on_abstract_visual_reasoning", "original_pdf": "/attachment/99788644d900212babae315dccf35c4242c75115.pdf", "_bibtex": "@misc{\nhahne2020attention,\ntitle={Attention on Abstract Visual Reasoning},\nauthor={Lukas Hahne and Timo L{\\\"u}ddecke and Florentin W{\\\"o}rg{\\\"o}tter and David Kappel},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkel1krKPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Bkel1krKPS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1456/Authors", "ICLR.cc/2020/Conference/Paper1456/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1456/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1456/Reviewers", "ICLR.cc/2020/Conference/Paper1456/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1456/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1456/Authors|ICLR.cc/2020/Conference/Paper1456/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504155744, "tmdate": 1576860556154, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1456/Authors", "ICLR.cc/2020/Conference/Paper1456/Reviewers", "ICLR.cc/2020/Conference/Paper1456/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1456/-/Official_Comment"}}}, {"id": "HkgWMFWhKr", "original": null, "number": 1, "cdate": 1571719433393, "ddate": null, "tcdate": 1571719433393, "tmdate": 1572972466553, "tddate": null, "forum": "Bkel1krKPS", "replyto": "Bkel1krKPS", "invitation": "ICLR.cc/2020/Conference/Paper1456/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #2", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This work introduced an attention-based model to solve the RPM cognitive tasks. The model is based on the transformer network, which performs relational reasoning through its self-attention mechanisms.\n\nTechnical novelty:\nThe method seems to be a straightforward application of the transformer network to the PGM task. The technical novelty of the proposed approach is unclear. I\u2019d love to hear what the authors have to say about the technical contributions of the proposed ARNe model in comparison to prior work.\n\nSupervision with meta-targets:\nIt also seems that the meta-targets are crucial for attaining a good performance with the ARNe model. According to Table 4, the model without meta-target training (beta=0) only achieved 12% accuracy in train/val/test sets. However, prior work [Santoro* et al. 2018] has demonstrated that even without training on meta-targets, WReN still achieves a performance of over 60% accuracy (Table 1). This result suggests that the proposed ARNe model does not work well when training with weaker supervision without meta-targets. The results could be a lot stronger if the authors show ARNe outperforms the prior work when beta is set to 0.\n\nAblation studies:\nThis model is only tested in the neutral PGM dataset. The evaluation would be strengthed with the generalization results of this model in different generalization regimes (see Table 1, Santoro* et al. 2018) and comparing its performance with prior works."}, "signatures": ["ICLR.cc/2020/Conference/Paper1456/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1456/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["l.hahne@stud.uni-goettingen.de", "timo.lueddecke@phys.uni-goettingen.de", "worgott@gwdg.de", "david.kappel@phys.uni-goettingen.de"], "title": "Attention on Abstract Visual Reasoning", "authors": ["Lukas Hahne", "Timo L\u00fcddecke", "Florentin W\u00f6rg\u00f6tter", "David Kappel"], "pdf": "/pdf/0829320eaecb985379f33f6975ab658e5d090ae7.pdf", "TL;DR": "Introducing Attention Relation Network (ARNe) that combines features from WReN and Transformer Networks.", "abstract": "Attention mechanisms have been boosting the performance of deep learning models on a wide range of applications, ranging from speech understanding to program induction.  However, despite experiments from psychology which suggest that attention plays an essential role in visual reasoning, the full potential of attention mechanisms has so far not been explored to solve abstract cognitive tasks on image data. In this work, we propose a hybrid network architecture, grounded on self-attention and relational reasoning. We call this new model Attention Relation Network (ARNe). ARNe combines features from the recently introduced Transformer and the Wild Relation Network (WReN). We test ARNe on the Procedurally Generated Matrices (PGMs) datasets for abstract visual reasoning. ARNe excels the WReN model on this task by 11.28 ppt. Relational concepts between objects are efficiently learned demanding only 35% of the training samples to surpass reported accuracy of the base line model. Our proposed hybrid model, represents an alternative on learning abstract relations using self-attention and demonstrates that the Transformer network is also well suited for abstract visual reasoning.", "code": "https://drive.google.com/file/d/19fNqoqULy1rPOf38YQ2OsOFkDlzhec-i/view?usp=sharing", "keywords": ["Transformer Networks", "Self-Attention", "Wild Relation Networks", "Procedurally Generated Matrices"], "paperhash": "hahne|attention_on_abstract_visual_reasoning", "original_pdf": "/attachment/99788644d900212babae315dccf35c4242c75115.pdf", "_bibtex": "@misc{\nhahne2020attention,\ntitle={Attention on Abstract Visual Reasoning},\nauthor={Lukas Hahne and Timo L{\\\"u}ddecke and Florentin W{\\\"o}rg{\\\"o}tter and David Kappel},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkel1krKPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Bkel1krKPS", "replyto": "Bkel1krKPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1456/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1456/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574722376000, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1456/Reviewers"], "noninvitees": [], "tcdate": 1570237737129, "tmdate": 1574723080166, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1456/-/Official_Review"}}}, {"id": "SJlIFDe6KH", "original": null, "number": 2, "cdate": 1571780477950, "ddate": null, "tcdate": 1571780477950, "tmdate": 1572972466519, "tddate": null, "forum": "Bkel1krKPS", "replyto": "Bkel1krKPS", "invitation": "ICLR.cc/2020/Conference/Paper1456/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "This paper describes a somewhat novel approach to abstract visual reasoning using transformers in the so-called \"Attention Relation Network\" (ARNe), which the authors show to improve on the \"Wild Relation Network\" (WReN). The Transformer is motivated by the role that attention may play in Human information processing - which sounds plausible, but the paper does not expand on this theme.\n\nThe paper is well written and makes an interesting contribution, but I feel the results are not quite yet ready for publication. The authors are writing that they are still working on baseline results on the full dataset, which would provide interesting comparisons, and some details on the implementation (number of parameters, etc) are missing - or maybe I missed them.\n\nThe learning curve in Figure 3 (sample efficiency, test accuracy) suggests that the ARNe training is not fully stable - why would the model deteriorate when going from ~40% of the training data to ~60%? Is the model potentially overfitting, and how does the size of the proposed model compare to the size of the baseline model(s)? It seems that the field is also moving towards the RAVEN dataset, which presents a more complex structure; it would be more convincing to present results on both datasets, to show that attention can indeed also improve results on more complex setups.\n\nThe text in the \"Acknowledgments\" section should be removed for the camera ready version!\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1456/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1456/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["l.hahne@stud.uni-goettingen.de", "timo.lueddecke@phys.uni-goettingen.de", "worgott@gwdg.de", "david.kappel@phys.uni-goettingen.de"], "title": "Attention on Abstract Visual Reasoning", "authors": ["Lukas Hahne", "Timo L\u00fcddecke", "Florentin W\u00f6rg\u00f6tter", "David Kappel"], "pdf": "/pdf/0829320eaecb985379f33f6975ab658e5d090ae7.pdf", "TL;DR": "Introducing Attention Relation Network (ARNe) that combines features from WReN and Transformer Networks.", "abstract": "Attention mechanisms have been boosting the performance of deep learning models on a wide range of applications, ranging from speech understanding to program induction.  However, despite experiments from psychology which suggest that attention plays an essential role in visual reasoning, the full potential of attention mechanisms has so far not been explored to solve abstract cognitive tasks on image data. In this work, we propose a hybrid network architecture, grounded on self-attention and relational reasoning. We call this new model Attention Relation Network (ARNe). ARNe combines features from the recently introduced Transformer and the Wild Relation Network (WReN). We test ARNe on the Procedurally Generated Matrices (PGMs) datasets for abstract visual reasoning. ARNe excels the WReN model on this task by 11.28 ppt. Relational concepts between objects are efficiently learned demanding only 35% of the training samples to surpass reported accuracy of the base line model. Our proposed hybrid model, represents an alternative on learning abstract relations using self-attention and demonstrates that the Transformer network is also well suited for abstract visual reasoning.", "code": "https://drive.google.com/file/d/19fNqoqULy1rPOf38YQ2OsOFkDlzhec-i/view?usp=sharing", "keywords": ["Transformer Networks", "Self-Attention", "Wild Relation Networks", "Procedurally Generated Matrices"], "paperhash": "hahne|attention_on_abstract_visual_reasoning", "original_pdf": "/attachment/99788644d900212babae315dccf35c4242c75115.pdf", "_bibtex": "@misc{\nhahne2020attention,\ntitle={Attention on Abstract Visual Reasoning},\nauthor={Lukas Hahne and Timo L{\\\"u}ddecke and Florentin W{\\\"o}rg{\\\"o}tter and David Kappel},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkel1krKPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Bkel1krKPS", "replyto": "Bkel1krKPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1456/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1456/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574722376000, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1456/Reviewers"], "noninvitees": [], "tcdate": 1570237737129, "tmdate": 1574723080166, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1456/-/Official_Review"}}}, {"id": "BygwFWrJcr", "original": null, "number": 3, "cdate": 1571930494565, "ddate": null, "tcdate": 1571930494565, "tmdate": 1572972466476, "tddate": null, "forum": "Bkel1krKPS", "replyto": "Bkel1krKPS", "invitation": "ICLR.cc/2020/Conference/Paper1456/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "title": "Official Blind Review #1", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A", "review": "This work proposes a new architecture for abstract visual reasoning, based on Transformer-style soft attention and relation networks. The authors test their network on the PGM dataset, and demonstrate a non-trivial improvement over previously reported baselines. \n\nIn general, abstract reasoning is an important field of current study in neural network-based machine learning, as it is an area that has notoriously eluded these types of models historically. The paper is reasonably well put together, and I have no reason to question the various technical aspects of the work.\n\nUnfortunately, I think there are significant shortcomings. Firstly, the PGM dataset was designed to stress out-of-distribution generalization, and performance on the Neutral split was not proposed as a particularly interesting challenge on its own. This is because, as the name implies, abstract reasoning requires the ability to identify abstract conceptual features of the data and compose them in novel ways at test time, which is *not* a feature of the neutral split.  The authors are encouraged to run their model on these other generalization splits. \n\nSecond, there seems to be little value to the field overall for research involving minor architectural improvements for single datasets. If the authors believe in this method, they are encouraged to demonstrate its effectiveness on a wide variety of data types. On this note, I should add that the authors are incorrect to state that this is the first work to use self-attention for abstract reasoning (please see Zambaldi, 2018 for one example of many papers that have incorporated self-attention into convolutional architectures). \n\nSo to sum up, while this work broaches an interesting subject and is technically fine, it does not surpass the threshold for acceptance because it fails to demonstrate the usefulness of the method on the task at hand, as well as broad utility of the proposed method.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1456/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1456/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["l.hahne@stud.uni-goettingen.de", "timo.lueddecke@phys.uni-goettingen.de", "worgott@gwdg.de", "david.kappel@phys.uni-goettingen.de"], "title": "Attention on Abstract Visual Reasoning", "authors": ["Lukas Hahne", "Timo L\u00fcddecke", "Florentin W\u00f6rg\u00f6tter", "David Kappel"], "pdf": "/pdf/0829320eaecb985379f33f6975ab658e5d090ae7.pdf", "TL;DR": "Introducing Attention Relation Network (ARNe) that combines features from WReN and Transformer Networks.", "abstract": "Attention mechanisms have been boosting the performance of deep learning models on a wide range of applications, ranging from speech understanding to program induction.  However, despite experiments from psychology which suggest that attention plays an essential role in visual reasoning, the full potential of attention mechanisms has so far not been explored to solve abstract cognitive tasks on image data. In this work, we propose a hybrid network architecture, grounded on self-attention and relational reasoning. We call this new model Attention Relation Network (ARNe). ARNe combines features from the recently introduced Transformer and the Wild Relation Network (WReN). We test ARNe on the Procedurally Generated Matrices (PGMs) datasets for abstract visual reasoning. ARNe excels the WReN model on this task by 11.28 ppt. Relational concepts between objects are efficiently learned demanding only 35% of the training samples to surpass reported accuracy of the base line model. Our proposed hybrid model, represents an alternative on learning abstract relations using self-attention and demonstrates that the Transformer network is also well suited for abstract visual reasoning.", "code": "https://drive.google.com/file/d/19fNqoqULy1rPOf38YQ2OsOFkDlzhec-i/view?usp=sharing", "keywords": ["Transformer Networks", "Self-Attention", "Wild Relation Networks", "Procedurally Generated Matrices"], "paperhash": "hahne|attention_on_abstract_visual_reasoning", "original_pdf": "/attachment/99788644d900212babae315dccf35c4242c75115.pdf", "_bibtex": "@misc{\nhahne2020attention,\ntitle={Attention on Abstract Visual Reasoning},\nauthor={Lukas Hahne and Timo L{\\\"u}ddecke and Florentin W{\\\"o}rg{\\\"o}tter and David Kappel},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkel1krKPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "Bkel1krKPS", "replyto": "Bkel1krKPS", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1456/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1456/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1574722376000, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1456/Reviewers"], "noninvitees": [], "tcdate": 1570237737129, "tmdate": 1574723080166, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1456/-/Official_Review"}}}, {"id": "SyeRK47CFr", "original": null, "number": 1, "cdate": 1571857542184, "ddate": null, "tcdate": 1571857542184, "tmdate": 1571857542184, "tddate": null, "forum": "Bkel1krKPS", "replyto": "S1lysesBOH", "invitation": "ICLR.cc/2020/Conference/Paper1456/-/Official_Comment", "content": {"comment": "Thank you for your comment. In the following, we reply to each criticized point.\n\nGeneralization:\nWe agree that this would enable further insights. We have tested it on the provided extrapolation dataset. ARNe achieved a performance of 17.76% which is slightly better than WReN. Unfortunately, we do not have the resources to conduct experiments of other PGM configurations: They would require large store capacities as well as extensive computations.\n\nRAVEN benchmark:\nThank you for pointing out this new benchmark. We evaluated our model on RAVEN and found it achieve a performance of 92.23% for 50k samples for each figure configuration. However, using Raven-10000 the performance is 19.67%.\n\nAblation: We replaced the encoder with a MLP of the same depth. In a second experiment we replaced the multi head attention mechanism with a linear transformation. The performances are 35.06% and 44.56% respectively.\n\nTo further strengthen the experimental validation of our model, we implemented a combination of WReN and MAC called WReN-MAC and found it achieve 79.6 % on PGM.\n\nThe paper will be updated to reflect these additional findings.\n", "title": "Further experiments on PGM and RAVEN"}, "signatures": ["ICLR.cc/2020/Conference/Paper1456/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1456/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["l.hahne@stud.uni-goettingen.de", "timo.lueddecke@phys.uni-goettingen.de", "worgott@gwdg.de", "david.kappel@phys.uni-goettingen.de"], "title": "Attention on Abstract Visual Reasoning", "authors": ["Lukas Hahne", "Timo L\u00fcddecke", "Florentin W\u00f6rg\u00f6tter", "David Kappel"], "pdf": "/pdf/0829320eaecb985379f33f6975ab658e5d090ae7.pdf", "TL;DR": "Introducing Attention Relation Network (ARNe) that combines features from WReN and Transformer Networks.", "abstract": "Attention mechanisms have been boosting the performance of deep learning models on a wide range of applications, ranging from speech understanding to program induction.  However, despite experiments from psychology which suggest that attention plays an essential role in visual reasoning, the full potential of attention mechanisms has so far not been explored to solve abstract cognitive tasks on image data. In this work, we propose a hybrid network architecture, grounded on self-attention and relational reasoning. We call this new model Attention Relation Network (ARNe). ARNe combines features from the recently introduced Transformer and the Wild Relation Network (WReN). We test ARNe on the Procedurally Generated Matrices (PGMs) datasets for abstract visual reasoning. ARNe excels the WReN model on this task by 11.28 ppt. Relational concepts between objects are efficiently learned demanding only 35% of the training samples to surpass reported accuracy of the base line model. Our proposed hybrid model, represents an alternative on learning abstract relations using self-attention and demonstrates that the Transformer network is also well suited for abstract visual reasoning.", "code": "https://drive.google.com/file/d/19fNqoqULy1rPOf38YQ2OsOFkDlzhec-i/view?usp=sharing", "keywords": ["Transformer Networks", "Self-Attention", "Wild Relation Networks", "Procedurally Generated Matrices"], "paperhash": "hahne|attention_on_abstract_visual_reasoning", "original_pdf": "/attachment/99788644d900212babae315dccf35c4242c75115.pdf", "_bibtex": "@misc{\nhahne2020attention,\ntitle={Attention on Abstract Visual Reasoning},\nauthor={Lukas Hahne and Timo L{\\\"u}ddecke and Florentin W{\\\"o}rg{\\\"o}tter and David Kappel},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkel1krKPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Bkel1krKPS", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1456/Authors", "ICLR.cc/2020/Conference/Paper1456/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1456/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1456/Reviewers", "ICLR.cc/2020/Conference/Paper1456/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1456/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1456/Authors|ICLR.cc/2020/Conference/Paper1456/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504155744, "tmdate": 1576860556154, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1456/Authors", "ICLR.cc/2020/Conference/Paper1456/Reviewers", "ICLR.cc/2020/Conference/Paper1456/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1456/-/Official_Comment"}}}, {"id": "S1lysesBOH", "original": null, "number": 1, "cdate": 1570250903189, "ddate": null, "tcdate": 1570250903189, "tmdate": 1570250903189, "tddate": null, "forum": "Bkel1krKPS", "replyto": "Bkel1krKPS", "invitation": "ICLR.cc/2020/Conference/Paper1456/-/Public_Comment", "content": {"comment": "The proposed model, which is a transformer-based RPM solver, achieved significantly high accuracy in the neutral setting, where the data distribution of training and test sets are the same.\nI think the idea of adopting the attention mechanism in solving abstract reasoning tasks is good.\n\n\nHowever, the model was not tested on generalization settings such as H.O. Triple Pairs, Interpolation and Extrapolation, where unseen objects and attributes appear during evaluation (Barret et al. 2018).\nSince the PGM dataset was proposed to evaluate the generalization abilities of models, I believe evaluation should have been conducted not only on the neutral setting, but also the generalization settings.\n\nAlso, there is an another benchmark dataset, called RAVEN (Zhang et al. 2019).\nIt would be better if the proposed model was evaluated on both PGM and RAVEN.\n\nLastly, I am concerned that the ablation study in the paper is insufficient.\nIt is questionable whether the high accuracy in the neutral setting is due to the effectiveness of the self-attention mechanism or just the large model size.", "title": "Several concerns about your paper"}, "signatures": ["~Hyunjae_Kim1"], "readers": ["everyone"], "nonreaders": [], "writers": ["~Hyunjae_Kim1", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["l.hahne@stud.uni-goettingen.de", "timo.lueddecke@phys.uni-goettingen.de", "worgott@gwdg.de", "david.kappel@phys.uni-goettingen.de"], "title": "Attention on Abstract Visual Reasoning", "authors": ["Lukas Hahne", "Timo L\u00fcddecke", "Florentin W\u00f6rg\u00f6tter", "David Kappel"], "pdf": "/pdf/0829320eaecb985379f33f6975ab658e5d090ae7.pdf", "TL;DR": "Introducing Attention Relation Network (ARNe) that combines features from WReN and Transformer Networks.", "abstract": "Attention mechanisms have been boosting the performance of deep learning models on a wide range of applications, ranging from speech understanding to program induction.  However, despite experiments from psychology which suggest that attention plays an essential role in visual reasoning, the full potential of attention mechanisms has so far not been explored to solve abstract cognitive tasks on image data. In this work, we propose a hybrid network architecture, grounded on self-attention and relational reasoning. We call this new model Attention Relation Network (ARNe). ARNe combines features from the recently introduced Transformer and the Wild Relation Network (WReN). We test ARNe on the Procedurally Generated Matrices (PGMs) datasets for abstract visual reasoning. ARNe excels the WReN model on this task by 11.28 ppt. Relational concepts between objects are efficiently learned demanding only 35% of the training samples to surpass reported accuracy of the base line model. Our proposed hybrid model, represents an alternative on learning abstract relations using self-attention and demonstrates that the Transformer network is also well suited for abstract visual reasoning.", "code": "https://drive.google.com/file/d/19fNqoqULy1rPOf38YQ2OsOFkDlzhec-i/view?usp=sharing", "keywords": ["Transformer Networks", "Self-Attention", "Wild Relation Networks", "Procedurally Generated Matrices"], "paperhash": "hahne|attention_on_abstract_visual_reasoning", "original_pdf": "/attachment/99788644d900212babae315dccf35c4242c75115.pdf", "_bibtex": "@misc{\nhahne2020attention,\ntitle={Attention on Abstract Visual Reasoning},\nauthor={Lukas Hahne and Timo L{\\\"u}ddecke and Florentin W{\\\"o}rg{\\\"o}tter and David Kappel},\nyear={2020},\nurl={https://openreview.net/forum?id=Bkel1krKPS}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "Bkel1krKPS", "readers": {"values": ["everyone"], "description": "User groups that will be able to read this comment."}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "~.*"}}, "readers": ["everyone"], "tcdate": 1569504194495, "tmdate": 1576860589300, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["everyone"], "noninvitees": ["ICLR.cc/2020/Conference/Paper1456/Authors", "ICLR.cc/2020/Conference/Paper1456/Reviewers", "ICLR.cc/2020/Conference/Paper1456/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1456/-/Public_Comment"}}}], "count": 8}