{"notes": [{"id": "SJlgOjAqYQ", "original": "BJgYzDd5KQ", "number": 321, "cdate": 1538087783690, "ddate": null, "tcdate": 1538087783690, "tmdate": 1545355419481, "tddate": null, "forum": "SJlgOjAqYQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "A quantifiable testing of global translational invariance in Convolutional and Capsule Networks", "abstract": " We design simple and quantifiable testing of global translation-invariance in deep learning models trained on the MNIST dataset. Experiments on convolutional and capsules neural networks show that both models have poor performance in dealing with global translation-invariance; however, the performance improved by using data augmentation. Although the capsule network is better on the MNIST testing dataset, the convolutional neural network generally has better performance on the translation-invariance.", "keywords": ["Translational invariance", "CNN", "Capsule Network"], "authorids": ["wikaiqi@gmail.com"], "authors": ["Weikai Qi"], "TL;DR": "Testing of global translational invariance in Convolutional and Capsule Networks", "pdf": "/pdf/1452b1e4370e690b624a123154fd502b39b9db06.pdf", "paperhash": "qi|a_quantifiable_testing_of_global_translational_invariance_in_convolutional_and_capsule_networks", "_bibtex": "@misc{\nqi2019a,\ntitle={A quantifiable testing of global translational invariance in Convolutional and Capsule Networks},\nauthor={Weikai Qi},\nyear={2019},\nurl={https://openreview.net/forum?id=SJlgOjAqYQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "r1eVXWd4JN", "original": null, "number": 1, "cdate": 1543958812197, "ddate": null, "tcdate": 1543958812197, "tmdate": 1545354495684, "tddate": null, "forum": "SJlgOjAqYQ", "replyto": "SJlgOjAqYQ", "invitation": "ICLR.cc/2019/Conference/-/Paper321/Meta_Review", "content": {"metareview": "The paper presents an empirical comparison of translation invariance property in CNN and capsule networks. As the reviewers point out, the paper is not acceptable quality at ICLR due to low novelty and significance. ", "confidence": "5: The area chair is absolutely certain", "recommendation": "Reject", "title": "decision"}, "signatures": ["ICLR.cc/2019/Conference/Paper321/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper321/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A quantifiable testing of global translational invariance in Convolutional and Capsule Networks", "abstract": " We design simple and quantifiable testing of global translation-invariance in deep learning models trained on the MNIST dataset. Experiments on convolutional and capsules neural networks show that both models have poor performance in dealing with global translation-invariance; however, the performance improved by using data augmentation. Although the capsule network is better on the MNIST testing dataset, the convolutional neural network generally has better performance on the translation-invariance.", "keywords": ["Translational invariance", "CNN", "Capsule Network"], "authorids": ["wikaiqi@gmail.com"], "authors": ["Weikai Qi"], "TL;DR": "Testing of global translational invariance in Convolutional and Capsule Networks", "pdf": "/pdf/1452b1e4370e690b624a123154fd502b39b9db06.pdf", "paperhash": "qi|a_quantifiable_testing_of_global_translational_invariance_in_convolutional_and_capsule_networks", "_bibtex": "@misc{\nqi2019a,\ntitle={A quantifiable testing of global translational invariance in Convolutional and Capsule Networks},\nauthor={Weikai Qi},\nyear={2019},\nurl={https://openreview.net/forum?id=SJlgOjAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper321/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353255754, "tddate": null, "super": null, "final": null, "reply": {"forum": "SJlgOjAqYQ", "replyto": "SJlgOjAqYQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper321/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper321/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper321/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353255754}}}, {"id": "SJeSpVJt3Q", "original": null, "number": 3, "cdate": 1541104829352, "ddate": null, "tcdate": 1541104829352, "tmdate": 1542901307964, "tddate": null, "forum": "SJlgOjAqYQ", "replyto": "SJlgOjAqYQ", "invitation": "ICLR.cc/2019/Conference/-/Paper321/Official_Review", "content": {"title": "No technical novelty or implementation described", "review": "Authors present a study to compare global translation invariance capabilities of CNNs and CapsuleNets.\nThe paper doesn't introduce any novel concept or technique but it simply compares two established techniques on MNIST dataset. The interest on this paper is rather limited. Besides many technical concepts are not really accurate on how they are presented. It needs further attention and improvements.\nThe paper reads more like a review papers than a new research article. I remain to my initial decision.\n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper321/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "A quantifiable testing of global translational invariance in Convolutional and Capsule Networks", "abstract": " We design simple and quantifiable testing of global translation-invariance in deep learning models trained on the MNIST dataset. Experiments on convolutional and capsules neural networks show that both models have poor performance in dealing with global translation-invariance; however, the performance improved by using data augmentation. Although the capsule network is better on the MNIST testing dataset, the convolutional neural network generally has better performance on the translation-invariance.", "keywords": ["Translational invariance", "CNN", "Capsule Network"], "authorids": ["wikaiqi@gmail.com"], "authors": ["Weikai Qi"], "TL;DR": "Testing of global translational invariance in Convolutional and Capsule Networks", "pdf": "/pdf/1452b1e4370e690b624a123154fd502b39b9db06.pdf", "paperhash": "qi|a_quantifiable_testing_of_global_translational_invariance_in_convolutional_and_capsule_networks", "_bibtex": "@misc{\nqi2019a,\ntitle={A quantifiable testing of global translational invariance in Convolutional and Capsule Networks},\nauthor={Weikai Qi},\nyear={2019},\nurl={https://openreview.net/forum?id=SJlgOjAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper321/Official_Review", "cdate": 1542234488040, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJlgOjAqYQ", "replyto": "SJlgOjAqYQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper321/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335698108, "tmdate": 1552335698108, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper321/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SJl-99jQ2Q", "original": null, "number": 2, "cdate": 1540762248560, "ddate": null, "tcdate": 1540762248560, "tmdate": 1541534094782, "tddate": null, "forum": "SJlgOjAqYQ", "replyto": "SJlgOjAqYQ", "invitation": "ICLR.cc/2019/Conference/-/Paper321/Official_Review", "content": {"title": "Clever idea with some weaknesses...", "review": "Thanks for the submission of you work. As far as I understood it correctly you deal with the idea to test the shift invariance of a given model on Helvetica digits. You propose that idea as general quantifiable approach.\n\nIn general, your paper is well-written, compact, in a good style and with a length of 5 pages really short.\n\nIn the introduction, you cite the work of Hinton and Sabour and describe the Capsule framework in general. I think that this description is not really precise. The aforementioned contributions are really different and your general explanation is technically incorrect.\n\nThe major concerns about your contributions are:\n1. Helvetica digits are not in American digit style, e.g. check the digit one. The MNIST database consists of American handwritten digits. Why you\u2019re not using an American digit font? What is the impact on your model due to that change?\n2. Fig. 1 in your contribution: It seems that your digits are too small compared to MNIST digits. Is that true? Note that MNIST digits are size normalized.\n3. What is the outstanding advantage of your proposal compared to a simple shift of a MNIST digit or the usage of the affNIST dataset?\n4. Page 4: You are mentioning that it is interesting that the reconstructed image looks like a handwritten digit. Why you think it is interesting? I would assume that this is a natural behavior since your network was trained to do so.\n\nPlease clarify the questions above and highlight what is the advantage of your method compared to simple shifts of MNIST digits or even the usage of affNIST. Right now, I\u2019m not seeing a real advantage neither a scientific contribution.  \n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper321/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A quantifiable testing of global translational invariance in Convolutional and Capsule Networks", "abstract": " We design simple and quantifiable testing of global translation-invariance in deep learning models trained on the MNIST dataset. Experiments on convolutional and capsules neural networks show that both models have poor performance in dealing with global translation-invariance; however, the performance improved by using data augmentation. Although the capsule network is better on the MNIST testing dataset, the convolutional neural network generally has better performance on the translation-invariance.", "keywords": ["Translational invariance", "CNN", "Capsule Network"], "authorids": ["wikaiqi@gmail.com"], "authors": ["Weikai Qi"], "TL;DR": "Testing of global translational invariance in Convolutional and Capsule Networks", "pdf": "/pdf/1452b1e4370e690b624a123154fd502b39b9db06.pdf", "paperhash": "qi|a_quantifiable_testing_of_global_translational_invariance_in_convolutional_and_capsule_networks", "_bibtex": "@misc{\nqi2019a,\ntitle={A quantifiable testing of global translational invariance in Convolutional and Capsule Networks},\nauthor={Weikai Qi},\nyear={2019},\nurl={https://openreview.net/forum?id=SJlgOjAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper321/Official_Review", "cdate": 1542234488040, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJlgOjAqYQ", "replyto": "SJlgOjAqYQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper321/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335698108, "tmdate": 1552335698108, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper321/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "ryxaa-_1hX", "original": null, "number": 1, "cdate": 1540485572611, "ddate": null, "tcdate": 1540485572611, "tmdate": 1541534094570, "tddate": null, "forum": "SJlgOjAqYQ", "replyto": "SJlgOjAqYQ", "invitation": "ICLR.cc/2019/Conference/-/Paper321/Official_Review", "content": {"title": "A simple test of CNN and CapsNet's performance on translation", "review": "The authors of this paper compare the robustness of CNN and CapsNet to global translation on the MNIST dataset. Both models were trained on the standard training set of MNIST, and then tested on a set with digits shifting from the upper left corner to the lower right corner. The results of both models were poor. To improve it, the authors add some shifted digits to the training set, and the performances of both models were significantly enhanced. Moreover, the performance of CNN was better than that of CapsNet in the experiments. Generally speaking, the work presented in this paper is clear and straightforward. However, the work is not significant enough to publish as a ICLR paper. Below is my major comments.\n\n1. There are lots of typos and grammatical errors everywhere in the paper. Thus, the manuscript was not well prepared.\n\n2. It is unclear which CapsNet and what settings were used in the experiment.  \n\n3. It is well-known that convolutional networks are good at capturing local patterns from the images, while capsule networks enhance it to consider global configurations of the local patterns, and robust to affine transformation. Obviously, the experiments presented in this manuscript is too simple. Lots of work should be done in the investigation. For example,o on the training set and shifted test set, the authors can enlarge the background and keep the digits in the original size to make it as a local pattern in the image. Will it be detected by CNNs with larger receptive fields for the images? How is it compared with CapsNets? \n\n4. How are both models compared on other (perhaps more complicated and larger) datasets?\n\nIn summary, the work presented here is interesting, but lots of work should be done in order to make it publishable.\n\n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper321/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "A quantifiable testing of global translational invariance in Convolutional and Capsule Networks", "abstract": " We design simple and quantifiable testing of global translation-invariance in deep learning models trained on the MNIST dataset. Experiments on convolutional and capsules neural networks show that both models have poor performance in dealing with global translation-invariance; however, the performance improved by using data augmentation. Although the capsule network is better on the MNIST testing dataset, the convolutional neural network generally has better performance on the translation-invariance.", "keywords": ["Translational invariance", "CNN", "Capsule Network"], "authorids": ["wikaiqi@gmail.com"], "authors": ["Weikai Qi"], "TL;DR": "Testing of global translational invariance in Convolutional and Capsule Networks", "pdf": "/pdf/1452b1e4370e690b624a123154fd502b39b9db06.pdf", "paperhash": "qi|a_quantifiable_testing_of_global_translational_invariance_in_convolutional_and_capsule_networks", "_bibtex": "@misc{\nqi2019a,\ntitle={A quantifiable testing of global translational invariance in Convolutional and Capsule Networks},\nauthor={Weikai Qi},\nyear={2019},\nurl={https://openreview.net/forum?id=SJlgOjAqYQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper321/Official_Review", "cdate": 1542234488040, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "SJlgOjAqYQ", "replyto": "SJlgOjAqYQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper321/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335698108, "tmdate": 1552335698108, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper321/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 5}