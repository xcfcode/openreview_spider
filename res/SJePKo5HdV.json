{"notes": [{"id": "SJePKo5HdV", "original": "S1x72ItruV", "number": 59, "cdate": 1553472383099, "ddate": null, "tcdate": 1553472383099, "tmdate": 1562082112687, "tddate": null, "forum": "SJePKo5HdV", "replyto": null, "invitation": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "content": {"title": "Learnability for the Information Bottleneck", "authors": ["Tailin Wu", "Ian Fischer", "Isaac Chuang", "Max Tegmark"], "authorids": ["tailin@mit.edu", "iansf@google.com", "ichuang@mit.edu", "tegmark@mit.edu"], "keywords": ["representation learning", "learnability", "information bottleneck"], "TL;DR": "Theory predicts the phase transition between unlearnable and learnable values of beta for the Information Bottleneck objective", "abstract": "Compressed representations generalize better (Shamir et al., 2010), which may be crucial when learning from limited or noisy labeled data. The Information Bottleneck (IB) method (Tishby et al. (2000)) provides an insightful and principled approach for balancing compression and prediction in representation learning. The IB objective I(X; Z) \u2212 \u03b2I(Y ; Z) employs a Lagrange multiplier \u03b2 to tune this trade-off. However, there is little theoretical guidance for how to select \u03b2. There is also a lack of theoretical understanding about the relationship between \u03b2, the dataset, model capacity, and learnability. In this work, we show that if \u03b2 is improperly chosen, learning cannot happen: the trivial representation P(Z|X) = P(Z) becomes the global minimum of the IB objective. We show how this can be avoided, by identifying a sharp phase transition between the unlearnable and the learnable which arises as \u03b2 varies. This phase transition defines the concept of IB-Learnability. We prove several sufficient conditions for IB-Learnability, providing theoretical guidance for selecting \u03b2. We further show that IB-learnability is determined by the largest confident, typical, and imbalanced subset of the training examples. We give a practical algorithm to estimate the minimum \u03b2 for a given dataset. We test our theoretical results on synthetic datasets, MNIST, and CIFAR10 with noisy labels, and make the surprising observation that accuracy may be non-monotonic in \u03b2.", "pdf": "/pdf/1290e4dc7b5d511b8b213f53c54006475d031bfc.pdf", "paperhash": "wu|learnability_for_the_information_bottleneck"}, "signatures": ["ICLR.cc/2019/Workshop/LLD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD"], "details": {"replyCount": 3, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Blind_Submission", "cdate": 1548689671889, "reply": {"forum": null, "replyto": null, "readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD"]}, "content": {"authors": {"values-regex": ".*"}, "authorids": {"values-regex": ".*"}}}, "tcdate": 1548689671889, "tmdate": 1557933709646, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["~"], "signatures": ["ICLR.cc/2019/Workshop/LLD"], "details": {"writable": true}}}, "tauthor": "OpenReview.net"}, {"id": "Hylb4teTYE", "original": null, "number": 1, "cdate": 1555003688568, "ddate": null, "tcdate": 1555003688568, "tmdate": 1555511877585, "tddate": null, "forum": "SJePKo5HdV", "replyto": "SJePKo5HdV", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper59/Official_Review", "content": {"title": "Interesting analysis of learnability in IB with surprising conclusions", "review": "The paper analyses learnability of the IB regulariser. It is well-written and the results are interesting because the non-monotonic behavior is not something one would intuitively assume to appear. I definitely recommend acceptance of the paper, even though it may be slightly out of scope for the workshop due to its lack of experiments on limited data.", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper59/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper59/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learnability for the Information Bottleneck", "authors": ["Tailin Wu", "Ian Fischer", "Isaac Chuang", "Max Tegmark"], "authorids": ["tailin@mit.edu", "iansf@google.com", "ichuang@mit.edu", "tegmark@mit.edu"], "keywords": ["representation learning", "learnability", "information bottleneck"], "TL;DR": "Theory predicts the phase transition between unlearnable and learnable values of beta for the Information Bottleneck objective", "abstract": "Compressed representations generalize better (Shamir et al., 2010), which may be crucial when learning from limited or noisy labeled data. The Information Bottleneck (IB) method (Tishby et al. (2000)) provides an insightful and principled approach for balancing compression and prediction in representation learning. The IB objective I(X; Z) \u2212 \u03b2I(Y ; Z) employs a Lagrange multiplier \u03b2 to tune this trade-off. However, there is little theoretical guidance for how to select \u03b2. There is also a lack of theoretical understanding about the relationship between \u03b2, the dataset, model capacity, and learnability. In this work, we show that if \u03b2 is improperly chosen, learning cannot happen: the trivial representation P(Z|X) = P(Z) becomes the global minimum of the IB objective. We show how this can be avoided, by identifying a sharp phase transition between the unlearnable and the learnable which arises as \u03b2 varies. This phase transition defines the concept of IB-Learnability. We prove several sufficient conditions for IB-Learnability, providing theoretical guidance for selecting \u03b2. We further show that IB-learnability is determined by the largest confident, typical, and imbalanced subset of the training examples. We give a practical algorithm to estimate the minimum \u03b2 for a given dataset. We test our theoretical results on synthetic datasets, MNIST, and CIFAR10 with noisy labels, and make the surprising observation that accuracy may be non-monotonic in \u03b2.", "pdf": "/pdf/1290e4dc7b5d511b8b213f53c54006475d031bfc.pdf", "paperhash": "wu|learnability_for_the_information_bottleneck"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper59/Official_Review", "cdate": 1553713411662, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "SJePKo5HdV", "replyto": "SJePKo5HdV", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper59/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper59/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713411662, "tmdate": 1555511821822, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper59/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "SJxPtBipKE", "original": null, "number": 2, "cdate": 1555047807183, "ddate": null, "tcdate": 1555047807183, "tmdate": 1555511876048, "tddate": null, "forum": "SJePKo5HdV", "replyto": "SJePKo5HdV", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper59/Official_Review", "content": {"title": "Learnability for the Information Bottleneck", "review": "The information-bottleneck (IB) framework of Tishby and coworkers proposes to learn a compression / representation of the data (x, y) which captures as little information as possible about the input x but as much information as possible about the prediction target y. To this end, it proposes to minimize a functional of the form\n\nmin I(X; Z) - beta * I(Y; Z), ... (IB)\n\nw.r.t to the conditional distribution P(z|x). It is known that the choice of the balancing parameter beta > 0 is crucial. In particular, if beta <= 1, then the global optimum of the above problem is an uninformative distribution P(z|x) = P(z), which discards the input x.\n\nThe current paper pushes the analysis further by proposing a new notion of learnability called IB-learnability: a problem is IB learnable at rank beta iff the stationary point* P(z|x) = P(z) is not a global optimum of problem (IB) above. The authors then go on to produce sufficient conditions under which a problem is learnable. Also, efficient heuristics are proposed for computing / checking these sufficient learnability conditions.\n\nThough I didn't check the proofs (> 16 pages), the paper seems well-grounded from a formal perspective. Also, a rich array of experiments on both synthetic and real data (MNIST, CIFAR10, etc.) are presented and discussed.\n\nMy only worry is that the paper might be slightly out of the scope of what the LLD workshop is concerned with. That notwithstanding, I think the paper should be accepted and discussed at the workshop.\n\n*A side result obtained by the paper is that for any beta, P(z|x) = p(z) is a stationary point for problem (IB).", "rating": "4: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Paper59/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Paper59/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learnability for the Information Bottleneck", "authors": ["Tailin Wu", "Ian Fischer", "Isaac Chuang", "Max Tegmark"], "authorids": ["tailin@mit.edu", "iansf@google.com", "ichuang@mit.edu", "tegmark@mit.edu"], "keywords": ["representation learning", "learnability", "information bottleneck"], "TL;DR": "Theory predicts the phase transition between unlearnable and learnable values of beta for the Information Bottleneck objective", "abstract": "Compressed representations generalize better (Shamir et al., 2010), which may be crucial when learning from limited or noisy labeled data. The Information Bottleneck (IB) method (Tishby et al. (2000)) provides an insightful and principled approach for balancing compression and prediction in representation learning. The IB objective I(X; Z) \u2212 \u03b2I(Y ; Z) employs a Lagrange multiplier \u03b2 to tune this trade-off. However, there is little theoretical guidance for how to select \u03b2. There is also a lack of theoretical understanding about the relationship between \u03b2, the dataset, model capacity, and learnability. In this work, we show that if \u03b2 is improperly chosen, learning cannot happen: the trivial representation P(Z|X) = P(Z) becomes the global minimum of the IB objective. We show how this can be avoided, by identifying a sharp phase transition between the unlearnable and the learnable which arises as \u03b2 varies. This phase transition defines the concept of IB-Learnability. We prove several sufficient conditions for IB-Learnability, providing theoretical guidance for selecting \u03b2. We further show that IB-learnability is determined by the largest confident, typical, and imbalanced subset of the training examples. We give a practical algorithm to estimate the minimum \u03b2 for a given dataset. We test our theoretical results on synthetic datasets, MNIST, and CIFAR10 with noisy labels, and make the surprising observation that accuracy may be non-monotonic in \u03b2.", "pdf": "/pdf/1290e4dc7b5d511b8b213f53c54006475d031bfc.pdf", "paperhash": "wu|learnability_for_the_information_bottleneck"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper59/Official_Review", "cdate": 1553713411662, "expdate": 1555718400000, "duedate": 1554681600000, "reply": {"forum": "SJePKo5HdV", "replyto": "SJePKo5HdV", "writers": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2019/Workshop/LLD/Paper59/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2019/Workshop/LLD/Paper59/AnonReviewer[0-9]+"}, "readers": {"values": ["everyone"], "description": "The users who will be allowed to read the above content."}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["5: Top 15% of accepted papers, strong accept", "4: Top 50% of accepted papers, clear accept", "3: Marginally above acceptance threshold", "2: Marginally below acceptance threshold", "1: Strong rejection"], "required": true}, "confidence": {"order": 4, "value-radio": ["3: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "2: The reviewer is fairly confident that the evaluation is correct", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "tcdate": 1553713411662, "tmdate": 1555511821822, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Paper59/Reviewers"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}, {"id": "BkxkqV26tE", "original": null, "number": 1, "cdate": 1555051655014, "ddate": null, "tcdate": 1555051655014, "tmdate": 1555510982756, "tddate": null, "forum": "SJePKo5HdV", "replyto": "SJePKo5HdV", "invitation": "ICLR.cc/2019/Workshop/LLD/-/Paper59/Decision", "content": {"title": "Acceptance Decision", "decision": "Accept"}, "signatures": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Learnability for the Information Bottleneck", "authors": ["Tailin Wu", "Ian Fischer", "Isaac Chuang", "Max Tegmark"], "authorids": ["tailin@mit.edu", "iansf@google.com", "ichuang@mit.edu", "tegmark@mit.edu"], "keywords": ["representation learning", "learnability", "information bottleneck"], "TL;DR": "Theory predicts the phase transition between unlearnable and learnable values of beta for the Information Bottleneck objective", "abstract": "Compressed representations generalize better (Shamir et al., 2010), which may be crucial when learning from limited or noisy labeled data. The Information Bottleneck (IB) method (Tishby et al. (2000)) provides an insightful and principled approach for balancing compression and prediction in representation learning. The IB objective I(X; Z) \u2212 \u03b2I(Y ; Z) employs a Lagrange multiplier \u03b2 to tune this trade-off. However, there is little theoretical guidance for how to select \u03b2. There is also a lack of theoretical understanding about the relationship between \u03b2, the dataset, model capacity, and learnability. In this work, we show that if \u03b2 is improperly chosen, learning cannot happen: the trivial representation P(Z|X) = P(Z) becomes the global minimum of the IB objective. We show how this can be avoided, by identifying a sharp phase transition between the unlearnable and the learnable which arises as \u03b2 varies. This phase transition defines the concept of IB-Learnability. We prove several sufficient conditions for IB-Learnability, providing theoretical guidance for selecting \u03b2. We further show that IB-learnability is determined by the largest confident, typical, and imbalanced subset of the training examples. We give a practical algorithm to estimate the minimum \u03b2 for a given dataset. We test our theoretical results on synthetic datasets, MNIST, and CIFAR10 with noisy labels, and make the surprising observation that accuracy may be non-monotonic in \u03b2.", "pdf": "/pdf/1290e4dc7b5d511b8b213f53c54006475d031bfc.pdf", "paperhash": "wu|learnability_for_the_information_bottleneck"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Workshop/LLD/-/Paper59/Decision", "cdate": 1554736073139, "reply": {"forum": "SJePKo5HdV", "replyto": "SJePKo5HdV", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-regex": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "signatures": {"values": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"title": {"order": 1, "required": true, "value": "Acceptance Decision"}, "decision": {"order": 2, "required": true, "value-radio": ["Accept", "Reject"], "description": "Acceptance decision"}, "comment": {"order": 3, "required": false, "value-regex": "[\\S\\s]{0,5000}", "description": ""}}}, "tcdate": 1554736073139, "tmdate": 1555510965713, "readers": ["everyone"], "writers": ["ICLR.cc/2019/Workshop/LLD"], "invitees": ["ICLR.cc/2019/Workshop/LLD/Program_Chairs"], "signatures": ["ICLR.cc/2019/Workshop/LLD"]}}}], "count": 4}