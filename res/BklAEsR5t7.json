{"notes": [{"id": "BklAEsR5t7", "original": "ryeENiBPY7", "number": 45, "cdate": 1538087733796, "ddate": null, "tcdate": 1538087733796, "tmdate": 1545355401705, "tddate": null, "forum": "BklAEsR5t7", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Large-scale classification of structured objects using a CRF with deep class embedding", "abstract": "This paper presents a novel deep learning architecture for classifying structured objects in ultrafine-grained datasets, where classes may not be clearly distinguishable by their appearance but rather by their context. We model sequences of images as linear-chain CRFs, and jointly learn the parameters from both local-visual features and neighboring class information. The visual features are learned by convolutional layers, whereas class-structure information is reparametrized by factorizing the CRF pairwise potential matrix. This forms a context-based semantic similarity space, learned alongside the visual similarities, and dramatically increases the learning capacity of contextual information. This new parametrization, however, forms a highly nonlinear objective function which is challenging to optimize. To overcome this, we develop a novel surrogate likelihood which allows for a local likelihood approximation of the original CRF with integrated batch-normalization. This model overcomes the difficulties of existing CRF methods to learn the contextual relationships thoroughly when there is a large number of classes and the data is sparse. The performance of the proposed method is illustrated on a huge dataset that contains images of retail-store product displays, and shows significantly improved results compared to linear CRF parametrization, unnormalized likelihood optimization, and RNN modeling.", "paperhash": "goldman|largescale_classification_of_structured_objects_using_a_crf_with_deep_class_embedding", "keywords": ["large-scale structure prediction", "likelihood approximation", "deep class embedding"], "authorids": ["eg4000@gmail.com", "jacob.goldberger@biu.ac.il"], "authors": ["Eran Goldman", "Jacob Goldberger"], "TL;DR": "We present a  technique for ultrafine-grained, large-scale structured classification, based on CRF modeling with factorized pairwise potentials, learned as neighboring class embedding in a whitened space.", "pdf": "/pdf/f82d45d67087a64b5616851caa33611ff3f944cf.pdf", "_bibtex": "@misc{\ngoldman2019largescale,\ntitle={Large-scale classification of structured objects using a {CRF} with deep class embedding},\nauthor={Eran Goldman and Jacob Goldberger},\nyear={2019},\nurl={https://openreview.net/forum?id=BklAEsR5t7},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "SkgLq_Xll4", "original": null, "number": 1, "cdate": 1544726670351, "ddate": null, "tcdate": 1544726670351, "tmdate": 1545354511080, "tddate": null, "forum": "BklAEsR5t7", "replyto": "BklAEsR5t7", "invitation": "ICLR.cc/2019/Conference/-/Paper45/Meta_Review", "content": {"metareview": "The paper addresses the problem of large scale fine-grained classification by estimating pairwise potentials in a CRF model. The reviewers believe that the paper has some weaknesses including (1) the motivation for approximate learning is not clear (2) the approximate objective is not well studied and (3) the experiments are not convincing. The authors did not submit a rebuttal. I encourage the authors to take the feedback into account to improve the paper.\n", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Reject", "title": "The paper can be improved"}, "signatures": ["ICLR.cc/2019/Conference/Paper45/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper45/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large-scale classification of structured objects using a CRF with deep class embedding", "abstract": "This paper presents a novel deep learning architecture for classifying structured objects in ultrafine-grained datasets, where classes may not be clearly distinguishable by their appearance but rather by their context. We model sequences of images as linear-chain CRFs, and jointly learn the parameters from both local-visual features and neighboring class information. The visual features are learned by convolutional layers, whereas class-structure information is reparametrized by factorizing the CRF pairwise potential matrix. This forms a context-based semantic similarity space, learned alongside the visual similarities, and dramatically increases the learning capacity of contextual information. This new parametrization, however, forms a highly nonlinear objective function which is challenging to optimize. To overcome this, we develop a novel surrogate likelihood which allows for a local likelihood approximation of the original CRF with integrated batch-normalization. This model overcomes the difficulties of existing CRF methods to learn the contextual relationships thoroughly when there is a large number of classes and the data is sparse. The performance of the proposed method is illustrated on a huge dataset that contains images of retail-store product displays, and shows significantly improved results compared to linear CRF parametrization, unnormalized likelihood optimization, and RNN modeling.", "paperhash": "goldman|largescale_classification_of_structured_objects_using_a_crf_with_deep_class_embedding", "keywords": ["large-scale structure prediction", "likelihood approximation", "deep class embedding"], "authorids": ["eg4000@gmail.com", "jacob.goldberger@biu.ac.il"], "authors": ["Eran Goldman", "Jacob Goldberger"], "TL;DR": "We present a  technique for ultrafine-grained, large-scale structured classification, based on CRF modeling with factorized pairwise potentials, learned as neighboring class embedding in a whitened space.", "pdf": "/pdf/f82d45d67087a64b5616851caa33611ff3f944cf.pdf", "_bibtex": "@misc{\ngoldman2019largescale,\ntitle={Large-scale classification of structured objects using a {CRF} with deep class embedding},\nauthor={Eran Goldman and Jacob Goldberger},\nyear={2019},\nurl={https://openreview.net/forum?id=BklAEsR5t7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper45/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353356086, "tddate": null, "super": null, "final": null, "reply": {"forum": "BklAEsR5t7", "replyto": "BklAEsR5t7", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper45/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper45/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper45/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353356086}}}, {"id": "Hkxa4xxWhQ", "original": null, "number": 1, "cdate": 1540583477394, "ddate": null, "tcdate": 1540583477394, "tmdate": 1543078270566, "tddate": null, "forum": "BklAEsR5t7", "replyto": "BklAEsR5t7", "invitation": "ICLR.cc/2019/Conference/-/Paper45/Official_Review", "content": {"title": "Work that introduces new ultrafine-grained classification dataset with a somewhat incremental model", "review": "Summary:\nThis paper introduces a new dataset consisting of images of various objects placed on store shelves that are labeled with object boundaries and what are described as \u201cultrafine-grained\u201d class labels. The accompanying task is to predict the labels of each object given the individual images as well as their spatial layout relative to each other. To solve this task, a deep structured model is used consisting of CNN features for each image which are fed into a linear-chain CRF. To better deal with the large number of classes, pairwise potentials are represented as the multiplication of two lower-rank matrices which represent a sort of \u201cclass embedding\u201d for each potential label. Training efficiency is improved by considering an objective based on a form of piecewise pseudolikelihood, which allows for training-time inference to be conducted with linear complexity relative to the number of labels. This objective also allows for easy use of batch normalization for the input features to the CRF model. This model/training procedure are compared against a number of models/training procedures to demonstrate its utility.\n\nComments:\nArguably, the primary contribution of this paper is the introduction of a new \u201cultrafine-grained\u201d classification dataset which additionally allows for context to be utilized during prediction. This an interesting task, and it\u2019s clear where being able to make such classifications is useful. The task is somewhat limited in scope, however. It\u2019s unclear to me how models developed for this specific task would contain insights or be useful for other tasks - the utility of any models developed for this task seem limited to this exact task. If you have any other examples where inputs might be structured in this way, this would be good to add to the paper.\n\nThe model introduced is interesting, but its novelty is limited. It\u2019s mostly a synthesis of ideas from previous work - CNN-based features, using a CRF to model correlations among labels, and approximating the full likelihood with pseudolikelihood. The interesting additions to these ideas are the fact that an \u201cembedding\u201d is learned for each class and that using the pseudolikelihood during training allows for batch norm to be applied in an easy way. Neither of these is a ground-breaking insight, but they are interesting nonetheless. I am somewhat surprised that the use of batch norm during training but not during testing did not hurt performance - a discussion of why this is the case would be good to have. For the most part, I think the experimentation is sufficiently rigorous - comparisons are made against a variety of baselines, and the new model trained with the specified training procedure outperforms the other alternatives. The one additional comparison I would have liked to see would have been against a model that pairwise potentials from the input features using a neural network-based model (for example, the one used in [1] - this seems like a rather glaring omission.\n\nOther Comments:\n-Since you ran a cross-validation, you should add confidence intervals to your reported numbers\n-One additional dataset detail I was hoping to see that you didn\u2019t provide is the mean/standard deviation of the number of instances per class,\n-Your appendix contains a number of interesting ablation studies - you really should report the numbers for these as well\n-The title of your paper is somewhat misleading - it\u2019s hard to argue that the form of class embedding you use is a \u201cdeep\u201d class embedding since it\u2019s just a matrix of parameters that are learned during training.\n\nOverall, I\u2019m not convinced the model/training procedure by themselves would be fully worthy of publication, but the fact that a new dataset is introduced with a challenging variant of standard classification tasks adds merit to this work.\n\n[1] Ma, Xuezhe, and Eduard Hovy. \"End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF.\"\n\n\nREVISION:\nThe other reviewers raised some concerns that I had overlooked (especially regarding novelty of using matrix factorization to generate your potentials). Given these, I do not think that this paper is in a state where it is ready to be accepted. Proper citations and analysis of your approach will be needed first.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper45/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Large-scale classification of structured objects using a CRF with deep class embedding", "abstract": "This paper presents a novel deep learning architecture for classifying structured objects in ultrafine-grained datasets, where classes may not be clearly distinguishable by their appearance but rather by their context. We model sequences of images as linear-chain CRFs, and jointly learn the parameters from both local-visual features and neighboring class information. The visual features are learned by convolutional layers, whereas class-structure information is reparametrized by factorizing the CRF pairwise potential matrix. This forms a context-based semantic similarity space, learned alongside the visual similarities, and dramatically increases the learning capacity of contextual information. This new parametrization, however, forms a highly nonlinear objective function which is challenging to optimize. To overcome this, we develop a novel surrogate likelihood which allows for a local likelihood approximation of the original CRF with integrated batch-normalization. This model overcomes the difficulties of existing CRF methods to learn the contextual relationships thoroughly when there is a large number of classes and the data is sparse. The performance of the proposed method is illustrated on a huge dataset that contains images of retail-store product displays, and shows significantly improved results compared to linear CRF parametrization, unnormalized likelihood optimization, and RNN modeling.", "paperhash": "goldman|largescale_classification_of_structured_objects_using_a_crf_with_deep_class_embedding", "keywords": ["large-scale structure prediction", "likelihood approximation", "deep class embedding"], "authorids": ["eg4000@gmail.com", "jacob.goldberger@biu.ac.il"], "authors": ["Eran Goldman", "Jacob Goldberger"], "TL;DR": "We present a  technique for ultrafine-grained, large-scale structured classification, based on CRF modeling with factorized pairwise potentials, learned as neighboring class embedding in a whitened space.", "pdf": "/pdf/f82d45d67087a64b5616851caa33611ff3f944cf.pdf", "_bibtex": "@misc{\ngoldman2019largescale,\ntitle={Large-scale classification of structured objects using a {CRF} with deep class embedding},\nauthor={Eran Goldman and Jacob Goldberger},\nyear={2019},\nurl={https://openreview.net/forum?id=BklAEsR5t7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper45/Official_Review", "cdate": 1542234550350, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "BklAEsR5t7", "replyto": "BklAEsR5t7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper45/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335636727, "tmdate": 1552335636727, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper45/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "Skx1bH993X", "original": null, "number": 3, "cdate": 1541215479412, "ddate": null, "tcdate": 1541215479412, "tmdate": 1541534333632, "tddate": null, "forum": "BklAEsR5t7", "replyto": "BklAEsR5t7", "invitation": "ICLR.cc/2019/Conference/-/Paper45/Official_Review", "content": {"title": "Limited significance ", "review": "This paper proposed to tackle a large-scale fine-grained object classification problem by approximated CRF. The main motivation is to exploit the spatial conference of object labels to reduce noises in the instance-wise prediction. To this end, the task is formulated by sequential inference problem using CRF. To speed up training, several techniques are applied such as factorized pairwise-potential and approximation of CRF objective.  \n\nAlthough the paper presented a reasonable idea for their particular problem (i.e. classification of products in the store display), the significance of the work is quite limited as the same idea is not generally applicable to other settings (e.g. there is no strong spatial correlation of labels in general images). Also, the performance improvement over the instance object classification is not significant as shown in Figure 5 (Unary vs. Approximate factorized). Due to the limited significance and impact of the work, this reviewer suggests a rejection of this paper. \n", "rating": "3: Clear rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper45/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large-scale classification of structured objects using a CRF with deep class embedding", "abstract": "This paper presents a novel deep learning architecture for classifying structured objects in ultrafine-grained datasets, where classes may not be clearly distinguishable by their appearance but rather by their context. We model sequences of images as linear-chain CRFs, and jointly learn the parameters from both local-visual features and neighboring class information. The visual features are learned by convolutional layers, whereas class-structure information is reparametrized by factorizing the CRF pairwise potential matrix. This forms a context-based semantic similarity space, learned alongside the visual similarities, and dramatically increases the learning capacity of contextual information. This new parametrization, however, forms a highly nonlinear objective function which is challenging to optimize. To overcome this, we develop a novel surrogate likelihood which allows for a local likelihood approximation of the original CRF with integrated batch-normalization. This model overcomes the difficulties of existing CRF methods to learn the contextual relationships thoroughly when there is a large number of classes and the data is sparse. The performance of the proposed method is illustrated on a huge dataset that contains images of retail-store product displays, and shows significantly improved results compared to linear CRF parametrization, unnormalized likelihood optimization, and RNN modeling.", "paperhash": "goldman|largescale_classification_of_structured_objects_using_a_crf_with_deep_class_embedding", "keywords": ["large-scale structure prediction", "likelihood approximation", "deep class embedding"], "authorids": ["eg4000@gmail.com", "jacob.goldberger@biu.ac.il"], "authors": ["Eran Goldman", "Jacob Goldberger"], "TL;DR": "We present a  technique for ultrafine-grained, large-scale structured classification, based on CRF modeling with factorized pairwise potentials, learned as neighboring class embedding in a whitened space.", "pdf": "/pdf/f82d45d67087a64b5616851caa33611ff3f944cf.pdf", "_bibtex": "@misc{\ngoldman2019largescale,\ntitle={Large-scale classification of structured objects using a {CRF} with deep class embedding},\nauthor={Eran Goldman and Jacob Goldberger},\nyear={2019},\nurl={https://openreview.net/forum?id=BklAEsR5t7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper45/Official_Review", "cdate": 1542234550350, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "BklAEsR5t7", "replyto": "BklAEsR5t7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper45/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335636727, "tmdate": 1552335636727, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper45/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "S1xUwr7LhX", "original": null, "number": 2, "cdate": 1540924766230, "ddate": null, "tcdate": 1540924766230, "tmdate": 1541534333426, "tddate": null, "forum": "BklAEsR5t7", "replyto": "BklAEsR5t7", "invitation": "ICLR.cc/2019/Conference/-/Paper45/Official_Review", "content": {"title": "weak contribution and experiments", "review": "This paper tackles the problem of estimating pairwise potentials when the number of labels is large. Two modifications are proposed: one is to factorize the matrix for pairwise potentials, and the other is to approximate the log likelihood objective with the MEMM objective.\n\nThe problem and the proposed approach are well motivated. It is particularly useful to draw the connections between MEMM and piecewise-pseudolikelihood.\n\nThe major weakness of the paper is whether the approximations are necessary. It is hard to see why approximating the log likelihood with MEMM is necessary, because inference and computing the gradients of the log likelihood have the same computational complexity. So the authors could have trained the model with the log likelihood.\n\nRegardless, it is still valuable to compare MEMM and log likelihood for training CRFs. However, the authors fail to show how well MEMM approximates the log likelihood. For example, the authors can compare the solutions when optimizing with the gradients of log likelihood and the with the gradients of MEMM. It is especially important to compute the training log likelihood for the two solutions, as it tells us how well MEMM approximates the log likelihood. This is also true for the low-rank approximation of the pairwise potentials. The authors fail to compare the case with low-rank approximation and the case without. It is important to evaluate the training error first with both methods as they share the same objective. This type of comparison should be apply to batch normalization as well.\n\nApproximating the pairwise potentials with matrix factorization is also not novel.  See the list below. (The list is by no means exhaustive. Please see the citations therein.)\n\nDense and low-rank Gaussian CRFs using deep embeddings\nChandra et al., ICCV 2017\n\nEfficient SDP inference for fully-connected CRFs based on low-rank decomposition\nWang et al., CVPR 2015\n\nNeural CRF parsing\nDurrett and Klein, ACL 2015\n\nFinally, some of the claims made in the paper (listed below) should be more careful.\n\np.4\n\nthe likelihood function, therefore, is log-linear and concave.\n--> concave in what?\n\nthe scoring function is still concave, ...\n--> concave in what?\n\nthe objective function is no longer linear or concave with respect to the network parameters, ...\n--> what are the network parameters?\n\nbut deep learning training techniques have been shown to yield good results ...\n--> this argument is weak. the key is point out that SGD is used, plus SGD has been shown to work well on many matrix factorization problems. see the paper below.\n\nOnline learning for matrix factorization and sparse coding\nMairal et al., JMLR 2010\n\np.5\n\nthe test time inference uses a global normalization ... avoids the label bias problem.\n--> the partition function is not even computed when using Viterbi. I'm also not sure how this avoids the label bias problem.\n\nwhitening the inputs to each layer may also prevent converging into poor local optima.\n--> this is a hand-wavy claim. it would be best if the authors can provide citations to the claim.\n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper45/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Large-scale classification of structured objects using a CRF with deep class embedding", "abstract": "This paper presents a novel deep learning architecture for classifying structured objects in ultrafine-grained datasets, where classes may not be clearly distinguishable by their appearance but rather by their context. We model sequences of images as linear-chain CRFs, and jointly learn the parameters from both local-visual features and neighboring class information. The visual features are learned by convolutional layers, whereas class-structure information is reparametrized by factorizing the CRF pairwise potential matrix. This forms a context-based semantic similarity space, learned alongside the visual similarities, and dramatically increases the learning capacity of contextual information. This new parametrization, however, forms a highly nonlinear objective function which is challenging to optimize. To overcome this, we develop a novel surrogate likelihood which allows for a local likelihood approximation of the original CRF with integrated batch-normalization. This model overcomes the difficulties of existing CRF methods to learn the contextual relationships thoroughly when there is a large number of classes and the data is sparse. The performance of the proposed method is illustrated on a huge dataset that contains images of retail-store product displays, and shows significantly improved results compared to linear CRF parametrization, unnormalized likelihood optimization, and RNN modeling.", "paperhash": "goldman|largescale_classification_of_structured_objects_using_a_crf_with_deep_class_embedding", "keywords": ["large-scale structure prediction", "likelihood approximation", "deep class embedding"], "authorids": ["eg4000@gmail.com", "jacob.goldberger@biu.ac.il"], "authors": ["Eran Goldman", "Jacob Goldberger"], "TL;DR": "We present a  technique for ultrafine-grained, large-scale structured classification, based on CRF modeling with factorized pairwise potentials, learned as neighboring class embedding in a whitened space.", "pdf": "/pdf/f82d45d67087a64b5616851caa33611ff3f944cf.pdf", "_bibtex": "@misc{\ngoldman2019largescale,\ntitle={Large-scale classification of structured objects using a {CRF} with deep class embedding},\nauthor={Eran Goldman and Jacob Goldberger},\nyear={2019},\nurl={https://openreview.net/forum?id=BklAEsR5t7},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper45/Official_Review", "cdate": 1542234550350, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "BklAEsR5t7", "replyto": "BklAEsR5t7", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper45/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335636727, "tmdate": 1552335636727, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper45/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 5}