{"notes": [{"id": "rkxw-hAcFQ", "original": "rJeXVyCqFX", "number": 1178, "cdate": 1538087934682, "ddate": null, "tcdate": 1538087934682, "tmdate": 1550813151654, "tddate": null, "forum": "rkxw-hAcFQ", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Generating Multi-Agent Trajectories using Programmatic Weak Supervision", "abstract": "We study the problem of training sequential generative models for capturing coordinated multi-agent trajectory behavior, such as  offensive basketball gameplay.  When modeling such settings, it is often beneficial to design hierarchical models that can capture long-term coordination using intermediate variables.  Furthermore, these intermediate variables should capture interesting high-level behavioral semantics in an interpretable and manipulable way. We present a hierarchical framework that can effectively learn such sequential generative models.  Our approach is inspired by recent work on leveraging programmatically produced weak labels, which we extend to the spatiotemporal regime. In addition to synthetic settings, we show how to instantiate our framework to effectively model complex interactions between basketball players and generate realistic multi-agent trajectories of basketball gameplay over long time periods. We validate our approach using both quantitative and qualitative evaluations, including a user study comparison conducted with professional sports analysts.", "keywords": ["deep learning", "generative models", "imitation learning", "hierarchical methods", "data programming", "weak supervision", "spatiotemporal"], "authorids": ["ezhan@caltech.edu", "stzheng@caltech.edu", "yyue@caltech.edu", "lsha@stats.com", "plucey@stats.com"], "authors": ["Eric Zhan", "Stephan Zheng", "Yisong Yue", "Long Sha", "Patrick Lucey"], "TL;DR": "We blend deep generative models with programmatic weak supervision to generate coordinated multi-agent trajectories of significantly higher quality than previous baselines.", "pdf": "/pdf/92bd373f4a7a19220bfef48707ae74610498bda3.pdf", "paperhash": "zhan|generating_multiagent_trajectories_using_programmatic_weak_supervision", "_bibtex": "@inproceedings{\nzhan2018generating,\ntitle={Generating Multi-Agent Trajectories using Programmatic Weak Supervision},\nauthor={Eric Zhan and Stephan Zheng and Yisong Yue and Long Sha and Patrick Lucey},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkxw-hAcFQ},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "BkgzW8tkeV", "original": null, "number": 1, "cdate": 1544685049720, "ddate": null, "tcdate": 1544685049720, "tmdate": 1545354506366, "tddate": null, "forum": "rkxw-hAcFQ", "replyto": "rkxw-hAcFQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1178/Meta_Review", "content": {"metareview": "The paper presents generative models to produce multi-agent trajectories. The approach of  using a simple heuristic labeling function that labels variables that would otherwise be latent in training data is novel and and results in higher quality than the previously proposed baselines.\nIn response to reviewer suggestions, authors included further results with models that share parameters across agents as well as agent-specific parameters and further clarifications were made for other main comments (i.e., baselines that train the hierarchical model by maximizing an ELBO on the marginal likelihood?).", "confidence": "3: The area chair is somewhat confident", "recommendation": "Accept (Poster)", "title": "Generative models to produce coordinated multi-agent behavior"}, "signatures": ["ICLR.cc/2019/Conference/Paper1178/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper1178/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Generating Multi-Agent Trajectories using Programmatic Weak Supervision", "abstract": "We study the problem of training sequential generative models for capturing coordinated multi-agent trajectory behavior, such as  offensive basketball gameplay.  When modeling such settings, it is often beneficial to design hierarchical models that can capture long-term coordination using intermediate variables.  Furthermore, these intermediate variables should capture interesting high-level behavioral semantics in an interpretable and manipulable way. We present a hierarchical framework that can effectively learn such sequential generative models.  Our approach is inspired by recent work on leveraging programmatically produced weak labels, which we extend to the spatiotemporal regime. In addition to synthetic settings, we show how to instantiate our framework to effectively model complex interactions between basketball players and generate realistic multi-agent trajectories of basketball gameplay over long time periods. We validate our approach using both quantitative and qualitative evaluations, including a user study comparison conducted with professional sports analysts.", "keywords": ["deep learning", "generative models", "imitation learning", "hierarchical methods", "data programming", "weak supervision", "spatiotemporal"], "authorids": ["ezhan@caltech.edu", "stzheng@caltech.edu", "yyue@caltech.edu", "lsha@stats.com", "plucey@stats.com"], "authors": ["Eric Zhan", "Stephan Zheng", "Yisong Yue", "Long Sha", "Patrick Lucey"], "TL;DR": "We blend deep generative models with programmatic weak supervision to generate coordinated multi-agent trajectories of significantly higher quality than previous baselines.", "pdf": "/pdf/92bd373f4a7a19220bfef48707ae74610498bda3.pdf", "paperhash": "zhan|generating_multiagent_trajectories_using_programmatic_weak_supervision", "_bibtex": "@inproceedings{\nzhan2018generating,\ntitle={Generating Multi-Agent Trajectories using Programmatic Weak Supervision},\nauthor={Eric Zhan and Stephan Zheng and Yisong Yue and Long Sha and Patrick Lucey},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkxw-hAcFQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1178/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545352936590, "tddate": null, "super": null, "final": null, "reply": {"forum": "rkxw-hAcFQ", "replyto": "rkxw-hAcFQ", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1178/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper1178/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1178/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545352936590}}}, {"id": "ryeTwe7bAm", "original": null, "number": 4, "cdate": 1542692964892, "ddate": null, "tcdate": 1542692964892, "tmdate": 1542924657463, "tddate": null, "forum": "rkxw-hAcFQ", "replyto": "BJgg0sJQpm", "invitation": "ICLR.cc/2019/Conference/-/Paper1178/Official_Comment", "content": {"title": "AnonReviewer2 Response", "comment": "Thank you for reviewing our paper and providing insightful feedback. We respond to your main points below.\n\n> \u201c... how would an intermediate baseline model where a set of parameters are shared and each agent also has an independent set of parameters perform?\u201d\n\nFollowing your suggestion, we trained such a model where the positions of all players are fed into a single GRU network, but independent networks are used to compute latent variables for each agent. This is a mix between VRNN-single and VRNN-indep, which we will call VRNN-mixed, and achieves an ELBO of 2331 and similar statistics as VRNN-indep (we will update Table 1 and Table 3). We\u2019ve also included some generated samples at (https://bit.ly/2S66iO9). However, we emphasize that this model remains fundamentally different from our solution, as our solution provides a degree of controllability and interpretability (through macro-intents) not offered by these baselines. \n\n> \u201cHow is the threshold for macro-intent generation selected.\u201d\n\nThe threshold is chosen such that it qualitatively matches realistic basketball behavior (i.e. when a basketball player is considered stationary). However, this is a very interesting question raised by the reviewer regarding the effect of labeling functions on the stability and robustness of the model. One can imagine other domains where labeling functions come from a variety of sources, some of which are noisy or redundant. Designing an algorithm that can process these labels and incorporate them into sample generation is a new line of research that we are very excited about.\n\n> \u201c... could using separate [macro-intent] vector for each agent \u2026 give the same result?\n\nIn the basketball setting, individual macro-intents are in fact sufficient for generating corresponding trajectories. However, this is mainly an architectural detail that is domain-dependent and not the most important part of our contributions. For example, one can also define macro-intents that cannot be factorized for each agent, such as friendly/unfriendly behavior in the Boids model included in our experiments.\n\n> Minor Comments\n\nThe results come from sampling from the posterior distribution. The average standard deviation of the learned posterior distribution is around 0.08 per latent dimension. The standard deviation of the learned likelihood of the data is very peaked (often less than 0.01). The macro-intent RNN model achieves a log-likelihood of 2180, which is an improvement over the RNN-gauss model but still worse than all VRNN models. We will update the paper to correct for typos. \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1178/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1178/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1178/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Generating Multi-Agent Trajectories using Programmatic Weak Supervision", "abstract": "We study the problem of training sequential generative models for capturing coordinated multi-agent trajectory behavior, such as  offensive basketball gameplay.  When modeling such settings, it is often beneficial to design hierarchical models that can capture long-term coordination using intermediate variables.  Furthermore, these intermediate variables should capture interesting high-level behavioral semantics in an interpretable and manipulable way. We present a hierarchical framework that can effectively learn such sequential generative models.  Our approach is inspired by recent work on leveraging programmatically produced weak labels, which we extend to the spatiotemporal regime. In addition to synthetic settings, we show how to instantiate our framework to effectively model complex interactions between basketball players and generate realistic multi-agent trajectories of basketball gameplay over long time periods. We validate our approach using both quantitative and qualitative evaluations, including a user study comparison conducted with professional sports analysts.", "keywords": ["deep learning", "generative models", "imitation learning", "hierarchical methods", "data programming", "weak supervision", "spatiotemporal"], "authorids": ["ezhan@caltech.edu", "stzheng@caltech.edu", "yyue@caltech.edu", "lsha@stats.com", "plucey@stats.com"], "authors": ["Eric Zhan", "Stephan Zheng", "Yisong Yue", "Long Sha", "Patrick Lucey"], "TL;DR": "We blend deep generative models with programmatic weak supervision to generate coordinated multi-agent trajectories of significantly higher quality than previous baselines.", "pdf": "/pdf/92bd373f4a7a19220bfef48707ae74610498bda3.pdf", "paperhash": "zhan|generating_multiagent_trajectories_using_programmatic_weak_supervision", "_bibtex": "@inproceedings{\nzhan2018generating,\ntitle={Generating Multi-Agent Trajectories using Programmatic Weak Supervision},\nauthor={Eric Zhan and Stephan Zheng and Yisong Yue and Long Sha and Patrick Lucey},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkxw-hAcFQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1178/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615238, "tddate": null, "super": null, "final": null, "reply": {"forum": "rkxw-hAcFQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1178/Authors", "ICLR.cc/2019/Conference/Paper1178/Reviewers", "ICLR.cc/2019/Conference/Paper1178/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1178/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1178/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1178/Authors|ICLR.cc/2019/Conference/Paper1178/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1178/Reviewers", "ICLR.cc/2019/Conference/Paper1178/Authors", "ICLR.cc/2019/Conference/Paper1178/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615238}}}, {"id": "BygisxQbCm", "original": null, "number": 5, "cdate": 1542693026934, "ddate": null, "tcdate": 1542693026934, "tmdate": 1542924584353, "tddate": null, "forum": "rkxw-hAcFQ", "replyto": "rygJogZanm", "invitation": "ICLR.cc/2019/Conference/-/Paper1178/Official_Comment", "content": {"title": "AnonReviewer3 Response", "comment": "Thank you for reviewing our paper and providing insightful feedback. We respond to your main points below.\n\n> \u201cWhat is more interesting is that a heuristic labeling function is sufficient to label macro-intents that lead to learning realistic basketball offense and swarm behavior.\u201d\n\nYes, we are very excited at the new lines of research that this opens up. One can envision many settings in which users wish to have diverse and detailed control over what\u2019s being generated. We believe models with this degree of control can be learned by incorporating labeling functions defined by users according to their preferences. We are very excited about future work in this direction.\n\n> \u201cAre any \u2026 baselines \u2026 equivalent to training the hierarchical model by maximizing an ELBO on the marginal likelihood?\u201d\n\nIf we understand the reviewer\u2019s question, then VRAE-mi (previously named VRNN-mi) does exactly this by introducing a global latent variable (in place of macro-intent weak labels) and maximizing the ELBO as well as the mutual information between the global latent variable and the trajectory. We will update the paper to make this more clear.\n\n> \u201c... could not the other models have higher likelihoods?\u201d\n\nYes, a higher ELBO does not imply a higher true likelihood, as it depends on the tightness of the bound. Computing the exact likelihood is infeasible, but it can be approximated with importance sampling. However, we note that likelihoods do not necessary correspond to quality of generated samples, as evidenced by our experiments and by [1]. Furthermore, reporting ELBOs is often sufficient when quantitatively comparing models [2,3,4].\n\n\u201c> ... 98% statistical significance.\u201d\n\nWe performed a one-sample t-test, where the null hypothesis is that the gains come from a zero-mean distribution (which would mean that both models are preferred equally).\n\n[1] Theis et al. A note on the evaluation of generative models.\n[2] Chung et al. A recurrent latent variable model for sequential data.\n[3] Fraccaro et al. Sequential neural models with stochastic layers.\n[4] Goyal et al. Z-forcing: training stochastic recurrent networks. \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1178/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1178/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1178/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Generating Multi-Agent Trajectories using Programmatic Weak Supervision", "abstract": "We study the problem of training sequential generative models for capturing coordinated multi-agent trajectory behavior, such as  offensive basketball gameplay.  When modeling such settings, it is often beneficial to design hierarchical models that can capture long-term coordination using intermediate variables.  Furthermore, these intermediate variables should capture interesting high-level behavioral semantics in an interpretable and manipulable way. We present a hierarchical framework that can effectively learn such sequential generative models.  Our approach is inspired by recent work on leveraging programmatically produced weak labels, which we extend to the spatiotemporal regime. In addition to synthetic settings, we show how to instantiate our framework to effectively model complex interactions between basketball players and generate realistic multi-agent trajectories of basketball gameplay over long time periods. We validate our approach using both quantitative and qualitative evaluations, including a user study comparison conducted with professional sports analysts.", "keywords": ["deep learning", "generative models", "imitation learning", "hierarchical methods", "data programming", "weak supervision", "spatiotemporal"], "authorids": ["ezhan@caltech.edu", "stzheng@caltech.edu", "yyue@caltech.edu", "lsha@stats.com", "plucey@stats.com"], "authors": ["Eric Zhan", "Stephan Zheng", "Yisong Yue", "Long Sha", "Patrick Lucey"], "TL;DR": "We blend deep generative models with programmatic weak supervision to generate coordinated multi-agent trajectories of significantly higher quality than previous baselines.", "pdf": "/pdf/92bd373f4a7a19220bfef48707ae74610498bda3.pdf", "paperhash": "zhan|generating_multiagent_trajectories_using_programmatic_weak_supervision", "_bibtex": "@inproceedings{\nzhan2018generating,\ntitle={Generating Multi-Agent Trajectories using Programmatic Weak Supervision},\nauthor={Eric Zhan and Stephan Zheng and Yisong Yue and Long Sha and Patrick Lucey},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkxw-hAcFQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1178/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615238, "tddate": null, "super": null, "final": null, "reply": {"forum": "rkxw-hAcFQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1178/Authors", "ICLR.cc/2019/Conference/Paper1178/Reviewers", "ICLR.cc/2019/Conference/Paper1178/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1178/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1178/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1178/Authors|ICLR.cc/2019/Conference/Paper1178/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1178/Reviewers", "ICLR.cc/2019/Conference/Paper1178/Authors", "ICLR.cc/2019/Conference/Paper1178/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615238}}}, {"id": "S1lglem-0Q", "original": null, "number": 3, "cdate": 1542692840116, "ddate": null, "tcdate": 1542692840116, "tmdate": 1542692840116, "tddate": null, "forum": "rkxw-hAcFQ", "replyto": "Bkgtp0yHaX", "invitation": "ICLR.cc/2019/Conference/-/Paper1178/Official_Comment", "content": {"title": "AnonReviewer1 Response", "comment": "Thank you for reviewing our paper and providing insightful feedback. We respond to your main points below.\n\n> \u201cThe evaluations are not very strong due to toy setup.\u201d\n\nWe emphasize that, although we use a 2D perspective of the game of basketball, this setting of modeling multi-agent tracking data is still highly non-trivial due to the following reasons:\n- Such data is often fine-grained and spans long time horizons.\n- Models must reason over all possible multi-agent trajectories, which is exponentially large w.r.t. the number of agents and time horizon.\n- Expert behavior is often inherently non-deterministic (being unpredictable on offense) and current methods struggle to accurately capture such multimodal behavior. \n- Modeling the coordination between agents is crucial for generating realistic trajectories (e.g. executing a specific offensive play in basketball).\n\nOur approach provides an efficient solution that addresses all the aforementioned challenges, whereas current state-of-the-art baselines perform very poorly in this task (e.g. players going out of bounds, players not moving cohesively, etc.). See (http://bit.ly/2DAu1Ub) for some comparisons, which is the same link provided in the footnote on page 5. Lastly, we comment that coaches and sports analysts evaluate team strategies using a 2D view of the game, so our solution in this space is practically relevant."}, "signatures": ["ICLR.cc/2019/Conference/Paper1178/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1178/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1178/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Generating Multi-Agent Trajectories using Programmatic Weak Supervision", "abstract": "We study the problem of training sequential generative models for capturing coordinated multi-agent trajectory behavior, such as  offensive basketball gameplay.  When modeling such settings, it is often beneficial to design hierarchical models that can capture long-term coordination using intermediate variables.  Furthermore, these intermediate variables should capture interesting high-level behavioral semantics in an interpretable and manipulable way. We present a hierarchical framework that can effectively learn such sequential generative models.  Our approach is inspired by recent work on leveraging programmatically produced weak labels, which we extend to the spatiotemporal regime. In addition to synthetic settings, we show how to instantiate our framework to effectively model complex interactions between basketball players and generate realistic multi-agent trajectories of basketball gameplay over long time periods. We validate our approach using both quantitative and qualitative evaluations, including a user study comparison conducted with professional sports analysts.", "keywords": ["deep learning", "generative models", "imitation learning", "hierarchical methods", "data programming", "weak supervision", "spatiotemporal"], "authorids": ["ezhan@caltech.edu", "stzheng@caltech.edu", "yyue@caltech.edu", "lsha@stats.com", "plucey@stats.com"], "authors": ["Eric Zhan", "Stephan Zheng", "Yisong Yue", "Long Sha", "Patrick Lucey"], "TL;DR": "We blend deep generative models with programmatic weak supervision to generate coordinated multi-agent trajectories of significantly higher quality than previous baselines.", "pdf": "/pdf/92bd373f4a7a19220bfef48707ae74610498bda3.pdf", "paperhash": "zhan|generating_multiagent_trajectories_using_programmatic_weak_supervision", "_bibtex": "@inproceedings{\nzhan2018generating,\ntitle={Generating Multi-Agent Trajectories using Programmatic Weak Supervision},\nauthor={Eric Zhan and Stephan Zheng and Yisong Yue and Long Sha and Patrick Lucey},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkxw-hAcFQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1178/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615238, "tddate": null, "super": null, "final": null, "reply": {"forum": "rkxw-hAcFQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1178/Authors", "ICLR.cc/2019/Conference/Paper1178/Reviewers", "ICLR.cc/2019/Conference/Paper1178/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1178/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1178/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1178/Authors|ICLR.cc/2019/Conference/Paper1178/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1178/Reviewers", "ICLR.cc/2019/Conference/Paper1178/Authors", "ICLR.cc/2019/Conference/Paper1178/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615238}}}, {"id": "r1lOYyQWRX", "original": null, "number": 2, "cdate": 1542692735875, "ddate": null, "tcdate": 1542692735875, "tmdate": 1542692735875, "tddate": null, "forum": "rkxw-hAcFQ", "replyto": "rkxw-hAcFQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1178/Official_Comment", "content": {"title": "General comments to revewiers", "comment": "We thank all reviewers for their insightful comments and will make updates to the paper as needed. We briefly summarize our contributions below.\n\nWe work in a novel sequential modeling setting in which the target phenomenon (coordinated multi-agent behavior) is inherently non-deterministic and multimodal. Current approaches do not scale to the complexity of this problem because the space of all possible multi-agent trajectories is exponentially large w.r.t. the number of agents, and the agents are often highly coordinated. \n\nWe propose an efficient solution that uses a simple labeling function in sequential generative models to learn a macro-intent latent variable that encodes long-term intent and captures the coordination between agents. Our results demonstrate that our model generates trajectories of significantly higher quality than current baselines. Lastly, we highlight that our approach provides a degree of control and interpretability not offered by other baselines; the macro-intent variables are well understood (since they originate from a heuristic labeling function) and their effect on generated samples can be easily analyzed. \n\nWe believe that this work opens a new line of research into algorithms that can provide users with various degrees of control during sample generation. Current alternatives involve learning latent variables in a fully unsupervised fashion and inspecting them after training for interpretable features. Our work uses labeling functions to directly control sample generation in ways that can be specified by the user. For example, the labeling function we used for basketball allows users to control where they want players to go (see Figure 6a in our paper). We are very excited about future work in this direction. \n"}, "signatures": ["ICLR.cc/2019/Conference/Paper1178/Authors"], "readers": ["everyone"], "nonreaders": ["ICLR.cc/2019/Conference/Paper1178/Reviewers/Unsubmitted"], "writers": ["ICLR.cc/2019/Conference/Paper1178/Authors", "ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Generating Multi-Agent Trajectories using Programmatic Weak Supervision", "abstract": "We study the problem of training sequential generative models for capturing coordinated multi-agent trajectory behavior, such as  offensive basketball gameplay.  When modeling such settings, it is often beneficial to design hierarchical models that can capture long-term coordination using intermediate variables.  Furthermore, these intermediate variables should capture interesting high-level behavioral semantics in an interpretable and manipulable way. We present a hierarchical framework that can effectively learn such sequential generative models.  Our approach is inspired by recent work on leveraging programmatically produced weak labels, which we extend to the spatiotemporal regime. In addition to synthetic settings, we show how to instantiate our framework to effectively model complex interactions between basketball players and generate realistic multi-agent trajectories of basketball gameplay over long time periods. We validate our approach using both quantitative and qualitative evaluations, including a user study comparison conducted with professional sports analysts.", "keywords": ["deep learning", "generative models", "imitation learning", "hierarchical methods", "data programming", "weak supervision", "spatiotemporal"], "authorids": ["ezhan@caltech.edu", "stzheng@caltech.edu", "yyue@caltech.edu", "lsha@stats.com", "plucey@stats.com"], "authors": ["Eric Zhan", "Stephan Zheng", "Yisong Yue", "Long Sha", "Patrick Lucey"], "TL;DR": "We blend deep generative models with programmatic weak supervision to generate coordinated multi-agent trajectories of significantly higher quality than previous baselines.", "pdf": "/pdf/92bd373f4a7a19220bfef48707ae74610498bda3.pdf", "paperhash": "zhan|generating_multiagent_trajectories_using_programmatic_weak_supervision", "_bibtex": "@inproceedings{\nzhan2018generating,\ntitle={Generating Multi-Agent Trajectories using Programmatic Weak Supervision},\nauthor={Eric Zhan and Stephan Zheng and Yisong Yue and Long Sha and Patrick Lucey},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkxw-hAcFQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1178/Official_Comment", "rdate": null, "ddate": null, "expdate": null, "duedate": null, "tmdate": 1543621615238, "tddate": null, "super": null, "final": null, "reply": {"forum": "rkxw-hAcFQ", "replyto": null, "readers": {"description": "Select all user groups that should be able to read this comment.", "value-dropdown-hierarchy": ["everyone", "ICLR.cc/2019/Conference/Paper1178/Authors", "ICLR.cc/2019/Conference/Paper1178/Reviewers", "ICLR.cc/2019/Conference/Paper1178/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"]}, "nonreaders": {"values": ["ICLR.cc/2019/Conference/Paper1178/Reviewers/Unsubmitted"]}, "signatures": {"description": "", "values-regex": "ICLR.cc/2019/Conference/Paper1178/AnonReviewer[0-9]+|ICLR.cc/2019/Conference/Paper1178/Authors|ICLR.cc/2019/Conference/Paper1178/Area_Chair[0-9]+|ICLR.cc/2019/Conference/Program_Chairs"}, "writers": {"description": "Users that may modify this record.", "values-copied": ["ICLR.cc/2019/Conference", "{signatures}"]}, "content": {"title": {"order": 0, "value-regex": ".{1,500}", "description": "Brief summary of your comment.", "required": true}, "comment": {"order": 1, "value-regex": "[\\S\\s]{1,5000}", "description": "Your comment or reply (max 5000 characters).", "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper1178/Reviewers", "ICLR.cc/2019/Conference/Paper1178/Authors", "ICLR.cc/2019/Conference/Paper1178/Area_Chairs", "ICLR.cc/2019/Conference/Program_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": true, "taskCompletionCount": null, "transform": null, "cdate": 1543621615238}}}, {"id": "Bkgtp0yHaX", "original": null, "number": 3, "cdate": 1541893824645, "ddate": null, "tcdate": 1541893824645, "tmdate": 1541893824645, "tddate": null, "forum": "rkxw-hAcFQ", "replyto": "rkxw-hAcFQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1178/Official_Review", "content": {"title": "Paper proposes multi-agent sequential generative models. This is influential beyond toy simulations presented in the paper.", "review": "Very strong paper, building on top of variational RNNs for multi-agent sequential generation. Dialogue use case is mentioned in Discussion is indeed very exciting. The approach extends VRNN to a hierarchical setup with high level coordination via a shared learned latent variable. The evaluations are not very strong due to toy task setup, however the approach is clear and impactful.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1178/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Generating Multi-Agent Trajectories using Programmatic Weak Supervision", "abstract": "We study the problem of training sequential generative models for capturing coordinated multi-agent trajectory behavior, such as  offensive basketball gameplay.  When modeling such settings, it is often beneficial to design hierarchical models that can capture long-term coordination using intermediate variables.  Furthermore, these intermediate variables should capture interesting high-level behavioral semantics in an interpretable and manipulable way. We present a hierarchical framework that can effectively learn such sequential generative models.  Our approach is inspired by recent work on leveraging programmatically produced weak labels, which we extend to the spatiotemporal regime. In addition to synthetic settings, we show how to instantiate our framework to effectively model complex interactions between basketball players and generate realistic multi-agent trajectories of basketball gameplay over long time periods. We validate our approach using both quantitative and qualitative evaluations, including a user study comparison conducted with professional sports analysts.", "keywords": ["deep learning", "generative models", "imitation learning", "hierarchical methods", "data programming", "weak supervision", "spatiotemporal"], "authorids": ["ezhan@caltech.edu", "stzheng@caltech.edu", "yyue@caltech.edu", "lsha@stats.com", "plucey@stats.com"], "authors": ["Eric Zhan", "Stephan Zheng", "Yisong Yue", "Long Sha", "Patrick Lucey"], "TL;DR": "We blend deep generative models with programmatic weak supervision to generate coordinated multi-agent trajectories of significantly higher quality than previous baselines.", "pdf": "/pdf/92bd373f4a7a19220bfef48707ae74610498bda3.pdf", "paperhash": "zhan|generating_multiagent_trajectories_using_programmatic_weak_supervision", "_bibtex": "@inproceedings{\nzhan2018generating,\ntitle={Generating Multi-Agent Trajectories using Programmatic Weak Supervision},\nauthor={Eric Zhan and Stephan Zheng and Yisong Yue and Long Sha and Patrick Lucey},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkxw-hAcFQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1178/Official_Review", "cdate": 1542234287741, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rkxw-hAcFQ", "replyto": "rkxw-hAcFQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1178/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335889863, "tmdate": 1552335889863, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1178/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "BJgg0sJQpm", "original": null, "number": 2, "cdate": 1541761992109, "ddate": null, "tcdate": 1541761992109, "tmdate": 1541761992109, "tddate": null, "forum": "rkxw-hAcFQ", "replyto": "rkxw-hAcFQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1178/Official_Review", "content": {"title": "Hierarchical latent variables with weak supervision help learning a global coordination between cooperative agents.", "review": "\nThis paper proposes training multiple generative models that share a common latent variable, which is learned in a weakly supervised fashion, to achieve high level coordination between multiple agents. Each agent has a separate VRNN model which is conditioned on the agent\u2019s own trajectory history as well as the shared latent variable. The model is trained to maximize the ELBO objective and log-likelihood over macro-intent labels. Experimental results are conducted over a basketball gameplay dataset (to model the trajectories of the offensive team members) and a synthetic dataset. The results show that the proposed model is on-par with the baseline models in terms of ELBO while showing that it can model multi-modality better and is preferred more by humans. \n\nIn general, the paper is well written and the overall framework captures the essence of the problem that the authors are trying to solve.\nFurthermore, incorporating an auxiliary latent variable to model the coordination between multiple agents is interesting.\nI have several comments related to the strength of the baselines and contribution of individual components in the proposed model.\n\n\nMajor Comments\n\n- It seems that VRNN-single and VRNN-indep are two models on the far two ends of a spectrum. To understand the contribution of the shared macro-intent, how would an intermediate baseline model where a set of parameters are shared between agents and each agent also has an independent set of parameters perform? This could be accomplished by sharing the parameters of the first layer of GRU networks and learning the second layer parameters independently.\n\n- How is the threshold for macro-intent generation selected? How does this parameter affect the overall performance? Since the smoothness of the segments between two macro-intents depend on this parameter, I am wondering its effect on the learned posterior distribution.\n\n- Rather than using the prediction of the macro-intent RNN as a single global vector (\\hat{g}_t), could using separate vectors for each agent (corresponding blocks of \\hat{g}_t) as inputs to VRNN give the same results? Since the macro-intent RNN is already aware of all the macro-intents, it would be interesting to see if individual macro-intents are sufficient for VRNN to generate corresponding trajectories.\n\n\nMinor Comments\n\n- Do results in Table (1) come from sampling or using mode of the distributions? How peaked are the learned posterior distributions?\n- What is the performance of the macro-intent RNN model?\n- In Eq (2), \u201c<=T\u201d should be \u201c<=t\u201d (as in Eq (11) in Chung 2015).\n- In Page 6, bullet point 4: it should be \u201cexcept we maximize the mutual information\u2026\u201d\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1178/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Generating Multi-Agent Trajectories using Programmatic Weak Supervision", "abstract": "We study the problem of training sequential generative models for capturing coordinated multi-agent trajectory behavior, such as  offensive basketball gameplay.  When modeling such settings, it is often beneficial to design hierarchical models that can capture long-term coordination using intermediate variables.  Furthermore, these intermediate variables should capture interesting high-level behavioral semantics in an interpretable and manipulable way. We present a hierarchical framework that can effectively learn such sequential generative models.  Our approach is inspired by recent work on leveraging programmatically produced weak labels, which we extend to the spatiotemporal regime. In addition to synthetic settings, we show how to instantiate our framework to effectively model complex interactions between basketball players and generate realistic multi-agent trajectories of basketball gameplay over long time periods. We validate our approach using both quantitative and qualitative evaluations, including a user study comparison conducted with professional sports analysts.", "keywords": ["deep learning", "generative models", "imitation learning", "hierarchical methods", "data programming", "weak supervision", "spatiotemporal"], "authorids": ["ezhan@caltech.edu", "stzheng@caltech.edu", "yyue@caltech.edu", "lsha@stats.com", "plucey@stats.com"], "authors": ["Eric Zhan", "Stephan Zheng", "Yisong Yue", "Long Sha", "Patrick Lucey"], "TL;DR": "We blend deep generative models with programmatic weak supervision to generate coordinated multi-agent trajectories of significantly higher quality than previous baselines.", "pdf": "/pdf/92bd373f4a7a19220bfef48707ae74610498bda3.pdf", "paperhash": "zhan|generating_multiagent_trajectories_using_programmatic_weak_supervision", "_bibtex": "@inproceedings{\nzhan2018generating,\ntitle={Generating Multi-Agent Trajectories using Programmatic Weak Supervision},\nauthor={Eric Zhan and Stephan Zheng and Yisong Yue and Long Sha and Patrick Lucey},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkxw-hAcFQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1178/Official_Review", "cdate": 1542234287741, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rkxw-hAcFQ", "replyto": "rkxw-hAcFQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1178/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335889863, "tmdate": 1552335889863, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1178/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "rygJogZanm", "original": null, "number": 1, "cdate": 1541374102771, "ddate": null, "tcdate": 1541374102771, "tmdate": 1541533356849, "tddate": null, "forum": "rkxw-hAcFQ", "replyto": "rkxw-hAcFQ", "invitation": "ICLR.cc/2019/Conference/-/Paper1178/Official_Review", "content": {"title": "Heuristic labeling enables learning of hierarchical model without needing to marginalize over latent variables", "review": "# Summary\n\nThe paper proposes training generative models that produce multi-agent trajectories using heuristic functions that label variables that would otherwise be latent in training data. The generative models are hierarchical, and these latent variables correspond to higher level goals in agent behavior. The paper focuses on basketball offenses as a motivating scenario in which multiple agents have coordinated high-level behavior. The generative models are RNNs where each output is fed into the decoder of a variational autoencoder to produce observed states. The authors add an intermediate layer to capture the latent variables, called macro-intents. The parameters are learned by maximizing an evidence lower bound.\n\nExperiments qualitatively and quantitatively show that the hierarchical model produces realistic multi-agent traces.\n\n# Comments\n\nThe paper presents a sensible solution for heuristically labeling latent variables. It is not particularly surprising that the model then learns useful behavior because it no longer has to maximize the marginal likelihood over all possible macro-intents. What is more interesting is that a heuristic labeling function is sufficient to label macro-intents that lead to learning realistic basketball offenses and swarm behavior.\n\nAre any of the baselines (VRNN-single, VRNN-indep, and VRNN-mi) equivalent to training the hierarchical model by maximizing an ELBO on the marginal likelihood? I do not think this comparison is done, which might be interesting to quantify how much of a difference heuristic labeling makes. Of course, the potentially poor fit of a variational distribution would confound the results.\n\n# Minor things\n\n1) In the caption of Table 1, it says \"Our hierarchical model achieves higher log-likelihoods than baselines for both datasets.\" Are not the reported scores evidence lower-bounds? So it achieves a higher evidence lower bound, but without actually computing the true likelihood, could not the other models have higher likelihoods?\n\n2) Under \"Human preference study\" it says \"All judges preferred our model over the baselines with 98% statistical significance.\" I am not familiar with this terminology. Does that mean that a p value for some null hypothesis is .02?\n\n3) Something is wrong with the citation commands. Perhaps \\citep should be used.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper1178/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Generating Multi-Agent Trajectories using Programmatic Weak Supervision", "abstract": "We study the problem of training sequential generative models for capturing coordinated multi-agent trajectory behavior, such as  offensive basketball gameplay.  When modeling such settings, it is often beneficial to design hierarchical models that can capture long-term coordination using intermediate variables.  Furthermore, these intermediate variables should capture interesting high-level behavioral semantics in an interpretable and manipulable way. We present a hierarchical framework that can effectively learn such sequential generative models.  Our approach is inspired by recent work on leveraging programmatically produced weak labels, which we extend to the spatiotemporal regime. In addition to synthetic settings, we show how to instantiate our framework to effectively model complex interactions between basketball players and generate realistic multi-agent trajectories of basketball gameplay over long time periods. We validate our approach using both quantitative and qualitative evaluations, including a user study comparison conducted with professional sports analysts.", "keywords": ["deep learning", "generative models", "imitation learning", "hierarchical methods", "data programming", "weak supervision", "spatiotemporal"], "authorids": ["ezhan@caltech.edu", "stzheng@caltech.edu", "yyue@caltech.edu", "lsha@stats.com", "plucey@stats.com"], "authors": ["Eric Zhan", "Stephan Zheng", "Yisong Yue", "Long Sha", "Patrick Lucey"], "TL;DR": "We blend deep generative models with programmatic weak supervision to generate coordinated multi-agent trajectories of significantly higher quality than previous baselines.", "pdf": "/pdf/92bd373f4a7a19220bfef48707ae74610498bda3.pdf", "paperhash": "zhan|generating_multiagent_trajectories_using_programmatic_weak_supervision", "_bibtex": "@inproceedings{\nzhan2018generating,\ntitle={Generating Multi-Agent Trajectories using Programmatic Weak Supervision},\nauthor={Eric Zhan and Stephan Zheng and Yisong Yue and Long Sha and Patrick Lucey},\nbooktitle={International Conference on Learning Representations},\nyear={2019},\nurl={https://openreview.net/forum?id=rkxw-hAcFQ},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper1178/Official_Review", "cdate": 1542234287741, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "rkxw-hAcFQ", "replyto": "rkxw-hAcFQ", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper1178/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335889863, "tmdate": 1552335889863, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper1178/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 9}