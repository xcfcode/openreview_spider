{"notes": [{"id": "HkxSOAEFDB", "original": "rJxt93vuDH", "number": 1209, "cdate": 1569439340629, "ddate": null, "tcdate": 1569439340629, "tmdate": 1577168244495, "tddate": null, "forum": "HkxSOAEFDB", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["changh17@mails.tsinghua.edu.cn", "yu.rong@hotmail.com", "sojoudi@berkeley.edu", "jzhuang@uta.edu", "wwzhu@tsinghua.edu.cn"], "title": "Octave Graph Convolutional Network", "authors": ["Heng Chang", "Yu Rong", "Somayeh Sojoudi", "Junzhou Huang", "Wenwu Zhu"], "pdf": "/pdf/36bf12ae5dc61232901a08399dd32de8f41584b8.pdf", "TL;DR": "Octave convolutional learning for graphs in spectral domain within the framework of Graph Convolutional Networks", "abstract": "Many variants of Graph Convolutional Networks (GCNs) for representation learning have been proposed recently and have achieved fruitful results in various domains. Among them, spectral-based GCNs are constructed via convolution theorem upon theoretical foundation from the perspective of Graph Signal Processing (GSP). However, despite most of them implicitly act as low-pass filters that generate smooth representations for each node, there is limited development on the full usage of underlying information from low-frequency. Here, we first introduce the octave convolution on graphs in spectral domain. Accordingly, we present Octave Graph Convolutional Network (OctGCN), a novel architecture that learns representations for different frequency components regarding to weighted filters and graph wavelets bases. We empirically validate the importance of low-frequency components in graph signals on semi-supervised node classification and demonstrate that our model achieves state-of-the-art performance in comparison with both spectral-based and spatial-based baselines.", "keywords": ["Graph Convolutional Networks", "Octave Convolution", "Graph Mining"], "paperhash": "chang|octave_graph_convolutional_network", "original_pdf": "/attachment/8232be9e118cc041b103b61b103b77009e76d36d.pdf", "_bibtex": "@misc{\nchang2020octave,\ntitle={Octave Graph Convolutional Network},\nauthor={Heng Chang and Yu Rong and Somayeh Sojoudi and Junzhou Huang and Wenwu Zhu},\nyear={2020},\nurl={https://openreview.net/forum?id=HkxSOAEFDB}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 7, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "VQSBEcGWti", "original": null, "number": 1, "cdate": 1576798717472, "ddate": null, "tcdate": 1576798717472, "tmdate": 1576800919069, "tddate": null, "forum": "HkxSOAEFDB", "replyto": "HkxSOAEFDB", "invitation": "ICLR.cc/2020/Conference/Paper1209/-/Decision", "content": {"decision": "Reject", "comment": "Two reviewers are negative on this paper while the other one is slightly positive. Overall, the paper does not make the bar of ICLR and thus a reject is recommended.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["changh17@mails.tsinghua.edu.cn", "yu.rong@hotmail.com", "sojoudi@berkeley.edu", "jzhuang@uta.edu", "wwzhu@tsinghua.edu.cn"], "title": "Octave Graph Convolutional Network", "authors": ["Heng Chang", "Yu Rong", "Somayeh Sojoudi", "Junzhou Huang", "Wenwu Zhu"], "pdf": "/pdf/36bf12ae5dc61232901a08399dd32de8f41584b8.pdf", "TL;DR": "Octave convolutional learning for graphs in spectral domain within the framework of Graph Convolutional Networks", "abstract": "Many variants of Graph Convolutional Networks (GCNs) for representation learning have been proposed recently and have achieved fruitful results in various domains. Among them, spectral-based GCNs are constructed via convolution theorem upon theoretical foundation from the perspective of Graph Signal Processing (GSP). However, despite most of them implicitly act as low-pass filters that generate smooth representations for each node, there is limited development on the full usage of underlying information from low-frequency. Here, we first introduce the octave convolution on graphs in spectral domain. Accordingly, we present Octave Graph Convolutional Network (OctGCN), a novel architecture that learns representations for different frequency components regarding to weighted filters and graph wavelets bases. We empirically validate the importance of low-frequency components in graph signals on semi-supervised node classification and demonstrate that our model achieves state-of-the-art performance in comparison with both spectral-based and spatial-based baselines.", "keywords": ["Graph Convolutional Networks", "Octave Convolution", "Graph Mining"], "paperhash": "chang|octave_graph_convolutional_network", "original_pdf": "/attachment/8232be9e118cc041b103b61b103b77009e76d36d.pdf", "_bibtex": "@misc{\nchang2020octave,\ntitle={Octave Graph Convolutional Network},\nauthor={Heng Chang and Yu Rong and Somayeh Sojoudi and Junzhou Huang and Wenwu Zhu},\nyear={2020},\nurl={https://openreview.net/forum?id=HkxSOAEFDB}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "HkxSOAEFDB", "replyto": "HkxSOAEFDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795714070, "tmdate": 1576800263837, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1209/-/Decision"}}}, {"id": "r1g_ALQoiB", "original": null, "number": 3, "cdate": 1573758671545, "ddate": null, "tcdate": 1573758671545, "tmdate": 1573758671545, "tddate": null, "forum": "HkxSOAEFDB", "replyto": "rJlkKoAe5r", "invitation": "ICLR.cc/2020/Conference/Paper1209/-/Official_Comment", "content": {"title": "Response to Official Blind Review #2", "comment": "Thank you for your earnest manner on review and we appreciate it very much!\nIndeed, both the different weighting between low vs high-frequency components and fewer dependencies across variables contribute to better performance. \n1. By assigning different weights between low vs high, the different importance of low vs high-frequency components existing in graphs is captured for the first time in our proposed model. For more details of our motivation, please kindly refer to the response to Reviewer #3.\n2. Along with the octave convolutional operations, we further reduce the parameters in our model as described in Section 3.4. Since the amount of training data is extremely limited in semi-supervised learning, the reduction of parameters alleviates the dependencies across variables and makes the representational learning have better performance."}, "signatures": ["ICLR.cc/2020/Conference/Paper1209/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1209/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["changh17@mails.tsinghua.edu.cn", "yu.rong@hotmail.com", "sojoudi@berkeley.edu", "jzhuang@uta.edu", "wwzhu@tsinghua.edu.cn"], "title": "Octave Graph Convolutional Network", "authors": ["Heng Chang", "Yu Rong", "Somayeh Sojoudi", "Junzhou Huang", "Wenwu Zhu"], "pdf": "/pdf/36bf12ae5dc61232901a08399dd32de8f41584b8.pdf", "TL;DR": "Octave convolutional learning for graphs in spectral domain within the framework of Graph Convolutional Networks", "abstract": "Many variants of Graph Convolutional Networks (GCNs) for representation learning have been proposed recently and have achieved fruitful results in various domains. Among them, spectral-based GCNs are constructed via convolution theorem upon theoretical foundation from the perspective of Graph Signal Processing (GSP). However, despite most of them implicitly act as low-pass filters that generate smooth representations for each node, there is limited development on the full usage of underlying information from low-frequency. Here, we first introduce the octave convolution on graphs in spectral domain. Accordingly, we present Octave Graph Convolutional Network (OctGCN), a novel architecture that learns representations for different frequency components regarding to weighted filters and graph wavelets bases. We empirically validate the importance of low-frequency components in graph signals on semi-supervised node classification and demonstrate that our model achieves state-of-the-art performance in comparison with both spectral-based and spatial-based baselines.", "keywords": ["Graph Convolutional Networks", "Octave Convolution", "Graph Mining"], "paperhash": "chang|octave_graph_convolutional_network", "original_pdf": "/attachment/8232be9e118cc041b103b61b103b77009e76d36d.pdf", "_bibtex": "@misc{\nchang2020octave,\ntitle={Octave Graph Convolutional Network},\nauthor={Heng Chang and Yu Rong and Somayeh Sojoudi and Junzhou Huang and Wenwu Zhu},\nyear={2020},\nurl={https://openreview.net/forum?id=HkxSOAEFDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HkxSOAEFDB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1209/Authors", "ICLR.cc/2020/Conference/Paper1209/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1209/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1209/Reviewers", "ICLR.cc/2020/Conference/Paper1209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1209/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1209/Authors|ICLR.cc/2020/Conference/Paper1209/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504159548, "tmdate": 1576860549373, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1209/Authors", "ICLR.cc/2020/Conference/Paper1209/Reviewers", "ICLR.cc/2020/Conference/Paper1209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1209/-/Official_Comment"}}}, {"id": "Skgfi8XosS", "original": null, "number": 2, "cdate": 1573758618322, "ddate": null, "tcdate": 1573758618322, "tmdate": 1573758618322, "tddate": null, "forum": "HkxSOAEFDB", "replyto": "rygxsZzmqH", "invitation": "ICLR.cc/2020/Conference/Paper1209/-/Official_Comment", "content": {"title": "Response to Official Blind Review #3", "comment": "Thank you for your recognition of the novelty of our works and valuable comments. We are sorry that our motivation is not specified sufficiently. Here we elaborate our motivation by example in the following. \nThe octave nature in computer vision usually denotes that the low-frequency components describe the smoothly changing structure (e.g. background) and high-frequency components describe the rapidly changing details (e.g. outlines) [A1]. \n\nSimilarly, the low- and high- frequency components in the nature of graphs also exhibit the different importance that contributes to the learning of modern GNNs [A2]. Concretely, we observe that the low-frequency components in graphs usually indicate smooth varying signals which can reflect the locality property (the neighbor nodes trend to be similar to each other) in graphs. To validate this observation, we investigate two measures in [A3]: Mean Average Distance (MAD) and Information-to-Noise Ratio (INR) w.r.t different spectrum basis. Different spectrum basis has a corresponding node in graph, which we refer as low- and high- frequency node.\n\nMAD reflects the smoothness of the transformed graph signal on node. Given a node $v$ and the feature $\\mathbf{x}_{v}$ on it as signal, we take its eigenvector $\\mathbf{u}_{v}$ to multiply $ \\mathbf{x}_{v}$ as the transformed feature $ \\tilde{\\mathbf{x}_{v}}$ in spectral domain. Then the MAD of $v$ is calculated by taking the average of cosine distances between the transformed feature of $v$ and that of its 1-hop neighbors. The lower MAD indicates better smoothness.\n\nINR is defined as the proportion of nodes from the same class as $v$ through the 1-hop neighborhood of $v$. The higher INR indicates richer information.\n\nFor each dataset, we compute the average MAD and INR of top-50% low-frequency nodes ($MAD_L$/$INR_L$) and high-frequency nodes ($MAD_H$/ $INR_H$) and report the gap between low- and high- frequency nodes.\nDataset | Citeseer | Cora | Pubmed\n$MAD_L$ \u2013 $MAD_H$ | $-3.7 \\times 10^{-4}$ | $ -9.0\\times 10^{-5}$ | $ -1.0\\times 10^{-5}$\n$INR_L$ \u2013 $INR_H$ | $0.018$ | $0.002$ | $0.005$\nWe can observe that the low-frequency components in real graphs are smoother than those of high-frequency (lower MAD). Meanwhile, they have higher INR, which indicates they contain richer information. In the vein, we argue that the low-frequency components may carry more information than that of the high-frequency components and should be more beneficial for representational learning. Therefore, comparing with current GNNs, that treat the low- and high- frequency components identically during training, our octave convolutional structure model could gain more from this octave nature existing in graphs. We updated this demonstration in the submission.\n\n[A1] Chen, Yunpeng, et al. \u201cDrop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave Convolution.\u201d ArXiv Preprint ArXiv:1904.05049, 2019.\n[A2] Nt, Hoang, and Takanori Maehara. \u201cRevisiting Graph Neural Networks: All We Have Is Low-Pass Filters.\u201d ArXiv Preprint ArXiv:1905.09550, 2019.\n[A3] Chen, Deli, et al. \"Measuring and Relieving the Over-smoothing Problem for Graph Neural Networks from the Topological View.\" arXiv preprint arXiv:1909.03211 (2019)."}, "signatures": ["ICLR.cc/2020/Conference/Paper1209/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1209/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["changh17@mails.tsinghua.edu.cn", "yu.rong@hotmail.com", "sojoudi@berkeley.edu", "jzhuang@uta.edu", "wwzhu@tsinghua.edu.cn"], "title": "Octave Graph Convolutional Network", "authors": ["Heng Chang", "Yu Rong", "Somayeh Sojoudi", "Junzhou Huang", "Wenwu Zhu"], "pdf": "/pdf/36bf12ae5dc61232901a08399dd32de8f41584b8.pdf", "TL;DR": "Octave convolutional learning for graphs in spectral domain within the framework of Graph Convolutional Networks", "abstract": "Many variants of Graph Convolutional Networks (GCNs) for representation learning have been proposed recently and have achieved fruitful results in various domains. Among them, spectral-based GCNs are constructed via convolution theorem upon theoretical foundation from the perspective of Graph Signal Processing (GSP). However, despite most of them implicitly act as low-pass filters that generate smooth representations for each node, there is limited development on the full usage of underlying information from low-frequency. Here, we first introduce the octave convolution on graphs in spectral domain. Accordingly, we present Octave Graph Convolutional Network (OctGCN), a novel architecture that learns representations for different frequency components regarding to weighted filters and graph wavelets bases. We empirically validate the importance of low-frequency components in graph signals on semi-supervised node classification and demonstrate that our model achieves state-of-the-art performance in comparison with both spectral-based and spatial-based baselines.", "keywords": ["Graph Convolutional Networks", "Octave Convolution", "Graph Mining"], "paperhash": "chang|octave_graph_convolutional_network", "original_pdf": "/attachment/8232be9e118cc041b103b61b103b77009e76d36d.pdf", "_bibtex": "@misc{\nchang2020octave,\ntitle={Octave Graph Convolutional Network},\nauthor={Heng Chang and Yu Rong and Somayeh Sojoudi and Junzhou Huang and Wenwu Zhu},\nyear={2020},\nurl={https://openreview.net/forum?id=HkxSOAEFDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HkxSOAEFDB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1209/Authors", "ICLR.cc/2020/Conference/Paper1209/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1209/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1209/Reviewers", "ICLR.cc/2020/Conference/Paper1209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1209/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1209/Authors|ICLR.cc/2020/Conference/Paper1209/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504159548, "tmdate": 1576860549373, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1209/Authors", "ICLR.cc/2020/Conference/Paper1209/Reviewers", "ICLR.cc/2020/Conference/Paper1209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1209/-/Official_Comment"}}}, {"id": "SJxJ7L7sjS", "original": null, "number": 1, "cdate": 1573758486655, "ddate": null, "tcdate": 1573758486655, "tmdate": 1573758535553, "tddate": null, "forum": "HkxSOAEFDB", "replyto": "BJgIcnIOcB", "invitation": "ICLR.cc/2020/Conference/Paper1209/-/Official_Comment", "content": {"title": "Response to Official Blind Review #1", "comment": "Thank you for the kind review and feedback and we sincerely appreciate it. In the following, we address the concerns point by point.\nQ1: The contribution of our paper. \n\nA1: We agree that the main structure of the proposed model is derived from GWNN and Spectral CNN [A1]. However, this paper is not intended to propose an extension of GWNN. Our intuition is behind the octave nature of graphs, that is, the low- and high- frequency components may contribute differently to the learning of GNNs [A2].  To better capture the different importance of low- and high- frequency components, we propose to learn two different filters $F_{L}$ and $F_{H}$ for graph convolution (9), respectively. In this paper, we choose GWNN as the backbone to demonstrate the effectiveness of our method due to the local and sparse property of spectral wavelet basis, which is beneficial to the learning. It\u2019s worth to point out that the low- and high- frequency filters can be easily adapted to another spectral basis, such as Fourier basis, and extended to other GNN backbones. We included more explanation of the intuition of the proposed formulation in the revised version.\n\nQ2: More experiments.\n\nA2: The benchmark datasets that we used in the experiments are well-studied and well-tuned in the graph learning field. The experiments are standardized and fair for comparisons with the mixed baselines from both spatial-based and spectral-based GNN families. The improvement on the performance could legitimately demonstrate the empirical gain with our proposed model.\nWe agree that more experiments, such as on larger graphs or various tasks, could be more interesting. However, the more important point of our experiments is that the proposed model can capture the importance of low-frequency components (Figure 2 & Table 3) and learn the better representation of the graph in our experiments (Figure 3 & Table 4). The results also validate our intuition of octave convolutional structure.\n\nQ3: Regarding the experiments, is it true that d/n=0 and d/n=1 should have exactly the same results? \n\nA3: Yes, it is true that d/n=0 and d/n=1 have exactly the same results, since full spectrum of basis is considered with same filter in both situations.\n\nQ4: In Figure 2, I guess d/n=0 should be reduced to the GWNN. But it seems the performance is different than GWNN on citeseer and cora. Why there\u2019s such inconsistency, or did I miss anything? \n\nA4: When d/n=0, our model is still different from the GWNN. The diagonal filter in GWNN is learned by N different parameters, while we further reduce the parameters in the filters for low- and high- frequency components $F_{L}$ and $F_{H}$ with the identical parameters on the diagonal controlled by two weight parameters $\\alpha_{L}$ and $\\alpha_{H}$. Therefore, the diagonal filter of our model is learned by N identical weight parameters when d/n=0. Since the graph-based semi-supervised learning might prohibit the parameter learning due to the limited amount of training data, this reduction in parameters of our model could be essential for the representational learning and explain the better performance of our model.\n\n[A1] Bruna, Joan, et al. \u201cSpectral Networks and Locally Connected Networks on Graphs.\u201d ICLR 2014\u202f: International Conference on Learning Representations (ICLR) 2014, 2014.\n[A2] Nt, Hoang, and Takanori Maehara. \u201cRevisiting Graph Neural Networks: All We Have Is Low-Pass Filters.\u201d ArXiv Preprint ArXiv:1905.09550, 2019."}, "signatures": ["ICLR.cc/2020/Conference/Paper1209/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1209/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["changh17@mails.tsinghua.edu.cn", "yu.rong@hotmail.com", "sojoudi@berkeley.edu", "jzhuang@uta.edu", "wwzhu@tsinghua.edu.cn"], "title": "Octave Graph Convolutional Network", "authors": ["Heng Chang", "Yu Rong", "Somayeh Sojoudi", "Junzhou Huang", "Wenwu Zhu"], "pdf": "/pdf/36bf12ae5dc61232901a08399dd32de8f41584b8.pdf", "TL;DR": "Octave convolutional learning for graphs in spectral domain within the framework of Graph Convolutional Networks", "abstract": "Many variants of Graph Convolutional Networks (GCNs) for representation learning have been proposed recently and have achieved fruitful results in various domains. Among them, spectral-based GCNs are constructed via convolution theorem upon theoretical foundation from the perspective of Graph Signal Processing (GSP). However, despite most of them implicitly act as low-pass filters that generate smooth representations for each node, there is limited development on the full usage of underlying information from low-frequency. Here, we first introduce the octave convolution on graphs in spectral domain. Accordingly, we present Octave Graph Convolutional Network (OctGCN), a novel architecture that learns representations for different frequency components regarding to weighted filters and graph wavelets bases. We empirically validate the importance of low-frequency components in graph signals on semi-supervised node classification and demonstrate that our model achieves state-of-the-art performance in comparison with both spectral-based and spatial-based baselines.", "keywords": ["Graph Convolutional Networks", "Octave Convolution", "Graph Mining"], "paperhash": "chang|octave_graph_convolutional_network", "original_pdf": "/attachment/8232be9e118cc041b103b61b103b77009e76d36d.pdf", "_bibtex": "@misc{\nchang2020octave,\ntitle={Octave Graph Convolutional Network},\nauthor={Heng Chang and Yu Rong and Somayeh Sojoudi and Junzhou Huang and Wenwu Zhu},\nyear={2020},\nurl={https://openreview.net/forum?id=HkxSOAEFDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "HkxSOAEFDB", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1209/Authors", "ICLR.cc/2020/Conference/Paper1209/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1209/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1209/Reviewers", "ICLR.cc/2020/Conference/Paper1209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1209/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1209/Authors|ICLR.cc/2020/Conference/Paper1209/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504159548, "tmdate": 1576860549373, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1209/Authors", "ICLR.cc/2020/Conference/Paper1209/Reviewers", "ICLR.cc/2020/Conference/Paper1209/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1209/-/Official_Comment"}}}, {"id": "rJlkKoAe5r", "original": null, "number": 1, "cdate": 1572035447408, "ddate": null, "tcdate": 1572035447408, "tmdate": 1572972498708, "tddate": null, "forum": "HkxSOAEFDB", "replyto": "HkxSOAEFDB", "invitation": "ICLR.cc/2020/Conference/Paper1209/-/Official_Review", "content": {"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "title": "Official Blind Review #2", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory.", "review": "Despite reading the paper multiple times,  I am not sure I have the background to know whether what is written is significant or not. I'm aware of work on general semi-supervised learning and see the much better performance of this approach compared to things like label propagation, but cannot say for sure whether the idea is novel/significant.\n\nOne q for authors -- I don't understand the core component of the proposal, is the key ingredient that have different weighting between low vs high that causes the better performance on tasks ? or is that we have less dependencies across variables (as reflected in the computational costs) that gets the better performance ?"}, "signatures": ["ICLR.cc/2020/Conference/Paper1209/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1209/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["changh17@mails.tsinghua.edu.cn", "yu.rong@hotmail.com", "sojoudi@berkeley.edu", "jzhuang@uta.edu", "wwzhu@tsinghua.edu.cn"], "title": "Octave Graph Convolutional Network", "authors": ["Heng Chang", "Yu Rong", "Somayeh Sojoudi", "Junzhou Huang", "Wenwu Zhu"], "pdf": "/pdf/36bf12ae5dc61232901a08399dd32de8f41584b8.pdf", "TL;DR": "Octave convolutional learning for graphs in spectral domain within the framework of Graph Convolutional Networks", "abstract": "Many variants of Graph Convolutional Networks (GCNs) for representation learning have been proposed recently and have achieved fruitful results in various domains. Among them, spectral-based GCNs are constructed via convolution theorem upon theoretical foundation from the perspective of Graph Signal Processing (GSP). However, despite most of them implicitly act as low-pass filters that generate smooth representations for each node, there is limited development on the full usage of underlying information from low-frequency. Here, we first introduce the octave convolution on graphs in spectral domain. Accordingly, we present Octave Graph Convolutional Network (OctGCN), a novel architecture that learns representations for different frequency components regarding to weighted filters and graph wavelets bases. We empirically validate the importance of low-frequency components in graph signals on semi-supervised node classification and demonstrate that our model achieves state-of-the-art performance in comparison with both spectral-based and spatial-based baselines.", "keywords": ["Graph Convolutional Networks", "Octave Convolution", "Graph Mining"], "paperhash": "chang|octave_graph_convolutional_network", "original_pdf": "/attachment/8232be9e118cc041b103b61b103b77009e76d36d.pdf", "_bibtex": "@misc{\nchang2020octave,\ntitle={Octave Graph Convolutional Network},\nauthor={Heng Chang and Yu Rong and Somayeh Sojoudi and Junzhou Huang and Wenwu Zhu},\nyear={2020},\nurl={https://openreview.net/forum?id=HkxSOAEFDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HkxSOAEFDB", "replyto": "HkxSOAEFDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1209/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1209/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575088023962, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1209/Reviewers"], "noninvitees": [], "tcdate": 1570237740723, "tmdate": 1575088023974, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1209/-/Official_Review"}}}, {"id": "rygxsZzmqH", "original": null, "number": 2, "cdate": 1572180375664, "ddate": null, "tcdate": 1572180375664, "tmdate": 1572972498665, "tddate": null, "forum": "HkxSOAEFDB", "replyto": "HkxSOAEFDB", "invitation": "ICLR.cc/2020/Conference/Paper1209/-/Official_Review", "content": {"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review": "This paper proposes to use octave convolution to learn a representation of a graph.\nTypically, a learning on a graph is done either in a spatial domain or in a spectral domain.\nA spectral domain based approach uses a eigenvalue decomposition form of a graph Laplacian (a symmetric matrix) and learning a filter that acts on the eigenvalue of a graph Laplacian while preserving eigenvectors of a graph Laplacian.\nThis architecture is called the graph convolutional network on a spectral domain.\n\nThis paper's main contribution is to adapt octave convolutional network's architecture to the usual graph convolutional network. While I believe that this is the first work on applying the idea behind octave convolutional network architecture, separating low and high frequency component in the learning stage, to graph convolutional network architecture, I cannot see a good motivation on why this architecture is good for learning on a graph.\nA comprehensive study in the paper shows a better performance gain compared to the existing method, but it would be better if the gains were substantial or the authors presented a good motivation on why this architecture is good in some cases.\n\nOverall, I think the paper is well-written, but I would suggest to present more meaningful justification why and when the octave GCN is better than the GCN."}, "signatures": ["ICLR.cc/2020/Conference/Paper1209/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1209/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["changh17@mails.tsinghua.edu.cn", "yu.rong@hotmail.com", "sojoudi@berkeley.edu", "jzhuang@uta.edu", "wwzhu@tsinghua.edu.cn"], "title": "Octave Graph Convolutional Network", "authors": ["Heng Chang", "Yu Rong", "Somayeh Sojoudi", "Junzhou Huang", "Wenwu Zhu"], "pdf": "/pdf/36bf12ae5dc61232901a08399dd32de8f41584b8.pdf", "TL;DR": "Octave convolutional learning for graphs in spectral domain within the framework of Graph Convolutional Networks", "abstract": "Many variants of Graph Convolutional Networks (GCNs) for representation learning have been proposed recently and have achieved fruitful results in various domains. Among them, spectral-based GCNs are constructed via convolution theorem upon theoretical foundation from the perspective of Graph Signal Processing (GSP). However, despite most of them implicitly act as low-pass filters that generate smooth representations for each node, there is limited development on the full usage of underlying information from low-frequency. Here, we first introduce the octave convolution on graphs in spectral domain. Accordingly, we present Octave Graph Convolutional Network (OctGCN), a novel architecture that learns representations for different frequency components regarding to weighted filters and graph wavelets bases. We empirically validate the importance of low-frequency components in graph signals on semi-supervised node classification and demonstrate that our model achieves state-of-the-art performance in comparison with both spectral-based and spatial-based baselines.", "keywords": ["Graph Convolutional Networks", "Octave Convolution", "Graph Mining"], "paperhash": "chang|octave_graph_convolutional_network", "original_pdf": "/attachment/8232be9e118cc041b103b61b103b77009e76d36d.pdf", "_bibtex": "@misc{\nchang2020octave,\ntitle={Octave Graph Convolutional Network},\nauthor={Heng Chang and Yu Rong and Somayeh Sojoudi and Junzhou Huang and Wenwu Zhu},\nyear={2020},\nurl={https://openreview.net/forum?id=HkxSOAEFDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HkxSOAEFDB", "replyto": "HkxSOAEFDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1209/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1209/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575088023962, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1209/Reviewers"], "noninvitees": [], "tcdate": 1570237740723, "tmdate": 1575088023974, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1209/-/Official_Review"}}}, {"id": "BJgIcnIOcB", "original": null, "number": 3, "cdate": 1572527245739, "ddate": null, "tcdate": 1572527245739, "tmdate": 1572972498621, "tddate": null, "forum": "HkxSOAEFDB", "replyto": "HkxSOAEFDB", "invitation": "ICLR.cc/2020/Conference/Paper1209/-/Official_Review", "content": {"rating": "3: Weak Reject", "experience_assessment": "I have published in this field for several years.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #1", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This paper extends the previous graph wavelet neural network with separate computation for low frequency and high frequency part. The idea is to bring the octave convolution in vision to the graph domain. Experiments on three benchmark node classification tasks show comparable performances as previous methods. \n\nOverall the paper is written in a coherent and self-contained way, where the paper clearly states the related work and the contribution of this newly proposed work. Also it is interesting to see that normalizing the diagonal filter, tying the weights for low/high frequency parts would make the generalization better. However, there are several major concerns with the paper:\n\n1. The contribution is somewhat limited. The main component is based on GWNN. While the GWNN itself takes the full spectrum of basis already, the formulation in (8) and (9) should somehow capture the same information. I think the paper spends too much content on the reviews, while lacks the intuition or theoretical explanations of the proposed formulation. \n\n2. Having marginal improvement on the three benchmarks is not that interesting. Also given the results are mixed with other baselines, I think more experiments (e.g., on large graphs, or graph-level supervised tasks, etc.) are necessary to demonstrate the empirical gain using the proposed formulation. \n\n3. Regarding the experiments, is it true that d/n=0 and d/n=1 should have exactly the same results? \n\n4. In Figure 2, I guess d/n=0 should be reduced to the GWNN. But it seems the performance is different than GWNN on citeseer and cora. Why there\u2019s such inconsistency, or did I miss anything? "}, "signatures": ["ICLR.cc/2020/Conference/Paper1209/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1209/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["changh17@mails.tsinghua.edu.cn", "yu.rong@hotmail.com", "sojoudi@berkeley.edu", "jzhuang@uta.edu", "wwzhu@tsinghua.edu.cn"], "title": "Octave Graph Convolutional Network", "authors": ["Heng Chang", "Yu Rong", "Somayeh Sojoudi", "Junzhou Huang", "Wenwu Zhu"], "pdf": "/pdf/36bf12ae5dc61232901a08399dd32de8f41584b8.pdf", "TL;DR": "Octave convolutional learning for graphs in spectral domain within the framework of Graph Convolutional Networks", "abstract": "Many variants of Graph Convolutional Networks (GCNs) for representation learning have been proposed recently and have achieved fruitful results in various domains. Among them, spectral-based GCNs are constructed via convolution theorem upon theoretical foundation from the perspective of Graph Signal Processing (GSP). However, despite most of them implicitly act as low-pass filters that generate smooth representations for each node, there is limited development on the full usage of underlying information from low-frequency. Here, we first introduce the octave convolution on graphs in spectral domain. Accordingly, we present Octave Graph Convolutional Network (OctGCN), a novel architecture that learns representations for different frequency components regarding to weighted filters and graph wavelets bases. We empirically validate the importance of low-frequency components in graph signals on semi-supervised node classification and demonstrate that our model achieves state-of-the-art performance in comparison with both spectral-based and spatial-based baselines.", "keywords": ["Graph Convolutional Networks", "Octave Convolution", "Graph Mining"], "paperhash": "chang|octave_graph_convolutional_network", "original_pdf": "/attachment/8232be9e118cc041b103b61b103b77009e76d36d.pdf", "_bibtex": "@misc{\nchang2020octave,\ntitle={Octave Graph Convolutional Network},\nauthor={Heng Chang and Yu Rong and Somayeh Sojoudi and Junzhou Huang and Wenwu Zhu},\nyear={2020},\nurl={https://openreview.net/forum?id=HkxSOAEFDB}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "HkxSOAEFDB", "replyto": "HkxSOAEFDB", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1209/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1209/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575088023962, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1209/Reviewers"], "noninvitees": [], "tcdate": 1570237740723, "tmdate": 1575088023974, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1209/-/Official_Review"}}}], "count": 8}