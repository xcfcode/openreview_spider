{"notes": [{"tddate": null, "replyto": null, "ddate": null, "tmdate": 1528124432548, "tcdate": 1518472931105, "number": 352, "cdate": 1518472931105, "id": "Sksy1ckvG", "invitation": "ICLR.cc/2018/Workshop/-/Submission", "forum": "Sksy1ckvG", "signatures": ["~Cheng-Zhi_Anna_Huang1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop"], "content": {"title": "Towards Mixed-initiative generation of multi-channel sequential structure", "abstract": "We argue for the benefit of designing deep generative models through a mixed-initiative, co-creative combination of deep learning algorithms and human specifications, focusing on multi-channel music composition.  Sequence models have shown convincing results in domains such as summarization and translation; however, longer-term structure remains a major challenge. Given lengthy inputs and outputs, deep generative systems still lack reliable representations of beginnings, middles, and ends, which are standard aspects of creating content in domains such as music composition. This paper aims to contribute a framework for mixed-initiative generation approaches that let humans both supply and control some of these aspects in deep generative models for music, and present a case study of Counterpoint by Convolutional Neural Network (CoCoNet). ", "paperhash": "huang|towards_mixedinitiative_generation_of_multichannel_sequential_structure", "keywords": ["Mixed-initiative", "Deep generative models", "human-in-the-loop"], "_bibtex": "@misc{\n  huang2018towards,\n  title={Towards Mixed-initiative generation of multi-channel sequential structure},\n  author={Cheng-Zhi Anna Huang and Sherol Chen and Mark Nelson and Douglas Eck},\n  year={2018},\n  url={https://openreview.net/forum?id=Sksy1ckvG}\n}", "authorids": ["annahuang@google.com", "sherol@google.com", "mjn@anadrome.org", "deck@google.com"], "authors": ["Cheng-Zhi Anna Huang", "Sherol Chen", "Mark Nelson", "Douglas Eck"], "TL;DR": "We argue for the benefit of designing deep generative models through a mixed-initiative, co-creative combination of deep learning algorithms and human specifications, focusing on multi-channel music composition. ", "pdf": "/pdf/837fe38f880a148092846c9d941b0168691f7d64.pdf"}, "nonreaders": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1518472800000, "tmdate": 1518474081690, "id": "ICLR.cc/2018/Workshop/-/Submission", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Workshop"]}, "signatures": {"values-regex": "~.*|ICLR.cc/2018/Workshop", "description": "Your authorized identity to be associated with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 9, "value-regex": "upload", "description": "Upload a PDF file that ends with .pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 8, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names. Please provide real names; identities will be anonymized."}, "keywords": {"order": 6, "values-regex": "(^$)|[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of keywords."}, "TL;DR": {"required": false, "order": 7, "description": "\"Too Long; Didn't Read\": a short sentence describing your paper", "value-regex": "[^\\n]{0,500}"}, "authorids": {"required": true, "order": 3, "values-regex": "([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,},){0,}([a-z0-9_\\-\\.]{2,}@[a-z0-9_\\-\\.]{2,}\\.[a-z]{2,})", "description": "Comma separated list of author email addresses, lowercased, in the same order as above. For authors with existing OpenReview accounts, please make sure that the provided email address(es) match those listed in the author's profile. Please provide real emails; identities will be anonymized."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1526248800000, "cdate": 1518474081690}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582986383, "tcdate": 1519683097571, "number": 1, "cdate": 1519683097571, "id": "HyM7UbMuz", "invitation": "ICLR.cc/2018/Workshop/-/Paper352/Official_Review", "forum": "Sksy1ckvG", "replyto": "Sksy1ckvG", "signatures": ["ICLR.cc/2018/Workshop/Paper352/AnonReviewer4"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper352/AnonReviewer4"], "content": {"title": "one of the official reviews", "rating": "8: Top 50% of accepted papers, clear accept", "review": "This workshop contribution examines a mixed-initiative approach to human-computer interaction via turns between human and computer, with application to music composition.  In particular, the computational creativity aspect is accomplished via CoCoNet.  \n\nThis is a very important topic of inquiry because computational creativity is and will continue to be a critical branch of artificial intelligence for society, whether it is in creating novel music, text, or molecules.  The human interaction is just as critical as the authors excellently justify.  These topics should be discussed at ICLR to help ensure the field moves towards creativity research.\n\nThe general concept of mixed-initiative co-creation is not new (and it is not claimed to be either).  The novel contribution in this work is expanding on CoCoNet for this regime.  \n\nThe paper is well written for the amount of allocated space.  \n\nSome form of evaluation of the results would be appreciated.  It might also be good to briefly discuss other hierarchical machine learning approaches for music, e.g. https://openreview.net/pdf?id=ryhqQFKgl.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Mixed-initiative generation of multi-channel sequential structure", "abstract": "We argue for the benefit of designing deep generative models through a mixed-initiative, co-creative combination of deep learning algorithms and human specifications, focusing on multi-channel music composition.  Sequence models have shown convincing results in domains such as summarization and translation; however, longer-term structure remains a major challenge. Given lengthy inputs and outputs, deep generative systems still lack reliable representations of beginnings, middles, and ends, which are standard aspects of creating content in domains such as music composition. This paper aims to contribute a framework for mixed-initiative generation approaches that let humans both supply and control some of these aspects in deep generative models for music, and present a case study of Counterpoint by Convolutional Neural Network (CoCoNet). ", "paperhash": "huang|towards_mixedinitiative_generation_of_multichannel_sequential_structure", "keywords": ["Mixed-initiative", "Deep generative models", "human-in-the-loop"], "_bibtex": "@misc{\n  huang2018towards,\n  title={Towards Mixed-initiative generation of multi-channel sequential structure},\n  author={Cheng-Zhi Anna Huang and Sherol Chen and Mark Nelson and Douglas Eck},\n  year={2018},\n  url={https://openreview.net/forum?id=Sksy1ckvG}\n}", "authorids": ["annahuang@google.com", "sherol@google.com", "mjn@anadrome.org", "deck@google.com"], "authors": ["Cheng-Zhi Anna Huang", "Sherol Chen", "Mark Nelson", "Douglas Eck"], "TL;DR": "We argue for the benefit of designing deep generative models through a mixed-initiative, co-creative combination of deep learning algorithms and human specifications, focusing on multi-channel music composition. ", "pdf": "/pdf/837fe38f880a148092846c9d941b0168691f7d64.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582986203, "id": "ICLR.cc/2018/Workshop/-/Paper352/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper352/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper352/AnonReviewer4", "ICLR.cc/2018/Workshop/Paper352/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper352/AnonReviewer1"], "reply": {"forum": "Sksy1ckvG", "replyto": "Sksy1ckvG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper352/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper352/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582986203}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582859361, "tcdate": 1520564712288, "number": 2, "cdate": 1520564712288, "id": "HJel5_ytz", "invitation": "ICLR.cc/2018/Workshop/-/Paper352/Official_Review", "forum": "Sksy1ckvG", "replyto": "Sksy1ckvG", "signatures": ["ICLR.cc/2018/Workshop/Paper352/AnonReviewer3"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper352/AnonReviewer3"], "content": {"title": "A good framework with a good example for human-machine collaborative creativity", "rating": "7: Good paper, accept", "review": "This position paper proposes thinking about the task of human-machine collaboration in creative endeavors along the axes of initiative and the types of controls the human is given in the interaction.  It provides a concrete example of such a system in CoCoNet and the ways that it can be used for tasks in different locations on these axes.  CoCoNet was recently introduced at ISMIR 2017 and is a model inspired by NADE, but over a piano roll representation of a musical score.  Instead of generating music sequentially, it provides a mechanism by which a creation or parts of it can be iteratively refined.  The user-control axis in this case is the types of modifications the user makes to this shared score representation, to the melody, harmony, or leaving blanks to be filled in by the model.  The initiative axis is controlled by when and how the human modification of the score is interleaved with the model's new proposals.\n\nOne issue that was not clear in the paper is the novelty of this perspective.  It states that there is a \"large literature on mixed-initiative and co-creative systems\" so it seems that th novelty is in applying this to deep generative models of music, but this could perhaps be stated more explicitly.\n\nOverall, this is an interesting perspective with a compelling concrete example that can help conceptualize these kinds of collaborations between humans and generative models.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Mixed-initiative generation of multi-channel sequential structure", "abstract": "We argue for the benefit of designing deep generative models through a mixed-initiative, co-creative combination of deep learning algorithms and human specifications, focusing on multi-channel music composition.  Sequence models have shown convincing results in domains such as summarization and translation; however, longer-term structure remains a major challenge. Given lengthy inputs and outputs, deep generative systems still lack reliable representations of beginnings, middles, and ends, which are standard aspects of creating content in domains such as music composition. This paper aims to contribute a framework for mixed-initiative generation approaches that let humans both supply and control some of these aspects in deep generative models for music, and present a case study of Counterpoint by Convolutional Neural Network (CoCoNet). ", "paperhash": "huang|towards_mixedinitiative_generation_of_multichannel_sequential_structure", "keywords": ["Mixed-initiative", "Deep generative models", "human-in-the-loop"], "_bibtex": "@misc{\n  huang2018towards,\n  title={Towards Mixed-initiative generation of multi-channel sequential structure},\n  author={Cheng-Zhi Anna Huang and Sherol Chen and Mark Nelson and Douglas Eck},\n  year={2018},\n  url={https://openreview.net/forum?id=Sksy1ckvG}\n}", "authorids": ["annahuang@google.com", "sherol@google.com", "mjn@anadrome.org", "deck@google.com"], "authors": ["Cheng-Zhi Anna Huang", "Sherol Chen", "Mark Nelson", "Douglas Eck"], "TL;DR": "We argue for the benefit of designing deep generative models through a mixed-initiative, co-creative combination of deep learning algorithms and human specifications, focusing on multi-channel music composition. ", "pdf": "/pdf/837fe38f880a148092846c9d941b0168691f7d64.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582986203, "id": "ICLR.cc/2018/Workshop/-/Paper352/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper352/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper352/AnonReviewer4", "ICLR.cc/2018/Workshop/Paper352/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper352/AnonReviewer1"], "reply": {"forum": "Sksy1ckvG", "replyto": "Sksy1ckvG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper352/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper352/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582986203}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521582715888, "tcdate": 1520686917361, "number": 3, "cdate": 1520686917361, "id": "rkTSvUWYz", "invitation": "ICLR.cc/2018/Workshop/-/Paper352/Official_Review", "forum": "Sksy1ckvG", "replyto": "Sksy1ckvG", "signatures": ["ICLR.cc/2018/Workshop/Paper352/AnonReviewer1"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Paper352/AnonReviewer1"], "content": {"title": "Sensible objective, but technical contents are thin", "rating": "3: Clear rejection", "review": "This paper proposes an architecture of \"humans-in-the-loop\" for generating\nmulti-channel structures such as music.\nFor this purpose, the authors propose COCONET that executes automatic partial\nscore completion as an orderless NADE, and works like a Gibbs sampler.\n\nI appreciate the objective and architectures of the proposed method. Indeed,\ngeneration of such multi-channel structure is not well studied and will be an\nimportant research area in the near future. However, this paper lacks neither\ntechnical descriptions of the proposed COCONET nor comparison with previous \nattempts for music generation. Lacking of description of technical difference\nfrom previous research, I cannot see this paper to be accepted as ICLR even as\na workshop paper.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Mixed-initiative generation of multi-channel sequential structure", "abstract": "We argue for the benefit of designing deep generative models through a mixed-initiative, co-creative combination of deep learning algorithms and human specifications, focusing on multi-channel music composition.  Sequence models have shown convincing results in domains such as summarization and translation; however, longer-term structure remains a major challenge. Given lengthy inputs and outputs, deep generative systems still lack reliable representations of beginnings, middles, and ends, which are standard aspects of creating content in domains such as music composition. This paper aims to contribute a framework for mixed-initiative generation approaches that let humans both supply and control some of these aspects in deep generative models for music, and present a case study of Counterpoint by Convolutional Neural Network (CoCoNet). ", "paperhash": "huang|towards_mixedinitiative_generation_of_multichannel_sequential_structure", "keywords": ["Mixed-initiative", "Deep generative models", "human-in-the-loop"], "_bibtex": "@misc{\n  huang2018towards,\n  title={Towards Mixed-initiative generation of multi-channel sequential structure},\n  author={Cheng-Zhi Anna Huang and Sherol Chen and Mark Nelson and Douglas Eck},\n  year={2018},\n  url={https://openreview.net/forum?id=Sksy1ckvG}\n}", "authorids": ["annahuang@google.com", "sherol@google.com", "mjn@anadrome.org", "deck@google.com"], "authors": ["Cheng-Zhi Anna Huang", "Sherol Chen", "Mark Nelson", "Douglas Eck"], "TL;DR": "We argue for the benefit of designing deep generative models through a mixed-initiative, co-creative combination of deep learning algorithms and human specifications, focusing on multi-channel music composition. ", "pdf": "/pdf/837fe38f880a148092846c9d941b0168691f7d64.pdf"}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1520657999000, "tmdate": 1521582986203, "id": "ICLR.cc/2018/Workshop/-/Paper352/Official_Review", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Paper352/Reviewers"], "noninvitees": ["ICLR.cc/2018/Workshop/Paper352/AnonReviewer4", "ICLR.cc/2018/Workshop/Paper352/AnonReviewer3", "ICLR.cc/2018/Workshop/Paper352/AnonReviewer1"], "reply": {"forum": "Sksy1ckvG", "replyto": "Sksy1ckvG", "writers": {"values-regex": "ICLR.cc/2018/Workshop/Paper352/AnonReviewer[0-9]+"}, "signatures": {"values-regex": "ICLR.cc/2018/Workshop/Paper352/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1528433999000, "cdate": 1521582986203}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1521573559596, "tcdate": 1521573559596, "number": 73, "cdate": 1521573559253, "id": "HJgp0RCKM", "invitation": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "forum": "Sksy1ckvG", "replyto": "Sksy1ckvG", "signatures": ["ICLR.cc/2018/Workshop/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Workshop/Program_Chairs"], "content": {"decision": "Accept", "title": "ICLR 2018 Workshop Acceptance Decision", "comment": "Congratulations, your paper was accepted to the ICLR workshop."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Towards Mixed-initiative generation of multi-channel sequential structure", "abstract": "We argue for the benefit of designing deep generative models through a mixed-initiative, co-creative combination of deep learning algorithms and human specifications, focusing on multi-channel music composition.  Sequence models have shown convincing results in domains such as summarization and translation; however, longer-term structure remains a major challenge. Given lengthy inputs and outputs, deep generative systems still lack reliable representations of beginnings, middles, and ends, which are standard aspects of creating content in domains such as music composition. This paper aims to contribute a framework for mixed-initiative generation approaches that let humans both supply and control some of these aspects in deep generative models for music, and present a case study of Counterpoint by Convolutional Neural Network (CoCoNet). ", "paperhash": "huang|towards_mixedinitiative_generation_of_multichannel_sequential_structure", "keywords": ["Mixed-initiative", "Deep generative models", "human-in-the-loop"], "_bibtex": "@misc{\n  huang2018towards,\n  title={Towards Mixed-initiative generation of multi-channel sequential structure},\n  author={Cheng-Zhi Anna Huang and Sherol Chen and Mark Nelson and Douglas Eck},\n  year={2018},\n  url={https://openreview.net/forum?id=Sksy1ckvG}\n}", "authorids": ["annahuang@google.com", "sherol@google.com", "mjn@anadrome.org", "deck@google.com"], "authors": ["Cheng-Zhi Anna Huang", "Sherol Chen", "Mark Nelson", "Douglas Eck"], "TL;DR": "We argue for the benefit of designing deep generative models through a mixed-initiative, co-creative combination of deep learning algorithms and human specifications, focusing on multi-channel music composition. ", "pdf": "/pdf/837fe38f880a148092846c9d941b0168691f7d64.pdf"}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1518629844880, "id": "ICLR.cc/2018/Workshop/-/Acceptance_Decision", "writers": ["ICLR.cc/2018/Workshop"], "signatures": ["ICLR.cc/2018/Workshop"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Workshop/Program_Chairs"], "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Workshop/-/Submission", "writers": {"values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Workshop/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Workshop/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Workshop Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept", "Reject"]}}}, "nonreaders": [], "noninvitees": [], "cdate": 1518629844880}}}], "count": 5}