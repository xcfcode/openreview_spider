{"notes": [{"id": "o7YTArVXdEW", "original": "Fm7QhA7axdy", "number": 3268, "cdate": 1601308362972, "ddate": null, "tcdate": 1601308362972, "tmdate": 1614985647367, "tddate": null, "forum": "o7YTArVXdEW", "replyto": null, "invitation": "ICLR.cc/2021/Conference/-/Blind_Submission", "content": {"title": "AC-VAE: Learning Semantic Representation with VAE for Adaptive Clustering", "authorids": ["~Xingyu_Xie2", "~Minjuan_Zhu1", "~Yan_Wang13", "~Lei_Zhang25"], "authors": ["Xingyu Xie", "Minjuan Zhu", "Yan Wang", "Lei Zhang"], "keywords": ["Unsupervised Representation Learning", "Neighbor Clustering", "Variational Autoencoder", "Unsupervised Classification"], "abstract": "Unsupervised representation learning is essential in the field of machine learning, and accurate neighbor clusters of representation show great potential to support unsupervised image classification. This paper proposes a VAE (Variational Autoencoder) based network and a clustering method to achieve adaptive neighbor clustering to support the self-supervised classification. The proposed network encodes the image into the representation with boundary information, and the proposed cluster method takes advantage of the boundary information to deliver adaptive neighbor cluster results.  Experimental evaluations show that the proposed method outperforms state-of-the-art representation learning methods in terms of neighbor clustering accuracy. Particularly, AC-VAE achieves 95\\% and 82\\% accuracy on CIFAR10 dataset when the average neighbor cluster sizes are 10 and 100. Furthermore, the neighbor cluster results are found converge within the clustering range ($\\alpha\\leq2$), and the converged neighbor clusters are used to support the self-supervised classification. The proposed method delivers classification results that are competitive with the state-of-the-art and reduces the super parameter $k$ in KNN (K-nearest neighbor), which is often used in self-supervised classification.", "one-sentence_summary": "This paper proposes a VAE based network and a z-score based clustering method to achieve adaptive neighbor clustering for supporting unsupervised classification.", "pdf": "/pdf/90d844e0df148c0ff7e2b38052bb2042f9f0450a.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xie|acvae_learning_semantic_representation_with_vae_for_adaptive_clustering", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=8DV4WJpLw2", "_bibtex": "@misc{\nxie2021acvae,\ntitle={{\\{}AC{\\}}-{\\{}VAE{\\}}: Learning Semantic Representation with {\\{}VAE{\\}} for Adaptive Clustering},\nauthor={Xingyu Xie and Minjuan Zhu and Yan Wang and Lei Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=o7YTArVXdEW}\n}"}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2021/Conference"]}, "signatures": {"values": ["ICLR.cc/2021/Conference"]}, "content": {"authors": {"values": ["Anonymous"]}, "authorids": {"values-regex": ".*"}, "reviewed_version_(pdf)": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}}}, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["~", "OpenReview.net/Support"], "tcdate": 1601308008205, "tmdate": 1614984599368, "id": "ICLR.cc/2021/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "vBSXJT2chX5", "original": null, "number": 1, "cdate": 1610040515059, "ddate": null, "tcdate": 1610040515059, "tmdate": 1610474123241, "tddate": null, "forum": "o7YTArVXdEW", "replyto": "o7YTArVXdEW", "invitation": "ICLR.cc/2021/Conference/Paper3268/-/Decision", "content": {"title": "Final Decision", "decision": "Reject", "comment": "This paper addresses automatically learning the neighborhood size (they call adaptive neighbor support) for unsupervised representation learning with a VAE.  The neighborhood size is determined based on z-scores from by estimating a normal distribution in the latent space. \n\nThe paper is poorly written.  There are several grammatical errors and typos that distracts from understanding the paper.  In addition, the use of terminology is not precise, which adds to the confusion, as pointed out by the reviewers.\n\nAC-VAE is better than VAE+KNN in Table 1 but worse in SCAN with KNN in Table 3.  Further analysis to understand why this is so is needed.\n\nAdditional measures of cluster quality is recommended.\n\nAs pointed out by the reviewers, this paper is below the acceptance threshold for ICLR.  The reviewers provided several constructive suggestions.  Please refer to detailed reviewer comments to help you improve your paper.\n"}, "signatures": ["ICLR.cc/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AC-VAE: Learning Semantic Representation with VAE for Adaptive Clustering", "authorids": ["~Xingyu_Xie2", "~Minjuan_Zhu1", "~Yan_Wang13", "~Lei_Zhang25"], "authors": ["Xingyu Xie", "Minjuan Zhu", "Yan Wang", "Lei Zhang"], "keywords": ["Unsupervised Representation Learning", "Neighbor Clustering", "Variational Autoencoder", "Unsupervised Classification"], "abstract": "Unsupervised representation learning is essential in the field of machine learning, and accurate neighbor clusters of representation show great potential to support unsupervised image classification. This paper proposes a VAE (Variational Autoencoder) based network and a clustering method to achieve adaptive neighbor clustering to support the self-supervised classification. The proposed network encodes the image into the representation with boundary information, and the proposed cluster method takes advantage of the boundary information to deliver adaptive neighbor cluster results.  Experimental evaluations show that the proposed method outperforms state-of-the-art representation learning methods in terms of neighbor clustering accuracy. Particularly, AC-VAE achieves 95\\% and 82\\% accuracy on CIFAR10 dataset when the average neighbor cluster sizes are 10 and 100. Furthermore, the neighbor cluster results are found converge within the clustering range ($\\alpha\\leq2$), and the converged neighbor clusters are used to support the self-supervised classification. The proposed method delivers classification results that are competitive with the state-of-the-art and reduces the super parameter $k$ in KNN (K-nearest neighbor), which is often used in self-supervised classification.", "one-sentence_summary": "This paper proposes a VAE based network and a z-score based clustering method to achieve adaptive neighbor clustering for supporting unsupervised classification.", "pdf": "/pdf/90d844e0df148c0ff7e2b38052bb2042f9f0450a.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xie|acvae_learning_semantic_representation_with_vae_for_adaptive_clustering", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=8DV4WJpLw2", "_bibtex": "@misc{\nxie2021acvae,\ntitle={{\\{}AC{\\}}-{\\{}VAE{\\}}: Learning Semantic Representation with {\\{}VAE{\\}} for Adaptive Clustering},\nauthor={Xingyu Xie and Minjuan Zhu and Yan Wang and Lei Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=o7YTArVXdEW}\n}"}, "tags": [], "invitation": {"reply": {"forum": "o7YTArVXdEW", "replyto": "o7YTArVXdEW", "readers": {"values": ["everyone"]}, "writers": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2021/Conference/Program_Chairs"]}, "content": {"title": {"value": "Final Decision"}, "decision": {"value-radio": ["Accept (Oral)", "Accept (Spotlight)", "Accept (Poster)", "Reject"]}, "comment": {"value-regex": "[\\S\\s]{0,50000}", "markdown": true}}}, "multiReply": false, "signatures": ["ICLR.cc/2021/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Program_Chairs"], "tcdate": 1610040515046, "tmdate": 1610474123226, "id": "ICLR.cc/2021/Conference/Paper3268/-/Decision"}}}, {"id": "ajd0eJ-sTQp", "original": null, "number": 1, "cdate": 1603901152191, "ddate": null, "tcdate": 1603901152191, "tmdate": 1605024033242, "tddate": null, "forum": "o7YTArVXdEW", "replyto": "o7YTArVXdEW", "invitation": "ICLR.cc/2021/Conference/Paper3268/-/Official_Review", "content": {"title": "Promising work towards image clustering may benefit from a more clear presentation and precise terminology.", "review": "Summary of the paper:\n\nThis paper proposes an encoder-decoder architecture for clustering images based on their semantic (high-level) features as well as creating a semantic representation for downstream tasks. The model takes as a basis the encoder part of a variational auto-encoder (VAE) and uses the properties of the distributions induced in the latent space to define cluster boundaries and avoiding the need of setting the parameter K (number of clusters), usually required in methods based on K-Means. In order to induce the encoder to focus on high-level features, a decoder loss based on consistency regulation is defined, which aims at mapping variations of each image, obtained by data augmentation transformations, to similar decoded representation.\n\nQuestions and Suggestions:\n\nShouldn\u2019t be abs(mu_i - x_j) In Equation (3)?\n\nz-scores are usually defined as (mu-x)/std. However, in Equation (3), defining d(x_i, x_j), there is a \u201c-0.5\u201d term. Although this equation is supposed to represent a distance, it can result in negative values when abs(mu_i-mu_j) is small. I suggest removing this term and compare the result against 0.5 instead of 0.0. Also, include the 2 in the denominator in the alpha parameter and make it range in [0.0, 1.0] instead of [-2.0, 2.0].\n\nEquation (2) is not an equation, since it has no equal sign. As it defines a loss function, I suggest using equality to introduce a symbol defining the loss.\n\nExplain Figure 2 in the caption, indicating what the terms mean as well as the doted and solid lines.\n\nFix typos: \n\u201cargumentations\u201d -> \u201caugmentations\u201d (section 3.1)\n\u201cCompression\u201d -> \u201cComparison\u201d (section 3.2)\n\nPros:\n\nThe paper is focusing on important problems in the field of representation learning.\nIt presents good clustering accuracy results in challenging datasets\nIt seems to boost self-supervised classification.\n\nCons:\n\nThe presentation and clarity of the article should be better and it would benefit from a review of the English\n\nThe use of terminology is not precise, leaving the reader oftentimes confused about what is meant. To give a few examples:\n- \u201cAutoencoders\u201d: The architecture does not map inputs to inputs themselves, so strictly speaking it is not an AE model.\n- \u201cAdaptive Clustering\u201d: This can mean different things in the literature, for instance, it is also used to mean methods that deal with non-static distributions. But in the article, the term is not clearly defined and just means establishing the number of clusters.\n\n- The use of the words neighbor/neighborhoods: is confusing: \u201cneighbor cluster performance\u201d: is this evaluating the capacity of the model to map similar clusters close to each other (making them neighbors) or of mapping similar samples close to each other  (regular clustering evaluation). Also, \u201cneighbor cluster accuracy\u201d: Is this the same as \u201cClustering Accuracy\u201d, a standard metric to evaluate clustering methods, or is this evaluating something else? How is it computed? \n\n- Define what these terms mean: \u201cBehaviour Pattern\u201d, \u201cRoot of cluster\u201d, \u201cSimilar flow as the root\u201d\n\nThe review of the literature misses some important articles, which should also be compared with in the experiments:\nVincent Fortuin et al, 2019 \u201cSOM-VAE: Interpretable Discrete Representation Learning on Time Series\u201d\nFlorent Forest et al 2019 \u201cDeep Embedded SOM: Joint Representation Learning and Self-Organization\u201d\n\nEvaluating Clustering is tricky and the use of only one metric is usually not enough and misleading. I suggest including other metrics such as Normalized Mutual Information and Purity to make the evaluation more sound.\n\nThe use of only CIFAR in evaluation is also a problem, as clustering datasets usually present a great variability with different methods. Other papers also consider MNIST and FASHION MNIST, for instance.\n\nThe article replaces the parameter K with two other parameters: alpha and theta. Although it states that these parameters are easier to adjust than K, the experiments are not enough to show that, It is missing especially one experiment evaluating the results of other methods with different values of K. It can be the case that with K high enough other methods will produce similar results in downstream tasks.\n\nHow many clusters the does method find? Is it the expected number? This is not covered by clustering accuracy.\n\nConclusion:\n\nAlthough the paper is interesting and has some novelty aspects, I am not convinced about the soundness of the results due to the lack of evaluation with other metrics and different datasets. Also, I believe that other similar methods, mentioned above, should be included in the comparison. Finally, experiments showing that alpha and theta are easier to adjust than K are needed.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3268/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3268/AnonReviewer4"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AC-VAE: Learning Semantic Representation with VAE for Adaptive Clustering", "authorids": ["~Xingyu_Xie2", "~Minjuan_Zhu1", "~Yan_Wang13", "~Lei_Zhang25"], "authors": ["Xingyu Xie", "Minjuan Zhu", "Yan Wang", "Lei Zhang"], "keywords": ["Unsupervised Representation Learning", "Neighbor Clustering", "Variational Autoencoder", "Unsupervised Classification"], "abstract": "Unsupervised representation learning is essential in the field of machine learning, and accurate neighbor clusters of representation show great potential to support unsupervised image classification. This paper proposes a VAE (Variational Autoencoder) based network and a clustering method to achieve adaptive neighbor clustering to support the self-supervised classification. The proposed network encodes the image into the representation with boundary information, and the proposed cluster method takes advantage of the boundary information to deliver adaptive neighbor cluster results.  Experimental evaluations show that the proposed method outperforms state-of-the-art representation learning methods in terms of neighbor clustering accuracy. Particularly, AC-VAE achieves 95\\% and 82\\% accuracy on CIFAR10 dataset when the average neighbor cluster sizes are 10 and 100. Furthermore, the neighbor cluster results are found converge within the clustering range ($\\alpha\\leq2$), and the converged neighbor clusters are used to support the self-supervised classification. The proposed method delivers classification results that are competitive with the state-of-the-art and reduces the super parameter $k$ in KNN (K-nearest neighbor), which is often used in self-supervised classification.", "one-sentence_summary": "This paper proposes a VAE based network and a z-score based clustering method to achieve adaptive neighbor clustering for supporting unsupervised classification.", "pdf": "/pdf/90d844e0df148c0ff7e2b38052bb2042f9f0450a.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xie|acvae_learning_semantic_representation_with_vae_for_adaptive_clustering", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=8DV4WJpLw2", "_bibtex": "@misc{\nxie2021acvae,\ntitle={{\\{}AC{\\}}-{\\{}VAE{\\}}: Learning Semantic Representation with {\\{}VAE{\\}} for Adaptive Clustering},\nauthor={Xingyu Xie and Minjuan Zhu and Yan Wang and Lei Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=o7YTArVXdEW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "o7YTArVXdEW", "replyto": "o7YTArVXdEW", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3268/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538078902, "tmdate": 1606915804347, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3268/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3268/-/Official_Review"}}}, {"id": "uy6XbDuWMzc", "original": null, "number": 2, "cdate": 1603913242303, "ddate": null, "tcdate": 1603913242303, "tmdate": 1605024033173, "tddate": null, "forum": "o7YTArVXdEW", "replyto": "o7YTArVXdEW", "invitation": "ICLR.cc/2021/Conference/Paper3268/-/Official_Review", "content": {"title": "Official Blind Review #1", "review": "This paper proposes an adaptive neighbor clustering method by estimating normal distribution on the representation space. The proposed neighbor clustering can utilize the acceptable range for each dimension of each instance from the estimated variance, which leads to different size of neighbors for each instance, and improved the neighbor clustering performances. In addition, the proposed neighbor clustering method can replace the KNN-based neighbor clustering in the previous SCAN (Semantic Clustering by Adopting Nearest neighbors) framework for image semantic clustering.\n\nOverall, the paper is hard to follow and understand with many typos, incorrect notations, and especially the main term, VAE. Why can it be called VAE without a decoder which decodes some original input from a compact representation? I think the proposed network contains only the encoder (transforming z to r is also encoding), and it applies the stochastic process in the middle of encoder (512-d z instead of 64-d r). Therefore, it seems that the proposed training can be considered as the previous contrastive learning with stochastic regularization. And, it naturally raises the question that why not imposing the normal distribution on the final representation r? In addition, I do not understand why the sum of the sampled z and \\mu is fed into for obtaining r. What if z is solely fed into? What is v in Eq. (1)? Is it d \\circ e? How to explicitly connect Eq. (1) and (2)?\n\nIn Table 3, The clustering performance drop of SCAN with AC-VAE is not marginal compared to the previous SCAN with KNN, even though the proposed AC-VAE seems to produce significantly improved neighbor clustering results in Table 1. However, there is no analysis on this.\n\nThe amortized inference of normal distribution on the (middle of) representation space, and the use of its estimated variance in obtaining reliable neighbors for each instance seems to be make sense, however the motivation, insight, and contribution of the derived framework seem to be very limited.\n\nTypos: SLT -> STL, VEA -> VAE, argumentations -> augmentations, d(x_i, x_i) -> d(x_j, x_i)", "rating": "3: Clear rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3268/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3268/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AC-VAE: Learning Semantic Representation with VAE for Adaptive Clustering", "authorids": ["~Xingyu_Xie2", "~Minjuan_Zhu1", "~Yan_Wang13", "~Lei_Zhang25"], "authors": ["Xingyu Xie", "Minjuan Zhu", "Yan Wang", "Lei Zhang"], "keywords": ["Unsupervised Representation Learning", "Neighbor Clustering", "Variational Autoencoder", "Unsupervised Classification"], "abstract": "Unsupervised representation learning is essential in the field of machine learning, and accurate neighbor clusters of representation show great potential to support unsupervised image classification. This paper proposes a VAE (Variational Autoencoder) based network and a clustering method to achieve adaptive neighbor clustering to support the self-supervised classification. The proposed network encodes the image into the representation with boundary information, and the proposed cluster method takes advantage of the boundary information to deliver adaptive neighbor cluster results.  Experimental evaluations show that the proposed method outperforms state-of-the-art representation learning methods in terms of neighbor clustering accuracy. Particularly, AC-VAE achieves 95\\% and 82\\% accuracy on CIFAR10 dataset when the average neighbor cluster sizes are 10 and 100. Furthermore, the neighbor cluster results are found converge within the clustering range ($\\alpha\\leq2$), and the converged neighbor clusters are used to support the self-supervised classification. The proposed method delivers classification results that are competitive with the state-of-the-art and reduces the super parameter $k$ in KNN (K-nearest neighbor), which is often used in self-supervised classification.", "one-sentence_summary": "This paper proposes a VAE based network and a z-score based clustering method to achieve adaptive neighbor clustering for supporting unsupervised classification.", "pdf": "/pdf/90d844e0df148c0ff7e2b38052bb2042f9f0450a.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xie|acvae_learning_semantic_representation_with_vae_for_adaptive_clustering", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=8DV4WJpLw2", "_bibtex": "@misc{\nxie2021acvae,\ntitle={{\\{}AC{\\}}-{\\{}VAE{\\}}: Learning Semantic Representation with {\\{}VAE{\\}} for Adaptive Clustering},\nauthor={Xingyu Xie and Minjuan Zhu and Yan Wang and Lei Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=o7YTArVXdEW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "o7YTArVXdEW", "replyto": "o7YTArVXdEW", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3268/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538078902, "tmdate": 1606915804347, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3268/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3268/-/Official_Review"}}}, {"id": "Ca5ehvl9QwK", "original": null, "number": 3, "cdate": 1604666014615, "ddate": null, "tcdate": 1604666014615, "tmdate": 1605024033105, "tddate": null, "forum": "o7YTArVXdEW", "replyto": "o7YTArVXdEW", "invitation": "ICLR.cc/2021/Conference/Paper3268/-/Official_Review", "content": {"title": "Interesting idea, clarifications needed", "review": "The paper describes the approach  for clustering the image data using z-scores for semantic representation.\n\nWhile the method seems novel, there are questions to be clarified, and the final rating is dependent on the answers on those questions:\n\n1. The paper states that the method performs adaptive clustering. This statement needs clarification. From that claim I would generally expect that it means adapting to non-stationary data but it has apparently a different meaning in the context of the description of the method. Instead, as the reviewer can see from Figure 3, it is a z-score based cluster assignment. It is unclear what is the precise meaning behind the \u2018adaptive\u2019 quality. \n2. It is unclear what would happen if the same point is matched to different clusters. Would it be possible to formalise it all as an algorithm so that the described procedure is reproducible?\n3. Section 3.2 Besides, $d(x_i,x_j)$ may not be equal to $d(x_i,x_i)$. There is an apparent typo: should be $d(x_j,x_i)$?\n4. On section 4.4, while the prototypes are shown, it would also be important to see the examples of neighbours of the prototype by their increased distance.\n5. It is said in the discussion of the Eq 1 that *\" The consistency regulation can be performed by minimizing the behavior loss stated in Equation (1): $BL_x = d(r_i,r_i^\u2032) = d(v(x_i),v(T(x_i)))$ in which, $T(x_i)$ is the augmentation of image $x_i$, $r_i$ is the representation of $x_i$ generated by the proposed network $v(\\cdot)$, and $d(\\cdot)$ measures the distance of two representations.\u201d* It is not clear how exactly the augmentation of image is constructed and what distance is used. Could this loss function be described in more detail?\n\n6. For Table 1, the results are shown with specially selected parameters. As the comment goes that it is possible to do it without task-specific $\\alpha$ parameter, would it be possible to show these results for the common value of $\\alpha$?\n7. It is said in section 4.2 that *'With KNN clustering, the proposed method\u2019s accuracy is lower than the state-of-the-art, SimCLR. This is because the sampling process introduced by the proposed network creates uncertainty in the representation, which contributes the decline of accuracy.\u2019* As I understand, the stochastic representation is essential for the z-score (but not for KNN). Therefore, is there a way to support this claim by the ablation study, i.e. produce a deterministic (autoencoder based, for example) representation and see what the accuracy would be with the deterministic representation + KNN ?", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2021/Conference/Paper3268/AnonReviewer5"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2021/Conference", "ICLR.cc/2021/Conference/Paper3268/AnonReviewer5"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "AC-VAE: Learning Semantic Representation with VAE for Adaptive Clustering", "authorids": ["~Xingyu_Xie2", "~Minjuan_Zhu1", "~Yan_Wang13", "~Lei_Zhang25"], "authors": ["Xingyu Xie", "Minjuan Zhu", "Yan Wang", "Lei Zhang"], "keywords": ["Unsupervised Representation Learning", "Neighbor Clustering", "Variational Autoencoder", "Unsupervised Classification"], "abstract": "Unsupervised representation learning is essential in the field of machine learning, and accurate neighbor clusters of representation show great potential to support unsupervised image classification. This paper proposes a VAE (Variational Autoencoder) based network and a clustering method to achieve adaptive neighbor clustering to support the self-supervised classification. The proposed network encodes the image into the representation with boundary information, and the proposed cluster method takes advantage of the boundary information to deliver adaptive neighbor cluster results.  Experimental evaluations show that the proposed method outperforms state-of-the-art representation learning methods in terms of neighbor clustering accuracy. Particularly, AC-VAE achieves 95\\% and 82\\% accuracy on CIFAR10 dataset when the average neighbor cluster sizes are 10 and 100. Furthermore, the neighbor cluster results are found converge within the clustering range ($\\alpha\\leq2$), and the converged neighbor clusters are used to support the self-supervised classification. The proposed method delivers classification results that are competitive with the state-of-the-art and reduces the super parameter $k$ in KNN (K-nearest neighbor), which is often used in self-supervised classification.", "one-sentence_summary": "This paper proposes a VAE based network and a z-score based clustering method to achieve adaptive neighbor clustering for supporting unsupervised classification.", "pdf": "/pdf/90d844e0df148c0ff7e2b38052bb2042f9f0450a.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "paperhash": "xie|acvae_learning_semantic_representation_with_vae_for_adaptive_clustering", "reviewed_version_(pdf)": "https://openreview.net/references/pdf?id=8DV4WJpLw2", "_bibtex": "@misc{\nxie2021acvae,\ntitle={{\\{}AC{\\}}-{\\{}VAE{\\}}: Learning Semantic Representation with {\\{}VAE{\\}} for Adaptive Clustering},\nauthor={Xingyu Xie and Minjuan Zhu and Yan Wang and Lei Zhang},\nyear={2021},\nurl={https://openreview.net/forum?id=o7YTArVXdEW}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters). Add formatting using Markdown and formulas using LaTeX. For more information see https://openreview.net/faq . ***Please remember to file the Code-of-Ethics report. Once you submitted the review, a link to the report will be visible in the bottom right corner of your review.***", "required": true, "markdown": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}, "forum": "o7YTArVXdEW", "replyto": "o7YTArVXdEW", "readers": {"description": "Select all user groups that should be able to read this comment.", "values": ["everyone"]}, "nonreaders": {"values": []}, "writers": {"values-copied": ["ICLR.cc/2021/Conference", "{signatures}"], "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2021/Conference/Paper3268/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1607428800000, "duedate": 1606752000000, "multiReply": false, "readers": ["everyone"], "tcdate": 1602538078902, "tmdate": 1606915804347, "super": "ICLR.cc/2021/Conference/-/Official_Review", "signatures": ["OpenReview.net"], "writers": ["ICLR.cc/2021/Conference"], "invitees": ["ICLR.cc/2021/Conference/Paper3268/Reviewers", "OpenReview.net/Support"], "id": "ICLR.cc/2021/Conference/Paper3268/-/Official_Review"}}}], "count": 5}