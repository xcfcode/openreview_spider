{"notes": [{"id": "B1lnjo05Km", "original": "ryelH1T5FX", "number": 659, "cdate": 1538087844199, "ddate": null, "tcdate": 1538087844199, "tmdate": 1545355419157, "tddate": null, "forum": "B1lnjo05Km", "replyto": null, "invitation": "ICLR.cc/2019/Conference/-/Blind_Submission", "content": {"title": "Graph Spectral Regularization For Neural Network Interpretability", "abstract": "Deep neural networks can learn meaningful representations of data. However, these representations are hard to interpret. For example, visualizing a latent layer is generally only possible for at most three dimensions. Neural networks are able to learn and benefit from much higher dimensional representations but these are not visually interpretable because nodes have arbitrary ordering within a layer. Here, we utilize the ability of the human observer to identify patterns in structured representations to visualize higher dimensions. To do so, we propose a class of regularizations we call \\textit{Graph Spectral Regularizations} that impose graph-structure on latent layers. This is achieved by treating activations as signals on a predefined graph and constraining those activations using graph filters, such as low pass and wavelet-like filters. This framework allows for any kind of graph as well as filter to achieve a wide range of structured regularizations depending on the inference needs of the data. First, we show a synthetic example that the graph-structured layer can reveal topological features of the data. Next, we show that a smoothing regularization can impose semantically consistent ordering of nodes when applied to capsule nets. Further, we show that the graph-structured layer, using wavelet-like spatially localized filters, can form localized receptive fields for improved image and biomedical data interpretation. In other words, the mapping between latent layer, neurons and the output space becomes clear due to the localization of the activations. Finally, we show that when structured as a grid, the representations create coherent images that allow for image-processing techniques such as convolutions.", "keywords": ["autoencoder", "interpretable", "graph signal processing", "graph spectrum", "graph filter", "capsule"], "authorids": ["alexander.tong@yale.edu", "david.vandijk@yale.edu", "jay.stanley@yale.edu", "guy.wolf@yale.edu", "smita.krishnaswamy@yale.edu"], "authors": ["Alexander Tong", "David van Dijk", "Jay Stanley", "Guy Wolf", "Smita Krishnaswamy"], "TL;DR": "Imposing graph structure on neural network layers for improved visual interpretability.", "pdf": "/pdf/23d53b1f9c8e989b383cce7c6a9eff44a4f24c8d.pdf", "paperhash": "tong|graph_spectral_regularization_for_neural_network_interpretability", "_bibtex": "@misc{\ntong2019graph,\ntitle={Graph Spectral Regularization For Neural Network Interpretability},\nauthor={Alexander Tong and David van Dijk and Jay Stanley and Guy Wolf and Smita Krishnaswamy},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lnjo05Km},\n}"}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Blind_Submission", "rdate": null, "ddate": null, "expdate": null, "duedate": 1538085600000, "tmdate": 1538142958393, "tddate": null, "super": null, "final": null, "reply": {"signatures": {"values": ["ICLR.cc/2019/Conference"]}, "forum": null, "readers": {"values": ["everyone"]}, "replyto": null, "content": {"authorids": {"values-regex": ".*"}, "authors": {"values": ["Anonymous"]}}, "writers": {"values": ["ICLR.cc/2019/Conference"]}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["~"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1538142958393}}, "tauthor": "OpenReview.net"}, {"id": "r1lb5fiByE", "original": null, "number": 1, "cdate": 1544037001296, "ddate": null, "tcdate": 1544037001296, "tmdate": 1545354495983, "tddate": null, "forum": "B1lnjo05Km", "replyto": "B1lnjo05Km", "invitation": "ICLR.cc/2019/Conference/-/Paper659/Meta_Review", "content": {"metareview": "The work presents a method of imposing harmonic structural regularizations to layers of a neural network. While the idea is interesting, the reviewers point out multiple issues.\n\nPros:\n+ Interesting method\n+ Hidden layer coherence tends to improve\n\nCons:\n- Deficient comparisons to baselines or context with other works.\n- Insufficient assessment of impact to model performance.\n- Lack of strategy to select regularizers\n- Lack of evaluation on more realistic datasets", "confidence": "4: The area chair is confident but not absolutely certain", "recommendation": "Reject", "title": "Structural regularizations imposed on layers. "}, "signatures": ["ICLR.cc/2019/Conference/Paper659/Area_Chair1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference/Paper659/Area_Chair1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Spectral Regularization For Neural Network Interpretability", "abstract": "Deep neural networks can learn meaningful representations of data. However, these representations are hard to interpret. For example, visualizing a latent layer is generally only possible for at most three dimensions. Neural networks are able to learn and benefit from much higher dimensional representations but these are not visually interpretable because nodes have arbitrary ordering within a layer. Here, we utilize the ability of the human observer to identify patterns in structured representations to visualize higher dimensions. To do so, we propose a class of regularizations we call \\textit{Graph Spectral Regularizations} that impose graph-structure on latent layers. This is achieved by treating activations as signals on a predefined graph and constraining those activations using graph filters, such as low pass and wavelet-like filters. This framework allows for any kind of graph as well as filter to achieve a wide range of structured regularizations depending on the inference needs of the data. First, we show a synthetic example that the graph-structured layer can reveal topological features of the data. Next, we show that a smoothing regularization can impose semantically consistent ordering of nodes when applied to capsule nets. Further, we show that the graph-structured layer, using wavelet-like spatially localized filters, can form localized receptive fields for improved image and biomedical data interpretation. In other words, the mapping between latent layer, neurons and the output space becomes clear due to the localization of the activations. Finally, we show that when structured as a grid, the representations create coherent images that allow for image-processing techniques such as convolutions.", "keywords": ["autoencoder", "interpretable", "graph signal processing", "graph spectrum", "graph filter", "capsule"], "authorids": ["alexander.tong@yale.edu", "david.vandijk@yale.edu", "jay.stanley@yale.edu", "guy.wolf@yale.edu", "smita.krishnaswamy@yale.edu"], "authors": ["Alexander Tong", "David van Dijk", "Jay Stanley", "Guy Wolf", "Smita Krishnaswamy"], "TL;DR": "Imposing graph structure on neural network layers for improved visual interpretability.", "pdf": "/pdf/23d53b1f9c8e989b383cce7c6a9eff44a4f24c8d.pdf", "paperhash": "tong|graph_spectral_regularization_for_neural_network_interpretability", "_bibtex": "@misc{\ntong2019graph,\ntitle={Graph Spectral Regularization For Neural Network Interpretability},\nauthor={Alexander Tong and David van Dijk and Jay Stanley and Guy Wolf and Smita Krishnaswamy},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lnjo05Km},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper659/Meta_Review", "rdate": null, "ddate": null, "expdate": null, "duedate": 1541548800000, "tmdate": 1545353135158, "tddate": null, "super": null, "final": null, "reply": {"forum": "B1lnjo05Km", "replyto": "B1lnjo05Km", "readers": {"description": "Select all user groups that should be able to read this comment. Selecting 'All Users' will allow paper authors, reviewers, area chairs, and program chairs to view this comment.", "values": ["everyone"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper659/Area_Chair[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values-regex": "ICLR.cc/2019/Conference/Paper659/Area_Chair[0-9]+"}, "content": {"title": {"order": 1, "value-regex": ".{1,500}", "description": "Brief summary of your review.", "required": true}, "metareview": {"order": 2, "value-regex": "[\\S\\s]{1,5000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "required": true}, "recommendation": {"order": 3, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The area chair is absolutely certain", "4: The area chair is confident but not absolutely certain", "3: The area chair is somewhat confident", "2: The area chair is not sure", "1: The area chair's evaluation is an educated guess"], "required": true}}}, "signatures": ["ICLR.cc/2019/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2019/Conference/Paper659/Area_Chairs"], "noninvitees": [], "writers": ["ICLR.cc/2019/Conference"], "multiReply": false, "taskCompletionCount": null, "transform": null, "cdate": 1545353135158}}}, {"id": "rJlPu3wi2m", "original": null, "number": 3, "cdate": 1541270638836, "ddate": null, "tcdate": 1541270638836, "tmdate": 1541533799218, "tddate": null, "forum": "B1lnjo05Km", "replyto": "B1lnjo05Km", "invitation": "ICLR.cc/2019/Conference/-/Paper659/Official_Review", "content": {"title": "Interesting technique, Lack of Related work", "review": "Authors present a novel regularizer to impose graph structure upon hidden layers of a neural Network. The intuition is that Neural Networks has typically  symmetric computation among different channels in one layer. Due to the lack of order, visually inspecting the hidden representation is not feasible. By adding edges one can impose a structure upon nodes in one layer and add for example a Laplacian regularizer rather than simple L2 norm regularizer to force the activations to follow the imposed structure. \n\nPros: \n\nInteresting idea for bringing some benefits of graphical models into Neural Networks using a regularizer.\n\nExperiments verify that one can successfully improve the intrepretability of hidden representations. Also, they provide examples of use cases for such technique like aligning the capsule dimmensions. \n\nCons:\n\nThe major flaw is the lack of comparison with ``any'' of the related work on interpretability or the prior work on imposing structure upon hidden representations. Also, the manuscripts lacks a clear discussion of where does this work stands in the literature like structured VAEs, graphical models, sum product nets + factor graphs. \n\nAlso, in none of the experiments authors mention how the added regularizer affects the model performance. Whether imposing the grid structure on CNN (last experiment) drops the CNN accuracy or has no effect? Same for the CapsNet.\n\nFurthermore, the feasibility of calculating the Laplacian for larger scale hidden layers or approximating it is not addressed.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper659/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Spectral Regularization For Neural Network Interpretability", "abstract": "Deep neural networks can learn meaningful representations of data. However, these representations are hard to interpret. For example, visualizing a latent layer is generally only possible for at most three dimensions. Neural networks are able to learn and benefit from much higher dimensional representations but these are not visually interpretable because nodes have arbitrary ordering within a layer. Here, we utilize the ability of the human observer to identify patterns in structured representations to visualize higher dimensions. To do so, we propose a class of regularizations we call \\textit{Graph Spectral Regularizations} that impose graph-structure on latent layers. This is achieved by treating activations as signals on a predefined graph and constraining those activations using graph filters, such as low pass and wavelet-like filters. This framework allows for any kind of graph as well as filter to achieve a wide range of structured regularizations depending on the inference needs of the data. First, we show a synthetic example that the graph-structured layer can reveal topological features of the data. Next, we show that a smoothing regularization can impose semantically consistent ordering of nodes when applied to capsule nets. Further, we show that the graph-structured layer, using wavelet-like spatially localized filters, can form localized receptive fields for improved image and biomedical data interpretation. In other words, the mapping between latent layer, neurons and the output space becomes clear due to the localization of the activations. Finally, we show that when structured as a grid, the representations create coherent images that allow for image-processing techniques such as convolutions.", "keywords": ["autoencoder", "interpretable", "graph signal processing", "graph spectrum", "graph filter", "capsule"], "authorids": ["alexander.tong@yale.edu", "david.vandijk@yale.edu", "jay.stanley@yale.edu", "guy.wolf@yale.edu", "smita.krishnaswamy@yale.edu"], "authors": ["Alexander Tong", "David van Dijk", "Jay Stanley", "Guy Wolf", "Smita Krishnaswamy"], "TL;DR": "Imposing graph structure on neural network layers for improved visual interpretability.", "pdf": "/pdf/23d53b1f9c8e989b383cce7c6a9eff44a4f24c8d.pdf", "paperhash": "tong|graph_spectral_regularization_for_neural_network_interpretability", "_bibtex": "@misc{\ntong2019graph,\ntitle={Graph Spectral Regularization For Neural Network Interpretability},\nauthor={Alexander Tong and David van Dijk and Jay Stanley and Guy Wolf and Smita Krishnaswamy},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lnjo05Km},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper659/Official_Review", "cdate": 1542234409187, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "B1lnjo05Km", "replyto": "B1lnjo05Km", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper659/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335774284, "tmdate": 1552335774284, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper659/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "SJgJVDb5nm", "original": null, "number": 2, "cdate": 1541179175103, "ddate": null, "tcdate": 1541179175103, "tmdate": 1541533799014, "tddate": null, "forum": "B1lnjo05Km", "replyto": "B1lnjo05Km", "invitation": "ICLR.cc/2019/Conference/-/Paper659/Official_Review", "content": {"title": "Latent structure through spectral regularization.", "review": "The paper introduces a spectral regularization with the aim of obtaining representations\nthat are easier to interpret.\n\nSome sentences are often confusing and, in general, clarity needs to be improved.\n\nThe motivation of the work is not very strong in my opinion, in particular by adding such\na prior the space of possible solutions greatly shrinks and I am afraid\nthat interesting solutions will be lost. I think one should focus on properties\nrather than visual inspection.\nAlso, isn't it that if we can clearly see the pattern, perhaps that pattern is\nlinear and of easy discovery also by simpler models?\n\nMore importantly, it seems that all experiments are performed on tasks where the\nunderlying structure is known, however this is almost never the case in practice.\nAssuming one uses the proposed spectral regularization, how would one interpret\nit in such cases?\n\nIn section 2 please clarify the paragraph on bounded Lp norm.\n\nI am sorry but why isn't there a relation, for convolutional nets,\nbetween neurons in different channels? Each element in the feature map represents\nthe input surrounding that location in a k dimensional space.\n\nThe authors state that the usual bottleneck for autoencoders is composed of 2/3\nneurons, this is simply not true. There has been extensive work on\novercomplete representations that shows that is better to have many more dimensions\nbut only few degrees of freedom.\n\nThe spectral bottleneck should cite VQVAE as the approach is very similar and the \nauthors should compare to it.\n\nFor the topological inference experiment it is assumed that one knows the structure,\nbut how to address the more general problem?\nMore practically, the regularization enforces smoothing (if few eigenfunctions\nare used, which is never explained in the paper) between connected nodes, did\nthe authors try to have a simple L2 penalty instead? E.g. minimize the difference\nbetween activations in the group.\n\nRegarding the capsule network example, when you write that without regularization\neach digit responds differently to perturbation of the same dimension, isn't it\npossibly true only up to a, unknown, permutation of the neurons?\n\nTo summarize, while the idea sounds interesting, I miss to find the easy interpretability\nof results and also the overall motivation sounds a bit weak. \nMore importantly the selection of W, crucial for defining structure, is not discussed at all in the paper.\nExperiments are performed on toy examples only whereas here, given that we can\npossibly interpret the results I would have liked something more involved to\nbetter show that this kind of interpretability is needed.\n\nMissing cites:\n[1] van den Oord et al, Neural Discrete Representation Learning.\n[2] Koutnik et al, Evolving neural networks in compressed weight space.\n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ICLR.cc/2019/Conference/Paper659/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Spectral Regularization For Neural Network Interpretability", "abstract": "Deep neural networks can learn meaningful representations of data. However, these representations are hard to interpret. For example, visualizing a latent layer is generally only possible for at most three dimensions. Neural networks are able to learn and benefit from much higher dimensional representations but these are not visually interpretable because nodes have arbitrary ordering within a layer. Here, we utilize the ability of the human observer to identify patterns in structured representations to visualize higher dimensions. To do so, we propose a class of regularizations we call \\textit{Graph Spectral Regularizations} that impose graph-structure on latent layers. This is achieved by treating activations as signals on a predefined graph and constraining those activations using graph filters, such as low pass and wavelet-like filters. This framework allows for any kind of graph as well as filter to achieve a wide range of structured regularizations depending on the inference needs of the data. First, we show a synthetic example that the graph-structured layer can reveal topological features of the data. Next, we show that a smoothing regularization can impose semantically consistent ordering of nodes when applied to capsule nets. Further, we show that the graph-structured layer, using wavelet-like spatially localized filters, can form localized receptive fields for improved image and biomedical data interpretation. In other words, the mapping between latent layer, neurons and the output space becomes clear due to the localization of the activations. Finally, we show that when structured as a grid, the representations create coherent images that allow for image-processing techniques such as convolutions.", "keywords": ["autoencoder", "interpretable", "graph signal processing", "graph spectrum", "graph filter", "capsule"], "authorids": ["alexander.tong@yale.edu", "david.vandijk@yale.edu", "jay.stanley@yale.edu", "guy.wolf@yale.edu", "smita.krishnaswamy@yale.edu"], "authors": ["Alexander Tong", "David van Dijk", "Jay Stanley", "Guy Wolf", "Smita Krishnaswamy"], "TL;DR": "Imposing graph structure on neural network layers for improved visual interpretability.", "pdf": "/pdf/23d53b1f9c8e989b383cce7c6a9eff44a4f24c8d.pdf", "paperhash": "tong|graph_spectral_regularization_for_neural_network_interpretability", "_bibtex": "@misc{\ntong2019graph,\ntitle={Graph Spectral Regularization For Neural Network Interpretability},\nauthor={Alexander Tong and David van Dijk and Jay Stanley and Guy Wolf and Smita Krishnaswamy},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lnjo05Km},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper659/Official_Review", "cdate": 1542234409187, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "B1lnjo05Km", "replyto": "B1lnjo05Km", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper659/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335774284, "tmdate": 1552335774284, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper659/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}, {"id": "HkgL68343m", "original": null, "number": 1, "cdate": 1540830909941, "ddate": null, "tcdate": 1540830909941, "tmdate": 1541533798810, "tddate": null, "forum": "B1lnjo05Km", "replyto": "B1lnjo05Km", "invitation": "ICLR.cc/2019/Conference/-/Paper659/Official_Review", "content": {"title": "The usefulness of graph spectral regularizer is shown, but the key points in practice are not considered.", "review": "Authors highlight the contribution of graph spectral regularizer to the interpretability of neural networks. Specifically, authors consider the Laplacian smoothing regularizer to enhance the local consistency/smoothness between a neuron and its neighbors. Furthermore, by extending the graph Fourier transformation to overcomplete dictionary representation, authors further propose a spectral bottleneck regularizer. Experimental results show that when suitable structural information and corresponding regularizers are imposed, the interpretability of the intermediate layers is improved.\n\nMy main concern is that the power of Graph-based regularizer has been well-known in the ML community for a long time. It is not surprising that adding such regularizers to the training process of neural networks can help to get more structural activations. The key points are \n\n1) How to define the Laplacian graph for the neurons? For the simple case shown in Figures 1 and 2, the topology of the neurons has been predefined and the functionality of them is predefined implicitly. For more challenging cases, how to build the Laplacian graph reasonably? \n\n2) How to add the regularizers with good scalability? The complexity of the proposed regularizers is O(N^2) where N is the number of neurons. When the layers contains thousands of neurons or more, how to add the regularizers efficiently?\n\n3) Which regularizer should be selected? Authors propose a class of graph spectral regularizers and their performance is different in different tasks. Is there any strategy helping us to select suitable regularizers for specific tasks?\n\nUnfortunately, authors provide little analysis on these key points.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ICLR.cc/2019/Conference/Paper659/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Graph Spectral Regularization For Neural Network Interpretability", "abstract": "Deep neural networks can learn meaningful representations of data. However, these representations are hard to interpret. For example, visualizing a latent layer is generally only possible for at most three dimensions. Neural networks are able to learn and benefit from much higher dimensional representations but these are not visually interpretable because nodes have arbitrary ordering within a layer. Here, we utilize the ability of the human observer to identify patterns in structured representations to visualize higher dimensions. To do so, we propose a class of regularizations we call \\textit{Graph Spectral Regularizations} that impose graph-structure on latent layers. This is achieved by treating activations as signals on a predefined graph and constraining those activations using graph filters, such as low pass and wavelet-like filters. This framework allows for any kind of graph as well as filter to achieve a wide range of structured regularizations depending on the inference needs of the data. First, we show a synthetic example that the graph-structured layer can reveal topological features of the data. Next, we show that a smoothing regularization can impose semantically consistent ordering of nodes when applied to capsule nets. Further, we show that the graph-structured layer, using wavelet-like spatially localized filters, can form localized receptive fields for improved image and biomedical data interpretation. In other words, the mapping between latent layer, neurons and the output space becomes clear due to the localization of the activations. Finally, we show that when structured as a grid, the representations create coherent images that allow for image-processing techniques such as convolutions.", "keywords": ["autoencoder", "interpretable", "graph signal processing", "graph spectrum", "graph filter", "capsule"], "authorids": ["alexander.tong@yale.edu", "david.vandijk@yale.edu", "jay.stanley@yale.edu", "guy.wolf@yale.edu", "smita.krishnaswamy@yale.edu"], "authors": ["Alexander Tong", "David van Dijk", "Jay Stanley", "Guy Wolf", "Smita Krishnaswamy"], "TL;DR": "Imposing graph structure on neural network layers for improved visual interpretability.", "pdf": "/pdf/23d53b1f9c8e989b383cce7c6a9eff44a4f24c8d.pdf", "paperhash": "tong|graph_spectral_regularization_for_neural_network_interpretability", "_bibtex": "@misc{\ntong2019graph,\ntitle={Graph Spectral Regularization For Neural Network Interpretability},\nauthor={Alexander Tong and David van Dijk and Jay Stanley and Guy Wolf and Smita Krishnaswamy},\nyear={2019},\nurl={https://openreview.net/forum?id=B1lnjo05Km},\n}"}, "tags": [], "invitation": {"id": "ICLR.cc/2019/Conference/-/Paper659/Official_Review", "cdate": 1542234409187, "expdate": 1552335264000, "duedate": 1541196000000, "reply": {"forum": "B1lnjo05Km", "replyto": "B1lnjo05Km", "readers": {"description": "The users who will be allowed to read the reply content.", "values": ["everyone"]}, "nonreaders": {"values": []}, "signatures": {"description": "How your identity will be displayed with the above content.", "values-regex": "ICLR.cc/2019/Conference/Paper659/AnonReviewer[0-9]+"}, "writers": {"description": "Users that may modify this record.", "values": ["ICLR.cc/2019/Conference"]}, "content": {"title": {"order": 1, "value-regex": ".{0,500}", "description": "Brief summary of your review.", "required": true}, "review": {"order": 2, "value-regex": "[\\S\\s]{1,200000}", "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons (max 200000 characters).", "required": true}, "rating": {"order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"], "required": true}, "confidence": {"order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"], "required": true}}}, "multiReply": false, "tcdate": 1552335774284, "tmdate": 1552335774284, "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2019/Conference"], "invitees": ["ICLR.cc/2019/Conference/Paper659/Reviewers"], "noninvitees": [], "signatures": ["ICLR.cc/2019/Conference"]}}}], "count": 5}