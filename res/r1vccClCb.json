{"notes": [{"tddate": null, "ddate": null, "tmdate": 1520294555096, "tcdate": 1520294555096, "number": 15, "cdate": 1520294555096, "id": "HymoqIs_G", "invitation": "ICLR.cc/2018/Conference/-/Paper464/Official_Comment", "forum": "r1vccClCb", "replyto": "B1o5Y45df", "signatures": ["ICLR.cc/2018/Conference/Paper464/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper464/Authors"], "content": {"title": "Thank you for your interest in our work", "comment": "Q: Would it be fair to say that just changing the optimization function to reconstruct the neighbors as well as the input with a simple metric like MSE would be suffice (instead of separate decoders)? \nA: First, thanks for your interest. Do you mean that training the decoder to output a 28 x 56 image (containing both the input\u2019s reconstruction and the neighbor\u2019s reconstruction)?\nIn the MNIST experiment we presented in the paper, the output of the decoder is always a 28 x 28 image containing either the input (in the case of autoencoder) or a neighbor (in the case of neighbor-encoder).\n\nQ: From what I gather, the paper also suggests that the architecture is more powerful in presence of noise (in comparison to existing AE architectures?\nA: It is an observation we made when comparing AE versus NE on the human physical activities data set as we are using a neighbor mining technique which ignores noisy dimensions.\nOur suggestion is that training by neighbor reconstruction instead of self-reconstruction yields better representation for semi-supervised classification and clustering. Since the proposed method is just changing the reconstruction target of existing AE architectures, it can be applied to most existing AE architectures. Based on our experimental result (with vanilla, denosing, and variational architectures), different architecture excels on different data set. Our main finding is on the effect of changing the reconstruction target (neighbor versus self) rather than the architectures.\n"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neighbor-encoder", "abstract": "We propose a novel unsupervised representation learning framework called neighbor-encoder in which domain knowledge can be trivially incorporated into the learning process without modifying the general encoder-decoder architecture. In contrast to autoencoder, which reconstructs the input data, neighbor-encoder reconstructs the input data's neighbors. The proposed neighbor-encoder can be considered as a generalization of autoencoder as the input data can be treated as the nearest neighbor of itself with zero distance. By reformulating the representation learning problem as a neighbor reconstruction problem, domain knowledge can be easily incorporated with appropriate definition of similarity or distance between objects. As such, any existing similarity search algorithms can be easily integrated into our framework. Applications of other algorithms (e.g., association rule mining) in our framework is also possible since the concept of ``neighbor\" is an abstraction which can be appropriately defined differently in different contexts. We have demonstrated the effectiveness of our framework in various domains, including images, time series, music, etc., with various neighbor definitions. Experimental results show that neighbor-encoder outperforms autoencoder in most scenarios we considered.", "pdf": "/pdf/37dcfc2fa414e93481ebef2c24570a2c09b5945a.pdf", "paperhash": "yeh|neighborencoder", "_bibtex": "@misc{\nmichael2018neighborencoder,\ntitle={Neighbor-encoder},\nauthor={Chin-Chia Michael Yeh and Yan Zhu and Evangelos E. Papalexakis and Abdullah Mueen and Eamonn Keogh},\nyear={2018},\nurl={https://openreview.net/forum?id=r1vccClCb},\n}", "keywords": ["unsupervised learning", "representation learning", "autoencoder"], "authors": ["Chin-Chia Michael Yeh", "Yan Zhu", "Evangelos E. Papalexakis", "Abdullah Mueen", "Eamonn Keogh"], "authorids": ["myeh003@ucr.edu", "yzhu015@ucr.edu", "epapalex@cs.ucr.edu", "mueen@unm.edu", "eamonn@cs.ucr.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825733223, "id": "ICLR.cc/2018/Conference/-/Paper464/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "r1vccClCb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper464/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper464/Authors|ICLR.cc/2018/Conference/Paper464/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper464/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper464/Authors|ICLR.cc/2018/Conference/Paper464/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper464/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper464/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper464/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper464/Reviewers", "ICLR.cc/2018/Conference/Paper464/Authors", "ICLR.cc/2018/Conference/Paper464/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825733223}}}, {"tddate": null, "ddate": null, "tmdate": 1520220562692, "tcdate": 1520220562692, "number": 1, "cdate": 1520220562692, "id": "B1o5Y45df", "invitation": "ICLR.cc/2018/Conference/-/Paper464/Public_Comment", "forum": "r1vccClCb", "replyto": "r1vccClCb", "signatures": ["(anonymous)"], "readers": ["everyone"], "writers": ["(anonymous)"], "content": {"title": "Replication of results / Loss Convergence ", "comment": "I am trying to replicate your results with MNIST. Just to confirm (before I jump to conclusions or present my findings). \nWould it be fair to say that just changing the optimisation function to reconstruct the neighbours as well as the input with a simple metric like MSE would be suffice (instead of seperate decoders)?\n\nFrom what I gather, the paper also suggests that the architecture is more powerful in presence of noise (in comparison to existing AE architectures? "}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neighbor-encoder", "abstract": "We propose a novel unsupervised representation learning framework called neighbor-encoder in which domain knowledge can be trivially incorporated into the learning process without modifying the general encoder-decoder architecture. In contrast to autoencoder, which reconstructs the input data, neighbor-encoder reconstructs the input data's neighbors. The proposed neighbor-encoder can be considered as a generalization of autoencoder as the input data can be treated as the nearest neighbor of itself with zero distance. By reformulating the representation learning problem as a neighbor reconstruction problem, domain knowledge can be easily incorporated with appropriate definition of similarity or distance between objects. As such, any existing similarity search algorithms can be easily integrated into our framework. Applications of other algorithms (e.g., association rule mining) in our framework is also possible since the concept of ``neighbor\" is an abstraction which can be appropriately defined differently in different contexts. We have demonstrated the effectiveness of our framework in various domains, including images, time series, music, etc., with various neighbor definitions. Experimental results show that neighbor-encoder outperforms autoencoder in most scenarios we considered.", "pdf": "/pdf/37dcfc2fa414e93481ebef2c24570a2c09b5945a.pdf", "paperhash": "yeh|neighborencoder", "_bibtex": "@misc{\nmichael2018neighborencoder,\ntitle={Neighbor-encoder},\nauthor={Chin-Chia Michael Yeh and Yan Zhu and Evangelos E. Papalexakis and Abdullah Mueen and Eamonn Keogh},\nyear={2018},\nurl={https://openreview.net/forum?id=r1vccClCb},\n}", "keywords": ["unsupervised learning", "representation learning", "autoencoder"], "authors": ["Chin-Chia Michael Yeh", "Yan Zhu", "Evangelos E. Papalexakis", "Abdullah Mueen", "Eamonn Keogh"], "authorids": ["myeh003@ucr.edu", "yzhu015@ucr.edu", "epapalex@cs.ucr.edu", "mueen@unm.edu", "eamonn@cs.ucr.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1512791685974, "id": "ICLR.cc/2018/Conference/-/Paper464/Public_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["~"], "reply": {"replyto": null, "forum": "r1vccClCb", "writers": {"values-regex": "~.*|\\(anonymous\\)"}, "signatures": {"values-regex": "~.*|\\(anonymous\\)", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Authors_and_Higher", "ICLR.cc/2018/Conference/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": ["ICLR.cc/2018/Conference/Paper464/Authors", "ICLR.cc/2018/Conference/Paper464/Reviewers", "ICLR.cc/2018/Conference/Paper464/Area_Chair"], "cdate": 1512791685974}}}, {"tddate": null, "ddate": null, "tmdate": 1518730176860, "tcdate": 1509120655052, "number": 464, "cdate": 1518730176851, "id": "r1vccClCb", "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "forum": "r1vccClCb", "original": "Sk8ccAgCW", "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference"], "content": {"title": "Neighbor-encoder", "abstract": "We propose a novel unsupervised representation learning framework called neighbor-encoder in which domain knowledge can be trivially incorporated into the learning process without modifying the general encoder-decoder architecture. In contrast to autoencoder, which reconstructs the input data, neighbor-encoder reconstructs the input data's neighbors. The proposed neighbor-encoder can be considered as a generalization of autoencoder as the input data can be treated as the nearest neighbor of itself with zero distance. By reformulating the representation learning problem as a neighbor reconstruction problem, domain knowledge can be easily incorporated with appropriate definition of similarity or distance between objects. As such, any existing similarity search algorithms can be easily integrated into our framework. Applications of other algorithms (e.g., association rule mining) in our framework is also possible since the concept of ``neighbor\" is an abstraction which can be appropriately defined differently in different contexts. We have demonstrated the effectiveness of our framework in various domains, including images, time series, music, etc., with various neighbor definitions. Experimental results show that neighbor-encoder outperforms autoencoder in most scenarios we considered.", "pdf": "/pdf/37dcfc2fa414e93481ebef2c24570a2c09b5945a.pdf", "paperhash": "yeh|neighborencoder", "_bibtex": "@misc{\nmichael2018neighborencoder,\ntitle={Neighbor-encoder},\nauthor={Chin-Chia Michael Yeh and Yan Zhu and Evangelos E. Papalexakis and Abdullah Mueen and Eamonn Keogh},\nyear={2018},\nurl={https://openreview.net/forum?id=r1vccClCb},\n}", "keywords": ["unsupervised learning", "representation learning", "autoencoder"], "authors": ["Chin-Chia Michael Yeh", "Yan Zhu", "Evangelos E. Papalexakis", "Abdullah Mueen", "Eamonn Keogh"], "authorids": ["myeh003@ucr.edu", "yzhu015@ucr.edu", "epapalex@cs.ucr.edu", "mueen@unm.edu", "eamonn@cs.ucr.edu"]}, "nonreaders": [], "details": {"replyCount": 9, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1506717071958, "id": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference"], "reply": {"forum": null, "replyto": null, "writers": {"values": ["ICLR.cc/2018/Conference"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference"]}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"authors": {"required": false, "order": 1, "values-regex": ".*", "description": "Comma separated list of author names, as they appear in the paper."}, "authorids": {"required": false, "order": 2, "values-regex": ".*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "cdate": 1506717071958}}, "tauthor": "ICLR.cc/2018/Conference"}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1517260076238, "tcdate": 1517250215102, "number": 864, "cdate": 1517250215088, "id": "ByJ3Lkarf", "invitation": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "forum": "r1vccClCb", "replyto": "r1vccClCb", "signatures": ["ICLR.cc/2018/Conference/Program_Chairs"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Program_Chairs"], "content": {"decision": "Reject", "title": "ICLR 2018 Conference Acceptance Decision", "comment": "The paper proposes a form of autoencoder that learns to predict the neighbors of a given input vector rather than the input itself.  The idea is nice but there are some reviewer concerns about insufficient evaluation and the effect of the curse of dimensionality.  The revised paper does address some questions and includes additional helpful experiments with different types of autoencoders.  However, the work is still a bit preliminary.  The area of auto-encoder variants, and corresponding experiments on CIFAR-10 and the like, is crowded.  In order to convince the reader that a new approach makes a real contribution, it should have very thorough experiments.  Suggestions:  try to improve the CIFAR-10 numbers (they need not be state-of-the-art but should be more credible), adding more data sets (especially high-dimensional ones), and analyzing the effects of factors that are likely to be important (e.g. dimensionality, choice of distance function for neighbor search)."}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neighbor-encoder", "abstract": "We propose a novel unsupervised representation learning framework called neighbor-encoder in which domain knowledge can be trivially incorporated into the learning process without modifying the general encoder-decoder architecture. In contrast to autoencoder, which reconstructs the input data, neighbor-encoder reconstructs the input data's neighbors. The proposed neighbor-encoder can be considered as a generalization of autoencoder as the input data can be treated as the nearest neighbor of itself with zero distance. By reformulating the representation learning problem as a neighbor reconstruction problem, domain knowledge can be easily incorporated with appropriate definition of similarity or distance between objects. As such, any existing similarity search algorithms can be easily integrated into our framework. Applications of other algorithms (e.g., association rule mining) in our framework is also possible since the concept of ``neighbor\" is an abstraction which can be appropriately defined differently in different contexts. We have demonstrated the effectiveness of our framework in various domains, including images, time series, music, etc., with various neighbor definitions. Experimental results show that neighbor-encoder outperforms autoencoder in most scenarios we considered.", "pdf": "/pdf/37dcfc2fa414e93481ebef2c24570a2c09b5945a.pdf", "paperhash": "yeh|neighborencoder", "_bibtex": "@misc{\nmichael2018neighborencoder,\ntitle={Neighbor-encoder},\nauthor={Chin-Chia Michael Yeh and Yan Zhu and Evangelos E. Papalexakis and Abdullah Mueen and Eamonn Keogh},\nyear={2018},\nurl={https://openreview.net/forum?id=r1vccClCb},\n}", "keywords": ["unsupervised learning", "representation learning", "autoencoder"], "authors": ["Chin-Chia Michael Yeh", "Yan Zhu", "Evangelos E. Papalexakis", "Abdullah Mueen", "Eamonn Keogh"], "authorids": ["myeh003@ucr.edu", "yzhu015@ucr.edu", "epapalex@cs.ucr.edu", "mueen@unm.edu", "eamonn@cs.ucr.edu"]}, "tags": [], "invitation": {"id": "ICLR.cc/2018/Conference/-/Acceptance_Decision", "rdate": null, "ddate": null, "expdate": 1541175629000, "duedate": null, "tmdate": 1541177635767, "tddate": null, "super": null, "final": null, "reply": {"forum": null, "replyto": null, "invitation": "ICLR.cc/2018/Conference/-/Blind_Submission", "writers": {"values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "signatures": {"description": "How your identity will be displayed with the above content.", "values": ["ICLR.cc/2018/Conference/Program_Chairs"]}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["ICLR.cc/2018/Conference/Program_Chairs", "everyone"]}, "content": {"title": {"required": true, "order": 1, "value": "ICLR 2018 Conference Acceptance Decision"}, "comment": {"required": false, "order": 3, "description": "(optional) Comment on this decision.", "value-regex": "[\\S\\s]{0,5000}"}, "decision": {"required": true, "order": 2, "value-dropdown": ["Accept (Oral)", "Accept (Poster)", "Reject", "Invite to Workshop Track"]}}}, "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "nonreaders": [], "invitees": [], "noninvitees": [], "writers": ["ICLR.cc/2018/Conference"], "multiReply": null, "taskCompletionCount": null, "transform": null, "cdate": 1541177635767}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515762916005, "tcdate": 1511385484285, "number": 1, "cdate": 1511385484285, "id": "Hk4qYw7eG", "invitation": "ICLR.cc/2018/Conference/-/Paper464/Official_Review", "forum": "r1vccClCb", "replyto": "r1vccClCb", "signatures": ["ICLR.cc/2018/Conference/Paper464/AnonReviewer1"], "readers": ["everyone"], "content": {"title": "Lack of comparison with other autoencoders", "rating": "5: Marginally below acceptance threshold", "review": "This paper describes a generalization of autoencoders that are trained to reconstruct a close neighbor of its input, instead of merely the input itself. Experiments on 3 datasets show that this yields better representations in terms of post hoc classification with a linear classifier or clustering, compared to a regular autoencoder.\n\nAs the authors recognize, there is a long history of research on variants of autoencoders. Unfortunately this paper compares with none of them. While the authors suggest that, since these variations can be combined with the proposed neighbor reconstruction variant, it's not necessary to compare with these other variations, I disagree. It could very well be that this neighbor trick makes other methods worse for instance. \n\nAt the very least, I would expect a comparison with denoising autoencoders, since they are similar if one thinks of the use of neighbors as a structured form of noise added to the input. It could very well be in fact that simply adding noise to the input is sufficient to force the autoencoder to learn a valuable representation, and that the neighbor reconstruction approach is simply an overly complicated approach of achieving the same results. This is an open question right now that I'd expect this paper to answer.\n\nFinally, I think results would be more impressive and likely to have impact if the authors used datasets that are more commonly used for representation learning, so that a direct performance comparison can be made with previously published results. CIFAR 10 and SVHN would be good alternatives.\n\nOverall, I'm afraid I must recommend that this paper be rejected.\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": true, "forumContent": {"title": "Neighbor-encoder", "abstract": "We propose a novel unsupervised representation learning framework called neighbor-encoder in which domain knowledge can be trivially incorporated into the learning process without modifying the general encoder-decoder architecture. In contrast to autoencoder, which reconstructs the input data, neighbor-encoder reconstructs the input data's neighbors. The proposed neighbor-encoder can be considered as a generalization of autoencoder as the input data can be treated as the nearest neighbor of itself with zero distance. By reformulating the representation learning problem as a neighbor reconstruction problem, domain knowledge can be easily incorporated with appropriate definition of similarity or distance between objects. As such, any existing similarity search algorithms can be easily integrated into our framework. Applications of other algorithms (e.g., association rule mining) in our framework is also possible since the concept of ``neighbor\" is an abstraction which can be appropriately defined differently in different contexts. We have demonstrated the effectiveness of our framework in various domains, including images, time series, music, etc., with various neighbor definitions. Experimental results show that neighbor-encoder outperforms autoencoder in most scenarios we considered.", "pdf": "/pdf/37dcfc2fa414e93481ebef2c24570a2c09b5945a.pdf", "paperhash": "yeh|neighborencoder", "_bibtex": "@misc{\nmichael2018neighborencoder,\ntitle={Neighbor-encoder},\nauthor={Chin-Chia Michael Yeh and Yan Zhu and Evangelos E. Papalexakis and Abdullah Mueen and Eamonn Keogh},\nyear={2018},\nurl={https://openreview.net/forum?id=r1vccClCb},\n}", "keywords": ["unsupervised learning", "representation learning", "autoencoder"], "authors": ["Chin-Chia Michael Yeh", "Yan Zhu", "Evangelos E. Papalexakis", "Abdullah Mueen", "Eamonn Keogh"], "authorids": ["myeh003@ucr.edu", "yzhu015@ucr.edu", "epapalex@cs.ucr.edu", "mueen@unm.edu", "eamonn@cs.ucr.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642452578, "id": "ICLR.cc/2018/Conference/-/Paper464/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper464/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper464/AnonReviewer1", "ICLR.cc/2018/Conference/Paper464/AnonReviewer3", "ICLR.cc/2018/Conference/Paper464/AnonReviewer2"], "reply": {"forum": "r1vccClCb", "replyto": "r1vccClCb", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper464/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642452578}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642452631, "tcdate": 1511805151306, "number": 2, "cdate": 1511805151306, "id": "HJDy-RKef", "invitation": "ICLR.cc/2018/Conference/-/Paper464/Official_Review", "forum": "r1vccClCb", "replyto": "r1vccClCb", "signatures": ["ICLR.cc/2018/Conference/Paper464/AnonReviewer3"], "readers": ["everyone"], "content": {"title": "Nice Idea but what about \"Curse of Dimensionality\"?", "rating": "6: Marginally above acceptance threshold", "review": "A representation learning framework from unsupervised data, based not on auto-encoding (x in, x out), but on neighbor-encoding (x in, N(x) out, where N(.) denotes the neighbor(s) of x) is introduced. \n\nThe underlying idea is interesting, as such, each and every degree of freedom do not synthesize itself similar to the auto-encoder setting, but rather synthesize a neighbor, or k-neighbors. The authors argue that this form of unsupervised learning is more powerful compared to the standard auto-encoder setting, and some preliminary experimental proof is also provided. \n\nHowever, I would argue that this is not a completely abstract - unsupervised representation learning setting since defining what is \"a neighbor\" and what is \"not a neighbor\" requires quite a bit of domain knowledge. As we all know, the euclidian distance, or any other comparable norm, suffers from the \"Curse of Dimensionality\" as the #-of-Dimensions increase. \n\nFor instance, in section 4.3, the 40-dimensional feature vector space is used to define neighbors in. It would be great how the neighborhood topology in that space looks like.\n\nAll in all, I do like the idea as a concept but I am wary about its applicability to real data where defining a good neighborhood metric might be a major challenge of its own. ", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neighbor-encoder", "abstract": "We propose a novel unsupervised representation learning framework called neighbor-encoder in which domain knowledge can be trivially incorporated into the learning process without modifying the general encoder-decoder architecture. In contrast to autoencoder, which reconstructs the input data, neighbor-encoder reconstructs the input data's neighbors. The proposed neighbor-encoder can be considered as a generalization of autoencoder as the input data can be treated as the nearest neighbor of itself with zero distance. By reformulating the representation learning problem as a neighbor reconstruction problem, domain knowledge can be easily incorporated with appropriate definition of similarity or distance between objects. As such, any existing similarity search algorithms can be easily integrated into our framework. Applications of other algorithms (e.g., association rule mining) in our framework is also possible since the concept of ``neighbor\" is an abstraction which can be appropriately defined differently in different contexts. We have demonstrated the effectiveness of our framework in various domains, including images, time series, music, etc., with various neighbor definitions. Experimental results show that neighbor-encoder outperforms autoencoder in most scenarios we considered.", "pdf": "/pdf/37dcfc2fa414e93481ebef2c24570a2c09b5945a.pdf", "paperhash": "yeh|neighborencoder", "_bibtex": "@misc{\nmichael2018neighborencoder,\ntitle={Neighbor-encoder},\nauthor={Chin-Chia Michael Yeh and Yan Zhu and Evangelos E. Papalexakis and Abdullah Mueen and Eamonn Keogh},\nyear={2018},\nurl={https://openreview.net/forum?id=r1vccClCb},\n}", "keywords": ["unsupervised learning", "representation learning", "autoencoder"], "authors": ["Chin-Chia Michael Yeh", "Yan Zhu", "Evangelos E. Papalexakis", "Abdullah Mueen", "Eamonn Keogh"], "authorids": ["myeh003@ucr.edu", "yzhu015@ucr.edu", "epapalex@cs.ucr.edu", "mueen@unm.edu", "eamonn@cs.ucr.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642452578, "id": "ICLR.cc/2018/Conference/-/Paper464/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper464/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper464/AnonReviewer1", "ICLR.cc/2018/Conference/Paper464/AnonReviewer3", "ICLR.cc/2018/Conference/Paper464/AnonReviewer2"], "reply": {"forum": "r1vccClCb", "replyto": "r1vccClCb", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper464/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642452578}}}, {"tddate": null, "ddate": null, "original": null, "tmdate": 1515642452593, "tcdate": 1511845942635, "number": 3, "cdate": 1511845942635, "id": "S1JBxOqlz", "invitation": "ICLR.cc/2018/Conference/-/Paper464/Official_Review", "forum": "r1vccClCb", "replyto": "r1vccClCb", "signatures": ["ICLR.cc/2018/Conference/Paper464/AnonReviewer2"], "readers": ["everyone"], "content": {"title": "Review: neighbor-encoder -> neighbor encoder", "rating": "4: Ok but not good enough - rejection", "review": "This paper presents a variant of auto-encoder that relaxes the decoder targets to be neighbors of a data point. Different from original auto-encoder, where data point x and the decoder output \\hat{x} are forced to be close, the neighbor-encoder encourage the decoder output to be similar to the neighbors of the input data point. By considering the neighbor information, the decoder targets would have smaller intra-class distances, thus larger inter-class distances, which helps to learn better separated latent representation of data in terms of data clusters. The authors conduct experiments on several real but relative small-scale data sets, and demonstrate the improvements of learned latent representations by using neighbors as targets. \n\nThe method of neighbor prediction is a simple and small modification of the original auto-encoder, but seems to provide a way to augment the targets such that intra-class distance of decoder targets can be tightened. Improvements in the conducted experiments seem significant compared to the most basic auto-encoder.\n\nMajor issues:\n\nThere are some unaddressed theoretical questions. The optimal solution to predict the set of neighbor points in mean-squared metric is to predict the average of those points, which is not well justified as the averaged image can easily fall off the data manifold. This may lead to a more blurry reconstruction when k increases, despite the intra-class targets are tight. It can also in turn harm the latent representation when euclidean neighbors are not actually similar (e.g. images in cifar10/imagenet that are not as simple as 10 digits). This seems to be a defect of the neighbor-encoder method and is not discussed in the paper.\n\nThe data sets used in the experiments  are relatively small and simple, larger-scale experiments should be conducted. The fluctuations in Figure 9 and 10 suggest the significant variances in the results. Also, more complicated data/images can decrease the actual similarities of euclidean neighbors, thus affecting the results.\n\nThe baselines are weak. Only the most basic auto-encoder is compared, no additional variants or other data augmentation techniques are compared. It is possible other variants improve the basic auto-encoder in similar ways. \n\nSome results are not very well explained. It seems the performance increases monotonically as the number of neighbors increases (Figure 5, 9, 10). Will this continue or when will the performance decrease? I would expect it to decrease as the far away neighbors will be dissimilar. The authors can either attach the nearest neighbors figures or their statistics, and provide explanations on when and why the performance decrease is expected.\n\nSome notations are confusing and need to be improved. For example, X and Y are actually the same set of images, the separation is a bit confusing; y_i \\in y in last paragraph of page 4 is incorrect, should use something like y_i in N(y).", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "writers": [], "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neighbor-encoder", "abstract": "We propose a novel unsupervised representation learning framework called neighbor-encoder in which domain knowledge can be trivially incorporated into the learning process without modifying the general encoder-decoder architecture. In contrast to autoencoder, which reconstructs the input data, neighbor-encoder reconstructs the input data's neighbors. The proposed neighbor-encoder can be considered as a generalization of autoencoder as the input data can be treated as the nearest neighbor of itself with zero distance. By reformulating the representation learning problem as a neighbor reconstruction problem, domain knowledge can be easily incorporated with appropriate definition of similarity or distance between objects. As such, any existing similarity search algorithms can be easily integrated into our framework. Applications of other algorithms (e.g., association rule mining) in our framework is also possible since the concept of ``neighbor\" is an abstraction which can be appropriately defined differently in different contexts. We have demonstrated the effectiveness of our framework in various domains, including images, time series, music, etc., with various neighbor definitions. Experimental results show that neighbor-encoder outperforms autoencoder in most scenarios we considered.", "pdf": "/pdf/37dcfc2fa414e93481ebef2c24570a2c09b5945a.pdf", "paperhash": "yeh|neighborencoder", "_bibtex": "@misc{\nmichael2018neighborencoder,\ntitle={Neighbor-encoder},\nauthor={Chin-Chia Michael Yeh and Yan Zhu and Evangelos E. Papalexakis and Abdullah Mueen and Eamonn Keogh},\nyear={2018},\nurl={https://openreview.net/forum?id=r1vccClCb},\n}", "keywords": ["unsupervised learning", "representation learning", "autoencoder"], "authors": ["Chin-Chia Michael Yeh", "Yan Zhu", "Evangelos E. Papalexakis", "Abdullah Mueen", "Eamonn Keogh"], "authorids": ["myeh003@ucr.edu", "yzhu015@ucr.edu", "epapalex@cs.ucr.edu", "mueen@unm.edu", "eamonn@cs.ucr.edu"]}, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1511845199000, "tmdate": 1515642452578, "id": "ICLR.cc/2018/Conference/-/Paper464/Official_Review", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "invitees": ["ICLR.cc/2018/Conference/Paper464/Reviewers"], "noninvitees": ["ICLR.cc/2018/Conference/Paper464/AnonReviewer1", "ICLR.cc/2018/Conference/Paper464/AnonReviewer3", "ICLR.cc/2018/Conference/Paper464/AnonReviewer2"], "reply": {"forum": "r1vccClCb", "replyto": "r1vccClCb", "writers": {"values": []}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper464/AnonReviewer[0-9]+", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"title": {"required": true, "order": 1, "description": "Brief summary of your review.", "value-regex": ".{0,500}"}, "review": {"required": true, "order": 2, "description": "Please provide an evaluation of the quality, clarity, originality and significance of this work, including a list of its pros and cons.", "value-regex": "[\\S\\s]{1,200000}"}, "rating": {"required": true, "order": 3, "value-dropdown": ["10: Top 5% of accepted papers, seminal paper", "9: Top 15% of accepted papers, strong accept", "8: Top 50% of accepted papers, clear accept", "7: Good paper, accept", "6: Marginally above acceptance threshold", "5: Marginally below acceptance threshold", "4: Ok but not good enough - rejection", "3: Clear rejection", "2: Strong rejection", "1: Trivial or wrong"]}, "confidence": {"required": true, "order": 4, "value-radio": ["5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "3: The reviewer is fairly confident that the evaluation is correct", "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "1: The reviewer's evaluation is an educated guess"]}}}, "nonreaders": [], "expdate": 1519621199000, "cdate": 1515642452578}}}, {"tddate": null, "ddate": null, "tmdate": 1515181051150, "tcdate": 1515180905949, "number": 2, "cdate": 1515180905949, "id": "SJzuXLaXz", "invitation": "ICLR.cc/2018/Conference/-/Paper464/Official_Comment", "forum": "r1vccClCb", "replyto": "HJDy-RKef", "signatures": ["ICLR.cc/2018/Conference/Paper464/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper464/Authors"], "content": {"title": "Thank you for your helpful review and kind words", "comment": "Dear Reviewer,\n\nThank you for your helpful review and kind words! We are glad that you like the idea.\n\nIn the review, you have argued that the neighbor-encoder method is not a completely abstract-unsupervised representation learning method as it requires domain knowledge to define the neighbor relationship. This statement is certainly valid, as we do need some domain knowledge. However, the amount of domain knowledge required by neighbor-encoder is minimal in comparison to what is required by a typical supervised representation learning method: we only need a \"neighbor\" to be defined, the \"non-neighbor\" information is not needed. In other words, we only need to know what is \"similar\" (and this information can be very sparse), but not what is \"not similar\" (the key information needed to divide objects into different classes/clusters). \nFurthermore, note that the domain knowledge provided do not need to be precise. Our MINST example in Section 4.1 simply use Euclidean distance in raw pixel space as the similarity measure to find the neighbors. For the newly added CIFAR10 data set Section 4.2, we use Euclidean distance in a common computer vision feature space as the similarity measure; the feature selected does not have much discriminative power for this data set and only 22% of the object-neighbor pairs are from the same class. Nevertheless, the results (Figure 9 and Table 2) show that all three variants of neighbor-encoder outperform their autoencoder counterparts in both semi-supervised classification (when number of labeled data is small) and clustering tasks.\n\nTo clarify, our claim is not that neighbor-encoder is a purely unsupervised representation learning method. Instead, our claim is that even a tiny amount of domain knowledge can greatly improve unsupervised representation learning, and neighbor-encoder is an effective way to incorporate such domain knowledge into the unsupervised representation learning framework.\n\nFor any comparable norm based neighbor definition, \"curse of dimensionality\" indeed would be a problem. To quantify the severity of such problem, we measured the percentage of object-neighbor pairs being in the same class. For example, in Section 4.4 (originally Section 4.3), about 49% of the object-neighbor pairs in the 40-dimensional feature vector space are in the same class (note that this is relatively high, as the default rate for randomly assigned neighbor is just ~9% for this data set). Another way we envision that can further increase this percentage is to use side information to define a neighbor (as introduced in Section 3.4). For instance, images/document on the same webpage or reviews of the same paper/movie/music could be declared being neighbor of each other. Such side information would much less sensitive to the curse of dimensionality.\n\nThanks,\nAuthors"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neighbor-encoder", "abstract": "We propose a novel unsupervised representation learning framework called neighbor-encoder in which domain knowledge can be trivially incorporated into the learning process without modifying the general encoder-decoder architecture. In contrast to autoencoder, which reconstructs the input data, neighbor-encoder reconstructs the input data's neighbors. The proposed neighbor-encoder can be considered as a generalization of autoencoder as the input data can be treated as the nearest neighbor of itself with zero distance. By reformulating the representation learning problem as a neighbor reconstruction problem, domain knowledge can be easily incorporated with appropriate definition of similarity or distance between objects. As such, any existing similarity search algorithms can be easily integrated into our framework. Applications of other algorithms (e.g., association rule mining) in our framework is also possible since the concept of ``neighbor\" is an abstraction which can be appropriately defined differently in different contexts. We have demonstrated the effectiveness of our framework in various domains, including images, time series, music, etc., with various neighbor definitions. Experimental results show that neighbor-encoder outperforms autoencoder in most scenarios we considered.", "pdf": "/pdf/37dcfc2fa414e93481ebef2c24570a2c09b5945a.pdf", "paperhash": "yeh|neighborencoder", "_bibtex": "@misc{\nmichael2018neighborencoder,\ntitle={Neighbor-encoder},\nauthor={Chin-Chia Michael Yeh and Yan Zhu and Evangelos E. Papalexakis and Abdullah Mueen and Eamonn Keogh},\nyear={2018},\nurl={https://openreview.net/forum?id=r1vccClCb},\n}", "keywords": ["unsupervised learning", "representation learning", "autoencoder"], "authors": ["Chin-Chia Michael Yeh", "Yan Zhu", "Evangelos E. Papalexakis", "Abdullah Mueen", "Eamonn Keogh"], "authorids": ["myeh003@ucr.edu", "yzhu015@ucr.edu", "epapalex@cs.ucr.edu", "mueen@unm.edu", "eamonn@cs.ucr.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825733223, "id": "ICLR.cc/2018/Conference/-/Paper464/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "r1vccClCb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper464/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper464/Authors|ICLR.cc/2018/Conference/Paper464/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper464/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper464/Authors|ICLR.cc/2018/Conference/Paper464/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper464/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper464/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper464/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper464/Reviewers", "ICLR.cc/2018/Conference/Paper464/Authors", "ICLR.cc/2018/Conference/Paper464/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825733223}}}, {"tddate": null, "ddate": null, "tmdate": 1515180948420, "tcdate": 1515180948420, "number": 3, "cdate": 1515180948420, "id": "r1nqmLp7M", "invitation": "ICLR.cc/2018/Conference/-/Paper464/Official_Comment", "forum": "r1vccClCb", "replyto": "Hk4qYw7eG", "signatures": ["ICLR.cc/2018/Conference/Paper464/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper464/Authors"], "content": {"title": "We really appreciate your valuable review", "comment": "Dear Reviewer,\n\nWe really appreciate your valuable review! We have modified our paper based on your feedback by:\n \n1) adding denoising and variational autoencoder (and their neighbor-encoder counterparts) to all experiments, and \u2026\n2) adding a new set of experiment on CIFAR 10 in Section 4.2. In all the experiments, we observed that neighbor-encoder and its variants outperform their autoencoder counterparts when applied in semi-supervised classification (when the number of labeled data available is small) and clustering tasks.\n\nThanks,\nAuthors"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neighbor-encoder", "abstract": "We propose a novel unsupervised representation learning framework called neighbor-encoder in which domain knowledge can be trivially incorporated into the learning process without modifying the general encoder-decoder architecture. In contrast to autoencoder, which reconstructs the input data, neighbor-encoder reconstructs the input data's neighbors. The proposed neighbor-encoder can be considered as a generalization of autoencoder as the input data can be treated as the nearest neighbor of itself with zero distance. By reformulating the representation learning problem as a neighbor reconstruction problem, domain knowledge can be easily incorporated with appropriate definition of similarity or distance between objects. As such, any existing similarity search algorithms can be easily integrated into our framework. Applications of other algorithms (e.g., association rule mining) in our framework is also possible since the concept of ``neighbor\" is an abstraction which can be appropriately defined differently in different contexts. We have demonstrated the effectiveness of our framework in various domains, including images, time series, music, etc., with various neighbor definitions. Experimental results show that neighbor-encoder outperforms autoencoder in most scenarios we considered.", "pdf": "/pdf/37dcfc2fa414e93481ebef2c24570a2c09b5945a.pdf", "paperhash": "yeh|neighborencoder", "_bibtex": "@misc{\nmichael2018neighborencoder,\ntitle={Neighbor-encoder},\nauthor={Chin-Chia Michael Yeh and Yan Zhu and Evangelos E. Papalexakis and Abdullah Mueen and Eamonn Keogh},\nyear={2018},\nurl={https://openreview.net/forum?id=r1vccClCb},\n}", "keywords": ["unsupervised learning", "representation learning", "autoencoder"], "authors": ["Chin-Chia Michael Yeh", "Yan Zhu", "Evangelos E. Papalexakis", "Abdullah Mueen", "Eamonn Keogh"], "authorids": ["myeh003@ucr.edu", "yzhu015@ucr.edu", "epapalex@cs.ucr.edu", "mueen@unm.edu", "eamonn@cs.ucr.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825733223, "id": "ICLR.cc/2018/Conference/-/Paper464/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "r1vccClCb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper464/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper464/Authors|ICLR.cc/2018/Conference/Paper464/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper464/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper464/Authors|ICLR.cc/2018/Conference/Paper464/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper464/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper464/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper464/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper464/Reviewers", "ICLR.cc/2018/Conference/Paper464/Authors", "ICLR.cc/2018/Conference/Paper464/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825733223}}}, {"tddate": null, "ddate": null, "tmdate": 1515180856842, "tcdate": 1515180856842, "number": 1, "cdate": 1515180856842, "id": "rJ-BQUaXM", "invitation": "ICLR.cc/2018/Conference/-/Paper464/Official_Comment", "forum": "r1vccClCb", "replyto": "S1JBxOqlz", "signatures": ["ICLR.cc/2018/Conference/Paper464/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2018/Conference/Paper464/Authors"], "content": {"title": "Thank you very much for your valuable review", "comment": "Dear Reviewer,\n\nThank you very much for your valuable review. Addressing your concerns has made our paper much stronger. Our responses to the major issues are listed below:\n\nIssue 1: There are some unaddressed theoretical questions. The optimal solution to predict the set of neighbor points in mean-squared metric is to predict the average of those points, which is not well justified as the averaged image can easily fall off the data manifold. This may lead to a more blurry reconstruction when k increases, despite the intra-class targets are tight. It can also in turn harm the latent representation when euclidean neighbors are not actually similar (e.g. images in cifar10/imagenet that are not as simple as 10 digits). This seems to be a defect of the neighbor-encoder method and is not discussed in the paper.\nResponse to Issue 1: Thank you for raising this concern. The issue is addressed by removing the original configuration in question (in which we randomly selected one of the k nearest neighbors as the target to predict) as it does have this \"averaging\" problem. All the experiments are rerun with the most basic neighbor-encoder setting, in which we predict only the nearest neighbor of each object. As the target to predict is fixed, we no longer suffer from the \"averaging neighbors\" problem.\n\nIssue 2: The data sets used in the experiments are relatively small and simple, larger-scale experiments should be conducted. The fluctuations in Figure 9 and 10 suggest the significant variances in the results. Also, more complicated data/images can decrease the actual similarities of euclidean neighbors, thus affecting the results.\nResponse to Issue 2: After we rerun all the experiments described in response to Issue 1, we no longer see significant variance in the results. A new set of experiment on CIFAR 10 is performed and reported in Section 4.2. We also included experiments comparing three variants of neighbor-encoder (vanilla, denoising, variational) with their autoencoder counterparts.\n\nIssue 3: The baselines are weak. Only the most basic auto-encoder is compared, no additional variants or other data augmentation techniques are compared. It is possible other variants improve the basic auto-encoder in similar ways.\nResponse to Issue 3: We added comparison to two more popular variants of autoencoder, the denoising and variational autoencoder, in all of our experiments.\n\nIssue 4: Some results are not very well explained. It seems the performance increases monotonically as the number of neighbors increases (Figure 5, 9, 10). Will this continue or when will the performance decrease? I would expect it to decrease as the far away neighbors will be dissimilar. The authors can either attach the nearest neighbors figures or their statistics, and provide explanations on when and why the performance decrease is expected.\nResponse to Issue 4: We believe that Figure 6 addresses this issue. A new set of experiments is performed by using neighbors that are further away (i.e., changing 1st neighbor to the ith nearest neighbor). The performance decreases as expected when i is larger than 16 because the performance is crippled by lower quality neighbors. Figure 15 shows example neighbor pairs under different proximity settings.\n\nIssue 5: Some notations are confusing and need to be improved. For example, X and Y are actually the same set of images, the separation is a bit confusing; y_i \\in y in last paragraph of page 4 is incorrect, should use something like y_i in N(y).\nResponse to Issue 5: The notation is improved as suggested.\n\nThanks,\nAuthors"}, "nonreaders": [], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"title": "Neighbor-encoder", "abstract": "We propose a novel unsupervised representation learning framework called neighbor-encoder in which domain knowledge can be trivially incorporated into the learning process without modifying the general encoder-decoder architecture. In contrast to autoencoder, which reconstructs the input data, neighbor-encoder reconstructs the input data's neighbors. The proposed neighbor-encoder can be considered as a generalization of autoencoder as the input data can be treated as the nearest neighbor of itself with zero distance. By reformulating the representation learning problem as a neighbor reconstruction problem, domain knowledge can be easily incorporated with appropriate definition of similarity or distance between objects. As such, any existing similarity search algorithms can be easily integrated into our framework. Applications of other algorithms (e.g., association rule mining) in our framework is also possible since the concept of ``neighbor\" is an abstraction which can be appropriately defined differently in different contexts. We have demonstrated the effectiveness of our framework in various domains, including images, time series, music, etc., with various neighbor definitions. Experimental results show that neighbor-encoder outperforms autoencoder in most scenarios we considered.", "pdf": "/pdf/37dcfc2fa414e93481ebef2c24570a2c09b5945a.pdf", "paperhash": "yeh|neighborencoder", "_bibtex": "@misc{\nmichael2018neighborencoder,\ntitle={Neighbor-encoder},\nauthor={Chin-Chia Michael Yeh and Yan Zhu and Evangelos E. Papalexakis and Abdullah Mueen and Eamonn Keogh},\nyear={2018},\nurl={https://openreview.net/forum?id=r1vccClCb},\n}", "keywords": ["unsupervised learning", "representation learning", "autoencoder"], "authors": ["Chin-Chia Michael Yeh", "Yan Zhu", "Evangelos E. Papalexakis", "Abdullah Mueen", "Eamonn Keogh"], "authorids": ["myeh003@ucr.edu", "yzhu015@ucr.edu", "epapalex@cs.ucr.edu", "mueen@unm.edu", "eamonn@cs.ucr.edu"]}, "tags": [], "invitation": {"rdate": null, "duedate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "tmdate": 1516825733223, "id": "ICLR.cc/2018/Conference/-/Paper464/Official_Comment", "writers": ["ICLR.cc/2018/Conference"], "signatures": ["ICLR.cc/2018/Conference"], "readers": ["everyone"], "reply": {"replyto": null, "forum": "r1vccClCb", "writers": {"values-regex": "ICLR.cc/2018/Conference/Paper464/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper464/Authors|ICLR.cc/2018/Conference/Paper464/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs"}, "signatures": {"values-regex": "ICLR.cc/2018/Conference/Paper464/AnonReviewer[0-9]+|ICLR.cc/2018/Conference/Paper464/Authors|ICLR.cc/2018/Conference/Paper464/Area_Chair|ICLR.cc/2018/Conference/Program_Chairs", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "value-dropdown": ["everyone", "ICLR.cc/2018/Conference/Paper464/Authors_and_Higher", "ICLR.cc/2018/Conference/Paper464/Reviewers_and_Higher", "ICLR.cc/2018/Conference/Paper464/Area_Chairs_and_Higher", "ICLR.cc/2018/Conference/Program_Chairs"]}, "content": {"title": {"required": true, "order": 0, "description": "Brief summary of your comment.", "value-regex": ".{1,500}"}, "comment": {"required": true, "order": 1, "description": "Your comment or reply (max 5000 characters).", "value-regex": "[\\S\\s]{1,5000}"}}}, "nonreaders": [], "noninvitees": [], "invitees": ["ICLR.cc/2018/Conference/Paper464/Reviewers", "ICLR.cc/2018/Conference/Paper464/Authors", "ICLR.cc/2018/Conference/Paper464/Area_Chair", "ICLR.cc/2018/Conference/Program_Chairs"], "cdate": 1516825733223}}}], "count": 10}