{"notes": [{"ddate": null, "legacy_migration": true, "tmdate": 1392727800000, "tcdate": 1392727800000, "number": 4, "id": "fiPAUv7VOTUR5", "invitation": "ICLR.cc/2014/-/submission/workshop/review", "forum": "wJuDwQ-d3XJMj", "replyto": "wJuDwQ-d3XJMj", "signatures": ["Alexey Dosovitskiy"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "An updated version of the paper is now available on arXiv. Main changes are:\r\n- extended related work, including brief discussion of connection to metric learning\r\n- an experiment on classification with random filters: plot in fig. 4,  description in the beginning of section 3.2"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised feature learning by augmenting single images", "decision": "submitted, no decision", "abstract": "When deep learning is applied to visual object recognition, data augmentation is often used to generate additional training data without extra labeling cost. It helps to reduce overfitting and increase the performance of the algorithm. In this paper we investigate if it is possible to use data augmentation as the main component of an unsupervised feature learning architecture. To that end we sample a set of random image patches and declare each of them to be a separate single-image surrogate class. We then extend these trivial one-element classes by applying a variety of transformations to the initial 'seed' patches. Finally we train a convolutional neural network to discriminate between these surrogate classes. The feature representation learned by the network can then be used in various vision tasks. We find that this simple feature learning algorithm is surprisingly successful, achieving competitive classification results on several popular vision datasets (STL-10, CIFAR-10, Caltech-101).", "pdf": "https://arxiv.org/abs/1312.5242", "paperhash": "dosovitskiy|unsupervised_feature_learning_by_augmenting_single_images", "keywords": [], "conflicts": [], "authors": ["Alexey Dosovitskiy", "Jost Tobias Springenberg", "Thomas Brox"], "authorids": ["adosovitskiy@gmail.com", "springj@informatik.uni-freiburg.de", "brox@cs.uni-freiburg.de"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1392237300000, "tcdate": 1392237300000, "number": 3, "id": "TN0nh4UfnshfF", "invitation": "ICLR.cc/2014/-/submission/workshop/review", "forum": "wJuDwQ-d3XJMj", "replyto": "wJuDwQ-d3XJMj", "signatures": ["Alexey Dosovitskiy"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "", "review": "We thank the reviewers for the positive feedback and useful comments. \r\n\r\nIt is certainly true that the paper could include more experiments and comparisons (as both reviewers point out), that is why we submitted it as a short workshop paper. We will include more experiments in follow-up versions of the paper.\r\n\r\nReviewer 1 (Anonymous 672b) points out that we do not discuss complexity issues and details of the algorithm such as used transformations and the effect of dropout. The complexity is the same as for training convolutional neural networks: in our experiments training usually takes 0.5 to 3 days, depending on the size of the network.  We discuss details of the applied transformations in section 2.1. Using dropout is nowadays a standard practice for training deep convolutional neural networks and studies have been published by others, hence we do not analyze its effect in detail (however, preliminary experiments show that the benefits are quite large).\r\n\r\nReviewer 2 (Anonymous 536d) points out that we do not discuss the connection to metric learning approaches and that our approach is very much similar to those. We thank the reviewer for pointing out this connection and will include a corresponding remark in the paper. \r\n\r\nHowever, we do not agree that our approach is very similar to the one proposed in [1]. First of all, their algorithm uses label information, while ours does not. Secondly, even if we applied the algorithm from [1] to our surrogate clusters, our discriminative objective is different from the 'spring system' objective in [1]. Our objective yields features which perform well in classification without need to specify parameters such as functions that represent 'attractive' and 'repulsive' forces, as in [1]. Finally, the quality of the features learned by our algorithm is demonstrated by good classification results. On the other hand, the paper [1] does not show any. \r\n\r\nWe will upload a newer version of the paper, modified according to some of the remarks, later this week.\r\n\r\nBest regards,\r\nAlexey Dosovitskiy, Jost Tobias Springenberg, Thomas Brox\r\n\r\n-----------\r\nReferences:\r\n\r\n[1] Raia Hadsell, Sumit Chopra and Yann LeCun: Dimensionality Reduction by Learning an Invariant Mapping, Proc. Computer Vision and Pattern Recognition Conference (CVPR'06), IEEE Press, 2006"}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised feature learning by augmenting single images", "decision": "submitted, no decision", "abstract": "When deep learning is applied to visual object recognition, data augmentation is often used to generate additional training data without extra labeling cost. It helps to reduce overfitting and increase the performance of the algorithm. In this paper we investigate if it is possible to use data augmentation as the main component of an unsupervised feature learning architecture. To that end we sample a set of random image patches and declare each of them to be a separate single-image surrogate class. We then extend these trivial one-element classes by applying a variety of transformations to the initial 'seed' patches. Finally we train a convolutional neural network to discriminate between these surrogate classes. The feature representation learned by the network can then be used in various vision tasks. We find that this simple feature learning algorithm is surprisingly successful, achieving competitive classification results on several popular vision datasets (STL-10, CIFAR-10, Caltech-101).", "pdf": "https://arxiv.org/abs/1312.5242", "paperhash": "dosovitskiy|unsupervised_feature_learning_by_augmenting_single_images", "keywords": [], "conflicts": [], "authors": ["Alexey Dosovitskiy", "Jost Tobias Springenberg", "Thomas Brox"], "authorids": ["adosovitskiy@gmail.com", "springj@informatik.uni-freiburg.de", "brox@cs.uni-freiburg.de"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391729340000, "tcdate": 1391729340000, "number": 2, "id": "JJNs1ddmaWfyT", "invitation": "ICLR.cc/2014/-/submission/workshop/review", "forum": "wJuDwQ-d3XJMj", "replyto": "wJuDwQ-d3XJMj", "signatures": ["anonymous reviewer 536d"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Unsupervised feature learning by augmenting single images", "review": "This paper proposes to reduce the unsupervised feature learning problem to a classification problem by: a) sampling patches at random from (unlabeled) images (in the order of several thousands) and b) creating surrogate classification tasks by considering each patch as a class and by generating several other samples by applying transformations (e.g., translation, rotation, scaling, etc.).\r\nThe features trained in this manner are used as patch descriptors for to classify images in Caltech 101, CIFAR and STL-10 datasets. The method compares well with other feature learning methods.\r\n\r\nThe paper reads well and has a clear narrative. The reduction from unsupervised to supervised learning is presented in an intriguing way. On the other hand, this method seems closely related to work in metric learning and it would be nice to have an explicit discussion about this.\r\n\r\nPros\r\n+ clearly written\r\n+ simple idea\r\n+ empirical analysis demonstrates good results\r\n\r\nCons\r\n- some baseline experiments are missing, namely\r\n  - compare to random filters (i.e., what\u2019s the role played by the architecture used)\r\n  - it would be nice to see a comparison of the accuracy after fine-tuning the whole system\r\n- prior reference to work in metric learning (neighborhood component analysis, DrLIM style) is not mentioned. One can cast a similar learning problem: making the features of patches belonging to the same \u201cclass\u201d be similar, and making the features of patches belonging to different \u201cclasses\u201d be as far as possible. I believe that by using a ranking loss on such triplets would yield similar results. Under this view, the paper would become very much similar to:\r\nRaia Hadsell, Sumit Chopra and Yann LeCun: Dimensionality Reduction by Learning an Invariant Mapping, Proc. Computer Vision and Pattern Recognition Conference (CVPR'06), IEEE Press, 2006\r\nexcept that the generation of similar and different patches is produced by transformation known in advance. One advantage of these metric learning approaches is that they naturally scale to an \u201cinfinite\u201d number of \u201cclasses\u201d.\r\n\r\nMinor details:\r\n- the schedule on the number of classes seems rather hacky\r\n- the overfitting hypothesis in sec. 3.2 could be easily be tested."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised feature learning by augmenting single images", "decision": "submitted, no decision", "abstract": "When deep learning is applied to visual object recognition, data augmentation is often used to generate additional training data without extra labeling cost. It helps to reduce overfitting and increase the performance of the algorithm. In this paper we investigate if it is possible to use data augmentation as the main component of an unsupervised feature learning architecture. To that end we sample a set of random image patches and declare each of them to be a separate single-image surrogate class. We then extend these trivial one-element classes by applying a variety of transformations to the initial 'seed' patches. Finally we train a convolutional neural network to discriminate between these surrogate classes. The feature representation learned by the network can then be used in various vision tasks. We find that this simple feature learning algorithm is surprisingly successful, achieving competitive classification results on several popular vision datasets (STL-10, CIFAR-10, Caltech-101).", "pdf": "https://arxiv.org/abs/1312.5242", "paperhash": "dosovitskiy|unsupervised_feature_learning_by_augmenting_single_images", "keywords": [], "conflicts": [], "authors": ["Alexey Dosovitskiy", "Jost Tobias Springenberg", "Thomas Brox"], "authorids": ["adosovitskiy@gmail.com", "springj@informatik.uni-freiburg.de", "brox@cs.uni-freiburg.de"]}, "tags": [], "invitation": {}}}, {"ddate": null, "legacy_migration": true, "tmdate": 1391695860000, "tcdate": 1391695860000, "number": 1, "id": "stMdtDjJlgWU8", "invitation": "ICLR.cc/2014/-/submission/workshop/review", "forum": "wJuDwQ-d3XJMj", "replyto": "wJuDwQ-d3XJMj", "signatures": ["anonymous reviewer 672b"], "readers": ["everyone"], "writers": ["anonymous"], "content": {"title": "review of Unsupervised feature learning by augmenting single images", "review": "The paper presents an approach for learning the filters of a convolutional NN, for an image classification task, without making use of target labels. The algorithm proceeds in two steps: learning a transformation of the original image and then learning a classifier using this new representation. For the first step, patches are sampled from an image collection, each patch will then correspond to a surrogate class and a classifier will be trained to associate transformed versions of the patches to the corresponding class labels using a convolutional net. In a second step, this net is replicated on whole images leading to a transformed representation of the original image. A linear classifier is then trained using this representation as input and the target labels relative to the image collection. Experiments are performed on different image collections and a comparison with several baselines is provided.\r\nThis paper introduces a simple idea for feature learning which seems to work relatively well. The paper could be easily improved or extended in several ways.  A natural extension would be to tune the learned filters using the target labels, which would allow a comparison with state of the art supervised techniques. This method might be less expensive for training than some of the alternatives, but the complexity issues are not discussed at all. The choices made for the convolutional net produce very dense codes. This could be discussed and a comparison with alternatives, e.g. larger filter size could be provided.\r\nAlso there could be more practical details like what are the combinations of transformations used for the patches, what is the increase provided by the dropout etc."}, "nonreaders": [], "details": {"replyCount": 0, "overwriting": [], "revisions": false, "forumContent": {"title": "Unsupervised feature learning by augmenting single images", "decision": "submitted, no decision", "abstract": "When deep learning is applied to visual object recognition, data augmentation is often used to generate additional training data without extra labeling cost. It helps to reduce overfitting and increase the performance of the algorithm. In this paper we investigate if it is possible to use data augmentation as the main component of an unsupervised feature learning architecture. To that end we sample a set of random image patches and declare each of them to be a separate single-image surrogate class. We then extend these trivial one-element classes by applying a variety of transformations to the initial 'seed' patches. Finally we train a convolutional neural network to discriminate between these surrogate classes. The feature representation learned by the network can then be used in various vision tasks. We find that this simple feature learning algorithm is surprisingly successful, achieving competitive classification results on several popular vision datasets (STL-10, CIFAR-10, Caltech-101).", "pdf": "https://arxiv.org/abs/1312.5242", "paperhash": "dosovitskiy|unsupervised_feature_learning_by_augmenting_single_images", "keywords": [], "conflicts": [], "authors": ["Alexey Dosovitskiy", "Jost Tobias Springenberg", "Thomas Brox"], "authorids": ["adosovitskiy@gmail.com", "springj@informatik.uni-freiburg.de", "brox@cs.uni-freiburg.de"]}, "tags": [], "invitation": {}}}, {"replyto": null, "ddate": null, "legacy_migration": true, "tmdate": 1387465380000, "tcdate": 1387465380000, "number": 2, "id": "wJuDwQ-d3XJMj", "invitation": "ICLR.cc/2014/workshop/-/submission", "forum": "wJuDwQ-d3XJMj", "signatures": ["adosovitskiy@gmail.com"], "readers": ["everyone"], "content": {"title": "Unsupervised feature learning by augmenting single images", "decision": "submitted, no decision", "abstract": "When deep learning is applied to visual object recognition, data augmentation is often used to generate additional training data without extra labeling cost. It helps to reduce overfitting and increase the performance of the algorithm. In this paper we investigate if it is possible to use data augmentation as the main component of an unsupervised feature learning architecture. To that end we sample a set of random image patches and declare each of them to be a separate single-image surrogate class. We then extend these trivial one-element classes by applying a variety of transformations to the initial 'seed' patches. Finally we train a convolutional neural network to discriminate between these surrogate classes. The feature representation learned by the network can then be used in various vision tasks. We find that this simple feature learning algorithm is surprisingly successful, achieving competitive classification results on several popular vision datasets (STL-10, CIFAR-10, Caltech-101).", "pdf": "https://arxiv.org/abs/1312.5242", "paperhash": "dosovitskiy|unsupervised_feature_learning_by_augmenting_single_images", "keywords": [], "conflicts": [], "authors": ["Alexey Dosovitskiy", "Jost Tobias Springenberg", "Thomas Brox"], "authorids": ["adosovitskiy@gmail.com", "springj@informatik.uni-freiburg.de", "brox@cs.uni-freiburg.de"]}, "writers": [], "details": {"replyCount": 4, "writable": false, "overwriting": [], "revisions": false, "tags": [], "invitation": {"rdate": null, "tddate": null, "ddate": null, "multiReply": null, "taskCompletionCount": null, "duedate": 1369422751717, "tmdate": 1496674357014, "id": "ICLR.cc/2014/workshop/-/submission", "writers": ["ICLR.cc/2014"], "signatures": ["OpenReview.net"], "readers": ["everyone"], "invitees": ["~"], "reply": {"forum": null, "replyto": null, "writers": {"values-regex": "~.*"}, "signatures": {"values-regex": "~.*", "description": "How your identity will be displayed with the above content."}, "readers": {"description": "The users who will be allowed to read the above content.", "values": ["everyone"]}, "content": {"pdf": {"required": true, "order": 5, "description": "Either upload a PDF file or provide a direct link to your PDF on ArXiv (link must begin with http(s) and end with .pdf)", "value-regex": "upload|(http|https):\\/\\/.+\\.pdf"}, "title": {"required": true, "order": 1, "description": "Title of paper.", "value-regex": ".{1,250}"}, "abstract": {"required": true, "order": 4, "description": "Abstract of paper.", "value-regex": "[\\S\\s]{1,5000}"}, "authors": {"required": true, "order": 2, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author names, as they appear in the paper."}, "conflicts": {"required": true, "order": 100, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of email domains of people who would have a conflict of interest in reviewing this paper, (e.g., cs.umass.edu;google.com, etc.)."}, "keywords": {"order": 6, "description": "Comma separated list of keywords.", "values-dropdown": []}, "authorids": {"required": true, "order": 3, "values-regex": "[^;,\\n]+(,[^,\\n]+)*", "description": "Comma separated list of author email addresses, in the same order as above."}}}, "nonreaders": [], "noninvitees": [], "expdate": 1377198751717, "cdate": 1496674357014}}}], "count": 5}