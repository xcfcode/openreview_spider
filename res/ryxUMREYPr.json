{"notes": [{"id": "ryxUMREYPr", "original": "r1ePOTVuvH", "number": 1000, "cdate": 1569439245520, "ddate": null, "tcdate": 1569439245520, "tmdate": 1577168257884, "tddate": null, "forum": "ryxUMREYPr", "replyto": null, "invitation": "ICLR.cc/2020/Conference/-/Blind_Submission", "content": {"authorids": ["wuzhenyu_sjtu@tamu.edu", "ye.yuan@tamu.edu", "zhawang@adobe.com", "jianmzha@adobe.com", "atlaswang@tamu.edu", "hljin@adobe.com"], "title": "Is There Mode Collapse? A Case Study on Face Generation and Its Black-box Calibration", "authors": ["Zhenyu Wu", "Ye Yuan", "Zhaowen Wang", "Jianming Zhang", "Zhangyang Wang", "Hailin Jin"], "pdf": "/pdf/45b7ac46e27f3ef1ae8fa3190726e39ef4e2a65c.pdf", "abstract": "Generative adversarial networks (GANs) nowadays are capable of producing im-ages of incredible realism.   One concern raised is whether the state-of-the-artGAN\u2019s learned distribution still suffers from mode collapse. Existing evaluation metrics for image synthesis focus on low-level perceptual quality. Diversity tests of samples from GANs are usually conducted qualitatively on a small scale. In this work, we devise a set of statistical tools, that are broadly applicable to quantitatively measuring the mode collapse of GANs. Strikingly, we consistently observe strong mode collapse on several state-of-the-art GANs using our toolset.  We analyze possible causes, and for the first time present two simple yet effective \u201cblack-box\u201d methods to calibrate the GAN learned distribution, without accessing either model parameters or the original training data.", "keywords": ["Generative Adversarial Networks", "Mode Collapse", "Calibration"], "paperhash": "wu|is_there_mode_collapse_a_case_study_on_face_generation_and_its_blackbox_calibration", "original_pdf": "/attachment/32e7edfaf3159d0c4361563a0795198fac048d94.pdf", "_bibtex": "@misc{\nwu2020is,\ntitle={Is There Mode Collapse? A Case Study on Face Generation and Its Black-box Calibration},\nauthor={Zhenyu Wu and Ye Yuan and Zhaowen Wang and Jianming Zhang and Zhangyang Wang and Hailin Jin},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxUMREYPr}\n}"}, "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "details": {"replyCount": 8, "writable": false, "overwriting": [], "revisions": true, "tags": [], "invitation": {"reply": {"readers": {"values-regex": ".*"}, "writers": {"values": ["ICLR.cc/2020/Conference"]}, "signatures": {"values": ["ICLR.cc/2020/Conference"]}, "content": {"spotlight_video": {"value-regex": ".*"}, "full_presentation_video": {"value-regex": ".*"}, "original_pdf": {"required": false, "description": "Upload a PDF file that ends with .pdf", "value-regex": ".*"}, "appendix": {"value-regex": ".*"}, "authorids": {"values-regex": ".*"}, "poster": {"value-regex": ".*"}, "authors": {"values": ["Anonymous"]}, "slides": {"value-regex": ".*"}}}, "final": [], "signatures": ["ICLR.cc/2020/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference"], "noninvitees": [], "tcdate": 1569271260237, "tmdate": 1593459412141, "id": "ICLR.cc/2020/Conference/-/Blind_Submission"}}, "tauthor": "OpenReview.net"}, {"id": "myzUxy6lvs", "original": null, "number": 1, "cdate": 1576798711877, "ddate": null, "tcdate": 1576798711877, "tmdate": 1576800924517, "tddate": null, "forum": "ryxUMREYPr", "replyto": "ryxUMREYPr", "invitation": "ICLR.cc/2020/Conference/Paper1000/-/Decision", "content": {"decision": "Reject", "comment": "This paper studies the problem of mode collapse in GANs. The authors present new metrics to judge the model's diversity of the generated faces. The authors present two black-box approaches to increasing the model diversity. The benefit of using a black box approach is that the method does not require access to the weights of the model and hence it is more easily usable than white-box approaches. However, there are significant evaluation problems and lack of theoretical and empirical motivation on why the methods proposed by the paper are good. The reviewers have not changed their score after having read the response and there is still some gaps in evaluation which can be improved in the paper. Thus, I'm recommending a Rejection.", "title": "Paper Decision"}, "signatures": ["ICLR.cc/2020/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Program_Chairs"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["wuzhenyu_sjtu@tamu.edu", "ye.yuan@tamu.edu", "zhawang@adobe.com", "jianmzha@adobe.com", "atlaswang@tamu.edu", "hljin@adobe.com"], "title": "Is There Mode Collapse? A Case Study on Face Generation and Its Black-box Calibration", "authors": ["Zhenyu Wu", "Ye Yuan", "Zhaowen Wang", "Jianming Zhang", "Zhangyang Wang", "Hailin Jin"], "pdf": "/pdf/45b7ac46e27f3ef1ae8fa3190726e39ef4e2a65c.pdf", "abstract": "Generative adversarial networks (GANs) nowadays are capable of producing im-ages of incredible realism.   One concern raised is whether the state-of-the-artGAN\u2019s learned distribution still suffers from mode collapse. Existing evaluation metrics for image synthesis focus on low-level perceptual quality. Diversity tests of samples from GANs are usually conducted qualitatively on a small scale. In this work, we devise a set of statistical tools, that are broadly applicable to quantitatively measuring the mode collapse of GANs. Strikingly, we consistently observe strong mode collapse on several state-of-the-art GANs using our toolset.  We analyze possible causes, and for the first time present two simple yet effective \u201cblack-box\u201d methods to calibrate the GAN learned distribution, without accessing either model parameters or the original training data.", "keywords": ["Generative Adversarial Networks", "Mode Collapse", "Calibration"], "paperhash": "wu|is_there_mode_collapse_a_case_study_on_face_generation_and_its_blackbox_calibration", "original_pdf": "/attachment/32e7edfaf3159d0c4361563a0795198fac048d94.pdf", "_bibtex": "@misc{\nwu2020is,\ntitle={Is There Mode Collapse? A Case Study on Face Generation and Its Black-box Calibration},\nauthor={Zhenyu Wu and Ye Yuan and Zhaowen Wang and Jianming Zhang and Zhangyang Wang and Hailin Jin},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxUMREYPr}\n}"}, "tags": [], "invitation": {"reply": {"writers": {"description": "How your identity will be displayed.", "values-regex": ["ICLR.cc/2020/Conference/Program_Chairs"]}, "signatures": {"values": ["ICLR.cc/2020/Conference/Program_Chairs"], "description": "How your identity will be displayed."}, "content": {"decision": {"value-radio": ["Accept (Spotlight)", "Accept (Talk)", "Accept (Poster)", "Reject"], "description": "Decision", "required": true, "order": 2}, "title": {"value": "Paper Decision", "required": true, "order": 1}, "comment": {"value-regex": "[\\S\\s]{0,5000}", "description": "", "required": false, "order": 3}}, "forum": "ryxUMREYPr", "replyto": "ryxUMREYPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}}, "expdate": 1576854540000, "duedate": 1576853940000, "multiReply": false, "readers": ["everyone"], "invitees": ["ICLR.cc/2020/Conference/Program_Chairs"], "tcdate": 1576795711998, "tmdate": 1576800261292, "super": "ICLR.cc/2020/Conference/-/Decision", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1000/-/Decision"}}}, {"id": "SJlp3GIRtr", "original": null, "number": 2, "cdate": 1571869364587, "ddate": null, "tcdate": 1571869364587, "tmdate": 1574460986110, "tddate": null, "forum": "ryxUMREYPr", "replyto": "ryxUMREYPr", "invitation": "ICLR.cc/2020/Conference/Paper1000/-/Official_Review", "content": {"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #2", "review": "The direction of this work, to evaluate whether mode collapse exists without using label information, is very good. Rather than using the labels, the authors use an off-the-shelf model (on faces) to provide a space on which to measure distances between generated images. They use this distance to test the hypothesis that samples are highly concentrated around some modes, thus under representing others.\n\nThe paper could benefit from more clarity. For instance, the methods would be better illustrated through some toy figures. In addition, some explanations in this work are very hard to parse, e.g., the first paragraph of the methods section.\n\nWhile this work is focusing on black box methods for evaluating and palliating mode dropping (aka collapse), it's a bit disappointing that these results are at least also evaluating on white-box type methods in settings where mode dropping is clearer, e.g. PACGAN on stacked MNIST or even normal CelebA. Unfortunately, no white-box methods are covered in this work, so there is no strong point of comparison, which would be helpful to establish the validity of this work.\n\nFinally, the authors demonstrated that there exist a high-density mode, but not whether some modes might be missing. How can this method be used to find missing modes if the generator isn't generating them without the real data? If my generator is only generating a few digits, but each of them represented similarly by the generated distribution, what would this measure do? It wont detect that the generator is missing modes: you'd need to know those modes existed (e.g., have examples of them).\n\nGenerally I like the experiments, though I wish there were more qualitative results looking at more than just the existence of one worst-case mode.\n\nOther comments\npage 1\nI'm not sure the connection between mode collapse and instability is well-established. What motivates connecting to instability in this work?\nThe statement about co-variate shift is a little vague, and it's not clear what the connection to mode collapse is.\npage 2\nI'm surprised PACGAN isn't mentioned in the white-box methods. It was one of the big SOTA methods for palliating mode dropping.\nI'm not sure why ignore white-box methods: at least it would be good verification that this method works (e.g., across methods, common measures of collapse used in those settings, etc)\npage 3\nThe first paragraph of Section 3 is very difficult to understand.\nf is normalized?\npage 4\nWhy not use Ripley's K? (this is not explained, and should be)\nThe main link missing in the test proposed is that to mode dropping. The problem is that this measure wont detect mode dropping if there's aren't samples from those modes to measure anything against. You need real samples as well.\nHow were these face models chosen? Why not use the discriminator of the GAN (at least test what it does)? How were these hyper parameters chosen?\npage 7:\n5.1.2 could use an accompanying toy figure demonstrating what's going on.\n\n---- Update ---\nThanks for your responses and the updated experiment on the white-box calibration. I still think that comparisons to existing methods that palliate mode-dropping is essential for this work, and I would encourage you to bring experiments that allow for comparison to PACGAN et al into the main text for future versions, as the work / direction as value. I will keep my score as-is.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1000/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1000/AnonReviewer2"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["wuzhenyu_sjtu@tamu.edu", "ye.yuan@tamu.edu", "zhawang@adobe.com", "jianmzha@adobe.com", "atlaswang@tamu.edu", "hljin@adobe.com"], "title": "Is There Mode Collapse? A Case Study on Face Generation and Its Black-box Calibration", "authors": ["Zhenyu Wu", "Ye Yuan", "Zhaowen Wang", "Jianming Zhang", "Zhangyang Wang", "Hailin Jin"], "pdf": "/pdf/45b7ac46e27f3ef1ae8fa3190726e39ef4e2a65c.pdf", "abstract": "Generative adversarial networks (GANs) nowadays are capable of producing im-ages of incredible realism.   One concern raised is whether the state-of-the-artGAN\u2019s learned distribution still suffers from mode collapse. Existing evaluation metrics for image synthesis focus on low-level perceptual quality. Diversity tests of samples from GANs are usually conducted qualitatively on a small scale. In this work, we devise a set of statistical tools, that are broadly applicable to quantitatively measuring the mode collapse of GANs. Strikingly, we consistently observe strong mode collapse on several state-of-the-art GANs using our toolset.  We analyze possible causes, and for the first time present two simple yet effective \u201cblack-box\u201d methods to calibrate the GAN learned distribution, without accessing either model parameters or the original training data.", "keywords": ["Generative Adversarial Networks", "Mode Collapse", "Calibration"], "paperhash": "wu|is_there_mode_collapse_a_case_study_on_face_generation_and_its_blackbox_calibration", "original_pdf": "/attachment/32e7edfaf3159d0c4361563a0795198fac048d94.pdf", "_bibtex": "@misc{\nwu2020is,\ntitle={Is There Mode Collapse? A Case Study on Face Generation and Its Black-box Calibration},\nauthor={Zhenyu Wu and Ye Yuan and Zhaowen Wang and Jianming Zhang and Zhangyang Wang and Hailin Jin},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxUMREYPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryxUMREYPr", "replyto": "ryxUMREYPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1000/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1000/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575667298399, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1000/Reviewers"], "noninvitees": [], "tcdate": 1570237743851, "tmdate": 1575667298412, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1000/-/Official_Review"}}}, {"id": "B1xNDIKosH", "original": null, "number": 2, "cdate": 1573783132116, "ddate": null, "tcdate": 1573783132116, "tmdate": 1573807808015, "tddate": null, "forum": "ryxUMREYPr", "replyto": "SJlp3GIRtr", "invitation": "ICLR.cc/2020/Conference/Paper1000/-/Official_Comment", "content": {"title": "Response to Reviewer #2", "comment": "Thank you for your careful reading and comments!\n\n- Q1:  Thanks for kindly pointing out our writing issues. We add a toy figure to better explain our evaluation process, please see Appendix Figure 6 in the revised paper.\n\n- Q2: We basically agree with your comment that evaluating on white-box type GAN mode-collapse calibrations need to be included. We attach the results of a white-box approach, i.e., importance sampling, in Appendix Figure 7. We are conducting the experiments on PacGAN that you have suggested and will update the results in comments once they become available, and also add them to the paper\u2019s next update.\n\nWe can observe that the FID score only marginally increases after the white-box calibration. Meanwhile, the solid-red line (before calibration) is shifted to the right dash-red line (after calibration), indicating that the white-box approach can alleviate the mode collapse problem and no severer mode is introduced. Besides, the solid-green line and dash-green line are almost overlaid, suggesting that the white-box approach has minimal impact on other modes.\n\n- Q3: In the current evaluation metric, we only consider worst case because the worst case is the most important mode collapse problem we care in generative models, i.e., if the model always generates similar faces, we can not use the generated dataset for other training purposes due to fairness/privacy concern.\n\nHowever, our evaluation metric can be easily adapted to detect median/mean dense regions by using faces with different percentiles instead of top k dense faces (please see Appendix Fig. 8 in the revised paper). In this figure, we show the clustering pattern of choosing different percentiles in step 1 mode detection. We can observe that R_ref overlays with R_obs-20% and above, which demonstrates that around 20% of the generated images are highly clustered.\n\nBesides, our approach also has the capability to detect missing modes between training data and the generated data by estimating the probability of any specific face mode being sampled from the generator. Given two images $I_0$ and $I_1$, we define similarity between $I_0$ and $I_1$ as $1-d(I_0, I_1)$, where the distance $d$ follow the same definition of equation 1 in the paper. The expected similarity between $I_0$ and a random sampled face $G(z)$ is defined as $\\int s(I_0, G(z))p(z)dz$, where $z \\sim N(0, \\Sigma)$, $I=G(z)$. The integral can be computed more efficiently by importance sampling on $z$, such that $G(z)$ is closer to $I_0$ in distance.\n\nWe can detect mode dropping by comparing the expected similarity of the dropped mode to a randomly sampled face, with those non-dropped mode's similarity to a randomly sampled face. The smaller the expected similarity is, the more strongly the mode is dropped.\n\nMoreover, if we simply change the first step to randomly sample m images from the training data to capture enough modes, then we could find the missing modes by comparing the clustering pattern between the training data and the testing data. (please see Appendix Fig. 9 in the revised paper). We can observe that the R_ref overlays with R_obs and we can not reject the hypothesis. Generated images are not severely clustered around anchors from the training data, indicating that GAN models have the capability to generate \"new faces\". The width of the R_ref band in Fig. 7 is similar to that in Fig.8, suggesting that mode dropping is not severe between the training data and the generated images.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1000/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1000/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["wuzhenyu_sjtu@tamu.edu", "ye.yuan@tamu.edu", "zhawang@adobe.com", "jianmzha@adobe.com", "atlaswang@tamu.edu", "hljin@adobe.com"], "title": "Is There Mode Collapse? A Case Study on Face Generation and Its Black-box Calibration", "authors": ["Zhenyu Wu", "Ye Yuan", "Zhaowen Wang", "Jianming Zhang", "Zhangyang Wang", "Hailin Jin"], "pdf": "/pdf/45b7ac46e27f3ef1ae8fa3190726e39ef4e2a65c.pdf", "abstract": "Generative adversarial networks (GANs) nowadays are capable of producing im-ages of incredible realism.   One concern raised is whether the state-of-the-artGAN\u2019s learned distribution still suffers from mode collapse. Existing evaluation metrics for image synthesis focus on low-level perceptual quality. Diversity tests of samples from GANs are usually conducted qualitatively on a small scale. In this work, we devise a set of statistical tools, that are broadly applicable to quantitatively measuring the mode collapse of GANs. Strikingly, we consistently observe strong mode collapse on several state-of-the-art GANs using our toolset.  We analyze possible causes, and for the first time present two simple yet effective \u201cblack-box\u201d methods to calibrate the GAN learned distribution, without accessing either model parameters or the original training data.", "keywords": ["Generative Adversarial Networks", "Mode Collapse", "Calibration"], "paperhash": "wu|is_there_mode_collapse_a_case_study_on_face_generation_and_its_blackbox_calibration", "original_pdf": "/attachment/32e7edfaf3159d0c4361563a0795198fac048d94.pdf", "_bibtex": "@misc{\nwu2020is,\ntitle={Is There Mode Collapse? A Case Study on Face Generation and Its Black-box Calibration},\nauthor={Zhenyu Wu and Ye Yuan and Zhaowen Wang and Jianming Zhang and Zhangyang Wang and Hailin Jin},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxUMREYPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryxUMREYPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1000/Authors", "ICLR.cc/2020/Conference/Paper1000/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1000/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1000/Reviewers", "ICLR.cc/2020/Conference/Paper1000/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1000/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1000/Authors|ICLR.cc/2020/Conference/Paper1000/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504162830, "tmdate": 1576860544187, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1000/Authors", "ICLR.cc/2020/Conference/Paper1000/Reviewers", "ICLR.cc/2020/Conference/Paper1000/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1000/-/Official_Comment"}}}, {"id": "B1lO4M2jsr", "original": null, "number": 4, "cdate": 1573794351841, "ddate": null, "tcdate": 1573794351841, "tmdate": 1573807770835, "tddate": null, "forum": "ryxUMREYPr", "replyto": "HJlStebC5r", "invitation": "ICLR.cc/2020/Conference/Paper1000/-/Official_Comment", "content": {"title": "Response to Review #3", "comment": "Thank you for your careful reading and comments.\n\nQ1: Missing assumptions about the black-box calibration approaches\nWe thank R1 and R2 for endorsing the merit of our proposed black-box calibration.\n\nThe black-box calibration assumes no read/write to model weights or availability training data, but access to the sampling of random seed. The black-box calibration is useful for both model user and API owner.\nModel owner: We suppose that the dense mode happens to be close to a specific training image, thus violating privacy. The model owner would like to calibrate the model to alleviate the mode collapse. In such a situation, training data may no longer be accessible since it contains private information, e.g. human faces or person images. Retraining consumes much time and energy, especially for complex models trained on a huge dataset. Besides, we empirically validate that the dense mode is not caused by imbalanced data or randomness during initialization/optimization. So retraining won't work for dense-mode alleviation. Our proposed black-box calibration has an advantage over retraining with minimum time and energy cost and no touching training data. Moreover, the calibration can target any dense mode for alleviation.\nAPI owner: For enterprise users having access to the face image generation service via cloud API, they are given the ping service for a huge number of times or not even restricted. Black-box calibration enables the API owner to customize the model's sampling process to meet the users' needs.\n\n\nQ2: Missing key experiments that will provide more motivation that 1. face identity can be used as a proxy for face image diversity; 2. applying our proposed metric to the training datasets should show no gap between $\\mathcal{R}_{obs}$ and $\\mathcal{R}_{ref}$:\n\n1. Face identity as a proxy for face image diversity\n\nWe would like to clarify that we are not using the identity label as a proxy. Instead, we are using the embedding features obtained from the neural network trained on the face recognition task. We claim that the embedding features have rich semantics of all kinds of facial attributes, e.g. age, gender, race and so on. The rich semantics of the face embedding feature can be validated by its strong transferability on other visual tasks, e.g. gender/race classification and age regression. Prior studies [Savchenko, Andrey V, \"Efficient facial representations for age, gender and identity recognition in organizing photo albums using multi-output ConvNet\" (2019)] have shown that transfer learning using neural networks pretrained on face recognition can produce highly effective results for gender recognition and age estimation.\n\n2. Applying our metric on the training set of FFHQ\n\nFFHQ is a public face dataset contains $56,138$ images, without repeating identities. We first randomly pick $1k$ images to form the S set and sort the S set according to the number of neighbors within distance 0.3. We choose the sample at percentile $0.01\\%, 0.1\\%, 1\\%, 10\\%, 20\\%, 30\\%, 40\\%, 50\\%, 60\\%, 70\\%, 80\\%, 90\\%$. We conduct the neighboring analysis on these selected samples. We still observe a gap between $\\mathcal{R}_{obs}$ and $\\mathcal{R}_{ref}$, which demonstrates that FFHQ dataset has dense mode, even without repeating identities. Furthermore, we would like to clarify that our metric is proposed to measure the collapse of GAN's learned distribution. We have empirically shown in the paper that the mode collapse still occurs despite balanced training data. You can check the details in the appendix of the paper, the paragraph of \"Applying Our Proposed Metric on FFHQ\".\n\nQ3: Minor improvements\n\n1. Proof or citation for the flaws of FID\nThere is a recently published survey paper that can back our claim. It is [Ali Borji, \"Pros and Cons of GAN Evaluation Measures\" (Arxiv 18)]\n\n2. The contradiction between the two statements\nWe use the word \"loss of diversity\" since IS's measuring of diversity is limited. E.g., on ImageNet with 1000 classes, it can not rule out the case when then generator simply repeating the same image for each different class.\n\n3. We take your advice and will address this piece of work as a \"pilot study\" in the final version."}, "signatures": ["ICLR.cc/2020/Conference/Paper1000/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1000/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["wuzhenyu_sjtu@tamu.edu", "ye.yuan@tamu.edu", "zhawang@adobe.com", "jianmzha@adobe.com", "atlaswang@tamu.edu", "hljin@adobe.com"], "title": "Is There Mode Collapse? A Case Study on Face Generation and Its Black-box Calibration", "authors": ["Zhenyu Wu", "Ye Yuan", "Zhaowen Wang", "Jianming Zhang", "Zhangyang Wang", "Hailin Jin"], "pdf": "/pdf/45b7ac46e27f3ef1ae8fa3190726e39ef4e2a65c.pdf", "abstract": "Generative adversarial networks (GANs) nowadays are capable of producing im-ages of incredible realism.   One concern raised is whether the state-of-the-artGAN\u2019s learned distribution still suffers from mode collapse. Existing evaluation metrics for image synthesis focus on low-level perceptual quality. Diversity tests of samples from GANs are usually conducted qualitatively on a small scale. In this work, we devise a set of statistical tools, that are broadly applicable to quantitatively measuring the mode collapse of GANs. Strikingly, we consistently observe strong mode collapse on several state-of-the-art GANs using our toolset.  We analyze possible causes, and for the first time present two simple yet effective \u201cblack-box\u201d methods to calibrate the GAN learned distribution, without accessing either model parameters or the original training data.", "keywords": ["Generative Adversarial Networks", "Mode Collapse", "Calibration"], "paperhash": "wu|is_there_mode_collapse_a_case_study_on_face_generation_and_its_blackbox_calibration", "original_pdf": "/attachment/32e7edfaf3159d0c4361563a0795198fac048d94.pdf", "_bibtex": "@misc{\nwu2020is,\ntitle={Is There Mode Collapse? A Case Study on Face Generation and Its Black-box Calibration},\nauthor={Zhenyu Wu and Ye Yuan and Zhaowen Wang and Jianming Zhang and Zhangyang Wang and Hailin Jin},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxUMREYPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryxUMREYPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1000/Authors", "ICLR.cc/2020/Conference/Paper1000/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1000/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1000/Reviewers", "ICLR.cc/2020/Conference/Paper1000/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1000/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1000/Authors|ICLR.cc/2020/Conference/Paper1000/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504162830, "tmdate": 1576860544187, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1000/Authors", "ICLR.cc/2020/Conference/Paper1000/Reviewers", "ICLR.cc/2020/Conference/Paper1000/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1000/-/Official_Comment"}}}, {"id": "Hye2jRossr", "original": null, "number": 3, "cdate": 1573793443765, "ddate": null, "tcdate": 1573793443765, "tmdate": 1573793443765, "tddate": null, "forum": "ryxUMREYPr", "replyto": "SJlp3GIRtr", "invitation": "ICLR.cc/2020/Conference/Paper1000/-/Official_Comment", "content": {"title": "Response to Reviewer #2 (Continued)", "comment": "Q1 Connection between mode collapse and instability: \nThe stability is more related to the GAN model itself, but we care more about the diversity of GAN generated results. We tried to alleviate the mode collapse problem while maintaining the stability of GAN models.\n\nQ2 Connection between co-variate shift and mode collapse is:\nWe followed the notion in this paper (https://arxiv.org/pdf/1711.00970.pdf) and consider mode collapse as a type of covariate shift: \u201cWe demonstrate two specific forms of covariate shift caused by GANs: 1) Mode collapse, which has been observed in prior work (Goodfellow, 2016; Metz et al., 2016); 2) Boundary distortion, a phenomenon identified in this work and corresponding to a drop in diversity of the periphery of the learned distribution.\u201d\n\nQ3 PACGAN is not mentioned in the white-box methods\nWe agree with your comment that evaluating on white-box type GAN mode-collapse calibrations need to be included. We attach the results of a white-box approach, i.e., importance sampling, in Appendix Figure 7. We will definitely include PACGAN results in the revised version once they become available.\n\nQ5 Why not use Ripley's K?\nThe Ripley's K function compares the expected number of points within a local neighborhood of radius r at any point in the dataset versus the expected density assuming complete spatial randomness (CSR). Our proposed neighboring function N is a surrogate of the K function. There are two reasons why we cannot use the Ripley's K.\nFirstly, there is neither spatial coordinates for each face sample nor a specified spatial region in the embedded face feature space. We can only get a pairwise distance between two face samples. Secondly, there is no complete spatial randomness (CSR) in the embedded face feature space. The standard model for CSR is that events follow a homogeneous Poisson process over the study area, which does not hold in the embedded face feature space.\n\nQ7 How were these face models chosen? \nWe choose the off-shelf face embedding models i.e. SOTA face recognition model. In fact, we could use any feature engineering/dimension reduction approaches such as PCA, sparse reprojection, neural network here. But we choose to use face recognition feature embedding here for three reasons:\na) Those features capture most information (rich semantics, strong transferability) since we can recognize a face identity, gender, race, etc. just based on those features.\nb) Traditional feature engineering/dimension reduction approaches are not as efficient, e.g. PCA can not scale up. \nc) The feature embedding is more general, transferable and is independent of the data and model used in GAN training.\n\nQ6 mode dropping detection\nPlease see Q3 in our last response.\n\nQ4 & Q8 toy figure to demonstrate evaluating procedure\nPlease see Appendix Figure 6 in the revised paper, which could better clarify our evaluating procedure. Yes, the features are normalized.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1000/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1000/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["wuzhenyu_sjtu@tamu.edu", "ye.yuan@tamu.edu", "zhawang@adobe.com", "jianmzha@adobe.com", "atlaswang@tamu.edu", "hljin@adobe.com"], "title": "Is There Mode Collapse? A Case Study on Face Generation and Its Black-box Calibration", "authors": ["Zhenyu Wu", "Ye Yuan", "Zhaowen Wang", "Jianming Zhang", "Zhangyang Wang", "Hailin Jin"], "pdf": "/pdf/45b7ac46e27f3ef1ae8fa3190726e39ef4e2a65c.pdf", "abstract": "Generative adversarial networks (GANs) nowadays are capable of producing im-ages of incredible realism.   One concern raised is whether the state-of-the-artGAN\u2019s learned distribution still suffers from mode collapse. Existing evaluation metrics for image synthesis focus on low-level perceptual quality. Diversity tests of samples from GANs are usually conducted qualitatively on a small scale. In this work, we devise a set of statistical tools, that are broadly applicable to quantitatively measuring the mode collapse of GANs. Strikingly, we consistently observe strong mode collapse on several state-of-the-art GANs using our toolset.  We analyze possible causes, and for the first time present two simple yet effective \u201cblack-box\u201d methods to calibrate the GAN learned distribution, without accessing either model parameters or the original training data.", "keywords": ["Generative Adversarial Networks", "Mode Collapse", "Calibration"], "paperhash": "wu|is_there_mode_collapse_a_case_study_on_face_generation_and_its_blackbox_calibration", "original_pdf": "/attachment/32e7edfaf3159d0c4361563a0795198fac048d94.pdf", "_bibtex": "@misc{\nwu2020is,\ntitle={Is There Mode Collapse? A Case Study on Face Generation and Its Black-box Calibration},\nauthor={Zhenyu Wu and Ye Yuan and Zhaowen Wang and Jianming Zhang and Zhangyang Wang and Hailin Jin},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxUMREYPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryxUMREYPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1000/Authors", "ICLR.cc/2020/Conference/Paper1000/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1000/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1000/Reviewers", "ICLR.cc/2020/Conference/Paper1000/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1000/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1000/Authors|ICLR.cc/2020/Conference/Paper1000/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504162830, "tmdate": 1576860544187, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1000/Authors", "ICLR.cc/2020/Conference/Paper1000/Reviewers", "ICLR.cc/2020/Conference/Paper1000/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1000/-/Official_Comment"}}}, {"id": "B1e7BLKijr", "original": null, "number": 1, "cdate": 1573783099291, "ddate": null, "tcdate": 1573783099291, "tmdate": 1573783099291, "tddate": null, "forum": "ryxUMREYPr", "replyto": "S1xrU4J2FS", "invitation": "ICLR.cc/2020/Conference/Paper1000/-/Official_Comment", "content": {"title": "Response to Reviewer #1", "comment": "Thank you for your careful reading and comments!\n\nQ1: We are evaluating the proposed metrics on more recent GAN-based models you suggested and will update the results once the results become available.\n\nQ2: The main contribution is listed as follows: \n1. A pilot study of mode collapse existence in GAN.\n2. Metric to detect mode collapse in GAN models without any labels (ground truth or pseudo-labels).\n2. Black-box plug-and-play model collapse calibration.\n\nThank you again for your careful reading and kindly identifying the typos in our paper! We will fix these typos and meticulously proofread our article.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1000/Authors"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1000/Authors", "ICLR.cc/2020/Conference"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["wuzhenyu_sjtu@tamu.edu", "ye.yuan@tamu.edu", "zhawang@adobe.com", "jianmzha@adobe.com", "atlaswang@tamu.edu", "hljin@adobe.com"], "title": "Is There Mode Collapse? A Case Study on Face Generation and Its Black-box Calibration", "authors": ["Zhenyu Wu", "Ye Yuan", "Zhaowen Wang", "Jianming Zhang", "Zhangyang Wang", "Hailin Jin"], "pdf": "/pdf/45b7ac46e27f3ef1ae8fa3190726e39ef4e2a65c.pdf", "abstract": "Generative adversarial networks (GANs) nowadays are capable of producing im-ages of incredible realism.   One concern raised is whether the state-of-the-artGAN\u2019s learned distribution still suffers from mode collapse. Existing evaluation metrics for image synthesis focus on low-level perceptual quality. Diversity tests of samples from GANs are usually conducted qualitatively on a small scale. In this work, we devise a set of statistical tools, that are broadly applicable to quantitatively measuring the mode collapse of GANs. Strikingly, we consistently observe strong mode collapse on several state-of-the-art GANs using our toolset.  We analyze possible causes, and for the first time present two simple yet effective \u201cblack-box\u201d methods to calibrate the GAN learned distribution, without accessing either model parameters or the original training data.", "keywords": ["Generative Adversarial Networks", "Mode Collapse", "Calibration"], "paperhash": "wu|is_there_mode_collapse_a_case_study_on_face_generation_and_its_blackbox_calibration", "original_pdf": "/attachment/32e7edfaf3159d0c4361563a0795198fac048d94.pdf", "_bibtex": "@misc{\nwu2020is,\ntitle={Is There Mode Collapse? A Case Study on Face Generation and Its Black-box Calibration},\nauthor={Zhenyu Wu and Ye Yuan and Zhaowen Wang and Jianming Zhang and Zhangyang Wang and Hailin Jin},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxUMREYPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"title": {"required": true, "description": "Brief summary of your comment.", "order": 0, "value-regex": ".{1,500}"}, "comment": {"required": true, "description": "Your comment or reply (max 5000 characters). Add TeX formulas using the following formats: $In-line Formula$ or $$Block Formula$$", "order": 1, "value-regex": "[\\S\\s]{1,5000}"}}, "forum": "ryxUMREYPr", "readers": {"values-dropdown": ["everyone", "ICLR.cc/2020/Conference/Paper1000/Authors", "ICLR.cc/2020/Conference/Paper1000/AnonReviewer.*", "ICLR.cc/2020/Conference/Paper1000/Reviewers/Submitted", "ICLR.cc/2020/Conference/Paper1000/Reviewers", "ICLR.cc/2020/Conference/Paper1000/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "description": "Who your comment will be visible to. If replying to a specific person make sure to add the group they are a member of so that they are able to see your response"}, "writers": {"values-copied": ["ICLR.cc/2020/Conference", "{signatures}"]}, "signatures": {"description": "How your identity will be displayed.", "values-regex": "ICLR.cc/2020/Conference/Paper1000/AnonReviewer[0-9]+|ICLR.cc/2020/Conference/Paper1000/Authors|ICLR.cc/2020/Conference/Paper1000/Area_Chair[0-9]+|ICLR.cc/2020/Conference/Program_Chairs"}}, "readers": ["everyone"], "tcdate": 1569504162830, "tmdate": 1576860544187, "super": "ICLR.cc/2020/Conference/-/Comment", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "invitees": ["ICLR.cc/2020/Conference/Paper1000/Authors", "ICLR.cc/2020/Conference/Paper1000/Reviewers", "ICLR.cc/2020/Conference/Paper1000/Area_Chairs", "ICLR.cc/2020/Conference/Program_Chairs"], "id": "ICLR.cc/2020/Conference/Paper1000/-/Official_Comment"}}}, {"id": "S1xrU4J2FS", "original": null, "number": 1, "cdate": 1571710029245, "ddate": null, "tcdate": 1571710029245, "tmdate": 1573022612282, "tddate": null, "forum": "ryxUMREYPr", "replyto": "ryxUMREYPr", "invitation": "ICLR.cc/2020/Conference/Paper1000/-/Official_Review", "content": {"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #1", "review": "This paper presents a set of statistical tools, that are applicable to quantitatively measuring the mode collapse of GANs. The authors consistently observe strong mode collapse on several state-of-the-art GANs using the proposed toolset. The authors analyze possible causes, and for the first time present two simple yet effective \u201cblack-box\u201d methods to calibrate the GAN learned distribution, without accessing either model parameters or the original training data.\n\nThe writing and presentation are good.\n\nMy concerns regarding this paper are as below.\n1) I wonder if the proposed method work for most GAN models, more experiments evaluated on more recent GAN-based  models should be added to verify the superiority claimed in this paper, e.g., TP-GAN [Huang et al., ICCV 2017], PIM [Zhao et al., CVPR 2018], DR-GAN [Tran et al., CVPR 2017], DA-GAN [Zhao et al., NIPS 2017], MH-Parser [Li et al., 2017], 3D-PIM [Zhao et al., IJCAI 2018], SimGAN [Shrivastava et al., CVPR 2016], AIM [Zhao et al., AAAI 2019].\n2) The main contributions of this paper are not quite clear to me.\n3) Typos need to be corrected in next version, e.g., all equations should have punctuation mark at the end, all e.g., i.e., et al., etc. should be italic, format of references should be consistent.\n\nBased on my comments above, I decide to give the rate of WA for this paper.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."}, "signatures": ["ICLR.cc/2020/Conference/Paper1000/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1000/AnonReviewer1"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["wuzhenyu_sjtu@tamu.edu", "ye.yuan@tamu.edu", "zhawang@adobe.com", "jianmzha@adobe.com", "atlaswang@tamu.edu", "hljin@adobe.com"], "title": "Is There Mode Collapse? A Case Study on Face Generation and Its Black-box Calibration", "authors": ["Zhenyu Wu", "Ye Yuan", "Zhaowen Wang", "Jianming Zhang", "Zhangyang Wang", "Hailin Jin"], "pdf": "/pdf/45b7ac46e27f3ef1ae8fa3190726e39ef4e2a65c.pdf", "abstract": "Generative adversarial networks (GANs) nowadays are capable of producing im-ages of incredible realism.   One concern raised is whether the state-of-the-artGAN\u2019s learned distribution still suffers from mode collapse. Existing evaluation metrics for image synthesis focus on low-level perceptual quality. Diversity tests of samples from GANs are usually conducted qualitatively on a small scale. In this work, we devise a set of statistical tools, that are broadly applicable to quantitatively measuring the mode collapse of GANs. Strikingly, we consistently observe strong mode collapse on several state-of-the-art GANs using our toolset.  We analyze possible causes, and for the first time present two simple yet effective \u201cblack-box\u201d methods to calibrate the GAN learned distribution, without accessing either model parameters or the original training data.", "keywords": ["Generative Adversarial Networks", "Mode Collapse", "Calibration"], "paperhash": "wu|is_there_mode_collapse_a_case_study_on_face_generation_and_its_blackbox_calibration", "original_pdf": "/attachment/32e7edfaf3159d0c4361563a0795198fac048d94.pdf", "_bibtex": "@misc{\nwu2020is,\ntitle={Is There Mode Collapse? A Case Study on Face Generation and Its Black-box Calibration},\nauthor={Zhenyu Wu and Ye Yuan and Zhaowen Wang and Jianming Zhang and Zhangyang Wang and Hailin Jin},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxUMREYPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryxUMREYPr", "replyto": "ryxUMREYPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1000/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1000/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575667298399, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1000/Reviewers"], "noninvitees": [], "tcdate": 1570237743851, "tmdate": 1575667298412, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1000/-/Official_Review"}}}, {"id": "HJlStebC5r", "original": null, "number": 3, "cdate": 1572896892910, "ddate": null, "tcdate": 1572896892910, "tmdate": 1572972525121, "tddate": null, "forum": "ryxUMREYPr", "replyto": "ryxUMREYPr", "invitation": "ICLR.cc/2020/Conference/Paper1000/-/Official_Review", "content": {"rating": "1: Reject", "experience_assessment": "I have read many papers in this area.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory.", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "title": "Official Blind Review #3", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "review": "This work addresses the important problem of generation bias and a lack of diversity in generative models, which is often called model collapse. It proposed a new metric to measure the diversity of the generative model's \"worst\" outputs based on the sample clustering patterns. Furthermore, it proposed two blackbox approaches to increasing the model diversity through resampling the latent z. Unlike most existing works that address the model collapse problem, a blackbox approach does not make assumptions about having access to model weights or the artifacts produced during model training, making it more widely applicable than the white-box approaches.  \nIn terms of experiment setup, the authors chooses face generation as the area to investigate and measures the diversity by detecting the generated face identity. With the proposed methods, the authors showed that most STOA methods have a wide gap between the top p faces of the most popular face identities and randomly sampled faces. It further showed that the proposed blackbox approaches increases the proposed diversity metric without sacrificing image quality.\n\nThe proposed diversity measuring metric is lacking both in terms of experimental proofs and intuitive motivations. While the black-box calibration of a GAN model may be attractive under specific settings, the authors did not consider the restrictions under those situations and their design may be hard to implement as a result. For those reasons, I propose to REJECT this paper.\n\nMissing key experiments that will provide more motivation that 1. the new metric reflects human perception of diversity 2. the new metric works better than existing ones:\n1. Please provide experiments and/or citation for using the face identity as a proxy for face image diversity. this is important since all your experiments rely on that assumption.\n2. Were there experiments that applies your metric to the training datasets like CelebA and FFHQ? In theory your metric should show no gap between N_R_obs and N_R_ref measured on the training dataset since that's the sampled ground truth.\n\nMissing assumptions about blackbox calibration approaches:\n1. If we do not have access to the model parameter, the training data, or the artifacts during training like the discriminator, what are some of the real world situations that fit this description? In those cases, is it too much to assume that we can control the random seed input to G? \n2. Is it reasonable to assume some constraints on how much data we can get from the blackbox generator? A website that just exposes the image generation API may not allow you to ping their service 100k times to improve the generation diversity. If you are allowed to do that, it may be reasonable to assume that you can contact the API provider to get access to the rest of the model.\n\nMinor improvements that did not have a huge impact on the score\n1. I found the argument about FID in section 2.1 unconvincing. Are there proofs or citations for the claim that real images don't follow multivariate gaussian distribution after applying FID? Copying is indeed an issue that FID cannot detect, but it may be tangential to model collapse for real world concerns like privacy. \n2. The statement \"IS, FID and MODE score takes both visual fidelity and diversity into account.\" under \"Evaluation of Mode Collapse\" is contradictory to the description in sec 2.1 that IS in fact does not measure diversity. \n3. You may want to consider stating the work as \"a pilot study\" (sec 6.) earlier in the abstract or in the introduction, so that the reader knows what to expect.\n"}, "signatures": ["ICLR.cc/2020/Conference/Paper1000/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2020/Conference/Paper1000/AnonReviewer3"], "details": {"replyCount": 0, "writable": false, "overwriting": [], "revisions": false, "forumContent": {"authorids": ["wuzhenyu_sjtu@tamu.edu", "ye.yuan@tamu.edu", "zhawang@adobe.com", "jianmzha@adobe.com", "atlaswang@tamu.edu", "hljin@adobe.com"], "title": "Is There Mode Collapse? A Case Study on Face Generation and Its Black-box Calibration", "authors": ["Zhenyu Wu", "Ye Yuan", "Zhaowen Wang", "Jianming Zhang", "Zhangyang Wang", "Hailin Jin"], "pdf": "/pdf/45b7ac46e27f3ef1ae8fa3190726e39ef4e2a65c.pdf", "abstract": "Generative adversarial networks (GANs) nowadays are capable of producing im-ages of incredible realism.   One concern raised is whether the state-of-the-artGAN\u2019s learned distribution still suffers from mode collapse. Existing evaluation metrics for image synthesis focus on low-level perceptual quality. Diversity tests of samples from GANs are usually conducted qualitatively on a small scale. In this work, we devise a set of statistical tools, that are broadly applicable to quantitatively measuring the mode collapse of GANs. Strikingly, we consistently observe strong mode collapse on several state-of-the-art GANs using our toolset.  We analyze possible causes, and for the first time present two simple yet effective \u201cblack-box\u201d methods to calibrate the GAN learned distribution, without accessing either model parameters or the original training data.", "keywords": ["Generative Adversarial Networks", "Mode Collapse", "Calibration"], "paperhash": "wu|is_there_mode_collapse_a_case_study_on_face_generation_and_its_blackbox_calibration", "original_pdf": "/attachment/32e7edfaf3159d0c4361563a0795198fac048d94.pdf", "_bibtex": "@misc{\nwu2020is,\ntitle={Is There Mode Collapse? A Case Study on Face Generation and Its Black-box Calibration},\nauthor={Zhenyu Wu and Ye Yuan and Zhaowen Wang and Jianming Zhang and Zhangyang Wang and Hailin Jin},\nyear={2020},\nurl={https://openreview.net/forum?id=ryxUMREYPr}\n}"}, "tags": [], "invitation": {"reply": {"content": {"experience_assessment": {"required": true, "order": 4, "description": "Please make a selection that represents your experience correctly", "value-radio": ["I have published in this field for several years.", "I have published one or two papers in this area.", "I have read many papers in this area.", "I do not know much about this area."]}, "rating": {"value-dropdown": ["1: Reject", "3: Weak Reject", "6: Weak Accept", "8: Accept"], "order": 3, "required": true}, "review_assessment:_checking_correctness_of_experiments": {"required": true, "order": 7, "description": "If no experiments, please select N/A", "value-radio": ["I carefully checked the experiments.", "I assessed the sensibility of the experiments.", "I did not assess the experiments.", "N/A"]}, "review_assessment:_thoroughness_in_paper_reading": {"required": true, "order": 5, "description": "If this is not applicable, please select N/A", "value-radio": ["I read the paper thoroughly.", "I read the paper at least twice and used my best judgement in assessing the paper.", "I made a quick assessment of this paper.", "N/A"]}, "title": {"value-regex": "Official Blind Review #[0-9]+", "order": 1, "required": true, "description": "Please replace NUM with your AnonReviewer number (it is the number following \"AnonReviewer\" in your signatures below)", "default": "Official Blind Review #NUM"}, "review": {"value-regex": "[\\S\\s]{500,200000}", "order": 2, "description": "Provide your complete review here (500 - 200000 characters). For guidance in writing a good review, see this brief reviewer guide (https://iclr.cc/Conferences/2020/ReviewerGuide) with three key bullet points.", "required": true}, "review_assessment:_checking_correctness_of_derivations_and_theory": {"required": true, "order": 6, "description": "If no derivations or theory, please select N/A", "value-radio": ["I carefully checked the derivations and theory.", "I assessed the sensibility of the derivations and theory.", "I did not assess the derivations or theory.", "N/A"]}}, "forum": "ryxUMREYPr", "replyto": "ryxUMREYPr", "readers": {"values": ["everyone"], "description": "Select all user groups that should be able to read this comment."}, "nonreaders": {"values": []}, "writers": {"values-regex": "ICLR.cc/2020/Conference/Paper1000/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}, "signatures": {"values-regex": "ICLR.cc/2020/Conference/Paper1000/AnonReviewer[0-9]+", "description": "How your identity will be displayed."}}, "expdate": 1575667298399, "duedate": 1572706740000, "multiReply": false, "readers": ["everyone"], "nonreaders": [], "invitees": ["ICLR.cc/2020/Conference/Paper1000/Reviewers"], "noninvitees": [], "tcdate": 1570237743851, "tmdate": 1575667298412, "super": "ICLR.cc/2020/Conference/-/Official_Review", "signatures": ["ICLR.cc/2020/Conference"], "writers": ["ICLR.cc/2020/Conference"], "id": "ICLR.cc/2020/Conference/Paper1000/-/Official_Review"}}}], "count": 9}