{"paper": {"title": "Group Sparse CNNs for Question Sentence Classification with Answer Sets", "authors": ["Mingbo Ma", "Liang Huang", "Bing Xiang", "Bowen Zhou"], "authorids": ["mam@oregonstate.edu", "liang.huang@oregonstate.edu", "bingxia@us.ibm.com", "zhou@us.ibm.com"], "summary": "", "abstract": "Classifying question sentences into their corresponding categories is an important task with wide applications, for example in many websites' FAQ sections. \nHowever, traditional question classification techniques do not fully utilize the well-prepared answer data which has great potential for improving question sentence representations which could lead to better classification performance. In order to encode answer information into question representation, we first introduce novel group sparse autoencoders which could utilize the group information in the answer set to refine question representation. We then propose a new group sparse convolutional neural network which could naturally learn the question representation with respect to their corresponding answers by implanting the group sparse autoencoders into the traditional convolutional neural network. The proposed model show significant improvements over strong baselines on four datasets.  ", "keywords": []}, "meta": {"decision": "Reject", "comment": "This paper proposes to use a group sparsity penalty to train an autoencoder on question answering. The idea to leverage hierarchies of categories in labels is an appealing one. However the paper has problems:\n - it is not clear. In particular, some of the equations do not make sense. This has been pointed by reviewers and not corrected.\n - the choice of the particular group sparsity penalty is not well justified or empirically validated with ablation experiments: experiments lack key comparisons and simply compare to unrelated baselines.\n In its current form, the paper cannot be recommended for acceptance."}, "review": {"ryYV-hp7l": {"type": "rebuttal", "replyto": "H1AOBRgQg", "comment": "Dear Reviewer #3:\n\nThanks for your comments. \n\nWe agree with your comments on ablation studies. We will include the comparison experiments between group sparse-based method and standard sparse-based method in the future revision.\n\nAbout the second comments, we only want to argue that SGA can not be trained jointly with CNN together. For SGL, we need to get the sentence representation before we apply the sparse coding model. Then the CNN (for sentence representation) and sparse coding model (for dictionary learning) are trained separately. The motivation of our proposed GSCNN is to combine these two models into one framework.", "title": "Re:Why not compare against a standard sparse auto-encoder?"}, "H1AOBRgQg": {"type": "review", "replyto": "BJFG8Yqxl", "review": "It seems to me that there is a lack of ablation studies to show the group sparse auto-encoder works better than standard sparse auto-encoder. In terms of comparison, you can simply place a standard sparse auto-encoder layer on top of the CNNs following your configuration in Sec. 4. \n\nTable 3 does not explain too much yet. At least a KNN+SGA and SVM+SGA can be applied. Also the author's claim on SGL cannot be applied on CNNs should be justified. To me energy based learning allows stacking a sparse coding network on top. Or we can substitute the l2 weight decay with ell_1,2 or ell_2,1 norm in order to induce group sparsity. This paper proposed the group sparse auto-encoder for feature extraction. The author then stack the group sparse auto-encoders on top of CNNs to extract better question sentence representation for QA tasks. \n\nPros: \n- group-sparse auto-encoder seems new to me.\n- extensive experiments on QA tasks. \n\nCons:\n- The idea is somewhat incremental.\n- Writing need to be improved. \n- Lack of ablation studies to show the effectiveness of the proposed approach. \n\nMoreover, I am not convinced by the author's answer regarding the baseline. A separate training stages of CNN+SGL for comparison is fine. The purpose is to validate and analyze why the proposed SGA is preferred rather than group lasso, e.g. joint training could improve, or the proposed group-sparse regularization outperforms l_21 norm, etc. However, we can't see it from the current experiments. ", "title": "Why not compare against a standard sparse auto-encoder?", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "ByGhiIVVl": {"type": "review", "replyto": "BJFG8Yqxl", "review": "It seems to me that there is a lack of ablation studies to show the group sparse auto-encoder works better than standard sparse auto-encoder. In terms of comparison, you can simply place a standard sparse auto-encoder layer on top of the CNNs following your configuration in Sec. 4. \n\nTable 3 does not explain too much yet. At least a KNN+SGA and SVM+SGA can be applied. Also the author's claim on SGL cannot be applied on CNNs should be justified. To me energy based learning allows stacking a sparse coding network on top. Or we can substitute the l2 weight decay with ell_1,2 or ell_2,1 norm in order to induce group sparsity. This paper proposed the group sparse auto-encoder for feature extraction. The author then stack the group sparse auto-encoders on top of CNNs to extract better question sentence representation for QA tasks. \n\nPros: \n- group-sparse auto-encoder seems new to me.\n- extensive experiments on QA tasks. \n\nCons:\n- The idea is somewhat incremental.\n- Writing need to be improved. \n- Lack of ablation studies to show the effectiveness of the proposed approach. \n\nMoreover, I am not convinced by the author's answer regarding the baseline. A separate training stages of CNN+SGL for comparison is fine. The purpose is to validate and analyze why the proposed SGA is preferred rather than group lasso, e.g. joint training could improve, or the proposed group-sparse regularization outperforms l_21 norm, etc. However, we can't see it from the current experiments. ", "title": "Why not compare against a standard sparse auto-encoder?", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}}