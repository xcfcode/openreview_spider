{"paper": {"title": "Dynamically Unfolding Recurrent Restorer: A Moving Endpoint Control Method for Image Restoration", "authors": ["Xiaoshuai Zhang", "Yiping Lu", "Jiaying Liu", "Bin Dong"], "authorids": ["jet@pku.edu.cn", "luyiping9712@pku.edu.cn", "liujiaying@pku.edu.cn", "dongbin@math.pku.edu.cn"], "summary": "We propose a novel method to handle image degradations of different levels by learning a diffusion terminal time. Our model can generalize to unseen degradation level and different noise statistic.", "abstract": "In this paper, we propose a new control framework called the moving endpoint control to restore images corrupted by different degradation levels in one model. The proposed control problem contains a restoration dynamics which is modeled by an RNN. The moving endpoint, which is essentially the terminal time of the associated dynamics, is determined by a policy network. We call the proposed model the dynamically unfolding recurrent restorer (DURR). Numerical experiments show that DURR is able to achieve state-of-the-art performances on blind image denoising and JPEG image deblocking. Furthermore, DURR can well generalize to images with higher degradation levels that are not included in the training stage.", "keywords": ["image restoration", "differential equation"]}, "meta": {"decision": "Accept (Poster)", "comment": "1. Describe the strengths of the paper.  As pointed out by the reviewers and based on your expert opinion.\n \n- The approach is novel\n- The experimental results are convincing.\n\n2. Describe the weaknesses of the paper. As pointed out by the reviewers and based on your expert opinion. Be sure to indicate which weaknesses are seen as salient for the decision (i.e., potential critical flaws), as opposed to weaknesses that the authors can likely fix in a revision.\n\n- The authors didn't show results with non-Gaussian noise\n- Some details that could help the understanding of the method are missing. \n\n3. Discuss any major points of contention. As raised by the authors or reviewers in the discussion, and how these might have influenced the decision. If the authors provide a rebuttal to a potential reviewer concern, it\u2019s a good idea to acknowledge this and note whether it influenced the final decision or not. This makes sure that author responses are addressed adequately.\n\nNo major points of contention.\n \n4. If consensus was reached, say so. Otherwise, explain what the source of reviewer disagreement was and why the decision on the paper aligns with one set of reviewers or another.\n\nThe reviewers reached a consensus that the paper should be accepted.\n"}, "review": {"BJl2pJ8_JV": {"type": "rebuttal", "replyto": "SJfZKiC5FX", "comment": "We have done our experiments on color image gaussian denoising, the quantitative results are reported as follows:\n\n\\sigma      25       35       45       55        65*      75*\nCBM3D     30.71  28.89  27.83  26.97  26.29   25.74\nCDnCNN   31.22  29.57  28.40  27.46  26.40  24.47\nCDURR      31.25  29.63  28.48  27.57  26.83  26.15\n\n(* The noise level is not presented during training for CDnCNN and DURR)\n\nAll the settings are the same as the grayscale experiments, except that the models (CDnCNN and CDURR) are trained on color images. One can see that the CDURR achieves best performance among all, as expected. Qualitative results also show our superior performance compared to other models, on color images and more noise types. These results as well as more details will be included when we have the chance to update the manuscript. Thanks!", "title": "Update of Results on Color Image Gaussian Denoising"}, "rkx9kJPPyE": {"type": "rebuttal", "replyto": "HJe2IOSPkE", "comment": "In our experiments, the term R is in fact set to 0. Therefore, the choice of lambda doesn't matter and thus we set it to 1 for simplicity. Our rebuttal may be misleading and we appoloize for the misunderstanding. We will correct this in our revision. The reason of introducing the general form as (3) is to relate it to the standard formulation in control theory as an illustration. \n\nAlso, we have already reported part of our performance on Set12 in the previous rebuttals. We will include complete results on the dataset in our next revision.", "title": "Re"}, "H1xU19HrR7": {"type": "rebuttal", "replyto": "HJgtlrWj3m", "comment": "We would like to thank Reviewer 2 for their review and helpful suggestions. Our responses inline:\n\n> Since the Deep Q-learning is used to train the policy unit, I suspect the training time could be quite long. How does the reward curve look like while training? How stable is the training? Showing such details should make the paper stronger.\n\n- The training process is stable and takes only ~ 4 hours on a single Titan Xp GPU for the DQN policy (our main exp). We also tested policy gradient based policies, and the training process is not as stable and needs 2x time to reach similar restoration performances. These details will be included in our next revision, if space permits. However, the details of the employed policy unit are not our main focus (as you can also use handcrafted policies/statistics-based policies as mentioned in Section 2.2). Also, The reward curves look normal and uninformative, as in any other RL tasks.\n\n> It will be interesting to see more details on the model. For example, what is the mean/std for the number of folds that model applies for BSD68? What is the distribution (histogram?) of the folds for BSD68? Currently, the paper just simply shows the results and seems to hide many details. \n\n- This makes a very good point, we've already included part of these details (in Fig. 13). In addition, the variances of the number of unfoldings are quite low for seen noise levels, but larger for those not included in the training process. We\u2019ll improve the figures while introducing new figures to illustrate the behavior of the DURR in our next revision.\n\n> What was the choice for \\lambda in Eq. (3),(4)? How do you choose it?\n\n- In our experiements, we simply set \\lambda to 0. The regularization term may have potential benefit to the problem and need further studies, though. \n\n> How does the result look like on other benchmark datasets other than BSD68? It seems like the specific number of looks for each noise level is important for training. Do the choices of (25,4), (35,6), (45,9), (55,12) generalize well to other datasets as well?\n\n- Yes, these choices generalize to other datasets. We've tested our performance of the LIVE1 and Set12, and witnessed a similar gain compared to other methods (our own implementation). We only include results on the BSD68 dataset as it is a common practice for denoising papers. Our preliminary results on Set12:\n\n\\sigma=25\nBM3D   WNNM   DnCNN-B   DURR (ours)\n29.97     30.26      30.36           30.41\n\n\n- The choices are only based on empirical results. Using a different training unfolding assignments does not significantly affect the performances though (e.g. using (25,3), (35,5), (45,8), (55,11)).", "title": "Response To Reviewer#2"}, "HJlCZ9SBCm": {"type": "rebuttal", "replyto": "rygjryLgn7", "comment": "We would like to thank Reviewer 3 for their review and helpful suggestions. Our responses inline:\n\n> It would be nice to present results on color images, and on datasets that contains natural noises.  \n\n- Of course, we will add results on color images and natural noise datasets in our next revision if time permits. As this requires modifications to the network arch and re-training.\n\n> Lowering the learning rate on plateaus during training is done by hand or is there an automatic criterion to define the plateaus?\n\n- This is done automatically by the pytorch learning rate scheduler (ReduceLROnPlateau), with default arguments.\n\n> p7 Table 1: the perf of DnCNN-B is 29.16 and not 29.15 for sigma 25, right?\n\n- Sorry for the mistake, the perf of DnCNN was from a pytorch re-implementation (code at https://github.com/SaoYan/DnCNN-PyTorch), which gave the result of 29.15. We are referring to the original paper now.\n\nThank you for your careful reading. We will fix the typos and minor issues in our next revision.\n\n", "title": "Response To Review#3"}, "HkxJZkLBRX": {"type": "rebuttal", "replyto": "SyeNxz5NaX", "comment": "We would like to thank Reviewer 4 for their review and helpful suggestions. Our responses inline:\n\n> The author seems to make strong assumptions on the nature of the noise and made no attempt to understand the nature of the learning beyond a limited set of qualitative example and PSNR. \n\n- Using gaussian distribution to simulate the noise statistics is a common setting in the image processing papers, due to the central limit theorem. However, we've shown our results for the case of natural image denoising, demonstrating our efficacy for more complicated noise modelings. Anyway, we will include more results on other noise types (e.g. poisson noise) in our next revision.\n\n> Even if the experimental protocol has been taken from prior work, it would have been appreciated to make it explicit in the paper, especially as ICLR is not a conference of image processing. Indeed, It would have made the paper more self-sufficient. \n> Second 2 describing the method is particularly hard to understand and would require more details. \n\n- Sorry for the writing issues. We will refine and include more details for these parts.\n\n> In the experimental section, the authors claim that \"These results indicate that the restoration unit has the potential to generalize on unseen degradation levels when trained with good policies\". It would have been important to mention that such generalization capability seems to occur for the given noise type used in the experiments. I didn't see any explicit attempt to variate the shape of the noise to evaluate the generalization capability of the model.\n\n- First, by saying \"generalize on unseen degradation levels\", we mean the generalization power on different degradation levels (e.g. different \\sigma for the gaussian noise) but not different noise statistics. Our extensive experiments have shown this kind of generalization for both tasks (gaussian denoise and JPEG deblocking).\n\n- Second, although we does not take the noise statistics into consideration initially when mentioning \"generalize\", the results on real image denoising clearly indicates our generalization power for unseen noise types: our model trained on gaussian noise also apply to real image noise (Fig. 7, and Section 4.4). And we will add more results on different noise types to further prove our generalization power, as is mentioned above.\n\nWe'd also like to defend that our main contribution is introducing the concept of optimal terminal time in the traditional nonlinear diffusion methods into the context of deep learning. Also, we've done analysis on using different restoration units (Appendix 4.1.2). Even using the plain fully convolutional neural network (ARCNN), the quantitive results are not decreasing. This phenomenon indicates that it is the designed dynamically unfolding strategy that brings the performance gain, using whatever kind of network as the restoration unit is not very important.\n", "title": "Response to Reviewer 4"}, "BylKLKBS0m": {"type": "rebuttal", "replyto": "HJgmIonkp7", "comment": "Thank you for your kind response. As demonstrated in Section 3.2.2, our generalization power can be witnessed for the task of JPEG deblocking as well. We will add results on other tasks (e.g. de-rain, and deblur), if time permits. ", "title": "Response To Anonymous Reader"}, "SyeNxz5NaX": {"type": "review", "replyto": "SJfZKiC5FX", "review": "The paper proposes a restoration method based on deep reinforcement learning. It is the idea of trainable unfolding that motivates the use of Reinforcement learning, the restoration unit is a SoA U-Net. \n\nRemarks\n\n* The author seems to make strong assumptions on the nature of the noise and made no attempt to understand the nature of the learning beyond a limited set of qualitative example and PSNR. \n\n* Even if the experimental protocol has been taken from prior work, it would have been appreciated to make it explicit in the paper, especially as ICLR is not a conference of image processing. Indeed, It would have made the paper more self-sufficient. \n\n* Second 2 describing the method is particularly hard to understand and would require more details. \n\n* In the experimental section, the authors claim that \"These results indicate that the restoration unit has the potential to generalize on unseen degradation levels when trained with good policies\". It would have been important to mention that such generalization capability seems to occur for the given noise type used in the experiments. I didn't see any explicit attempt to variate the shape of the noise to evaluate the generalization capability of the model.\n\nIn conclusion, the paper proposes an interesting method of image denoising through state of the art deep learning model and reinforcement learning algorithm. The main difference with the SoA on the domain is the use of a diffusion dynamics. IMHO, the paper would need more analysis and details on the mentioned section.\n", "title": "An improvement to the SoA of the domain, more explanations and analysis welcomed", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "HJgtlrWj3m": {"type": "review", "replyto": "SJfZKiC5FX", "review": "Summary:\n\nThe authors proposes a new image restoration method that becomes particularly useful for blind restoration setting, e.g., the unknown noise variance setting for denoising. They utilized the moving endpoint control methodology, which essentially is applying reinforcement learning to the image restoration, and devised a method that adaptively decides the unfolding steps for given noisy image. The experimental results show encouraging results. \n\nPros:\nIn the experimental result, the proposed DURR outperforms DnCNN-B, a current state-of-the-art. Particularly, while DnCNN-B suffers for the noise level that it was not trained for, DURR can still denoise much better. (Table 2) A similar result is obtained for the JPEG deblocking problem as well. \n\nCons:\n- Since the Deep Q-learning is used to train the policy unit, I suspect the training time could be quite long. How does the reward curve look like while training? How stable is the training? Showing such details should make the paper stronger. \n- It will be interesting to see more details on the model. For example, what is the mean/std for the number of folds that model applies for BSD68? What is the distribution (histogram?) of the folds for BSD68? Currently, the paper just simply shows the results and seems to hide many details. \n- What was the choice for \\lambda in Eq. (3),(4)? How do you choose it?\n- How does the result look like on other benchmark datasets other than BSD68? It seems like the specific number of looks for each noise level is important for training. Do the choices of (25,4),(35,6),(45,9),(55,12) generalize well to other datasets as well?\n\nOverall, I think the paper should add more details mentioned above to make the paper stronger. ", "title": "A useful method for blind image restoration problems", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "rygjryLgn7": {"type": "review", "replyto": "SJfZKiC5FX", "review": "Summary\n\nThis paper decomposes the image restoration task in two part: the restoration part handled by a restoration RNN, and the number of steps to apply the RNN is determined using a policy unit. \nState of the art results are achieved on blind grey level Gaussian noise denoising on the BSD68 dataset.\n\nThe approach is novel to my knowledge, the paper is well written, the results are good and well illustrated.\n\nQuestions:\n-It would be nice to present results on color images, and on datasets that contains natural noises.  \n-Lowering the learning rate on plateaus during training is done by hand or is there an automatic criterion to define the plateaus?\n\nMinor:\npage 1: extra \")\" after ref to Bredies et al 2010\ncould cite Chen, Zu, Koltun ICCV17 in deep models for restoration\nSeveral \"L\" have been replaced by \"_' e.g. under review at IC_R, R_-based, etc in the whole paper\np.4: rain-> train\ngreatly influence -> greatly influences\np5: typo performace\nmake a uniform bib: whole first name or abbr. , no URL, etc.\np6: the weight -> the set of weights \nadd the specification that the noise is Gaussian\nthe sentence \"the training set and testing set of ...\" is used twice, remove one.\np7 Table 1: the perf of DnCNN-B is 29.16 and not 29.15 for sigma 25, right?", "title": "Simple and effective restoration approach ", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}}