{"paper": {"title": "Deep Graph Infomax", "authors": ["Petar Veli\u010dkovi\u0107", "William Fedus", "William L. Hamilton", "Pietro Li\u00f2", "Yoshua Bengio", "R Devon Hjelm"], "authorids": ["petar.velickovic@cst.cam.ac.uk", "liam.fedus@gmail.com", "wleif@stanford.edu", "pietro.lio@cst.cam.ac.uk", "yoshua.umontreal@gmail.com", "devon.hjelm@microsoft.com"], "summary": "A new method for unsupervised representation learning on graphs, relying on maximizing mutual information between local and global representations in a graph. State-of-the-art results, competitive with supervised learning.", "abstract": "We present Deep Graph Infomax (DGI), a general approach for learning node representations within graph-structured data in an unsupervised manner. DGI relies on maximizing mutual information between patch representations and corresponding high-level summaries of graphs---both derived using established graph convolutional network architectures. The learnt patch representations summarize subgraphs centered around nodes of interest, and can thus be reused for downstream node-wise learning tasks. In contrast to most prior approaches to unsupervised learning with GCNs, DGI does not rely on random walk objectives, and is readily applicable to both transductive and inductive learning setups. We demonstrate competitive performance on a variety of node classification benchmarks, which at times even exceeds the performance of supervised learning.", "keywords": ["Unsupervised Learning", "Graph Neural Networks", "Graph Convolutions", "Mutual Information", "Infomax", "Deep Learning"]}, "meta": {"decision": "Accept (Poster)", "comment": "Because of strong support from two of the reviewers I am recommending accepting this paper. However, I believe reviewer 1's concerns should be taken seriously. Although I disagree with the reviewer that a general \"framework\" method is a bad thing, I agree with them that additional experiments would be valuable."}, "review": {"HkgPLafJkE": {"type": "rebuttal", "replyto": "B1giOunS0Q", "comment": "Thank you for following the discussion, and giving us further comments. To address them:\n\nFor the optimal discriminator, the GAN and JSD objectives are directly proportional to each other, so in this limit the two discriminators actually optimize the exact same thing (this was pointed out in original GAN paper by Goodfellow et al.). However, the proportionality actually extends to the non-optimal discriminator: plugging in the activation function and convex conjugate into equation (7) in the f-GAN paper for JSD and GAN, makes these two versions of the Fenchel dual proportional as well. We have updated the paper to clarify this.\n\nWhile we do not perform a more exhaustive study of architectures, and our modifications are fairly small compared to common architectures used in other works, we can offer some further insights here based on our experiences. \n\nOverall, we found that using the \u201cwide\u201d architectures with a standard supervised loss quickly and drastically overfits, whereas increasing the depth for a DGI encoder had a less-pronounced effect. For the transductive datasets especially, increased depth could induce a 2-3% drop in accuracy, and the reason for this is likely because deeper GCNs have larger \u201creceptive fields\u201d. This is analogous to the number of random walk steps in other unsupervised approaches, which tend to not benefit from more than two steps. While we cannot say that these trends will hold in general, we now offer some concrete suggestions in the paper: i.e., that with the DGI loss function we often found benefits from employing wider, rather than deeper models.", "title": "Response to Comments"}, "rJe0kif1yN": {"type": "rebuttal", "replyto": "SklVLSaOCX", "comment": "Thank you for following the discussion and for your further thoughts.\n\nAs the square function is convex, Jensen's inequality will only give us a lower bound (of 1/2|X|) rather than an upper one. However, we can upper bound the sum of squares of probabilities to 1 without using Jensen's inequality (it's maximised for the one-hot distribution, as for all s_k, p(s_k)^2 <= p(s_k)). Therefore, we can establish that our bound on the error rate lies in the range 1/2|X| <= Err* <= 1/2. Intuitively, in the case of a one-hot distribution, only one summary is ever possible, and therefore anything that belongs to the product of marginals also belongs to the joint---making the classifier's choices a random guess.\n\nWe have checked again, and can confirm that our procedure gives us an upper bound on the error rate. As the error rate is proportional to the sum of eq (2) (the product of marginals over pairs X and R(X)), and the conditional is bounded from above by one, the sum of the marginal squared is an upper bound (including the conditional in the sum will only decrease the value of the sum).\n\nLastly, it is unclear what is meant by a \u201csufficient statistic\u201d in this case: could you provide a concrete example? Given the assumption of the problem (X being i.i.d. and a deterministic encoder), the max-info encoder must be invertible. A simple counter example (two i.i.d. samples mapping to the same feature vector) is trivially suboptimal.\n\nWe have made modifications to the paper in the Conclusions section (as proposed) and added remarks about the bounds on Err*.\n\nThank you once again for your comments!", "title": "Response to Comments"}, "HJeiYITZ07": {"type": "rebuttal", "replyto": "BkeOgwpm37", "comment": "Thank you for the very careful review and kind words about our contributions.\n\nRegarding your comment about our information-theoretic contributions, please see our global comment on mutual information and the JSD. We reorganised Sections 3.2 / 3.3 to include more concrete theoretical motivation from mutual information maximisation, and separate this from the specifics that are important for implementation.\n\nYou make an exceptionally good point regarding our method\u2019s reliance on random walks - thanks! It is, in fact, our main claim that combining random-walk *objectives* with GCN-like encoders is potentially unsuitable (given that the GCN already encodes the \u201crandom-walk\u201d information within its structural inductive biases). We have appropriately modified our abstract to reflect this intention.\n\nTo answer your remaining questions:\n\n- The minibatch of 256 nodes for Reddit is randomly selected, and therefore the cost function does not rely on random-walk similarities in this case.\n\n- Regarding the averaging readout: this is a great point, and we expect that the performance on larger graphs will decrease somewhat, especially when using averaging as a readout function, since it is known that the quality of graph-level embeddings degrades as the number of nodes increases when using simple averaging. That said, we expect this problem could be alleviated by applying more sophisticated set2vec and/or pooling approaches for the readout function, and we mention this point in the revised paper---immediately after the averaging is introduced in Section 4.2. Moreover, in this particular case, the smaller performance improvement on the Reddit data is also simply due to the fact that most GCN approaches are already in the 90+% F1 range, and therefore there is limited room for improvement.\n\n- The \u201cDeepWalk+features\u201d baseline directly concatenates the two kinds of features, as was done in all prior work utilising this baseline (e.g. Hamilton et al., NIPS 2017).\n\n- We note that we specifically designed the model with node classification tasks in mind. However, in principle, the generated embeddings could be used for link prediction, as with node2vec embeddings, etc. That said, we expect that strong performance on link prediction could require minor modifications (e.g., tweaking the negative sampling function) and we plan to investigate this in future work.\n\n- Regarding your concern about high variance of the gradient, we haven\u2019t found any issues regarding learning stability---as long as an appropriate choice of learning rate is made.\n\nWe thank you once again for your review, which has definitely helped make our paper\u2019s contributions stronger!\n", "title": "Reply to AnonReviewer2"}, "rkxb4LT-C7": {"type": "rebuttal", "replyto": "B1lVxghvnm", "comment": "Firstly, thanks so much for your thorough review!\n\nTowards your comment about Section 3.2 and Equation 1, please see our global comment on mutual information and the JSD. We reorganised Sections 3.2 / 3.3 to include more concrete theoretical motivation from mutual information maximisation, and separate this from the specifics that are important for implementation.\n\nWe agree with your comment that the GCN is in fact used in a semi-supervised setting (as not all nodes are labelled). What we referred to is that the learning objective is fully supervised (solely cross-entropy on the training nodes\u2019 labels), and have revised the paper accordingly.\n\nWe acknowledge your comment about our method having the traits of a framework, but claim that such features are a consequence of the current state of the art in graph neural networks, rather than any limitations of our methodology. Namely:\n\n- Similar to other recently proposed GCN methods, such as the DiffPool algorithm (Ying et al., NIPS 2018), we indeed are agnostic to the choice of the GCN layer. This is because graph convolutional networks are a very active area of research and we don't currently have a \u201ccatch-all\u201d layer for all possible scenarios (e.g. transductive vs. inductive).\n\n- The fact that different high-level architectures are used is normal, and constitutes hyperparameter optimisation and/or relating the work to previous successful architectures.\n\n- Our negative distribution choice is, in fact, mostly uniform. We\u2019d like to use different input graphs as negative examples (as DIM does), but this is only possible (with a limited pool of examples) for PPI. In all other case we use node-wise shuffling, which was demonstrably robust---and we also motivate this robustness with further studies in Appendix C.\n\n\nA randomly initialised graph convolutional network is basically the setting in which we set the number of training epochs to zero---i.e. we start with weights initialised according to Xavier initialisation, and then immediately proceed to use this as our encoder rather than performing any unsupervised training of the encoder.\n\nWe thank you once again for your review, which has definitely helped make our paper\u2019s contributions stronger!\n", "title": "Reply to AnonReviewer1"}, "r1gu9BpZAX": {"type": "rebuttal", "replyto": "HkgHlf-qnX", "comment": "Thank you very much for the extremely kind review, and we are very glad you enjoyed the paper! We have made further updates to the paper---some details of which are outlined in our global comment above.", "title": "Reply to AnonReviewer3"}, "HyeIUHpZAm": {"type": "rebuttal", "replyto": "rklz9iAcKQ", "comment": "We agree that the discussion on the connections between mutual information and the Jensen-Shannon Divergence / binary cross entropy was insufficient in our paper, and we have added further details in our revision. \n\nWe have added this intuition as motivation to our loss function in Section 3.3.\n\nFor a brief overview:\n\nLet p(X, f(X)) be the joint distribution of the random variable X and f(X), a random variable corresponding to the transformation of X by a deterministic function, f. Also, let p(X) be an empirical distribution specified by a finite set of given samples, and let p(f(X)) be the marginal.\n\nIn our setting, we both train a classifier to distinguish between samples from p(X, f(X)) and from p(X) p(f(X))) and find the function f in F that minimizes the same classifier\u2019s loss. In other words, we are looking for the functions f* in F that satisfy \nf* = argmin_f argmin_c error(p(X, f(X)), p(X) p(f(X)); c), \nand we use the binary cross-entropy (BCE) as a proxy for the classification error.\n\nIt is enough to show that optimal solutions to the above only contain functions f that are invertible, as the mutual information MI(X; f(X)) is invariant over invertible functions of F, and maximized for them. Because f is deterministic, and considering a discrete X, card(X) >= card(f(X)), where with non-invertible functions, this ordering is strict ( i.e., card(X) > card(f(X))). Given a mixture between the joint and the product of marginals, it can be shown that the optimal f (under the classification error) has card(X) = card(f(X)). This and the fact that f is deterministic implies there exists an inverse. Hence the f* that minimizes the classification error between the joint and the product of marginals in this setting also maximizes the mutual information MI(X;f(X)) = MI(X; X) = H(X).\n", "title": "[Revision] On mutual information estimation and maximization and the cross-entropy"}, "HJeDwVp-AQ": {"type": "rebuttal", "replyto": "Skei4zS7a7", "comment": "Thank you for your comment pointing out similarities between our work and Embedding Propagation (EP). However, we believe that some of the similarities you mention might have been misattributed. To highlight:\n\nIn DGI, we not only add graph convolutions, we also employ a very different objective function, where the goal is to maximize the mutual information between single node embeddings and a summary embedding of the entire graph. Thus, there are two key points of clarification regarding the fundamental difference between our work and EP: \n\n1) the \u201creadout\u201d function in our work does not simply abstract away the neighborhood aggregation function in EP, since in our work the \u201creadout\u201d function embeds an entire graph; \n\n2) the objective in our work maximizes the mutual information between a single node embedding and the summary graph embedding, whereas in EP they use a \u201cone-step\u201d random walk objective, which maximizes the similarity between a node embedding and the embedding of its local neighborhood.\n", "title": "On the link to Embedding Propagation (EP)"}, "B1eoGoSQpX": {"type": "rebuttal", "replyto": "BygK5QSXp7", "comment": "Hello,\n\nThank you for your comment!\n\nAll reported improvements in PPI results concern solely the fully supervised setup; not the unsupervised one. And, indeed, this is the supervised result we report---namely, the avg. pooling architecture from the GaAN paper (Zhang et al., UAI 2018), which we report, is one example of a supervised result that substantially (30+%) improves on the supervised result reported in the original GraphSAGE paper (of 0.612).", "title": "More recent results for PPI are reported"}, "BkeOgwpm37": {"type": "review", "replyto": "rklz9iAcKQ", "review": "This paper adapts the Deep Informax (DIM; Hjelm et al. 2018) method, which was used on\nimage data, into the graph domain. The architecture of the neural network and\nthe learning cost function are given by figure 1 and eq.(1), respectively.\n\nThe idea is to maximize the mutual information between a local representation\n(of a \"patch\" defined by graph adjacency) and a global representation (of the entire graph),\nso those different local patches are encouraged to carry some shared\nglobal information.\n\nThis is in contrast to most unsupervised graph encoders, where the objective is\nto fit the random walk similarities (node adjacency on the graph).\n\nIn an unsupervised learning scenario, where the graph structure and node features\nare given, the authors achieved state-of-the-art performance on transductive and\ninductive node classification tasks, in some cases even better than supervised baselines. \n\nThe paper is well written. I recommend acceptance and have the following concerns.\n\nMain comment 1\n\nThe title suggests that there are some information theory contents. \nHowever, section 3 does not include much information theory.\nRather, the author(s) directly give eq.(1) with pointers to references and informal discussions.\nThis is not so helpful. It is not straightforward for\nthe reader to relate eq.(1) with the definition of mutual information.\nIdeally, before eq.(1) there should be one or two equations (with text)\nto introduce the Jesen-Shannon MI estimation and information theoretic bounds etc.\n\nOverall, due to this, the contribution is mainly on adapting the DIM method info the graph domain. Although the experimental results are good, there is not much theoretical insight or \"recreative\" introduction of the DIM method from the authors' perspectives. This is the main reason for that it is not a strong accept.\n\nMain comment 2\n\nA motivation of the proposition is to \"not rely on random walks\", or graph node adjacency.\nNotice that random walks can be intuitively regarded as higher order node adjacency.\nHowever, the encoder, which is based on GCN, does rely on the adjacency matrix,\nas the convolution is done in local neighborhoods (that can also be defined based on\nrandom-walk similarities). The authors are therefore suggested to make it\nclear in related places that, it is the cost function which is not based\non node adjacency, although the neural network structure does rely on it.\n\nAs a related question, in the inductive experiments, in the mini-batch of 256 nodes\nrandomly selected, or selected by a local patch of the graph which is connected or nearby?\nIf it is the latter case, the cost function does rely on random-walk similarities,\nas the summary vector will be a local patch average.\n\nQuestions:\n\n-The summary vector is the average of all node features. On large graphs, the\naverage may carry less information as compared to small graphs. It can be\nobserved that on Pubmed and Reddit, the performance improvement is not as\nhigh as the other small graphs. Could you comment on this?\n\n-In the baseline \"DeepWalk+features\", are the two different types of features directly concatenated?\n\n-Is it straightforward to apply DGI to link prediction tasks?\n\n-It that a concern that the random corruption function will cause a high variance of the gradient?\n", "title": "Alternative information-theoretic objective for unsupervised graph representation learning", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "HkgHlf-qnX": {"type": "review", "replyto": "rklz9iAcKQ", "review": "This paper describes an approach for unsupervised learning of node features on a graph (with known structure), so that learned local representations represent community information that has high mutual info with a graph-level summary. The general idea is they apply InfoMax to graphs via graph convolutional networks (GCN), and report impressive results, including rivaling supervised learning methods for node classification. The 3 experiments are on paper topic classification, social network modeling, and protein classification.\n\nThe idea of using InfoMax with GCNs for unsupervised node learning is clever and timely, the technical contribution is solid, the experiments are executed well, and the paper is clear and easy to read.", "title": "Solid work, will have high impact", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "B1lVxghvnm": {"type": "review", "replyto": "rklz9iAcKQ", "review": "This paper proposes an unsupervised approach to learning node representations. The basic steps are: (1) use an encoder E to learn node vectors, (2) use a readout function R to summarize node vectors into the graph vector, (3) use a scoring function D to score how much the node vectors are aligned with the graph vector, and (4) maximize the scores for the given graph meanwhile minimize the those from the negative distribution.\n\nI feel that the idea is interesting; however, the paper is less well written and the realization of the idea has drawbacks as well.\n\n1. Presentation of Section 3.2 can be improved. The proposed approach becomes clear only toward the end.\n\n2. Naming and wording is misleading. The title and the whole paper use the wording \"mutual information\", whereas in reality, the loss function is a cross entropy.\n\n3. In equation (1), it is unclear why the authors take expectation with respect to the distribution of graphs before summing the scores for one particular graph. Should the order of the expectation and summation be swapped?\n\n4. The proposal is more like a framework than a specific method. The encoder and the negative distribution need to be separately designed for different graphs.\n\nGood things about the proposal:\n\n5. The downstream classification results are quite comparable to those of supervised methods (except for the PPI data).\n\n6. The learned node representations possess a clear clustering structure (Figure 3).\n\nMinor comments:\n\n7. In the third paragraph of section 4.3, the authors state that \"... for the GCN model in the fully supervised setting\". GCN should be a semi-supervised method rather than a fully-supervised one.\n\n8. In the last paragraph of section 4.3, what is a \"randomly initialized graph convolutional network\" and how is it different from the proposal?\n", "title": "Idea is interesting; realization is graph-specific", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "SkxB37p2t7": {"type": "rebuttal", "replyto": "rJl0fT6itQ", "comment": "Hi Ming,\n\nThanks for your comment and kind feedback!\n\nDGI performs unsupervised learning, so comparisons with supervised methods are inappropriate---the supervised methods we did include were the ones that used similar propagation rules as our encoders. In the transductive case, this was the GCN---as it uses an identical propagation rule (with one extra layer).\n\nWe'll cite GraphSGAN as an indicator of the current supervised state-of-the-art in an updated version of the paper -- thanks!", "title": "Provided results"}}}