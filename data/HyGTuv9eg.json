{"paper": {"title": "Incorporating long-range consistency in CNN-based texture generation", "authors": ["Guillaume Berger", "Roland Memisevic"], "authorids": ["guillaume.berger@umontreal.ca", "memisevr@iro.umontreal.ca"], "summary": "We propose a simple extension to the Gatys et al. algorithm which makes it possible to incorporate long-range structure into texture generation.", "abstract": "Gatys et al. (2015) showed that pair-wise products of features in a convolutional network are a very effective representation of image textures. We propose a simple modification to that representation which makes it possible to incorporate long-range structure into image generation, and to render images that satisfy various symmetry constraints. We show how this can greatly improve rendering of regular textures and of images that contain other kinds of symmetric structure. We also present applications to inpainting and season transfer.", "keywords": ["Computer vision", "Deep learning"]}, "meta": {"decision": "Accept (Poster)", "comment": "The program committee appreciates the authors' response to concerns raised in the reviews. While there are some concerns about the computational speed of the approach as well as its advantage over existing methods for some textures, reviewers are excited by the ability of this work to produce structured texture that requires long-range interactions. Overall, the work has contributions that are worth presenting at ICLR."}, "review": {"rywHfTILe": {"type": "rebuttal", "replyto": "SJrhkAWEl", "comment": "Thank you for the extensive feedback. We respond to the main criticisms raised by the reviewer below.\n\n>> I agree with claim a). However, the generated textures still have some issues such as greyish regions so the problem is not solved.\n>> Additionally, the procedure proposed is very costly which makes an already slow texture synthesis method substantially slower. For \n>> example, in comparison, the concurrent work by Liu et al. (http://arxiv.org/abs/1605.01141) that tackles the same problem by adding \n>> constraints to the Fourier spectrum of the synthesised texture shows comparable or better results while being far more efficient.\n\nAs computational efficiency is concerned, our solution to incorporate long-range consistency has indeed a cost in terms of speed and memory. Regarding speed, if one has a limited time budget to generate textures, two solutions come to mind:\n\na) Not wait for convergence and use intermediate outputs. As you can see here (https://github.com/guillaumebrg/texture_generation/blob/master/results/Renderings%20after%202-5-30%20minutes.pdf), our renderings after 2 and 5 minutes* are comparable (or better) to the ones produced by the Gatys et al. algorithm. In some cases, the long-range structure of the reference image is reproduced early and already visible after 2 minutes (the flags image, the crowd painting, e.g.). In other cases, one would have to wait longer before observing the long-range structure (the brick wall, e.g.), but again, even in those cases, intermediate outputs are visually comparable to the ones produced by Gatys et al.'s method within the same amount of time.\n\t\t\nb) If one wants very fast results, the technique described in [Ulyanov et al., https://arxiv.org/pdf/1603.03417v1.pdf] is compatible with our texture model. While requiring a specific training for each reference image, it would permit to obtain feedforward neural nets that would generate structured textures within milliseconds (on a decent GPU). Whatever the texture model used during training is, the generation time would be the same afterwards.\n\nWe think that these two considerations mitigate the computational drawback of our proposal. \n\nRegarding Liu et al.'s work, they propose to retropropagate an additional gradient term which encourages the Fourier spectrum of the image being constructed to match the one of the reference image. This seems to produce very nice results on quasi-periodic textures. Nevertheless, this approach seems to be built on the fact that quasi-periodic images exhibit very specific Fourier spectrums. In particular, the approach is only evaluated on this category of textures. In comparison, our transformed Gramians are not limited to near-regular textures and we show that our approach permits to incorporate long-range properties other than periodicity: depth, symmetry, consistency in inpainted images...\n\n*: according to their webpage (http://bethgelab.org/deeptextures/), images produced in the original paper have been obtained within 10 minutes on a K40 GPU (and images were smaller in this work: 256x256 vs 384x384 in our paper).\n\n\n>> With c) I don\u2019t see a clear advantage of the proposed method to the existing Gatys et al. algorithm.\n\nWe agree on this point and do not claim c). The original work by Gatys et al. on texture synthesis has been greatly used in style transfer applications. Section 4.4 is aimed at showing results when applying our approach in this context. However, as written in the article, although we observe noticeable differences between the two approaches, our results are similar to those from Gatys et al..", "title": "Response"}, "BJEzlSCQx": {"type": "rebuttal", "replyto": "ry-_LJ1Xe", "comment": "Thank you for your feedback, and I'm sorry for the delay...\n\nWe did all our inpainting experiments again, monitoring the Gatys et al. loss after each LBFGS iteration. In most cases, the final Gatys et al. loss is higher when using our model. It makes sense since we are optimizing a modified version of the loss. For now, you can find the optimization curves, as well as rendered images at different steps of the optimization, in this GitHub repository: https://github.com/guillaumebrg/texture_generation/tree/master/results/inpainting_analysis. We will probably include these results in the paper by the end of the week.\n\nWe also did some experiments with other optimizers (Conjugate Gradient, Adam) and we obtained similar results. We kept using LBFGS as it gives faster results.", "title": "Inpainting results"}, "rkN7j8Emg": {"type": "rebuttal", "replyto": "SJ6cwnrze", "comment": "Thank you for your questions.\n\nIn our approach, we propose to compute Gram matrices of spatially transformed feature maps. In the translation case, this allows, for instance, to capture correlations between features at position (i, j+delta) and (i, j-delta) in average. There exists a specific situation where our approach is strictly equivalent to computing Gram matrices of deeper layers. Indeed, if the pre-trained CNN uses linear activations and \"one-hot\" kernels that have only one non-zero component (delta and -delta horizontally shifted from the center to strictly match our approach), then, deeper layers simply contain translated version of lower feature maps. In that case, computing Gram matrices of deeper layers would permit to directly capture cross-correlation statistics in lower ones. Nevertheless, this situation is highly non-probable: why would the pre-trained CNN simply copy translated versions of lower feature maps ? It clashes with the limited capacity of the CNN which has probably learned more interesting operations during its supervised training. Experiments discussed in the paper confirm this intuition: Figure 3 shows that using feature maps up to \"pool5\"* helps, but is not enough to reproduce reasonable long-range structure. In other words, the pre-trained CNN has learned complex non-linear operations, making it difficult to capture cross-correlations through Gram matrices of deeper feature maps. Moreover, recent work in [2] (under review at ICLR2017) showed that using a deep pre-trained CNN is not necessary to generate visually sensible textures: random shallow CNN features work surprisingly well, in particular when exploiting a multi-scale shallow CNN. This finding with multi-scale shallow CNNs might be very linked to our results with translated Gramians, as computing Gram matrices on top of feature maps given by multi-scale kernels is a way to capture correlation of features at several spatial locations. We will clarify this in an updated version of the paper.\n\nRegarding evaluation, we compare our approach with [1] by assessing the visual quality of renderings given by both methods. With the gain we get for the majority of the numerous textures we tried, it seems fair to conclude that our approach incorporates long-range consistency into the generated texture that [1] fails to reproduce. This is particularly visible on regular and symmetric textures, for which renderings obtained by [1] differ significantly from ours. When the reference texture does not contain any long-range structure, a visual comparison is indeed more difficult as our approach gives results very similar to [1]. For a quantitative evaluation, one possible solution, inspired by the classification experiment reported in [1], might be to try comparing recognition performance obtained on a labeled texture dataset** when exploiting the texture representation proposed by [1] or ours. In practice, the classification procedure would consist in using Gram matrices of feature maps as inputs to a simple texture classifier. It would be interesting to observe how the accuracy score changes when adding transformed Gramians to the input representation. \n\n*: \"pool5\" is the last VGG19 convolutional layer before fully connected ones. The input receptive field of \"pool5\" covers the whole image.\n**: DTD link: https://www.robots.ox.ac.uk/~vgg/data/dtd/\n\n[1] L. A. Gatys, A. S. Ecker, and M. Bethge. Texture synthesis using convolutional neural networks. \nIn Advances in Neural Information Processing Systems 28, 2015a. URL http://arxiv.org/abs/1505.07376.\n\n[2] D. Ulyanov, V. Lebedev, A. Vedaldi, and V. Lempitsky. Texture networks: Feed-forward synthesis of textures and stylized images. \nIn International Conference on Machine Learning (ICML), 2016. Under review at ICLR 2017 under the title: What does it take to generate natural textures ? (https://openreview.net/forum?id=BJhZeLsxx)", "title": "significance of the method and evaluation"}, "ry-_LJ1Xe": {"type": "review", "replyto": "HyGTuv9eg", "review": "The inpainting results with the Gatys et al. method look like there are some problems with the convergence of the optimisation. Could you please report the values of the Gatys et al. loss function for both, the result of your method as well as the result of the Gatys et al. method? \nI could imagine that the results of your method would also give a smaller loss for the loss function of the Gatys et al. method, which would indicate that a better optimiser for the Gatys et al. method might achieve comparable results.The paper introduces a variation to the CNN-based texture synthesis procedure of Gatys et al. that matches correlations between spatially shifted feature responses in addition to the correlations between feature responses at the same position in the feature maps. \nThe paper claims that this \na) improves texture synthesis for textures with long-range regular structures, that are not preserved with the Gatys et al. method\nb) improves performance on texture inpainting tasks compared to the Gatys et al. method\nc) improves results in season transfer when combined with the style transfer method by Gatys et al. \nFurthermore the paper shows that\nd) by matching correlations between spatially flipped feature maps, symmetry properties around the flipping axis can be preserved.\n\nI agree with claim a). However, the generated textures still have some issues such as greyish regions so the problem is not solved. Additionally, the procedure proposed is very costly which makes an already slow texture synthesis method substantially slower. For example, in comparison, the concurrent work by Liu et al. (http://arxiv.org/abs/1605.01141) that tackles the same problem by adding constraints to the Fourier spectrum of the synthesised texture shows comparable or better results while being far more efficient.\n\nAlso with b) the presented results constitute an improvement over the Gatys et al. method but again the results are not too exciting - one would not prefer this model to other inpainting algorithms.\n\nWith c) I don\u2019t see a clear advantage of the proposed method to the existing Gatys et al. algorithm.\n\nFinally, d) is a neat idea and the initial results look interesting but they don\u2019t go much further than that. \n\nAll in all I think it is decent work but neither its originality and technical complexity nor the quality of the results are convincing enough for acceptance.\nThat said, I could imagine this to be a nice contribution to the workshop track though.\n", "title": "Inpainting comparison with Gatys et al", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "SJrhkAWEl": {"type": "review", "replyto": "HyGTuv9eg", "review": "The inpainting results with the Gatys et al. method look like there are some problems with the convergence of the optimisation. Could you please report the values of the Gatys et al. loss function for both, the result of your method as well as the result of the Gatys et al. method? \nI could imagine that the results of your method would also give a smaller loss for the loss function of the Gatys et al. method, which would indicate that a better optimiser for the Gatys et al. method might achieve comparable results.The paper introduces a variation to the CNN-based texture synthesis procedure of Gatys et al. that matches correlations between spatially shifted feature responses in addition to the correlations between feature responses at the same position in the feature maps. \nThe paper claims that this \na) improves texture synthesis for textures with long-range regular structures, that are not preserved with the Gatys et al. method\nb) improves performance on texture inpainting tasks compared to the Gatys et al. method\nc) improves results in season transfer when combined with the style transfer method by Gatys et al. \nFurthermore the paper shows that\nd) by matching correlations between spatially flipped feature maps, symmetry properties around the flipping axis can be preserved.\n\nI agree with claim a). However, the generated textures still have some issues such as greyish regions so the problem is not solved. Additionally, the procedure proposed is very costly which makes an already slow texture synthesis method substantially slower. For example, in comparison, the concurrent work by Liu et al. (http://arxiv.org/abs/1605.01141) that tackles the same problem by adding constraints to the Fourier spectrum of the synthesised texture shows comparable or better results while being far more efficient.\n\nAlso with b) the presented results constitute an improvement over the Gatys et al. method but again the results are not too exciting - one would not prefer this model to other inpainting algorithms.\n\nWith c) I don\u2019t see a clear advantage of the proposed method to the existing Gatys et al. algorithm.\n\nFinally, d) is a neat idea and the initial results look interesting but they don\u2019t go much further than that. \n\nAll in all I think it is decent work but neither its originality and technical complexity nor the quality of the results are convincing enough for acceptance.\nThat said, I could imagine this to be a nice contribution to the workshop track though.\n", "title": "Inpainting comparison with Gatys et al", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "SJ6cwnrze": {"type": "review", "replyto": "HyGTuv9eg", "review": "The paper investigates a simple extension of Gatys et al. CNN-based texture descriptors for image generation. The idea is to measure correlation statistics between shifted texture locations. This is obtained as a simple modification of Gatys et al. where a shift operation is introduced before the Gram matrices are computed.\n\nThe idea is a simple one but with interesting effects on the generated texture. It can also be extended to transformations other than translation, which is a nice bonus. However, I have a few questions that I would like to see discussed in the paper.\n\nFirst, an indirect way of capturing longer range statistics is simply to compute the correlation between deeper CNN feature responses, as these would have automatically larger receptive fields. It would be nice to explain why measuring longer ranger correlations is preferable.\n\nSecond, there is a fundamental issue which makes evaluation of this and similar approaches difficult. Here the goal is to generate an image which resembles the reference. Crucially, however, the result must also be different from the input, as the trivial solution is to simply copy the reference image as is. In other words, the goal is to learn a generative model of the ``texture'', intended as a distribution over analogous images. This is clearly difficult, particularly when long range relationships are involved since the statistics of those is difficult to model from a single small texture sample. Can the authors describe what should be done, at lest in the ideal case, in order to say whether this and similar methods are good models of textures?\n\n\nThe paper investigates a simple extension of Gatys et al. CNN-based texture descriptors for image generation. Similar to Gatys et al., the method uses as texture descriptor the empirical intra-channel correlation matrix of the CNN feature response at some layer of a deep network. Differently from Gatys et al., longer range correlations are measured by introducing a shift between the correlated feature responses, which translates in a simple modification of the original architecture.\n\nThe idea is simple but has interesting effects on the generated textures and can be extended to transformations other than translation. While longer range correlations could be accounted for by considering the response of deeper CNN features in the original method by Gatys et al., the authors show that modelling them explicitly using shallower features is more effective, which is reasonable.\n\nAn important limitation that this work shares with most of its peers is the lack of a principled quantitative evaluation protocol, such that judging the effectiveness of the approach remains almost entirely a qualitative affair. While this should not be considered a significant drawback of the paper due to the objective difficulty of solving this open issue, nevertheless it is somewhat limiting that no principled evaluation method could be devised and implemented. The authors suggest that, as future work, a possible evaluation method could be based on a classification task -- this is a potentially interesting approach that merits some further investigation.\n", "title": "Significance of the method and assessing its quality", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "ByUEmu-Ee": {"type": "review", "replyto": "HyGTuv9eg", "review": "The paper investigates a simple extension of Gatys et al. CNN-based texture descriptors for image generation. The idea is to measure correlation statistics between shifted texture locations. This is obtained as a simple modification of Gatys et al. where a shift operation is introduced before the Gram matrices are computed.\n\nThe idea is a simple one but with interesting effects on the generated texture. It can also be extended to transformations other than translation, which is a nice bonus. However, I have a few questions that I would like to see discussed in the paper.\n\nFirst, an indirect way of capturing longer range statistics is simply to compute the correlation between deeper CNN feature responses, as these would have automatically larger receptive fields. It would be nice to explain why measuring longer ranger correlations is preferable.\n\nSecond, there is a fundamental issue which makes evaluation of this and similar approaches difficult. Here the goal is to generate an image which resembles the reference. Crucially, however, the result must also be different from the input, as the trivial solution is to simply copy the reference image as is. In other words, the goal is to learn a generative model of the ``texture'', intended as a distribution over analogous images. This is clearly difficult, particularly when long range relationships are involved since the statistics of those is difficult to model from a single small texture sample. Can the authors describe what should be done, at lest in the ideal case, in order to say whether this and similar methods are good models of textures?\n\n\nThe paper investigates a simple extension of Gatys et al. CNN-based texture descriptors for image generation. Similar to Gatys et al., the method uses as texture descriptor the empirical intra-channel correlation matrix of the CNN feature response at some layer of a deep network. Differently from Gatys et al., longer range correlations are measured by introducing a shift between the correlated feature responses, which translates in a simple modification of the original architecture.\n\nThe idea is simple but has interesting effects on the generated textures and can be extended to transformations other than translation. While longer range correlations could be accounted for by considering the response of deeper CNN features in the original method by Gatys et al., the authors show that modelling them explicitly using shallower features is more effective, which is reasonable.\n\nAn important limitation that this work shares with most of its peers is the lack of a principled quantitative evaluation protocol, such that judging the effectiveness of the approach remains almost entirely a qualitative affair. While this should not be considered a significant drawback of the paper due to the objective difficulty of solving this open issue, nevertheless it is somewhat limiting that no principled evaluation method could be devised and implemented. The authors suggest that, as future work, a possible evaluation method could be based on a classification task -- this is a potentially interesting approach that merits some further investigation.\n", "title": "Significance of the method and assessing its quality", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}}}