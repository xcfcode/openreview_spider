{"paper": {"title": "Identifying Analogies Across Domains", "authors": ["Yedid Hoshen", "Lior Wolf"], "authorids": ["yedidh@fb.com", "wolf@fb.com"], "summary": "Finding correspondences between domains by performing matching/mapping iterations", "abstract": "Identifying analogies across domains without supervision is a key task for artificial intelligence. Recent advances in cross domain image mapping have concentrated on translating images across domains. Although the progress made is impressive, the visual fidelity many times does not suffice for identifying the matching sample from the other domain. In this paper, we tackle this very task of finding exact analogies between datasets i.e. for every image from domain A find an analogous image in domain B. We present a matching-by-synthesis approach: AN-GAN, and show that it outperforms current techniques. We further show that the cross-domain mapping task can be broken into two parts: domain alignment and learning the mapping function. The tasks can be iteratively solved, and as the alignment is improved, the unsupervised translation function reaches quality comparable to full supervision. ", "keywords": ["unsupervised mapping", "cross domain mapping"]}, "meta": {"decision": "Accept (Poster)", "comment": "This paper builds on top of Cycle GAN ideas where the main idea is to jointly optimize the domain-level translation function with an instance-level matching objective. Initially the paper received two negative reviews (4,5) and a positive (7). After the rebuttal and several back and forth between the first reviewer and the authors, the reviewer was finally swayed by the new experiments. While not officially changing the score, the reviewer recommended acceptance. The AC agrees that the paper is interesting and of value to the ICLR audience."}, "review": {"BkyDnj5VG": {"type": "rebuttal", "replyto": "ByECSWv4z", "comment": "We are deeply thankful to AnonReviewer2 for holding an open discussion and for acknowledging the significance of the proposed problem setting, the work\u2019s novelty, and the quality of the experiments.\nWe are also happy that AnonReviewer2 found the list of possible applications, provided in reply to the challenge posted in the review, to be exciting. We therefore gladly accept the new challenge that was set, to demonstrate the success of our method on one of the proposed applications in the list.\nSince the reviewer explicitly requested 3D point cloud matching, we have evaluated our method on this task. It should be noted that our method was never tested before in low-D settings, so this experiment is of particular interest.\nSpecifically, we ran the experiment using the Bunny benchmark, exactly as is shown in \u201cDiscriminative optimization: theory and applications to point cloud registration\u201d, CVPR\u201917 available as an extended version at https://arxiv.org/pdf/1707.04318.pdf, Sec. 6.2.3 . In this benchmark, the object is rotated by a random degree, and we tested the success rate of our model in achieving alignment for various ranges of rotation angles. \nFor both CycleGAN and our method, the following architecture was used. D is a fully connected network with 2 hidden layers, each of 2048 hidden units, followed by BatchNorm and with Leaky ReLU activations. The mapping function is a linear affine matrix of size 3 * 3 with a bias term. Since in this problem, the transformation is restricted to be a rotation matrix, in both methods we added a loss term that encourages orthonormality of the weights of the mapper.  Namely, ||WW^T-I||, where W are the weights of our mapping function.\nThe table below depicts the success rate for the two methods, for each rotation angle bin, where success is defined in this benchmark as achieving an RMSE alignment accuracy of 0.05.\nRotation angle | CycleGAN |   Ours\n============================\n0-30                    0.12000     1.00000 \n30-60                  0.12500     1.00000 \n60-90                  0.11538     0.88462 \n90-120                0.07895     0.78947 \n120-150              0.05882     0.64706 \n150-180              0.10000     0.76667\n               \nComparing to the results reported in Fig. 3 of  https://arxiv.org/pdf/1707.04318.pdf, middle column, our results seem to significantly outperform the methods presented there at large angles. Therefore, the proposed method outperforms all baselines and, once again, proves to be effective as well as broadly applicable.\nP.S. It seems that the comment we posted above, which was titled \u201cA real-world application of our method in cell biology\u201d (https://openreview.net/forum?id=BkN_r2lR-&noteId=rJ6aA85QG), went unnoticed. In a way, it already addressed the new challenge by presenting quantitative results on a real-world dataset for which there are no underlying ground truth matches. ", "title": "Additional experiment requested by Reviewer"}, "SkHatuolz": {"type": "review", "replyto": "BkN_r2lR-", "review": "This paper presents an image-to-image cross domain translation framework based on generative adversarial networks. The contribution is the addition of an explicit exemplar constraint into the formulation which allows best matches from the other domain to be retrieved. The results show that the proposed method is superior for the task of exact correspondence identification and that AN-GAN rivals the performance of pix2pix with strong supervision.\n\n\nNegatives:\n1.) The task of exact correspondence identification seems contrived. It is not clear which real-world problems have this property of having both all inputs and all outputs in the dataset, with just the correspondence information between inputs and outputs missing.\n2.) The supervised vs unsupervised experiment on Facades->Labels (Table 3) is only one scenario where applying a supervised method on top of AN-GAN\u2019s matches is better than an unsupervised method.  More transfer experiments of this kind would greatly benefit the paper and support the conclusion that \u201cour self-supervised method performs similarly to the fully supervised method.\u201d \n\nPositives:\n1.) The paper does a good job motivating the need for an explicit image matching term inside a GAN framework\n2.) The paper shows promising results on applying a supervised method on top of AN-GAN\u2019s matches.\n\nMinor comments:\n1. The paper sometimes uses L1 and sometimes L_1, it should be L_1 in all cases.\n2. DiscoGAN should have the Kim et al citation, right after the first time it is used. I had to look up DiscoGAN to realize it is just Kim et al.", "title": "AN-GAN: match-aware translation of images across domains, new ideas for combining image matching and GANs", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "HJ08-bCef": {"type": "review", "replyto": "BkN_r2lR-", "review": "The paper presents a method for finding related images (analogies) from different domains based on matching-by-synthesis. The general idea is interesting and the results show improvements over previous approaches, such as CycleGAN (with different initializations, pre-learned or not). The algorithm is tested on three datasets.\n\nWhile the approach has some strong positive points, such as good experiments and theoretical insights (the idea to match by synthesis and the proposed loss which is novel, and combines the proposed concepts), the paper lacks clarity and sufficient details.\n\nInstead of the longer intro and related work discussion, I would prefer to see a Figure with the architecture and more illustrative examples to show that the insights are reflected in the experiments. Also, the matching part, which is discussed at the theoretical level, could be better explained and presented at a more visual level. It is hard to understand sufficiently well what the formalism means without more insight.\n\nAlso, the experiments need more details. For example, it is not clear what the numbers in Table 2 mean.\n\n\n\n", "title": "The approach is interesting but the paper lacks clarity of presentation", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "ryhcYB-bG": {"type": "review", "replyto": "BkN_r2lR-", "review": "This paper adds an interesting twist on top of recent unpaired image translation work. A domain-level translation function is jointly optimized with an instance-level matching objective. This yields the ability to extract corresponding image pairs out of two unpaired datasets, and also to potentially refine unpaired translation by subsequently training a paired translation function on the discovered matches. I think this is a promising direction, but the current paper has unconvincing results, and it\u2019s not clear if the method is really solving an important problem yet.\n\nMy main criticism is with the experiments and results. The experiments focus almost entirely on the setting where there actually exist exact matches between the two image sets. Even the partial matching experiments in Section 4.1.2 only quantify performance on the images that have exact matches. This is a major limitation since the compelling use cases of the method are in scenarios where we do not have exact matches. It feels rather contrived to focus so much on the datasets with exact matches since, 1) these datasets actually come as paired data and, in actual practice, supervised translation can be run directly, 2) it\u2019s hard to imagine datasets that have exact but unknown matches (I welcome the authors to put forward some such scenarios), 3) when exact matches exist, simpler methods may be sufficient, such as matching edges. There is no comparison to any such simple baselines.\n\nI think finding analogies that are not exact matches is much more compelling. Quantifying performance in this case may be hard, and the current paper only offers a few qualitative results. I\u2019d like to see far more results, and some attempt at a metric. One option would be to run user studies where humans judge the quality of the matches. The results shown in Figure 2 don\u2019t convince me, not just because they are qualitative and few, but also because I\u2019m not sure I even agree that the proposed method is producing better results: for example, the DiscoGAN results have some artifacts but capture the texture better in row 3.\n\nI was also not convinced by the supervised second step in Section 4.3. Given that the first step achieves 97% alignment accuracy, it\u2019s no surprised that running an off-the-shelf supervised method on top of this will match the performance of running on 100% correct data. In other words, this section does not really add much new information beyond what we could already infer given that the first stage alignment was so successful.\n\nWhat I think would be really interesting is if the method can improve performance on datasets that actually do not have ground truth exact matches. For example, the shoes and handbags dataset or even better, domain adaptation datasets like sim to real.\n\nI\u2019d like to see more discussion of why the second stage supervised problem is beneficial. Would it not be sufficient to iterate alpha and T iterations enough times until alpha is one-hot and T is simply training against a supervised objective (Equation 7)?\n\nMinor comments:\n1. In the intro, it would be useful to have a clear definition of \u201canalogy\u201d for the present context.\n2. Page 2: a link should be provided for the Putin example, as it is not actually in Zhu et al. 2017.\n3. Page 3: \u201cWeakly Supervised Mapping\u201d \u2014 I wouldn\u2019t call this weakly supervised. Rather, I\u2019d say it\u2019s just another constraint / prior, similar to cycle-consistency, which was referred to under the \u201cUnsupervised\u201d section.\n4. Page 4 and throughout: It\u2019s hard to follow which variables are being optimized over when. For example, in Eqn. 7, it would be clearer to write out the min over optimization variables.\n5. Page 6: The Maps dataset was introduced in Isola et al. 2017, not Zhu et al. 2017.\n6. Page 7: The following sentence is confusing and should be clarified: \u201cThis shows that the distribution matching is able to map source images that are semantically similar in the target domain.\u201d\n7. Page 7: \u201cThis shows that a good initialization is important for this task.\u201d \u2014 Isn\u2019t this more than initialization? Rather, removing the distributional and cycle constraints changes the overall objective being optimized.\n8. In Figure 2, are the outputs the matched training images, or are they outputs of the translation function?\n9. Throughout the paper, some citations are missing enclosing parentheses.", "title": "Interesting direction but unconvincing experiments and uncompelling applications", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "rJ6aA85QG": {"type": "rebuttal", "replyto": "BkN_r2lR-", "comment": "Two reviewers were concerned that the problem of unsupervised simultaneous cross-domain alignment and mapping, while well suited to the existing ML benchmarks, may not have real-world applications. In our rebuttal, we responded to the challenge posed by AnonReviewer2 to present examples of applications with many important use cases.\n\nIn order to further demonstrate that the task has general scientific significance, we present results obtained using our method in the domain of single cell expression analysis. This field has emerged recently, due to new technologies that enable the measurement of gene expression at the level of individual cells. This capability already led to the discovery of quite a few previously unknown cell types and holds the potential to revolutionize cell biology. However, there are many computational challenges since the data is given as sets of unordered measurements. Here, we show how to use our method to map between gene expression of cell samples from two individuals and find interpersonal matching cells.\n\nFrom the data of [1], we took the expressions of blood cells (PMBC) extracted for donors A and B (available online at https://support.10xgenomics.com/single-cell-gene-expression/datasets; we used the matrices of what is called \u201cfiltered results\u201d). These expressions are sparse matrices, denoting 3k and 7k cells in the two samples and expressions of around 32k genes.  We randomly subsampled the 7k cells from donor B to 3k and reduced the dimensions of each sample from 32k to 100 via PCA. Then, we applied our method in order to align the expression of the two donors (find a transformation) and match between the cell samples in each. Needless to say, there is no supervision in the form of matching between the cells of the two donors and the order of the samples is arbitrary. However, we can expect such matches to exist. \n\nWe compare three methods:\nThe mean distance between a sample in set A and a sample in set B (identity transformation). \nThe mean distance after applying a CycleGAN to compute the transformation from A to B (CG for CycleGAN).\nThe mean distance after applying our complete method.\n\nThe mean distance with the identity mapping is 3.09, CG obtains 2.67, and our method 1.18. The histograms of the distances are shown in the anonymous url:\nhttps://imgur.com/xP3MVmq\n\nWe see a great potential in further applying our method in biology with applications ranging from interspecies biological network alignment [2] to drug discovery [3], i.e. aligning expression signatures of molecules to that of diseases.\n  \n[1] Zheng et al, \u201cMassively parallel digital transcriptional profiling of single cells\u201d. Nature Communications, 2017.\n\n[2] Singh, Rohit, Jinbo Xu, and Bonnie Berger. \"Global alignment of multiple protein interaction networks with application to functional orthology detection.\" Proceedings of the National Academy of Sciences 105.35 (2008): 12763-12768.\n\n[3] Gottlieb, et al. \"PREDICT: a method for inferring novel drug indications with application to personalized medicine.\" Molecular systems biology 7.1 (2011): 496.\n", "title": "A real-world application of our method in cell biology"}, "Hyj4tk1GM": {"type": "rebuttal", "replyto": "SkHatuolz", "comment": "We thank you for highlighting the novelty and successful motivation of the exemplar-based matching loss. \n\nWe think that the exact-analogy problem is very important.  Please refer to our comment to AnonReviewer2 for an extensive discussion. \n\nFollowing your request, we have added AN-GAN supervised experiments for the edges2shoes and edges2handbags datasets. The results as for the Facades case are very good.\n\nThank you for highlighting the inconsistency in L_1 notation and the confusing reference. This has been fixed in the revised version.\n", "title": "Response"}, "Sk0k9JkfG": {"type": "rebuttal", "replyto": "HJ08-bCef", "comment": "Thank you for your positive feedback on the theoretical and experimental merits of this paper.\n\nFollowing your feedback on the clarity of presentation of the method. we included a diagram (including example images) illustrating the algorithm. To help keep the length under control, we shortened the introduction and related work section as you suggested.\n\nWe further clarified the text of the experiments. Specifically the numbers in Tab 2 are the top-1 accuracy for both directions (A to B and B to A) when 0%, 10% and 25% of examples do not have matches in the other domain. If some details remain unclear, we would be glad to clarify them.\n\nWe hope that your positive opinion of the content of the paper with the improvement in clarity of presentation will merit an acceptance.\n", "title": "Response"}, "rklEiy1Mz": {"type": "rebuttal", "replyto": "ryhcYB-bG", "comment": "We thank the reviewer for the extensive style and reference comments. They have been fixed in the revised version:\n1. A definition of \u201canalogy\u201d for the present context added to intro.\n2. Putin example removed for need of space.\n3. \u201cWeakly Supervised Mapping\u201d previous work section removed and references merged for need of space.\n4. Optimization variables have been explicitly added to equations.\n5. Maps dataset citation was changed to Isola et al. 2017\n6. Removed confusing comment: \u201cThis shows that the distribution matching is able to map source images that are semantically similar in the target domain.\u201d\n7. \u201cThis shows that a good initialization is important for this task.\u201d: one way of looking at it, is that the exemplar loss optimizes the matching problem that we care about but is a hard optimization task. The two other losses are auxiliary losses that help optimization converge. Clarification added in text.\n8. The results shown for inexact matching are as follows: For alpha iterations and ANGAN we show the matches recovered by our methods, The DiscoGAN results are the outputs of the translation function.\n9. Parentheses added to all citations.\n\nWe hope that this has convinced the reviewer of the importance of this work and are keen to answer any further questions.\n", "title": "Response to the rest of the comments"}, "Byqw2JyGf": {"type": "rebuttal", "replyto": "ryhcYB-bG", "comment": "Thank you for the detailed and constructive review. It highlighted motivation and experimental protocols that were further clarified in the revised version.\n\nThis paper is focused on exact analogy identification. A core question in the reviews was the motivation for the scenario of exact matching, and we were challenged by the reviewer to find real world applications for it. \n\nWe believe that finding exact matches is an important problem and occurs in multiple real-world problems. Exact or near-exact matching occurs in: \n* 3D point cloud matching.\n* Matching between different cameras panning the same scene in different trajectories (hard if they are in different modalities such as RGB and IR).\n* Matching between the audio samples of two speakers uttering the same set of sentences.\n* Two repeats of the same scripted activity (recipe, physics experiment, theatrical show)\n* Two descriptions of the same news event in different styles (at the sentence level or at the story level).\n* Matching parallel dictionary definitions and visual collections.\n* Learning to play one racket sport after knowing to play another, building on the existing set of acquired movements and skills.\n\nIn all these cases, there are exact or near exact analogies that could play a major rule in forming unsupervised links between the domains.\n \nWe note that on a technical level, most numerical benchmarks in cross domain translation are already built using exact matches, and many of the unsupervised techniques could be already employing this information, even if implicitly. We show that our method is more effective at it than other methods.\n\nOn a more theoretical level, cognitive theories of analogy-based reasoning mostly discuss exact analogies from memory (see, e.g., G. Fauconnier, and M. Turner, \u201cThe way we think\u201d, 2002 ). For example, a new situation is dealt with by retrieving and adopting a motor action that was performed before. Here, the chances of finding such analogies are high since the source domain is heavily populated due to life experiences. \n\nRegarding experiments. We believe that in some cases the requests are conflicting: we cannot provide numerical results in places for which there are no analogies and no metrics for success. We provide a large body of experiments for exact matches and show that our method far surpasses everything else. We have compared with multiple baselines covering all the reasonable successful approaches for matching between domains. \n\nThe experiments regarding cases without exact matches are, admittedly, less extensive, added for completeness, and not the focus of this paper.\n\nThe reviewer wondered if matching will likely work better with simpler methods. Our baselines test precisely this possibility and show that the simpler methods do not perform well. Specifically edge-based matches are well covered by the more general VGG feature baseline (which uses also low level maps - not just fc7). AN-GAN has easily outperformed this method. If it is possible to hand-craft a successful method for each task individually, these hand-crafted features are unlikely to generalize as well as the multi-scale VGG features or AN-GAN.\n\nWe put further clarification in the paper for the motivation for the second \u201csupervised\u201d step. In unsupervised semantic matching, larger neural architecture have been theoretically and practically shown to be less successful (due to overfitting and finding it less easy to recover the correct transformation). The distribution matching loss function (e.g. CycleGAN) is adversarial and is therefore less stable and might not optimize the quantity we care about (e.g. L1/L2 loss). Once the datasets are aligned and analogies are identified, however, the cross domain translation becomes a standard supervised deep learning problem where large architectures do well and standard loss functions can be used. This is the reason for the two steps. It might be possible to include the increase in architecture into the alpha-iterations but it\u2019s non-trivial and we didn\u2019t find it necessary.\n", "title": "Response to the motivation and experimental comments"}}}