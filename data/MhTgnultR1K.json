{"paper": {"title": "A Real-time Contribution Measurement Method for Participants in Federated Learning", "authors": ["Bingjie Yan", "Yize Zhou", "Boyi Liu", "Jun Wang", "Yuhan Zhang", "Li Liu", "Xiaolan Nie", "Zhiwei Fan", "Zhixuan Liang"], "authorids": ["~Bingjie_Yan1", "yizezhou20001203@163.com", "by.liu@ieee.org", "20180581310080@hainanu.edu.cn", "zhangyh01230@163.com", "hainan_lily2001@163.com", "niexiaolan25@163.com", "hnufzw@gmail.com", "~Zhixuan_Liang1"], "summary": "", "abstract": "Federated learning is a framework for protecting distributed data privacy and has participated in commercial activities. However, there is a lack of a sufficiently reasonable contribution measurement mechanism to distribute the reward for each agent. In the commercial union, if there is no mechanism like this, every agent will get the same reward. This is unfair to agents that provide better data, so such a mechanism is needed. To address this issue, this work proposes a real-time contribution measurement method. Firstly, the method defines the impact of each agent. Furthermore, we comprehensively consider the current round and the previous round to obtain the contribution rate of each agent. To verify effectiveness of the proposed method, the work conducts pseudo-distributed training and an experiment on the Penn Treebank dataset. Comparing the Shapley Value in game theory, the comparative experiment result shows that the proposed method is more sensitive to both data quantity and data quality under the premise of maintaining real-time.", "keywords": ["Federated Learning", "Contribution Evaluation", "Multi-party Participation"]}, "meta": {"decision": "Reject", "comment": "Although this paper tackles an important problem, all reviewers agree that it requires further work before it can be published. First, the paper would need to be polished in order to be easier to read. Stronger experiments would also be needed in order to support the claims of the paper, e.g. by considering additional datasets and proper baselines. Finally, an important concern about this paper is novelty and originality. It is not clear at this point that the contribution is substantial enough for a conference like ICLR. Addressing these points would significantly improve the paper."}, "review": {"LdxLRhnQAT": {"type": "rebuttal", "replyto": "w8_7d-o5qH", "comment": "Dear reviewer:\n\nFirstly, thank you for your review on our paper, we will accept it with an open mind and continue to improve the paper. We will strengthen the theoretical proof of the paper and provide more experimental data. The polishing of the paper is also one of the tasks we need to carry out, and the revision of the chart annotations. We will continue to enrich the experimental part of the problems on the experimental data set and refer to more recent research work. Thank you for your suggestions for our paper.\n", "title": "Reviewer 4 Response"}, "9cWjcy_OapH": {"type": "rebuttal", "replyto": "3NFR5hFguhG", "comment": "Dear reviewer:\n\nThanks for your comments on our paper. We will improve the judgment and constraints of attackers, and strengthen the research on the system. At the same time, we will also select more datasets and baseline methods to enrich our experiments. Thanks again for your suggestions and review. We will continue to study related work.", "title": "Reviewer 3 Response"}, "0bzyBCYvgap": {"type": "rebuttal", "replyto": "_x8-Dx8deQk", "comment": "Dear reviewer:\n\nThank you for your review on our paper, and thank you for your affirmation of the direction of our paper. We will choose more general algorithms for experimental verification, such as FedAVG and FedSGD. We will conduct theoretical proofs of our experiments based on game theory to enrich our theoretical part. For the problem of insufficient datasets, we will also verify with more datasets. In the meanwhile, we will continue to revise the issues of the paper to meet the requirements. Thank you again for your suggestions and affirmation of our work direction.\n", "title": "Reviewer 1 Response"}, "2h4iP9Z4Lu5": {"type": "rebuttal", "replyto": "80mIhJhBkT-", "comment": "Dear reviewer:\n\nThank you for your review on our paper, we will accept it with an open mind and continue to improve the paper. In response to the dataset in the experiment, we will also verify it on more comprehensive dataset. Simultaneously, we will polish the sentence of the paper to make it easier to read. For the contribution measurement method proposed in this article, we will also follow strengthen the theoretical support. Based on our measurement method, we will compare it with the more accurate Shapley Value, which will be reflected in the subsequent submissions. Thanks again for your suggestions and review. We will continue to study related work.", "title": "Reviewer 2 Response"}, "3NFR5hFguhG": {"type": "review", "replyto": "MhTgnultR1K", "review": "The paper is to measure each client\u2019s contribution to training the federated learning model. In particular, the contribution is measured by the distance between the local model and the global model in each iteration. The targeting problem is interesting, and the use of attention-based model divergence is also an interesting idea to measure the contribution. However, the paper lacks strict theoretical discussion to prove the proposed solution is a reasonable one rather than a heuristic method. Moreover, the experiment is too weak to support the claims. The paper\u2019s technique contribution and originality are also limited. \n\nBelow are some detailed concerns.\n\n1) The authors need to make a clear definition of the assumed application scenario so that the below problems can be avoided or solved. \n\nIf the client\u2019s contribution is linked to rewards, it is unavoidable that some clients will produce fake data to gain more contribution to the commercial federation system. Therefore, the paper should discuss the prevention of \u201cattacking by fake data\u201d. \n\nFor example, if the client randomly shuffles the index of neurons in the trained local model w_k, then the client\u2019s local model will get a bigger s_k^l calculated by equation 2. Thus, this client is likely to gain a big reward at every iteration.\n\nAccording to equation 5, the contribution at the early stage will be discounted. It is unfair for the clients to be selected at an early stage. Therefore, from a systematic perspective, some clients may refuse to contribute to the training process at an early stage. \n\n\n2) Contribution is not enough\n\nThe core method comes from the FedAtt algorithm \u2013 an attention-based federated aggregation method. The paper\u2019s primary contribution relies on section 3.3 to measure the contribution according to the gradients.  \n\n\n3) The experiments are too weak to support their claim. \n\nMore datasets and baseline methods are required, for example, the FEMNIST, FeCeleba.\n\nIt is unclear how to define an objective metric to measure the quality of the proposed method. The contribution is a subjective feeling that various to different tasks and assessor.", "title": "The paper needs more thoughtful thinking. ", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "w8_7d-o5qH": {"type": "review", "replyto": "MhTgnultR1K", "review": "The paper proposes a low computational complexity method for weighting contributions of clients in a federated learning setting. The main contributions are to compare the weighting method with Shapley values and their sensitivity to low data volume and quality. The paper is based on the FedAtt paper that calculates weights based on the Euclidean distance between the server model and each client and for each layer.\n\nThe experimental setup is well described, including details about the hardware, software, datasets, model, and evaluation criteria. However, the model only specifies a \"smaller GRU-based model\" without giving any details of what that model is. They do not clearly describe some parameters of the approximation of the Shapley value calculation, reducing the value of the comparison between FedAtt and Shapley values. They could also have taken additional steps to improve the claims' confidence, e.g., only one dataset was used, which is relatively weak compared to the original FedAtt paper. The graphs in the results section could be described with more detail to explain what, e.g., the colors of the \"special agents\" mean. Also, there are no confidence measures specified, making it hard to evaluate the claims' validity.\n\nThe references include essential papers but are missing some core references, such as Federated Learning and Shapley values themselves. Also, related papers such as \"Active Federated Learning\" by Goetz et al. talk about very similar ideas but lack any mention in the paper.  The language and grammar could be improved, and some of the formulations make it hard to read. The comparison to Shapley values is also not motived in any detail, thus further reducing the paper contributions' value.", "title": "Low computational complexity calculation of weights for federated learning clients  ", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "_x8-Dx8deQk": {"type": "review", "replyto": "MhTgnultR1K", "review": "Summary:\n\nThe paper proposes a new contribution measurement approach for federated learning. The basic idea is that the agent with a larger model update has a larger contribution. Specifically, based on FedAtt [1], the impact of a client is computed as the local updates plus the impact of the previous round times a decay rate. The experiments on a dataset show that the proposed approach can have a similar contribution measurement compared with Shapley Value.\n\n[1] Learning private neural language modeling with attentive aggregation.    IJCNN 2019\n \nStrengths: \n\n(1) The motivation of the paper is clear.\n\n(2) The studied area is important. Effective incentive mechanisms in federated learning are still an open challenge.\n\nWeakness:\n\n(1) The proposed idea lacks novelty and may not be applicable in general federated learning algorithms. The contribution of each client is simply evaluated by its local update in FedAtt. FedAtt is not a widely used federated learning algorithm currently. It is not clear whether the proposed approach is applicable to other standard federated learning algorithms such as FedAvg. Also, I do not understand why the paper focuses on FedAtt instead of FedAvg.\n\n(2) The paper lacks reasonable explanations for the proposed approach. A client may have arbitrary bad data and the local updated model may be far from the global optimal model. In such a case, since the distance between the local model and the global model is large, the contribution is also large according to the proposed approach, which is not reasonable. It is not clear how the proposed approach can handle such cases.\n\n(3) The experiments are weak and not clear. \n\n  a) It is not explained how the agent contribution rate is computed. \n\n  b) The experiments are conducted on a single dataset. More datasets are needed. \n\n  c) From Figure 2, it is hard to say that the proposed approach has a similar measurement with SV. \n\n  d) Since the motivation is to reduce the computation overhead, the authors should show compare the computation complexity or the computation time of the proposed approach and SV.\n\nMinor issues:\n\n(1) The writing can be improved, e.g., \u201cSuch\u201d -> \u201cFor example,\u201d\n\n(2) Figure 1 is not referred to in the text.\n\n(3) Figure2-5: orange and blue colors are not explained.\n", "title": "The idea lacks novelty and the experiments are not convincing", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "80mIhJhBkT-": {"type": "review", "replyto": "MhTgnultR1K", "review": "This paper designs an equation, i.e., equation (5) in the paper, to measure the impact or contribution of each participant/agent in federated learning. The designed measurement method is applied to attention aggregation algorithm of federated learning. Few experiments using Penn Treebank are conducted to support its claims.\n\nThis paper should be rejected because (1) the paper is unpolished and thus is hard to read, (2) the novelty appears quite weak, and (3) the experiments are difficult to understand and generally do not support its contributions\n\nConcerns:\n\nThe paper is difficult to read due to the poor use of English. Many sentences are incomprehensible. Thus, it was often impossible for me to determine exactly what the authors would like to say or describe. Please have your submission proof-read for English writing style and grammar issues. Moreover, please treat the equations as the parts of sentences and make sure that the caption formats of Figures obey the ICLR format.\n\nI also have a serious concern about the novelty of this paper. If my understanding is correct (due to the aforementioned reason), Subsection 3.3 is the only new material proposed by the authors. However, the proposed equation, i.e., equation (5), seems like a design choice without any theoretical justification or providing any intuitive reason, which significantly degrades the novelty of this paper.\n\nFinally, the experiments should be refined to support its main claims. As claimed in Section 1, the proposed measurement method is real-time and has low computational complexity. However, no experiment nor quantitative comparison addressing the running time and complexity between the proposed method and Shapley Value. Actually, the authors compared their method with the method of approximating Shapley Value instead of exact Shapley Value. Furthermore, please cite for Shapley Value papers.\n", "title": "A REAL-TIME CONTRIBUTION MEASUREMENT METHOD FOR PARTICIPANTS IN FEDERATED LEARNING", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}}