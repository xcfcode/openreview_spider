{"paper": {"title": "CNNSAT: Fast, Accurate Boolean Satisfiability using Convolutional Neural Networks", "authors": ["Yu Wang", "Fengjuan Gao", "Amin Alipour", "Linzhang Wang", "Xuandong Li", "Zhendong Su"], "authorids": ["yuwang@seg.nju.edu.cn", "fjgao@seg.nju.edu.cn", "alipour@cs.uh.edu", "lzwang@nju.edu.cn", "lxd@nju.edu.cn", "zhendong.su@inf.ethz.ch"], "summary": "We introduce CNNSAT, a fast and accurate statistical decision procedure for SAT based on convolutional neural networks.", "abstract": "Boolean satisfiability (SAT) is one of the most well-known NP-complete\nproblems and has been extensively studied.  State-of-the-art solvers\nexist and have found a wide range of applications. However, they still\ndo not scale well to formulas with hundreds of variables. To tackle\nthis fundamental scalability challenge, we introduce CNNSAT, a fast\nand accurate statistical decision procedure for SAT based on\nconvolutional neural networks. CNNSAT's effectiveness is due to a\nprecise and compact representation of Boolean\nformulas. On both real and synthetic formulas, CNNSAT is highly\n  accurate and orders of magnitude faster than the\nstate-of-the-art solver Z3.  We also describe how to extend CNNSAT to\npredict satisfying assignments when it predicts a formula to be\nsatisfiable.", "keywords": ["Convolutional Neural Networks", "Boolean satisfiability problem", "Satisfiability modulo theories"]}, "meta": {"decision": "Reject", "comment": "The authors provide a convolutional neural network for predicting the satisfiability of SAT instances. The idea is interesting, and the main novelty in the paper is the use of convolutions in the architecture and a procedure to predict a witness when the formula is satisfiable. However, there are concerns about the suitability of convolutions for this problem because of the permutation invariance of SAT. Empirically, the resulting models are accurate (correctly predicting sat/unsat 90-99% of the time) while taking less time than some existing solvers. However, as pointed out by the reviewers, the empirical results are not sufficient to demonstrate the effectiveness of the approach. I want to thank the authors for the great work they did to address the concerns of the reviewers. The paper significantly improved over the reviewing period, and while it is not yet ready for publication, I want to encourage the authors to keep pushing the idea to further and improve the experimental results.\n"}, "review": {"BkgBcAO_JV": {"type": "rebuttal", "replyto": "ryxwUYbD1N", "comment": "Thank you for this follow-up question.\n\n> Are these numbers (e.g., 128 (SAT) + 112 (UNKNOWN) for the 2016\n> instances) the results of a single run of your method, with a time\n> budget less than 5000s?\n\nNo.\n\n> Or what are they?\n\nThese are results from running Dimetheus and YaleSAT.\t\n\n> If they are not the result of running your method, what would be the\n> result of running your method? It's perfectly fine that there are no\n> UNSAT instances; it is known that the instances in this track are\n> satisfiable, but the problem is to actually find a satisfying\n> assignment. So, for many of these instances does your method find a\n> satisfying assignment?\n\nWe wish to clarify that CNNSAT's focus is on predicting SAT/UNSAT, not\nsolving.  As we commented on another thread, CNNSAT does not replace,\nbut complements modern solvers to quickly and accurately predict\nsatisfiability.  One interesting example application of CNNSAT is for\nsymbolic execution --- if a (complex) path constraint is quickly\npredicted to be UNSAT, no expensive solver call is necessary, and the\ncorresponding path does not need to be explored.\n\nWe did not evaluate our solving extension on these instances. If the\nreviewer believes that this is important, we are happy to conduct this\nexperiment and report back the results, even though the experiment\nwould take some time.", "title": "Re \"clarification question\""}, "Syedaq__yN": {"type": "rebuttal", "replyto": "H1g73lQD14", "comment": "Thank you.  We will make the small fixes that you mentioned.\n\n> The critical issue for me is whether the paper really demonstrates\n> improvements over the state of the art in SAT solving. I am not yet\n> convinced the authors really demonstrate that their approach\n> outperforms modern SAT solvers (and their author response confirmed\n> that this is supposed to be the paper's key message).\n> ...\n\nOur wording may be unclear, which we will state more accurately: (1)\nCNNSAT's focus is on predicting SAT/UNSAT, not solving, and (2) it\nachieves very accurate and fast SAT/UNSAT prediction.\n\nCNNSAT does not replace, but complements modern solvers to quickly and\naccurately predict satisfiability.  One interesting example\napplication of CNNSAT is for symbolic execution --- if a (complex)\npath constraint is quickly predicted to be UNSAT, no expensive solver\ncall is necessary, and the corresponding path does not need to be\nexplored.\n\nWe will paraphrase as follows to avoid misinterpretation: \"On both\nreal and synthetic formulas, CNNSAT is highly accurate and efficient\nin predicting satisfiability.\"\n\n> Incidentally, I also don't believe that the paper would have to\n> demonstrate improvements over the state-of-the-art in SAT solving if\n> the methods are interesting enough. Unfortunately, when trying to\n> summarize to myself what the paper's novel methodological\n> contribution is, I mainly could think of the use of convolutions,\n> which I continue to find troublesome in this context.\n\nWe wish to note that the novel methodological contributions include\n(1) the use of convolutions and a novel compact representation to\nscale to formulas with large numbers of variables, and (2) a SAT\nsolving algorithm based on satisfiability prediction to speed up\nconstraint solving.\n\n> Due to exchangeability, there should be no local structure that can\n> exploited. Also, I don't see any experiments where the authors study\n> scalability of this approach (e.g., fraction of errors as a function\n> of instance size).\n\nPlease note that our experiments show that CNNSAT can deal with large\ninstances with excellent performance. Its time is rather invariant\nacross different formula sizes. Below is some more information on the\n\"Long Range\" dataset to demonstrate this:\n\n(1) #var between 100 and 150:\n- total formulas: 522\n- prediction time: 53.0s (0.102s per formula)\n- accuracy: 99.23%\n\n(2) #var between 150 and 200:\n- total formulas: 503\n- prediction time: 52.4s ((0.104s per formula)\n- accuracy: 99.20%\n\n(3) #var between 200 and 250:\n- total formulas: 518\n- prediction time: 53.6s (0.104s per formula)\n- accuracy: 99.80%\n\n(4) #var between 250 and 300:\n- total formulas: 505\n- prediction time: 52.8s (0.105s per formula)\n- accuracy: 99.20%\n\n(5) #var between 300 and 350:\n- total formulas: 518\n- prediction time: 54.3s (0.105s per formula)\n- accuracy: 95.17%\n\n(6) #var between 350 and 400:\n- total formulas: 519\n- prediction time: 55.0s (0.106s per formula)\n- accuracy: 99.81%\n\n> Finally, here is a conceptual question: if we always split instances\n> into 10000 submatrices (100x100), and for each of these submatrices\n> record the number of positive and negative literals, then couldn't\n> an instance that has 1000 times more variables but the same number\n> of literals end up with the same representation? That seems very\n> suboptimal.\n\nPlease note that such two instances would have very different initial\nrepresentations because of their drastically different sizes, C1xV1\nvs.  C2xV2 (where C1, C2 the numbers of clauses, and V1, V2 the\nnumbers of variables in the two instances): C1 = C2, but V1 <<\nV2. Thus, CNNSAT works well with similarly sized instances.\n\nCNNSAT's compressed representation can indeed lead to collisions.  As\nwe commented earlier and also shown empirically, using 100x100\nsubmatrices balances well accuracy and scalability. The\nexchangeability evaluation (whose purpose is to demonstrate that\nCNNSAT can identify semantically equivalent formulas) also shows a\nsmall (i.e., 0.35%) difference in prediction results.\n\nWe sincerely hope that these help clarify your questions and improve\nyour evaluation of the work. If you have further questions, we are\nhappy to answer them promptly.", "title": "Re \"update\""}, "HkgK8jD53X": {"type": "review", "replyto": "ryxhynC9KX", "review": "The authors present CNNSAT, a CNN-based approach to predict the satisfiability of SAT instances.\nThe problem is very relevant, and the approach is interesting, but unfortunately, the presentation is very misleading (see details below). In terms of methods, the main innovation appears to be the use of CNNs for predicting the solubility of SAT instances, but because of the exchangeability I don't actually see the intuition for this (see details below). Overall, because of these issues, I do not think this paper is ready for publication.\n\nMisleading parts:\n=================\n\n1. Already in the abstract the authors make an utterly wrong statement about SAT solvers: \n\"State-of-the-art solvers exist and have found a wide range of applications.  However, they still do not scale well to formulas with hundreds of variables.\"\nThe same sentiment is repeated in the introduction; I'm puzzled why the authors would believe this. SAT solvers nowadays are routinely used on instances with hundreds of thousands of variables and millions of clauses (just see any of the recent SAT competitions (https://satcompetition.org/) for examples).\n\n2. Z3 is *not* a good solver for random instances, far from state-of-the-art. It is not the right baseline.\n\n3. The authors' approach implicitly makes use of PicoSAT, so their experiments are really implicitly comparing PicoSAT vs. Z3.\n\n4. Comparing the prediction time of CNNSAT with the solving time of Z3 does not make much sense to me, since it does not solve every instance.  \n\n5. No comparison of CNNSAT (internally using PicoSAT) vs. PicoSAT is given.\n\n6. The paper did *not* demonstrate that CNNSAT is competitive in practice. It is only faster than Z3 on random instances, which are not of practical interest. Demonstrating practical usefulness would require competitive performance on the SAT competition instances. By the way, CNNSAT would be disqualified in any SAT competition for falsely returning UNSAT for some satisfiable instances. Algorithm 1 should instead return UNKNOWN when it cannot find a solution.\n\n7. Taken out of context, the predictive quality the authors achieve looks great: between 96% and 99% for random 3-SAT instances. However, this is misleading since the instances are not sampled at the phase transition and may thus be very easy to classify. Usually, for uniform random 3-SAT, the phase transition happens when the number of clauses for a number of variables v exceeds c = 4.258 * v +58.26 * v^{\u22122/3} (see [1]), although I do not remember whether this is for clauses being generated with and without replacement. (I looked into the documentation of CNFGEN, and for random k-cnf, it samples clauses without replacement.) It would be very useful to see the classification accuracy of classifying every formula with >= the number of clauses c from that formula as unsatisfiable and every formula with < that many clauses as satisfiable. Could the authors please report this number during the author response period?\n\nThe authors are also missing an additional related paper: [2] used simple models to obtain better-than-chance predictions at the phase transition.\n\n\n\nExchangeability and the use of CNNs:\n====================================\nDue to the exchangeability property, we do *not* care about spatial correlation in the adjacency matrix. I am really missing the details on how to achieve the fixed-size 100x100 matrices. This approach sounds like it would lose a lot of information!\n\nI do not find the experiment studying exchangeability to be convincing. The experiment I would like to see is shuffling all variables, and/or negating half the variables, rather than swapping a single pair of variables. Even then, the experiment should optimally measure differences in individual predictions rather than differences in aggregate performance statistics.\n\n\nOne more question:\n- How was N chosen? I only saw the statement \"We choose to determine N dynamically based on the dataset.\"\n\n[1] Crawford and Auton: Experimental results on the crossover point in random 3SAT. In Artificial Intelligence Journal, 1996.\n[2] Xu, Hoos, and Leyton-Brown: Predicting Satisfiability at the Phase Transition. In AAAI 2012.", "title": "Interesting problem & method, but misleading presentation", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "r1gq0XWDyN": {"type": "rebuttal", "replyto": "HkxdYvRiAm", "comment": "\n--------\n\n\n(4)\n\n> For analyzing the performance of CNNSAT at the phase transition, I would recommend to\n> explicitly follow the protocol of Xu et al. 2012. Notably,\n> * Use the generator: https://www.satcompetition.org/2003/TOOLBOX/genAlea.c\n> * Use the solver kcnfs07 with a budget of 36,000s for labeling the instances.\n\nWe tried to regenerate formulas following the protocol of Xu et\nal. 2012. However, it takes a very long time to solve uniform 3-SAT\nproblems with large numbers of variables. For example, it takes 48\nhours with 28 solving instances to solve only 159 formulas with around\n350 variables.  To make this experiment feasible, we follow Xu et\nal.'s protocol with 300-400 variables. We used genAlea and kcnfs07 to\nconstruct a dataset with 1292 SAT and 1292 UNSAT instances. We use 75%\nfor training and 25% for testing (both training and testing have an\nSAT:UNSAT ratio 1:1).  CNNSAT's overall accuracy is 61% (97.83% for\nUNSAT, and 24.17% for SAT). There are 646 formulas used for testing,\nand CNNSAT's prediction time is 28.8 seconds.  In comparison, it takes\nCaDiCaL 8 hours to solve only 76 formulas.  We could not find Xu et\nal.'s code and experimental data for a more direct evaluation.\n\n\n--------\n\n\nIn summary, our additional experiments show that CNNSAT not only can\nclassify random 3-SAT instances, but also classify other types of SAT\n(e.g., those problems converted from SMT benchmarks or from the Agile\nbenchmarks).  CNNSAT can learn and classify SAT/UNSAT instances with\nhigh accuracy without the need to inspect patterns in specific types\nof problems.\n\nThank you again for your time and consideration. We will include these\nresults in our revision if space permits or in an extended version\nthat will be shared on arXiv.", "title": "Part 2: Additional Experiments and Results "}, "Skx7_7WvkV": {"type": "rebuttal", "replyto": "HkxdYvRiAm", "comment": "We apologize first for the delayed update because the additional\nexperiments took significant amount of time. They are completed now,\nand below summarizes the main results.\n\nNote: All solvers were configured with 5000s budget in these experiments.\n\n\n--------\n\n\n(1) CNNSAT vs. state-of-the-art solvers on SAT competitions' random track instances\n\nWe tried to perform the following experiment:\n- train CNNSAT on instances from the random track in 2016\n- test it on the instances from the random track in 2017\n- use 5000s for the timeout budget for each instance\n- compare CNNSAT with Dimetheus and YalSAT, the two best performing solvers for the random track\n\nDimetheus was the winner for RandomSAT 2016 (with 5000s budget):\n- time: 41h53m with 5 threads\n\nYaleSAT was the winner for RandomSAT 2017 (with 5000s timeout):\n- time: 49h7m with 5 threads\n\nFrom our results from running Dimetheus and YaleSAT, and information\non the SAT competition results, we did not find any UNSAT instances:\n- RandomSAT 2016: 128 (SAT) + 112 (UNKNOWN) = 240 (total)\n- RandomSAT 2017: 211 (SAT) + 89 (UNKNOWN) = 300 (total)\n- RandomSAT 2018: 243 (SAT) + 12 (UNKNOWN) = 255 (total)\nwhere we also attempted the RandomSAT 2018 instances.\n\nThus, these are not good datasets for comparing CNNSAT and the other\nsolvers because CNNSAT would have 100% accuracy (since there are not\nany UNSAT instances).\n\n\n--------\n\n\n(2) Use the \"Long Range\" dataset with 5000s budget, and compare with Dimetheus and YalSAT\n\nAfter more than 86 hours, Dimetheus and YalSAT only solved 155 and 147\ninstances, respectively.  Please note that there are 16000 formulas in\nthis dataset.  Even when using 10min budget (as we did and reported\nearlier), the two solvers did not perform nearly as well as MiniSAT\nand PicoSAT.\n\n\n--------\n\n\n(3) Experiment on the Agile benchmarks from the SAT competitions\n\nCaDiCaL and Riss: CaDiCaL Agile took 35h5m to solve the formulas in\nAgile 2017 with 5000s budget, 64G memory, and 10 solving instances. It\nwould take much more time to solve the formulas one by one. CaDiCal\ntook 75h to solve 913 formulas (out of the 5000 formulas in each of\nAgile 2016 and 2017).  It took the Riss solver more than 48h to solve\nthe formulas in Agile 2016 with 5 solving instances.\n\nCNNSAT trained and tested on Agile 2016:\n- Accuracy: 99.20% overall (99.7% over UNSAT instances, 98.2% over SAT instances)\n- Prediction time: 522.72 seconds\n\nCNNSAT trained on Agile 2016 and tested on Agile 2017:\n*** [Case 1] without matched formula size (i.e., training on Agile 2016 and testing on all Agile 2017)\n- Accuracy: 84.9% overall (96.8% for UNSAT, 70.0% for SAT)\n- Prediction time: 17574 seconds\n\n*** [Case 2] with matched formula size (i.e., training on Agile 2016\nand testing on those Agile 2017 formulas with no more than the maximum\nnumber of variables for Agile 2016 formulas)\n- Accuracy: 99.1% overall (99.3% for UNSAT, 98.8% for SAT)\n- Prediction time: 1236 seconds\n\nStatistics on the Agile benchmarks:\n- Agile 2016: total 5000 formulas with 2207 SAT, 2777 UNSAT, and 16 timeout\n- Agile 2017: total 5000 formulas with 2187 SAT, 2744 UNSAT, and 69 timeout\n- Overlapping formulas in Agile 2016 and 2017: We found 3095 formulas\n  in Agile 2017 are the same as in Agile 2016.  Further inspecting the\n  datasets, we found that there were 19 new formulas in Agile 2017\n  with fewer than the maximum number of variables in Agile 2016.  If\n  we test on these 19 formulas, CNNSAT's overall accuracy is 94.7%\n  (100% for UNSAT, 94.4% for SAT).", "title": "Part 1: Additional Experiments and Results "}, "BkxNCJMLJN": {"type": "rebuttal", "replyto": "HyxNIq0VyE", "comment": "Thank you for this follow-up question.\n\n> The authors instead responded with a comparison to classification\n> percentages from Xu et al. Are these exactly the same instances used\n> by Xu et al?\n\nThese are not.  We could not find online the code or experimental data\nused by Xu et al.\n\n> If not then I do not think that the percentages are\n> comparable. Could the authors please answer my original question?\n\n(1) We did the calculation for the \"Long Range\" data set. Among the 1610\ntesting instances, we have\n- 782 above phase transition point with\t766 UNSAT and 16 SAT\n- 828 below the phase transition point with 787 SAT and 41 UNSAT\n\nThe accuracy would have been (766+787)/1610 = 96.46%. Thus, the\tsimple\nclassification performs very well on this dataset that mostly follows\nthe phase transition.\n\n(2) On the Agile benchmarks from SAT competition 2016, all instances\nare below the phase transition point (with maximum c/v ratio 4.07).\nAs commented under \"#6\", \"CNNSAT solved all of them in 287 seconds\nwith 97.5% accuracy --- the accuracy for UNSAT is 97.6%, while the\naccuracy for SAT is 97.1%.\"  Using the phase transition for\nclassification, the accuracy would have been 50% as there are the same\nnumber of SAT and UNSAT instances for testing.", "title": "Re: Quick question"}, "rJlK9vC-14": {"type": "rebuttal", "replyto": "rJxd44Xt27", "comment": "\n> [Second Update] I still find the method proposed in this paper appealing, and think that it may have practical \n> applications in addition to providing significant research contributions. A key question that was raised by the other \n> two reviewers was whether the proposed approach was fairly evaluated against existing state-of-the-art solvers. The \n> authors have responded to these concerns by adding clarifications and new baselines to their paper. However, based \n> on the discussions to date, I feel that I am not sufficiently familiar with related work on SAT solvers to say whether the \n> other reviewers' concerns have been fully addressed. If they have been, I'd strongly lean towards accepting the paper. \n\nThank you.   If possible, it would be very helpful to hear from the other two reviewers. \n\nWe are also running the additional experiments that we promised in our latest response to AnonReviewer2.  These experiments are taking time, and we hope to have the results ready by tomorrow and then share with the reviewers immediately.  \n\n> As for the concerns from my original review: the transferability experiments reported in the author comments below \n> are quite informative, and I'd encourage the authors to incorporate them into the paper (or an appendix if space is an \n> issue). \n\nThank you; we will. \n\n> I'd also encourage the author to incorporate the full comparisons against Z3, PicoSAT, MiniSAT, Glucose, \n> Dimetheus, and CaDiCaL from Section 5.1. \n\nYes, we will. \n\n> (I've updated my rating for the paper from 5 to 6, and my confidence score from 3 to 2.)\n\nThank you for your time and consideration. ", "title": "Re \"Second Update\" "}, "rJxd44Xt27": {"type": "review", "replyto": "ryxhynC9KX", "review": "[Second Update] I still find the method proposed in this paper appealing, and think that it may have practical applications in addition to providing significant research contributions. A key question that was raised by the other two reviewers was whether the proposed approach was fairly evaluated against existing state-of-the-art solvers. The authors have responded to these concerns by adding clarifications and new baselines to their paper. However, based on the discussions to date, I feel that I am not sufficiently familiar with related work on SAT solvers to say whether the other reviewers' concerns have been fully addressed. If they have been, I'd strongly lean towards accepting the paper. As for the concerns from my original review: the transferability experiments reported in the author comments below are quite informative, and I'd encourage the authors to incorporate them into the paper (or an appendix if space is an issue). I'd also encourage the author to incorporate the full comparisons against Z3, PicoSAT, MiniSAT, Glucose, Dimetheus, and CaDiCaL from Section 5.1. (I've updated my rating for the paper from 5 to 6, and my confidence score from 3 to 2.)\n\n[First Update] Based on the feedback of the other two reviewers, I believe that I was missing some important context about SAT solvers when I wrote my initial review. Reviewer 1 and Reviewer 2 both raised serious concerns about the types of SAT instances that were used to evaluate the experimental setup, as well as about the use of Z3 as a baseline for solving random SAT instances. (No author response was provided.) Given this additional information, I've lowered my score for the paper from an 8 to a 5. I do think that the approach is interesting, but have reservations about the experimental evaluation and the claims made by the current submission. (Note: As the paper authors point out in the comment below, this update was mistakenly submitted a few days before the end of the rebuttal period.)\n\n[Original Title] Interesting idea, impressive results for a first paper\n\n[Summary] The authors propose a method of using convolutional neural networks to determine whether large boolean formulas (containing hundreds of variables and thousands of clauses) are satisfiable. The resulting models are accurate (correctly distinguishing between satisfiable and unsatisfiable formulas more between 90% and 99% of the time, depending on the dataset) while taking 10x - 100x less time than an off-the-shelf solver (Z3), offering slightly better quality on some problems and slightly worse quality on others. In addition to determining whether formulas are satisfiable, the authors propose and evaluate a method for finding satisfying assignments. They also evaluate their system on SMT benchmarks, where it also shows 10x-100x speed-ups, albeit with somewhat lower accuracy (e.g., 73% - 92% accuracy; I couldn't find baselines for these experiments).\n\n[Key Comments] Unless I'm missing something major, I'd prefer to accept this paper, since the problem appears novel and the experimental results seem very promising for a first paper on a new problem.\n\n[Pro 1] The paper seems polished and well-written. I generally found it well-motivated and easy to follow.\n\n[Pro 2] To the best of my knowledge, the problem domain (machine learning for satisfiability problems that are so large that they are difficult to solve using conventional methods) is both novel and well-motivated.\n\n[Pro 3] Algorithms seem conceptually straightforward (but might be a bit challenging to implement in practice due to the large input size), and yield excellent results. The magnitude of speed-ups reported in the paper (10x - 100x) is large enough to be exciting from a research perspective, and also seems like it should be large enough to have significant practical applications.\n\n[Pro 4] Results are evaluated on a variety of different boolean satisfiability and SMT problems.\n\n[Con 1] To improve reproducibility, it would be helpful if the authors could provide more details about their model training setup. Figure 2 is a good start, but adding details about the layer sizes, types of pooling layers used, and the model training setup would help clarify the experiments.\n\n[Con 2] It seems like a significant number of labeled training examples (i.e., examples that are already known to be satisfiable or unsatisfiable) are needed in order to train a neural network. This seems like it could present a bootstrapping problem for certain domains: it may be computationally expensive to generate ground-truth labels for training examples, but a significant number of labels are needed to train a good prediction model. I'd be very interested to see a study of how well trained models transfer across domains: how well do models trained on one domain (e.g., a synthetic problem where labeled training data is cheap to generate) transfer to a different domain (e.g., a real-world problem where training labels are expensive to compute)? However, this is a minor point for a first paper on a new problem, and I think the paper is interesting enough to merit acceptance without such an analysis.\n", "title": "Interesting idea, problematic evaluation", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "Byg1KgFhAm": {"type": "rebuttal", "replyto": "HkxdYvRiAm", "comment": "> Yes, sure, I\u2019ve read all comments. \n\nThank you. \n\n> The key message of the paper is that CNNSAT is in position to outperform the state-of-the-art \n> solvers on random 3-SAT instances. Right?\n\nYes, that is accurate.   Again, we wish to contend that our experiments are already extensive and demonstrate CNNSAT's orders of magnitude performance gains over state-of-the-art solvers.  \n\nTo make the case even stronger and more convincing to the reviewer, we will sincerely follow the reviewer's suggestions to conduct further experiments and summarize our results. \n\n> So, in order to prove this assertion, and to really highlight the performance of CNNSAT:\n> ... \n> * Ideally, it would be nice to use scatter plots (or similar plots) for providing as much \n> information as possible about the results.\n\nThis is a good suggestion; thank you, and we will.  \n\n> For now, in the revised version of the paper, we essentially have experimental results on two\n> datasets. The datasets were generated from CNFGen (which is fine, I\u2019m not criticizing this \n> generator), but :\n> * All SAT problems that couldn\u2019t be solved by PicoSAT within a 10-minute budget have been \n> discarded;\n> * CNNSAT was trained on 75% of those instances, and tested on the remaining 25% instances, > and\n> * For the results, we only have a two-row table about CNNSAT vs MiniSAT and PicoSAT, which > are two CDCL solvers.\n> \n> Based on this protocol, we can hardly conclude that CNNSAT is outperforming most SAT \n> solvers on random 3-SAT instances. We just can say something like  \u201cFor the 3-SAT instances \n> (in which clauses are uniformly generated without replacement) that have been solved by \n> PicoSAT within a range of 10 minutes, and using 75% instances for training, CNNSAT \n> outperforms MiniSAT and PicoSAT on the remaining test instances.\u201d \n\nWe wish to make some clarifications: \n\n(1) PicoSAT was able to solve each formula in the \"Separated\" dataset within the 10-minute budget.  For the \"Long Range\" dataset, it could not solve only 6 formulas (out of the 16,000 formulas in the dataset) within the 10-minute budget.  Therefore, we chose this time budget because it seems to be sufficient for both datasets.  However, we are willing to solve the remaining 6 formulas using whatever resources (e.g., much larger time budgets) and redo our experiments. \n\n(2) We also compared the performance with other solvers besides MiniSAT and PicoSAT.   In particular, Section 5.1 mentions that \"We use Z3, PicoSAT, MiniSAT, Glucose, Dimetheus, and CaDiCaL for comparison to evaluate CNNSAT's efficiency. Due to space constraints, we only show the results for the two best-performing solvers.\"   Thus, the results show that \u201cFor the 3-SAT instances (in which clauses are uniformly generated without replacement) that have been solved by PicoSAT within a range of 10 minutes, and using 75% instances for training, CNNSAT outperforms all six solvers (not only MiniSAT and PicoSAT) on the remaining test instances.\u201d \n\n> Now, based on some of your comments (which are not included in the paper):\n> ... \n> For the sake of fairness, don\u2019t use PicoSAT (which is not the best solver for random instances) > for prunning out instances, and don\u2019t use a 10mn timeout. I would suggest to use the recent > winners here : Dimetheus or YalSAT, with a standard 5000s timeout. Ideally, CNNSAT should \n> not be trained on the SAT\u201916 benchmark instances (which are obviously \u201ctest\u201d instances); it \n> should be trained on the instances of other SAT\u2019<16 benchmarks , or using the generator for \n> those instances (Tomas Balyo).\n\nAs commented earlier, we are happy to conduct any necessary experiments to make our results more convincing to the reviewer, so we will perform this experiment. \n\nPlease do note that on the \"Long Range\" dataset generated by CNFGen, Dimetheus performed worse than both MiniSAT and PicoSAT, and CNNSAT outperformed both by two orders of magnitude (Section 5.1).  \n \n> Finally, the results should be reported in the paper.\n\nYes, we will (when we are permitted to revise the paper again).  \nFor now, we will share any results requested by the reviewer that we obtain on this discussion forum. \n \n> > Below are the results when considering the phase transition over the \"Long Range\" dataset.\n> > We follow Xu et al., 2012 and consider those instances with clause-to-variable (c/v) ratio\n> ... \n> For analyzing the performance of CNNSAT at the phase transition, I would recommend to \n> explicitly follow the protocol of Xu et al. 2012. Notably,\n> * Use the generator: https://www.satcompetition.org/2003/TOOLBOX/genAlea.c\n> * Use the solver kcnfs07 with a budget of 36,000s for labeling the instances.\n\nWe will also do and report relevant results here as soon as we are able to obtain them.  \n \n> And, again, the results should be reported in the paper, or in the Appendix.\n\nYes, we will. \n", "title": "Re Re Re \"Comments about Experiments\" "}, "Hkgd8D7jRX": {"type": "rebuttal", "replyto": "r1xyoXi9A7", "comment": "Thank you for your time and the additional comments.  We are happy to perform any additional experiments that the reviewer deems relevant, although we contend that we have demonstrated, via a set of extensive experiments, the orders of magnitude speedups of CNNSAT over the state-of-the-art solvers, including MiniSAT, PicoSAT, Dimetheus, etc. \n\nMore information is also posted in our response to AnonReviewer1 and AnonReviewer3.  As it contains additional details that are not in the revised paper, could you please also look at the response if you have not already?   Thank you. \n\nMeanwhile, we will conduct additional experiments and post relevant results here. \n\n", "title": "Re \"Comments about Experiments\""}, "rJxXT0DOCQ": {"type": "rebuttal", "replyto": "SkgSKDHdA7", "comment": "We greatly appreciate your consideration; thank you! ", "title": "Re \"Response deadline\" "}, "r1gpxB7w0X": {"type": "rebuttal", "replyto": "SygnL1qDhX", "comment": "Thank you for the helpful comments and suggestions.\n\nRegarding the example, the goal of it is to help the reader understand\nthe algorithm more easily. The wrong assignment with 80% probability\nis used to illustrate the situation where some predictions are wrong.\n\"if we try here $x_2 = 1$\" is based on the original formula, which is\n\"$x_1 \\lor x_2) \\land (\\lnot x_1 \\lor x_2) \\land ( x_1 \\lor \\lnot\nx_2)$\". Therefore, the assigned formula is $x_1$.\n\nWe tested PicoSAT, MiniSAT, Dimetheus and CaDiCaL and reported the\nresults in the updated paper. CNNSAT outperformed all these solvers by\nat least two orders of magnitude over the \"Long Range\" dataset.", "title": "Response to AnonReviewer2"}, "Syl2A4mPR7": {"type": "rebuttal", "replyto": "rJxd44Xt27", "comment": "Thank you for the valuable comments and suggestions. We apologize for\nnot submitting our response and updated paper sooner as we had been\nperforming additional experiments and analyses, and updating the\npaper.  We understand from an email from the PC chairs that the author\nresponse and revision deadline is Monday, November 26, 2018, which has\nnot yet passed.\n\nCon 1: Thank you for the suggestion; we added details for Figure 2.\n\nCon 2: We tried two experiments:\n\n(1) Using the \"Long Range\" dataset for training and SAT instances\nconverted from QF_BV for testing: we tested SAT instances with fewer\nthan 500 variables since the maximum number of variables of the\ntraining set is 400. The accuracy is 69% --- accuracy on UNSAT is 23%\nand 82% on SAT.  The overall accuracy is 4% lower but the accuracy on\nUNSAT is significantly worse (compared to 48%).\n\n(2) Using Agile from the SAT competition 2016 benchmarks for training\nand SAT instances converted from QF_BV for testing: The accuracy is\n38.8%, which is lower. We also trained on Agile and tested on the\n\"Long Range\" dataset. The accuracy is 39.7%.\n\nThese results suggest that it is more effective to train the model for\na specific domain as one would expect.", "title": "Response to AnonReviewer3"}, "rJxTi4mDR7": {"type": "rebuttal", "replyto": "HkgK8jD53X", "comment": "We appreciate the detailed, constructive feedback, which we discuss\nand respond to below.\n\n#1\n\nThank you for pointing this out.  We changed the sentence to \"they\nstill do not scale well to formulas with hundreds of variables for\nuniform 3-SAT problems.\"\n\nWe used MiniSAT and PicoSAT to solve the SAT instances in our dataset,\nall of which are uniform 3-SAT problems (see Figure 4 and Table 1):\nThe \"Long Range\" instances take about 11 hours for both MiniSAT and\nPicoSAT to solve, while it only takes 429 seconds for MiniSAT and 355\nseconds for PicoSAT to solve those instances in \"Separated\".\n\nThe main difference between the \"Long Range\" and \"Separated\" datasets\nis that \"Long Range\" contains more complex formulas with more than 300\nvariables. Formulas in SAT competitions are not uniform 3-SAT\nproblems.\n\n------\n\n#2, #3, #5\n\nWe evaluated CNNSAT against four SAT solvers, MiniSAT, PicoSAT,\nCaDiCaL and Dimetheus, and updated the paper with the additional\nresults.  In summary, CNNSAT outperforms all of them by at least two\norders of magnitude over the \"Long Range\" dataset.\n\nOur original submission had a typo in the sentence: \"% of Imp on\nassign\" denotes the percentage of improvement for our SAT solving\nalgorithm compared to directly solving CNFs predicted as satisfiable\nusing Z3.  Z3 should have been PicoSAT, which we have corrected in the\nupdated paper.\n\n------\n\n#6\n\nWe evaluated the performance of CNNSAT on the Agile benchmarks from\nSAT competition 2016. The results are as follows.  The benchmarks took\nPicoSAT more than 48 hours to solve (the budget for each was 10\nminutes).  CNNSAT solved all of them in 287 seconds with 97.5%\naccuracy --- the accuracy for UNSAT is 97.6%, while the accuracy for\nSAT is 97.1%.\n\n------\n\n#7\n\nBelow are the results when considering the phase transition over the\n\"Long Range\" dataset.  We follow Xu et al., 2012 and consider those\ninstances with clause-to-variable (c/v) ratio in [3.26, 5.26], where a\nratio of 4.26 is the solubility phase transition. Out of the 16,000\ninstances in the \"Long Range\" dataset, 6,437 have c/v ratio within\n[3.26, 5.26].  We use 4,827 for training and 1,610 for testing (803 of\nwhich are SAT instances and 807 are UNSAT instances), and obtain the\nfollowing results:\n\n- CNNSAT's overall prediction accuracy: 95.5% (vs. 70% for Xu et\n  al., 2012)\n\n- CNNSAT's accuracy over the 803 SAT instances: 99.4%\n\n- CNNSAT's accuracy over the 807 UNSAT instances: 91.6%\n\n------\n\nRe \"Exchangeability and the use of CNNs\"\n\nThe goal of the exchangeability evaluation is to demonstrate that\nCNNSAT is able to identify semantic equivalent formulas.  Thank you\nfor your suggestion; we have redone the experiment and updated the\npaper accordingly (see Table 2). In particular, we negated half of the\nvariables and swapped half of the variables. There is only an average\ndifference of 0.35% in prediction results from the results on the\noriginal formulas.\n\nThe fixed-size 100x100 matrices are constructed by the first layer of\nCNN. We can define the size filter and stride based on the size of\nmatrices. This compression is done by CNN.  Note that the matrix\nrepresentation for CNF is very sparse, but the number of variables and\nclauses are very large (for SAT problems converted from SMT problems,\nthe number of variables can be in the millions), which can easily lead\nto out-of-memory errors. Therefore, we compress the sparse matrices so\nthat they are denser.\n\nIn summary, we employ two types of compressions: (1) sparse matrix\ncompression from the representation of CNF formulas, and (2)\ncompression by the first layer of CNN.  The size of the compressed\nmatrix (100x100) and N are both tuned with respect to accuracy or\nmemory usage.", "title": "Response to AnonReviewer1"}, "BkxxZ4mD07": {"type": "rebuttal", "replyto": "ryxhynC9KX", "comment": "We thank the reviewers for their detailed and helpful feedback, which\nhas guided us in refining our paper and providing the additional\nresults to address the main review comments, i.e.,\n\n(1) comparison with state-of-the-art SAT solvers such as PicoSAT and MiniSAT,\n\n(2) experiment to take into consideration the solubility phase transition,\n\n(3) exchangeability experiments, and\n\n(4) experiment to understand how well models trained on one domain\ntransfer to another domain.\n\nWe have updated our paper accordingly, and will incorporate all the\nadditional results and discussions as permitted by the space\nconstraints.\n\nWe believe that we have carefully addressed all the major comments\nfrom the reviewers, and hope the reviewers also find them responsive\nand satisfactory. If the reviewers have further comments, we are happy\nto hear about them and will respond accordingly. Thank you for your\nvaluable time and strong effort in reviewing and considering this\nsubmission for ICLR 2019.", "title": "Revision Summary"}, "SygnL1qDhX": {"type": "review", "replyto": "ryxhynC9KX", "review": "The aim of this paper is to solve SAT instances using a CNN architecture. SAT instances are represented using an efficient encoding of boolean matrices. The overall idea is to decompose an input SAT instance into simpler ones, and to train the neural model on simpler instances using an existing solver for labeling these instances. Based on satisfaction probabilities induced from simpler formulas, the architecture predicts a partial assignment which is fed to the existing solver for deriving the satisfiability result.\n\nArguably, the topic of \u201clearning to solve SAT instances\u201d is very interesting, by coupling results from neural networks and SAT solvers. This work is inspired from the landmark paper on NeuroSAT, and the experimental results look promising. \n\nHowever, since the framework is focused on solving random SAT problems (especially random 3-SAT instances), the paper is missing a detailed description of this active research topic in AI and the SAT community (see e.g. [1,2]). Notably, the problem of generating realistic random k-SAT instances has long been considered as one of the most important challenges in SAT research [3]. Importantly, modern random k-SAT instances are not only characterized by their number of variables, and their ratio  #clauses / #variables, but with an additional \u201cstructure\u201d which mimics real-world, industrial instances (see e.g. [4]). \n\nFurthermore, I had some trouble understanding how a SAT instance is solved using algorithm 1. Specifically the text in Section 3.3 that explains Algorithm 1 is a bit confusing. How do \u201cwe choose a specific number of assignments based on prediction probabilities\u201d? Unless I missed something, the output of the CNN architecture is a probability value that the input formula is SAT, so I don\u2019t really see how this can be related to prediction probabilities of assignments. This should be explained in detail since Line 15 is the main output of the algorithm, which is fed (Line 16) to an existing solver for completing the assignment. The example at the end of section 3.3 is not very helpful: namely, the CNF formula $(x_2) \\land (\\neg x_2)$ is clearly unsatisfiable, so how can the model predict that it is satisfiable with 80% probability? And, if we try here $x_2 = 1$, we immediately get $\\bot$ (the unsat CNF), but not $x_1$ (which was already assigned to $0$).\n\nFinally, the CNN architecture should be compared with modern SAT solvers which have been participating to SAT competitions. The Z3 solver is mainly focused on solving SMT instances [5], not random k-SAT instances which, by the way, is a common track in annual SAT competitions (see e.g. [6]). To this point, generic SAT solvers such as MiniSAT [7] and Glucose [8] are able to solve in few seconds some random 3-SAT instances with thousands of variables and tens of thousands of clauses (see e.g. [4]). So, the motivating assertion \u201c[...] state-of-the-art solvers do not yet scale to large, difficult formulas, such as ones with hundreds of variables and thousands of clauses\u201d in the introduction of the paper, is not totally correct. To sum up, I would recommend to compare the CNNSAT architecture with well-known SAT solvers such as MinSAT, Glucose, March, or Dimetheus [9] which has been one of the strongest solvers in recent years for tackling random instances. Also, as mentioned above, it would be interesting to incorporate some structures (such as, for example, community attachments or popularity-similarities) in SAT instances, in order to estimate whether CNNSAT could handle pseudo-industrial problems.\n\n[1] D. Mitchell, B. Selman, H. Levesque, Hard and easy distributions of SAT problems, in: Proceedings of the 10th National Conference on Artificial Intelligence, AAAI\u201992, 1992, pp. 459\u2013465.\n\n[2] Nudelman, E., Leyton-Brown, K., Hoos, H. H., Devkar, A., & Shoham, Y. Understanding random SAT: Beyond the clauses-to-variables ratio. In 10th International Conference on Principles and Practice of Constraint Programming (CP\u201904), pp. 438\u2013452.\n\n[3] B. Selman, H.A. Kautz, D.A. McAllester, Ten challenges in propositional reasoning and search, in: Proceedings of the 15th International Joint Conference on Artificial Intelligence, IJCAI\u201997, 1997, pp. 50\u201354.\n\n[4] J. Gir\u00e1ldez-Cru and J. Levy. Generating sat instances with community structure. Artificial Intelligence, 238:119 \u2013 134, 2016. \n\n[5] The 2014 SMT Competition https://satassociation.org/jsat/index.php/jsat/article/download/122/114\n\n[6] The 2018 SAT Competition\nhttp://sat2018.forsyte.tuwien.ac.at/index.php?cat=results\n\n[7] N. E\u00e9n, N. S\u00f6rensson, An extensible SAT-solver, in: Proceedings of the 6th International Conference on Theory and Applications of Satisfiability Testing, SAT\u201903, 2003, pp. 502\u2013518.\n\n[8] ] G. Audemard, L. Simon, Predicting learnt clauses quality in modern SAT solvers, in: Proceedings of the 21st International Joint Conference on Artificial Intelligence, IJCAI\u201909, 2009, pp. 399\u2013404\n\n[9] Dimetheus\nhttps://www.gableske.net/dimetheus\n\n\n", "title": "Promising neural SAT solver, though limited contributions", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "rJglK4INhQ": {"type": "rebuttal", "replyto": "H1eyyfEWhQ", "comment": "Thank you for your comment and the question!   We trained the neural network for the SMT benchmarks based on the SAT problems converted from the SMT problems.  For example, we first converted all the QF_BV benchmarks to their corresponding SAT problems, and then used 75% of the resulting SAT problems for training and the remaining 25% for testing.\n", "title": "Re: Question about SMT Benchmarks "}}}