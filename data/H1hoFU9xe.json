{"paper": {"title": "Generative Adversarial Networks for Image Steganography", "authors": ["Denis Volkhonskiy", "Boris Borisenko", "Evgeny Burnaev"], "authorids": ["dvolkhonskiy@gmail.com", "bborisenko@hse.ru", "e.burnaev@skoltech.ru"], "summary": "We consider a new type of GAN model and apply it to secure image steganography", "abstract": "Steganography is collection of methods to hide secret information (\"payload\") within non-secret information (\"container\"). Its counterpart, Steganalysis, is the practice of determining if a message contains a hidden payload, and recovering it if possible. Presence of hidden payloads is typically detected by a binary classifier. In the present study, we propose a new model for generating image-like containers based on Deep Convolutional Generative Adversarial Networks (DCGAN). This approach allows to generate more setganalysis-secure message embedding using standard steganography algorithms. Experiment results demonstrate that the new model successfully deceives the steganography analyzer, and for this reason, can be used in  steganographic applications.", "keywords": ["Computer vision", "Deep learning", "Unsupervised Learning", "Applications", "Supervised Learning"]}, "meta": {"decision": "Reject", "comment": "This paper examines an application of that deviates from the usual applications presented at ICLR. The idea seems very interesting to the reviewers, but a number of reviewers had trouble really understanding why the proposed SGAN would be attractive for this problem, and this problem setup with the SGAN in general. Clearer concrete 'use case scenarios' and experimentation that helps clarify the precise application setting and the advantages of the SGAN formulation would help make this work more impactful on the community. Given the quality of other paper submitted to ICLR this year the reviewer scores are just short of the threshold for acceptance"}, "review": {"SJLvUP6Nl": {"type": "rebuttal", "replyto": "SkPLQan7l", "comment": "Thank you for your review.\n\n\"Alice\" wants to send some private notification in cleartext to \"Bob\" inside a unique photograph of a human face. An eavesdropping adversary \"Eve\" knows that Alice would only use human faces as stegocontainers and wants to detect if an intercepted image contains some concealed payload information, but doesn't know the particular stego algorithm used for embedding and the source seed used for generation (may be allow Eve to know the Stego(...) function, but then allow Alice to send ciphered messages). Eve also knows that Alice is aware of the existence of an adversary with Eve's capabilities.\n\nIn this setting it is best for Alice to explicitly model Eve detection capabilities inside a SGAN as the network S. This allows to Alice to train a generator that is secure against the best Eve's detector, since during training the model of Eve has access to more information (the faces dataset, source and \u201cloaded\" image, gradients and stego/empty labelling, and synthetic/realistic) than the real Eve, who has access to the same dataset, the labelling and source vs. \u201cloaded\" image.\n\nWe further allow Eve to have a labeled train dataset with synthetic images and real images to train a classifier S^*.\n", "title": "Answer"}, "Bkd0rDT4e": {"type": "rebuttal", "replyto": "BydZ35WNx", "comment": "Thank you for your review.\n\nYes, potentially this function is non-differentiable, but given fixed payload the final result of its acton onto an image is a fixed additive distortion. This makes backprop through it quite straightforward. Note, that during training the action matrix of the Stego(...) is effectively random: we use the same pool of payload information for each batch, but within a batch random payload information is embedded in each image.\n\n-------\n We apply GAN approach in the paper purely as a training technique to get an image generator (G) that achieves both realism with respect to a discriminator (D) and security against stegodetector (S), both jointly adversarially trained (eq. 4). This way we get a generator, the images of which have the pixel distribution, specifically tailored to securely concealing images with a particular Stego(...) function. Since we are not using the GAN trained D and S any further and want to use G solely as an image generator, we are therefore free to train it on the whole dataset. This permits us to verify how well the GAN approach works in stego.\n\nThe 90-10 train-test split is related to training/validating the independent stego-detector S^*, used to assess the security of the generated images.\n-------\nIn this paper we have tested our model for the +-1 embedding algorithm only, but in the future we plan to test it for other steganographic algorithms.The key idea of the paper is that SGAN produces a generator the images of which have pixel distributions better \"aligned\" with the distortions introduced by a particular Stego-algorithm, and are sufficiently realistic-looking. In fact, this is slightly more powerful than simply trying to deceive a particular family of stegoanalysers.", "title": "Answer"}, "HkTnfv6Vg": {"type": "rebuttal", "replyto": "SJNBJ4vEg", "comment": "Thank you for your review.\n\nIndeed, there is no guarantee, that the trained generator is secure against S^*, since G is trained to deceive the jointly trained steganalyzer S, which is suboptimal with respect to S^*. The steganalyzer S^*, as a binary classifier, is trained using the pairs of raw and \"loaded\" images.\n\nHowever, training the generator with an adversarial technique, we in effect get a generator, trained against a more powerful opponent than S^*: GAN  provides S with the feedback gradients of the generator in the backprop, which is obviously unavailable while training S^*, since the generator is assumed unavailable to the eavesdropping party.", "title": "Answer"}, "ryha6Q7Xg": {"type": "rebuttal", "replyto": "SJ4mQO0fx", "comment": "In section 5.3 we showed, that if we have trained on faces Steganalyzer 'S*', we can deceive it with generated faces. Our goal was to create images from the same distribution, that 'S*' has seen.\n\nDue to adversarial nature in which the container image generator was trained, it is better suited for being undetectable by a jointly trained stegoanalyzer 'S*', which itself trains to better detect concealed payloads.", "title": "We compared our generated samples as a containers with real in section 5.3"}, "SybzzyJ7x": {"type": "rebuttal", "replyto": "H1lNNT3zx", "comment": "In steganographic articles the payload bit rate is usually set to 0.4-0.6 bits per pixel (bpp). In this paper we used the default 0.4 bpp, but will analyze the sensitivity in the further experiments.", "title": "No, at the moment we have not analyzed the sensitivity of detectability to the bit rate of the secret message."}, "SJ4mQO0fx": {"type": "review", "replyto": "H1hoFU9xe", "review": "How do the samples from the proposed model perform compared to using real images as containers? What is the main incentive to use generated containers as opposed to randomly picking real data?I found this paper very original and thought-provoking, but also a bit difficult to understand. It is very exciting to see a practical use case for image-generating GANs, with potentially meaningful benchmarks aside from subjective realism.\n\nI found eq. 4 interesting because it introduces a potentially non-differentiable black-box function Stego(...) into the training of (S, G). Do you in fact backprop through the Stego function?\n\n- For the train/test split, why is the SGAN trained on all 200k images? Would it not be cleaner to use the same splits for training SGAN as for \"steganalysis purposes\"? Could this account for the sensitivity to random seed shown in table 2?\n- Sec. 5.3: \"Steganographic Generative Adversarial Networks can potentially be used as a universal tool for generating Steganography containers tuned to deceive any specific steganalysis algorithm.\". This experiment showed that SGAN can fool HUGO, but I do not see how it was \"tuned\" to deceive HUGO, or how it could be tuned in general for a particular steganalyzer.\n\nAlthough S* seems to be fooled by the proposed method, in general for image generation the discriminator D is almost never fooled. I.e. contemporary GANs never converge to actually fooling the discriminator, even if they produce samples that sometimes fool humans. What if I created an additional steganalyzer S**(x) = S*(x) * D(x)? This I think would be extremely difficult to fool reliably because it requires realistic image generation.\n\nAfter reading the paper several times, it is still a bit unclear to me how or why precisely one would use a trained SGAN. I think the paper could be greatly improved by detailing, step by step, the workflow of how a hypothetical user would use a trained SGAN. This description should be aimed at a reader who knows nothing or very little about steganography (e.g. most of ICLR attendees).\n", "title": "Samples vs real images as containers", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "BydZ35WNx": {"type": "review", "replyto": "H1hoFU9xe", "review": "How do the samples from the proposed model perform compared to using real images as containers? What is the main incentive to use generated containers as opposed to randomly picking real data?I found this paper very original and thought-provoking, but also a bit difficult to understand. It is very exciting to see a practical use case for image-generating GANs, with potentially meaningful benchmarks aside from subjective realism.\n\nI found eq. 4 interesting because it introduces a potentially non-differentiable black-box function Stego(...) into the training of (S, G). Do you in fact backprop through the Stego function?\n\n- For the train/test split, why is the SGAN trained on all 200k images? Would it not be cleaner to use the same splits for training SGAN as for \"steganalysis purposes\"? Could this account for the sensitivity to random seed shown in table 2?\n- Sec. 5.3: \"Steganographic Generative Adversarial Networks can potentially be used as a universal tool for generating Steganography containers tuned to deceive any specific steganalysis algorithm.\". This experiment showed that SGAN can fool HUGO, but I do not see how it was \"tuned\" to deceive HUGO, or how it could be tuned in general for a particular steganalyzer.\n\nAlthough S* seems to be fooled by the proposed method, in general for image generation the discriminator D is almost never fooled. I.e. contemporary GANs never converge to actually fooling the discriminator, even if they produce samples that sometimes fool humans. What if I created an additional steganalyzer S**(x) = S*(x) * D(x)? This I think would be extremely difficult to fool reliably because it requires realistic image generation.\n\nAfter reading the paper several times, it is still a bit unclear to me how or why precisely one would use a trained SGAN. I think the paper could be greatly improved by detailing, step by step, the workflow of how a hypothetical user would use a trained SGAN. This description should be aimed at a reader who knows nothing or very little about steganography (e.g. most of ICLR attendees).\n", "title": "Samples vs real images as containers", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "H1lNNT3zx": {"type": "review", "replyto": "H1hoFU9xe", "review": "Have you explored how many bits may be stored in an adversarial perturbation that might not be detected? I would imagine that if the perturbation were larger, more bits might be communicated but at a risk of being detected easier.\nI reviewed the manuscript as of December 6th.\n\nSummary:\nThe authors build upon generative adversarial networks for the purpose of steganalysis -- i.e. detecting hidden messages in a payload. The authors describe a new model architecture in which a new element, a 'steganalyser' is added a training objective to the GAN model.\n\nMajor Comments:\nThe authors introduce an interesting new direction for applying generative networks. That said, I think the premise of the paper could stand some additional exposition. How exactly would a SGAN method be employed? This is not clear from the paper. Why does the model require a generative model? Steganalysis by itself seems like a classification problem (i.e. a binary decision if there a hidden message?) Would you envision that a user has a message to send and does not care about the image (container) that it is being sent with? Or does the user have an image and the network generates a synthetic version of the image as a container and then hide the message in the container? Or is the SGAN somehow trained as a method for detecting hidden codes performed by any algorithm in an image? Explicitly describing the use-case would help with interpreting the results in the paper.\n\nAdditionally, the experiments and analysis in this paper is quite light as the authors only report a few steganalysis performance numbers in the tables (Table 1,2,3). A more extensive analysis seems warranted to explore the parameter space and provide a quantitative comparison with other methods discussed (e.g. HUGO, WOW, LSB, etc.) When is it appropriate to use this method over the others? Why does the seed effect the quality of results? Does a fixed seed correspond realistic scenario for employing this method?\n\nMinor comments:\n- Is Figure 1 necessary?\n- Why does the seed value effect the quality of the predictive performance of the model?", "title": "Number of bits that may be stored in the adversarial perturbations", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "SkPLQan7l": {"type": "review", "replyto": "H1hoFU9xe", "review": "Have you explored how many bits may be stored in an adversarial perturbation that might not be detected? I would imagine that if the perturbation were larger, more bits might be communicated but at a risk of being detected easier.\nI reviewed the manuscript as of December 6th.\n\nSummary:\nThe authors build upon generative adversarial networks for the purpose of steganalysis -- i.e. detecting hidden messages in a payload. The authors describe a new model architecture in which a new element, a 'steganalyser' is added a training objective to the GAN model.\n\nMajor Comments:\nThe authors introduce an interesting new direction for applying generative networks. That said, I think the premise of the paper could stand some additional exposition. How exactly would a SGAN method be employed? This is not clear from the paper. Why does the model require a generative model? Steganalysis by itself seems like a classification problem (i.e. a binary decision if there a hidden message?) Would you envision that a user has a message to send and does not care about the image (container) that it is being sent with? Or does the user have an image and the network generates a synthetic version of the image as a container and then hide the message in the container? Or is the SGAN somehow trained as a method for detecting hidden codes performed by any algorithm in an image? Explicitly describing the use-case would help with interpreting the results in the paper.\n\nAdditionally, the experiments and analysis in this paper is quite light as the authors only report a few steganalysis performance numbers in the tables (Table 1,2,3). A more extensive analysis seems warranted to explore the parameter space and provide a quantitative comparison with other methods discussed (e.g. HUGO, WOW, LSB, etc.) When is it appropriate to use this method over the others? Why does the seed effect the quality of results? Does a fixed seed correspond realistic scenario for employing this method?\n\nMinor comments:\n- Is Figure 1 necessary?\n- Why does the seed value effect the quality of the predictive performance of the model?", "title": "Number of bits that may be stored in the adversarial perturbations", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}}}