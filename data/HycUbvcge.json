{"paper": {"title": "Deep Generalized Canonical Correlation Analysis", "authors": ["Adrian Benton", "Huda Khayrallah", "Biman Gujral", "Drew Reisinger", "Sheng Zhang", "Raman Arora"], "authorids": ["adrian@cs.jhu.edu", "huda@jhu.edu", "bgujral1@jhu.edu", "reisinger@cogsci.jhu.edu", "zsheng2@jhu.edu", "arora@cs.jhu.edu"], "summary": "A multiview representation learning technique that can learn nonlinear mappings from arbitrarily many views to a shared semantic space -- Deep Generalized Canonical Correlation Analysis.", "abstract": "We present Deep Generalized Canonical Correlation Analysis (DGCCA) \u2013 a method for learning nonlinear transformations of arbitrarily many views of data, such that the resulting transformations are maximally informative of each other. While methods for nonlinear two-view representation learning (Deep CCA, (Andrew et al., 2013)) and linear many-view representation learning (Generalized CCA (Horst, 1961)) exist, DGCCA is the first CCA-style multiview representation learning technique that combines the flexibility of nonlinear (deep) representation learning with the statistical power of incorporating information from many independent sources, or views. We present the DGCCA formulation as well as an efficient stochastic optimization algorithm for solving it. We learn DGCCA representations on two distinct datasets for three downstream tasks: phonetic transcription from acoustic and articulatory measurements, and recommending hashtags and friends on a dataset of Twitter users. We find that DGCCA representations soundly beat existing methods at phonetic transcription and hashtag recommendation, and in general perform no worse than standard linear many-view techniques.", "keywords": ["Unsupervised Learning", "Deep learning", "Multi-modal learning"]}, "meta": {"decision": "Reject", "comment": "This is largely a clearly written paper that proposes a nonlinear generalization of a generalized CCA approach for multi-view learning. In terms of technical novelty, the generalization follows rather straightforwardly. Reviewers have expressed the need to clarify relationship and provide comparisons to existing proposals for combining deep learning with CCA. As such the paper has been evaluated to be borderline. The proposed method appears to yield significant gains on a speech dataset, though comparisons on other datasets appear to be less conclusive. Some basic baselines as missing, e.g., concatenating views and running a deep model, or using much older nonlinear extensions of CCA such as kernel CCA (e.g. accelerated via random features, and combined with deep representations underneath)."}, "review": {"HkLqk2SUg": {"type": "rebuttal", "replyto": "HycUbvcge", "comment": "Thank you for your helpful comments.  We just uploaded a revised draft, incorporating the reviewers' suggestions, and hopefully addressing many of their concerns.  Below are the things to note:\n\n- The linear GCCA solution for G and U is included in Appendix A, along with a full gradient derivation: \"... the rows of G are the top r (orthonormal) eigenvectors of M, and $U_j = C_{jj}^{\u22121} Y_j G^T$\" (reviewer 2)\n\n- In the last paragraph of the Optimization subsection (page 4), we include big-Oh notation for the gradient update time complexity.  We leverage the GCCA solution presented in [R1] to scale DGCCA to large datasets. (reviewer 2)\n\n- We qualify the pronouncement of being \"the first nonlinear multiview learning technique\" with the adjective \"CCA-style\".  Although our work focuses on extending CCA-based multiview methods, we recognize that others have attempted to learn embeddings by merging information from multiple views. (reviewer 5)\n\n- In Section 5, \"Other Multiview Work\", we include a discussion of a non-CCA-based techniques for nonlinear representation learning from multiple views, and how they differ from DGCCA.  As reviewers 2 and 5 mention, the multiview learning literature is vast, and we are not able to address all models proposed that make learned representations from more than one view.  However, we do hope that this section will clarify how our proposed model differs from other representation learning techniques exploiting multiple views. (reviewers 2 and 5)\n\n- Appendix C includes a short discussion of how the DGCCA objective reconstruction error relates to downstream task performance for Twitter hashtag recommendation.  In short, we found that high reconstruction error is a strong signal for poor downstream performance, but there is significant variation in downstream performance between embeddings learned by models with low reconstruction error. (reviewer 4)\n\nWe also trained Bridge Correlational Neural Network embeddings for Twitter hashtag and friend recommendation in a series of preliminary experiments.  We swept over hidden layer width in the same range as the DGCCA experiments, $\\lambda \\in \\{0.0, 0.1, 1.0, 10.0\\}$ (the strength of the correlation term in the DGCCA objective), and used either the Twitter user ego text view or their friend network view as the pivot view, since these were the solely most effective views for hashtag and friend recommendtion.  Other learning parameters were left at the defaults and networks were trained for 50 epochs.  However, the performance of these embeddings was much worse than the CCA-style models we compare to (R@1000=0.06 for hashtag recommendation.)  We grant that downstream performance would be improved by tuning learning parameters, but these preliminary experiments underscore the fact that this class of models is not a panacea, and may not be appropriate for these recommendation tasks.  We explicitly note this in the text, since these models assume that all views should be correlated with a pivot view representation.  Entraining all embeddings to a single view is, thus, probably not as effective at hashtag recommendation as learning a CCA-style joint representation for all views. (reviewer 5)\n\nPlease let us know if any of these revisions are confusing, or if you have any additional suggestions.\n\n[R1] Pushpendre Rastogi, Benamin Van Durme, and Raman Arora. Multiview LSA: Representation Learning via Generalized CCA. Proceedings of NAACL. 2015.", "title": "Draft revised, added prior work section"}, "rysznW2Eg": {"type": "rebuttal", "replyto": "H1GCKjB4l", "comment": "\n- The detailed algorithm and updates for U, G are given in Algorithm 1 in Appendix B on page 13. We will highlight the key updates in the main text as well. \n\n- Figures 3(b) and Figure 4(a) show different things. Figure 3(b) shows the shared representation G whereas Figure 4(a) shows the projection of View 1 (in Figure 2(a)) projected onto its corresponding subspace, in other words it shows U\u2019X_1. They do look similar in that the two components are well separated. \n\n- We can easily add view-specific reconstruction errors and rainbow plots. Note that from Figure 4 it appears that in terms of reconstruction error, View 3 is worse than View 2 which is worse than View 1. \n\n- We found that reconstruction error was a reasonable proxy in choosing regularization parameters, but not the best model for a downstream task.  For example, if the L2 regularization penalty was too low, the reconstruction error would be orders of magnitude larger than a correctly regularized model, and downstream task performance would be very poor.  However, we did not purely rely on reconstruction error to select models, since networks with narrower output layers will necessarily have lower reconstruction error.  Ultimately we selected models that perform best on the downstream task.  We can include a figure containing reconstruction error vs. downstream task performance to illustrate this.", "title": "AnonReviewer4 Review Response"}, "rJ23ob3Nl": {"type": "rebuttal", "replyto": "B1atHaUEg", "comment": "\n- Thanks for the additional reference, we will discuss it in the revision as it is related work. However, the \u201cBridge Correlational Neural Networks\u201d paper considers a setting where instead of several parallel views, there is a bridge view that provides a parallel view between other views.  Therefore the problem reduces to two-view CCA and their nonlinear/deep extensions. This is clearly very different from the setting we consider here as DGCCA has no such notion of a bridge view. We emphasize again that extending correlative learning to many views, say p views, using (two-view) CCA would require solving p-choose-2 CCA-like problems and various heuristics to combine them. We will add a discussion to that effect; future work/extensions will compare with bridge Corr-nets.\n\n- We discuss and compare with the most relevant related work in two view learning here, especially CCA and Deep CCA. For extensive literature, we refer the readers to our prior work including the DCCA and DCCAE papers available online. We emphasize again that this is a non-trivial extension of DCCA and various modifications/extensions of DCCA can be considered for the proposed method here as well, but that is not the focus here.", "title": "AnonReviewer5 Review Response"}, "BJpliW3Nl": {"type": "rebuttal", "replyto": "BkPCVXwEl", "comment": "\n- The code and other resources are already posted online (see the footnote on page 2).  The synthetic data are included in the linked repository.\n\n- Yes, the key idea in extending correlative learning to many views, say p views, is to compute correlation between every pair of views, store them in a pxp symmetric matrix and maximize some norm of that matrix. The norm that we consider in this paper is the spectral norm, as it leads to tractable solutions.  Na\u00efve approaches solve p-choose-2 CCA-like problems and come up with heuristics to combine them. We will add a discussion to this effect.\n\n- We greatly appreciate pointers to additional references; there has been immense activity in this area and it has been hard to catch up with the related work. We have done extensive review of related work in machine learning conferences as well as speech and language processing, but we do realize that there have been several remarkable contributions in computer vision and information retrieval. We will rectify this in the revision. \n\n- It is hard to characterize the computational complexity of the proposed methodology as is the case with any deep learning technique (it being a highly non-convex optimization problem). We can, and will, indeed discuss the computational cost per iteration and memory requirements of the proposed method (which we had included in a previous draft.)", "title": "AnonReviewer2 Review Response"}}}