{"paper": {"title": "On the Relationship between Neural Machine Translation and Word Alignment", "authors": ["Xintong Li", "Lemao Liu", "Guanlin Li", "Max Meng", "Shuming Shi"], "authorids": ["znculee@gmail.com", "redmondliu@tencent.com", "epsilonlee.green@gmail.com", "max.meng@ieee.org", "shumingshi@tencent.com"], "summary": "It proposes methods to induce word alignment for neural machine translation (NMT) and uses them to interpret the relationship between NMT and word alignment.", "abstract": "Prior researches suggest that attentional neural machine translation (NMT) is able to capture word alignment by attention, however, to our surprise, it almost fails for NMT models with multiple attentional layers except for those with a single layer. This paper introduce two methods to induce word alignment from general neural machine translation models. Experiments verify that both methods obtain much better word alignment than the method by attention.  Furthermore, based on one of the proposed method, we design a criterion to divide target words into two categories (i.e. those mostly contributed from source \"CFS\" words and the other words mostly contributed from target \"CFT\" words), and analyze word alignment under these two categories in depth. We find that although NMT models are difficult to capture word alignment for CFT words but these words do not sacrifice translation quality significantly, which provides an explanation why NMT is more successful for translation yet worse for word alignment compared to statistical machine translation. We further demonstrate that word alignment errors for CFS words are responsible for translation errors in some extent by measuring the correlation between word alignment and translation for several NMT systems.", "keywords": ["Neural Machine Translation", "Word Alignment", "Neural Network", "Pointwise Mutual Information"]}, "meta": {"decision": "Reject", "comment": "This paper examines the relationship between attention and alignment in NMT. The reviewers all agreed that this is a valuable topic that is worth thinking about.\n\nHowever, there were concerns both about the clarity of the paper and the framing with respect to previous work. First, it was hard for some reviewers to understand exactly what the paper was trying to do due to issues of the paper structure, etc. Second, there are a number of previous works that also examine similar concepts, and the description of how the proposed method differs seemed lacking.\n\nDue to these issues, I cannot recommend it for acceptance in its current form."}, "review": {"rygE92FMA7": {"type": "rebuttal", "replyto": "B1gxs8AZR7", "comment": "Thanks for your comment! We have added AER of the Transformer attention to the table3 in the new manuscript.", "title": "New manuscript with updated table3 has been uploaded"}, "B1l-APxhTm": {"type": "rebuttal", "replyto": "BJxkBrOipm", "comment": "Thank you for the constructive suggestion.\n\nWe have added the experiments to compare the alignment performance on different\ntranslation models in section 4.3. Because training multiple-layers RNN is too\nslow, we investigate Transformer with layers ranging from 1 to 6 in this\nexperiment. As shown in the following Table, with the same amount of\nsupervision from silver alignment data, Transformer-L1 generates much worse\nalignment than Transformer-L6 and it is only comparable to PMI (fast-align) in\nAER. This suggests that supervision is not enough to obtain good alignment and\nthe hidden units learned by a translation model indeed implicitly capture\nalignment knowledge.\n\n\nTransformer | L1    | L2    | L3    | L4    | L5    | L6    | PMI (FastAlign)\n--          | --    | --    | --    | --    | --    | --    | --\nAER         | 54.50 | 47.94 | 40.47 | 38.40 | 38.80 | 38.88 | 60.18\nBLEU        | 36.51 | 44.83 | 45.63 | 47.19 | 46.35 | 46.95 | N/A", "title": "New manuscript with more experimental results has been uploaded"}, "HkxSe15qTQ": {"type": "rebuttal", "replyto": "rylolAUKn7", "comment": "Thanks for your the thoughtful review with interesting suggestions. We address\nyour concerns below.\n\n(1) About the title of section 3, it is meant to the new methods for inducing\nalignment, although the methods in section 3.2 is inspired by Zintgraf, who use\nsimilar method to visualize CNN for image classification.  However, different\nfrom Zintgraf's sampling method, we purpose a deterministic method. We have\nupdated the method descriptions in section 3.2 supported by experiments in\nTable 3. And we have also modified the title to \"Methods for Inducing Word\nAlignment\". Thanks for motivating us to differentiate our method from\nZintgraf's sampling method.\n\n(2) Using 0 vector is a deterministic method to approximate the expectation in\nequation 8. We also use the Monte Carlo approach to approximate the\nexpectation. Specifically, we sample several words from vocabulary, and use\ntheir embedding instead of 0 vector to approximate the expectation. As shown in\nthe following table, the alignment performance is improving as growing of the\nsample size when using Monte Carlo Method. Fortunately, the result of\ndeterministic method, namely using a 0 vector, is very close to the result of\nusing Monte Carlo approach with enough sample size. In particular, the\ndeterministic method is one order of magnitude faster than the sampling method\nwith the best configuration in Table 3, while maintaining comparable AER.\n\nMethods           |                    Sampling PD |||||               | Deterministic PD\n--                | --    | --     | --     | --     | --     | --     | --\nSample size       | 1     | 2      | 4      | 10     | 20     | 50     | N/A\nAER               | 44.92 | 43.30  | 42.42  | 41.95  | 41.83  | 41.73  | 41.77\nVariance          | 0.004 | < 1e\u22125 | < 1e\u22125 | < 1e\u22125 | < 1e\u22125 | < 1e\u22125 | N/A\nSpeed (Words/Sec) | 114   | 58     | 27     | 12     | 5      | 2      | 115\n\n(3) You thought CFT and CFS words are global and independent on context.\nMostly, you are right. At the beginning, we also believe CFT words should be\nvery similar with functional words. However, it is hard to define the border\nbetween CFS and CFT words. For example, we can call higher frequent words CFT\nwords and lower frequent words CFS words. But this definition has many\nproblems. In addition, some words are polysemous such as \"being\", which can\neither be a part of \"human being\" and \"having being\". Obviously, the meaning of\nthis word should be determined by the context. The original partition of CFS\nand CFT words are relevant to a specific model, because it is used to interpret\nthe model's prediction. When comparing different models, we also purpose a\npartition of CFS and CFT based on PMI, which is independent on a model being\nused.\n\n(4-5) You thought there should be a probability margin when dividing CFS and\nCFT words. We have generalised the definition of CFS and CFT words in equation\n11 by introducing a margin. The results of different margin as shown in the\nfollowing table. As shown in this table, different margin generate the\ndifferent partitions of CFS and CFT words. As growing of the margin, the\npartition of CFS and CFT words becomes more confident. And the more confident\nCFS words can achieve better alignment performance and translation performance.\nBut the translation recall is still similar between CFS and CFT words, despite\nthe big gap of AER between CFS and CFT words. Besides, Contributing From Source\nor Target means where the most contribution comes from, but not means the\ncontributions only come from source or target.\n\nMargin | Target Words | AER   | Translation Recall | Proportion\n--     | --           | --    | --                 | --\n1e-4   | CFS          | 31.64 | 65.54              | 65.61%\n       | CFT          | 62.91 | 66.39              | 24.66%\n1e-3   | CFS          | 30.33 | 67.82              | 60.40%\n       | CFT          | 63.29 | 69.40              | 22.04%\n1e-2   | CFS          | 28.26 | 71.56              | 51.53%\n       | CFT          | 64.22 | 73.76              | 17.56%\n1e-1   | CFS          | 22.87 | 78.59              | 34.85%\n       | CFT          | 64.13 | 78.33              | 10.39%\n\n(6) You mentioned the relationship between the quality of the sliver alignments\nand the analysis in this paper. Firstly, the only analysis relying on sliver\nalignments are the results of explicit model. The better silver alignments will\nonly lead the explicit model perform better. And we would like to convey the\nexplicit model has achieved enough alignment performance to indicate the\ntranslation model processes the information of a good alignment.", "title": "New manuscript with more experimental results has been uploaded"}, "rkeFI1596X": {"type": "rebuttal", "replyto": "SkxwFxnu2Q", "comment": "Thanks for your review and constructive comments. We address your concerns\nbelow.\n\nYou mentioned \"multiple attention layers\", which might be the reason of\nterrible AER of attention-based alignment. As shown in Table 1, an acceptable\nalignment can be induced form a single layer multi-head attention, but cannot\nfrom a multi-layer multi-head attention. Therefore, we ascribe the degradation\nof alignment quality to \"multiple attention layers\" rather than \"the forms of\nattention\". The reason behind is multi-layer attention disrupt the order of\nsource annotations in higher layer computing.\n\nAbout GNMT in the introduction, we thank you for the scrupulous correction. We\nhave deleted it from the paper.\n\nIn equation 1, s_i^L is defined in the following text, and the specific meaning\nof variable L is defined in the end of the following text and equation 2.\n\nYou concerned Equation 3 forbid a null alignment, which is indeed an advantage\nfor FastAlign compared with NMT. This definition is located in the section\ncalled preliminaries, because previous researches of alignment on NMT is such\ndefined. Effective null alignment can definitely improve the alignment\nprecision. However, this is not trivial, and there is not effective methods to\ngenerate null alignment. With our methods, the null alignment can be generated\naccording to CFT words. Unfortunately, the AER becomes 44.84 with null\nalignment, which is worse than 41.77 without null alignment. The reason is null\nalignment can not only increase the precision, but also decrease the recall.\nAlthough null alignment may helpful, it is hard to determine which target word\nshould be aligned to null. In addition, comparing AER of CFS words in Table 3,\nFastAlign is still better but with smaller gap than overall words. This means\nexcept the advantage of null alignment, FastAlign is indeed better.\n\nThank you for mention the tricks for achieving better alignment. In our\ntraining, we do not use any of these tricks for both FastAlign and NMT models.\n\nSorry for confusing you about the description of prediction difference method,\nand we have revised the description in section 3.2. Equation 7 and 8 are\nprobabilistic definition of the prediction difference, where an expectation has\nto be approximated by Monte Carlo approach, but equation 9 is a deterministic\napproximation of the expectation. And we have verified the deterministic method\ncan achieve the similar performance as the Monte Carlo sampling method with\nenough samples, but only need the same computation as sample size equals one in\nsampling method.\n\nThroughout out this paper, we report AER on NIST 2005 test set, whose reference\nalignment was manually annotated by experts. And we have added this description\nin section 4.1.\n\nYou mentioned \"translation recall\" in the section 4.4. In this section, we\ninvestigate the performance of alignment and translation based on AER and\ntranslation recall, which is related to the 1-gram BLEU in some sense. We agree\nyour concerning, and we have modified the last sentence in section 4.4 a weaker\ntone.\n\nAbout the typo of \"with replacement\" in section 4.5, we have revised it in the\npaper. Thank you very much!", "title": "New manuscript with more clear descriptions has been uploaded"}, "HJgr2AK96X": {"type": "rebuttal", "replyto": "rkefoTRt2X", "comment": "Thanks for your feedback. We address your concerns below.\n\nYou mentioned you are not surprised by the bad attention-based alignment. Yes,\nyou are right, and several previous papers [1,2,3] also addressed\nattention-based alignment is not good enough. However, as far as we know,\ninducing alignment from attention has being the most mainly method to\ninvestigate the alignment performance of a NMT model in previous researches,\nand several previous works [4,5,6] tried to improve attention-based alignment\nto improve the translation quality. In addition, we were trying to emphasize\nthat attention-base alignment may be not only bad but also surprisingly\nterrible. In Table 1, alignment inducing from 6-layers Transformer is even\nworse compared with alignment inducing from PMI. As PMI measures the intrinsic\nalignment from the bilingual training data, this indicates attention-based\nalignment sometimes does not even achieve the amount of alignment information\nfrom the bilingual data. Therefore, we claim that the inducing alignment from\nattention cannot be regarded as a proper alignment model in general. However,\nNMT indeed can learn alignment from translation as it can be induced by\nprediction difference in spite of not by attention.\n\nYou also mentioned you are not surprised by the better alignment inducing from\nexplicit model, because you think the model is trained for achieving better\nAER. Yes, you are definitely right, but this is only one of the reasons why\nexplicit model achieve better AER. Actually, we investigated the AER of\nexplicit model over different pre-trained translation models. We found a bad\ntranslation model generally also hard to generate good alignment with only\noptimizing the bridge matrix in explicit model. For example, a six layer\ntransformer can achieve around 47 BLEU points, and a single layer transformer\ncan only achieve around 37 BLEU points. When we train the bridge of explicit\nmodel over each initialization, the six layer transformer's AER is around 39,\nbut the single layer transformer's AER is only around 54. This means training\nan explicit model over a translation model is to unearth the potential of\ninducing a good alignment from the translation model. In other words, if a\ntranslation model does not possess enough information of a good alignment, it\nis also hard to get a good AER by explicit model.\n\nFinally, thank you for your concerning of the reference alignment. Throughout\nthis paper, we evaluate AER by golden alignment labeled by experts.\n\nReference\n1. Modeling coverage for neural machine translation\n2. What does Attention in Neural Machine Translation Pay Attention to?\n3. Six challenges for neural machine translation\n4. Guided alignment training for topic-aware neural machine translation\n5. Supervised attentions for neural machine translation\n6. Neural machine translation with supervised attention", "title": "Response to the surprising point of this paper"}, "rkefoTRt2X": {"type": "review", "replyto": "S1eEdj0cK7", "review": "This paper empirically evaluates whether NMT can predict word alignment. This is done by measuring the alignment error rate between silver-data generated from FastAlign and various methods to extract alignment from NMT. The conclusions are that NMT attention does not predict alignment well, and the proposed method of training an additional alignment extraction model performs better. \n\nUnfortunately, I do not appreciate the motivation of the work. Attention is not alignment. Yes, we can try to extract alignment from attention or other parts of the model. But we should really not expect attention to do alignment, because it was simply not designed to do so. \n\nSo I am not surprised by the first result that AER for attention-based alignment is bad. I am also not suprised by the second result where training an explicit word alignment model (Eq 6) gets better AER, because that is what the model is designed for. \n\nI do understand that probing alignments might increase our ability to understand and interpret these NMT models. I also thought the CFS and CFT analysis was interesting. But unfortunately I don't think the overall problem attacked by this paper is sufficiently well-motivated for a full paper at ICLR. I do think this will be suitable at, for example, a workshop on visualizing/interpreting neural networks in applications. \n\nAdditional note: Please be more specific whether the AER results in Sec 4.2-4.4 are based on scoring on gold alignments in the NIST2015 data, or silver alignments from FastAlign. The former is fine, but the latter might make the results biased for the explicit alignment model trained on the same alignments. ", "title": "Sorry I don't fully appreciate the motivation", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "rylolAUKn7": {"type": "review", "replyto": "S1eEdj0cK7", "review": "The authors study various NMT models and show that most of them do not learn a good alignment model but still achieve good translation. They suggest that the translated output contains two types of words (i) contributed from source (CFS) and (ii) contributed from target (CFT) and hypothesize that even if the alignment is not good the CFT words contribute to the the better quality of translation (as these are not dependent on alignment).\n\nI have a few questions for the authors:\n\n1) Section 3 is titled \"Proposed Methods for Inducing Word Alignment\". This gives an impression that you are proposing some methods. However, the methods listed in  section 3.2 is from existing work (as you have already acknowledged by citing them correctly). I request you to rename the section or make this more explicit.\n\n2) I am not very convinced about the idea of using a 0 vector to dropout a particular word. Did you try any other options for this ?\n\n3) R_0 and R depend on the model. I mean these scores are as good as the model itself. Therefore I am not sure if it is correct to use these scores to determine CFT and CFS words. Ideally, CFT and CFS words should be a global phenomenon irrespective of the model being used. For example, while translating from a language which does not use articles (a, an, the) to a language which uses such articles, all articles in the target language would be CFT words, irrespective of the model being used. However, this is not the case in your definitions (the definitions are tied to the model scores).\n\n4) Shouldn't you also consider a certain margin  in Equation 11. I mean shouldn't the LHS be greater than the RHS by a certain margin for the word to be classified as CFS. \n\n5) Conceptually, I don't agree with the idea that a word is either CFS or CFT. What about words which require both source and target information? Equation 11 does not completely account for it because the quantity on the LHS does depend on the target words and the quantity on the RHS does dependent on the source words. It is difficult to isolate of effect on source/target.\n\n6) Can you comment on the quality of the silver alignments as the analysis presented in the paper will depend on the quality of these alignments.  \n", "title": "Need more convincing", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "SkxwFxnu2Q": {"type": "review", "replyto": "S1eEdj0cK7", "review": "This paper sets out to build good bilingual word alignments from the information in an NMT system (both Transformer and RNN), where the goal is to match human-generated word-alignments as measured by AER. At least that\u2019s how it starts. They contribute two aligners: one supervised aligner that uses NMT source and target representations as features and is trained on silver data generated by FastAlign, and one interpretability-based aligner that scores the affinity of a source-target word-pair by deleting the source word (replacing its embedding with a 0-vector) and measuring the impact on the probability of the target word. These are both shown to outperform directly extracting alignments from attention matrices by large margins. Despite the supervised aligner getting better AER, the authors proceed to quickly discard it as they dive deep on the interpretability approach, applying it also to target-target word pairs, and drawing somewhat interesting conclusions about two classes of target words: those that depend most of source context and those that depend most on target context.\n\nUltimately, this paper\u2019s main contribution is its subtraction-based method for doing model interpretation. Its secondary contributions are the idea of evaluating this interpretation method empirically using human-aligned sentence pairs, and the idea of using the subtraction method on target-target pairs. The conclusion does a good job of emphasizing these contributions, but the abstract and front-matter do not. Much of the rest of the paper feels like a distraction. Overall, I believe the contributions listed above are valuable, novel and worth publishing. I can imagine using this paper\u2019s techniques and ideas in my own research.\n\nSpecific concerns:\n\nThe front-matter mentions \u2018multiple attention layers\u2019. It would probably be a good idea to define this term carefully, as there are lots of things that could fit: multiple decoder layers with distinct attentions, multi-headed attention, etc.\n\nIn contrast to what is said in the introduction, GNMT as described in the Wu et al. 2016 paper only calculates attention once, based on the top encoder layer and the bottom decoder layer, so it doesn\u2019t fit any definition of multiple attention layers.\n\nEquation (1) and the following text use the variable L without defining it.\n\n\u2018dominative\u2019 -> \u2018dominant\u2019\n\nIs there any way to generate a null alignment with Equation 3? That is, a target word that has no aligned source words? If not, that is a major advantage for FastAlign.\n\nSimilarly, what exactly are you evaluating when you evaluate FastAlign? Are you doing the standard tricks from the phrase-based days, and generating source->target and target->source models, and combining their alignments with grow-diag-final? If so, you could apply the same tricks to the NMT system to help even the playing field. Maybe this isn\u2019t that important since the paper didn\u2019t win up being about how to build the best possible word aligner from NMT (which I think is for the best).\n\nI found Equations (7) and (8) to be confusing and distracting. I understand that you were inspired by Zintgraf\u2019s method, but the subtraction-based method you landed on doesn\u2019t seem to have much to do with the original Zintgraf et al. approach (and your method is much easier to the understand in the context of NMT than theirs). Likewise, I do not understand why you state, \u201cwe take the uniform distribution as P(x) regarding equation 8 for simplicity\u201d - equation 9 completely redefines the LHS of equation 8, with no sum over x and no uniform distribution in sight.\n\nThe Data section of 4.1 never describes the NIST 2005 hand-aligned dataset.\n\nThe conclusions drawn at the end of 4.4 based on \u2018translation recall\u2019 are too strong. What we see is that the Transformer outperforms Moses by 2.8 onCFS, and by 3.7 on CFT. This hardly seems to support a claim that CFT words are the reason why Transformer yields better translation.\n\n4.5 paragraph 1: there is no way to sample 12000 datasets without replacement from NIST 2005 and have the samples be the same size as NIST 2005. You must mean \u201cwith replacement\u201d?", "title": "Interesting interpretability work cast as bilingual word alignment.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}}