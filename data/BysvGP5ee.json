{"paper": {"title": "Variational Lossy Autoencoder", "authors": ["Xi Chen", "Diederik P. Kingma", "Tim Salimans", "Yan Duan", "Prafulla Dhariwal", "John Schulman", "Ilya Sutskever", "Pieter Abbeel"], "authorids": ["peter@openai.com", "dpkingma@openai.com", "tim@openai.com", "rocky@openai.com", "prafulla@mit.edu", "joschu@openai.com", "ilyasu@openai.com", "pieter@openai.com"], "summary": "A VAE that provably learns global structure of images with a local PixelCNN decoder.", "abstract": "Representation learning seeks to expose certain aspects of observed data in a learned representation that's amenable to downstream tasks like classification. \nFor instance, a good representation for 2D images might be one that describes only global structure and discards information about detailed texture. \nIn this paper, we present a simple but principled method to learn such global representations by combining Variational Autoencoder (VAE) with neural autoregressive models such as RNN, MADE and PixelRNN/CNN. \nOur proposed VAE model allows us to have control over what the global latent code can learn and , by designing the architecture accordingly, we can force the global latent code to discard irrelevant information such as texture in 2D images, and hence the code only ``autoencodes'' data in a lossy fashion.\nIn addition, by leveraging autoregressive models as both prior distribution $p(z)$ and decoding distribution $p(x|z)$, we can greatly improve generative modeling performance of VAEs, achieving new state-of-the-art results on MNIST, OMNIGLOT and Caltech-101 as well as competitive results on CIFAR10.  \n", "keywords": ["Deep learning", "Unsupervised Learning"]}, "meta": {"decision": "Accept (Poster)", "comment": "The reviewers agree that this is a well executed paper, and should be accepted and will make a positive contribution to the conference. In any final version please try to make a connection to the other paper at this conference with the same aims and execution."}, "review": {"H1DccZh8e": {"type": "rebuttal", "replyto": "r16fjx28g", "comment": "Thank you for following up!\n\n- \"When you say \"... when Kl is too much higher than \u03bb, \u03b3 is increased, and when Kl is too low, ...\", how do you determine \"too much\" and \"too low\"? I guess those thresholds are hyperparameters, what kind of values did you try and work for you?\"\nThresholds are hyperparameters and we tried a wide range from 3%~30%, all of which yield improved results. We have added more details to that section (PDF updated).\n\n- \"Also, just to clarify in your previous comment when you say \"experiments in Appendix. C of the latest revision of the paper\", you are in fact referring to Appendix D, right?\"\nYes you are right, thanks for catching that (comment above edited).\n\n", "title": "response"}, "rJZPIswUl": {"type": "rebuttal", "replyto": "BysvGP5ee", "comment": "Dear Reviewers & AC:\n\nWe'd like to thank all the reviewers & commenters for their useful suggestions. By taking into account discussion so far, we have significantly updated the manuscript to address questions/concerns.\n\nMinor clarification questions have been answered in discussion below. Here we summarize the main concerns of reviewers and subsequently explain how our latest revision address these concerns:\n\n*** Larger scale experiments (Reviewer1, Reviewer3)\nThis is the main focus of the latest revision. In Section 4.3 of the latest revision, we have shown:\n1. VLAE has the current best density estimation performance on CIFAR10 among latent-code models. It also outperforms PixelCNN/PixelRNN [1] and is only second to PixelCNN++ [2].\n2. We show several different ways to encode different kinds of information into latent code to demonstrate that one can similarly control information placement on CIFAR10.\n\n*** \"the necessity of \"crippling\" the decoder ... has already been pointed out\" (Reviewer1)\nThanks for making the distinction clear. We have revised relevant text (last paragraph of introduction for example) to highlight that the analysis of \"why crippling is necessary\" is our main contribution as opposed to \"pointing out it's necessary\" [3].\n\n*** \"However, they never actually showed how a VAE without AF prior but that has a PixelCNN decoder performs. What would be the impact on the latent code is no AF prior is used?\" (Reviewer2)\nThanks for your suggestion and we have added related experiments in Appendix. C (edit: should be Appendix. D) of the latest revision of the paper. These experiments show removing AF prior will result in worse performance and make the latent code carry less information.\n\nNext we briefly summarize additional contributions in the latest revision.\n\nIn the initial revision, we hypothesized that by improving VAE training procedure, VLAE's modelling performance can be improved. In initial experiments, we used the \u201cfree-bits\u201d technique [5] and this turned out to create optimization challenges. In the latest revision, we proposed a new technique \"soft free-bits\" (described in Appendix.C) which has resulted in more robust optimization. \n\nWe also investigated replacing ResNet VAEs [4,5] with DenseNet [6] VAEs and this change reduces overfitting. \u201cSoft free-bits\u201d and DenseNet VAEs are novel changes and enable VLAE models to outperform previous latent-code models like ResNet VAE w/ IAF [5] as well as competitive autoregressive density estimators like PixelRNN [1] on CIFAR10. These techniques are not unique to VLAE and we suspect they will also be useful to other types of VAEs.\n\nWe also have added one more way to separate information -- by restricting the PixelCNN decoder to condition only on grayscale image, a lossy latent code can be forced to learn color information.\n\nWe believe we have addressed reviewers' concerns and overall strengthened this submission. We hope reviewers can take a look at the latest revision and possibly adjust rating in light of new evidence.\n\nWe are happy to answer any additional questions!\n\n---------------------------------------------------------\n\nPS: We also plan to include experiments with 64x64 datasets but due to time constraints we haven't been able to finish them in time for inclusion in the current revision. We will include them in a later version and release all code when experiments are finished.\n\n[1]: van den Oord, Aaron, Nal Kalchbrenner, and Koray Kavukcuoglu. \"Pixel Recurrent Neural Networks.\" arXiv preprint arXiv:1601.06759 (2016).\n[2]: https://openreview.net/forum?id=BJrFC6ceg\n[3]: Bowman, Samuel R., et al. \"Generating sentences from a continuous space.\" arXiv preprint arXiv:1511.06349 (2015).\n[4]: Salimans, Tim, Diederik P. Kingma, and Max Welling. \"Markov chain Monte Carlo and variational inference: Bridging the gap.\" International Conference on Machine Learning. 2015.\n[5]: Kingma, Diederik P., Tim Salimans, and Max Welling. \"Improving variational inference with inverse autoregressive flow.\" arXiv preprint arXiv:1606.04934 (2016).\n[6]: Huang, Gao, et al. \"Densely connected convolutional networks.\" arXiv preprint arXiv:1608.06993 (2016).\n", "title": "Rebuttal & revision"}, "HJrDCDeBg": {"type": "rebuttal", "replyto": "SJQg0w84l", "comment": "I'm glad that you like the design principles for lossy coding! The section on autoregressive could indeed use some additional elaboration, which we will probably defer to appendix due to page limit.\n\nAs shown in Eqn 14, an autoregressive flow prior is equivalent to using a simple prior (like factorized gaussian) w/ inverse autoregressive flow approximate posterior + autoregressive generative path. Hence if we are interested in obtaining a simple latent code, we can treat \\epsilon in Eqn 14 as latent code.\n\nIn terms of the costs and potential drawbacks of this approach, the most prominent cost is the slow generation issue that we discussed in Sec 6 due to the sequential nature of autoregressive transformation, which can amount to hundreds of fully connected layers. The interesting thing, however, is that during training only the inverse autoregressive flow is evaluated, which is only a couple fully connected layers: we train on a shallow model (inverse autoregressive flow for inference) but get a much deeper model in effect (autoregressive flow for generation). Since AF prior enhances the generative modeling expressiveness in a way that's similar to using deeper decoder networks, this extra expressiveness will make overfitting more likely if there isn't enough data.\n", "title": "Thanks for your comment"}, "SJQg0w84l": {"type": "rebuttal", "replyto": "BysvGP5ee", "comment": "I greatly enjoyed the bits-back interpretation and the implied design principles for lossy coding.\n\nThe second half of the contribution with autoregressive flow priors seems less appealing. If I understood it correctly, it seems you are effectively performing empirical Bayes estimation over a very complex part of a model instead of more properly Bayesian variational inference. Instead of blindly taking this as an improvement, I would recommend you to also discuss the costs and potential drawbacks of this approach. Being open about what the approach really does would also seem useful.", "title": "Very nice work with the bits-back interpretation, autoregressive priors might need work on presentation"}, "SkCiEOX4l": {"type": "rebuttal", "replyto": "ByPpYGmNx", "comment": "- \"the necessity of \"crippling\" the decoder distribution as to learn any informative latent code has already been pointed out\"\nWe acknowledged that [1,2,3] discussed the phenomenon that the latent code (or part of it) will be ignored when there is a strong decoder distribution and hence either crippling decoder or other tricks like KL annealing or freebits is necessary. The new insight that we offer is \"why this happens\" rather than pointing out \"this phenomenon can happen\". More importantly, this work includes the key discussion that what information will be explained by the decoder distribution and what will be explained by the latent code, which we have not found in literature. We believe that our discussion on lossy coding provides new analysis but again we are happy to include any relevant previous work that we overlooked.\n\nWhile the current revision hasn't reflected this change, the next revision will include discussion of \"word dropout\" as well.\n\n- large-scale experiments\nThe limitation of Omniglot is intentionally shown since the Omniglot experiment uses the same receptive field size as MNIST while this dataset contains meaningful variation that's finer. We can definitely provide additional lossy coding experiments on richer datasets in next revision to show we can similarly control information placement.\nIn addition, spatial locality (limited-depth PixelCNN as decoder) is just one way to construct a lossy code and we used this as an example to illustrate the ideas that we discussed. We believe how to do it differently is an interesting future research direction. \n\nThank you again for participating in this discussion - it's much better than a one-off rebuttal. I hope we will be able to reach an understanding.\n\n[1]: Bowman, Samuel R., et al. \"Generating sentences from a continuous space.\" arXiv preprint arXiv:1511.06349 (2015).\n[2]: S\u00f8nderby, Casper Kaae, et al. \"Ladder variational autoencoders.\" Advances In Neural Information Processing Systems. 2016.\n[3]: Kingma, Diederik P., Tim Salimans, and Max Welling. \"Improving variational inference with inverse autoregressive flow.\" arXiv preprint arXiv:1606.04934 (2016).\n", "title": "Thanks for continuing the discussion!"}, "BybWDlmNl": {"type": "rebuttal", "replyto": "BkB8c0fEe", "comment": "Dear AnonReviewer2,\n\nThank you for your thoughtful review and we are glad that you think learning lossy features that are relevant is important\uff01Below are our answers to your questions:\n\n- \"What would be the impact on the latent code is no AF prior is used?\"\nWe addressed this question indirectly in text \"A similar gain carries over when an autoregressive decoder is used: on statically binarized MNIST, using AF prior instead of IAF posterior reduces train NLL by $0.8$ nat and test NLL by $0.6$ nat.\" And the effect of introducing IAF posterior to a VAE that uses PixelCNN decoder is similar to that of a VAE that uses factorized decoder (Table 1 in [1]). We will address this more directly in next revision by giving direct ablation experiments to show the complementary benefits of both modifications.\n\n- \"The authors mentioned the window can be represented as a small rectangle adjacent to a pixel x_i, must it only contains pixels above and to the left of x_i (similar to PixelCNN)\"\nThe small window will be exacly the local receptive field of a depth-limited PixelCNN. We will include visualizations to make the exact definition used more explicit.\n\n- \"In Equation 8, should there be an expectation over the data distribution?\"\nYes, you are right! It will be fixed in next revision.\n\nThanks again for taking time to review.\n\n[1]: http://papers.nips.cc/paper/6581-improving-variational-autoencoders-with-inverse-autoregressive-flow", "title": "review responses"}, "HkfcDyQEe": {"type": "rebuttal", "replyto": "SJ6Ye6ZNg", "comment": "Dear AnonReviewer3,\n\nThank you for reading our manuscript carefully! Below are some answers to questions in your review. I'd like to also ask a few clarification questions that can help us better prepare next revision:\n\n- \"However, the way this intuition is empirically evaluated is a bit weak .... but such an analysis would have been more compelling with more complex image datasets\"\nDo you want to see qualitative results on colored datasets that have richer variations? We do have some initial results on CIFAR10 that show characteristics qualitatively similar to current binary experiments: global shape being preserved whilst local color patterns and exact details change from one decompression to another. We can also run similar experiments on higher-resolution datasets if this is what you are looking for.\n\n- \"This means that VLAE significantly outperforms the state-of-the-art in only one of the four settings examined.\"\nWe'd like to reiterate that on three out of four settings, we kept the hyperparameters fixed for VLAE and we kept VLAE at a disadvantage to assess its ability to generalize across datasets. We do out-perform previous SOTA (ConvDraw)  on OMNIGLOT, for instance, more significantly when we tune hyperparameters specifically for this dataset. Do you want to see this kind of evaluation?\n\n- \"\"Does a latent representation on top of an autoregressive model help improve the density modeling performance?\" The paper touches this question, but very briefly: the only setting in which VLAE is compared against recent autoregressive approaches shows that it wins against PixelRNN by a small margin.\"\nI apologize for the confusion as the question that we try to ask and answer is \"Does an autoregressive model as decoder help improve latent-code models' density estimation performance\". Since a latent-code model like VAE suffers some penalty in code length for using approximate posterior, PixelCNN/RNN seems to be a better fit for just getting good logprob. Nevertheless, it's usually hard to get good representations from this kind of autoregressive models, unlike latent-code models. We believe part of this work's value is improving density estimation performance for latent-code models specifically.\n\n- \"It is not clear to me that having a very powerful prior is necessarily a good thing .....\"\nA prior that's transformed by an autoregressive flow can indeed become quite complicated and less useful for learning disentangled representations. If we are interested in obtaining a latent code that has factorized distribution, we can treat the noise source \\epsilon in (14) as the true latent code.\n\n- \"weaknesses in the empirical evaluation prevent me from recommending its acceptance.\"\nWe thought the current set of experiments, though on smaller scale datasets, do validate the 3 main contributions that you summarized excellently, but we are definitely open to suggestions. Is there any additional evaluation not covered in questions above that you think is important?\n\nThanks again for your time. I hope that, through more discussion enabled an open review format, we can improve the manuscript to make it more useful to our community.\n", "title": "review responses and questions"}, "H1zKi0G4x": {"type": "rebuttal", "replyto": "rkaibsZ4e", "comment": "Dear AnonReviewer1,\n\nThank you for your thoughtful review! I'd like to ask a few clarification questions that can help us better prepare next revision:\n\n- \"I find that the insights provided in the paper, e.g. with respect to the effect of having a more powerful decoder on learning the latent code, the bit-back coding, and the lossy decoding are well-written but are not novel.\n\"\nI'd like to agree with you that the connection between bits-back coding and variational inference is widely known, as acknowledged in original submission. Nevertheless, to the best of my knowledge, there is no prior work that discusses lossy decoding and information placement. If you could point us to related work, we would include proper citations and discussions.\n\n- \"Larger scale experiments will be necessary.\"\nIs this the main concern you have about the current revision? If so, what kind of evaluations do you want to see on datasets with higher complexity?\n\nThanks again for your time. I hope that, through more discussion enabled an open review format, we can improve the manuscript to make it more useful to our community.\n", "title": "review questions"}, "Sy_6rOR7g": {"type": "rebuttal", "replyto": "rynnuApXx", "comment": "Thanks for your comment!\n\n1.1) Yes, we did experiment with using a PixelCNN with full receptive field and the latent code was ignored (KL(q(z|x) || p(z)) = 0)\n\n1.2) Sorry for not being clear -- when we mention \"receptive field\", we mean the effective receptive field after layers of convolutions as opposed to the receptive field of a single convolution layer. So we are using a PixelCNN that's crippled in receptive field but it can be deep as well by using 1x1 convolutions and channel-wise autoregressive connections [1].\n\n2) You are right that this specific form of whitening is just one possible instantiation of normalizing flows [2]. The reason we use this instantiation is because we found it effective and scalable. Its performance is documented also in [3].\n\n[1]: https://openreview.net/forum?id=BJrFC6ceg\n[2]: Rezende, Danilo Jimenez, and Shakir Mohamed. \"Variational inference with normalizing flows.\" arXiv preprint arXiv:1505.05770 (2015).\n[3]: Kingma, Diederik P., Tim Salimans, and Max Welling. \"Improving variational inference with inverse autoregressive flow.\" arXiv preprint arXiv:1606.04934 (2016).", "title": "response"}, "SJivzuRXe": {"type": "rebuttal", "replyto": "r1WWP8n7e", "comment": "Hi Luke,\n\nThanks for your comment! I believe your paper [1] is the first to systematically document and study the problems that arise from combining a latent code model and an autoregressive model, which is very valuable to our community. In fact, this manuscript's inquiry was partly insipred by the phenomenon noted in your paper: a more powerful decoder will more likely ignore latent code. We conclude with an asymptotic analysis that shows when a decoder is very powerful, latent code is guaranteed to be ignored due to mismatch of approximate posterior. This analysis leads us to structurally weaken decoders to produce desired lossy representations.\n\nIn next revision, we will elaborate on observations made in [1] and include a discussion of the \"word dropout\" technique.\n\n[1]: Bowman, Samuel R., et al. \"Generating sentences from a continuous space.\" arXiv preprint arXiv:1511.06349 (2015).", "title": "response"}, "rynnuApXx": {"type": "rebuttal", "replyto": "BysvGP5ee", "comment": "Hi, I have a few questions:\n\n1) The main argument of the paper is using autoregressive decoder with in variational AE leads to the problem of code part is completely is ignored because the decoder is too powerful. The solution is to depend on a small window instead of all previous data. However, the experiment section does not support this claim: Did you try combining PixelRNN with VAE and find the code has no information (KL near 0)?\n(Although this has been verified in text, text and image are very different and the finding in text does not generalize to image.)\n\nEven for PixelCNN, although it uses a small convolution window, it has a very deep architecture, the x_i may end up depending on all previous x_{<i}. This point was mentioned in the PixlCNN paper. That's why PixelCNN has as good performance as PixelRNN.\n\n2) For the inverse autoregressive flow, z_i = \\frac{y_i - \\mu_i} / \\sigma_i. y is a simple distribution and z is a complex distribution that we want to get through all kinds of transformation of y, why z is called whitening of y, although it is mathematically equivalent to z_i = y_i \\sigma_i + \\mu_i.\n\nThe normalization flow (in Rezende et al 2015 ) z_{t} = f(z_{t-1}, y) is more general than the form z_i = \\frac{y_i - \\mu_i} / \\sigma_i, do you find it performs better? Why?\n\n", "title": "lossy autoencoder"}, "r1WWP8n7e": {"type": "rebuttal", "replyto": "BysvGP5ee", "comment": "Hi, I'm one of the authors of Bowman et al. 2016, and I wanted to point out that while our description of the difficulties in training RNN type models with global latent variables occurs in a section called \"Optimization Challenges,\" we make similar observations as you do in your paper, namely that having a very powerful decoder model like an RNN can result in the model ignoring the global latent variable even at the optimum (perhaps the section should have more generally been called \"Learning Challenges\"). \n\nSpecifically, we found that without using \"word dropout\" in the decoder, which effectively weakens the decoder model and forces the global variable to encode more information, we would not learn a useful latent variable. In our Figure 3, we show the results of using different amounts of word dropout and how the proportional split between the global latent code KL and the p(x|z) likelihood changes, even though the total lower bound always gets worse. This indicates that the word dropout is not simply optimizing the same model better, but is giving us a tradeoff between global and local coding.\n\nWe also note that the factorized p(x|z) used in the independent pixel decoding models of previous work forces the model to use the latent variable to achieve good likelihoods, as you mention in Section 2.2. In fact, because a word-dropout decoder models some things as (randomly) conditionally independent, this is sort of a semi-factored decoding distribution.", "title": "\"Optimization challenges\""}, "SJDJoCjmg": {"type": "rebuttal", "replyto": "HJ748gRMg", "comment": "Thanks for your question! I apologize for the late response due to NIPS.\n\n- did you do a proper hyperparameter search for each model or did you use the same hyperparameters for both experiments?\nWe swept and chose best hyperparameters for the IAF model while working on the camera-ready version of its corresponding paper [1]. We then used the same set of hyperparameters for AF model with little further tweaking.\n\n[1]: Kingma, Diederik P., Tim Salimans, and Max Welling. \"Improving variational inference with inverse autoregressive flow.\" arXiv preprint arXiv:1606.04934 (2016).", "title": "response"}, "ryznY0s7l": {"type": "rebuttal", "replyto": "HkOAj-Rzg", "comment": "Thanks for your questions! I apologize for the late response due to NIPS.\n\n- Have you tried different numbers of dimensions for the latent code?\nWe have tried a couple numbers of dimensions like 16, 32, ... 128. In terms of density estimation, a higher-dimensional latent code usually gives better performance, possibly because optimization is easier in those cases.\n\n- Have you looked at how changing only a particular dimension of the latent code influences the decompressed image?\nWe haven't, however, looked at the case of using an low-dimensional latent codes that have a higher chance of being interpretable. I think investigating interpretable latent codes is a good way to gain more understanding of lossy latent codes and we will perform some experiments with techniques in [1,2].\n\n[1]: Chen, Xi, et al. \"Infogan: Interpretable representation learning by information maximizing generative adversarial nets.\" Advances in Neural Information Processing Systems. 2016.\n[2]: Higgins, Irina, et al. \"Early visual concept learning with unsupervised deep learning.\" arXiv preprint arXiv:1606.05579 (2016).", "title": "response"}, "HkOAj-Rzg": {"type": "review", "replyto": "BysvGP5ee", "review": "Have you tried different numbers of dimensions for the latent code?\nHave you looked at how changing only a particular dimension of the latent code influences the decompressed image?This paper proposes a Variational Autoencoder model that can discard information found irrelevant, in order to learn interesting global representations of the data. This can be seen as a lossy compression algorithm, hence the name Variational Lossy Autoencoder. To achieve such model, the authors combine VAEs with neural autoregressive models resulting in a model that has both a latent variable structure and a powerful recurrence structure.\n\nThe authors first present an insightful Bits-Back interpretation of VAE to show when and how the latent code is ignored. As it was also mentioned in the literature, they say that the autoregressive part of the model ends up explaining all structure in the data, while the latent variables are not used. Then, they propose two complementary approaches to force the latent variables to be used by the decoder. The first one is to make sure the autoregressive decoder only uses small local receptive field so the model has to use the latent code to learn long-range dependency. The second is to parametrize the prior distribution over the latent code with an autoregressive model.\n\nThey also report new state-of-the-art results on binarized MNIST (both dynamical and statically binarization), OMNIGLOT and Caltech-101 Silhouettes.\n\nReview:\nThe bits-Back interpretation of VAE is a nice contribution to the community. Having novel interpretations for a model helps to better understand it and sometimes, like in this paper, highlights how it can be improved.\n\nHaving a fine-grained control over the kind of information that gets included in the learned representation can be useful for a lot of applications. For instance, in image retrieval, such learned representation could be used to retrieve objects that have similar shape no matter what texture they have.\n\nHowever, the authors say they propose two complementary classes of improvements to VAE, that is the lossy code via explicit information placement (Section 3.1) and learning the prior with autoregressive flow (Section 3.2). However, they never actually showed how a VAE without AF prior but that has a PixelCNN decoder performs. What would be the impact on the latent code is no AF prior is used?\n\nAlso, it is not clear if WindowAround(i) represents only a subset of x_{<i} or it can contain any data other than x_i. The authors mentioned the window can be represented as a small rectangle adjacent to a pixel x_i, must it only contains pixels above and to the left of x_i (similar to PixelCNN)\n\nMinor:\nIn Equation 8, should there be an expectation over the data distribution?", "title": "Latent code dimensions and interpretability", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "BkB8c0fEe": {"type": "review", "replyto": "BysvGP5ee", "review": "Have you tried different numbers of dimensions for the latent code?\nHave you looked at how changing only a particular dimension of the latent code influences the decompressed image?This paper proposes a Variational Autoencoder model that can discard information found irrelevant, in order to learn interesting global representations of the data. This can be seen as a lossy compression algorithm, hence the name Variational Lossy Autoencoder. To achieve such model, the authors combine VAEs with neural autoregressive models resulting in a model that has both a latent variable structure and a powerful recurrence structure.\n\nThe authors first present an insightful Bits-Back interpretation of VAE to show when and how the latent code is ignored. As it was also mentioned in the literature, they say that the autoregressive part of the model ends up explaining all structure in the data, while the latent variables are not used. Then, they propose two complementary approaches to force the latent variables to be used by the decoder. The first one is to make sure the autoregressive decoder only uses small local receptive field so the model has to use the latent code to learn long-range dependency. The second is to parametrize the prior distribution over the latent code with an autoregressive model.\n\nThey also report new state-of-the-art results on binarized MNIST (both dynamical and statically binarization), OMNIGLOT and Caltech-101 Silhouettes.\n\nReview:\nThe bits-Back interpretation of VAE is a nice contribution to the community. Having novel interpretations for a model helps to better understand it and sometimes, like in this paper, highlights how it can be improved.\n\nHaving a fine-grained control over the kind of information that gets included in the learned representation can be useful for a lot of applications. For instance, in image retrieval, such learned representation could be used to retrieve objects that have similar shape no matter what texture they have.\n\nHowever, the authors say they propose two complementary classes of improvements to VAE, that is the lossy code via explicit information placement (Section 3.1) and learning the prior with autoregressive flow (Section 3.2). However, they never actually showed how a VAE without AF prior but that has a PixelCNN decoder performs. What would be the impact on the latent code is no AF prior is used?\n\nAlso, it is not clear if WindowAround(i) represents only a subset of x_{<i} or it can contain any data other than x_i. The authors mentioned the window can be represented as a small rectangle adjacent to a pixel x_i, must it only contains pixels above and to the left of x_i (similar to PixelCNN)\n\nMinor:\nIn Equation 8, should there be an expectation over the data distribution?", "title": "Latent code dimensions and interpretability", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "HJ748gRMg": {"type": "review", "replyto": "BysvGP5ee", "review": "In Table 1, when comparing the model with the IAF approximate posterior and the model with the equivalent AF prior, did you do a proper hyperparameter search for each model or did you use the same hyperparameters for both experiments?This paper introduces the notion of a \"variational lossy autoencoder\", where a powerful autoregressive conditional distribution on the inputs x given the latent code z is crippled in a way that forces it to use z in a meaningful way. Its three main contributions are:\n\n(1) It gives an interesting information-theoretical insight as to why VAE-type models don't tend to take advantage of their latent representation when the conditional distribution on x given z is powerful enough.\n\n(2) It shows that this insight can be used to efficiently train VAEs with powerful autoregressive conditional distributions such that they make use of the latent code.\n\n(3) It presents a powerful way to parametrize the prior in the form of an autoregressive flow transformation which is equivalent to using an inverse autoregressive flow transformation on the approximate posterior.\n\nBy itself, I think the information-theoretical explanation of why VAEs do not use their latent code when the conditional distribution on x given z is powerful enough constitutes an excellent addition to our understanding of VAE-related approaches.\n\nHowever, the way this intuition is empirically evaluated is a bit weak. The \"crippling\" method used feels hand-crafted and very task-dependent, and the qualitative evaluation of the \"lossyness\" of the learned representation is carried out on three datasets (MNIST, OMNIGLOT and Caltech-101 Silhouettes) which feature black-and-white images with little-to-no texture. Figures 1a and 2a do show that reconstructions discard low-level information, as observed in the slight variations in strokes between the input and the reconstruction, but such an analysis would have been more compelling with more complex image datasets. Have the authors tried applying VLAE to such datasets?\n\nI think the Caltech101 Silhouettes benchmark should be treated with caution, as no comparison is made against other competitive approaches like IAF VAE, PixelRNN and Conv DRAW. This means that VLAE significantly outperforms the state-of-the-art in only one of the four settings examined.\n\nA question which is very relevant to this paper is \"Does a latent representation on top of an autoregressive model help improve the density modeling performance?\" The paper touches this question, but very briefly: the only setting in which VLAE is compared against recent autoregressive approaches shows that it wins against PixelRNN by a small margin.\n\nThe proposal to transform the latent code with an autoregressive flow which is equivalent to parametrizing the approximate posterior with an inverse autoregressive flow transformation is also interesting. There is, however, one important distinction to be made between the two approaches: in the former, the prior over the latent code can potentially be very complex whereas in the latter the prior is limited to be a simple, factorized distribution.\n\nIt is not clear to me that having a very powerful prior is necessarily a good thing from a representation learning point of view: oftentimes we are interested in learning a representation of the data distribution which is untangled and composed of roughly independent factors of variation. The degree to which this can be achieved using something as simple as a spherical gaussian prior is up for discussion, but finding a good balance between the ability of the prior to fit the data and its usefulness as a high-level representation certainly warrants some thought. I would be interested in hearing the authors' opinion on this.\n\nOverall, the paper introduces interesting ideas despite the flaws outlined above, but weaknesses in the empirical evaluation prevent me from recommending its acceptance.\n\nUPDATE: The rating has been revised to a 7 following the authors' reply.", "title": "Table 1 question", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "SJ6Ye6ZNg": {"type": "review", "replyto": "BysvGP5ee", "review": "In Table 1, when comparing the model with the IAF approximate posterior and the model with the equivalent AF prior, did you do a proper hyperparameter search for each model or did you use the same hyperparameters for both experiments?This paper introduces the notion of a \"variational lossy autoencoder\", where a powerful autoregressive conditional distribution on the inputs x given the latent code z is crippled in a way that forces it to use z in a meaningful way. Its three main contributions are:\n\n(1) It gives an interesting information-theoretical insight as to why VAE-type models don't tend to take advantage of their latent representation when the conditional distribution on x given z is powerful enough.\n\n(2) It shows that this insight can be used to efficiently train VAEs with powerful autoregressive conditional distributions such that they make use of the latent code.\n\n(3) It presents a powerful way to parametrize the prior in the form of an autoregressive flow transformation which is equivalent to using an inverse autoregressive flow transformation on the approximate posterior.\n\nBy itself, I think the information-theoretical explanation of why VAEs do not use their latent code when the conditional distribution on x given z is powerful enough constitutes an excellent addition to our understanding of VAE-related approaches.\n\nHowever, the way this intuition is empirically evaluated is a bit weak. The \"crippling\" method used feels hand-crafted and very task-dependent, and the qualitative evaluation of the \"lossyness\" of the learned representation is carried out on three datasets (MNIST, OMNIGLOT and Caltech-101 Silhouettes) which feature black-and-white images with little-to-no texture. Figures 1a and 2a do show that reconstructions discard low-level information, as observed in the slight variations in strokes between the input and the reconstruction, but such an analysis would have been more compelling with more complex image datasets. Have the authors tried applying VLAE to such datasets?\n\nI think the Caltech101 Silhouettes benchmark should be treated with caution, as no comparison is made against other competitive approaches like IAF VAE, PixelRNN and Conv DRAW. This means that VLAE significantly outperforms the state-of-the-art in only one of the four settings examined.\n\nA question which is very relevant to this paper is \"Does a latent representation on top of an autoregressive model help improve the density modeling performance?\" The paper touches this question, but very briefly: the only setting in which VLAE is compared against recent autoregressive approaches shows that it wins against PixelRNN by a small margin.\n\nThe proposal to transform the latent code with an autoregressive flow which is equivalent to parametrizing the approximate posterior with an inverse autoregressive flow transformation is also interesting. There is, however, one important distinction to be made between the two approaches: in the former, the prior over the latent code can potentially be very complex whereas in the latter the prior is limited to be a simple, factorized distribution.\n\nIt is not clear to me that having a very powerful prior is necessarily a good thing from a representation learning point of view: oftentimes we are interested in learning a representation of the data distribution which is untangled and composed of roughly independent factors of variation. The degree to which this can be achieved using something as simple as a spherical gaussian prior is up for discussion, but finding a good balance between the ability of the prior to fit the data and its usefulness as a high-level representation certainly warrants some thought. I would be interested in hearing the authors' opinion on this.\n\nOverall, the paper introduces interesting ideas despite the flaws outlined above, but weaknesses in the empirical evaluation prevent me from recommending its acceptance.\n\nUPDATE: The rating has been revised to a 7 following the authors' reply.", "title": "Table 1 question", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "rktqM37-e": {"type": "rebuttal", "replyto": "SJmvq87Wg", "comment": "Hi Kundan,\n\nThanks so much for the comment! We have updated the paper draft to reflect correct numbers for \"Discrete VAE\" in tables for dynamically binarized MNIST and statically binarized MNIST.\n\nThanks,\nPeter Chen", "title": "Table 1 fixed"}, "SJmvq87Wg": {"type": "rebuttal", "replyto": "BysvGP5ee", "comment": "Dear authors,\n\nI liked the paper very much and particularly enjoyed the section involving Bits-Back interpretation of VAE.\n\nI just wanted to point out a very minor stuff with your paper. It appears as if you have placed results for dynamically binarized MNIST for \"Discrete VAE\" model in the table for statically binarized MNIST e.g. table 1 in your paper.\n\nThanks,\nKundan", "title": "A comment on table 1 in the paper"}}}