{"paper": {"title": "SQLNet: Generating Structured Queries From Natural Language Without Reinforcement Learning", "authors": ["Xiaojun Xu", "Chang Liu", "Dawn Song"], "authorids": ["xuxiaojun1005@gmail.com", "liuchang@eecs.berkeley.edu", "dawnsong@cs.berkeley.edu"], "summary": "", "abstract": "Synthesizing SQL queries from natural language is a long-standing open problem and has been attracting considerable interest recently. Toward solving the problem, the de facto approach is to employ a sequence-to-sequence-style model. Such an approach will necessarily require the SQL queries to be serialized. Since the same SQL query may have multiple equivalent serializations, training a sequence-to-sequence-style model is sensitive to the choice from one of them. This phenomenon is documented as the \"order-matters\" problem. Existing state-of-the-art approaches rely on reinforcement learning to reward the decoder when it generates any of the equivalent serializations. However, we observe that the improvement from reinforcement learning is limited.\n    \nIn this paper, we propose a novel approach, i.e., SQLNet, to fundamentally solve this problem by avoiding the sequence-to-sequence structure when the order does not matter. In particular, we employ a sketch-based approach where the sketch contains a dependency graph, so that one prediction can be done by taking into consideration only the previous predictions that it depends on. In addition, we propose a sequence-to-set model as well as the column attention mechanism to synthesize the query based on the sketch. By combining all these novel techniques, we show that SQLNet can outperform the prior art by 9% to 13% on the WikiSQL task.", "keywords": []}, "meta": {"decision": "Reject", "comment": "The pros and cons of the paper cited by the reviewers can be summarized as follows:\n\nPros:\n- good problem, NL2SQL is an important task given how dominant SQL is\n- incorporating a grammar (\"sketch\") is a sensible improvement.\n\nCons:\n- The dataset used makes very strong simplification assumptions (that every token is an SQL keyword or appears in the NL)\n- The use of a grammar in the context of semantic parsing is not novel, and no empirical comparison is made against other reasonable recent baselines that do so (e.g. Rabinovich et al. 2017).\n\nOverall, the paper seems to do some engineering for the task of generating SQL, but without an empirical comparison to other general-purpose architectures that incorporate grammars in a similar way, the results seem incomplete, and thus I cannot recommend that the paper be accepted at this time."}, "review": {"B1y7_3YgM": {"type": "review", "replyto": "SkYibHlRb", "review": "This submission proposes a new seq2sel solution by adopting two new techniques, a sequence-to-set model and column attention mechanism. They show performance improve over existing studies on WikiSQL dataset.\n\nWhile the paper is written clearly, the contributions of the work heavily depends on the WikiSQL dataset. It is not sure if the approach is generally applicable to other sequence-to-sql workloads. Detailed comments are listed below:\n\n1. WikiSQL dataset contains only a small class of SQL queries, with aggregation over single table and various filtering conditions. It does not involve any complex operator in relational database system, e.g., join and groupby. Due to its simple structure, the problem of sequence-to-sql translation over WikiSQL is actually simplified as a parameter selection problem for a fixed template. This greatly limits the generalization of approaches only applicable to WikiSQL. The authors are encouraged to explore other datasets available in the literature.\n\n2. The \"order-matters\" motivation is not very convincing. It is straightforward to employ a global ordering approach to rank the columns and filtering conditions based on certain rules, e.g., alphabetical order. That could ensure the orders in the SQL results are always consistent.\n\n3. The experiments do not fully verify how the approaches bring performance improvements. In the current version, the authors only report superficial accuracy results on final outcomes, without any deep investigation into why and how their approach works. For instance, they could verify how much accuracy improvement is due to the insensitivity to order in filtering expressions.\n\n4. They do not compare against state-of-the-art solution on column and expression selection. While their attention mechanism over the columns could bring performance improvement, they should have included experiments over existing solutions designed for similar purpose. In (Yin, et al., IJCAI 2016), for example, representations over the columns are learned to generate better column selection.\n\nAs a conclusion, I find the submission contains certain interesting ideas but lacks serious research investigations. The quality of the paper could be much enhanced, if the authors deepen their studies on this direction.", "title": "The motivation of the work is neither convincing nor verified empirically", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "HksQE4cez": {"type": "review", "replyto": "SkYibHlRb", "review": "The authors present a neural architecture for the WikiSQL task. The approach can be largely seen as graphical model tailored towards the constrained definition of SQL queries in WikiSQL. The model makes strong independence-assumptions, and only includes interactions between structures where necessary, which reduces the model complexity while alleviating the \"order matters\" problem. An attention mechanism over the columns is used to model the interaction between columns and the op or value in a soft differentiable manner. The results show impressive gains over the baseline, despite using a much simpler model. I appreciated the breakdown of accuracy over the various subtasks, which provides insights into where the challenges lie.", "title": "Well motivated and straightforward approach for WikiSQL", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "HkTzAHqxf": {"type": "review", "replyto": "SkYibHlRb", "review": "This paper proposes a neural network-based approach to converting natural language questions to SQL queries. The idea is to use a small grammar to facilitate the process, together making some independence assumptions. It is evaluated on a recently introduced dataset for natural language to SQL.\n\nPros:\n- good problem, NL2SQL is an important task given how dominant SQL is\n- incorporating a grammar (\"sketch\") is a sensible improvement.\n\nCons:\n- The dataset used makes very strong simplification assumptions. Not  problem per se, but it is not the most challenging SQL dataset. The ATIS corpus is NL2SQL and much more challenging and realistic:\nDeborah A. Dahl, Madeleine Bates, Michael Brown, William Fisher, Kate Hunicke-Smith, David Pallett, Christine Pao, Alexander Rudnicky, and Elizabeth Shriberg. 1994. Expanding the scope of the ATIS task: the ATIS-3 corpus. In Proceedings of the workshop on Human Language Technology (HLT '94). Association for Computational Linguistics, Stroudsburg, PA, USA, 43-48. DOI: https://doi.org/10.3115/1075812.1075823\n\n- In particular, the assumption that every token in the SQL statement is either an SQL keyword or appears in the natural language statement is rather atypical and unrealistic.\n\n- The use of a grammar in the context of semantic parsing is not novel; see this tutorial for many pointers:\nhttp://yoavartzi.com/tutorial/\n\n- As far as I can tell, the set prediction is essentially predicted each element independently, without taking into account any dependencies. Nothing wrong, but also nothing novel, that is what most semantic parsing/semantic role labeling baseline approaches do. The lack of ordering among the edges, doesn't mean they are independent.\n\n- Given the rather constrained type of questions and SQL statements, it would make sense to compare it against approaches for question answering over knowledge-bases:\nhttps://github.com/scottyih/Slides/blob/master/QA%20Tutorial.pdf\nWhile SQL can express much more complex queries, the ones supported by the grammar here are not very different.\n\n- Pasupat and Liang (2015) also split the data to make sure different tables appear only in training, dev, test and they developed their dataset using crowd sourcing.\n\n- The comparison against Dong and Lapata (2016) is not fair because their model is agnostic and thus applicable to 4 datasets while the one presented here is tailored to the dataset due the grammar/sketch used. Also, suggesting that previous methods might not generalize well sounds odd given that the method proposed seems to use much larger datasets.\n\n- Not sure I agree that mixing the same tables across training/dev/test is more realistic. If anything, it assumes more training data and manual annotation every time a new table is added.", "title": "Re-positioning with respect to the literature is needed", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "S1LubAnQz": {"type": "rebuttal", "replyto": "ryjOuKfQG", "comment": "We apologize for misunderstanding the comments. We are aware of the WikiTableQuestion task as well. However, it is a question-answering task, rather than a query-generation task. We have explained in previous responses why we prefer query-generation over touching the data directly. This is also why we thought the overnight dataset was referred to before, since overnight is a query-generation dataset.\n", "title": "Responses to feedbacks part2 from Reviewer A"}, "HykdZyNmz": {"type": "rebuttal", "replyto": "HyrNZJ4mM", "comment": "Fourth, we acknowledge of the QA task studied in Sun et al 2016, and they are very important. However, as we mentioned, their approaches need to touch the data to propose candidate answers first and then rank the answers directly. However, the applications that we care most are in the enterprise setting dealing with user\u2019s private data. One such scenario is described in the Uber study (Johnson et al. 2018). Therefore, we focus on query generation rather than question answering.\n\nHaving said this, we acknowledge the concerns from the reviewer that such an approach will have the limitation that the values must appear as a substring of the description, and we have stated it clearly in Section 2. However, we argue that touching the data directly is not ideal due to the privacy concern. In our agenda, we plan to study the propose-repair scheme to mitigate this issue. That is, we can generate a query based on the description, and query the database, and revise the query. Such an approach is similar to the PL-approach such as SQLizer. Note that in this process, querying the database may still leak private information. However, we can apply the approach proposed by Johnson et al. 2018 to automatically convert a SQL query into a differentially private one so that the information leakage can be mitigated. Such a paradigm is much better than QA directly with respect to the privacy concern.\n\nWith respect to the scalability issue, our target application scenarios may contain billions of records in a database (e.g., the Uber study in Johnson et al. 2018). A model handling such large-scale datasets typically special designs. In a SQL query synthesis setting, we do not think such a burden is necessary, and thus we prefer synthesizing SQL queries directly from description and schema, without touching the data. We want to also emphasize that WikiSQL does not reflect the scale of the target applications in our mind, but its problem setup automatically makes the database scale not an issue since, during query generation, the data in the table is not touched.\n", "title": "Responses to feedbacks from Reviewer A (Part 2)"}, "HyrNZJ4mM": {"type": "rebuttal", "replyto": "B1SI_FfQz", "comment": "Thanks a lot for the further feedback! We have uploaded a further revision to reflect our responses. More feedbacks are welcome, and we would be happy to address as many of them as possible before the end of the discussion period.\n\nFirst, we have changed the example to the following one:\nQuestion: Which country is Jim Les from?\nSQL query: SELECT Nationality WHERE Player \uff1d Jim Les\n\nIn this example, the column name \u201cnationality\u201d is not a simple rename of any utterance in the description. There have been several others, for example:\nQuestion: What is the green house made of?\nSQL query: SELECT Composition WHERE Colours = green\n\nThese examples should justify our argument that the column names are not a substring of the original statement. Note, our model can correctly process these examples.\n\nSecond, \u201cgrammar based semantic parsing seems to be also important enough previous work to be acknowledged and cited.\u201d We cite a few more papers:\n\nMaxim Rabinovich, Mitchell Stern, Dan Klein, Abstract Syntax Networks for Code Generation and Semantic Parsing, EMNLP 2017\nParisotto, Emilio, et al. Neuro-symbolic program synthesis, ICLR 2017\n\nWe think these are the most relevant approaches, which are quite similar to Seq2SQL baseline. In fact, we can view Seq2SQL as a modification of these works by incorporating the pointer network for value prediction. We are happy to cite more papers that the reviewer would suggest.\n\nThird, thanks for the pointer to the 2006 paper! However, we would like to argue that the SCFG used in (Wong 2006) is quite different than the sketch (or CFG) used in our work, and constructing an SCFG requires much more efforts. \n\nIn fact, an SCFG production rule is of the form NT -> (A, B), where A and B indicate rules in the source and target language respectively. In the semantic parsing setting, A is the natural language and B is SQL. This means that such a rule is essentially a translation rule to say that every natural sentence A should be translated into B. Therefore, constructing an SCFG is essentially not only constructing the grammar B, but also constructing a formal grammar for natural language A and the translation rule from A to B, which is highly non-trivial.\n\nIn our sketch-based approach, we only need the grammar B, but NEITHER the grammar for A NOR the translation rule from A to B. Further, grammar B is typically already available, since B is a programming language, i.e., SQL. Therefore, to apply our approach, we only need to construct a dependency graph for a SQL sub-grammar, which requires not many efforts. This makes our approach much more practical than SCFG-based approaches such as Wong (2006). We want to note that constructing an SCFG, which requires constructing a set of translation rules and a manually designed alignment approach (as in Wong 2006), is a non-trivial work, and we find it hard to justify why such an approach serves a more reasonable baseline than Zhong et al 2017.\n\nHaving said this, we acknowledge the concerns from Reviewer A that more baselines should be compared. We will examine Seq2seq, seq2tree, and abstract syntax network, which are likely the state-of-the-arts on parsing and semantic parsing. The time may not be sufficient before the rebuttal period, but we guarantee that our best results of these approaches will be provided in the final version. Based on our existing experience, these approaches are unlikely to outperform Zhong et al 2017.\n", "title": "Responses to feedbacks from Reviewer A (Part 1)"}, "rJP3AS0fM": {"type": "rebuttal", "replyto": "B1y7_3YgM", "comment": "We thank the reviewers for the valuable comments. We would like to clarify some clear misunderstandings and highlight the differences in our revisions.\n\nWe agree with the reviewer that this work focus on the WikiSQL dataset. This is because this is the only largest scale dataset that is close to a practical application scenario to the best of our knowledge. In our revision, we cite one recent case study on 8.1 million real-world SQL queries written by uber data analysts (Johnson 2017). They show that almost 40% of all these queries (1) involve only table; and (2) each WHERE constraint involves only one column. They do not contain join at all. This is exactly the same as the queries proposed in WikiSQL. On the other hand, this problem is not trivial, since we can see even our new state-of-the-art\u2019s performance is less than 70%. By showing these two points, we believe we are dealing with a meaningful problem which is not trivial to tackle. \n\nTo all other datasets, such as atis-3 mentioned by Reviewer A or the dataset used in (Yin, et al., IJCAI 2016), they suffer one or more problems discussed in Section 2 which render them not practical, and thus not an ideal target of our study.\n\nWe include one more section in our evaluation to document the order-matters phenomenon. In particular, we want to emphasize that WikiSQL is already employing a global ordering, but the columns may appear in the natural language statement in an arbitrary order. For example, we include the following example in our revision:\nNL:  What are the seasons when twente came in third place and ajax was the winner?\nSQL: SELECT season WHERE winner = ajax AND third place = twente\n\nWe can observe that the statement \u201ctwente came in third place\u201d and \u201cajax was the winner\u201d appear in the reverse order of the global order of the two columns \u201cwinner\u201d and \u201cthird place\u201d. This is the ``order-matters\u201d issue we discuss. However, this issue cannot be solved by changing the global order of the two columns, since the human users should also be allowed to state:\n\u201cWhat are the seasons when ajax was the winner and twente came in third place?\u201d\nNo matter what global order is used, one of these two statements will cause the ``order-matters\u201d issue. As far as we can see, the only way to mitigate this issue is to restrict human users to state their goals following the global order. Again, doing so will render the dataset artificial and not practical.\n\nWe are very confused about the reviewer\u2019s comment \u201cThe experiments do not fully verify how the approaches bring performance improvements\u201d. In fact, the entire Section 4.3 is devoted to an ablation study to show the improvements brought by each component. In particular, the SQLNet (seq2set) shows the accuracy improvement due to the insensitivity to order. In our revision, we add Sec 4.4 to provide one more section to even further understand the effectiveness due to \u201corder-matters\u201d issue.\n\nSeq2SQL is the state-of-the-art on the WikiSQL dataset, and we have compared against it. Yin et al 2016 is not suitable for the WikiSQL task since their approach needs to take the data in the table as a part of the input. We have argued that this is not a scalable approach and may also have privacy issue. We have discussed this in Section 2.\n\nWe hope the reviewer can clarify some of the earlier comments with respect to our clarification. We are also welcome more comments.\n", "title": "Response to AnonReviewer3"}, "SkkIarCfz": {"type": "rebuttal", "replyto": "HksQE4cez", "comment": "We thank the reviewer\u2019s comment. We have updated the paper to address some comments raised in all reviews. We have posted a separate comment for a highlight overview of revision, and updated the paper. Please take a look and see if there are any comments that we should address further. More feedbacks are welcome!", "title": "Response to AnonReviewer2"}, "BkOfprAzG": {"type": "rebuttal", "replyto": "HkTzAHqxf", "comment": "We appreciate reviewers\u2019 valuable comments, and we have improved our paper to address some of the concerns. We find that most comments on the novelty are to some points that we do not claim as our contribution (e.g., the WikiSQL task itself is not our contribution at all). We clarify some of such confusions below, and hope the reviewers can provide more feedback to help us to improve our paper.\n\nFirst, the reviewer mentioned ATIS-3. We agree with the reviewer that atis-3 is much more challenging than WikiSQL. But we want to emphasize that we choose the problem not simply based on its difficulty, but also based on its practical impact. In our revision, we cite one recent case study on 8.1 million real-world SQL queries written by uber data analysts (Johnson 2017). They show that almost 40% of all these queries (1) involve only one table; and (2) each WHERE constraint involves only one column. This is exactly the same as the queries proposed in WikiSQL. On the other hand, this problem is not trivial, since we can see even our new state-of-the-art\u2019s performance is less than 70%. By showing these two points, although we are not solving a challenging problem as 'NP vs P', we believe we are dealing with a meaningful problem which is not trivial to tackle.\n\nOn the other hand, although atis-3 is more challenging, we observe that its dataset is small by the deep neural network standard. This is one additional reason why we prefer WikiSQL.\n\nThe reviewer mentioned: \u201cIn particular, the assumption that every token in the SQL statement is either an SQL keyword or appears in the natural language statement is rather atypical and unrealistic.\u201d We want to emphasize that this is NOT true. We only assume the value in the query must appear in the description to make the problem amenable, but we do not assume the column names appear in the description. \n\nFor the constraints on the values, we agree that further efforts need to devote to making a better dataset. But we do not see the problem is overly simplified as discussed above.\n\nNext, the reviewer mentioned: \u201cThe use of a grammar in the context of semantic parsing is not novel\u201d. We agree with the reviewers, and we also didn\u2019t claim using a grammar is our contribution. At the end of the introduction, we highlight the three contributions of this work: (1) seq2set; (2) column attention; (3) achieving the state-of-the-art on WikiSQL.\n\nWe do not follow very clearly about the comments \u201cthe set prediction is essentially predicted each element independently, without taking into account any dependencies\u201d. Clearly, predicting the value in one constraint in the WHERE clause depends on the column selected in a previous step. Also, it is mentioned that \u201cnothing novel\u201d and \u201cthis is most \u2026 baselines do\u201d. We would highly appreciate it if the reviewer could provide some references. To the best of our knowledge, some typical baseline approaches such as Seq2tree has been demonstrated ineffective on this Wikisql dataset in Zhong et al. 2017.\n\nThe reviewer mentioned QA tasks. First, since QA has been studied over decades and many QA tasks have been proposed (and mentioned in the slides), we would appreciate it if the reviewer can point out the particular one that is relevant. Second, in our understanding, most existing works on KB-based QA will take the entire KB as an input to answer a question. We have argued in our paper why we do not prefer such a problem: the KB can be too huge or contain privacy-sensitive information, and thus generating the query without touching the data itself is an important factor for practical usages. Again, WikiSQL task is more suitable to such a requirement than previously proposed tasks involving data itself.\n\nFor the overnight dataset (Pasupat and Liang 2015), it is not true that the schemas from train/dev/test are non-overlapping. We quote the statement from (Pasupat and Liang 2015):\n\u201cFor each domain, we held out a random 20% of the examples as the test set, and performed development on the remaining 80%, further splitting it to a training and development set (80%/20%). We created a database for each domain by randomly generating facts using entities and properties in the domain (with type-checking).\u201d\nHere, each domain is one schema. Also, the novelty of WikiSQL over Overnight is not the problem that we want to address in our paper.\n\nWe are not comparing against Seq2tree (Dong et al 2016), which was originally compared in Zhong et al 2017. We only compare to the Seq2SQL which is the state-of-the-art on the WikiSQL dataset. Again, as we discussed above, our work is focusing on the WikiSQL dataset itself, since we believe that is an important, though somehow narrow, task.\n\nJohnson et al,  Practical differential privacy for SQL queries using elastic sensitivity. to appear in VLDB 2017.\n", "title": "Response to AnonReviewer1"}, "ByNjir0Mf": {"type": "rebuttal", "replyto": "SkYibHlRb", "comment": "We have improved our paper with the following revision:\nWe have added more discussions in Section 2 to explain why WikiSQL is a more meaningful and challenging task that is more practical than previous datasets, as part of our explanation why our work, dealing with WikiSQL, is a meaningful contribution.\nWe have added a separate subsection (Section 4.4) to document our study on the 'order-matters' issue, and we also explain why this is not a specific issue in WikiSQL but a general issue that may be encountered in all other tasks. We also provide more detailed analysis to show how our seq2set technique helps to mitigate this issue.\n", "title": "Our latest revision"}}}