{"paper": {"title": "End-To-End Input Selection for Deep Neural Networks", "authors": ["Stefan Oehmcke", "Fabian Gieseke"], "authorids": ["stefan.oehmcke@gmail.com", "fabian.gieseke@di.ku.dk"], "summary": "We propose a framework that automatically learns to select the relevant parts of the input data for a given neural network and its task.", "abstract": "Data have often to be moved between servers and clients during the inference phase. This is the case, for instance, when large amounts of data are stored on a public storage server without the possibility for the users to directly execute code and, hence, apply machine learning models. Depending on the available bandwidth, this data transfer can become a major bottleneck. We propose a simple yet effective framework that allows to select certain parts of the input data needed for the subsequent application of a given neural network. Both the associated selection masks as well as the neural network are trained simultaneously such that a good model performance is achieved while, at the same time, only a minimal amount of data is selected. During the inference phase, only the parts selected by the masks have to be transferred between the server and the client. Our experiments indicate that it is often possible to significantly reduce the amount of data needed to be transferred without affecting the model performance much.", "keywords": ["Deep Learning", "Input Selection", "Gumbel Softmax Trick", "Remote Sensing", "Feature Selection"]}, "meta": {"decision": "Reject", "comment": "This paper proposes to address the high bandwidth cost when transferring data between server and user for machine learning applications. The input data is augment with channel and spatial mask so that the file transfer cost is reduced. While the reviewers agree that this is a well motivated and interesting problem to study, a number of concerns are raised, including loosely specified performance/size trade-off, how this work is compared to related work, low novelty relative to a few key missing references. The authors respond to Reviewers\u2019 concerns but did not change the rating. The ACs concur the concerns and the paper can not be accepted at its current state."}, "review": {"ByeiFD69iB": {"type": "rebuttal", "replyto": "BklJZax5jS", "comment": "As mentioned, we also did the pixel-wise selection (any-mask) and stopped at 50 pixel (loss Q of 0.0638). We now have the results for Fashion-MNIST and without any fixation afterwards, we achieved 85.7% accuracy compared to 67.7% in [1].\n\nWe would like to stress that this task only covers a subset of our frameworks capabilities (any-selection pixel-wise) and  a comparison to [1] is complicated:\n- We are using an end-to-end supervised/task-dependent approach with an any-mask with 28x28 learnable parameters and an out-of-the-box LeNet5 (431080 learnable parameters) as classifier.\n- [1] select  50 pixel (with no spatial information intact) in an unsupervised/task-independent way with an Auto-Encoder-like architecture and then trains a Random Forest as classifier on the selected features.\n", "title": "New results for Fashion-MNIST"}, "Hkxcppxqir": {"type": "rebuttal", "replyto": "SJgDHU86FS", "comment": "Thank you very much for your comments and suggestions and apologies for the slight delay; our response has been delayed due to personal reasons. \n\n\nConcern: \n\u201cAll presented results are learning curves, but there are no clear final numbers.\u201d\n\nAnswer: \nThis is on purpose, since we do not want to choose a specific amount of features/options to select, but rather optimize and then pick the trade-off that the practitioner deems reasonable (and maybe fixate the model for that state a bit more).\n\n\nConcern: \n\u201cHow does random selection of channels perform?\u201d\n\nAnswer: \nWe did random selection as a preliminary study and it performed worse with decreasing number of selected channels (for channel-wise selection) and a high number of channels. We have included these results in the updated version of our manuscript.\n\n\nConcern: \n\u201cThe pixel selection task (4.2) is simplistic.\u201c\n\nAnswer: \nThe pixel selection mask allows to select the optimal amount (!) of pixels needed for a given task; typically, it is not clear a priori how large such a cloud of pixels has to be, and our framework allows to optimize for this size. \nFurther, In this paper we focus on a static mask after training and no individual mask for each instance (since no further calculation are possible on the data server). Nevertheless, future work could include this option.\n\n\nConcern: \n\u201cFeature map selection (4.3, channel 'xor') could be likely solved with hyper-parameter search\u201d\n\nAnswer: \nThe channel selection task is most important for non-standard imagery, for example, satellite images with many channels or selection of different quality levels (select different compression algorithms). Another advantage is that we do not need to perform hyperparameter searches that might not account for dependencies between choices (e.g., if we take away one channel, we might take a complete other set of pixel, or vise versa).\n\n\nConcern: \n\u201cthe author could additionally mention distillation\u201d\n\nAnswer: \nWe added distilling of networks to our references, although we are more concerned with the input masking and not with the training of the predictor network (this could be used together though).\n\n\nConcern: \n\u201cGumbel noise is only applied to half the inputs\u201d \n\nAnswer:\nCould you please specify this? We apply Gumbel noise to all selections while training in the exploration phase.\n\n\nConcern: \n\u201cThe binary variant of Gumbel-softmax (\u2026) could be used\u201d\n\nAnswer: \nThe binary variant is used in implementation for the \u2018any\u2019 masks, but we wanted to keep the manuscript coherent since it is theoretically the same.\n", "title": "Rebuttal for Review #1"}, "Byg88pl5ir": {"type": "rebuttal", "replyto": "H1lFl73pKS", "comment": "Apologies for the slight delay; our response has been delayed due to personal reasons. Thank you very much for your insightful review.\n\n\nConcern:\n\u201cA discussion on the connection/comparison with representation learning and dimensionality reduction (VAEs, quantization, etc) would help improve the exposition of the paper\u201d\n\nAnswer: \nWe do representation learning as in the general term that we learn a selection of features or quality levels, but we assume that no additional computations, such as VAE or similar can be performed on the data server.\nWe added a distinction between dim. red. and feature selection to the manuscript.\nIn short:\nDim. reduction (VAEs, PCA, etc.) yields features in a lower dimensionality, but such methods do not \u201csave\u201d on features since every feature is used even if only to a small amount and change the structure of the data (e.g. from image to vector data). \nIn addition, these methods are unsupervised and not task depending compared to our framework. \nFeature selection takes a pre-defined subset of the features (e.g. k out of d), but our approach decreases this k on its own and we can pick the best trade-off between prediction performance and feature cost.\nIt is worth stressing that our framework jointly learns a selection of the data without changing its structure and the necessary adaptation to given neural network structure (original networks can be reused).\n\n\nConcern:\n \u201cI would like to see an experiment that compares other works mentioned as related work. [4] has been mentioned as one of the nontrivial compression methods for image data, how does the proposed method compare to it?\u201d\n\nAnswer: \nThe work in [4] is a compression framework, whereas our approach is feature selection, which makes a comparison infeasible. That said, the representation from [4] could be another option to choose from when selecting pixel (e.g. choices could be RGB from original, JPEG, and [4]), one only needs to assign weights to the representations and check if the the compute resources are available on the data server (which we do not assume).\n\n\nConcern:\n\u201cPlease include reference accuracy values for the dataset/NN pairs used in Table 1.\u201d\n\nAnswer: \nWe haven\u2019t added those numbers yet due to space constraints, but this information is present in all plots as the initial evaluation (epoch 0) is done with the original network without any masking (loss Q=1).\n\n\nConcern: \n\u201cIn Section 4.5, the paper states that large lambda values correspond to blue and red lines \u2026\u201d\n\nAnswer: \nThank you for point out this issue! Yes, there was a mix-up in the plot, which we have have already adjusted.\n", "title": "Rebuttal for Review #3 "}, "BklJZax5jS": {"type": "rebuttal", "replyto": "rJgm2PsCFB", "comment": "Apologies for the slight delay; our response has been delayed due to personal reasons. Thank you very much for your in-depth review and comments.\n\n\nConcern: \n\u201cHardly any technical novelty because the core ideas are already presented as well as applied to the same task in [1]. It is very surprising that the authors do not even cite [1] in their paper, despite their work being extremely closely related to it. Most of the discussion in the Related Work section is unrelated to the specific task\u201d\n\nAnswer:\n We would like to stress that we were not aware of [1] at the time of finalizing our work, which we submitted to NeurIPS on May 23 this year (and which was considered borderline with scores of 6, 7, and 4). The corresponding draft was made available after the submission on Arxiv (using a slightly different title, which we do not reveal here due to the double blind review process).\n\nWe have added [1] as well as [2] and [3] to the related work section of our manuscript. While [1] is related to our work, we would like to point out the following differences:\n\nOur framework resorts to selection masks, which can be adapted to the specific needs of the server/client capabilities. The masks can be used to enforce various additional constraints such as channel-wise selections. This is, in our opinion, a novel and original contribution.\n[1] requires the hyperparameter k to be pre-defined, while our approach is dynamic in a way that it reduces the amount of used features on its own, which could be more interesting if one is looking for the best performance/selection compromise.\nSince k is static, the network that follows cannot be (to our knowledge) convolutional, which limits the approach to fully connected networks. Furthermore, pre-trained networks are also not usable.\n\n\nConcern: \n\u201cThe authors do not compare their approach against any existing baselines from literature for this task, again with the most apt being [1] and baselines therein.\u201d\n\nAnswer:\nThe two approaches are hard to compare since we do not select k features, but our mask model removes features on its own (maybe skipping k) going from all features or highest quality features (e.g. original image instead of jpeg version) to fewer and fewer.\nFurthermore, since we replace values not selected by zero, we are able to use pre-trained weights and convolutional networks instead of relying on fully connected networks that need to be trained from scratch and with no spatial information intact meaning the architectures are not necessarily comparable.  Nevertheless, we have conducted experiments on MNIST (not pre-trained weights) and compared the accuracy at k=50 (as in used in [1]) without any fixation phase and achieved 97.85% compared to the reported 90.6%. We would be happy to add these results as well as corresponding experiments on Fashion-MNIST.", "title": "Rebuttal for Review #2"}, "H1lFl73pKS": {"type": "review", "replyto": "HkgbKaEtvB", "review": "The paper addresses the problem of high-cost transfer between server and user for machine learning applications. The method proposes to augment inputs with channel/spatial masks that are trained via the Gumbel-softmax trick together with the model's weights trained/finetuned to account for the loss of information. These learned masks are then applied to the image before sending it to a server with where inference takes place to reduce file transfer costs. In the experimental study, the paper shows that on computer vision tasks inputs can be reduced with relatively little drop in accuracy and analyses how hyperparameters of the model affect its performance. The framework is also adapted to the downstream task-guided choice of compression techniques, e.g. which compression quality to choose for JPEG that will be an optimal trade-off in terms of downstream task quality vs data transfer cost.\nOverall, this paper could be a valid algorithmic contribution, however, I have concerns about how this method fares with others, resolving the following issues in the author response will likely increase the score.\n- A discussion on the connection/comparison with representation learning and dimensionality reduction (VAEs, quantization, etc) would help improve the exposition of the paper and help define how and when the suggested method is more appropriate to use, as well as citations to the other lines of work in reducing the model size (knowledge distillation [1], tensor decomposition approaches [2], adaptive computation time techniques [3], etc).\n- I would like to see an experiment that compares other works mentioned as related work. [4] has been mentioned as one of the nontrivial compression methods for image data, how does the proposed method compare to it?\n- Another experiment comparing a method from representation learning, e.g. a VAE trained with the embedding size corresponding to some optimal Q value in this work would be helpful.\n- Please include reference accuracy values for the dataset/NN pairs used in Table 1.\n- In Section 4.5, the paper states that large lambda values correspond to blue and red lines, however in the corresponding figure large lambda values correspond to blue and orange lines which exhibit different behaviors, could you please clarify this?\n\nReferences\n[1] Hinton, Geoffrey, Oriol Vinyals, and Jeff Dean. \"Distilling the knowledge in a neural network.\"\n[2] Novikov, Alexander, et al. \"Tensorizing neural networks.\" Advances in neural information processing systems. 2015.\n[3] Figurnov, Michael, et al. \"Spatially adaptive computation time for residual networks.\" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017.\n[4] Jiang, Feng, et al. \"An end-to-end compression framework based on convolutional neural networks.\" IEEE Transactions on Circuits and Systems for Video Technology 28.10 (2017): 3007-3018.", "title": "Official Blind Review #3", "rating": "3: Weak Reject", "confidence": 2}, "SJgDHU86FS": {"type": "review", "replyto": "HkgbKaEtvB", "review": "The authors argue that data transfer costs for ML inference may be significant in some scenarios, such as for remote sensing. They propose to jointly train a model to maintain good performance while significantly reducing input size by applying a global mask. To allow training with discrete masks, the Gumbel-softmax trick is used. The experiments cover multiple datasets and multiple types of mask. Generally, performance remains reasonably high and degrades gracefully as the input is increasingly masked.\n\nI lean slightly towards rejecting the paper. The problem is interesting and potentially important, but many experiments are  too simplistic and lack strong baselines.\n\nI believe the problem is well motivated, but not very much explored yet. There has been much work on reduce ML system computation costs and memory storage requirements, but mostly by modifying the model instead of the data. The paper proposes a reasonable approach to reduce data transfer costs.\n\nThe authors propose 4 types of masks (channel/any, channel/xor, pixel/any, pixel/xor), which are applicable under different circumstances. Some of them may also be combined. To learn discrete masks, they apply the Gumbel-softmax trick. Results clearly show that learning discrete masks (reducing input size) while maintaining decent performance is feasible .\n\nAs the objective function is modified during training by adjusting \\lambda, the performance/size trade-off is only loosely specified. All presented results are learning curves, but there are no clear final numbers.\n\nThe channel selection task (4.1) is potentially interesting, but lacks a baseline. How does random selection of channels perform?\n\nThe pixel selection task (4.2) is simplistic. Using a cloud of pixels near the center of the images appears sufficient, which could be inferred by looking at a few samples and doesn't necessarily necessitate learning. Could the approach be extended to more complex images, predicting one mask per image instead of a global mask?\n\nFeature map selection (4.3, channel 'xor') could be likely solved with hyper-parameter search, especially if the number of channels is small. Section 4.4 combines the previous two subsections, and it is unclear how much we gain from learning the masks over using simple heuristics.\n\nMore minor points:\n\nIn the related work section, the author could additionally mention distillation.\n\nThe Gumbel noise is used on half of the inputs, while the current argmax is used otherwise. It is unclear whether this is necessary, and there are no related experiments.\n\nAlthough this is not crucial, for the 'any' variants, the last mask dimension appears superfluous (2-class softmax). The binary variant of Gumbel-softmax (Maddison et al. The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables, Appendix B) could be used.", "title": "Official Blind Review #1", "rating": "3: Weak Reject", "confidence": 2}, "rJgm2PsCFB": {"type": "review", "replyto": "HkgbKaEtvB", "review": "The paper presents an approach to discrete input selection for NNs, using the Gumbel-Softmax trick at its core. It motivates this problem in the context of communicating data over a network with limited bandwidth budget. It proposes constructing different kinds of masks that can be applied over channels or pixels in the input, grounding the discussion in the image domain. This can be seen as a special case of Feature Selection, with image specific substructures motivating the choice of mask types. \n\nThere is very little novelty in this work over that presented in Abubakar Abid et. al. [1], where the idea of using Gumbel-Softmax as a differentiable Feature Selection algorithm has already been expounded at depth, both in unsupervised as well as supervised settings. The current work draws directly from the supervised form in [1]. The only incremental contribution in this work is the specific mask types and mask-specific losses.\n\nPros\n\u2022\tInteresting approach to extend the framework in [1] to CNNs, with use of masks and mask-specific loss\n\u2022\tClear motivation for the network bandwidth limited use case\n\nCons\n\u2022\tHardly any technical novelty because the core ideas are already presented as well as applied to the same task in [1]\n\u2022\tIt is very surprising that the authors do not even cite [1] in their paper, despite their work being extremely closely related to it\n\u2022\tMost of the discussion in the Related Work section is unrelated to the specific task they tackled in the paper (i.e., input/feature selection). The second paragraph in this section talks about \u2018gradient-driven search\u2019 for discrete selection, which has been recently explored not only in [1] but also related G-S applications like [2], [3], but the authors seem unaware of this line of works\n\u2022\tThe authors do not compare their approach against any existing baselines from literature for this task, again with the most apt being [1] and baselines therein. This makes it hard to understand the true value of their proposals such as mask types, schedule that adjusts both \u2018tau\u2019 and \u2018lambda\u2019 during training etc.\n\n[1] Abubakar Abid et al., \u201cConcrete Autoencoders for Differentiable Feature Selection and Reconstruction\u201d, ICML 2019, (https://arxiv.org/abs/1901.09346)\n[2] Hanxiao Liu et al., \u201cDARTS: Differentiable Architecture Search\u201d, ICLR 2019\n[3] Bichen Wu et al., \u201cFBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search\u201d CVPR 2019\n", "title": "Official Blind Review #2", "rating": "3: Weak Reject", "confidence": 2}}}