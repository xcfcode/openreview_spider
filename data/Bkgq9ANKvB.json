{"paper": {"title": "Peer Loss Functions: Learning from Noisy Labels without Knowing Noise Rates", "authors": ["Yang Liu", "Hongyi Guo"], "authorids": ["yangliu@ucsc.edu", "guohongyi@sjtu.edu.cn"], "summary": "This paper introduces peer loss, a family of loss functions that enables training a classifier over noisy labels, but without using explicit knowledge of the noise rates of labels.", "abstract": "Learning with noisy labels is a common problem in supervised learning. Existing approaches require practitioners to specify noise rates, i.e., a set of parameters controlling the severity of label noises in the problem. In this work, we introduce a technique to learn from noisy labels that does not require a priori specification of the noise rates. In particular, we introduce a new family of loss functions that we name as peer loss functions. Our approach then uses a standard empirical risk minimization (ERM) framework with peer loss functions. Peer loss functions associate each training sample with a certain form of \"peer\" samples, which evaluate a classifier' predictions jointly. We show that, under mild conditions, performing ERM with peer loss functions on the noisy dataset leads to the optimal or a near optimal classifier as if performing ERM over the clean training data, which we do not have access to. To our best knowledge, this is the first result on \"learning with noisy labels without knowing noise rates\" with theoretical guarantees. We pair our results with an extensive set of experiments, where we compare with state-of-the-art techniques of learning with noisy labels. Our results show that peer loss functions based method consistently outperforms the baseline benchmarks. Peer loss provides a way to simplify model development when facing potentially noisy training labels, and can be promoted as a robust candidate loss function in such situations. ", "keywords": ["learning with noisy labels", "empirical risk minimization", "peer loss"]}, "meta": {"decision": "Reject", "comment": "Thank you very much for the detailed feedback to the reviewers, which helped us better understand your paper.\nThanks also for revising the manuscript significantly; many parts were indeed revised. \nHowever, due to the major revision, we find more points to be further discussed, which requires another round of reviews/rebuttals.\nFor this reason, we decided not to accept this paper.\nWe hope that the reviewers' comments are useful for improving the paper for potential future publication.\n"}, "review": {"BJlM6AygoS": {"type": "rebuttal", "replyto": "r1esAQqrtB", "comment": "We thank the reviewer for detailed comments, and for providing pointers to the more recent literature. We want to clarify our motivation, novelty and significance. We do think the reviewer might have missed the main novelty and contribution of peer loss in that peer loss operates without the need of estimating the transition matrix T.\n\nReference: \n\nWe apologize for not surveying sufficiently the most recent results. We wanted to focus on comparing with the more classical results. We are working on an updated related work section based on the reviewer\u2019s and Nontawat\u2019s comments. We thank the reviewer for relevant pointers. \n\n\nMotivation: \n\nWhen we claim \u201cexisting approaches require practitioners to specify noise rates\u201d, it includes the cases when the transition matrix T need to and can be estimated. Probably our claim was not clear - we wanted to say that these existing methods require *explicit* knowledge of T, so in practice, the practitioners will need to estimate these Ts and plug in. We are indeed aware of these line of work. But this was exactly one of our main motivations! We felt this requirement of additional estimation steps might complicate the learning process, and the additional errors introduced via learning these parameters are concerning too.\n\nPeer loss does *not* require the knowledge or estimation of these Ts, and operates without the need of *specifying* the noise rates. We now start to think that a better way to position our paper is to say we contribute to \u201clearning with noisy labels without specifying the error rates\u201d.\n\nWe do not claim that our results will challenge all existing works that require estimation of the transition matrices, we are simply trying to provide an alternative that operates without these estimates and when these estimates might not be reliable/available. Nonetheless, in our experiments, we provide evidences that even we give the surrogate loss function method (e.g., [Natarajan et al 13]) a perfect estimate of the noise rates, peer loss has shown advantages. \n\nWe are glad the reviewer 2 in fact mentioned the challenge of estimating instance dependent transition matrix - part of the reason that we are excited about peer loss is that peer loss removes the need of estimating transition matrix and it opens up a new possibility in handling instance-dependent label noises. \n\nWe acknowledge the comments, from both Nontawat and the reviewer, that for symmetric error rates case  there exist methods that do not require the knowledge of error rates. We focus on asymmetric error rate cases. We are updating our draft and will clarify this.\n\n\nNovelty: \n\nThank you for pointing out the CVPR 2017 paper (we now cited). There seems to be a misunderstanding - unless we are mistaking, the proposed loss function and the correction procedure therein would require the transition matrix T to perform backward and forward corrections. In fact, the proposed loss correction method is derived from the surrogate loss function literature (again, e.g., [Natarajan et al 13]), which is one of the baseline method we compare to. We want to emphasize again our operation of peer loss does *not* require this knowledge of T. We do not see any further connection, but would love to hear a more specific pointer if the reviewer disagrees. Please let us know, thanks. \n\nOur connection of using peer prediction in this learning with noisy label setting frees up the requirement of estimating the transition matrix, which we believe is novel (this was acknowledged in other reviewer\u2019s comments, including R3 and Nontawat\u2019s). \n\n*Updated comments*: After reading the CVPR more carefully, the paper did mention the Hessian of ReLU is invariant to noises, so minimizing it will not need the specification of noise rates. First, this is not the same as the proposed loss correction approach, which is the focus of the paper; Second, it is acknowledged in the paper that \" this does not provide any assurance on minima: indeed, stationary points may change location due to label noise.\"\n\n\nSignificance:\n\nAgain because of that peer loss does not require the knowledge of transition matrix, our method generalizes to multi-class labels easily. In an earlier draft we do provide a justification, but we wanted to stay focused with our binary setting, since our results are already dense. In the updated version, we will add the preliminary results back. \n\n*Update*: we have restructured our presentation, and have added an experiment on CIFAR-10. \n\nWe hope the above helps clarify our contributions. Thank you for reading our paper, and we are happy to discuss further. \n", "title": "clarification of our motivation, novelty and significance; peer loss operates without estimating transition matrices ; added experiment on CIFAR-10"}, "SkgGILdiiB": {"type": "rebuttal", "replyto": "r1esPNlOir", "comment": "Updated the organization and  presentation, as suggested by Reviewer 2.", "title": "updated organization and presentation"}, "HJlLUFmoiB": {"type": "rebuttal", "replyto": "BkxWXCicjH", "comment": "Great! We are glad that we were able to clarify some concerns. \n\nYes indeed we have been making some structural changes, and adding explanations. We suffered from page limit and are working on the best way to deliver the explanations. Hopefully we will finish before the deadline! \n\nIn the current revision (uploaded now), \n\n- we added a paragraph (top of page 2) to briefly introduce why peer loss can get rid of estimation of noise rates. \n- at the end of Sec 3 (page 5), we added a paragraph to explain the connection between Sec 3 and 4. \n- we restructured Sec 4: now in 4.1, we present some preparation and explain the effects of peer term. 4.2 focuses on peer loss only. We added an example and explanation of why we do not need the explicit knowledge of noises rates at the top of page 7. \n- Sec 4.3 now has an interpretation of Lemma 3 and how it helps. \n\nWe think probably Sec 4.1 - 4.3 are the most important ones to understand the basic ideas, while 4.4 and 4.5 focus on the technical properties. \n\nWe are checking with the reviewer to see whether we are on the right direction about this and would appreciate further comments/suggestions (before the response deadline) on improving readability (but we understand if not, given the short time left).\n", "title": "working on that! just uploaded a new version, but will continue updating it"}, "r1esPNlOir": {"type": "rebuttal", "replyto": "Bkgq9ANKvB", "comment": "Dear reviewers and all,\n\nWe have updated our draft according to your comments and uploaded a revision. Major revisions are highlighted in blue. We would like to thank the reviewers and our public comments again for the extremely helpful comments. We won\u2019t be able to reach this revision without your help. We believe our draft has improved significantly. We would highly appreciate it if you could read our revisions and let us know if you have any further concerns. \n\nTo summarize our main changes:\n\n1. We have updated our introduction and related work to better position our contributions. We want to emphasize that we have focused on asymmetric error rates \u2013 it is true that there exist loss functions which do not require the knowledge of noise rate when the error rates are symmetric (or under specific conditions, e.g., when the optimal Bayes risk is 0). We have added comparisons with symmetric loss functions (we\u2019d like to thank Reviewer 1 and Nontawat for very helpful comments and pointers.)\n\nIn response to Reviewer 1 & 2\u2019s comments, we have \u201ctoned\u201d down a bit (it was not our intention, but we were not super clear) - we didn\u2019t mean that the estimation of noise rates is not possible (or transition matrix, as used in a number of papers). Our goal is to provide a different and new approach that wouldn\u2019t require this estimation. Our method is useful in settings when the practitioner does not have access to reliable estimates of the noise rates (e.g., when the training data has limited size for the estimation tasks, or when the training data is already collected in a form that makes the estimation hard to perform. This challenge was particularly cited in the CVPR'17 paper pointed out by Reviewer 1 (https://arxiv.org/abs/1609.03683):\n\n\"The quality of noise estimation is a key factor for obtaining robustness ..... where estimation destroys most of the gain\nfrom loss correction. We believe that the mix of high noise and limited number of images per class (500) is detrimental\nto the estimator. \"\n\n2. Compare to a recent NeurIPS 19 paper (DMI): per the request by both Reviewer 2 and a public comment, we have added a discussion about our difference with a very recent work on an information theoretical measure (DMI) that does not require specification of noise rates either. Besides peer loss\u2019 additional theoretical guarantees of generalization and calibration, peer loss has shown consistent empirical advantages in comparing to DMI (we\u2019d like to note that DMI performs fairly well too; in the previous paper DMI was only tested with simple and sparse noise setting. So we provide a more extensive study of it).\n\n3. We further clarified our contributions. Regarding Reviewer 1\u2019s comment on our novelty in light of a CVPR\u201917 paper, we clarify that the proposed loss correction approach therein requires the knowledge of a noise transition matrix T. Peer loss does *not* require either the knowledge of T nor the estimation of T. The loss correction approach was derived from the surrogate loss function methods (e.g., [Natarajan et al 13]) where the goal is also to define unbiased estimators of the true losses. We have compared with surrogate unbiased loss approach in our paper. We hope this clarifies and justifies our novelty. \n\n4. We added back some preliminary results on multi-class classification (on CIFAR-10 dataset) with an implementation of peer loss in ResNet (replacing cross entropy loss). As we mentioned earlier in the paper, because of that peer loss does not require the knowledge of transition matrix of noise labels, our method generalizes to multi-class labels easily. We added some preliminary analysis for multi-class in Section 4.1 and Appendix. We do observe peer loss is effective compared to DMI and another baseline. This implementation also demonstrates the usefulness of peer loss in a deep learning task.\n\n5. Notations are updated to avoid confusion. \n\nBest,\nAuthors", "title": "Revised draft uploaded; summary of main changes; added experiment results (comparing to other works, multi-class); related works"}, "HJxAIGggjr": {"type": "rebuttal", "replyto": "BylUU8YTFB", "comment": "We thank the reviewer for his/her comments. We will clarify our contribution in comparing to L_{DMI}, our assumptions made for the theoretical results, and our claims.\n\n\nCompare to L_{DMI}: \n\nWhile we are working hard to compare us with L_{DMI} and update our draft, we\u2019d like to mention that the pointed article was submitted to arXiv on Sep 8, 2019, which was roughly two weeks before ICLR deadline. We feel that would be too fresh for us to include a thorough comparison - around the point, we have pretty much finalized our results and were focusing on writing up our draft. \n\nWe have received a public comment on L_{DMI}, and have commented publicly about the differences. We copy the responses at the end too. Since received the comment, we have looked into the codes shared by the authors of L_{DMI}. We do realize the experiments presented therein largely focused on simple noise model, with noises being either added to only one class (one single noise parameter, and this makes the problem much easier! as one class has entirely clean labels, and the other class still has dominantly clean label!), and symmetric noises (different class labels have the same error rates, again one noise parameter). We do think our results provide evidence that peer loss is robust to different asymmetric noise settings. \n\n\nOur assumptions: \n\nInly our conceptual results in Section 3 require S to elicit Bayes optimal classifier. Our main results on the specific forms of peer losses in Section 4 do *not* require any of such. Our theoretical results and properties hold for any hypothesis class. \n\nFor instance, in Theorem 3,4 (Sec 4.1), Theorem 5 (Sec 4.2), the results are over a generic hypothesis class $\\mathcal F$.\n\n\nOn our claim: \n\nProbably our claim was not clear - we wanted to say that these existing methods require *explicit* knowledge of T, so in practice, the practitioners will need to estimate these Ts and plug in. We are indeed aware of these line of work. But this was exactly one of our main motivations! We felt this requirement of additional estimation steps might complicate the learning process, and the additional errors introduced via learning these parameters are concerning too.\n\nPeer loss does *not* require the knowledge or estimation of these Ts, and operates without the need of *specifying* the noise rates. We now start to think that a better way to position our paper is to say we contribute to \u201clearning with noisy labels without specifying the error rates\u201d.\n\nWe do not claim that our results will challenge all existing works that require estimation of the transition matrices, we are simply trying to provide an alternative that operates without these estimates and when these estimates might not be reliable/available. Nonetheless, in our experiments, we provide evidence that peer loss has shown advantages, even we give the surrogate loss function method (e.g., [Natarajan et al 13]) a perfect estimate of the noise rates.\n \nWe are glad the reviewer mentioned the challenge of estimating instance dependent transition matrix - part of the reason that we are excited about peer loss is that peer loss removes the need of estimating transition matrix and it opens up a new possibility in handling instance-dependent label noises. \n\nWe hope the above clarifies our contribution. Happy to discuss further. \n\n\u2014\u2014\u2014\u2014\u2014---------------------------------\nEarlier public comments to the difference between our work and L_{DMI}:\n\n- We aimed for a simple-to-optimize loss function that can easily adapt to existing ERM solutions. After the submission, we have observed other successes in adapting peer loss to more sophisticated neural network solutions, differentially private ERM, and semi-supervised learning etc. [1] seems to require estimations of a joint distribution matrix, and then to invoke computing a certain information theoretical measure.\n\n- With above concern, it is not entirely clear to us about the sample complexity requirement in [1], and the sensitivity to noises in this estimation. We do provide calibration guarantees and generalization bounds. \n\n- We provide conditions when the loss functions are convex. In general, we do think computationally peer loss functions are easy to optimize with, in comparing to information theoretical measures. \n\n- We provide extensive comparisons with the state-of-the-art learning with noisy label approaches (which even have access to the error rate information).\n\n- We provide theoretical guarantees for both Bayes' optimal classifiers and general hypothesis classes, and establish a broad connection between learning with noisy labels with peer prediction score functions. It is true we have focused on CA, but the connection implies the possibility of applying other peer prediction functions. \n", "title": "clarification of our contributions, assumptions and claims"}, "Sye_PVbljr": {"type": "rebuttal", "replyto": "HJxAIGggjr", "comment": "Thank for pointing out that R was a bit abused in Section 3. We will find another notation for it in the updated draft. ", "title": "R was indeed a bit abused in Section 3; thank you!"}, "rJeXn7Zxsr": {"type": "rebuttal", "replyto": "r1ex9g6pKS", "comment": "We thank the reviewer for the comments, and for acknowledging our contribution of \u201cavoiding specifying the noise rates, is significant to the community.\u201d Below we clarify \n\nDetailed examples for computing Delta:\n\nFirst of all, we compute the marginals of $f^*$ and $\\tilde{Y}$:\n$P \\bigl(f^*(x)=-1\\bigr) = P \\bigl(f^*(x)=-1|Y=-1\\bigr) P(Y=-1) + P \\bigl(f^*(x)=-1|Y=+1\\bigr) P(Y=+1) = (1-e^*_{-1})\\cdot 0.4 + e^*_{+1} \\cdot 0.6 = 0.5\n$, and $P \\bigl(f^*(x)=+1\\bigr) = 1-P \\bigl(f^*(x)=-1\\bigr) = 0.5$. \n\nFor noisy labels:\n$P \\bigl(\\tilde{Y}=-1\\bigr) = P \\bigl(\\tilde{Y}=-1|Y=-1\\bigr) P(Y=-1) + P \\bigl(\\tilde{Y}=-1|Y=+1\\bigr) P(Y=+1) = (1-e_{-1})\\cdot 0.4 + e_{+1} \\cdot 0.6 = 0.52\n$, and $P \\bigl(f^*(x)=+1\\bigr) = 1-P \\bigl(f^*(x)=-1\\bigr) = 0.48$.\n\nFor the joint distribution:\n$P\\bigl(f^*(X)=-1,\\tilde{Y}=-1\\bigr) = P\\bigl(f^*(X)=-1,\\tilde{Y}=-1|Y=-1\\bigr)P(Y=-1) +P\\bigl(f^*(X)=-1,\\tilde{Y}=-1|Y=+1\\bigr)P(Y=+1) \n= (1-e^*_{-1})(1-e_{-1})\\cdot 0.4+e^*_{+1} \\cdot e_{+1}\\cdot 0.6 = 0.296\n$, and $P\\bigl(f^*(X)=-1,\\tilde{Y}=+1\\bigr) = P\\bigl(f^*(X)=-1\\bigr) - P\\bigl(f^*(X)=-1,\\tilde{Y}=-1\\bigr) = 0.264$.\n\nFurther\n$\nP\\bigl(f^*(X)=+1,\\tilde{Y}=-1\\bigr) = P\\bigl(\\tilde{Y}=-1\\bigr) - P\\bigl(f^*(X)=-1,\\tilde{Y}=-1\\bigr) = 0.224,\n$ $~P\\bigl(f^*(X)=+1,\\tilde{Y}=+1\\bigr) = P\\bigl(f^*(X)=+1\\bigr) - P\\bigl(f^*(X)=+1,\\tilde{Y}=-1\\bigr) = 0.216.\n$\n\nWith above, the entries in Delta can be computed easily, for instance\n$$\n\\Delta(1,1) =P\\bigl(f^*(X)=-1,\\tilde{Y}=-1\\bigr) - P\\bigl(f^*(x)=-1\\bigr)\\cdot P\\bigl(\\tilde{Y} = -1\\bigr) = 0.296 -  0.5*0.52 = 0.036\n$$\n\nWe do notice a miscalculation in the draft; we will update!\n\n\nLemma 6:\n\nWe apologize for the unclear last step - this was due to the reshuffle of results. We have used a partial results in Lemma 1. We updated the draft:\n\nSince $R^*$ can be written as a function of $X$ and $Y$, due to conditional independence between $R$ and $X$ (conditional on $Y$), by chain rule $(R^*=-1, R=+1) = P(Y=+1) (1-e_{+1})e^*_{+1} + P(Y=-1) e_{-1} \\cdot (1-e^*_{-1})\n$.\n\nSince\n$$\nP(R=+1) = P(Y=+1) (1-e_{+1})+P(Y=-1)\\cdot e_{-1}, \nP(R^*=+1) \n= P(Y=+1) (1-e^*_{+1})+P(Y=-1)\\cdot e^*_{-1}\n$$\n\nWe then have\n$$P(R^*=+1, R=-1)  - P(R^*=+1) P(R=-1)=-P(Y=+1)P(Y=-1)(1-e_{+1}-e_{-1})(1-e^*_{+1}-e^*_{-1}).$$ The above equation establishes the last equivalence. \n\n\nOn p: \n\nWe accidentally dropped the definition of $p := P(Y=1)$, which is simply the marginal distribution of true label Y.\n\n\nOn sensitivity of alpha:\n\nMost of alphas are close to 1. We thank the reviewer for the comment; we will provide the details and discussion in the updated draft. \n\n\nWe hope the above clarifies!\n", "title": "clarifications & thank you for acknowledging our contributions"}, "r1esAQqrtB": {"type": "review", "replyto": "Bkgq9ANKvB", "review": "This paper proposed peer loss function for learning with noisy labels, combining two areas learning with noisy labels and peer prediction together. The novelty and the significance are both borderline (or below). There are 4 major issues I have found so far.\n\nReferences: Looking at section 1.1 the related work, the references are a bit too old. While I am not sure about the area of peer prediction, in the area of learning with noisy labels (in a general sense), there were often 10 to 15 papers from every NeurIPS, ICML, ICLR and CVPR in recent years. The authors didn't survey the literature after 2016 at all... Nowadays most papers focus on sample selection/reweighting and label correction rather than loss correction in this area, but there are still many recent papers on designing more robust losses, see https://arxiv.org/abs/1805.07836 (NeurIPS 2018 spotlight), https://openreview.net/forum?id=rklB76EKPr and references therein. Note also that some label-noise related papers may not have the term label noise or noisy labels in the title, for example, https://openreview.net/forum?id=B1xWcj0qYm (ICLR 2019).\n\nMotivation: The motivating claim \"existing approaches require practitioners to specify noise rates\" is wrong... Many loss correction methods can estimate the transition matrix T (which is indispensable in any loss correction) without knowing the noise rate, when there are anchor points or even no anchor points in the noisy training data. See https://arxiv.org/abs/1906.00189 (NeurIPS 2019) and references therein. See also the public comment posted by Nontawat when a special symmetric condition is assumed on the surrogate loss function.\n\nNovelty: The paper introduced peer prediction, an area in computational economics and algorithmic game theory, to learning with noisy labels. This should be novel (to the best of my knowledge) and I like it! However, the obtained loss is very similar to the general loss correction approach, see https://arxiv.org/abs/1609.03683 (CVPR 2017 oral). This fact undermines the novelty of the paper, significantly. The authors should clarity the connection to and the difference from the loss correction approach.\n\nSignificance: The proposed method focuses on binary classification, otherwise the paper will be much more significant! Note that the backward and forward corrections can both be applied to multi-class classification. Moreover, similar to many theory papers, the experiments are too simple, where single-hidden-layer neural networks were trained on 10 UCI benchmark datasets. I have to say this may not be enough for ICLR that should be a more deep learning conference.", "title": "Official Blind Review #1", "rating": "3: Weak Reject", "confidence": 4}, "BylUU8YTFB": {"type": "review", "replyto": "Bkgq9ANKvB", "review": "The paper studies the label noise problem with the motivation of without estimating the flip rate or transition matrix. This is an interesting direction for dealing with label noise. Most of the previous studies need either estimate the transition matrix or put restrictions on it, e.g., to be symmetric. A very related work to this paper: L_{DMI}: A Novel Information-theoretic Loss Function for Training Deep Nets Robust to Label Noise, where no restrictions have been made on the class-dependent transition matrix and the proposed method does not need to estimate the transition matrix. The authors may need to discuss the paper.\n\nThe paper is not well-presented. I tried several times to go through the details but failed. The reasons are, e.g., (1) notation is not clear, e.g., R(X). \\tilde{Y}, and R have been abused. (2) Intuitive explanations are limited. (3) Lots of details can be put on the appendix, keeping the main part to have a strong and clear logic.\n\nIt seems the theories of the paper depends on a very strong assumption, i.e., \"Suppose S(.) is able to elicit the Bayes optimal classifier f^*\".  By quickly go through the proofs in the appendix, it seems there is a strong connection to the paper L_{DMI}.\n\nSome claims are strong. In the literature, with a mild assumption, the class-dependent transition matrix can accurately be estimated just from noisy data with theoretical guarantees. There are also methods proposed for this. Estimating class-dependent transition matrix is not a bottleneck. I think the challenge is about how to learn instance-dependent transition matrix.\n\nOverall, this is an interesting paper but needs to be improved.", "title": "Official Blind Review #2", "rating": "3: Weak Reject", "confidence": 4}, "r1ex9g6pKS": {"type": "review", "replyto": "Bkgq9ANKvB", "review": "This paper studies the problem of learning classifiers from noisy data without specifying the noise rates. Inspired by the literature of peer prediction, the authors propose peer loss. First, a scoring function is introduced, minimizing which we can elicit the Bayes optimal classifier f*. Then the authors use the setting of CA to induces a scoring matrix, and then the peer loss. Moreover, this paper explores the theoretical properties of peer loss when p=0.5. In particular, the authors propose \\alpha weighted peer loss to provide strong theoretical guarantees of the proposed ERM framework. The calibration and generalization abilities are also discussed in section 4.3. Finally, empirical studies show that the propose peer loss indeed remedies the difficulty of determining the noise rates in noisy label learning.\n\nThis paper is well written. The theoretical properties of the proposed peer loss are thoroughly explored. The motivation is rational with a good theoretical guarantee, i.e. Theorem 1. Moreover, the tackled problem, i.e. avoiding specifying the noise rates, is significant to the community.\n\nNevertheless, Some parts of this paper may be confusing:\n- The computation of the scoring matrix delta is not that clear. Can the authors provide the detailed computation steps of the example? \n- In the proof of Lemma 6, can the authors provide a proof sketch of the equivalence of the last two equations?\n- Third, where is the definition of p?\n\nIn the experiments, the authors propose to tuning the hyperparameter alpha. I would be appreciated if the authors provide the sensitivity experiments of alpha to show its fluence for the final prediction.\n\nThough I'm not that familiar with learning from noisy labels, I think it is a good paper and I suggest to accept.", "title": "Official Blind Review #3", "rating": "8: Accept", "confidence": 1}, "SJebzaMR5H": {"type": "rebuttal", "replyto": "HkeRt0bC5H", "comment": "Dear Yilun,\n\nThank you for the pointer. Indeed we are not aware of the work until the posted comment. We'd like to note that the pointed article [1] was submitted to arXiv on Sep 8, 2019, which was roughly two weeks before ICLR deadline. To be fair, we feel that would be too fresh for us to include a thorough comparison - around the point, we have pretty much finalized our results and were focusing on writing up our draft. But we definitely will include this in our next version; in fact we are keen to observe the difference between the methods. \n\nA (very) quick read seems to imply the following differences:\n\n- We aimed for a simple-to-optimize loss function that can easily adapt to existing ERM solutions. After the submission, we have observed other successes in adapting peer loss to more sophisticated neural network solutions, differentially private ERM, and semi-supervised learning etc. [1] seems to require estimations of a joint distribution matrix, and then to invoke computing a certain information theoretical measure.\n\n- With above concern, it is not entirely clear to us about the sample complexity requirement in [1], and the sensitivity to noises in this estimation. We do provide calibration guarantees and generalization bounds. \n\n- We provide conditions when the loss functions are convex. In general, we do think computationally peer loss functions are easy to optimize with, in comparing to information theoretical measures. \n\n- We provide extensive comparisons with the state-of-the-art learning with noisy label approaches (which even have access to the error rate information).\n\n- We provide theoretical guarantees for both Bayes' optimal classifiers and general hypothesis classes, and establish a broad connection between learning with noisy labels with peer prediction score functions. It is true we have focused on CA, but the connection implies the possibility of applying other peer prediction functions. \n\nNonetheless, it looks a fun paper to us to read, and we will certainly do. \n\nHappy to discuss further. \n\nBest,\nAuthors ", "title": "thanks for the pointer. Our differences & the pointed out article was too fresh for us to include "}, "rJeXF_Q9YB": {"type": "rebuttal", "replyto": "BkxFF8w_tS", "comment": "I see. Right, for 0-1 loss we leveraged the symmetricity property as you correctly pointed out. This now indeed looks generalizable to other losses when the sum is a constant. (we see the connection with the pointed out references now)\n\nThanks for pointing out the equivalence between the two measures when p=0.5 - this is helpful for us to understand [8] and our differences. \n\nWe appreciate your advises on why the symmetric losses might not see a good performance. We will play around with it more!\n\nBest,\nAuthors", "title": "thank you for your clarification and careful reading"}, "S1xL8xFvtH": {"type": "rebuttal", "replyto": "H1lGE6g8YS", "comment": "Dear Nontawat,\n\nWe greatly appreciate your comments. Indeed reading through them helped us refresh our thoughts about the symmetric loss.\n\nWe were aware of symmetric loss functions proposed in the literature, when the error rates are symmetric. We indeed implemented one symmetric loss (sigmoid loss) and observed that it performs worse than both peer loss and the surrogate loss proposed by Natarajan et al 2013 (which is one of our benchmark method), for both symmetric and asymmetric error rate setting. The above observation partially motivated us to to focus on the methods proposed for asymmetric error rate and decided to not include everything from the broad learning with noisy data literature. But thank you for reminding us that under some conditions (e.g., L( f(x), 1) + L( f(x), \u22121) = Constant), the techniques developed for the symmetric case are also robust to asymmetric noises. We aimed for a generic method that would not require much assumption on the error rates and the loss functions. In the next version, we will make it clear that \"learning with noisy data without knowing noise rates\" has been studied in the symmetric setting, and the asymmetric setting under conditions.\n\nFollowing the comment, we have just tried replacing the cross-entropy loss in peer loss with the sigmoid loss, but we didn\u2019t observe clear improvement either (but thank you!). \n\nWe will add these references to our next version, and we will add symmetric loss to our baseline competitors. This will indeed help us improve our related works and the experiment session to be more comprehensive. \n\nWe are keen to read [8] and understand the conditions that would make symmetric loss work and more robust. \n\nIn our theorem 3, our symmetricity assumption is mainly in ground truth label\u2019s prior (p=0.5), which we believe is different from the \u201csymmetricity\u201d in the symmetric loss setting. We do agree Lemma 4 is related to [6-8]; will definitely cite. We do appreciate you pointing this out. We will better clarify. \n\nHappy to discuss further!\n", "title": "thank you for the pointers! focused more methods for asymmetric noise rates; have experimented with symmetric loss"}}}