{"paper": {"title": "A Graph Neural Network Assisted Monte Carlo Tree Search Approach to Traveling Salesman Problem", "authors": ["Zhihao Xing", "Shikui Tu"], "authorids": ["xingzhihao@sjtu.edu.cn", "tushikui@sjtu.edu.cn"], "summary": "A Graph Neural Network Assisted Monte Carlo Tree Search Approach to Traveling Salesman Problem", "abstract": "We present a graph neural network assisted Monte Carlo Tree Search approach for the classical traveling salesman problem (TSP). We adopt a greedy algorithm framework to construct the optimal solution to TSP by adding the nodes successively. A graph neural network (GNN) is trained to capture the local and global graph structure and give the prior probability of selecting each vertex every step. The prior probability provides a heuristics for MCTS, and the MCTS output is an improved probability for selecting the successive vertex, as it is the feedback information by fusing the prior with the scouting procedure. Experimental results on TSP up to 100 nodes demonstrate that the proposed method obtains shorter tours than other learning-based methods.", "keywords": ["Traveling Salesman Problem", "Graph Neural Network", "Monte Carlo Tree Search"]}, "meta": {"decision": "Reject", "comment": "The paper is a contribution to the recently emerging literature on learning                                                        \nbased approaches to combinatorial optimization.                                                                                    \nThe authors propose to pre-train a policy network to imitate SOTA solvers for                                                      \nTSPs.                                                                                                                              \nAt test time, this policy is then improved, in an alpha-go like manner, with                                                       \nMCTS, using beam-search rollouts to estimate bootstrap values.                                                                     \n                                                                                                                                   \nThe main concerns raised by the reviewers is lack of novelty (the proposed                                                         \nalgorithm is a straight forward application of graph NNs to MCTS) as well a the                                                    \nexperimental results.                                                                                                              \nAlthough comparing well to other learning based methods, the algorithm is far                                                      \naway from the performance of SOTA solvers.                                                                                         \n                                                                                                                                   \nAlthough well written, the paper is below acceptance threshold.                                                                    \nThe methodological novelty is low.                                                                                                 \nThe reported results are an order of magnitude away from SOTA solvers, while previous work                                         \nhas already reported the general feasibility of learned solvers to TPSs.                                                           \nFurthermore, the overall contribution is somewhat unclear as the policy relies                                                     \non pre-training with solutions form existing solvers. "}, "review": {"Syga-qC2FS": {"type": "review", "replyto": "Syg6fxrKDB", "review": "In this paper, the authors introduce a new Monte Carlo Tree Search-based (MCTS) algorithm for computing approximate solutions to the Traveling Salesman Problem (TSP). Yet since the TSP is NP-complete, a learned heuristic is used to guide the search process. For this learned heuristic, the authors propose a Graph Neural Network-derived approach, in which an additional term is added to the network definition that explicitly adds the metric distance between neighboring nodes during each iteration. They perform favorably compared to other TSP approaches, demonstrating improved performance on relatively small TSP problems and quite well on larger problems out of reach for other deep learning strategies.\n\nI believe that the paper is built around some good ideas that tackle an interesting problem; the Traveling Salesman Problem and variants are popular and having learning-based approaches to replace heuristics is important. In particular, choosing to use an MCTS to tackle this problem feels like a natural approach, and using a GNN as a learning backend feels like a encourage better performance with fewer training samples. However, there are too many questions raised by decisions the authors have made to warrant acceptance in the current state; I would be willing to revise my score if some more detailed analysis of these points were included.\n\nFirst, the heuristic value function: this value function h(s) is defined in the appendix but should be motivated and described (in detail) in the text body. As written, this information is not included in the main body of the paper yet is critical for the implementation. Also, though it is intuitively clear why a random policy is unlikely to result in a poor result, it is never compared against; how does the performance degrade if the heuristic value function is not used? Finally, the parameter 'beam width' used in the evaluation of the value function but is only set to 1 in all experiments. Some experiments should be included to show how increasing beam width impacts performance (or the authors should provide a reason these experiments were not run). Finally, it seems as if there already exists heuristic methods (against which the paper compares performance); could these be used instead of this value function?\n\nAdditionally, how is the set of Neighbors defined? It is suggested in the text that it is not all nodes, but not using all nodes is a limiting assumption. Relatedly, it would be helpful if the authors could better motivate their additional term in Eq. (2); at the moment, though using the euclidian distance to weight the edges, it is unclear why this function is a better choice than something else, for instance a Gaussian kernel or a kernel with finite support. In addition, the authors motivate that the distance between nodes is very important for the performance of the system, yet the coordinates of each vertex are included as part of the input vector so that (in principle) the network could learn to use this information. A comparison against a network implemented using the basic GNN model, defined in Eq. (1), should be included to compare performance.\n\nIn summary, there are a few choices that would need to be better justified for me to really support acceptance. However, there are some quite interesting ideas underpinning this paper, and I hope to see it published.\n\nMinor comments:\n- Overall, I like the structure of the paper. At the beginning of all major sections there is an overview of what the remainder of the section will contain. This helps readability. I also like the comparison between the proposed work and AlphaGo, which popularized using deep learning in combination with MCTS; this enhances the clarity of the paper.\n- The related work section would be more instructive if it also gave some information about the limitations of the alternative deep learning approaches and how the proposed technique overcomes these. My assumption is that all approaches discussed in the second paragraph are \"greedy\" and suffer from the limitations mentioned in the introduction. However, I am not sufficiently familiar with the literature to be certain. A sentence or two mentioning this or relating that work to the proposed MCTS approach would be informative.\n- The last paragraph of the Related Work section, discussing the work of Nowak et al 2017 and Dai et al 2017, introduces some numbers with no context: e.g., \"optimality gap of 2.7%\". It is unclear at this stage if this number is good or bad. Some more context and discussion of this work might be helpful for clarity, particularly since the Nowak work seems to be the only other technique using GNN.\n- Some general proofreading for language should be performed, as there are occasionally typos or missing words throughout the paper. Some examples: \"compute the prior probability that indicates how likely each vertex [being->is] in the tour sequence\"; \"Similar to the [implement->implementation], in Silver...\"; \"[Rondom->Random]\" in tables.\n- In Sec. 4.1, it is unclear what is meant by \"improved probability \\hat{P} of selecting the next vertex\".\n- I believe there is an inconsistency in the description of the MCTS strategy. Though the action value is set to the 'max' during the Back-Propagation Strategy, the value of Q is initialized to infinity.\n\nSuggestions for improvement (no impact on review):\n- Clarity: the language in the 3rd and 4th paragraphs of the introduction [begins with \"In this paper, ...\"] could be made clearer.\n  - The language \"part of the tour sequence\" is not quite clear, since, when the process is complete, all points will be in the tour. It should be made clearer that the algorithm is referring to a \"partial tour\" as opposed to the final tour. This clarity issue also appears later in Sec. 4.\n  - \"Similar to above-learned heuristic approaches...\" It might be clearer if you began the sentence with \"Yet,\" or \"However,\" so that it is more obvious to the reader that you intend to introduce a solution to this problem.\n- Equation formatting: Please use '\\left(' and '\\right)' for putting parenthesis around taller symbols, like \\sum.\n- When describing the MCTS procedure, I have seen the word \"rollouts\" used much more frequently than \"playouts\". Consider changing this language (though the meaning is clear).", "title": "Official Blind Review #3", "rating": "6: Weak Accept", "confidence": 2}, "H1eL7g195S": {"type": "review", "replyto": "Syg6fxrKDB", "review": "EDIT: After the authors response and update of the contributions to indicate that the main contribution of the paper is the application of GNNs and MCTS to the TSP (rather than the original claims that that the model architecture and search approach were novel contributions), I increased my score from Weak Reject to Weak Accept. However, given that the paper is now more focused on solving the TSP, and I am not an expert on that specifically I had to reduce my experience assessment, as while I am more confident now that the paper is technically correct, it is harder for me to judge if the paper should be accepted in terms of empirical strength since I am not familiar with TSP baselines.\n\nThe authors propose an MCTS-based learned approach using Graph Neural Networks to solve the traveling salesman problem (TSP) agents. \n\nThe authors write the TSP as an MDP where the state consists of the nodes visited by the agent and the last node visited by the agent, the action consists of selecting the next node to visit, and the reward at each step is the negative cost of the travel between the last node and the next node. \n\nThe learned part of the model uses a \u201cstatic-edge graph neural network\u201d (SE-GNN). This network allows to access the full graph context, including edge features, to make node predictions. This is listed as the first paper contribution. At train time, this network is trained to predict the probability of each unvisited node to be next in the optimal path. This is trained via supervised learning using optimal paths precomputed with state of the art TSP solvers.\n\nAt test time, they use MCTS with a variant of PUCT, where the pre-trained SE-GNN is used as the prior policy, and there is a selection strategy during search that balances the prior probability, and the Q values estimated by MCTS, using max based updates (e.g. during back up new Q estimates replace old estimates if and only if the are larger than the previous ones). This is listed as the second paper contribution. Authors show that the approach beats other learned solvers in the TSP problem by a large margin in terms of optimality gap.\n\nWhile I think the work is interesting, I am not sure that what the authors cite as main contributions of the paper are truly the main contributions. In my opinion the main contribution would be the state of the art performance at solving the TSP using learned methods. I cannot, however, recommend acceptance due to the following reasons.\n\nWith respect to the first claim \u201cSE-GNN that has access to the full graph context and generates the prior probability of each vertex\u201d, there are already many models that allow to condition on edge features, including InteractionNetworks, RelationNetworks and GraphNetworks. This paper has a good overview of this family of methods and most of them allow to access the full graph context too (https://arxiv.org/abs/1806.01261). Most of these models are very well known and are in principle more expressive than the one proposed in this paper, and allow generalization to different graph sizes, so the motivation for introducing a new model is not very clear, specially if these baselines are not compared.\n\nWith respect to the MCTS contribution at test time, it seems that the changes made to the algorithm compared to AlphaGo, are very specific to the TSP and there is not much discussion about which other sort of problems may benefit from the same modifications, so it is hard to evaluate its value as a standalone contribution independent from the TSP.\n\nOn the basis of state of the art performance at solving the TSP using learned methods:\n* The model requires access to a dataset with optimal solutions to train it, and I doubt it can solve the problems faster than Gurobi in terms of wall time. For this result to be more interesting, the authors should be able to show that the model can generalize to larger problems (where the combinatorial complexity may start making approaches like Gurobi struggle). However it is not clear if the model can generalize to larger graphs.\n* Beyond that I am not an expert on TSP specifically, and I don\u2019t know the TSP literature, so I cannot give a strong recommendation.\n\nThere are some additional papers that may be relevant to this line of work:\n* (MIP, NeurIPS 2019) Learning to branch in MIP problems using similar technique pretraining a GNN and use it to guide a solver at test time (no MCTS though) (https://arxiv.org/abs/1906.01629) \n* (SAT, SAT Conference 2019) Learning to predict unsat cores (similar to the previous one but for SAT problems) (https://arxiv.org/abs/1903.04671)\n* (Structural construction, ICML 2019) Building graphs by choosing actions over the edges of a graph solving the full RL problem end to end, and also integrating MCTS with learned prior both at train time and test time (together and independently) (http://proceedings.mlr.press/v97/bapst19a/bapst19a.pdf)\n\nSome additional typos/ feedback:\n* It would be good to have a pure MCTS baseline with not learned prior as an additional ablation (e.g. taking the SE-GNN prior out of the picture).\n* In the \u201cSelection Strategy\u201d paragraph, the action is said to be picked as argmax(Q + U), where U is proportional to the prior for each action. However, Q is said to be initialized to infinite. This would mean that at the beginning of search all actions will be tied at infinite value, and my default assumption would be that in these conditions an action is chosen uniformly at random. I suspect what happens in this case is that the action with the highest prior is picked to break the tie at infinite, however if this is the case this should be indicated in the math.\n* In the \u201cExpansion Strategy\u201d paragraph, the Q values are said to be initialized to infinite. However in the Back-Propagation strategy it is said they are updated using newQ = max(oldQ, value_rollout). If this was true the values would always remain infinite, I assume the max is not applied if the previous value was still infinite.\n* In the \u201cPlay\u201d paragraph: The action is said to be picked according to the biggest Q value at the root, I assume in cases where the planning budget is smaller than the number of nodes, and not all actions at the root are explored, the actions that have not been explored are masked out.\n* Non-exhaustive list of typos: \u201cRondom\u201d \u2014> \u201cRandom\u201d, \u201cprovides a heuristics\u201d \u2014> \u201cprovides a heuristic\u201d, \u201cstrcuture2vec\u201d \u2014 > \u201cstructure2vec\u201d, weird line break at top of page 8. \n\n", "title": "Official Blind Review #4", "rating": "6: Weak Accept", "confidence": 2}, "rkeV3rQ3sH": {"type": "rebuttal", "replyto": "H1eL7g195S", "comment": "Thank you for seeing the importance of the problem and the value of showing the broad applicability. Please let us address your concerns.\n\nQuestion 1: \u201cThe motivation for introducing a new model is not very clear, specially if these baselines are not compared.\u201d\nAnswer 1: In this paper, our intention is not to introduce a new GNN model and beats other well-known models, but to use GNN to extract features for TSP. Rather than using the basic GNN, we integrate edge information into the GNN and empirical results show that the incremental chance can improve the feature extraction ability of the GNN. We have modified the representation of the corresponding part in the article. In the feature, we will explore other GNN models as you mentioned to improve the feature extraction and generalization capabilities of our method.\n\nQuestion 2: Could other sorts of problems benefit from the GNN-MCTS?\nAnswer 2: In this paper, we focus on the traveling salesman problem and we will extend the proposed MCTS to other combinatorial optimization problems in the future work. \n \nQuestion 3: Running time and generalization of the algorithm.\nAnswer 3: Running time and generalization of the algorithm are also noted by Reviewer 2 and please see our response to Reviewer 2 on question 1 and question 2.\n \nQuestion 4: \u201cIt would be good to have a pure MCTS baseline with not learned prior as an additional ablation (e.g. taking the SE-GNN prior out of the picture).\u201d\nAnswer 4: Thanks for your proposal. We have added the pure MCTS baseline in the new version.\n \nQuestion 5: Question about Q value initialization.\nAnswer 5: We are so sorry for our description to confuse you. The Q value only needs to be initialized to a small value, i.e., - infinity. In our code, we initialize Q value to -5.0 (TSP20), -10.0 (TSP50) and -15.0 (TSP100).\n\nQuestion 6: \u201cplanning budget is smaller than the number of nodes, and not all actions at the root are explored, the actions that have not been explored are masked out. \u201d\nAnswer 6: In the MCST procedure, only nodes with high value (Q+U) will be explored multiple times. So, the MCTS can allocate more exploration resources to the direction of the possible optimal solution. By using PUCT, the small prior child nodes are rarely visited, and the solution space can cut down in this way. In the \u201cplay\u201d phase, we pick action according to the biggest Q value at the root and mask out the actions that have not been explored because these nodes have very small prior or Q value.\n \nQuestion 7: typos\nAnswer 7: We will correct typos in the new version.\n", "title": "Response to Review #4"}, "BJebXVm3oH": {"type": "rebuttal", "replyto": "ryxI8_Q1qS", "comment": "Thank you for the detailed review and helpful suggestions. We address your concerns below:\n\nQuestion 1: Running time of the algorithm.\nAnswer 1: Thank you for this suggestion (which was also noted by reviewer 4), this is indeed something that was missing which we have supplemented the running time of our algorithm, Gurobi, and other learning-based methods. Running times are important but hard to compare: they can vary by two orders of magnitude as a result of implementation (Python vs C++) and hardware (CPU vs GPU). Our algorithm is slower than other learning-based algorithms due to the look-ahead search. Our code is written by Python and we note that the MCTS procedure can speed up by rewritten code to C++. We test our algorithm, Gurobi and learning-based methods on a machine with 32 virtual CPU systems (2 * Xeon(R) E5-2620)) and 8 * 2080ti. At each epoch, we test 32 instances in parallel and after 4 epochs, we report the time it takes to solve on each test instance. The results are as follows: \n\t\t\t\tTSP20\t\tTSP50\t\tTSP100\n- Our  \t\t\t3.2s  \t\t6.6s\t\t\t31.4s\n- Gurobi\t\t\t0.017s   \t        0.2s\t\t\t1.9s\n- Dai et al\t\t0.007s\t\t0.018s\t\t0.043s\n- Kool et al\t\t0.036s\t\t0.054s\t\t0.084s\n\nAlthough the cost time of our algorithm is not as fast as the traditional optimizer such as Gurobi, our algorithm has a good generalization ability than other learning-based algorithms. \n\nQuestion 2: \u201cThe discussion on whether the approach can plausibly scale to much larger TSP instances\u201d.\nAnswer 2: We conduct the experiment to explore the performance of our algorithm and other learning-based algorithms on larger problems. We made some changes to make our algorithm work on larger instances.\n  Firstly, we revise the Eq.(4) to $f(G|S;\\Theta)=\\text{softmax}(sum(H_{1}^{T}),\u2026,sum(H_{n}^{T}))$, where sum denotes summation operator. This change allows our network to inference on large-scale instances after training on small-scale instances.\n  Secondly, in order to reduce the amount of memory used in the MCTS procedure, we only expand the top ten child nodes based on the prior probability output by SE-GNN.\n  We retrain our SE-GNN on TSP100 random instances and test our algorithm using the pre-trained model (TSP100) on random instances including TSP200, TSP300, and TSP500. We mainly compare the learning-based algorithm proposed by Kool et al. and Dai et al. which made the best performance before our work respectively in Encoder-Decoder and Graph Embedding framework. We report the Gap as defined in Table 1. The results are as follows: \n\n                      TSP200        TSP300\t TSP500\nOur               1.91%           2.99%\t\t  4.37%\nKool et al.    8.19%           12.32%          20.40%\nDai et al.      11.11%\t    11.70%         11.84%\n\nThe results show that our algorithm could generalize to larger problems well than other learning-based algorithms even if trained in the small-scale instances. Scalability is indeed a very important direction for further research. We think that the way that heuristics (like you mention) scale almost linearly is by considering the problem locally, e.g. by local search or by limiting the set of edges for nodes (e.g. consider a sparse graph). Unlikely the previous work that directly using the deep neural network to construct a tour, we combine the neural network with the classic local search method (MCTS). We see the presented work as a step towards a new family of solvers for NP-hard problems that leverage both deep learning and classic heuristics.\n \nQuestion 2: Adding more empirical results.\nAnswer 2: Based on the comments of reviewer 3 and reviewer 4, we added more experiments about GNN and GNN-MCTS in the new version.\n\nQuestion 2: typos\nAnswer 2: We will correct typos in the new version. \n             \nQuestion 3: Misleading metric in Table 6.\nAnswer 3: We agree with you and have removed Acc* metric.\n             \nQuestion 4: \u201cTable 3 title is confusing\u201d.\nAnswer 4: We change the title to \u2018\u2019Confidence interval on different confidence levels ", "title": "Response to Review #2"}, "HyxFhSiYsH": {"type": "rebuttal", "replyto": "Syga-qC2FS", "comment": "Question 8: \u201c The related work section would be more instructive if it also gave some information about the limitations of the alternative deep learning approaches and how the proposed technique overcomes these.\u201d\nAnswer 8: Thank you for the suggestion. We reorganized the related work. We agree with you that all the approaches discussed in the second paragraph are \"greedy\" and suffer from the limitations mentioned in the introduction. What\u2019s more, we have made more context and discussion of Nowak et al 2017 and Dai et al 2017 and you will see that in the new version.\n \nQuestion 9: typos\nAnswer 9: We will correct typos in the new version.\n \nQuestion 10: The meaning of the \"improved probability \\hat{P} of selecting the next vertex\".\nAnswer 10: It should be that \u201cbased on the improved probability \\hat{P} generated by the GNN-MCTS\u201d.\n \nQuestion 11: The value of Q is initialized to infinity.\nAnswer 11: We are so sorry for our description to confuse you. The Q value only needs to be initialized to a small value, i.e., - infinity. In our code, we initialize Q value to -5.0 (TSP20), -10.0 (TSP50) and -15.0 (TSP100).\n \nQuestion 12: Suggestions for improvement\nAnswer 12: We are so grateful for your suggestions and we will adjust the corresponding part in the new version.\n", "title": "Response to Review #3 Part 2"}, "SJenfBotor": {"type": "rebuttal", "replyto": "Syga-qC2FS", "comment": "Thank you for your constructive and encouraging comments. we address your concerns below:\n\nQuestion 1: \u201cFirst, the heuristic value function: this value function h(s) is defined in the appendix but should be motivated and described (in detail) in the text body.\u201d\nAnswer 1: We accept your suggestion, and adjust the value function\u2019s position to the corresponding place in the article's body in the new version.\n\nQuestion 2: \u201cAlso, though it is intuitively clear why a random policy is unlikely to result in a poor result, it is never compared against; how does the performance degrade if the heuristic value function is not used?\u201d\nAnswer 2: The results were included in Table 5, where SE-GNN+Tree_v denotes using the policy random and SE-GNN+Tree denotes using the value function. The description for Table 5 was not clear in the manuscript. We will revise the related part accordingly.\n \nQuestion 3: \u201cFinally, the parameter 'beam width' used in the evaluation of the value function but is only set to 1 in all experiments. Some experiments should be included to show how increasing beam width impacts performance (or the authors should provide a reason these experiments were not run).\u201d\nAnswer 3: We conduct experiments to explore the effects of different widths on the performance of the algorithm. Since the beam width mainly affects the accuracy of the value function, we use the result of the value function as a measure and report the Gap as defined in Table 1. Specifically, we set beam width to 1, 5, 10, 20 and test performance of the value function on random instances including TSP20, TSP50, and TSP100. The experimental results are as follows: For TSP20, the Gap is 2.25%(1), 1.50%(5), 1.50%(10), 1.50%(20) ; For TSP50, the Gap is 5.32%(1), 3.64%(5), 3.38%(10), 3.22%(20); For TSP100, the Gap is 11.37%(1), 8.11%(5), 7.48%(10), 6.87%(20). We also count the time cost of the different settings of the beam width. The result of the time cost are as follows: For TSP20, 55ms(1), 265ms(5), 534ms(10), 1063ms(20); For TSP50, 147ms(1), 730ms(5), 1461ms(10), 2957ms(20); For TSP100, 323ms(1), 1639ms(5), 3338ms(10), 6820ms(20). The experimental results show that as the beam width increases, the performance of the value function will get better while the time cost will become larger. We need to make a trade-off between accuracy and time cost.\n\nQuestion 4:  Finally, it seems as if there already exists heuristic methods (against which the paper compares performance); could these be used instead of this value function?\nAnswer 4: We conduct experiments about replacing value function with different heuristic methods including nearest insertion, farthest insertion and random insertion. We report the Gap as defined in Table 1. The results are as follows: For nearest insertion, TSP20(4.53%), TSP50(14.95%), TSP100(21.79%); For farthest insertion, TSP20(4.40%), TSP50(14.52%), TSP100(21.76%); For random insertion, TSP20(4.99%), TSP50(13.95%), TSP100(22.03%). The results show that the heuristic methods mentioned in the article are not suitable for our algorithm. We think that the partial tour corresponding to the leaf node in the tree suffers the performance of the above heuristic methods. Designing an effective evaluation function is indeed a very important direction for further research.\n \nQuestion 5: \u201cHow is the set of Neighbors defined?\u201d\nAnswer 5: Complete graph is constructed for TSP, so the set of neighbors of one node contains all nodes except itself. We will describe it with more details in the new version.\n \nQuestion 6: \u201cRelatedly, it would be helpful if the authors could better motivate their additional term in Eq. (2);\u201d \u201cA comparison against a network implemented using the basic GNN model, defined in Eq. (1), should be included to compare performance.\u201d\nAnswer 6: We agree that in principle the neural network should have learned the distance information from the coordinates of the nodes. It is a simple thing for people, but our empirical results indicate that it is difficult for the neural network to learn the distance information. \nIn the paper, we compare the basic GNN (no edge information) with SE-GNN in the following ways. Firstly, we compare the accuracy of two models on test data when training the neural network. And then we use the greedy policy that selecting node with biggest prior output by the network as next move to derive the tour. Table 6 reports the corresponding results and shows that adding distance information to the GNN can improve the performance of the model.\n \nQuestion 7: Alternative way to measure the distance between nodes.\nAnswers 7: Like Gaussian kernel function, we use $e_{v,u}W^{t}_{3}$ to map Euclidian distance to high dimensional in Eq.(2).\n ", "title": "Response to Review #3 Part 1"}, "ryxI8_Q1qS": {"type": "review", "replyto": "Syg6fxrKDB", "review": "The paper proposes learning a TSP solver that incrementally constructs a tour by adding one city at a time to it using a graph neural network and MCTS. The problem is posed as a reinforcement learning problem, and the graph neural network parameters are trained to minimize the tour length on a training set of TSP instances. A graph neural network architecture called Static Edge Graph Neural Networks is introduced which takes into account the graph of all cities in a given problem instance as well as the partial tour constructed so far in an episode. The network predicts probabilities for the remaining cities to be selected as the next city in the tour, which is then used to compute a value function that guides MCTS. Results on synthetic TSP instances with 20, 50, and 100 cities show that the approach is able to achieve better objective values than prior learning-based approaches. Applying AlphaZero-like approaches to TSP is an interesting test case for understanding how well they can work on hard optimization problems.\n\n\nThe paper has several drawbacks:\n- The evaluation seems to be flawed as there is no mention of running time of the various algorithms being compared anywhere in the text. It\u2019s not possible to make a fair comparison without controlling for running time. As an extreme example, even random search will eventually find the global optimum if given sufficient time. So the results are not very meaningful without the running times.\n\n- Novelty is fairly low. The changes in SEGNN compared to previous works are incremental or not novel, and the overall idea is the same as AlphaGo/Zero. While I don\u2019t think novelty is a strict requirement, if it is absent, then it should be compensated with strong empirical results, but the paper lacks that as well.\n\n- A discussion on whether the approach can plausibly scale to much larger TSP instances is missing. First, there is the question of whether learning can succeed on much larger instances. Second, even if good policies can indeed be learned, can they provide competitive running times compared to the state-of-the-art TSP solvers? Graph net inference\u2019s compute cost scales linearly with graph size (number of cities), and since multiple inference passes need to be performed per step (to pick the next city to add to the current partial tour), the overall cost scales quadratically. This is worse than the empirical scaling of solvers like LKH and POPMUSIC. One has to consider approaches with cost that scales roughly linearly to be able to compete with state-of-the-art solvers. It should be noted that TSP instances with <= 100 cities are really trivial for the best solvers, and outperforming them with a learning-based approach may not be plausible until much larger instances are considered (e.g., > 10K cities). The ML community needs to move away from evaluating on small instances if the long term goal is to beat state-of-the-art solvers with learning.\n\n\nAdditional comments:\n- There are a lot of typos. A few that I caught: Tables 1 and 7 say \u201cRondom\u201d, \u201capproximation ration\u201d, \u201cReLu\u201d, \u201cprovides a heuristics\u201d, \u201cSimilar to the implement\u201d.\n\n- Table 6 gives the highest test accuracy during training, but this could be misleading (e.g., there could be random spikes in test performance during training). A smoother metric should be used.\n\n- Table 3 title is confusing.\n", "title": "Official Blind Review #2", "rating": "1: Reject", "confidence": 2}}}