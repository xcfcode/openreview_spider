{"paper": {"title": "A Unified framework for randomized smoothing based certified defenses", "authors": ["Tianhang Zheng", "Di Wang", "Baochun Li", "Jinhui Xu"], "authorids": ["th.zheng@mail.utoronto.ca", "dwang45@buffalo.edu", "bli@ece.toronto.edu", "jinhui@buffalo.edu"], "summary": "", "abstract": "Randomized smoothing, which was recently proved to be a certified defensive technique, has received considerable attention due to its scalability to large datasets and neural networks. However, several important questions still remain unanswered in the existing frameworks, such as (i) whether Gaussian mechanism is an optimal choice for certifying $\\ell_2$-normed robustness, and (ii) whether randomized smoothing can certify $\\ell_\\infty$-normed robustness (on high-dimensional datasets like ImageNet). To answer these questions, we introduce a {\\em  unified} and {\\em self-contained} framework to study randomized smoothing-based certified defenses, where we mainly focus on the two most popular norms in adversarial machine learning, {\\em i.e.,} $\\ell_2$ and $\\ell_\\infty$ norm. We answer the above two questions by first demonstrating that Gaussian mechanism and  Exponential mechanism are the (near) optimal options to certify the $\\ell_2$ and $\\ell_\\infty$-normed robustness. We further show that the largest $\\ell_\\infty$ radius certified by randomized smoothing is upper bounded by $O(1/\\sqrt{d})$, where $d$ is the dimensionality of the data. This theoretical finding suggests that certifying $\\ell_\\infty$-normed robustness by randomized smoothing may not be scalable to high-dimensional data. The veracity of our framework and analysis is verified by extensive evaluations on CIFAR10 and ImageNet.", "keywords": ["Certificated Defense", "Randomized Smoothing", "A Unified and Self-Contained Framework"]}, "meta": {"decision": "Reject", "comment": "After the rebuttal, the reviewers agree that this paper would benefit from further revisions to clarify issues regarding the motivation of the DP-based security definition,  any relationship it may have to standard definitions of privacy, and the role of dimensionality in the theoretical guarantees."}, "review": {"Ske9LpCEjB": {"type": "rebuttal", "replyto": "rkg0VfQCYH", "comment": "Thanks for your valuable comments. We appreciate your efforts on reviewing this paper.\n\n(1) Your observation on the connection between (Lecurer et al.) and our framework is correct. But actually, Eg(x) is also not a deterministic classifier. It shares the same issue with the definition of random g (Cohen et al.). Because in practice, for both definitions, we need to sample x+z (z is noise) for approximation. So all the guarantees are *probabilistic*. The connection between our framework and the lemma1 in (Lecurer et al.) also demonstrates this: Specifically, as long as $D_\\infty$ robustness is certified, the expected output (Eg(x)) stability bound  in (Lecuyer et al.) will be guaranteed with $\\delta'=0$. And if $D_{MR}$ robustness is certified, the expected output stability bound in (Lecuyer et al.) will be guaranteed with $\\epsilon'=(c+1)\\sqrt{\\epsilon}$ and $\\delta'= \\exp(-\\frac{c^2}{4})$, according to Theorem 10 . \n\n(2) The proof is based on some lemmas in Bun et al. But Bun et al. is a work on DP not on adversarial robustness.\n\n(3) This result might be not that surprising, but we are the first to prove it under a framework (that has connections with the existing frameworks). From our viewpoint, randomized smoothing is popular recently due to its strong scalability to arbitrary networks and large datasets. By this theorem, we want to show that this method might also have a limitation in terms of scalability. \n\n(4) We are sorry that we do not quite understand your concern regarding theorem 12. What we claim here is with regards to L_2 norm not L_infty norm. That's why this does not depend on dimensionality. It seems like you already understand this part.  As we mentioned above, randomized-smoothing is popular recently due to its strong scalability. Our proof here indicates it might also have a limitation in terms of scalability.  Considering the connections between our framework and the existing ones, we think this theorem at least sheds light on this question as we mention in the paper.\n\n\n\nOver-claim issue:\nThe main reason we use seemingly new notions and framework is to make all the proof clearer. But there are a lot of connections between our notions and the previous work. We detail the connections in the remark after theorem 8 in the revision. To avoid over-claim, all the main claims we make in this paper are regarding scales, and we also use phrases like \"may\" or \"under our framework\" or \"certify the robustness defined in our frameworks\" in the claims in the paper. Therefore, we respect your points, but from our perspective, we do not think those claims really over-claim. \n\n\nThanks for your valuable comments again.", "title": "Reply to Reviewer3"}, "r1lHcOR4jr": {"type": "rebuttal", "replyto": "rklU2Gp6FH", "comment": "Thanks for your comments. We appreciate your efforts on reviewing this paper.\n\nWe would like to first try to address your main criticisms before going into details.\n\n(1) Motivations for studying $D_\\infty$ and $D_MR$ robustness: One big motivation of studying $D_\\infty$ and $D_{MR}$ robustness is that it is easy to answer the questions in the abstract using these notions. Although D_infty and D_MR robustness are seemingly new notions, they are **actually relevant to previous \"standard\" notions**. We clarify the connections in the remark after theorem 8.\nSpecifically, as long as $D_\\infty$ robustness is certified, the expected output stability bound in (Lecuyer et al.) will be guaranteed with $\\delta'=0$. And if $D_{MR}$ robustness is certified, the expected output stability bound in (Lecuyer et al.) will be guaranteed with $\\epsilon'=(c+1)\\sqrt{\\epsilon}$ and $\\delta'= \\exp(-\\frac{c^2}{4})$, according to Theorem 10 . Besides, the ``scale'' of the robust radius certified by our framework is similar the ``scale'' of the robust radius in (Cohen et al.), according to corollary 11.\n\n(2) Unsubstantiated claims: All the main claims we make in this paper are regarding scales, and we also use phrases like \"may\" or \"under our framework\" or \"certify the robustness defined in our frameworks\" in the claims in the paper. Also considering the connections between our framework and the existing ones, we are sorry that we do not think those claims are really unsubstantiated. But we still respect your points.\n\nDetailed comments:\n1 \\& 2: We clarify this in the remark after theorem 8 in the revision. You can also refer to our response to the main criticism (1). Thanks for pointing this out.\n\n3. Our attempt here is not to compare with the other frameworks, as we mention at the beginning the \"experiment\" section.\n\n4. Please refer to our response to the main criticism (1).\n\n5. We just want to explain our framework here. As we mention in the paper, our attempt here is not to compare with the other frameworks but to study the optimality and scalability of random mechanisms. \n\n6. We are sorry that we do not quite understand your concern regarding theorem 12. The data entries are in [0, $r/\\sqrt(d)$] do not indicate their outputs are the same (similar). 2r robustness implies the outputs are similar. We are not sure if this is your question (sorry about this).\n\n7. We clarified this claim right after it (up to a log{d} factor). We use \"near\" because \"up to\" indicates the maximum factor is log d, and thus the factor might be small (smaller than log d).\n\n8. Loss(Y||Y') is a basic concept coming from differential privacy.\n\nThanks for your comments again.\n", "title": "Reply to reviewer 2"}, "Bye0GSySsS": {"type": "rebuttal", "replyto": "SkeCKq0oYH", "comment": "Thanks for your valuable comments.\n\nThanks for comments regarding theorem 12. You indeed make a point. In theorem 12, we provide lower bound on $L_\\infty$ because we are still not sure if there is an expected $L_2$ norm lowest bound. \n\nWhat we prove here is that if we want to guarantee this robust radius r, how much noise should be added. From our viewpoint, *the contraposition of this claim is what you are talking about here*: adding this amount of noise, the largest possible robust radius is r.\n\nActually , to avoid over-claim, all the main claims we make in this paper are regarding scales, and we also use phrases like \"may\" or \"under our framework\" or \"certify the robustness defined in our frameworks\" in the claims in the paper. *Specific to theorem 12*, at the beginning of the comments, we say \"to guarantee $(r, D_{MR}, \\|\\cdot\\|_2, \\epsilon)$-robustness\", which already indicates the scope of this theorem. We use \"near\" optimal because \"up to\" indicates the maximum factor is log d, and thus the factor might be small (smaller than log d).\n\n\nIn the experiments, we mainly want to verify our theorems not compare the framework with the prior work since our attempt here is not to compare with the other frameworks but to study the optimality and scalability of random mechanisms. \n\n\nThanks for your comments again.", "title": "Reply to reviewer 1"}, "BkxqJ5AKsS": {"type": "rebuttal", "replyto": "HygsIG4q_B", "comment": "Hi Mirman,\n\nThanks for your previous comments. We appreciate you pointed those two sentences out, and we already refine one and delete one (to avoid ambiguity) in the revision based on our current understanding after reading your paper carefully.\n\nThanks again for your valuable comments.\n", "title": "Follow-up reply"}, "SkeCKq0oYH": {"type": "review", "replyto": "ryl71a4YPB", "review": "This work examines the recently proposed randomized smoothing method for certifying the robustness of neural networks. The authors explain a theoretical framework for analyzing randomized smoothing as a certification method, propose two alternative definitions of robustness (D_MR and D_inf), and prove that using Gaussian noise for smoothing is near \u201coptimal\u201d for L2 robustness, while using exponential noise for smoothing is optimal for L_inf robustness (the authors do this by establishing a lower bound on the noise necessary for smoothing to work). This also leads the authors to the interesting conclusion that randomized smoothing may not be scalable to high dimensional data for L_inf robustness.\n\nIn its current state, I would vote to weakly reject this paper for one key reason. The notions of robustness defined by the authors (Definitions 3/7/8) is not the same as standard adversarial robustness (Definition 2), and the authors do not explain clearly how to translate their results back to adversarial robustness. Proving results about their own version of robustness is interesting, but it must be related back to the standard notion of adversarial robustness so that the broader machine learning community can understand how the authors\u2019 contributions fit in the literature. It may in fact be quite straightforward to relate the two notions, but I think the authors should explain how to do so clearly. I am happy to reconsider if the authors can address this (and other comments below) in a satisfactory manner.\n\nI did not check the authors\u2019 theoretical proofs, but I find the statements of the theorems interesting, especially the results about the maximum certifiable radius for L_inf robustness. This provides significant new insight about the fact that L_inf robustness may not be easy to certify using randomized smoothing methods. However, it is not clear to me how best to translate the authors\u2019 results to a result for the standard notion of adversarial robustness, which I believe would be interesting to present clearly.\n\nI would encourage the authors\u2019 to clarify (and tone down) their statement about the \u201coptimality\u201d of Gaussian noise for L2 robustness. Theorem 12 provides a lower bound on the L_inf norm of the noise added, and they show that Gaussian noise is close to \u201coptimal\u201d in terms of expected L_inf norm. I am a bit confused as to why are we providing bounds on the L_inf norm of the added noise (especially since we are verifying L2 robustness) - in what other ways is Gaussian noise (near) optimal? Does it also have the expected lowest L2 norm? Also, why do we want the noise to have low norm? I feel that \u201coptimal\u201d should mean being able to prove the largest possible robust radius, and if that is not what you are proving, I would encourage you to try to avoid overclaiming.\n\nFinally, the experimental results should also not just be in terms of D_MR robustness. Otherwise, it is hard to compare with prior work like Cohen et. al.\n\nSome additional feedback:\n\n- \u201cthe Lp-normed robustness\u201d can be replaced with \u201cLp-norm robustness\u201d everywhere\n- Page 1, say \u201cthe Gaussian mechanism\u201d instead of \u201cGaussian mechanism\u201d (toward the end of the first paragraph)\n- Table 1\u2019s formatting can be improved (maybe have a box around the whole table)\n- Theorem 12 - use \u201cIn other words\u201d instead of \u201cIn another word\u201d", "title": "Official Blind Review #1", "rating": "3: Weak Reject", "confidence": 3}, "rklU2Gp6FH": {"type": "review", "replyto": "ryl71a4YPB", "review": "Summary of the paper's contributions:\n\nThis paper introduces two new notions of robustness for randomized classifiers, which are based on the notions of differential privacy (DP) of randomized mechanisms. Specifically, the D_\\infty robustness and D_{MR} robustness of a random classifier are defined based on \\epsilon-DP and \\epsilon-zCDP, respectively.\n\nThe paper proves lower bounds on the noise level of a random classifier for which it can be certified D_\\infty robust and D_{MR} robust. Further, it is shown that the lower bounds are achieved by random classifiers constructed using Gaussian noise and exponential noise for l_2 and l_\\infty robustness, respectively.\n\nMajor criticisms: (1) The paper does not give sufficient motivation for studying D_\\infty robustness and D_{MR} robustness. (2) The paper makes several unsubstantiated claims regarding the optimality of different noise models for adversarial robustness.\n\nDetailed comments:\n\n- All the claims made in the paper regarding the optimality of different noise models  are specific to D_\\infty and D_{MR} robustness. However, they are written in a way to imply that the claims also hold for the standard l_2/l_\\infty robustness which is studied in adversarial ML literature (especially in the abstract and intro section). The authors should make clear the relation between D_\\infty and D_{MR} robustness and the standard notion of robustness of a classifier. Does one imply the other?\n\n- Does the relaxed notion of robustness of a random classifier g (Definition 3) imply a robustness guarantee for the final output of the random classifier, i.e., \\argmax_c P(g(x) = c) ?\n\n- The experiments use the same setup as in Cohen et al, but the results are not compared with those in Cohen et al. It is not clear how to judge the significance of these results without comparison to any other method of evaluating robustness.\n\n- \"However, it is known that adding Gaussian noise often does not lead to \\epsilon-DP, but rather (\\epsilon; \\delta)-DP (Dwork et al., 2014) which has an additional parameter \\delta and thus is harder to be incorporated in our framework. To alleviate this issue, we employ Maximal Relative Renyi Divergence as the probability distance measurement to define another type of robustness, namely D_{MR} robustness.\" - This does not provide sufficient justification for studying D_{MR} robustness.\n\n- A comparison is made between Theorem 10 & Corollary 11 in the paper to Theorem 1 in Cohen et al. However, it is not clear how the result in the paper is better or even equivalent to the one in Cohen et al. D_{MR} robustness seems to be an approximate notion of robustness, while the result in Cohen et al gives perfect robustness within a ball of a certain radius. The radius r in both papers scales linearly with \\sigma. It is said that \"a smaller c yields a larger r compared to Cohen et al.\" It is not clear why that is useful.\n\n- In Theorem 12, each entry in x is restricted to be in the range [0, r/\\sqrt{d}]. This means the l_2 norm of x cannot be more than r. Then, how is it meaningful to discuss the (2r, D_{MR}, l_2, \\epsilon/2) robustness of an algorithm on this data, with the radius of the robust guarantee being 2r?\n\n- In Theorem 12, the lower bound on the expected l_\\infty norm of the random noise is shown to be independent of d, while the expected l_\\infty norm for Gaussian noise scales with \\sqrt{\\log d}. I don't think it is correct to claim that Gaussian noise is \"near\" optimal from this analysis.\n\n-  In Definition 23, it is not clear what Loss(Y||Y') is.\n\nSuggestions for improvement:\n\n- The authors should make it clear in the abstract that the optimality of the noise models is with regards to the newly defined notions of robustness.\n\n- It would be worthwhile to discuss how D_\\infty and D_{MR} robustness differ from standard notions of minimax robustness.\n\n- One possible way to motivate the relaxed robustness introduced in Definition 3 is to link it to the robustness of the randomized classifier in Definition 1.\n\n- Please consider using \\left( \\right) instead of ( ).\n\n- For experiments, it would help to compare D_\\infty and D_{MR} robustness alongside the standard l_2 robustness. In addition to training the network on Gaussian augmented dataset, it might be worthwhile to compare it to other baseline approaches as done in Cohen et al.", "title": "Official Blind Review #2", "rating": "1: Reject", "confidence": 2}, "rkg0VfQCYH": {"type": "review", "replyto": "ryl71a4YPB", "review": "Summary.\nThe authors propose a new definition for robustness of random functions. This definition is ideal for analyzing the certified robustness under randomized smoothing techniques. They analyze and show that the Gaussian smoothing is near optimal for \\ell_2 smoothing as the mean maximum error is only off by a factor of log d where d is the dimension from the optimal mean maximum energy. This is the case even under a more strict definition of robustness defined as D_\\infty. Moreover, the authors show that indeed smoothing with an exponential family  is optimal under D_\\infty robustness metric with radius measured in \\ell_\\infty.\n\n\n\nI find the paper very interesting and the approach is novel and generic. I do not have any major criticism.\n\nMinor comments.\n1) Equation 3 \"D(A(x'),A(x))\" >> \"D_\\infty(A(x'),A(x))\"\n2) Page 6 third line below Theorem 16. Reference of Theorem 11 should be Corollary 11.\n3) The authors should report the certified accuracy of the undefended baseline classifier over varying radius in Figures 1 and 2 and 3.\n4) Running experiments on ImageNet following Cohen et al. should make the paper stronger.\n4) Can the authors comment on is the certified accuracy for \\sigma=0.5 at radius = 0 is better than the unsmoothned classifier a sigma 1.0. I expect that the radius of certification is larger for larger sigma.\n5) The authors should explain how does the new definition of robustness relate to the common robustness definitions as the one by Cohen et al.  More discussion is necessary for this and more justification. \n6) Why is the D_MR defined as maximum over $\\alpha$? It seems it is only sufficient to define it as the ratio over $\\alpha$. It seems that this is only needed for Theorem 8 to hold.\n\n\n------------------------------------------------------------------------\n\nAfter further careful read of several relevant papers, e.g. Bun et. al 2016 and the work of Dwork \"Concentrated Differential Privacy\", I have several questions I would like to ask for some further clarifications.\n\n\n\n1) Showing that a network is robust under $D_{\\infty}$ robustness, implies very strong results. The type of results that are common in the literature. This is since $D_{\\infty}$ robustness, implies $\\epsilon$ DP networks (see Lemma 3.2 and proposition 3.3 of Bun et al.). Once $\\epsilon$ DP is guaranteed identical results of Lecurer et al. can be derived immediately as this implies separation in expectation (Lecurer et al.) where one can study directly the deterministic classifier $\\mathbb{E}g(\\mathbf{x})$ and not the random $g$ studied in this work.\n\n2) The authors rely on the lower bounds of Bun et al. to find the average maximum energy that preserves the $D_{\\infty}$ robustness (Thm 15 and 16). Authors show that indeed exponential smoothing is optimal. This is significant but the analysis was intensively based on Bun et al.\n\n\n3) The relaxation to $D_{MR}$ robustness results into improvement of the dependency on the dimension to $\\sqrt{d}$ instead of $d$ for under $\\ell_\\infty$. This should not be surprising at all and in fact is identical to the results of Bun et al. Note that the zCDP proposed by Bun et al, is a relaxed version of DP where $\\epsilon$-DP for some radius $r$ implies zCDP with radius $r^2$. See proposition 3.3. Therefore, Theorem 6 and 17 are not surprising nor are they new.\n\n\n4) My major concern was with the results relating to Gaussian smoothing. I do understand that since Gaussian smoothing only implies high probability result of DP which is often referred to as ($\\epsilon$,$\\delta$)-DP which happens to be a equivalent to zCDP proposed by Bun et. al. Therefore, I have no issues of using $D_{MR}$ to analyzing the robustness for Gaussian smoothing since it was always analyzed in the DP community with the $\\epsilon,\\delta$-DP and not the stronger $\\epsilon$-DP. However, the statement of the result (Theorem 12) confused me vastly. Let me clarify.\n\n\nTheorem 12 seems to be too good to be true. How is it possible that one can guarantee $D_{MR}$ robustness without any dimensionality dependence. Using Gaussian smoothing the $D_{MR}$ can depend on $\\sqrt{\\log{d}}$. While $\\sqrt{\\log{d}}$ may seem small; improving this to a constant in dimension is still a very big gap from $\\sqrt{\\log{d}}$. This may raise several questions whether one can actually find this optimal smoothing distribution. However, with a careful read of Theorem 12, the range of the input decreases as a function of $\\sqrt{d}$. That is for a given range of input (independent from d), the energy in fact is NOT constant but scales with $\\sqrt{d}$. In such a case, the Gaussian smoothing is now of order $\\sqrt{d \\log{d}}$. Now, the factor is still $\\log{d}$, but now this is very different as indeed improving the Gaussian to $\\sqrt{d}$ may not be of significant interest as the energy still depends in the optimal sense on $\\sqrt{d}$ which does not allow it to scale for larger problems. Moreover, Cohen et al results show that with Gaussian smoothing the energy of the noise scales $\\sqrt{d}$ since the noise energy $\\|n\\| = \\mathcal{O}(\\sqrt{d} \\sigma)$ where $\\sigma$ is std of Gaussian. Therefore, it seems that there is nothing surprising about such a result at all. The statement of the Theorem is very misleading and confusing.\n\nOverall, I like this new approach of analyzing the random smoothed classifier; however, the poor presentation of the work and the mis-represented Theorems that seem to over claim are a major reason for my rating. In addition, the paper should be self-contained in which one should not need to read 2-3 other works to figure out the details in this work and the meaning of the several robustness metrics and their direct relations to DP and Lecuer et al. results. The statement of constant in dimension lower bound on the energy of the noise under $D\\_{MR}$ was to me the major contribution; however, I found now that the statement is misleading and that in fact it is $\\sqrt{d}$ reduces the contribution of the paper particularly after learning that such lower bounds are already derived in Bun et al.", "title": "Official Blind Review #3", "rating": "3: Weak Reject", "confidence": 3}, "Syga-SBqdB": {"type": "rebuttal", "replyto": "HygsIG4q_B", "comment": "Hi Mirman,\n\nThanks for pointing this out. We will refine this sentence as you commented. Apparently, primal over-approximation certification (as you mentioned) is another good direction. But since it is not (very) related to our attempts and theories, we might try to go through those papers and include some details in Appendix later. It is not necessary to mention the details in the main body (a clarification for other readers).\n\nThose methods (you mention) might have the potential to overcome certain limitations we prove here. However, we are not sure about it (except the well-known \"probabilistic\" limitation). So we prefer to study those methods meticulously (on the limitations we prove regarding randomized smoothing) later and include more details in our future work. \n\nThanks.\n\n\n", "title": "We will refine this sentence as you commented. But since the methods you mention are not (very) related to our attempt and theories, we might try to include some details in Appendix later."}, "ByeBRbG5dS": {"type": "rebuttal", "replyto": "B1ez4d1cdS", "comment": "Hi Mirman,\n\nFirst, thanks for your reply. By \"this is not an issue of this paper\", we mean *this is not a big issue* because what we study here is randomized smoothing not IBP. They are *completely* different methods. *The things you mention about IBP (and this direction) are not related to our theories and proof*. Moreover, the main attempt of our paper is to *shed light on those questions regarding randomized smoothing* as we mention in the abstract and introduction *not* compare all the methods. Again, **IBP is a good method but not (very) related to our main attempt, theories and proof.**\n\nSecond, we just want to use \"interval analysis\" (from another work) to summarize those methods including MIP and linear relaxations in that sentence.  It seems not accurate to you, and we will list the methods for clarification in the related work as you commented since we know you are an expert in IBP.\n\nWe do not know why you mention \"our method can not certify anything (when 8/255 l-infty) here (compared with IBP).\" One of our attempts is to prove that **certifying l-infty robustness by randomized smoothing might be hardly scalable**. The experiments show our proof and analysis might be correct (that is all we want to show here). **Given this attempt, we do not know why we should compare the results with IBP?** We acknowledge that IBP might perform better on cifar-10 (8/255 l-infty), but this is indeed not related to what we want to show here.\n\nAs we mentioned in our last comment, **we will clarify the few sentences about IBP** (as you commented). But due to the limited space, it is difficult to clarify all the seemingly related work in the main body, and thus *we will add some background in the Appendix in our revision*. Actually, from our point of view, **differential privacy theory is even more related (than IBP)**, but we put the background in the Appendix due to the limited space.\n\nLast but not least, our attempt is to *give answers (in O()) to those questions regarding randomized smoothing under our framework* not to compare the performance and details with all the other methods. That's why we did not fully discuss *the other methods*. Actually, we even do not have to mention more details about IBP and the other methods you mention, **simply because they are not really very related to our attempt, theories, and proof**.\n\nAgain, IBP is a good method, and thanks for correcting those two sentences.\nBut IBP (and the methods you mention) are indeed not (very) related to our main attempt, theories, and proof.\n\nThanks.\n\n", "title": "We are talking about *ImageNet*, and we will clarify those two sentences about IBP. But actually, **given the main attempt of this paper**, we do not have to compare with IBP, and we even do not have to mention more details about IBP."}, "Byg3XvFvdH": {"type": "rebuttal", "replyto": "SylAUxYPur", "comment": "Hi, Matthew\n\nFirst, thanks for your comments. Here large datasets refer to datasets like ImageNet (*high dimensionality* and large data size)\n\nTo my best knowledge, we have not seen any work that could certify robustness on ImageNet by IBP. A very recent work we know in this direction (IBP) certifies on tiny ImageNet. Pls correct me if our observation is wrong.\n\nTo our knowledge on IBP, we should use the symbolic method to analyze very deep network and ImageNet, otherwise, the error will be very large. However, using symbolic method on very deep network and ImageNet will lead to additional computational cost (and *the error also accumulates layer by layer*).\n\nWe concur with you that *this single sentence* might be a little ambiguous, so we will clarify it in the next revision (as you commented). \n\nHowever, *we do not think this is a (big) issue of this paper*, because what we study in this paper is *randomized smoothing* not IBP. They are completely different methods. More importantly, the main attempt of our paper is to *shed light on those questions regarding randomized smoothing* as we mention in the abstract and introduction *not compare all the methods*.  It means we even do not have to mention the details of IBP in the related work, because it is actually not very related (to our attempt).\n\nThanks for your comment again!\n\n", "title": "Thanks for your comment, here we refer to *ImageNet*."}}}