{"paper": {"title": "Classless Association using Neural Networks", "authors": ["Federico Raue", "Sebastian Palacio", "Andreas Dengel", "Marcus Liwicki"], "authorids": ["federico.raue@dfki.de", "sebastian.palacio@dfki.de", "andreas.dengel@dfki.de", "liwicki@cs.uni-kl.de"], "summary": "Learning based on the relation between two instances of the same unknown class", "abstract": "The goal of this paper is to train a model based on the relation between two instances that represent the same unknown class.  This scenario is inspired by the Symbol Grounding Problem and the association learning in infants.  We propose a novel model called Classless Association.  It has two parallel Multilayer Perceptrons (MLP) that uses one network as a target of the other network, and vice versa.  In addition, the presented model is trained based on an EM-approach, in which the output vectors are matched against a statistical distribution.  We generate four classless datasets based on MNIST, where the input is two different instances of the same digit.  In addition,  the digits have a uniform distribution.  Furthermore, our classless association model is evaluated against two scenarios: totally supervised and totally unsupervised.  In the first scenario, our model reaches a good performance in terms of accuracy and the classless constraint.  In the second scenario, our model reaches better results against two clustering algorithms.\n", "keywords": []}, "meta": {"decision": "Reject", "comment": "The paper explores neural-network learning on pairs of samples that are labeled as either similar or dissimilar. The proposed model appears to be different from standard siamese architectures, but it is poorly motivated. The experimental evaluation of the proposed model is very limited."}, "review": {"BkMGOJDUx": {"type": "rebuttal", "replyto": "ryh_8f9lg", "comment": "We have updated our paper.  The changes are\n* We have improved the clarity and motivation of our model\n* We have evaluated our model to three more classless datasets (Rotated-90 MNIST, Inverted MNIST, and Random Rotation MNIST).\n* We have updated Figure 4 and 5 for showing some random output classification samples instead of the mean of all images.\n* We have added two more examples and demo as supplemental material ", "title": "New revision"}, "BycX8kP8x": {"type": "rebuttal", "replyto": "rkU9hAM4g", "comment": "We thank the anonymous reviewer for reading the paper and providing valuable feedback.  As a general remark, we have improved the clarity of the paper, mainly in the motivation behind the model.  In addition, we have extended the experimental setup with three more classless datasets based on MNIST (Rotated-90 MNIST, Inverted MNIST, and Random Rotation MNIST).  Our findings still hold for these datasets where our model reaches better results than clustering algorithms and promising results in relation with the supervised scenario.  Finally, we have added a few extra examples as supplemental material.\n\n\nRemark:  The previous version of the paper had a mistyping error about the MLP parameters.  We have reported the results of a model that has 200 neurons for each layer instead of two fully connected layers of 200 and 100 neurons, respectively.  We have already fixed this problem in the next version of our paper.  Note that the performance of both architectures is quite similar\n\n\n* We agree that the motivation of the model is not totally clear, and it is fixed in the next version of our paper.  Our constraint is inspired by the Symbol Grounding Problem and the association learning in infants.  The first part of our constraint is to learn without labeled data.  Thus, we have used the statistical distribution as an alternative mechanism for training MLPs.  The second part of our constraint forces us that different instances of the same unknown class must be classified with the same pseudo-class.  As a result, we have used one network as a target of the other network for converging to the same classification.\n\n* We have proposed our model in an optimal scenario where the dataset is balanced, and the number of classes is known.  We believe that our model can handle unknown prior distributions changing the size of the output vector z \\in R^d, where d is not the optimal number of ground-truth classes.  This can be seen as the number of clusters k in K-means.  In addition, the statistical distribution \\phi can be modified as well.\n\n\n* We have evaluated with different batch sizes (M) in our validation set, and the best result was presented in the paper.  Our assumptions are the training rule requires a big batch size for two reasons.  First, the more input samples, the closer to the statistical distribution.  Second, the model needs to learn slowly otherwise, all input samples would be concentrated in one.\n", "title": "Rebuttal Answer"}, "rJa3HkPUl": {"type": "rebuttal", "replyto": "r1uSbyMVx", "comment": "We thank the anonymous reviewer for their comments and time.  As a general remark, we have improved the clarity of the paper, mainly in the motivation behind the model.  In addition, we have extended the experimental setup with three more classless datasets based on MNIST (Rotated-90 MNIST, Inverted MNIST, and Random Rotation MNIST).  Our findings still hold for these datasets where our model reaches better results than clustering algorithms and promising results in relation with the supervised scenario.  Finally, we have added a few extra examples as supplemental material.\n\nRemark:  The previous version of the paper had a mistyping error about the MLP parameters.  We have reported the results of a model that has 200 neurons for each layer instead of two fully connected layers of 200 and 100 neurons, respectively.  We have already fixed this problem in the next version of our paper.  Note that the performance of both architectures is quite similar\n  \n* Thank you for pointing out that the motivation of the model is not clear.  We have improved the clarity of the paper.   Our model is motivated by the Symbol Grounding Problem and infants learning, mainly the binding between abstract concepts and the real world via sensory input signals and the association between the sensory streams via abstract concept.  Thus, an alternative training rule is required where the classes are unknown.  In this paper, we use a simple statistical constraint for learning the association between two streams of information.\n", "title": "Rebuttal Answer"}, "BkWPBkDIe": {"type": "rebuttal", "replyto": "Byq8VfUNl", "comment": "We thank the anonymous reviewer for their comments and time.  As a general remark, we have improved the clarity of the paper, mainly the motivation behind the model.  In addition, we have extended the experimental setup with three more classless datasets based on MNIST (Rotated-90 MNIST, Inverted MNIST, and Random Rotation MNIST).  Our findings still hold for these extra datasets where our model reaches better results than clustering algorithms and promising results in relation with the supervised scenario.  Finally, we have added a few extra examples as supplemental material.\n\nRemark:  The previous version of the paper had a mistyping error about the MLP parameters.  We have reported the results of a model that has 200 neurons for each layer instead of two fully connected layers of 200 and 100 neurons, respectively.  We have already fixed this problem in the next version of our paper.  Note that the performance of both architectures is quite similar\n\n\n* We would like to mention that our model relies on sample pairs of different instances of the same unknown class (\u2018link information\u2019).  However, the relation between two sample pairs is not available in our case (\u2018not-link information\u2019).  We clarify this in the next version of our paper. \n\n* Thank you for pointing out that some details of the model are not clear.  The output classification of the input samples is quite similar when the network is initialized.  For example, arg max_c z_i (i=1,...,m) might be classified as c=2.  The power function gives us the initial boost in order to separate the pseudo-classes since the first iterations. Finally, we agree that a more extensive analysis is useful for the future.\n\n* We agree that is not clear the motivation for using the uniform distribution and how to extend to different cases.  The new version of the paper includes the motivation.  We have selected an optimal case where the dataset is balanced (uniform distribution), and the number of classes is known.  Moreover, our model can be extended to more general cases where the input distribution and the number of classes are unknown.  One way is to change the size of the output vector z \\in R^d, where d is not the optimal number of classes according to the ground-truth.  This step can be seen as deciding the number of clusters k in k-means.\n\n* We are aware of semi-supervised learning with co-training[1,2,3]. However, the strict constraint of our challenge in Symbol Grounding is that the data is totally unlabeled. We agree that a small labeled dataset would improve the performance of our model, but we like to focus on the more challenging problem.\n\n[1] Blum, Avrim, and Tom Mitchell. \"Combining labeled and unlabeled data with co-training.\" Proceedings of the eleventh annual conference on Computational learning theory. ACM, 1998.\n\n[2] Tur, Gokhan. \"Co-adaptation: Adaptive co-training for semi-supervised learning.\" 2009 IEEE International Conference on Acoustics, Speech and Signal Processing. IEEE, 2009.\n\n[3] Sindhwani, Vikas, Partha Niyogi, and Mikhail Belkin. \"A co-regularization approach to semi-supervised learning with multiple views.\" Proceedings of ICML workshop on learning with multiple views. 2005.\n", "title": "Rebuttal Answer"}, "SymWGl7Qe": {"type": "rebuttal", "replyto": "SyQuQDk7l", "comment": "Thank you very much for your question.\nOur model relies on the distribution of the classes  i.e., for a given dataset, the distribution should be known in advance.\nFor the paper, we made experiments assuming a uniform distribution.\nHowever, it is perfectly possible to work with a different distribution (e.g., Gaussian, Zipf).\nChoosing another distribution affects the way we define \\phi (and should be adjusted accordingly).\nFurthermore, we are thinking (as part of the future work) on different strategies where even the prior distribution is unknown.", "title": "RE: Any prior info?"}, "SyQuQDk7l": {"type": "review", "replyto": "ryh_8f9lg", "review": "Interesting paper, but still i do not understand how to define the  \"target distribution (E[z1 , . . . , zm ] \u223c \u03c6 \u2208 Rc )\" why it should be \"uniform\", should we know the prior of the different classes?\n\nThe paper looks correct but still i am not convinced about the experimentation performed. Perhaps another experiment with more challenging data would be welcome. Honestly i don't find a clear motivation for this work however it could have some potential and it would be interested to be presented in conference.\n", "title": "Any prior info?", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "r1uSbyMVx": {"type": "review", "replyto": "ryh_8f9lg", "review": "Interesting paper, but still i do not understand how to define the  \"target distribution (E[z1 , . . . , zm ] \u223c \u03c6 \u2208 Rc )\" why it should be \"uniform\", should we know the prior of the different classes?\n\nThe paper looks correct but still i am not convinced about the experimentation performed. Perhaps another experiment with more challenging data would be welcome. Honestly i don't find a clear motivation for this work however it could have some potential and it would be interested to be presented in conference.\n", "title": "Any prior info?", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}}}