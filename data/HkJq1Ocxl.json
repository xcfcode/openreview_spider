{"paper": {"title": "Programming With a Differentiable Forth Interpreter", "authors": ["Matko Bo\u0161njak", "Tim Rockt\u00e4schel", "Jason Naradowsky", "Sebastian Riedel"], "authorids": ["m.bosnjak@cs.ucl.ac.uk", "t.rocktaschel@cs.ucl.ac.uk", "j.narad@cs.ucl.ac.uk", "s.riedel@cs.ucl.ac.uk"], "summary": "This paper presents the first neural implementation of an abstract machine for an actual language, allowing programmers to inject prior procedural knowledge into neural architectures in a straightforward manner.", "abstract": "There are families of neural networks that can learn to compute any function, provided sufficient training data. However, given that in practice training data is scarce for all but a small set of problems, a core question is how to incorporate prior knowledge into a model. Here we consider the case of prior procedural knowledge, such as knowing the overall recursive structure of a sequence transduction program or the fact that a program will likely use arithmetic operations on real numbers to solve a task. To this end we present a differentiable interpreter for the programming language Forth. Through a neural implementation of the dual stack machine that underlies Forth, programmers can write program sketches with slots that can be filled with behaviour trained from program input-output data. As the program interpreter is end-to-end differentiable, we can optimize this behaviour directly through gradient descent techniques on user specified objectives, and also integrate the program into any larger neural computation graph. We show empirically that our interpreter is able to effectively leverage different levels of prior program structure and learn complex transduction tasks such as sequence sorting or addition with substantially less data and better generalisation over problem sizes. In addition, we introduce neural program optimisations based on symbolic computation and parallel branching that lead to significant speed improvements. ", "keywords": []}, "meta": {"decision": "Invite to Workshop Track", "comment": "This work is stood out for many reviewers in terms of it's clarity (\"pleasure to read\") and originality, with reviewers calling it \"very ambitious\" and \"provocative\". Reviewers find the approach novel, and to fill an interesting niche in the area. All the reviewers were interested in the results, even if they did not buy completely the motivation (what \"practically gained from this formulation\", how does this fit in with prob programming).\n \n The main quality and impact issue is the lack of experimental results and baselines. Several reviewers find that the experiments \"do not fit the claims\", and ask for any type of baselines, even just enumeration. Lacking empirical evidence, there is a desire for a future plan showing what this type of approach could be useful for, even if it cannot really scale. I recommend this paper to be submitted to the workshop track."}, "review": {"HJc4S9VFe": {"type": "rebuttal", "replyto": "HypL9UCul", "comment": "Dear Matko, \n\nWe (the PCs) have reached out to the AC and asked the AC his thoughts regarding your comments to the AC\u2019s meta-review. \n\nThe AC highlights that your rebuttals and resubmission were submitted on Jan. 17th, whereas the original reviews are on Dec 20th. However, you might remember the following instructions sent to authors by us:\n\n\"We recommend you respond to all reviews before January 13th, 2017. The rebuttal period, where authors and reviewers can engage into further discussions, will last until January 20th, 2017 at 5PM EST. Please, do not wait until then to respond to reviewers, but do it as soon as you can in order to give reviewers time to take your answers into account. After January 20th, Area Chairs will make an  accept/reject recommendation for your paper. \"\n\nThe AC, lacking earlier rebuttals, and with only 3 days for a review of a resubmission, had not sufficient notice to collect views and obtain new opinions from the reviewers on this new version. We realize the ICLR guidelines encourage resubmission, but it does not mean encouraging significant rewrites up until the final deadline: those require longer fresh reads and a new review process.  Therefore the decision had to be made based on the final discussions from reviewers based mostly on the material from January 13th. The AC believes that there was not clear enough evidence to overrule the original reviews, which put this work significantly below the accept threshold in the AC\u2019s area. \n\nWe, the PCs, agree with this assessment and thus maintain our decision for this paper.\n\nThat being said, the PCs and AC are supporters of this work, and the clear interest expressed by the reviewers warrants discussion at the conference. For this reason, we recommended this paper to the workshop track ahead of several papers with higher aggregate reviews. Clearly this is not the expectation of the author, but given the details of the situation, we believe this to be a just final decision. ", "title": "Response to request for reconsideration"}, "HJZumkhLx": {"type": "rebuttal", "replyto": "Sk4_FbPVg", "comment": "Thank you for your review and the suggestion regarding improving our empirical studies.  We have included additional experiments, baselines, and discussions that we hope address at least some of these concerns.", "title": "Authors' response"}, "Skws2jjIl": {"type": "rebuttal", "replyto": "rySar3ZEe", "comment": "Thank you for your review and feedback. It\u2019s great to hear that you found the paper provocative and inspiring. You are right that for the tasks in our experiments we are neuralising problems that could also have been solved by an exhaustive search over discrete programs. However, such brute-force enumeration only works if the inputs to the program are discrete, but not dense vector representations (such as image representations or word vectors). Our architecture is designed to be able to backpropagate through the entire execution of a program, thus allowing us to calculate a gradient with respect to input representations. Furthermore, output representations can be used in a downstream neural network that is trained jointly with d4. Admittedly, we did not test this explicitly in our experiments, but instead first focused on providing a testbed for understanding how much prior structural bias a neural architecture needs to solve a certain problem.\n\nIn addition, we added the Seq2Seq baseline to both tasks and expanded the experimental section. We also expanded the adding task description and experimental setting with an additional sketch (based on choose) and showed that it performs better than manipulate, and explained why. Furthermore, we added a \u201cDiscussion\u201d section where we discuss some of the failure cases, and underlying reasons, as well as proposing ways to circumvent them. The conclusion section has been expanded with future work offering both the nuanced outlook and the long-term goals of the framework.", "title": "Authors' response"}, "SyZdnijLl": {"type": "rebuttal", "replyto": "SyVPl5rNg", "comment": "Thank you for pointing out the error in Figure 2. It indeed contained a color coding error. We updated the paper, both explaining this figure in more detail and appropriately fixing section 3.3.1. Regarding additional baselines, we want to note that a Seq2Seq model has already been tested in the NPI paper (Reed et al. 2015) on the sorting and addition tasks and it was found that there is no generalisation for sequences longer than the ones trained on. Still, we added a Seq2Seq baseline to the paper and can confirm the results by Reed et al. (2015). \nFurthermore, we updated the paper with a detailed analysis regarding at which sequence lengths the models are not able to generalise. We argue that due to test-time discretisation, once the model learns the correct behaviour, it is able to generalise to a sequence of any length. We ran our experiments on sequences up to length 64 (we ran it on sequences of lengths 1 2 4 8 16 32 and 64, but displayed only 8 and 64 for brevity) and observed perfect generalisation for all these test lengths. We also expanded both the description of the addition task and its experimental section by adding another more specific sketch to it (based on choose). The experiments show that we are able to generalise to long sequences (tested up to length 64). Note that due to the usage of one-hot encoding for the sequence length counter we are not able to run our models on much longer sequences, a limitation that we know discuss in the \u201cDiscussion\u201d section in the paper. We believe a solution to this issue could be floating point representation, which we plan to investigate for future work.", "title": "Authors' response"}, "HyVZhji8l": {"type": "rebuttal", "replyto": "HkJq1Ocxl", "comment": "Dear reviewers, thank you for your thoughtful reviews. Based on your comments we uploaded an updated version of the paper in which we:\n- added results of a Seq2Seq baseline to both sorting and adding tasks\n- added a much more detailed quantitative analysis, regarding at which sequence length the models are not able to generalise, together with a qualitative evaluation\n- expanded the addition task section with an additional sketch (choose), more text clarifying the sketches and a detailed quantitative analysis\n- added a \u201cDiscussion\u201d section clearly stating the limitations of the presented framework, and discussing failures\nexpanded the conclusion with additional future work, showing both nuanced outlook, and the long-term goals of the framework\n- fixed Figure 2 and added details to section 3.3.1", "title": "New revision overview"}, "rk_XI4vXe": {"type": "rebuttal", "replyto": "SJuTX2Rfx", "comment": "Thank you for your questions. Here are our answers:\n\nAnswer 1\n\nManipulate decoder:\nIn a case of a static encoder, manipulate produces the output of size m * w (m is the number of manipulated stack elements, w is the stack width) which is essentially equal to encoder biases reshaped into m * w.\nIn a case of a observe decoder, the output of the encoder is h = W * input (where W is a learnt matrix, h is of size m * w). Manipulate produces the output of size m * w again, where m * w is essentially the reshaped output of the encoder h.\nIn addition to that, we enable the definition of multiple intermediate hidden layers by chaining linear layers of a set size (linear N) and activation functions (sigmoid, tanh). In this case, manipulate IS an MLP (at least one hidden layer).\n\nPermute decoder:\nThe output of the permute decoder is a linear combination of m! state vectors, one for each permutation of the m chosen stack elements. The weights of this combination are calculated as softmax(W*h) where h is the encoder vector.\n\nWe will make sure to add these details to the next iteration of the paper.\n\nAnswer 2\n\nWhen considering the particular problems presented in the paper, there are 600 states for the bubble sort and 4000 for the adder. However, an aim of our architecture is to allow working with dense vectors as well (e.g. as the output of an RNN). In that sense, we don't look at the problem as a discrete learning problem.\n\nAnswer 3\n\nYes, squared error objective allows us to work with vectors that represent continuous values, not just discrete values. We did experiment with cross entropy loss for problems where the machine state contains only discrete symbols, but in our experiments this did not make a big difference.\n\nAnswer 4\n\nIndeed we do that, as mentioned in paragraph 4: \"During test time we employ memory element discretisation, replacing differentiable stacks and pointers with their discrete counterparts.\" And yes, that improves generalisation to longer sequences.", "title": "Answer"}, "SJuTX2Rfx": {"type": "review", "replyto": "HkJq1Ocxl", "review": "Interesting ideas. A few questions:\n\n- Could you explain in more detail what the Manipulate and Permute decoders do in Sec 3.2? Manipulate just uses an MLP to turn h into a set of m vectors? What is the structure of Permute?\n\n- Is it possible to cast your learning problems as discrete search problems? If so, how large would the search spaces be for the problems considered in the experiments?\n\n- What are the reasons for choosing a squared error objective in Sec 3.5 over cross entropy?\n\n- Is it possible to discretize a learned model and interpret it as a discrete program like in Neural Random Access Machines (Kurach et al)? Would this improve the results on generalizing to longer sequences than seen in training?This paper develops a differentiable interpreter for the Forth programming\nlanguage. This enables writing a program \"sketch\" (a program with parts left\nout), with a hole to be filled in based upon learning from input-output\nexamples. The main technical development is to start with an abstract machine\nfor the Forth language, and then to make all of the operations differentiable.\nThe technique for making operations differentiable is analogous to what is done\nin models like Neural Turing Machine and Stack RNN. Special syntax is developed\nfor specifying holes, which gives the pattern about what data should be read\nwhen filling in the hole, which data should be written, and what the rough\nstructure of the model that fills the hole should be. Motivation for why one\nshould want to do this is that it enables composing program sketches with other\ndifferentiable models like standard neural networks, but the experiments focus\non sorting and addition tasks with relatively small degrees of freedom for how\nto fill in the holes.\n\nExperimentally, result show that sorting and addition can be learned given\nstrong sketches.\n\nThe aim of this paper is very ambitious: convert a full programming language to\nbe differentiable, and I admire this ambition. The idea is provocative and I\nthink will inspire people in the ICLR community.\n\nThe main weakness is that the experiments are somewhat trivial and there are no\nbaselines. I believe that simply enumerating possible values to fill in the\nholes would work better, and if that is possible, then it's not clear to me what\nis practically gained from this formulation. (The authors argue that the point\nis to compose differentiable Forth sketches with neural networks sitting below,\nbut if the holes can be filled by brute force, then could the underlying neural\nnetwork not be separately trained to maximize the probability assigned to any\nfilling of the hole that produces the correct input-output behavior?)\n\nRelated, one thing that is missing, in my opinion, is a more nuanced outlook of\nwhere the authors believe this work is going. Based on the small scale of the\nexperiments and from reading other related papers in the area, I sense that it\nis hard to scale up differentiable forth to large real-world problems. It\nwould be nice to have more discussion about this, and perhaps even an experiment\nthat demonstrates a failure case. Is there a problem that is somewhat more\ncomplex than the ones that appear in the paper where the approach does not work?\nWhat has been tried to make it work? What are the failure modes? What are the\nchallenges that the authors believe need to be overcome to make this work.\n\nOverall, I think this paper deserves consideration for being provocative.\nHowever, I'm hesitant to strongly recommend acceptance because the experiments\nare weak.", "title": "Questions", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "rySar3ZEe": {"type": "review", "replyto": "HkJq1Ocxl", "review": "Interesting ideas. A few questions:\n\n- Could you explain in more detail what the Manipulate and Permute decoders do in Sec 3.2? Manipulate just uses an MLP to turn h into a set of m vectors? What is the structure of Permute?\n\n- Is it possible to cast your learning problems as discrete search problems? If so, how large would the search spaces be for the problems considered in the experiments?\n\n- What are the reasons for choosing a squared error objective in Sec 3.5 over cross entropy?\n\n- Is it possible to discretize a learned model and interpret it as a discrete program like in Neural Random Access Machines (Kurach et al)? Would this improve the results on generalizing to longer sequences than seen in training?This paper develops a differentiable interpreter for the Forth programming\nlanguage. This enables writing a program \"sketch\" (a program with parts left\nout), with a hole to be filled in based upon learning from input-output\nexamples. The main technical development is to start with an abstract machine\nfor the Forth language, and then to make all of the operations differentiable.\nThe technique for making operations differentiable is analogous to what is done\nin models like Neural Turing Machine and Stack RNN. Special syntax is developed\nfor specifying holes, which gives the pattern about what data should be read\nwhen filling in the hole, which data should be written, and what the rough\nstructure of the model that fills the hole should be. Motivation for why one\nshould want to do this is that it enables composing program sketches with other\ndifferentiable models like standard neural networks, but the experiments focus\non sorting and addition tasks with relatively small degrees of freedom for how\nto fill in the holes.\n\nExperimentally, result show that sorting and addition can be learned given\nstrong sketches.\n\nThe aim of this paper is very ambitious: convert a full programming language to\nbe differentiable, and I admire this ambition. The idea is provocative and I\nthink will inspire people in the ICLR community.\n\nThe main weakness is that the experiments are somewhat trivial and there are no\nbaselines. I believe that simply enumerating possible values to fill in the\nholes would work better, and if that is possible, then it's not clear to me what\nis practically gained from this formulation. (The authors argue that the point\nis to compose differentiable Forth sketches with neural networks sitting below,\nbut if the holes can be filled by brute force, then could the underlying neural\nnetwork not be separately trained to maximize the probability assigned to any\nfilling of the hole that produces the correct input-output behavior?)\n\nRelated, one thing that is missing, in my opinion, is a more nuanced outlook of\nwhere the authors believe this work is going. Based on the small scale of the\nexperiments and from reading other related papers in the area, I sense that it\nis hard to scale up differentiable forth to large real-world problems. It\nwould be nice to have more discussion about this, and perhaps even an experiment\nthat demonstrates a failure case. Is there a problem that is somewhat more\ncomplex than the ones that appear in the paper where the approach does not work?\nWhat has been tried to make it work? What are the failure modes? What are the\nchallenges that the authors believe need to be overcome to make this work.\n\nOverall, I think this paper deserves consideration for being provocative.\nHowever, I'm hesitant to strongly recommend acceptance because the experiments\nare weak.", "title": "Questions", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}}