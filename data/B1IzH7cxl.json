{"paper": {"title": "A Neural Stochastic Volatility Model", "authors": ["Rui Luo", "Xiaojun Xu", "Weinan Zhang", "Jun Wang"], "authorids": ["r.luo@cs.ucl.ac.uk", "xuxj@apex.sjtu.edu.cn", "wnzhang@apex.sjtu.edu.cn", "j.wang@cs.ucl.ac.uk"], "summary": "A novel integration of statistical models with recurrent neural networks providing a new way of formulating volatility models.", "abstract": "In this paper, we show that the recent integration of statistical models with recurrent neural networks provides a new way of formulating volatility models that have been popular in time series analysis and prediction. The model comprises a pair of complementary stochastic recurrent neural networks: the generative network models the joint distribution of the stochastic volatility process; the inference network approximates the conditional distribution of the latent variables given the observable ones.\nOur focus in this paper is on the formulation of temporal dynamics of volatility over time under a stochastic recurrent neural network framework. Our derivations show that some popular volatility models are a special case of our proposed neural stochastic volatility model. Experiments demonstrate that the proposed model generates a smoother volatility estimation, and largely outperforms a widely used GARCH model on several metrics about the fitness of the volatility modelling and the accuracy of the prediction.", "keywords": ["Deep learning", "Supervised Learning"]}, "meta": {"decision": "Reject", "comment": "This paper presents an interesting application of variational methods for time series, in particular VRNN-like approaches, for stochastic volatility. Applications such as these are clearly in the scope of the conference, which was a point that one of the reviewer brought up. That said, questions of context, especially with regards to relation to different approaches, especially smoothing are relevant. Also, the number of methods GRACH and stochastic volatility is immense and this makes assessing the impact of this very hard to do and is more is needed to address this point. This paper is certainly interesting, but given these concerns, the paper is not yet rady for acceptance at the conference."}, "review": {"HJ4Lqc8Ue": {"type": "rebuttal", "replyto": "Hy5E206El", "comment": "Dear Reviewer,\n\nThank you very much for your detailed comment and advice.\n\nWe have modified the manuscript according to your suggestions:\n\n1. As we have known, for models that evolve explicitly in terms of the squares of the residuals (e^2), e.g. GARCH, the multi-step-ahead forecasts have closed-form solutions, which means that those forecasts can be efficiently computed in a recursive fashion due to the linear formulation of the model and the exploitation of relation E_{t-1}[e^2_t] = sigma^2_t.\n\nOn the other hand, for models that are not linear or do not explicitly evolve in terms of e^2, e.g. EGARCH (linear but not evolve in terms of e^2), our NSVM (nonlinear and not evolve in terms of e^2), the closed-form solutions are absent and thus the analytical forecast is not available. We will instead use simulation-based forecast, which uses random number generator to simulate draws from the predicted distribution and build up a pre-specified number of paths of the variances at 1 step ahead. The draws are then averaged to produce the forecast of the next step. For n-step-ahead forecast, it requires n iterations of 1-step-ahead forecast to get there.\n\nNSVM is designed as an end-to-end model for volatility estimation and forecast. It takes the price of stocks as input and outputs the distribution of the price at next step. It learns the dynamics using RNN, leading to an implicit, highly nonlinear formulation, where only simulation-based forecast is available. In order to obtain reasonably accurate forecasts, the number of draws should be relatively large, which will be very expensive for computation. Moreover, the number of draws will increase exponentially as the forecast horizon grows, so it will be infeasible to forecast several time steps ahead and that is why we focus on 1-step-ahead forecast.\n\n2. For GARCH volatility forecasts with longer horizon, i.e. multi-step-ahead forecasts, we usually exploit the relationship E_{t-1} [e^2_t] = sigma^2_t to substitute corresponding terms related to the absent observations and calculate the next sigma^2_{t+1} in a recursive fashion, which means that we use the predicted variances of the former steps to calculate the predictions of the latter steps. \n\n3. We have exploit the R packages ``stochvol'' and ``fGarch'' to extend the experiment by including more baselines such as stochvol, ARCH, TARCH, APARCH, AGARCH, NAGARCH, IGARCH, IAVARCH, FIGARCH. The result shows that our model still has the best performance on NLL metric.\n\n4. We have added more details about the network specification as well as the data generating procedure in Sec 5.2 and 5.3 as required.\n\n5. We believe the reason of the ``puzzling'' drops in Fig 4(b) and (c) is that NSVM has captured the jumps and drops of the stock price using its nonlinear dynamics and modelled the sudden changes as part of the trend: the estimated trend ``mu'' goes very close to the real observed price even around the jumps and drops (see the upper figure of Fig 4(b) and (c) around step 1300 and 1600). The residual (i.e. difference between the real value of observation and the trend of prediction) therefore becomes quite small, which lead to a lower volatility estimation.\n\nOn the other hand, for the baselines, we adopt AR as the trend model, which is a relatively simple linear model compared with the nonlinear NSVM. AR would not capture the sudden changes and leave those spikes in the residual; GARCH then took the residuals as input for volatility modelling, resulting in the spikes in volatility estimation.\n\nOur NSVM outperforms GARCH(1,1) on 142 out of 162 stocks on the metric of NLL. In particular, NSVM obtains -2.609 and -1.939 on the stocks corresponding to Fig 4(b) and (c) respectively, both of which are better than the results of GARCH (0.109 and 0.207 lower on NLL).\n\nYour comment enlightened us to carry out more investigations about multistep forecast in the future.\n\nThank you very much for your time and valuable advice.\n\n\nBest regards,\nThe authors", "title": "Feedback from the authors and update of the paper"}, "HJGIpI3Qx": {"type": "rebuttal", "replyto": "rkPV4kDmg", "comment": "Dear Reviewer,\n\nWe are very glad to have your comment, where you have mentioned 3 issues of concern: 1) heavy-tailed distributions fit better than Gaussian in financial modelling; 2) you think the limited size of dataset and the plain structure of financial time series prevents neural networks from learning features; 3) you have concerns about the evaluation procedure and are wondering how we are doing this.\n\nWe agree with you on the first issue that some studies show that heavy-tailed distributions have better fitness to financial time series. We choose Gaussian rather than some heavy-tailed distribution to model the residual for the sake of simplicity. This allows us to model volatility in a principled yet simple way. That said, the higher moments beyond the first and the second can be later incorporated in a neural network, but the discussion beyond the scope of the paper and we leave this for future work.\n\nAs for the second issue, we would not agree as much as the first one. Indeed, the size of dataset we exploited (daily market prices) is limited comparing with those in CV (eg ImageNet). However, we can still learn critical information via neural networks as long as we set an appropriate dimension of networks or introduce some proper prior knowledge. In fact, the neural networks are essentially nothing more than a family of parameterised function approximators with gradient-based optimisation methods. To extract useful information, we would look for the optimal size of parameters by adjusting the dimensions to match the size of dataset and imposing proper constraints that incorporate our prior knowledge. On the other hand, we would say that the structure of financial time series is not ``little'' at all, on the contrary, it can be extremely complicated, as a consequence of the immense interacting factors within financial market. The reason econometricians utilise linear models like GARCH is not that the relations among factors are linear, but that those linear models provide with a good approximation to the latent, probably non-linear dynamics, where the time complexity of exact inference is too high to afford or no closed-form solutions can be obtained. Our proposed model is trying to improve the accuracy (ie. provide better approximation) on limited dataset. In section 4.4, we discussed the link between our model and GARCH, proving that GARCH is merely a special case of our model. It can be seen as a non-linear generalisation of linear model. In the revision of the paper, we have added additional experiments on widely used GARCH and its variants as well as a recent Gaussian processes models (using sampling-based learning algorithm) as baselines, namely GARCH(1,1), EGARCH(1,1), GJR-GARCH(1,1,1) and GPVOL [2]. The result shows that our model has the best predictive performance.\n\nIn the third issue, you've mentioned the sliding window approach. Actually, we have been using a sliding window of size 20 (by time-delay embedding) upon observations in the nearest past to make a one-step prediction in the future. The window then slides one step forward and the predictive procedure repeats so forth, as you described. The thing is we will not retrain the model on the test set (with ~500 points), but just use it to make predictions. The parameters are trained on the training set and held fixed afterwards. Notably, the baselines are retrained at each time step and our model still outperforms among all models.\n\n\nWe would sincerely ask the reviewer to read the sections of formulation, evaluation and comparison one more time to get more technical details.\n\nThank you for your valuable time and advice.\n\n\nBest regards,\nThe authors\n\n\n[1] Rezende, Danilo Jimenez, Shakir Mohamed, and Daan Wierstra. \"Stochastic backpropagation and approximate inference in deep generative models.\" arXiv preprint arXiv:1401.4082 (2014).\n[2] Wu, Yue, Jos\u00e9 Miguel Hern\u00e1ndez-Lobato, and Zoubin Ghahramani. \"Gaussian process volatility model.\" Advances in Neural Information Processing Systems. 2014.", "title": "Answers to the questions"}, "r1AdZ_uQl": {"type": "rebuttal", "replyto": "rkxCjOszx", "comment": "Dear Reviewer,\n\nWe have updated the paper with additional experiment on GPVOL, EGARCH, GJR-GARCH models.\nWe found out that the performance of EGARCH and GJR-GARCH are comparable with the standard GARCH while GPVOL performs poorly on synthetic dataset.\nThe GPVOL in our experiment is almost identical with that in the original paper (same parameter/hyperparameter, slightly modified procedure to fit our setting).\n\n\nBest regards,\nAuthors", "title": "Additional experiment is added in the recent revision"}, "rkPV4kDmg": {"type": "review", "replyto": "B1IzH7cxl", "review": "One well known limitation of GARCH is that its predictive distribution for the next time step is Gaussian. Empirically, it has been shown that when fitting this model to financial data, the residuals are still heavy-tailed. To solve this problem, there are many variants of GARCH that that include heavy-tailed distributions for the noise, instead of Gaussians. Stochastic volatility models have also heavy-tailed predictive distributions. The authors should compare with stronger baselines to really quantify the gains produced by their method with respect to previous work.\n\nIt seems that using recurrent neural networks in this setting is not very well justified. The amount of training data used is not very large (1500 data points) and also financial data has very little structure. Therefore, it is unlikely that the proposed neural networks are able to learn any feature representations that would justify them as an alternative to other modeling approaches such as Gaussian processes for example or other simpler models such as linear models (e.g. GARCH).\n\nThe evaluation process is also a bit strange. The authors evaluate their methods in a window with the last 500 data points. However, the most common approach for evaluating the predictive performance of models for financial time series is to use a sliding window approach in which the model is used to predict only the next point output of the training window. After this, the training window is moved one step forward, the model is retrained and the process repeats. By doing this, the model is always updated with the most up to date data. Why is that the authors do not use this evaluation approach?\n\n\nThe authors propose a recurrent neural network approach for constructing a\nstochastic volatility model for financial time series. They introduce an\ninference network based on a recurrent neural network that computes the\napproximation to the posterior distribution for the latent variables given the\npast data. This variational approximation is used to maximize the marginal\nlikelihood in order to learn the parameters of the model. The proposed method\nis validated in experiments with synthetic and real-world time series, showing\nto outperform parametric GARCH models and a Gaussian process volatility model.\n\nQuality:\n\nThe method proposed seems technically correct, with the exception that in\nequation (19) the inference model is doing filtering and not smoothing, in the\nsense that the posterior for z_t' only depends on those other z_t and x_t\nvalues with t<t', but in the true posterior p(Z|X) each z_t depends on all the\nX. This means the proposed learning method is inefficient. The reference below\nshows how to perform smoothing too and the results in that paper show indeed that\nsmoothing produces better results for learning the model.\n\nSequential Neural Models with Stochastic Layers Fraccaro, Marco and S\\o nderby,\nS\\o ren Kaae and Paquet, Ulrich and Winther, Ole In NIPS 2016.\n\nIt is not clear if the method proposed in the above reference would perform better \njust because of using smoothing when learning the model parameters.\n\nClarity:\n\nThe paper is clearly written and easy to read.\n\nFor the results on real-world data, in Table 1, how is the NLL computed? Is the\naverage NLL across the 162 time series?\n\nOriginality:\n\nThe method proposed is not very original. Previous work has already used the\nvariational approach with the reparametrization trick to learn recurrent neural\nnetworks with stochastic units (see the reference above). It seems that the main\ncontribution of the authors is to apply this type of techniques to the problem\nof modeling financial time series.\n\nSignificance:\n\nThe results shown are significant, the method proposed by the authors\noutperforms previous approaches. However, there is a huge amount of techniques\navailable for modeling financial time-series. The number of GARCH variants is\nprobably close to hundreds, each one claiming to be better than the others.\nThis makes difficult to quantify how important the results are.\n", "title": "Lack of heavy tails in the 1 step-ahead predictive distribution of GARCH and evaluation approach", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "S1149YZNl": {"type": "review", "replyto": "B1IzH7cxl", "review": "One well known limitation of GARCH is that its predictive distribution for the next time step is Gaussian. Empirically, it has been shown that when fitting this model to financial data, the residuals are still heavy-tailed. To solve this problem, there are many variants of GARCH that that include heavy-tailed distributions for the noise, instead of Gaussians. Stochastic volatility models have also heavy-tailed predictive distributions. The authors should compare with stronger baselines to really quantify the gains produced by their method with respect to previous work.\n\nIt seems that using recurrent neural networks in this setting is not very well justified. The amount of training data used is not very large (1500 data points) and also financial data has very little structure. Therefore, it is unlikely that the proposed neural networks are able to learn any feature representations that would justify them as an alternative to other modeling approaches such as Gaussian processes for example or other simpler models such as linear models (e.g. GARCH).\n\nThe evaluation process is also a bit strange. The authors evaluate their methods in a window with the last 500 data points. However, the most common approach for evaluating the predictive performance of models for financial time series is to use a sliding window approach in which the model is used to predict only the next point output of the training window. After this, the training window is moved one step forward, the model is retrained and the process repeats. By doing this, the model is always updated with the most up to date data. Why is that the authors do not use this evaluation approach?\n\n\nThe authors propose a recurrent neural network approach for constructing a\nstochastic volatility model for financial time series. They introduce an\ninference network based on a recurrent neural network that computes the\napproximation to the posterior distribution for the latent variables given the\npast data. This variational approximation is used to maximize the marginal\nlikelihood in order to learn the parameters of the model. The proposed method\nis validated in experiments with synthetic and real-world time series, showing\nto outperform parametric GARCH models and a Gaussian process volatility model.\n\nQuality:\n\nThe method proposed seems technically correct, with the exception that in\nequation (19) the inference model is doing filtering and not smoothing, in the\nsense that the posterior for z_t' only depends on those other z_t and x_t\nvalues with t<t', but in the true posterior p(Z|X) each z_t depends on all the\nX. This means the proposed learning method is inefficient. The reference below\nshows how to perform smoothing too and the results in that paper show indeed that\nsmoothing produces better results for learning the model.\n\nSequential Neural Models with Stochastic Layers Fraccaro, Marco and S\\o nderby,\nS\\o ren Kaae and Paquet, Ulrich and Winther, Ole In NIPS 2016.\n\nIt is not clear if the method proposed in the above reference would perform better \njust because of using smoothing when learning the model parameters.\n\nClarity:\n\nThe paper is clearly written and easy to read.\n\nFor the results on real-world data, in Table 1, how is the NLL computed? Is the\naverage NLL across the 162 time series?\n\nOriginality:\n\nThe method proposed is not very original. Previous work has already used the\nvariational approach with the reparametrization trick to learn recurrent neural\nnetworks with stochastic units (see the reference above). It seems that the main\ncontribution of the authors is to apply this type of techniques to the problem\nof modeling financial time series.\n\nSignificance:\n\nThe results shown are significant, the method proposed by the authors\noutperforms previous approaches. However, there is a huge amount of techniques\navailable for modeling financial time-series. The number of GARCH variants is\nprobably close to hundreds, each one claiming to be better than the others.\nThis makes difficult to quantify how important the results are.\n", "title": "Lack of heavy tails in the 1 step-ahead predictive distribution of GARCH and evaluation approach", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "HJAmDeBme": {"type": "rebuttal", "replyto": "rkxCjOszx", "comment": "Dear Reviewer,\n\nWe are very glad to read your message, it is indeed helpful for this topic!\nAs it is a completely different approach -- Gaussian processes other than neural networks -- to volatility modelling, we have been working on the additional experiments in the past few days using the recently proposed method GPVOL which you've mentioned. We have already got some promising result and hence have confidence in our newly proposed NSVM. Once comprehensive experiment is done, we will provide an updated version of the paper with additional experiment result and comparison.\n\nThank you very much for your time and valuable advice.\n\n\nBest regards,\nAuthors", "title": "Additional experiment and comparison will be presented shortly."}, "rkxCjOszx": {"type": "review", "replyto": "B1IzH7cxl", "review": "Thank you for an interesting read.\n\nThough I'm not very familiar with machine learning applications in Finance, I do notice that the GARCH method you were comparing with has been published around 30 years. Have you ever considered comparing with some recent machine learning methods for volatility, e.g. see the following paper which tested a Gaussian process?\n\nhttps://papers.nips.cc/paper/5376-gaussian-process-volatility-model.pdfThank you for an interesting read.\n\nI found the application of VRNN type generative model to financial data very promising. But since I don't have enough background knowledge to judge whether the performance gap is significant or not, I wouldn't recommend acceptance at this stage. \n\nTo me, the biggest issue for this paper is that I'm not sure if the paper contains significant novelty. The RNN-VAE combination has been around for more than a year and this paper does not propose significant changes to it. Maybe this paper fits better to an application targeting conference, rather than ICLR. But I'm not exactly sure about ICLR's acceptance criteria, and maybe the committee actually prefer great performances and interesting applications?", "title": "comparison to recent methods", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "rytIA0A7e": {"type": "review", "replyto": "B1IzH7cxl", "review": "Thank you for an interesting read.\n\nThough I'm not very familiar with machine learning applications in Finance, I do notice that the GARCH method you were comparing with has been published around 30 years. Have you ever considered comparing with some recent machine learning methods for volatility, e.g. see the following paper which tested a Gaussian process?\n\nhttps://papers.nips.cc/paper/5376-gaussian-process-volatility-model.pdfThank you for an interesting read.\n\nI found the application of VRNN type generative model to financial data very promising. But since I don't have enough background knowledge to judge whether the performance gap is significant or not, I wouldn't recommend acceptance at this stage. \n\nTo me, the biggest issue for this paper is that I'm not sure if the paper contains significant novelty. The RNN-VAE combination has been around for more than a year and this paper does not propose significant changes to it. Maybe this paper fits better to an application targeting conference, rather than ICLR. But I'm not exactly sure about ICLR's acceptance criteria, and maybe the committee actually prefer great performances and interesting applications?", "title": "comparison to recent methods", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}}}