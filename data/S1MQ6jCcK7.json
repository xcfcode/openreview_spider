{"paper": {"title": "ChoiceNet: Robust Learning by  Revealing Output Correlations", "authors": ["Sungjoon Choi", "Sanghoon Hong", "Kyungjae Lee", "Sungbin Lim"], "authorids": ["sungjoon.s.choi@gmail.com", "sanghoon.hong@kakaobrain.com", "kyungjae.lee@cpslab.snu.ac.kr", "sungbin.lim@kakaobrain.com"], "summary": "", "abstract": "In this paper, we focus on the supervised learning problem with corrupt training data. We assume that the training dataset is generated from a mixture of a target distribution and other unknown distributions. We estimate the quality of each data by revealing the correlation between the generated distribution and the target distribution. To this end, we present a novel framework referred to here as ChoiceNet that can robustly infer the target distribution in the presence of inconsistent data. We demonstrate that the proposed framework is applicable to both classification and regression tasks. Particularly, ChoiceNet is evaluated in comprehensive experiments, where we show that it constantly outperforms existing baseline methods in the handling of noisy data in synthetic regression tasks as well as behavior cloning problems. In the classification tasks, we apply the proposed method to the MNIST and CIFAR-10 datasets and it shows superior performances in terms of robustness to different types of noisy labels.", "keywords": ["Robust Deep Learning", "weakly supervised learning"]}, "meta": {"decision": "Reject", "comment": "The paper addresses an interesting problem (learning in the presence of noisy labels) and provides extensive experiments. However, while the experiments in some sense cover a good deal of ground, reviewers raised issues with their quality, especially concerning baselines and depth (in terms of realism of the data). The authors provided many additional experiments during the rebuttal, but the reviewers did not find them sufficiently convincing."}, "review": {"B1eAxJHGa7": {"type": "review", "replyto": "S1MQ6jCcK7", "review": "This paper presents an apparently original method targeted toward models training in the presence of low-quality or corrupted data. To accomplish this they introduce a \"mixture of correlated density network\" (MCDN), which processes representations from a backbone network, and the MCDN models the corrupted data generating process. Evaluation is on a regression problem with an analytic function, two MuJoCo problems, MNIST, and CIFAR-10.\n\nThis paper's primary strength is that the proposed method is a tool quite distinct from recent work, in that it does not use bootstrapping or solely use corruption transition matrices. The paper is typeset well. In addition to this, the experimentation has unusual breadth.\n\nHowever, the synthetic regression task is a nice proof-of-concept, but thorough regression evaluation could perhaps include the Boston Housing Prices dataset or some UCI datasets.\n\nThe hamartia of this paper is that it does not provide sufficient depth in its computer vision experiments. For one, experimentation on CIFAR-100 would be appreciated.\nIn the CIFAR-10 experiments, they consider one label corruption setting and lack experimentation on uniform label corruptions.\nThe related works has thorough coverage on label corruption, but these works do not appear in the experiments. They instead compare their label corruption technique to mixup, a general-purpose network regularizer. It is not clear why it is thought the \"state-of-the-art technique on noisy labels\"; this may be true among network regularization approaches (such as dropout) but not among label correction techniques. For this problem I would expect comparison to at least three label correction techniques, but the comparison is to one technique which was not primarily designed for label corruption.\n\n\nNitpicks:\n-In the related works we are told that a smaller learning rate can improve label corruption robustness. They train their method with a learning rate of 0.001; the baseline gets a learning rate of 0.1.\n-The larger-than-usual batch size is 256 for their 22-4 Wide ResNets, and at the same time they do not use dropout (standard for WRNs of this width) and use less weight decay than is common. Is this because of mixup? If so why is the weight decay two orders of magnitude less for your approach compared to the baseline? How were these various atypical parameters chosen?\n-They also use gradient clipping for their method, which is extremely rare for CIFAR-10 classification. Why is this necessary?\n-This document could be cleaner by eschewing the Theorem of this paper, which \"states that a correlation between two random matrices is invariant to an affine transform.\" For this audience, I suspect this theorem is unnecessary. Likewise the three lines expended for the maths of a Gaussian probability density function could probably be used for other parts of this paper.\n-\"a leverage optimization method which optimizes the leverage of each demonstrations is proposed. Unlike to former study,\" -> \"a leverage optimization method which optimizes the leverage of each demonstration is proposed. Unlike a former study,\"\n-\"In the followings,\" -> \"In the following,\"\n\nEdit: The updated results need consistent baselines. For example, the method of [7] should be consistently compared against.", "title": "Interesting Approach with Insufficient Results", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "B1eqVtIKRm": {"type": "rebuttal", "replyto": "ByeZ3mlo3m", "comment": "We conducted additional experiments based on other reviews where we observe that the proposed method show superior performance to symmetric noises but vulnerable to asymmetric noise on CIFAR-10 following the settings in [3]. We implement the 9-layer CNN architecture following VAT [5] and Co-teaching [3] to fairly evaluate the performance of CIFAR10 experiments with both symmetric and asymmetric noise settings: Pair-45%, Symmetry-50%, and Symmetry-20%, using the authors\u2019 implementations available on github. Pair-45% flips 45% of each label to the next label. For example, randomly flipping 45% of label 1 to label 2 and label 2 to label3. On the other hand, Symmetriy-50% randomly assigns 50% of each label to other labels uniformly. For example, Symmetriy-50% randomly flips 50% the labels of instances whose original label is 1 to a random label sampled from 2-10. \n\nWe set other configurations such as the network topology and an activation functions to be the same as [3]. \n\n(Single-run, last validation accuracy)\n              Pair-45%  sym-50%   sym-20% \n------------------------------------------\nChoiceNet     70.3%     85.2%     91.0%\n------------------------------------------\nMentorNet     58.14%    71.10%    80.76%\nCo-teaching   72.62%    74.02%    82.32%\nF-correction  6.61%     59.83%    84.55%\n\nThe results of MentorNet [6], Co-teaching [3], and F-correction [7] are copied from [3]. While our proposed method outperforms all compared methods on symmetric noise settings, it shows inferior performances to Co-teaching. This shows the weakness of the proposed method. In other words, our mixture distribution failed to correctly infer the dominant distribution which shows the weakness of the mixture-based method. However, we would like to note that Co-teaching [5] is complementary to our method where one can combine these two methods by using two ChoiceNets and update each network using Co-teaching. \n\n* We also conducted additional experiments to show the strength of the proposed method. \n\na). More baselines to current CIFAR-10 experiments: We implemented MentorNet [6] and VAT [5] to better evaluate the performance of the proposed method on current CIFAR-10 setting. \n\ncorruption rate     20%     50%      80%\n----------------------------------------------\nMentorNet PD        64.0%   49.0%    21.4%\nMentorNet DD        62.0%   43.1%    21.8%\nVAT                 82.0%   71.6%    16.9%\n----------------------------------------------\nCN+Mixup            92.3%   87.9%    75.4% \n\nb) Natural language processing experiments: We used a Large Movie Review Dataset consist of 25,000 movie reviews for training and 25,000 reviews for testing. Each movie review (sentences) is mapped to a 128-dimensional feature vector using feed-forward Neural-Net Language Models [8] and we tested the robustness of the proposed method, mix-up, and naive MLP baseline by randomly flipping the labels. \n\nrandom flip rate    0%      10%     20%     30%     40%\n-------------------------------------------------------------\nChoiceNet           79.43%  79.50%  78.66%  77.10%  73.98%\nMix-up              79.77%  78.73%  77.58%  75.85%  69.63%\nBaseline (MLP)      79.04%  77.88%  75.70%  69.05%  62.83%\nVAT                 76.40%  72.50%  69.20%  65.20%  58.30%\n\nSimilar to regression experiments, ChoiceNet shows the superior performance in the presence of outliers where we observe that the proposed method can be used for NLP tasks as well. \n\n[1] V. Belagiannis, C. Rupprecht, G, Carneiro, N. Navab, \"Robust Optimization for Deep Regression\", ICCV, 2015\n[2] H. Zhang, M. Cisse, Y. Dauphin, D. Lopez-Paz, \u201cmixup: Beyond Empirical Risk Minimization\u201c, ICLR, 2018.\n[3] B. Han, Q. Yao, X. Yu, G. Niu, M. Xu, W. Hu, I. Tsang, M. Sugiyama, \u201cCo-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels\u201d, NIPS, 2018. \n[4] Platanios, E. Antonios, A. Dubey, and T. Mitchell. \"Estimating accuracy from unlabeled data: A bayesian approach.\" International Conference on Machine Learning. 2016.\n[5] T. Miyato, S. Maeda, M. Koyama, and S. Ishii. Virtual adversarial training: A regularization method for supervised and semi-supervised learning. ICLR, 2016.\n[6] L. Jiang, Z. Zhou, T. Leung, L. Li, and L. Fei-Fei. Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels. In ICML, 2018.\n[7] G. Patrini, A. Rozza, A. Menon, R. Nock, and L. Qu. Making deep neural networks robust to label noise: A loss correction approach. In CVPR, 2017.\n[8] Y. Bengio, R. Ducharme, P. Vincent, C. Jauvin. A Neural Probabilistic Language Model. Journal of Machine Learning Research, 3:1137-1155, 2003.", "title": "More experiments + modified related work + limitations (2/2)"}, "BkxWU_UtR7": {"type": "rebuttal", "replyto": "B1eAxJHGa7", "comment": "[1] B. Han, Q. Yao, X. Yu, G. Niu, M. Xu, W. Hu, Ivor W. Tsang, M. Sugiyama, \u201cCo-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels\u201d, NIPS, 2018. \n[2] V. Belagiannis, C. Rupprecht, G. Carneiro, N. Navab, \"Robust Optimization for Deep Regression\", ICCV, 2015\n[3] Y. Bengio, R. Ducharme, P. Vincent, C. Jauvin. A Neural Probabilistic Language Model. Journal of Machine Learning Research, 3:1137-1155, 2003.\n[4] H. Zhang, M. Cisse, Y. Dauphin, D. Lopez-Paz, \u201cmixup: Beyond Empirical Risk Minimization\u201c, ICLR, 2018.\n[5] T. Miyato, S. Maeda, M. Koyama, and S. Ishii. Virtual adversarial training: A regularization method for supervised and semi-supervised learning. ICLR, 2016.\n[6] L. Jiang, Z. Zhou, T. Leung, L. Li, and L. Fei-Fei. Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels. In ICML, 2018.\n[7] G. Patrini, A. Rozza, A. Menon, R. Nock, and L. Qu. Making deep neural networks robust to label noise: A loss correction approach. In CVPR, 2017.\n[8] P. Goyal, P. Doll\u00e1r, R. Girshick, P. Noordhuis, \u201cAccurate, Large Minibatch SGD: Training ImageNet in 1 Hour\u2019, ArXiv, 2018. \n[9] K. He, et al. \"Deep residual learning for image recognition.\u201d, CVPR, 2016.", "title": "References"}, "Syxsn_8KRQ": {"type": "rebuttal", "replyto": "B1eAxJHGa7", "comment": "We thank the reviewer for the helpful comments. Especially, we agree that more in-depth experiments would be helpful for convincing the strength of the proposed method. In this regards, we conducted four additional experiments: a) robust regression experiments using a real-world dataset, b) experiments on NLP tasks, c) more baselines (MentorNet and VAT) on current CIFAR-10 experiments, and d) experiments with both symmetric and asymmetric following the recent work [1].\n\na). Robust regression experiments: Here, we used the Boston housing price dataset and checked the robustness of the proposed method and compared our method with standard MLPs with four different types of loss functions: standard L2-loss, L1-loss which is known to be robust to outliers, a robust loss function proposed in [2], and a leaky robust function extending [2]. We implement the leaky version in that the Tukey\u2019s biweight function discards the instances whose residuals exceed a certain threshold. Two-layer MLPs with 128 units and a relu activation is used for all scenarios. We vary the outlier ratio from 0% to 40% where the outputs of the outliers are uniformly sampled within the minimum and the maximum values of the training outputs. The results are as follows:\n\noutlier rate \t0%    5%    10%   15%   20%    30%    40%    50%\n-----------------------------------------------------------------------\nChoiceNet       3.29  3.71  3.99  4.45  4.77   5.94   6.80   9.00\nL2 loss         3.22  4.61  5.97  6.65  7.51   9.04   9.88   10.92\nL1 loss         3.26  4.36  5.72  6.61  7.16   8.65   9.69   10.33\nRobust loss     4.28  4.63  6.36  6.59  8.08   10.54  10.94  11.96\nLeaky Robust    3.36  4.51  5.71  6.54  7.08   8.67   9.68   10.46\n\nThe proposed method (ChoiceNet) outperforms all compared methods in the presence of outliers and shows a comparable performance without the outlier. \n\n2. Natural language processing experiments: We used a Large Movie Review Dataset consist of 25,000 movie reviews for training and 25,000 reviews for testing. Each movie review (sentences) is mapped to a 128-dimensional embedding vector using feed-forward Neural-Net Language Models [3] and we tested the robustness of the proposed method, mix-up [4], VAT [5], and naive MLP baseline by randomly flipping the labels. In all experiments, we used two-layer MLPs with 128 hidden units and ReLU activations. \n\nrandom flip rate    0%      10%     20%     30%     40%\n-------------------------------------------------------------\nChoiceNet           79.43%  79.50%  78.66%  77.10%  73.98%\nMix-up              79.77%  78.73%  77.58%  75.85%  69.63%\nBaseline (MLP)      79.04%  77.88%  75.70%  69.05%  62.83%\nVAT                 76.40%  72.50%  69.20%  65.20%  58.30%\n\nSimilar to regression experiments, ChoiceNet shows the superior performance in the presence of outliers where we observe that the proposed method can be used for NLP tasks as well. \n\n3. More baselines to current CIFAR-10 experiments: We compared MentorNet [6] and VAT [5] to better evaluate the performance of the proposed method on the current CIFAR-10 setting. For MentorNet, we compare two methods: MentorNet PD which uses the pre-de\ufb01ned curriculum to train StudentNet and the other, MentorNet DD, which uses data-driven curriculum to train StudentNet where we use Resent-101 for the StudentNet following the author\u2019s implementations. We would like to note that the base networks of the StudentNet are not the same as the one we used for ChoiceNet, but even bigger. Due to the limited time for tuning the hyper-parameters, we simply used the existing implementations while changing the train and test dataset. To measure the robustness of compared methods, we vary the corruption probabilities from 20% to 80% and the results are as follows where the results of CN and CN+Mixup are copied from the current manuscript. We're working on reproducing MentorNet and VAT on the exact same network architecture.\n\ncorruption rate     20%     50%      80%\n----------------------------------------------\nMentorNet PD        64.0%   49.0%    21.4%\nMentorNet DD        62.0%   43.1%    21.8%\nVAT                 82.0%   71.6%    16.9%\n----------------------------------------------\nCN                  90.3%   84.6%    65.2%\nCN+Mixup            92.3%   87.9%    75.4% \n\nIn all cases, the proposed methods (CN and CN+Mixup) outperforms the baselines. ", "title": "More experiments (robust regression, nlp, more baselines, and both symmetric and asymmetric noisy datasets) 1/2 "}, "BylM8YLYRQ": {"type": "rebuttal", "replyto": "ByeZ3mlo3m", "comment": "We thank the reviewer for the valuable comments, especially the suggestions regarding the related work. We admit that the current explanation about the proposed method is not straightforward and has some rooms for the improvements. Followings are the motivation of the proposed method and we will revise the manuscript so that the readers can better understand the concept more easily. (We didn\u2019t modify this part of the manuscript yet).\n\n1. To handle noisy data, we reveal the quality of each data using the notion of correlation between output features. Specifically, we model the data to be collected from a mixture of a target distribution p(y|x) and other irrelevant distributions q(y|x). We quantify the irrelevancy (or independency) by correlation \u03c1 between p(y|x) and q(y|x) where \u03c1 \u2208 [\u22121, 1]. Intuitively speaking, corrupted data will be modeled to be collected from a class of q(y|x) with small rho e.g. \u03c1 = 0.\n\n2. We model the target conditional distribution p(y|x) using a parametrized distribution with expected measurement variance \u03c4 \u22121 , i.e., p(y|x; \u03b8) = N(y; f \u03b8 (x), \u03c4 \u22121 ) where f \u03b8 (\u00b7) is a neural network and \u03b8 is a set of parameters including \u00b5_W and \u03a3_W . The Cholesky transform is proposed to construct a \u03c1-correlated conditional distribution using \u03b8 and \u03c1. In other words, the correlation between q(y|x; \u03b8) (constructed from the Cholesky transform) and p(y|x; \u03b8) is \u03c1.\n\n3. Now, we can construct a mixture model of the target distribution, p(y|x; \u03b8), and other distributions, q \u03c1 (y|x; \u03b8) parametrized by \u03b8 and the correlation parameter \u03c1. However, we still need to assess the quality (correlation) of each data point. Since the correlation information is not explicitly given, we model the correlation of each data to be a function of an input x, i.e., \u03c1 \u03c6 (x), parametrized by \u03c6 and jointly optimize \u03c6 and \u03b8 using a mixture distribution. The mixture of correlated density network (MCDN) block is proposed for this purpose.\n\nFollowing the reviewer\u2019s comments, we conducted additional regression experiments using the Boston housing dataset. Here, we used the Boston housing price dataset and checked the robustness of the proposed method and compared with standard multi-layer perceptrons with four different types of loss functions: standard L2-loss, L1-loss which is known to be robust to outliers, a robust loss function proposed in [1], and a leaky robust function extending [1]. We further implement the leaky version of [1] in that the original loss function with Tukey\u2019s biweight function discards the instances whose residuals exceed certain threshold. \n\nOutlier rate \t0%    5%    10%   15%   20%    30%    40%    50%\n-----------------------------------------------------------------------\nChoiceNet       3.29  3.71  3.99  4.45  4.77   5.94   6.80   9.00\nL2 loss         3.22  4.61  5.97  6.65  7.51   9.04   9.88   10.92\nL1 loss         3.26  4.36  5.72  6.61  7.16   8.65   9.69   10.33\nRobust loss     4.28  4.63  6.36  6.59  8.08   10.54  10.94  11.96\nLeaky Robust    3.36  4.51  5.71  6.54  7.08   8.67   9.68   10.46\n\nWe also modify the naming convention in the experiment section, e.g., ConvNet+CN+Mixup.In fact, we believe this naming convention can help understanding the benefit of the proposed method. In fact, it can be combined with other methods for achieving robustness such as mixup [2] or co-teaching [3] as these methods are compatible with our method. \nWe rewrote the related work section to better categorize existing and current studies and added [4] to the related work. ", "title": "More experiments + modified related work + limitations (1/2) "}, "B1xx0YLtAm": {"type": "rebuttal", "replyto": "SyxB2-Bd3m", "comment": "3. Motivation: \n\nAs reviewer 1 and 3 pointed out, the manuscript requires more explanations regarding the proposed methods, Cholesky transform and MCDN block. Let us brie\ufb02y explain the motivations (backgrounds) and the practical meanings of the proposed methods. We will add them to the revised version. (We didn\u2019t modify this part of the manuscript yet).\n\n1. To handle noisy data, we reveal the quality of each data using the notion of correlation between output features. Specifically, we model the data to be collected from a mixture of a target distribution p(y|x) and other irrelevant distributions q(y|x). We quantify the irrelevancy (or independency) by correlation \u03c1 between p(y|x) and q(y|x) where \u03c1 \u2208 [\u22121, 1]. Intuitively speaking, corrupted data will be modeled to be collected from a class of q(y|x) with small rho e.g. \u03c1 = 0.\n\n2. We model the target conditional distribution p(y|x) using a parametrized distribution with expected measurement variance \u03c4 \u22121 , i.e., p(y|x; \u03b8) = N(y; f \u03b8 (x), \u03c4 \u22121 ) where f \u03b8 (\u00b7) is a neural network and \u03b8 is a set of parameters including \u00b5_W and \u03a3_W . The Cholesky transform is proposed to construct a \u03c1-correlated conditional distribution using \u03b8 and \u03c1. In other words, the correlation between q(y|x; \u03b8) (constructed from the Cholesky transform) and p(y|x; \u03b8) is \u03c1.\n\n3. Now, we can construct a mixture model of the target distribution, p(y|x; \u03b8), and other distributions, q \u03c1 (y|x; \u03b8) parametrized by \u03b8 and the correlation parameter \u03c1. However, we still need to assess the quality (correlation) of each data point. Since the correlation information is not explicitly given, we model the correlation of each data to be a function of an input x, i.e., \u03c1 \u03c6 (x), parametrized by \u03c6 and jointly optimize \u03c6 and \u03b8 using a mixture distribution. The mixture of correlated density network (MCDN) block is proposed for this purpose.\n\n\n[1] L. Jiang, Z. Zhou, T. Leung, L. Li, and L. Fei-Fei. Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels. In ICML, 2018.\n[2] T. Miyato, S. Maeda, M. Koyama, and S. Ishii. Virtual adversarial training: A regularization method for supervised and semi-supervised learning. ICLR, 2016.\n[3] B. Han, Q. Yao, X. Yu, G. Niu, M. Xu, W. Hu, I. Tsang, M. Sugiyama, \u201cCo-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels\u201d, NIPS, 2018. \n[4] G. Patrini, A. Rozza, A. Menon, R. Nock, and L. Qu. Making deep neural networks robust to label noise: A loss correction approach. In CVPR, 2017.\n[5] Y. Bengio, R. Ducharme, P. Vincent, C. Jauvin. A Neural Probabilistic Language Model. Journal of Machine Learning Research, 3:1137-1155, 2003.", "title": "Modification on related work + more experiments (2/2)"}, "H1lLgc8YCm": {"type": "rebuttal", "replyto": "SyxB2-Bd3m", "comment": "We appreciate the reviewer for the valuable reviews. \n\n1. Related work: We admit that the current manuscript lacks comprehensive curation of related work. We rewrote the whole related work section and categorized existing work into four groups and try to compare them in a more principled way. Please refer to the revised manuscript. \n\n2. Experiments: Following the review, we conducted three additional experiments: a) more baselines (MentorNet and VAT), b) using both symmetric and asymmetric noisy data, and c) using an NLP dataset.\n\na). More baselines to current CIFAR-10 experiments: We implemented MentorNet [1] and VAT [2] to better evaluate the performance of the proposed method on current CIFAR-10 setting. \n\ncorruption rate     20%     50%      80%\n----------------------------------------------\nMentorNet PD        64.0%   49.0%    21.4%\nMentorNet DD        62.0%   43.1%    21.8%\nVAT                 82.0%   71.6%    16.9%\n----------------------------------------------\nCN                  90.3%   84.6%    65.2%\nCN+Mixup            92.3%   87.9%    75.4% \n\nIn all cases, the proposed methods (CN and CN+Mixup) outperforms the baselines. \n\n\nb) Asymmetric noise experiments following Co-teaching [3]. We implement the 9-layer CNN architecture following VAT [2] and Co-teaching [3] to fairly evaluate the performance of CIFAR10 experiments with both symmetric and asymmetric noise settings: Pair-45%, Symmetry-50%, and Symmetry-20%, using the authors\u2019 implementations available on github. We also set other configurations such as having no data augmentation and activation functions to be the same as [3]. \n\n(Single-run, last validation accuracy)\n              Pair-45%  sym-50%   sym-20% \n------------------------------------------\nChoiceNet     70.3%     85.2%     91.0%\n------------------------------------------\nMentorNet     58.14%    71.10%    80.76%\nCo-teaching   72.62%    74.02%    82.32%\nF-correction  6.61%     59.83%    84.55%\n\nThe results of MentorNet [1], Co-teaching [3], and F-correction [4] are copied from [3]. While our proposed method outperforms all compared methods on symmetric noise settings, it shows inferior performances to Co-teaching. This shows the weakness of the proposed method. In other words, our mixture distribution failed to correctly infer the dominant distribution which shows the weakness of the mixture-based method. However, we would like to note that Co-teaching [3] is complementary to our method where one can combine these two methods by using two ChoiceNets and update each network using Co-teaching. \n\nc) Natural language processing experiments: We used a Large Movie Review Dataset consist of 25,000 movie reviews for training and 25,000 reviews for testing. Each movie review (sentences) is mapped to a 128-dimensional feature vector using feed-forward Neural-Net Language Models [5] and we tested the robustness of the proposed method, mix-up, and naive MLP baseline by randomly flipping the labels. \n\nrandom flip rate    0%      10%     20%     30%     40%\n-------------------------------------------------------------\nChoiceNet           79.43%  79.50%  78.66%  77.10%  73.98%\nMix-up              79.77%  78.73%  77.58%  75.85%  69.63%\nBaseline (MLP)      79.04%  77.88%  75.70%  69.05%  62.83%\nVAT                 76.40%  72.50%  69.20%  65.20%  58.30%\n", "title": "Modification on related work + more experiments (1/2) "}, "rklBiO8YAQ": {"type": "rebuttal", "replyto": "B1eAxJHGa7", "comment": "4. Asymmetric noise experiments following Co-teaching [1]. We implement the 9-layer CNN architecture following VAT [5] and Co-teaching [1] to fairly evaluate the performance of CIFAR10 experiments with both symmetric and asymmetric noise settings: Pair-45%, Symmetry-50%, and Symmetry-20%. Pair-45% flips 45% of each label to the next label. For example, randomly flipping 45% of label 1 to label 2. We used the authors\u2019 implementations available on the github for generating the corrupted datasets. We also set configurations such as network topology (except for adding a MCDN layer instead of a linear layer), learning rate, optimizer max epoch to be the same as [1].\n\n(Single-run, last validation accuracy)\n              Pair-45%  sym-50%   sym-20% \n------------------------------------------\nChoiceNet     70.3%     85.2%     91.0%\n------------------------------------------\nMentorNet     58.14%    71.10%    80.76%\nCo-teaching   72.62%    74.02%    82.32%\nF-correction  6.61%     59.83%    84.55%\n\nThe results of MentorNet [6], Co-teaching [1], and F-correction [7] are copied from [1]. While our proposed method outperforms all compared methods on symmetric noise settings, it shows inferior performances to Co-teaching. This shows the weakness of the proposed method. In other words, our mixture distribution failed to correctly infer the dominant distribution which shows the weakness of the mixture-based method. However, we would like to note that Co-teaching [1] is complementary to our method where one can combine these two methods by using two ChoiceNets and update each network using Co-teaching. \n\n- We did not conduct CIFAR-100 experiments due to the limited time and computation resources available. However, we plan to do additional experiments following the settings from Co-teaching [1].\n\nResponses to nitpicks:\n-In the related works we are told that a smaller learning rate can improve label corruption robustness. They train their method with a learning rate of 0.001; the baseline gets a learning rate of 0.1. \n=> The learning rate of 0.001 is only applied for the first epoch and the base learning rate of 0.1 is applied afterward. This technique is often called 'warming-up'. We will modify the manuscript so that there's no confusion about this [8,9].\n\n-The larger-than-usual batch size is 256 for their 22-4 Wide ResNets, and at the same time they do not use dropout (standard for WRNs of this width) and use less weight decay than is common. Is this because of mixup? If so why is the weight decay two orders of magnitude less for your approach compared to the baseline? How were these various atypical parameters chosen?\n=> The optimal hyper-parameters of the proposed ChoiceNet varies from the standard resnet in that the way we train the network is totally different. The manual tuning of the hyper-parameters of both our method and baseline methods are automatically selected from the blackbox optimization method using a separate validation set. \n\n-They also use gradient clipping for their method, which is extremely rare for CIFAR-10 classification. Why is this necessary?\n=> The gradient clipping is used to stabilize training. The main reason is that the proposed method first \u2018samples\u2019 a set of weights of the network and use the sampled parameters for inference. This seldom causes instability in the training phase.\n\n-This document could be cleaner by eschewing the Theorem of this paper, which \"states that a correlation between two random matrices is invariant to an affine transform.\" For this audience, I suspect this theorem is unnecessary. Likewise the three lines expended for the maths of a Gaussian probability density function could probably be used for other parts of this paper.\n=> We agree that current paper only uses a Gaussian prior distribution over the weight matrices. However, the theorem itself does not assume the Gaussian distribution. In fact, any centered distributions such as Gaussian or Laplacian can be used to model the weight matrices. \n\nOther typos will be modified in the revised manuscript. ", "title": "More experiments (robust regression, nlp, more baselines, and both symmetric and asymmetric noisy datasets) 2/2"}, "ByeZ3mlo3m": {"type": "review", "replyto": "S1MQ6jCcK7", "review": "The paper presents a framework, called ChoiceNet, for learning when the \nsupervision outputs (e.g., labels) are corrupted by noise. The method relies on \nestimating the correlation between the training data distribution and a \ntarget distribution, where training data distribution is assumed to be a mixture \nof that target distribution and other unknown distributions. The paper also \npresents some compelling results on synthetic and real datasets, for both \nregression and classification problems.\n\nThe proposed idea builds on top of previously published work on Mixture Density \nNetworks (MDNs) and Mixup (Zhang et al, 2017). The main difference is the MDN \nare modified to construct the Mixture of Correlated Density Network (MCDN) \nblock, that forms the main component of ChoiceNets.\n\nI like the overall direction and idea of modelling correlation between the \ntarget distribution and the data distribution to deal with noisy labels. The \nresults are also compelling and I thus lean towards accepting this paper. My \ndecision on \"marginal accept\" is based primarily on my unfamiliarity with this \nspecific area and that some parts of the paper are not very easy or intuitive \nto read through.\n\n== Related Work ==\n\nI like the related work discussion, but would emphasize more the connection to \nMDNs and to Mixup. Only one sentence is mentioned about Mixup but reading \nthrough the abstract and the introduction that is the first paper that came to \nmy mind and thus I believe that it may deserve a bit more discussion.\n\nAlso, there are a couple more papers that felt relevant to this work but are \nnot mentioned:\n  - Estimating Accuracy from Unlabeled Data: A Bayesian Approach, Platanios et al., ICML 2016.\n    I believe this is related in how noisy labels are modeled (i.e., section 3 \n    in the reviewed paper) and in the idea of correlation/consistency as a means \n    to detect errors. There are couple more papers in this line of work that \n    may be relevant.\n  - ADIOS: Architectures Deep In Output Space, Al-Shedivat et al., ICML 2016.\n    I believe this is related in learning some structure in the output space, \n    even though not directly dealing with noisy labels.\n\n== Method ==\n\nI believe the methods section could have been written in a more \nclear/easy-to-follow way, but this may also be due to my unfamiliarity with this \narea. Figure 1 is hard to parse and does not really offer much more than section \n3.2 currently does. If the figure is improved with some more text/labels on \nboxes rather than plain equations, it may go a long way in making the methods \nsection easier to follow.\n\nI would also point out MCDN as the key contribution of this paper as ChoiceNet \nis just any base network with an MCDN block stacked on top of this. Thus, I \nbelieve this should be emphasized more to make your key contribution clear.\n\n== Experiments ==\n\nThe experiments are nicely presented and are quite thorough. A couple minor \ncomments I have are:\n\n  - It would be nice to run regression experiments for bigger real-world \n    datasets, as the ones used seem to be quite small.\n  - I am a bit confused at the fact that in table 3 you compare your method to \n    mixup and in table 4 you also show results when using both your method and \n    mixup combined. Up until that point I thought that mixup was posed as an \n    alternative method, but here it seems it's quite orthogonal and can be used \n    together, which I think makes sense, but would be good to clarify. Also, \n    given that you show combined results in table 4, why not also perform \n    exactly the same analysis for table 3 and also show numbers for CN + Mixup?\n\nIt would also be nice to use the same naming scheme for both tables. I would \nuse: ConvNet, ConvNet + CN, ConvNet + CN + Mixup, and the same with WRN for \ntable 4. This would make the tables easier to read because currently the first \nthing that comes to mind is what may be different between the two setups given \nthat they are presented side-by-side but use different naming conventions.\n\nOne question that comes to mind is that you make certain assumptions on the \nkinds of noise your model can capture, so are there any cases where you have \ngood intuition as to why your model may fail? It would be good to present a \nshort discussion on this to help readers understand whether they can benefit by \nusing your model or not.", "title": "Interesting Approach with Nice Results", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "SyxB2-Bd3m": {"type": "review", "replyto": "S1MQ6jCcK7", "review": "This paper formulates a new deep learning method called ChoiceNet for noisy data. Their main idea is to estimate the densities of data distributions using a set of correlated mean functions. They argue that ChoiceNet can robustly infer the target distribution on corrupted data.\n\nPros:\n\n1. The authors find a new angle for learning with noisy labels. For example, the keypoint of ChoiceNet is to design the mixture of correlated density network block. \n\n2. The authors perform numerical experiments to demonstrate the effectiveness of their framework in both regression tasks and classification tasks. And their experimental result support their previous claims.\n\nCons:\n\nWe have three questions in the following.\n\n1. Related works: In deep learning with noisy labels, there are three main directions, including small-loss trick [1-3], estimating noise transition matrix [4-6], and explicit and implicit regularization [7-9]. I would appreciate if the authors can survey and compare more baselines in their paper instead of listing some basic ones.\n\n2. Experiment: \n2.1 Baselines: For noisy labels, the authors should add MentorNet [1] as a baseline https://github.com/google/mentornet From my own experience, this baseline is very strong. At the same time, they should compare with VAT [7]. \n\n2.2 Datasets: For datasets, I think the author should first compare their methods on symmetric and aysmmetric noisy data [4]. Besides, the current paper only verifies on vision datasets. The authors are encouraged to conduct 1 NLP dataset.\n\n3. Motivation: The authors are encouraged to re-write their paper with more motivated storyline. The current version is okay but not very exciting for idea selling.\n\nReferences:\n\n[1] L. Jiang, Z. Zhou, T. Leung, L. Li, and L. Fei-Fei. Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels. In ICML, 2018.\n\n[2] M. Ren, W. Zeng, B. Yang, and R. Urtasun. Learning to reweight examples for robust deep learning. In ICML, 2018.\n\n[3] B. Han, Q. Yao, X. Yu, G. Niu, M. Xu, W. Hu, I. Tsang, M. Sugiyama. Co-teaching: Robust training of deep neural networks with extremely noisy labels. In NIPS, 2018.\n\n[4] G. Patrini, A. Rozza, A. Menon, R. Nock, and L. Qu. Making deep neural networks robust to label noise: A loss correction approach. In CVPR, 2017.\n\n[5] J. Goldberger and E. Ben-Reuven. Training deep neural-networks using a noise adaptation layer. In ICLR, 2017.\n\n[6] S. Sukhbaatar, J. Bruna, M. Paluri, L. Bourdev, and R. Fergus. Training convolutional networks with noisy labels. In ICLR workshop, 2015.\n\n[7] T. Miyato, S. Maeda, M. Koyama, and S. Ishii. Virtual adversarial training: A regularization method for supervised and semi-supervised learning. ICLR, 2016.\n\n[8] A. Tarvainen and H. Valpola. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. In NIPS, 2017.\n\n[9] S. Laine and T. Aila. Temporal ensembling for semi-supervised learning. In ICLR, 2017.", "title": "ok papers but lacking of related works, important baselines and well-motivated storyline.", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}}}