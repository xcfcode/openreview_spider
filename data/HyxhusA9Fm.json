{"paper": {"title": "Talk The Walk: Navigating Grids in New York City through Grounded Dialogue", "authors": ["Harm de Vries", "Kurt Shuster", "Dhruv Batra", "Devi Parikh", "Jason Weston", "Douwe Kiela"], "authorids": ["mail@harmdevries.com", "kshuster@fb.com", "dbatra@gatech.edu", "parikh@gatech.edu", "jase@fb.com", "dkiela@fb.com"], "summary": "First large-scale dialogue dataset grounded in action and perception", "abstract": "We introduce `\"Talk The Walk\", the first large-scale dialogue dataset grounded in action and perception. The task involves two agents (a 'guide' and a 'tourist') that communicate via natural language in order to achieve a common goal: having the tourist navigate to a given target location. The task and dataset, which are described in detail, are challenging and their full solution is an open problem that we pose to the community. We (i) focus on the task of tourist localization and develop the novel Masked Attention for Spatial Convolutions (MASC) mechanism that allows for grounding tourist utterances into the guide's map, (ii) show it yields significant improvements for both emergent and natural language communication, and (iii) using this method, we establish non-trivial baselines on the full task. ", "keywords": ["Dialogue", "Navigation", "Grounded Language Learning"]}, "meta": {"decision": "Reject", "comment": "This paper introduces a newly collected dataset of natural language interactions between a tourist and a guide for localization and navigation.  The paper also includes baseline experiments with a reasonably novel approach. \nThe task is well motivated (although an open question remains due to GPS, comment by reviewer 1), but the description of the dataset and collection, approach and experiments were not ideal in the first version of the paper. Much of the information was pushed to the appendix and it was hard to follow the paper without going back and forth, and even then some points were missing. Authors rewrote parts of the paper to address these concerns, but there are still some open questions. For example, is it possible to have sub-tasks, given the task is complex and may not be easy to accomplish as a whole? Or could simple LSTM be another baseline (the final review of the third reviewer)?\n\n\n"}, "review": {"B1xMzl-dCm": {"type": "rebuttal", "replyto": "rklAz2j92m", "comment": "Thanks for your positive feedback on our work. It would be really helpful if you could elaborate on the usefulness and challenges of the new task, the introduced baselines, or the descriptions of our experiments. ", "title": "Thank you for the positive feedback; can you please elaborate?"}, "BkxzjYxdR7": {"type": "rebuttal", "replyto": "rkgGwTlF27", "comment": "Thank you for taking the time to review our manuscript :)\n\nWe believe there is a misinterpretation of our experimental findings, most likely due to the lack of clarity in the presentation of our results. We did not intend to communicate that the main takeaways are 1) success of emergent language and 2) the bold claim that humans are bad at localizing. Concerning 1), we have included emergent localization to put our natural language experiments in perspective, as well as to show that the full task is do-able under some simplifications. For instance, it points out that our conditional (natural) language models do not achieve high localization accuracy because of the guide model not being able to handle messages that are grounded in multiple observations and actions (because it can do so for emergent communication). Concerning 2), we wanted to convey that the human baseline does not rely as much on the localization capabilities as our constructed random walk protocol. This is partly supported by low localization performance from extracted natural language utterances, although we agree that this might be due to modeling issues. We removed this paragraph from the results section and rewrote this entire section to better highlight our main findings.  \n\nWe also want to reiterate that the main modeling contributions are:\n- We establish an initial baseline on the full navigation task, by designing a random walk protocol that utilizes tourist and guide agents trained for localization.\n- We show that the localization task is challenging, as it requires communication of a short random path (i.e. observations and actions from multiple time steps) \n- For emergent communication, we show that the MASC mechanism is a crucial component to successfully learn a protocol that grounds observations and actions over multiple time steps\n- Localization performance from human utterances is much worse than that from emergent communication\n- Our analysis shows that tourist generation models can only produce natural language utterances grounded in a single landmark observation and are less successful when conditioned on observations and actions of multiple time steps. \n\nWe have rewritten the paper from Section 3 onwards to improve the clarity of our key findings. Specifically, we have made the following revisions:\n- We start Section 3 by explaining that our focus is on establishing baselines for the full task, subsequently describing the random walk protocol, and then moving on to the localization task. \n- After we introduce the simplifying assumptions for the localization task, we explain in one paragraph what the remaining challenges of the task are.\n- At the beginning of Section 5, we now briefly summarize our main findings.\n- We divided the findings of different experiments in separate subsections: analysis of localization task, emergent localization, natural language localization, and localization-based baselines. \n- We refactored the result subsection on natural language localization: \ni) removed the claim that humans are bad localizers, \nii) added a paragraph explaining that generated utterances from a tourist model achieve better localization accuracy than extracted human utterances, as well as added an explanation that this is due improved grounding on a single observation (see point below), \niii) added that tourist generation models can not (yet) produce utterances about multiple observations\n- We fixed the caption of Table 8 and moved the examples to the main paper as it illustrates well why the generated tourist utterances lead to better localization accuracy than human utterances from the dataset.\n\nQ: Clarifications regarding dataset statistics\nA:  In section 2.3, the phrase \"before they successfully complete the task\" indicates that the average number of acts are calculated over the successfully completed dialogues in the collected dataset (i.e. 76.74% of all dialogues). We use the calculated task success rate (76.74%) as human accuracy., i.e. this statistic is not gathered by a separate human evaluation. We have updated section 2.3 to point this out. \n\nQ: Isn't 45 actions a lot for 4x4 grids?\nA: Yes, but most of these actions are turning actions (30 turn lefts/rights), which do not move the tourist to new x,y coordinates.", "title": "Improved paper presentation to resolve misunderstanding of our experimental findings"}, "rJlShugu07": {"type": "rebuttal", "replyto": "r1lkCfhc3m", "comment": "Thank you for your extensive review of our work! We find it encouraging that you describe the dataset as a useful contribution to the community and the related work section exceptionally thorough and useful for researchers interested in this topic. \n\nWe apologize for the lack of clarity in the experimental section, and we agree that this part of the paper did not communicate our motivations and findings very well. The main focus of the current work is to establish a minimal baseline for the full navigation task, so as to facilitate future research on the task. In order to do so, we design a random walk protocol that utilizes tourist and guide agents trained for localization. This simple baseline only relies on a localization model; hence we primarily focus on this sub-task. Even though our objective is to accomplish this task via natural language communication, we also investigate emergent communication baselines in order to provide useful comparisons and to get a better understanding of the difficulty of the task. \n\nConcerning the challenges of the localization task after the introduced simplifications, we investigate this question in the first two paragraphs of section 5 (5.1 in the revised paper). The task requires communication of a short path---i.e., not only a sequence of landmark observations but also actions---to achieve high localization accuracy. That is, the guide needs to decode observations from multiple time steps, as well as understand their 2D spatial arrangement as communicated via the sequence of actions. For emergent communication, we show that the introduced MASC mechanism is a crucial component to achieve high accuracy on the localization task, by successfully learning a protocol that can ground such actions in the guide's overhead map. \n\nWe have rewritten the paper from Section 3 onwards in order to present the above points better. Specifically, we have made the following changes:\n- We start Section 3 by explaining that our focus is on establishing baselines for the full task, subsequently describing the random walk protocol, and then moving on to the localization task. \n- After we introduce the simplifying assumptions for the localization task, we explain in one paragraph what the remaining challenges of the task are.\n- At the beginning of Section 5, we now briefly summarize our main findings.\n- We divided the findings of different experiments in separate subsections: analysis of localization task, emergent localization, natural language localization, and localization-based baselines. \n- We refactored the result subsection on natural language localization: \n1) removed the claim that humans are bad localizers, \n2) added a paragraph explaining that generated utterances from a tourist model achieve better localization accuracy than extracted human utterances, as well as added an explanation that this is due to improved grounding on a single observation (see point below), \n3) added that tourist generation models can not (yet) produce utterances about multiple observations\n- We fixed the caption of Table 8 and moved the examples to the main paper as it illustrates well why the generated tourist utterances lead to better localization accuracy than human utterances from the dataset.\n\nThese modifications should help clarify our experiments, motivations, and findings. Below, we will address some specific concerns and questions. \nQ: Is the list of landmarks exhaustive?\nA: Yes, the list of 9 landmarks is exhaustive, and not-annotated buildings (e.g. schools) are not shown on the map. As a result, the human annotators might sometimes talk about whether a particular observation is on the overhead map or not. \n\nQ: To what extent does the difficulty of the tasks depends on the variability\nof the combination of landmarks visible at each location?\nA: This is a great question - if the landmark observation is unique (i.e. the only one on the map), we have absolute certainty about the location of the tourist. However, the overhead maps have coarsely annotated landmarks so that the landmarks are often visible at multiple locations. We investigate the difficulty of the localization task (on average) in the first two paragraphs of section 5 (5.1 in the revised version) by analyzing the upper bound performance on the localization task when varying the length of a random path on the map. We find that communicating a single observation is not sufficient; instead, a random path (of length T >= 2) needs to be communicated to achieve high localization accuracy (>=86%). ", "title": "Substantially revised paper to better motivate experiments"}, "r1lkCfhc3m": {"type": "review", "replyto": "HyxhusA9Fm", "review": "The paper introduces a new dataset \"Talk the Walk\" that are dialogs\nbetween a guide and a tourist, where the guide is to help the tourist\nnavigate to a target location.  The guide has access to a map and the\ntarget location, but he relies on the tourist to communicate her\nstate (location) by natural language.\n\nPros.:\n\nThe task represented in the dataset can be highly challenging, and\nrespectable effort went into creating the dataset based on real city\nneighborhoods.   The description and analysis of the dataset are\ndetailed.  The paper is well written up to the end of page 3.\n\nThe dataset by itself is a good contribution to the scientific\ncommunity when it is shared.  There could be many topics open\nfor studying within the same data.\n\nThe list of references and related work is exceptionally thorough\nand useful for researchers interested in the topic.\n\nCons.:\n\nThe description of the experiments done with the dataset, however,\nsuffers from being overly cryptic.  The methods are not sufficiently\nmotivated, very few alternatives are presented and argued against,\nand the several sections give a dry report of the sequences of things\nthe authors did.  It is not clear how others may find value in the\nresults and conclusions.\n\nWhile the paper opens with the emphasis of a real-world setting,\nafter a series of simplifications (e.g. landmark typing, perfect perception)\nit seems that much of the full complexity of the natural task is taken out,\nand the main goal of the study is no longer clear.\nFor example, since there are only 9 types of landmarks,\nin a small neighborhood there are not many combinations to draw reference to.\nSimple observation sequences of such can easily narrow down the location\nuncertainty.  It is important to highlight what the remaining open\nissues are that make the task still challenging.\n\nMisc.:\n\nExamples are missing in the discussion of the experimental tasks.\ne.g. in the study of emergent language, what could be a message that a\ntourist may generate to describe his location?  what makes it hard for\nthe guide to decode it?  Likewise, what could be an example state of\nthe tourist and the description of that state in natural language?\nWithout the examples, it is difficult for the reader to have a sense\nof the challenges in each task.\n\nTable 8 is the first place where (finally) some utterances are presented.\nHowever the description in the table or in the text is not sufficient\nto convey the point that is supposed to be explained by the example.\n\nThe descriptions of the landmarks are restricted to the type of business\nat the location with 9 possibilities.  Is the list of 9 exhaustive?\nAre there any exceptions  (e.g. schools)?  How are such exceptions\nrepresented and treated in the dialogs?\n\nTo what extent the difficulty of the tasks depends on the variability\nof the combination of landmarks visible at each location?\n\nWhat could be a simplest way to do this without neural-modeling?\ne.g. with the many limitations that are built into the task and its\nrepresentations, will a simple decision tree based instruction method suffice?\nOr a traditional algorithm that relies on repeated exploration and evaluation?\nIt is surprising that such possibilities are not even mentioned.\nA complex neural architecture does not seem to be well justified unless\nit is motivated by the need to overcome limitations of a classical method.\n\nIrrelevant to the research effort, a thought about the dataset is that,\nin these days with popular uses of GPS, the reliance on such dialogs for\nnavigation feels a bit backwards.\n", "title": "A realistic dataset on dialogs for navigation, with a report of some early studies", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "rklAz2j92m": {"type": "review", "replyto": "HyxhusA9Fm", "review": "The paper introduces a new task called \"Talk the Walk\", where a tourist and a guide has to communicate in natural language to reach a common goal. It also introduces strong baselines for the task. The descriptions are thorough and clear. My only worry is that the task is too hard and has too many complexities to be a stand alone task.  Future work will probably focus on sub-parts of the task.", "title": "A challenging new task and dataset", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "rkgGwTlF27": {"type": "review", "replyto": "HyxhusA9Fm", "review": "The primary contribution of this work is a dataset for action following through dialogue.  The authors collect a comparatively small dataset in terms of language but one which contains real images and dialogue. \n\nThere are a number of aspects of the proposed approach which I found hard to follow/justify.  First off, I was unclear on the details of the collected data (e.g. average action sequence length, dialogue length, lexical types/tokens, etc).  There's a claim of 62 acts which sums both dialogue and actions with averages of 8 and 9 dialogue acts for tourist/guide implying 45 move actions?  on a 4x4 grid?  Is it safe therefore to assume that the example dialogue is therefore atypical? It's very hard to figure out based on the number of steps across the different tables what the model should be aiming for.  Also, in 2.3 does the claim that they \"successfully complete the task\" mean in the 76.74% of cases where they succeed or did they succeed in 100% of cases and then a new human eval was run afterwards which performed worse?\n\nThe primary modeling result appears to be the success of emergent language and the bold claim that humans are bad at localizing.  This doesn't feel intuitively true from the example dialogue, but the NLG system samples to appear to be quite bad which makes me worried that it's not so much that humans are bad localizers but that the model's NLU/NLG system is quite weak and maybe there's a problem with the data-collection procedure.  Additional justification and analysis would be appreciated.\n\nAs I understand the paper right now:\n1. Humans talking to one another do very well on the task and achieve success very quickly. \n2. Emergent language can do better at the task though their approach is very sub-optimal (requiring 2-3x the number of steps).\n3. The currently proposed NLU/NLG mechanisms are very weak and cannot produce or correctly interpret actual language.\n\nThere are many moving pieces in this paper (e.g. extracting text from images vs detections), there doesn't seem to be any pretraining of the decoder, etc which makes it very hard for me to understand what's going wrong.  The results in this paper, don't convince me that emergent language is better than natural language or that agents are better communicators than humans, but that the data-collection methodology was faulty leading to lots of failures. \n\nI haven't touched on the MASC aspect and how this compares to existing work on interpretable spatial relations and questions as to why various architectural choices were made though the paper would obviously benefit from that discussion as well.\n\nI found this paper very confusing to read.  It relies heavily on 11 pages of appendices (where it puts all of the related work) and still fails to clearly explain its contributions or justify its claims.  \n\nMinor: URLs intermittently anonymized page 12 vs 19", "title": "Emergent Language is Easier than Natural Language", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "BkgwVGyN5X": {"type": "rebuttal", "replyto": "Hygemsnz5Q", "comment": "Thank you for your interest in our work!\n\nThe perfect perception assumption is not part of the full task that we propose (i.e. the gathered human data is using 360-degree navigation with two-way natural language communication). We simplified the perception aspect in our experiments because initial findings suggested that perceptual grounding is difficult for simple baseline models (see Section 12 of the Appendix). This indeed makes it easier for the tourist to produce a message about the observed landmarks. Nevertheless, the localization task is still challenging because only communicating the list of observed landmarks is not sufficient for accurate localization (see Table 2:  the upper bound on localization performance is ~56% for taking T=3 actions). In other words, the tourist also needs to communicate their actions to the guide, who is responsible for grounding the entire trajectory (landmarks + actions) in the overhead map before predicting the location. We believe that this sub-task is non-trivial and develop a novel action-grounding mechanism (MASC) that is essential to obtain high localization accuracy with emergent language, as well as improves performance for natural language. \n\nYou can find samples of the natural language model (for different decoding strategies) in Table 8 of the Appendix :)", "title": "Perfect Perception is to establish sensible baselines, but is not part of the full task"}}}