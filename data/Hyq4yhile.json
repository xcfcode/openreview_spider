{"paper": {"title": "Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning", "authors": ["Abhishek Gupta", "Coline Devin", "YuXuan Liu", "Pieter Abbeel", "Sergey Levine"], "authorids": ["abhigupta@berkeley.edu", "coline@berkeley.edu", "yuxuanliu@berkeley.edu", "pabbeel@cs.berkeley.edu", "svlevine@eecs.berkeley.edu"], "summary": "Learning a common feature space between robots with different morphology or actuation to transfer skills.", "abstract": "People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where twp agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of ``analogy making,'' or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven.", "keywords": ["Deep learning", "Reinforcement Learning", "Transfer Learning"]}, "meta": {"decision": "Accept (Poster)", "comment": "pros:\n - tackles a fundamental problem of interest to many\n - novel approach\n \n cons:\n - originally not evaluated against some reasonable benchmarks. Note: now added or addressed\n - little theoretical development cf MDP theory\n - some remaining questions about the necessity (and ability) to find good time alignments\n \n I personally found the ideas to be quite compelling, and believe that this is likely to inspire future work.\n The experiments represent interesting scenarios for transfer, with the caveat that they are just in simulation."}, "review": {"HJAnNWgDl": {"type": "rebuttal", "replyto": "Hyq4yhile", "comment": "Dear Reviewers and Area Chair,\nThe reviewers for the paper provided a positive evaluation, with suggestions for additional experiments providing comparisons with several prior methods, some clarifications, and brought up the important problem of addressing time-based correspondence alignment. We have edited the paper to include additional experiments that address these issues, and therefore believe that the reviewer concerns about the work have been addressed. We discuss the specifics below.\n\nAnonReviewer 1 Comments: \n\u201cCompared to previous work (Ammar et al. 2015)\u201d\n- Performed this comparison and added the results into the Figures 5 and 8. We found that our method performed significantly better than this prior work. \n\u201cIs it possible to use dynamic time warping (or similar method) to achieve reasonable results?  Robustness to misspecification of the pairing correspondence P seems a major concern.\u201d\n- We introduced an EM style algorithm which removes this assumption. Description of this method are in Section 3.3.2, and results in Figures 5 and 8. \n\u201cmore comparison to other transfer methods, including those listed in Sec.2, would be very valuable\u201d\n- We have implemented several more baselines: KCCA, Unsupervised Manifold Alignment as suggested by Bou Ammar et al, Direct mappings, random projections, CCA in Figures 5 and 8.\n\nAnonReviewer3 Comments: \n\u201cpreferable to see comparisons for something more current and up to date, such as manifold alignment or kernel CCA\u201d, \u201ccomparisons to related approaches is not very up to date\u201d \n-Performed comparisons to Kernel CCA and Manifold Alignment using Unsupervised Manifold Alignment (Wang and Mahadevan, Bou Ammar et al) and added to our experiments in Figures 5 and 8. \n\nAnonReviewer4 Comments: \n\u201cA limitation of the paper is that the authors suppose that time alignment is trivial [...] could be dealt with through subsampling, dynamic time warping, or learning a matching function\u201d \n-We introduce a new EM style algorithm alternating between feature learning and dynamic time warping. Description is in Section 3.3.2 and results in Figures 5 and 8. \n\u201cAnother baseline (worse than CCA) would be to just have the random projections for \"f\" and \"g\"\u201d\n-We added this comparison in Figures 5 and 8.\n\u201cat least a much bigger sample budget should be tested [...] control for the fact that the embeddings were trained with more iterations in the case of doing transfer\u201d \n- We ran the baseline with a significantly higher sample budget as shown in Table 1. The poor performance is likely due to not enough guided exploration happening without good reward shaping for the baseline. \n\u201cproblem of learning invariant feature spaces is also linked to metric learning [...] no parallel is drawn with Multi-Task learning in ML \u201d\n-The additional references suggested have been added in the Related Work (Section 2).\n", "title": "Note to AC and Reviewers"}, "Syo_hloLl": {"type": "rebuttal", "replyto": "Hyq4yhile", "comment": "Dear reviewers,\n\nWe have addressed the concerns presented in the reviews, including comparisons to several prior methods and a method for automatically determining alignment, as detailed in the individual reviewer responses. If you have suggestions for additional comparisons, we would be happy to add them in the final version. As such, we hope you will consider adjusting your reviews accordingly. \n\nRegards\nAbhishek, Coline, Yuxuan, Pieter, Sergey", "title": "Note to reviewers"}, "HkEruiMIx": {"type": "rebuttal", "replyto": "Hyq4yhile", "comment": "We thank the reviewers for their comments. Most comments asked for additional comparisons and learned state correspondences. \nIn response to reviewer comments, we have added the following to our paper:\n\n1. Learning state correspondences by using an alternating optimization to jointly assign the state pairs in P and learn the embedding functions f and g. This significantly relaxes the assumption that states can be paired by time-step and provides better performance in experiment 1. See section 3.3.2 for a description of this method and figures 5 and 7a for results.\n\n2. All of the comparisons suggested by the reviewers: kernel-CCA, unsupervised manifold alignment (Ammar et al. 2015), and random projections. Results are in Figures 5 and 7a.\n\n3. Connections to metric learning and multitask learning in Section 2.\n\nThe comparisons have been run on experiments 1 and 2 and will be added to experiment 3 for the final version.", "title": "Summary of Updates (Jan 10)"}, "HJFGKozLg": {"type": "rebuttal", "replyto": "SyMMfs-Ve", "comment": "Thank you for pointing out the highly related work by (Ammar et al. 2015) . In order to ensure a fair comparison we use the Matlab code provided by Chang Wang (https://sites.google.com/site/changwangnk/home/ma-html). We find that the unsupervised manifold learning method described in (Wang and Mahadevan 2009) and (Ammar et al. 2015) performs poorly. We suspect that this is because the method relies on pairwise distance and the raw state spaces do not provide a meaningful metric space. Ammar et al use a hand-specified feature mapping phi that provides a good metric space for the method. As we assume no prior knowledge about the state space, we do not have a hand-specific feature mapping in our experiments.\n\nWe would like to clarify that our primary contribution is to learn a feature space in which the source and target states can be compared. This differs from prior work because we do not reconstruct the source states from target states, allowing the embeddings to discard information that is not common. This is more suitable for transferring between robots with varying morphologies.\n\nTo address your comment about assuming correspondences, we have formulated an alternating optimization, alternating between establishing common feature space using current correspondences, and reestablishing correspondences using current feature space and dynamic time warping. This is described in detail in Section 3.3.2, and results are seen in Fig 5, Fig 7a. \n\nAs suggested, we have also run comparisons with several prior methods such as (Ammar et al. 2015), kernel CCA, random projections, CCA and using state mappings instead of embeddings. These results are shown in Figures 5 and 7a, and show the advantage of using our proposed method over several prior methods. Although kernel CCA is quite competitive with our method on the tendon task, it performs very poorly on the button task while our method is able to achieve excellent performance on both.\n\nUnfortunately we could not compare to the work in Raimalwala et al (2016) because it is quite specific to systems which have a single input, a single output, and can be modeled as linear time invariant. Our tasks are nonlinear and have multidimensional states.\n", "title": "Author Response"}, "SkHhdofLl": {"type": "rebuttal", "replyto": "SyEvEhMVg", "comment": "Thank you for bringing up several important points in the review. We have added several more comparisons to our results in Figures 5 and 7a. The first is using random projections, which performs slightly better than no transfer. The second is kernel CCA, and the last is unsupervised manifold learning, using the method presented in (Wang and Mahadevan 2009) and (Ammar et al 2015).  Please see the response to Reviewer 3 for more details on why we believe this last method performs poorly in our settings.\n\n\nAdditionally, we have formulated a method to find the state alignment jointly with the feature embedding as described in Section 3.3.2, allowing us to remove the assumption that the states are aligned by timestep. The method alternates between common feature space learning using current correspondences and dynamic time warping to reestimate correspondences using the current learned feature space. Figure 5 shows that this method actually provides better results than just assuming correspondences by time-step.", "title": "Author Response"}, "ByFcujGIe": {"type": "rebuttal", "replyto": "S1zWvGXNg", "comment": "Thank you for your review. We agree that assuming a trivial time alignment is somewhat unsatisfying, and to address this we have formulated an alternating optimization to learn the alignment jointly with the embeddings, described in Section 3.3.2. The method alternates between common feature space learning using current correspondences and dynamic time warping to reestimate correspondences using the current learned feature space, as described in Section 3.3.2. Results using this method can be found in Figure 5, Figure 7a. Using this approach usually works better than just assuming timestep correspondences, or as well in the case of well aligned data. \n\nAs per the suggestion of comparing with random projections, we have added a comparison using random projections as feature embeddings. As shown in Figures 5 and 7a, this method achieves a low level of performance in between the CCA method and no transfer. Also, as pointed out in the review we do indeed anneal \\alpha over the course of learning in all our experiments.\n\nAs shown in Table 1, we have run the \u201cNo Transfer\u201d method for 75 iterations (seeing 3 times more samples). A likely reason the no transfer baseline doesn\u2019t work even with this greater sample budget is that the exploration is insufficiently coherent for any reward to be obtained at all, leading to the behavior seen. \n\nFinally, we have added a connection to metric learning in the last paragraph of Section 2, as well as a paragraph on multitask learning (the third paragraph in Section 2).\n\nFigure 7b does not yet contain the comparisons with CCA and direct mapping because we have been adding these comparisons over the course of the response period. This figure will contain all comparisons for the final version. Thanks!\n", "title": "Author Response"}, "BJFp2x0mg": {"type": "rebuttal", "replyto": "Hyq4yhile", "comment": "To address the reviewers\u2019 questions, we have made the following changes:\n-We added comparisons of our method to using canonical correlation analysis to find the embedding functions F and G (see Figures 5 and 8a)\n-We added comparisons of our method to directly predicting the target states from the source states (see Figures 5, 8a)\n-We have clarified the description of P in Sec 4.1\n-We have added two previous approaches to the related work section.\n", "title": "Summary of Author Responses"}, "rkIqhe0Qe": {"type": "rebuttal", "replyto": "SygYFjTMx", "comment": "Thank you for the pointers to CCA and the papers using unsupervised manifold alignment. We have added experiments in Figures 5 and 7 using CCA to determine the functions F and G. We find that this method performs poorly because a linear mapping into a common feature space is not sufficiently expressive to capture the complex nonlinear interactions present.\n\nWe have also included included an additional comparison between our method (learning a common embedding between robots) and directly mapping from source states to target states. These comparisons show that using invariant nonlinear embedding functions allows for better transfer than a simple linear mapping or a prediction of the whole source state.\n\nWe find that the Bou Ammar et al. reference addresses a complementary problem to the one we aim to solve. For example, it assumes the presence of a feature mapping phi that provides distances between states, and use these (hand designed) features to assign correspondences between states in the different domains. In contrast, we assume that good correspondences in episodic tasks can be extracted through time alignment, and focus on learning the feature mapping itself. The focus in our work is on learning complex nonlinear mappings from states to a shared feature space.\n\nThe work from Raimalwala et al was very effective in enabling transfer in the LTI single input single output systems considered, but we believe it is not suitable for the nonlinear, more complex systems being considered in our experiments without restrictive linearizations. Additionally these methods also learn a direct mapping between state spaces, rather than mappings to a shared feature space, which as seen from our additional comparisons, do not perform as well.  We have added information about these works to Section 2.", "title": "Author Response"}, "SJvUhlCme": {"type": "rebuttal", "replyto": "SkD6YqJme", "comment": "Thank you for your questions.\n\n> I was confused by P.  Can you define this more precisely: is it a distribution?  or a mapping?  or a function?: \nP is a set of tuples (s_S, s_T) that put the source and target states into correspondence. The correspondences are used to specify which states should be placed close together in the feature space via the contrastive loss.\n\n\n> The loss equation at the beginning of Sec.4.1 should probably have super-script \u201cj\u201d in the last term:\nYes, that is indeed a typo. We have updated the notation accordingly.\n\n> Did you compare to any other transfer method?  What would be the most appropriate?\nWe have added two comparisons: finding the feature space using canonical correlation analysis, and learning a direct mapping between state spaces of domains. Please see Section 5.1 for further descriptions.\n\n\n> How does the Baseline method do if it gets as much data as the transfer method (i.e. 3 times more for Fig.5 to compare with \u201cAll proxies\u201d):\nWe ran the baseline for a larger number of iterations, and the results are shown in Table 1. These results suggest that the baseline method does not substantially benefit from the additional samples. \n", "title": "Author Response"}, "SkD6YqJme": {"type": "review", "replyto": "Hyq4yhile", "review": "I was confused by P.  Can you define this more precisely: is it a distribution?  or a mapping?  or a function?\n\nThe loss equation at the beginning of Sec.4.1 should probably have super-script \u201cj\u201d in the last term.\n\nDid you compare to any other transfer method?  What would be the most appropriate?\n\nHow does the Baseline method do if it gets as much data as the transfer method (i.e. 3 times more for Fig.5 to compare with \u201cAll proxies\u201d)\nThe paper considers the problem of transferring skills between robots with different morphologies, in the context of agents that have to perform several tasks.  A core component of the proposed approach is to use a task-invariant future space, which can be shared between tasks & between agents.\n\nCompared to previous work (Ammar et al. 2015), it seems the main contribution here is to \u201cassume that good correspondences in episodic tasks can be extracted through time alignment\u201d (Sec. 2).  This is an interesting hypothesis. There is also similarity to work by Raimalwala et al (2016), but the authors argue their method is better equipped to handle non-linear dynamics. These are two interesting hypotheses, however I don\u2019t see that they have been verified in the presented empirical results.  In particular, the question of the pairing correspondence seems crucial. What happens when the time alignment is not suitable. Is it possible to use dynamic time warping (or similar method) to achieve reasonable results?  Robustness to misspecification of the pairing correspondence P seems a major concern.\n\nIn general, more comparison to other transfer methods, including those listed in Sec.2, would be very valuable.  The addition of Sec.5.1 is definitely a right step in this direction, but represents a small portion of the recent work on transfer learning.  I appreciate that other methods transfer other pieces of information (e.g. the policy), but still if the end goal is better performance, what is worth transferring (in addition to how to do the transfer) should be a reasonable question to explore.\n\nOverall, the paper tackles an important problem, but this is a very active area of research, and further comparison to other methods would be worthwhile.  The method proposed of transferring the representation is well motivated, cleanly described, and conceptually sound.  The assumption that time alignment can be used for the state pairing seems problematic, and should be further validated.", "title": "Questions", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "SyMMfs-Ve": {"type": "review", "replyto": "Hyq4yhile", "review": "I was confused by P.  Can you define this more precisely: is it a distribution?  or a mapping?  or a function?\n\nThe loss equation at the beginning of Sec.4.1 should probably have super-script \u201cj\u201d in the last term.\n\nDid you compare to any other transfer method?  What would be the most appropriate?\n\nHow does the Baseline method do if it gets as much data as the transfer method (i.e. 3 times more for Fig.5 to compare with \u201cAll proxies\u201d)\nThe paper considers the problem of transferring skills between robots with different morphologies, in the context of agents that have to perform several tasks.  A core component of the proposed approach is to use a task-invariant future space, which can be shared between tasks & between agents.\n\nCompared to previous work (Ammar et al. 2015), it seems the main contribution here is to \u201cassume that good correspondences in episodic tasks can be extracted through time alignment\u201d (Sec. 2).  This is an interesting hypothesis. There is also similarity to work by Raimalwala et al (2016), but the authors argue their method is better equipped to handle non-linear dynamics. These are two interesting hypotheses, however I don\u2019t see that they have been verified in the presented empirical results.  In particular, the question of the pairing correspondence seems crucial. What happens when the time alignment is not suitable. Is it possible to use dynamic time warping (or similar method) to achieve reasonable results?  Robustness to misspecification of the pairing correspondence P seems a major concern.\n\nIn general, more comparison to other transfer methods, including those listed in Sec.2, would be very valuable.  The addition of Sec.5.1 is definitely a right step in this direction, but represents a small portion of the recent work on transfer learning.  I appreciate that other methods transfer other pieces of information (e.g. the policy), but still if the end goal is better performance, what is worth transferring (in addition to how to do the transfer) should be a reasonable question to explore.\n\nOverall, the paper tackles an important problem, but this is a very active area of research, and further comparison to other methods would be worthwhile.  The method proposed of transferring the representation is well motivated, cleanly described, and conceptually sound.  The assumption that time alignment can be used for the state pairing seems problematic, and should be further validated.", "title": "Questions", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "SygYFjTMx": {"type": "review", "replyto": "Hyq4yhile", "review": "The most widely used method for constructing latent feature spaces across source and domain tasks is canonical correlational analysis (CCA), invented more than 80 years ago. CCA requires explicit correspondences, but recent work by Wang et al. (ICML 2008, IJCAI 2009, IJCAI 2011, AAAI 2014) on manifold alignment generalizes CCA to allow for weak correspondences, as well as enables other objective functions, such as preserving global distances or local geometry. In recent years, a number of researchers in RL and robotics have used manifold alignment methods to show successful transfer in RL. It would be useful to compare against these methods, both experimentally as well as theoretically. \n\nExamples of such work include: \n\nAmar et al., (\"Unsupervised Cross-Domain Transfer in Policy Gradient Reinforcement Learning via Manifold Alignment\", AAAI 2015) apply manifold alignment to show transfer in RL, such as from inverted pendulum to quad rotor control. Raimalwala et al. (\"A Preliminary Study of Transfer Learning between Unicycle Robots\", AAAI SS 2016) apply a similar approach to show transfer in robotics as well \nThis paper explores transfer in reinforcement learning between agents that may be morphologically distinct. The key idea is for the source and target agent to have learned a shared skill, and then to use this to construct abstract feature spaces to enable the transfer of a new unshared skill in the source agent to the target agent. The paper is related to much other work on transfer that uses shared latent spaces, such as CCA and its variants, including manifold alignment and kernel CCA. \n\n\nThe paper reports on experiments using a simple physics simulator between robot arms consisting of three vs. four links. For comparison, a simple CCA based approach is shown, although it would have been preferable to see comparisons for something more current and up to date, such as manifold alignment or kernel CCA. A three layer neural net is used to construct the latent feature spaces. \n\nThe problem of transfer in RL is extremely important, and receives less attention than it should. This work uses an interesting hypothesis of trying to construct transfer based on shared skills between source and target agent. This is a promising approach. However, the comparisons to related approaches is not very up to date, and the domains are fairly simplistic. There is little by way of theoretical development of the ideas using MDP theory. \n", "title": "Comparison to other work on feature space construction ", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "SyEvEhMVg": {"type": "review", "replyto": "Hyq4yhile", "review": "The most widely used method for constructing latent feature spaces across source and domain tasks is canonical correlational analysis (CCA), invented more than 80 years ago. CCA requires explicit correspondences, but recent work by Wang et al. (ICML 2008, IJCAI 2009, IJCAI 2011, AAAI 2014) on manifold alignment generalizes CCA to allow for weak correspondences, as well as enables other objective functions, such as preserving global distances or local geometry. In recent years, a number of researchers in RL and robotics have used manifold alignment methods to show successful transfer in RL. It would be useful to compare against these methods, both experimentally as well as theoretically. \n\nExamples of such work include: \n\nAmar et al., (\"Unsupervised Cross-Domain Transfer in Policy Gradient Reinforcement Learning via Manifold Alignment\", AAAI 2015) apply manifold alignment to show transfer in RL, such as from inverted pendulum to quad rotor control. Raimalwala et al. (\"A Preliminary Study of Transfer Learning between Unicycle Robots\", AAAI SS 2016) apply a similar approach to show transfer in robotics as well \nThis paper explores transfer in reinforcement learning between agents that may be morphologically distinct. The key idea is for the source and target agent to have learned a shared skill, and then to use this to construct abstract feature spaces to enable the transfer of a new unshared skill in the source agent to the target agent. The paper is related to much other work on transfer that uses shared latent spaces, such as CCA and its variants, including manifold alignment and kernel CCA. \n\n\nThe paper reports on experiments using a simple physics simulator between robot arms consisting of three vs. four links. For comparison, a simple CCA based approach is shown, although it would have been preferable to see comparisons for something more current and up to date, such as manifold alignment or kernel CCA. A three layer neural net is used to construct the latent feature spaces. \n\nThe problem of transfer in RL is extremely important, and receives less attention than it should. This work uses an interesting hypothesis of trying to construct transfer based on shared skills between source and target agent. This is a promising approach. However, the comparisons to related approaches is not very up to date, and the domains are fairly simplistic. There is little by way of theoretical development of the ideas using MDP theory. \n", "title": "Comparison to other work on feature space construction ", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}}}