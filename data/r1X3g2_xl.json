{"paper": {"title": "Adversarial Training Methods for Semi-Supervised Text Classification", "authors": ["Takeru Miyato", "Andrew M. Dai", "Ian Goodfellow"], "authorids": ["takeru.miyato@gmail.com", "adai@google.com", "ian@openai.com"], "summary": "", "abstract": "Adversarial training provides a means of regularizing supervised learning algorithms while virtual adversarial training is able to extend supervised learning algorithms to the semi-supervised setting.\nHowever, both methods require making small perturbations to numerous entries of the input vector, which is inappropriate for sparse high-dimensional inputs such as one-hot word representations.\nWe extend adversarial and virtual adversarial training to the text domain by applying perturbations to the word embeddings in a recurrent neural network rather than to the original input itself.\nThe proposed method achieves state of the art results on multiple benchmark semi-supervised and purely supervised tasks.\nWe provide visualizations and analysis showing that the learned word embeddings have improved in quality and that while training, the model is less prone to overfitting.\n", "keywords": ["Natural language processing", "Deep learning", "Semi-Supervised Learning"]}, "meta": {"decision": "Accept (Poster)", "comment": "This paper is concerned with extending adversarial and virtual adversarial training to text classification tasks. The main technical contribution is to apply perturbations to word embeddings rather than discrete input symbols. Excellent empirical performance is reported across a variety of tasks. \n \n The reviewers were consensual in acknowledging the clarity and significance of the contribution, highlighting the quality of the numerical experiments. Moreover, the authors were responsive in the rebuttal phase and updated their paper with reviewers suggestions (such as the svm-related comparisons). \n \n The AC thus recommends accepting this work as a poster."}, "review": {"HkwLjwnHx": {"type": "rebuttal", "replyto": "Skzr55l4e", "comment": "Thank you for the review! \n\n\u201cIn Table 2 (and for other datasets as well), could you include an SVM baseline? e.g. S Wang and C Manning 2012?\u201d\nYes, we added the IMDB performance with Naive Bayes SVM by Wang and Manning (2012) to the Table 2.\n\n\u201cAs another baseline, did you consider dropping words, i.e. masking noise?\u201d\nThe performance using dropping words is demonstrated by Dai and Le (2015) (SA-LSTM in Table 2 in our paper.), and it is little bit better than our baseline ( 7.24% with SA-LSTM, and 7.33% with our baseline). \nWe also tested dropping words ( randomly masking each embedding of the word ) on our baseline models, however, we could not find any improvement from the baseline.\n\n\u201cI am not sure I understand why virtual adversarial is worse than the baseline in Table 5.\u201d\nIt is because we optimized epsilon between [1.0, 10.0] on each dataset. If epsilon is set to 0, the performance should be same as the baseline. The reason why we optimized epsilon between such a narrow range is that training the LSTM model is computationally costly, and on IMDB, Elec and RCV1, the optimal epsilons seem to be within [1.0, 10.0] on each validation set.\n\n\u201cI think it would be interesting to point at SVM, transductive SVM who achieve something similar to adversarial training.\u201d\nWe added the performance with transductive SVMs on IMDB, Elec and RCV1 by Johnson and Zhang (2015) to Table 2 and 4, and our proposed method outperforms the SVM-based methods.\nNote that transductive learning is somewhat different from semi-supervised learning because transductive learning allows the model to look at the test set.\nWe added an explanation of the similarities between adversarial training methods and SVM-based methods in the related work section. Please see the revised version of our paper. \n\n\u201cAlso it would be interesting to draw a parallel between adversarial training and contrastive divergence. \u201c\nThe similarities and differences between adversarial training and other methods like CAEs, double backprop, tangent propagation, etc. are described in the Deep Learning textbook ( http://www.deeplearningbook.org/contents/regularization.html , http://www.deeplearningbook.org/contents/representation.html ) so we don\u2019t feel it\u2019s necessary to repeat this amount of background explanation in the conference paper. There is also a separate ICLR 2015 workshop paper describing the connections between adversarial training and contrastive divergence: Goodfellow, On distinguishability criteria for estimating generative models. https://arxiv.org/abs/1412.6515\n", "title": "Response to AnonReviewer4"}, "rkFOsvhBg": {"type": "rebuttal", "replyto": "r1TrCM7Eg", "comment": "Thank you for the review! \n\n\u201cit is also interesting to see how much adversarial training can help in the performance of RNN, which is a simpler model and may be easier to analyze.\u201c\nAn LSTM is a kind of RNN. Simple RNNs, such as those based on linear transformation and tanh at each time step, are very difficult to interpret, just as LSTMs are. LSTMs may even be somewhat easier to interpret because information is propagated through time using addition.\n\n", "title": "Response to AnonReviewer3"}, "BJXyqv2rx": {"type": "rebuttal", "replyto": "ByxiEPX4l", "comment": "Thank you for the review! \nAs you suggested, we added results on IMDB performance with Naive Bayes SVM by Wang and Manning (2012) to Table 2 in the paper. \nWe also added results with transductive SVMs on IMDB, Elec and RCV1 by Johnson and Zhang (2015) to Table 2 and 4.\nWe confirmed that adversarial and virtual adversarial training outperform the SVM-based approaches.\nAdditionally, we explain the similarities between SVM-based methods and adversarial training methods in the related work section. Please see the revised version of our paper.\n", "title": "We added results with SVM-based methods and explain the similarities between SVM-based methods and adversarial training methods."}, "ryTIC1-Ne": {"type": "rebuttal", "replyto": "HyKnE6l4e", "comment": "We did not try that constraint on the datasets we used in our paper,\nbut I think the balancing constraint would improve the performance especially on RCV1 dataset (The classes in RCV1 dataset are unbalanced).\nI have tried similar constraint with virtual adversarial training on semi-supervised learning task on MNIST (I constrained the marginal distribution p(y) := \\sum_x p(y|x)q(x) to be uniform) and it stabilized the training process and improved performance over the training without the constraint. \n\nThank you for your comment!\n", "title": "Thanks for the comment!"}, "HyKnE6l4e": {"type": "review", "replyto": "r1X3g2_xl", "review": "Did the author try setups were classes were unbalanced? (In past semi-supervised literature, balancing constraints were important).\nThe authors propose to apply virtual adversarial training to semi-supervised classification.\n\nIt is quite hard to assess the novelty on the algorithmic side at this stage: there is a huge available literature on semi-supervised learning (especially SVM-related literature, but some work were applied to neural networks too); unfortunately the authors do not mention it, nor relate their approach to it, and stick to the adversarial world.\n\nIn terms of novelty on the adversarial side, the authors propose to add perturbations at the level of words embeddings, rather than the input itself (having in mind applications to NLP).\n\nConcerning the experimental section, authors focus on text classification methods. Again, comparison with the existing SVM-related literature is important to assess the viability of the proposed approach; for example (Wang et al, 2012) report 8.8% on IMBD with a very simple linear SVM (without transductive setup).\n\nOverall, the paper reads well and propose a semi-supervised learning algorithm which is shown to work in practice. Theoretical and experimental comparison with past work is missing.", "title": "balancing constraint", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "ByxiEPX4l": {"type": "review", "replyto": "r1X3g2_xl", "review": "Did the author try setups were classes were unbalanced? (In past semi-supervised literature, balancing constraints were important).\nThe authors propose to apply virtual adversarial training to semi-supervised classification.\n\nIt is quite hard to assess the novelty on the algorithmic side at this stage: there is a huge available literature on semi-supervised learning (especially SVM-related literature, but some work were applied to neural networks too); unfortunately the authors do not mention it, nor relate their approach to it, and stick to the adversarial world.\n\nIn terms of novelty on the adversarial side, the authors propose to add perturbations at the level of words embeddings, rather than the input itself (having in mind applications to NLP).\n\nConcerning the experimental section, authors focus on text classification methods. Again, comparison with the existing SVM-related literature is important to assess the viability of the proposed approach; for example (Wang et al, 2012) report 8.8% on IMBD with a very simple linear SVM (without transductive setup).\n\nOverall, the paper reads well and propose a semi-supervised learning algorithm which is shown to work in practice. Theoretical and experimental comparison with past work is missing.", "title": "balancing constraint", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "Sk9L4qmXl": {"type": "rebuttal", "replyto": "ryaPN5k7g", "comment": "Thanks for your comments!\n>Is the virtual adversarial training used in the pre-training phase?\nNo, we used virtual adversarial training only in the fine-tune phase.\n> Also In the results of Table 2, for the line of \"Virtual Adv\" and \"Adv+Virtual Adv\", the cost term of formula (3) are applied to all the samples, or only applied to unlabeled samples?\nThe former is correct. We calculate the virtual adversarial training loss (3) on both labeled and unlabeled samples.\n\n", "title": "Re. Experimental settings"}, "ryaPN5k7g": {"type": "review", "replyto": "r1X3g2_xl", "review": "Hi,\n\nIs the virtual adversarial training used in the pre-training phase? Also In the results of Table 2, for the line of \"Virtual Adv\" and \"Adv+Virtual Adv\", the cost term of formula (3) are applied to all the samples, or only applied to unlabeled samples?\nThis paper applies the idea of the adversarial training and virtual adversarial training to the LSTM-based model in the text context. The paper is in general well written and easy to follow. Extending the idea of the adversarial training to the text tasks is simple but non-trivial. Overall the paper is worth to publish. \n\nI only have a minor comment: it is also interesting to see how much adversarial training can help in the performance of RNN, which is a simpler model and may be easier to analyze. ", "title": "Experiment settings", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "r1TrCM7Eg": {"type": "review", "replyto": "r1X3g2_xl", "review": "Hi,\n\nIs the virtual adversarial training used in the pre-training phase? Also In the results of Table 2, for the line of \"Virtual Adv\" and \"Adv+Virtual Adv\", the cost term of formula (3) are applied to all the samples, or only applied to unlabeled samples?\nThis paper applies the idea of the adversarial training and virtual adversarial training to the LSTM-based model in the text context. The paper is in general well written and easy to follow. Extending the idea of the adversarial training to the text tasks is simple but non-trivial. Overall the paper is worth to publish. \n\nI only have a minor comment: it is also interesting to see how much adversarial training can help in the performance of RNN, which is a simpler model and may be easier to analyze. ", "title": "Experiment settings", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}}}