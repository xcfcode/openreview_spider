{"paper": {"title": "Multi-view Generative Adversarial Networks", "authors": ["Micka\u00ebl Chen", "Ludovic Denoyer"], "authorids": ["mickael.chen@lip6.fr", "ludovic.denoyer@lip6.fr"], "summary": "We describe the MV-BiGAN model able to perform density estimation from multiple views, and to update its prediction when additional views are provided", "abstract": "Learning over multi-view data is a challenging problem with strong practical applications. Most related studies focus on the classification point of view and assume that all the views are available at any time. We consider an extension of this framework in two directions. First, based on the BiGAN model, the Multi-view BiGAN (MV-BiGAN) is able to perform density estimation from multi-view inputs. Second, it can deal with missing views and is able to update its prediction when additional views are provided. We illustrate these properties on a set of experiments over different datasets.", "keywords": ["Deep learning", "Supervised Learning"]}, "meta": {"decision": "Reject", "comment": "The presented approach builds heavily on recent work, but does provide some novelty. The presentation is generally all right, but there are parts of the manuscript that the reviewers feel needed/needs work. All reviewers note that the evaluation and experimental work could be improved."}, "review": {"H1QkdnHmg": {"type": "rebuttal", "replyto": "BktgfAkmg", "comment": "Thank you for your questions. Actually, we only use the MV-GAN for generation, and a future work will be to see if the learned distributions can be used for other tasks e.g semi-supervised learning.", "title": "re: have you used the latent features for some tasks"}, "SkSwvnSme": {"type": "rebuttal", "replyto": "BJgb6j1mx", "comment": "Thank you for the questions:\n\nQ1: n_k refer to the number of features of view k. We are only pointing out that all observations for each view k must be vectors in \\mathbb{R}^n_k\n\nQ2: In the case of the MV-BiGAN, \\tilde{x} is a set of views. Therefore p(z|\\tilde{x}) is approximated with a neural network that takes a set as input. \\Psi is a learned function which goal is to aggregate  the differents views into a single vector. In our experiments, \\phi are either linear transformations or convolutional networks that are learned together with the MV-BiGAN.\n\nQ3: They are two main distinctions between standard CGAN proposed by Mirza & Osindero, 2014 and CV-BiGAN.\nThe first difference concerns the generation process: In CGAN, a noise is added at the input level. (It is concatenated with the input  and then used to generate an output). The CV-BiGAN instead only uses an input which is mapped to a distribution in the latent space. The generator then uses one latent vector sampled from this distribution. Let us illustrate the two processes:\nCGAN: G(x + z) -> y\nCV-BiGAN: G(x) -> mu,sigma ~> z -> y\n\nThe second difference concerns the discriminator: \nCGAN's discriminator learns to differentiate fake pairs (x,y) where x is sampled using G(y) from real pairs (x,y) directly drawn from the dataset. Depending on the data, this task can be too easy for the discriminator, especially when x and y are both images. This can hamper the learning process.\nCV-BiGAN decomposes the task using two discriminators, one for (x,z) and one for (z,y). Then, the discriminators never have access to both the input and the output at the same time making learning easier.\n\nThe paper has been updated and now includes this discussion", "title": "re: A few questions"}, "BktgfAkmg": {"type": "review", "replyto": "SJgWQPcxl", "review": "I have not found major problems with the formulation, derivation etc. \n\nAt this point, I am curious, have you used the latent low-dimensional features for some downstream tasks? A quick scan indicates the authors are mostly focusing on generation tasks.\n\nIt would be good to consider using those features for the multi-view representation learning tasks, such as those in the deep variational CCA paper. This paper presents extensions of bidirectional generative adversarial networks to the conditional setting and multi-view setting. The methods are well-motivated, the mathematical derivations appear to be correct, and the presentation is clear enough to me. \n\nI would suggest this paper to be accepted. However, I find it somewhat limited to only present results for generation tasks. I think a main advantage of using bi-GAN (rather than the standard GAN) is the additional inference model that can learn useful features. I am curious about how good the features are for some other supervised (or semi-supervised) learning tasks and what have they really learned.\n\nI also find it interesting that the counterpart of these models under the VAE framework have also been proposed\n- Kihyuk Sohn and Honglak Lee and Xinchen Yan. Learning Structured Output Representation using Deep Conditional Generative Models. NIPS 2015.  (*** contitional VAE ***)\n- Weiran Wang, Xinchen Yan, Honglak Lee, and Karen Livescu. Deep Variational Canonical Correlation Analysis. In submission to ICLR 2017. (*** sort of multi-view VAE ***)\n\nIt would be nice to have discussions and comparisons in future work. ", "title": "have you used the latent features for some tasks", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "S1Z8Ta-Nx": {"type": "review", "replyto": "SJgWQPcxl", "review": "I have not found major problems with the formulation, derivation etc. \n\nAt this point, I am curious, have you used the latent low-dimensional features for some downstream tasks? A quick scan indicates the authors are mostly focusing on generation tasks.\n\nIt would be good to consider using those features for the multi-view representation learning tasks, such as those in the deep variational CCA paper. This paper presents extensions of bidirectional generative adversarial networks to the conditional setting and multi-view setting. The methods are well-motivated, the mathematical derivations appear to be correct, and the presentation is clear enough to me. \n\nI would suggest this paper to be accepted. However, I find it somewhat limited to only present results for generation tasks. I think a main advantage of using bi-GAN (rather than the standard GAN) is the additional inference model that can learn useful features. I am curious about how good the features are for some other supervised (or semi-supervised) learning tasks and what have they really learned.\n\nI also find it interesting that the counterpart of these models under the VAE framework have also been proposed\n- Kihyuk Sohn and Honglak Lee and Xinchen Yan. Learning Structured Output Representation using Deep Conditional Generative Models. NIPS 2015.  (*** contitional VAE ***)\n- Weiran Wang, Xinchen Yan, Honglak Lee, and Karen Livescu. Deep Variational Canonical Correlation Analysis. In submission to ICLR 2017. (*** sort of multi-view VAE ***)\n\nIt would be nice to have discussions and comparisons in future work. ", "title": "have you used the latent features for some tasks", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "BJgb6j1mx": {"type": "review", "replyto": "SJgWQPcxl", "review": "I have a few questions regarding this paper:\n\n1) Does n_k refer to the number of points observed for view k, or to the number of features with which each point is represented? \n\n2) Why is \\phi used? What is the benefit from the basic approach where we let the latent space z deal with the representation of \\tilde{x}? Also, how is \\phi parameterized? Doesn't the consideration of \\phi (instead of just having \\tilde{x}) make training more tricky (i.e. it'd be easier to learn p(z|\\tilde{x}) rather than p(z | \\Psi))?\n\n3) I'd be interested to see more discussion on CGAN vs CV-BiGAN; from the current discussion it seems that CV-BiGAN is like CGAN but with an extra mapping (following BiGAN). Is there a further distinction?\n\nThank youThis paper builds in the bidirectional GAN (BiGAN) to obtain an extension which can handle multiple views of data. To this end, the authors extend the BiGAN for multiple view aggregation. This is an easy task and just requires the introduction of the additional distribution and accompanying discriminator. The main challenging and novel part is in regularizing the model to avoid instabilities. The authors propose a novel KL divergence based constraint.\n\nAs mentioned above, the approach builds quite heavily on previous ones but it has enough novel elements, in particular the constraint for regularization. This constraint is a reasonable assumption an in practice seems to work well. One downside is that it comes with a parameter \\lambda which controls its strength and which is not obvious how to find efficiently. For example, for the MNIST data it takes a very small value, 10^-5 and for the CELEBA it's 10^-3. It could be that the results are not very sensitive to this value, but there's no discussion concerning this aspect. \n\nApart from the regularization term, the rest of the model construction is well motivated, I agree with the authors that a multi-view approach employing GANs is an interesting topic to consider. \n\nPresentation is in general good although at parts readability is hindered. I feel that the notation is unnecessarily complicated, and some parts of the text too. Furthermore, it wasn't immediately obvious to me what is considered as \\tilde{x} and what is y in the experiments. \n\nAdditionally, most of the discussion on the well-studied area of multi-view learning (intro and sec. 6) omits reference to important prior work which is not based on neural networks. Indeed, some of the issues mentioned as common in today's methods (discrete outputs only, no density estimation...) do not actually exist in many non-neural network approaches. There are too many works to suggest including in the discussion, but I guess the most relevant ones are in the field of probabilistic and non-linear multi-view learning, which is also what MV-BiGAN is doing.\n\nThe experiments presented in the paper are nice illustrations but unfortunately insufficient. Firstly, they only cover the task of generating (small) images and correspond to non-real world settings (I'd actually consider all of the experiments as toy experiments). Furthermore, the most difficult of these experiments (sec. 5.3) is quite unconvincing. If Fig. 6 shows some of the best results that can be achieved, then this is rather disappointing. Important details are also missing: what is exactly the attribute vector used? How many instances exist?\n\nThe two other experiments on 5.1 and 5.2 are well executed. It's important that the authors show a comparison with \\lambda=0. \n\nHowever, beyond showing the validity of the KL term, one can't conclude much about the overall merit of the method as a multi-view learning approach, given the above experiments. \n\nOverall this was a nice paper to read, but seems somehow incomplete.\n", "title": "A few questions", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "rkqugZfVe": {"type": "review", "replyto": "SJgWQPcxl", "review": "I have a few questions regarding this paper:\n\n1) Does n_k refer to the number of points observed for view k, or to the number of features with which each point is represented? \n\n2) Why is \\phi used? What is the benefit from the basic approach where we let the latent space z deal with the representation of \\tilde{x}? Also, how is \\phi parameterized? Doesn't the consideration of \\phi (instead of just having \\tilde{x}) make training more tricky (i.e. it'd be easier to learn p(z|\\tilde{x}) rather than p(z | \\Psi))?\n\n3) I'd be interested to see more discussion on CGAN vs CV-BiGAN; from the current discussion it seems that CV-BiGAN is like CGAN but with an extra mapping (following BiGAN). Is there a further distinction?\n\nThank youThis paper builds in the bidirectional GAN (BiGAN) to obtain an extension which can handle multiple views of data. To this end, the authors extend the BiGAN for multiple view aggregation. This is an easy task and just requires the introduction of the additional distribution and accompanying discriminator. The main challenging and novel part is in regularizing the model to avoid instabilities. The authors propose a novel KL divergence based constraint.\n\nAs mentioned above, the approach builds quite heavily on previous ones but it has enough novel elements, in particular the constraint for regularization. This constraint is a reasonable assumption an in practice seems to work well. One downside is that it comes with a parameter \\lambda which controls its strength and which is not obvious how to find efficiently. For example, for the MNIST data it takes a very small value, 10^-5 and for the CELEBA it's 10^-3. It could be that the results are not very sensitive to this value, but there's no discussion concerning this aspect. \n\nApart from the regularization term, the rest of the model construction is well motivated, I agree with the authors that a multi-view approach employing GANs is an interesting topic to consider. \n\nPresentation is in general good although at parts readability is hindered. I feel that the notation is unnecessarily complicated, and some parts of the text too. Furthermore, it wasn't immediately obvious to me what is considered as \\tilde{x} and what is y in the experiments. \n\nAdditionally, most of the discussion on the well-studied area of multi-view learning (intro and sec. 6) omits reference to important prior work which is not based on neural networks. Indeed, some of the issues mentioned as common in today's methods (discrete outputs only, no density estimation...) do not actually exist in many non-neural network approaches. There are too many works to suggest including in the discussion, but I guess the most relevant ones are in the field of probabilistic and non-linear multi-view learning, which is also what MV-BiGAN is doing.\n\nThe experiments presented in the paper are nice illustrations but unfortunately insufficient. Firstly, they only cover the task of generating (small) images and correspond to non-real world settings (I'd actually consider all of the experiments as toy experiments). Furthermore, the most difficult of these experiments (sec. 5.3) is quite unconvincing. If Fig. 6 shows some of the best results that can be achieved, then this is rather disappointing. Important details are also missing: what is exactly the attribute vector used? How many instances exist?\n\nThe two other experiments on 5.1 and 5.2 are well executed. It's important that the authors show a comparison with \\lambda=0. \n\nHowever, beyond showing the validity of the KL term, one can't conclude much about the overall merit of the method as a multi-view learning approach, given the above experiments. \n\nOverall this was a nice paper to read, but seems somehow incomplete.\n", "title": "A few questions", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}}}