{"paper": {"title": "Minimal Images in Deep Neural Networks: Fragile Object Recognition in Natural Images", "authors": ["Sanjana Srivastava", "Guy Ben-Yosef", "Xavier Boix"], "authorids": ["sanjanas@mit.edu", "gby@csail.mit.edu", "xboix@mit.edu"], "summary": "", "abstract": "The human ability to recognize objects is impaired when the object is not shown in full. \"Minimal images\" are the smallest regions of an image that remain recognizable for humans. Ullman et al. (2016) show that a slight modification of the location and size of the visible region of the minimal image produces a sharp drop in human recognition accuracy. In this paper, we demonstrate that such drops in accuracy due to changes of the visible region are a common phenomenon between humans and existing state-of-the-art deep neural networks (DNNs), and are much more prominent in DNNs. We found many cases where DNNs classified one region correctly and the other incorrectly, though they only differed by one row or column of pixels, and were often bigger than the average human minimal image size. We show that this phenomenon is independent from previous works that have reported lack of invariance to minor modifications in object location in DNNs. Our results thus reveal a new failure mode of DNNs that also affects humans to a much lesser degree. They expose how fragile DNN recognition ability is in natural images even without adversarial patterns being introduced. Bringing the robustness of DNNs in natural images to the human level remains an open challenge for the community. ", "keywords": []}, "meta": {"decision": "Accept (Poster)", "comment": "This paper characterizes a particular kind of fragility in the image classification ability of deep networks: minimal image regions which are classified correctly, but for which neighboring regions shifted by one row or column of pixels are classified incorrectly. Comparisons are made to human vision. All three reviewers recommend acceptance. AnonReviewer1 places the paper marginally above threshold, due to limited originality over Ullman et al. 2016, and concerns about overall significance.\n"}, "review": {"SyxRF01G1V": {"type": "rebuttal", "replyto": "BygMhU1Gy4", "comment": "Note that evaluating human FRIs on DNNs (Ullman et al.) is quite different from extracting FRIs from DNNs (our paper). These two experiments investigate different things: \n\n*evaluating human FRIs on DNNs (Ullman et al.): Are DNNs affected by human FRIs? The answer was no.\n*extracting FRIs on DNNs (our paper): do DNNs have their own set of FRIs (different from humans FRIs)? The answer is yes. We showed for the first time that DNNs also have FRIs.\n\nSo, Ullman et al. asks about the transferability of human FRIs to DNNs, while we ask if DNNs have their own FRIs.\n\nQuoting from our paper in the introduction:\n\"Ullman et al. (2016) show that DNNs are unable to recognize human minimal images, and the DNN\ndrop in accuracy for these minimal images is gradual rather than sharp. This begs the question of\nwhether the sharp drop in accuracy for minimal images is a phenomenon exclusive to human vision,\nor there exist distinct but analogous images that produce a sharp drop in DNN accuracy.\"", "title": "differences vs. Ullman et al 2018 "}, "rJl_o4iG6Q": {"type": "review", "replyto": "S1xNb2A9YX", "review": "Ullman et al. showed that slight changes in location or size of visible regions in minimal recognizable images can significantly impair human ability to recognize objects. This paper is a  follow-up of Ullman et al. paper, with focus on sensitivity of DNNs to certain regions in images. In other words, slight change of such regions\u2019 size or location in the image can significantly affect DNN ability in recognizing them, even-though these changes are not noticeable for humans. \n\n\nComments and questions:\n\nThis paper provides in-depth study of fragile recognition in DNNs. \n\n- Visualizing activations of different layers of DNN for Loose shift/shrink FRIs can potentially provide more details on why the final output of DNN is significantly different for two visually similar images.   \n\n- Naively augmenting training data with crops of small FRI sizes can potentially harm and confuse DNN in classifying training samples as many small patches in training images are background and they don't contain target object. It is interesting to see the sensitivity of DNNs that are trained for the task of object detection to FRIs, like sensitivity of R-CNN to FRIs. In this case augmenting training data with crops of small FRI sizes can be properly done since ground-truth bounding boxes can determine which region is foreground and which region is background. ", "title": "Interesting paper but requires additional experiments ", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "Hyl7zKrTnm": {"type": "review", "replyto": "S1xNb2A9YX", "review": "This paper is a more thorough follow-up to e a previous work by Ullman et al that was comparing minimally recognizable patches by humans compared to deep neural network. This paper exhibits that a wide range of architectures features the same fragility and that these effects can combated by better training methodology and different pooling architectures. Still even with those changes deep CNNs still posses more fragile behavior than human vision. One of my criticism is that human vision is kind of different: it makes multiple passes over the same images at multiple scales, so this might contribute significantly to these differences. Still this paper makes a lot of interesting observations and analyses and represents a first methodological study of this phenomenon.\n\nA novelty of this work is that it is the first paper that methodologically analyses FRIs for DNNs a reasearch area which might shed new light on the understanding of how vision systems work and the source of misrecognitions and the limitations of recognition systems.\n\nIn light of the changes of the paper and the clarification on the novelty aspect of this research, I suggest this paper to be accepted as it constitutes novel research in understanding how DNNs recognize image content and its similarities and differences to human vision.\n\n\n\n", "title": "Interesting progress in measuring the fragility of deep neural network based recognition.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "r1lABXCFAX": {"type": "rebuttal", "replyto": "ByxajLCdhQ", "comment": "We thank the reviewer for her/his valuable comments and questions, which we address below.\n\nReviewer: \u201cIt would be more insightful if authors added comparison between DNN sensitivity to tiny translations of small image crops vs. full-size images\u201d\nAuthors: We are unsure we have understood correctly this comment because in Section 4 of the original submission (\u201cFragile recognition is not lack of object location invariance\u201d) we have provided the comparison between DNN sensitivity to tiny translations of small image crops vs. full-size images.\n\nReviewer: \u201cWould upscaling say a small 28x28 crop into 224x224 image here naturally negatively impact the DNN predictive performance? [...] One hypothesis here is that fragile recognition may be because the test image resolution does not match the training image resolution. \nAuthors: The results presented in the paper reject this hypothesis:\n1) Matching the training image resolution does not solve FRIs. Fig. 6a shows that augmenting training data with small crops does not solve FRIs. \n2) There are FRIs at any crop size. Fig.5 shows that about 1 out of 50 crops of 200x200 pixels (P=0.8) are FRIs. \n\nReviewer: \u201cAn alternative to upscaling here is to zero-pad the crop region. Can you help us understand your choice of upscaling here?\u201d\nAuthors: Note that FRIs can also be constructed by zero-padding. We added an experiment to clarify this in Fig. A.6. We tested FRIs generated by zero-padding (instead of upscaling) in DNNs with different pooling region sizes. The results show that FRIs arise in zero-padding in the same way as upscaling, and larger pooling does not significantly reduce the amount of FRIs the way it reduces lack of invariance. This result further strengthens the conclusion that FRIs are a phenomenon independent of the lack of invariance reported in previous works. Upscaling was chosen for the study instead of zero-padding because upscaling leads to natural images while zero-padding does not. FRIs can be produced by just moving the camera a bit closer or a bit to the side. Studying the failure modes of DNNs in natural images is crucial, as these failures happen without the need of an attacker handcrafting images by adding zero-padding or synthetic perturbations. \n\nReviewer: \u201cThe originality is limited as it is a close extenstion work of Ullman et al. 2016\u201d \nUllman et al. analyses minimal images for human vision, while we analyze minimal images for DNNs (more generally denoted as FRIs). We have shown for the first time that: 1) minimal images are a common phenomenon among human vision and DNNs, 2) DNNs are more severely affected by minimal images than humans, and 3) minimal images are a new failure mode of DNNs that arise in natural images and are independent of phenomena found in previous works. \n\n\nReviewer: \u201cGiven what we learned from the adversarial example research area, the contribution of this work is low because results might not be too surprising.\u201d\nAuthors: Note that we have shown a new type of adversarial example that arises without the need of artificial perturbations. As shown in Section 4, previous works on adversarial examples without artificial perturbations use zero-padding and can be alleviated with architectures with large pooling regions, while FRIs are entirely natural images and cannot be similarly alleviated.\n", "title": "rebuttal"}, "SylXYGAtAm": {"type": "rebuttal", "replyto": "Hyl7zKrTnm", "comment": "We thank the reviewer for her/his valuable comments and questions, which we address below.\n\nReviewer: \u201chuman vision is kind of different: it makes multiple passes over the same images at multiple scales, so this might contribute significantly to these differences.\u201d\nAuthors: DNNs and human vision are different and investigating these differences will help developing better DNNs and understanding human vision. In the paper, we have shown that minimal images are a common phenomenon among DNNs and humans, which opens a new line of research for studying the commonalities and differences between DNNs and humans.  To illustrate how to proceed in this line of research, we added an experiment to show the effect of multiscale and the eccentricity dependence of human vision in FRIs. Fig. A.4 shows the FRIs for a scale invariant architecture that processes multiple scales in parallel and is eccentricity dependent (Chen et al. 2017), trained in CIFAR-10. We can see that this architecture alleviates FRIs compared to the architectures we previously tested, but there is still much to do to completely close the gap between DNNs and humans.", "title": "rebuttal"}, "Hyx5WGAtRX": {"type": "rebuttal", "replyto": "rJl_o4iG6Q", "comment": "We thank the reviewer for her/his valuable comments and questions, which we address below. \n\nReviewer: \u201cVisualizing activations of different layers of DNN for Loose shift/shrink FRIs can potentially provide more details on why the final output of DNN is significantly different for two visually similar images.\u201d\nAuthors: We have added visualizations in Figure A.11. As in previous works on adversarial examples, these visualizations do not clarify much beyond that fact that differences are small for the first layers, then are magnified at the later layers. \n\nReviewer: \u201cNaively augmenting training data with crops of small FRI sizes can potentially harm and confuse DNN in classifying training samples as many small patches in training images are background and they don't contain target object.\u201d\nAuthors: To verify that adding crops in the training set does not harm the accuracy, we added Fig. A.2 in the paper, which shows that the accuracy of the network always improves when adding the crops in the training set. This may be because in CIFAR the crops are always on the object, as the object is centered and occupies the whole CIFAR image. For ImageNet, the tested networks add crops in the training set from the interior of the annotated bounding-box.\n\nReviewer: \u201cIt is interesting to see the sensitivity of DNNs that are trained for the task of object detection to FRIs, like sensitivity of R-CNN to FRIs.\u201d\nAuthors: We added Figure A.12 in the paper to show qualitative examples of FRIs for the YOLO object detector. This result illustrates that object detectors also suffer from FRIs, as they are based on DNNs. Quantifying how much the accuracy of the detectors is due to FRIs is an interesting follow up of our paper. ", "title": "rebuttal"}, "ByxajLCdhQ": {"type": "review", "replyto": "S1xNb2A9YX", "review": "Thanks the authors for an interesting work!\nThe paper studies the differences between human and DNN vision via means of minimal images (i.e. smallest image crops that can be correctly classified).\n\nThere are a few notable take-away messages:\n1. DNNs are not invariant to even tiny (1-2 px) translations of small image crops.\n    - It would be more insightful if authors added comparison between DNN sensitivity to tiny translations of small image crops vs. full-size images (i.e. translation-based adversarial examples https://openreview.net/forum?id=BJfvknCqFQ ).\n2. The smaller the image crops, the more sensitive DNNs become (here, more FRIs)\n3. DNNs and human vision misclassify the image crops differently: (1) DNNs have almost twice more FRI(s) and (2) FRIs of human and DNNs differ in location.\n\nQuestions:\n\n- \"After extracting the region from the image, the region is resized to be of the size required by the network.\"\nWould upscaling say a small 28x28 crop into 224x224 image here naturally negatively impact the DNN predictive performance?\nThat is, because typically image classifiers are trained on one (or a few) fixed resolution(s) of images.\n\nOne hypothesis here is that fragile recognition may be because the test image resolution does not match the training image resolution.\nHuman on the other hands, have been trained on images of variable resolutions.\n\nAn alternative to upscaling here is to zero-pad the crop region. Can you help us understand your choice of upscaling here?\n\n+ Originality\nThe originality is limited as it is a close extenstion work of Ullman et al. 2016\n\n+ Clarity\nThe paper is well written and presented.\n\n+ Significance\nThis work extends our understanding of the differences between DNNs and human vision.\nHowever, given what we learned from the adversarial example research area, the contribution of this work is low because results might not be too surprising.", "title": "ok paper; an important question on upscaling image crops", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}}