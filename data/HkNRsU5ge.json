{"paper": {"title": "Sigma Delta Quantized Networks", "authors": ["Peter O'Connor", "Max Welling"], "authorids": ["peter.ed.oconnor@gmail.com", "max.welling@uva.nl"], "summary": "A deep neural network that saves computation on temporal data by using neurons that only communicate their changes in activation", "abstract": "Deep neural networks can be obscenely wasteful. When processing video, a convolutional network expends a fixed amount of computation for each frame with no regard to the similarity between neighbouring frames. As a result, it ends up repeatedly doing very similar computations. To put an end to such waste, we introduce Sigma-Delta networks. With each new input, each layer in this network sends a discretized form of its change in activation to the next layer. Thus the amount of computation that the network does scales with the amount of change in the input and layer activations, rather than the size of the network. We introduce an optimization method for converting any pre-trained deep network into an optimally efficient Sigma-Delta network, and show that our algorithm, if run on the appropriate hardware, could cut at least an order of magnitude from the computational cost of processing video data.\n", "keywords": ["Computer vision", "Deep learning", "Applications"]}, "meta": {"decision": "Accept (Poster)", "comment": "The reviewers are in consensus that this paper introduces an interesting idea with potentially huge gains in the efficiency of video analysis tasks (dependent on hardware advances). There was extensive discussion during the question/review period. Two of the reviewers scored this paper in the Top 50% of accepted papers. The lower score is from the less confident reviewer. This seems to the AC to be a clear accept."}, "review": {"Hy89n0Evg": {"type": "rebuttal", "replyto": "HkNRsU5ge", "comment": "Dear Reviewers.\n\nThank you for all your comments.  We have uploaded a final draft based on your feedback.  \n\nSummary of changes:\n- Added to the discussion section, mentioning applicability for hardware, and how training on \"slow features\" may improve our network, as mentioned by Reviewers 1 and 2.  \n- Added new plots to the final figure, showing how computation breaks down across layers in different versions of the network. \n- Added a small experiment, in appendix, demonstrating that in the pretrained VGGnet we used, features to not change significantly more slowly in higher layers than in lower layers.\n- Moved connection to herding to appendix.\n- Clarified the point about Temporal vs Sequential differences brought up by Reviewer 3.\n", "title": "Updated Version"}, "B18MBkm4g": {"type": "rebuttal", "replyto": "Bk4502Z4l", "comment": "Thank you for your review and comments.\n\nRegarding the temporal difference comment, it was made with event-based vision sensors in mind.  When the temporal spacing between input samples is not constant, there is a distinction between a \"temporal difference\" and an \"interframe difference\".  I'll try to reword this to clarify for the final draft.  ", "title": "Re: Temporal vs Interframe difference"}, "BJTVhJh7x": {"type": "rebuttal", "replyto": "Hyp_fbs7l", "comment": "I'm no hardware expert, but I have a sense that such performance gains will not transfer easily to GPU.  Our \"performance\" is measured as the number of arithmetic operations.  I would expect that the main performance bottleneck with implementing this on GPU would be the need for sparse random lookup of weights - not arithmetic operations.  Fortunately, there is work going on on specialized hardware (e.g. IBM TrueNorth) which stores memory closer to processing, vastly reducing the overhead of memory access, and may be able to actually take advantage of the gains discussed in this paper.  ", "title": "Re: GPU Performance"}, "Hyp_fbs7l": {"type": "review", "replyto": "HkNRsU5ge", "review": "Do the authors have a sense of how easily the theoretical performance gains reported can be transferred to the GPU based deep learning frameworks that are used in practice?The paper presents a method to improve the efficiency of CNNs that encode sequential inputs in a \u2018slow\u2019 fashion such that there is only a small change between the representation of adjacent steps in the sequence.\nIt demonstrates theoretical performance improvements for toy video data (temporal mnist) and natural movies with a powerful Deep CNN (VGG). \n\nThe improvement is naturally limited by the \u2018slowness\u2019 of the CNN representation that is transformed into a sigma-delta network: CNNs that are specifically designed to have \u2018slow\u2019 representations will benefit most. Also, it is likely that only specialised hardware can fully harness the improved efficiency achieved by the proposed method. Thus as of now, the full potential of the method cannot be thoroughly evaluated.\nHowever, since the processing of sequential data seems to be a broad and general area of application, it is conceivable that this work will be useful in the design and application of future CNNs.\n\nAll in all, this paper introduces an interesting idea to address an important topic. It shows promising initial results, but the demonstration of the actual usefulness and relevance of the presented method relies on future work.\n", "title": "Practical performance gains", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "B1G7WCZVe": {"type": "review", "replyto": "HkNRsU5ge", "review": "Do the authors have a sense of how easily the theoretical performance gains reported can be transferred to the GPU based deep learning frameworks that are used in practice?The paper presents a method to improve the efficiency of CNNs that encode sequential inputs in a \u2018slow\u2019 fashion such that there is only a small change between the representation of adjacent steps in the sequence.\nIt demonstrates theoretical performance improvements for toy video data (temporal mnist) and natural movies with a powerful Deep CNN (VGG). \n\nThe improvement is naturally limited by the \u2018slowness\u2019 of the CNN representation that is transformed into a sigma-delta network: CNNs that are specifically designed to have \u2018slow\u2019 representations will benefit most. Also, it is likely that only specialised hardware can fully harness the improved efficiency achieved by the proposed method. Thus as of now, the full potential of the method cannot be thoroughly evaluated.\nHowever, since the processing of sequential data seems to be a broad and general area of application, it is conceivable that this work will be useful in the design and application of future CNNs.\n\nAll in all, this paper introduces an interesting idea to address an important topic. It shows promising initial results, but the demonstration of the actual usefulness and relevance of the presented method relies on future work.\n", "title": "Practical performance gains", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "Hy105m47x": {"type": "rebuttal", "replyto": "r1Zs9yRMe", "comment": "Thank you for your feedback.\n\n1) herd(delta(x)) vs delta(round(x))\nI should clarify that.  The aim was just to draw a connection to doing herding on the differences, and taking the difference of the rounded value.   In practice we would implement the network with Delta(Round(x)) approach.  In retrospect this connection to herding is more an \"aside\" to the paper, and the paper could be simplified to omit herding from the explanation.  \n\n2) Herding now vs Herding then\nherd(x) can be seen as a deterministic sampling of the real value x, and is similar to equation 13 in the Welling 2009 paper, just on activations instead of parameters, and with value of x not bounded in [0, 1] as it is in the Welling, 2009.\n\n3) Incorporating computational loss from higher layers.\nI wouldn't say I have a full understanding, but I have some inkling.  If we're trying to optimize LC2 (computational loss of layer 2) with respect to s1 (the scale of layer 1), we have the equation: LC2 = N2*sum(abs(s2*h(round(s1*x)/s1 <dot> w))).   (where *, / are elementwise mult,div, h is hidden activation).  This contains the function: round(x*s)/s, which is differentiable in s, but has discontinuities.  Discontinuities get larger as s gets smaller.  The error-loss function also contains round(x*s)/s, but the need to decrease error keeps s from getting too small.   The computational loss however, doesn't care if s gets small, so I think when this term is included, scales can get into a regime with large discontinuities.  An example with random weights, relating the computational loss in layer 2 to the scale of one neuron in layer 1: https://github.com/petered/data/blob/master/images/unstable_error_example.png shows how this error surface can cause instability.\n", "title": "Response to your comments"}, "SyJfBG77g": {"type": "rebuttal", "replyto": "B1W0mtsfe", "comment": "Thank you for your careful review.  I'll respond to your comments here, and use your input to clarify some things in the final draft.\n\nFigure 4:\n1) The Lambda=0 limit:\nFor the Rounding/Sigma-Delta Networks, we measure computation by \"number of additions\" as described in Section 3.3.  This is possible because our activations are integer vectors, and multiplying a real (weight matrix row) by an integer K can be represented as K additions of the real.  For the \"Original\" network, in which activations are also real, we measure computation as the cost of all matrix multiplications (also in 3.3, just below Equation 3).  \n\nFor the Rounding/Sigma-Delta Networks at lambda=0, we would expect computation to grow to infinity (as the scale keeps increasing to compensate for the discretization), and the error to approach that of the \"Original Network\".  However, eventually, it would make sense to do the computations as matrix multiplications, in which case the curves should meet the leftmost dot of the \"Original\" network in the left part of Figure 4.  \n\nThis slightly \"apples to oranges\" comparison (comparing #additions to #multiplications) is why we chose to include the right two plots, which factor in the energy difference between addition and multiplication.  \n\n2) Energy calculations with the Horowitz numbers\n\nYou found an error, thank you.  The energy numbers were listed with #flops calculated as if we were doing sparse multiplications (as opposed to additions), while the left plots were counting additions.  I've updated the plot, which now reflects that we are simply multiplying the x-axis by conversion constants.\n\n3) Lack of Large Difference of Rounding and Sigma-Delta\nI've looked a bit into this since finishing the paper.   The reason appears to be that, at least for neural networks pre-trained on non-temporal data (like the ones here), hidden representations are quite unstable.  Small, frame-to-frame changes in the input data tend to cause larger changes to the hidden representations.  If you look at the cosine-distance between neighbouring frames, it tends to be higher for hidden layers than the input layer, which was the opposite of what I expected.  Hopefully networks trained on temporal data can learn more stable representations.\n\n4) Preliminary results (last experiment on VGGnet) seem to show that on large networks with video, our Temporal-Difference approach uses about 1/4 to 1/2 the computation required by simply rounding.  In the Temporal-MNIST experiment it uses about 1/2.  So it seems the magnitude of the effect doesn't change dramatically with network size.  \n", "title": "Response to your comments."}, "r1Zs9yRMe": {"type": "review", "replyto": "HkNRsU5ge", "review": "I enjoyed reading this paper. I had some questions, especially about the use of herding in Section 3.2.\n\nFirst: why is the use of herding an improvement? That is, why is herd(Delta) better than Delta(round)? I would expect exactly the opposite. By accumulating deltas before rather than after discretization, it seems that you are forcing the Delta operation to both use more expensive floating point arithmetic, and to store floating point rather than integer values.\n\nSecond: could you elaborate on how \"herding\" in this context is analogous to herding as introduced in Welling, 2009? I thought I knew what herding was, but am having difficulty seeing a clear connection.\n\nFinally, not crucial to the story of the paper, but for my own curiosity -- in Section 4.3 do you have a sense of why training became unstable when you incorporated the computational loss of higher layers in the gradient?This paper presented a method of improving the efficiency of deep networks acting on a sequence of correlated inputs, by only performing the computations required to capture changes between adjacent inputs. The paper was clearly written, the approach is clever, and it's neat to see a practical algorithm driven by what is essentially a spiking network. The benefits of this approach are still more theoretical than practical -- it seems unlikely to be worthwhile to do this on current hardware. I strongly suspect that if deep networks were trained with an appropriate sparse slowness penalty, the reduction in computation would be much larger.", "title": "quantization", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "rJwfTbM4l": {"type": "review", "replyto": "HkNRsU5ge", "review": "I enjoyed reading this paper. I had some questions, especially about the use of herding in Section 3.2.\n\nFirst: why is the use of herding an improvement? That is, why is herd(Delta) better than Delta(round)? I would expect exactly the opposite. By accumulating deltas before rather than after discretization, it seems that you are forcing the Delta operation to both use more expensive floating point arithmetic, and to store floating point rather than integer values.\n\nSecond: could you elaborate on how \"herding\" in this context is analogous to herding as introduced in Welling, 2009? I thought I knew what herding was, but am having difficulty seeing a clear connection.\n\nFinally, not crucial to the story of the paper, but for my own curiosity -- in Section 4.3 do you have a sense of why training became unstable when you incorporated the computational loss of higher layers in the gradient?This paper presented a method of improving the efficiency of deep networks acting on a sequence of correlated inputs, by only performing the computations required to capture changes between adjacent inputs. The paper was clearly written, the approach is clever, and it's neat to see a practical algorithm driven by what is essentially a spiking network. The benefits of this approach are still more theoretical than practical -- it seems unlikely to be worthwhile to do this on current hardware. I strongly suspect that if deep networks were trained with an appropriate sparse slowness penalty, the reduction in computation would be much larger.", "title": "quantization", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "B1W0mtsfe": {"type": "review", "replyto": "HkNRsU5ge", "review": "I am a bit puzzled about the results shown in Figure 4. I guess for lambda=0 one should recover the original network so that all the data points should come together. Is that right? \n\nAlso, I guess the transformation of Horowitz must be non-linear for how would suddenly the difference at low lambda in the temporal MNIST goes to zero in the low lambda regime. Or is there another way to understand what is going on? \n\nI would have expected (and maybe you would have hoped for) a much more significant difference between Rounding and Sigma-Delta. Indeed, how significant is this?\n\nAnd finally, mainly curious, how would you say that these results change with scaling to larger networks?This is an interesting paper about quantized networks that work on temporal difference inputs.  The basic idea is that when a network has only to process differences then this is computational much more efficient specifically with natural video data since large parts of an image would be fairly constant so that the network only has to process the informative sections of the image (video stream). This is of course how the human visual system works, and it is hence of interest even beyond the core machine learning community. \n\nAs an aside, there is a strong community interested in event-based vision such as the group of Tobi Delbr\u00fcck, and it might be interesting to connect to this community. This might even provide a reference for your comments on page 1.\n\nI guess the biggest novel contribution is that a rounding network can be replaced by a sigma-delta network, but that the order of discretization and summation doe make some difference in the actual processing load. I think I followed the steps and \nMost of my questions have already been answers in the pre-review period. My only question remaining is on page 3, \u201cIt should be noted that when we refer to \u201ctemporal differences\u201d, we refer not to the change in the signal over time, but in the change between two inputs presented sequentially. The output of our network only depends on the value and order of inputs, not on the temporal spacing between them.\u201d\n\nThis does not make sense to me. As I understand you just take the difference between two frames regardless if you call this temporal or not it is a change in one frame. So this statement rather confuses me and maybe should be dropped unless I do miss something here, in which case some more explanation would be necessary.\n\nFigure 1 should be made bigger.\n\nAn improvement of the paper that I could think about is a better discussion of the relevance of the findings. Yes, you do show that your sigma-delta network save some operation compared to threshold, but is this difference essential for a specific task, or does your solution has relevance for neuroscience? ", "title": "Significance of difference between rounding and sigma-delta", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "Bk4502Z4l": {"type": "review", "replyto": "HkNRsU5ge", "review": "I am a bit puzzled about the results shown in Figure 4. I guess for lambda=0 one should recover the original network so that all the data points should come together. Is that right? \n\nAlso, I guess the transformation of Horowitz must be non-linear for how would suddenly the difference at low lambda in the temporal MNIST goes to zero in the low lambda regime. Or is there another way to understand what is going on? \n\nI would have expected (and maybe you would have hoped for) a much more significant difference between Rounding and Sigma-Delta. Indeed, how significant is this?\n\nAnd finally, mainly curious, how would you say that these results change with scaling to larger networks?This is an interesting paper about quantized networks that work on temporal difference inputs.  The basic idea is that when a network has only to process differences then this is computational much more efficient specifically with natural video data since large parts of an image would be fairly constant so that the network only has to process the informative sections of the image (video stream). This is of course how the human visual system works, and it is hence of interest even beyond the core machine learning community. \n\nAs an aside, there is a strong community interested in event-based vision such as the group of Tobi Delbr\u00fcck, and it might be interesting to connect to this community. This might even provide a reference for your comments on page 1.\n\nI guess the biggest novel contribution is that a rounding network can be replaced by a sigma-delta network, but that the order of discretization and summation doe make some difference in the actual processing load. I think I followed the steps and \nMost of my questions have already been answers in the pre-review period. My only question remaining is on page 3, \u201cIt should be noted that when we refer to \u201ctemporal differences\u201d, we refer not to the change in the signal over time, but in the change between two inputs presented sequentially. The output of our network only depends on the value and order of inputs, not on the temporal spacing between them.\u201d\n\nThis does not make sense to me. As I understand you just take the difference between two frames regardless if you call this temporal or not it is a change in one frame. So this statement rather confuses me and maybe should be dropped unless I do miss something here, in which case some more explanation would be necessary.\n\nFigure 1 should be made bigger.\n\nAn improvement of the paper that I could think about is a better discussion of the relevance of the findings. Yes, you do show that your sigma-delta network save some operation compared to threshold, but is this difference essential for a specific task, or does your solution has relevance for neuroscience? ", "title": "Significance of difference between rounding and sigma-delta", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}}