{"paper": {"title": "Learning a Static Analyzer: A Case Study on a Toy Language", "authors": ["Manzil Zaheer", "Jean-Baptiste Tristan", "Michael L. Wick", "Guy L. Steele Jr."], "authorids": ["manzil.zaheer@cmu.edu", "jean.baptiste.tristan@oracle.com", "michael.wick@oracle.com", "guy.steele@oracle.com"], "summary": "", "abstract": "Static analyzers are meta-programs that analyze programs to detect\n  potential errors or collect information. For example, they are used\n  as security tools to detect potential buffer overflows. Also, they\n  are used by compilers to verify that a program is well-formed and\n  collect information to generate better code. In this paper, we\n  address the following question: can a static analyzer be learned\n  from data? More specifically, can we use deep learning to learn a\n  static analyzer without the need for complicated feature\n  engineering? We show that long short-term memory networks are able\n  to learn a basic static analyzer for a simple toy language. However,\n  pre-existing approaches based on feature engineering, hidden Markov\n  models, or basic recurrent neural networks fail on such a simple\n  problem. Finally, we show how to make such a tool usable by\n  employing a language model to help the programmer detect where the\n  reported errors are located.", "keywords": []}, "meta": {"decision": "Reject", "comment": "There is a general consensus that, though the idea is interesting, the work is not mature enough for a conference publication (e.g., the problem is too toy, not clear that really solves any, even artificial problem, better than existing techniques)."}, "review": {"B1xoF30me": {"type": "review", "replyto": "ry54RWtxx", "review": "The paper is very clear, I don't have any questions.The authors explore the idea of deep-learning a static analyzer. They do it with a toy programming language and a very simplified analysis problem -- just checking if all variables are initalized.\n\nWhile the idea is interesting and might be developped into a tool in the future, the toy task presented in this paper is too simple to warrant an ICLR submission. Just detecting whether a variable is initialized in a string is a toy algorihtmic task, similar to the ones solved in a number of paper in recent years by models such as the Neural Turing Machine, Stack RNNs, Neural GPU, or Differentiable Neural Computer. All these architectures perform almost perfectly on a number of algorithmic tasks, so it is highly probable that they would also solve this one. Unluckily, the authors only compare to much more basic models, such as HMMs. Since the code for many of the above-mentioned models is available online, a paper without these baselines is not ready for ICLR. Moreover, there is a risk that existing models already solve this problem very well, making the contribution unclear.", "title": "No questions, just making this message go away.", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "rkHNthR7x": {"type": "review", "replyto": "ry54RWtxx", "review": "The paper is very clear, I don't have any questions.The authors explore the idea of deep-learning a static analyzer. They do it with a toy programming language and a very simplified analysis problem -- just checking if all variables are initalized.\n\nWhile the idea is interesting and might be developped into a tool in the future, the toy task presented in this paper is too simple to warrant an ICLR submission. Just detecting whether a variable is initialized in a string is a toy algorihtmic task, similar to the ones solved in a number of paper in recent years by models such as the Neural Turing Machine, Stack RNNs, Neural GPU, or Differentiable Neural Computer. All these architectures perform almost perfectly on a number of algorithmic tasks, so it is highly probable that they would also solve this one. Unluckily, the authors only compare to much more basic models, such as HMMs. Since the code for many of the above-mentioned models is available online, a paper without these baselines is not ready for ICLR. Moreover, there is a risk that existing models already solve this problem very well, making the contribution unclear.", "title": "No questions, just making this message go away.", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "rkUVIk8Xe": {"type": "rebuttal", "replyto": "BJJuuASXx", "comment": "-- Motivation.\n\nAside from the comment that the motivation is unclear, I happen to\nagree with every point you make. As you point out, such a black box\nanalyzer would be useful if predictions were challenging. But before\nwe can tackle challenging program analysis problem, we have to tackle\nsimple ones. There have been a few papers recently that address\nproblems such as reversing a sequence or adding two integers. While we\nknow of deterministic and fast algorithms to do so, I find it very\ninteresting to understand how we can learn such algorithms and how far\nwe can go doing this. This is the spirit of the experiment we report\nin the paper. \n\n-- Related work.\n\nThanks for telling us about this work. I didn't yet know about it, but\nnote that it was published on arxiv a few days after we submitted our\npaper, so we can't be expected to have mentioned it. It seems like a\ngreat paper. At first glance it seems like unlike us, they attack a\nreal program analysis problem, and I find it very encouraging that\nthey get such good results. However, their approach is very different,\nas we're more interested in understanding the limits of black-box\nlearning for program analysis.", "title": "Re: Unclear motivation + Related work"}, "BJJuuASXx": {"type": "rebuttal", "replyto": "ry54RWtxx", "comment": "-- The motivation behind the work is somewhat unclear: by now, it is very well understood how to design analyzers and what sound/optimal means. Creating a ``black box'' analyzer that can make basic predictions (that are sometimes incorrect) without being able to modify it would be useful if the predictions were challenging and need not be sound all the time (like in some of the cited papers). Note that when analyzers are not sound there are typically clear  reasons for why this is so, e.g., dealing with native methods, frameworks, dynamic evaluation, etc. They are not unsound for 'random reasons'. \n\n-- There is also related work, already pointed out: the one of Hindle and others which already addresses what is in section 4.\n\n-- Here is also recent related work on learning (the transformers of the) static analyzers from data, one that is more elaborate as it learns the transformers of real analyzers and even finds real-world issues in Facebook's Flow: https://arxiv.org/abs/1611.01752", "title": "Unclear motivation + Related work"}, "BJQXcpBml": {"type": "rebuttal", "replyto": "H1MHizoGx", "comment": "Here's the result of a new experiment: we train on sentence of length\nup to 205 and then test on sentences of length between 206 and\n410. The results are:\n\nClassification task:\n\nAccuracy: 99.7% \nfalse positive: 0.4% \nfalse negative: 0.2% \n\n\nTransduction task:\n\nAccuracy:  99.9%\nfalse positive:  0.1%\nfalse negative:  0.1%\n\n\nHowever, our method does not generalize to previously unseen\nvariables. A key problem is that the input is token based, therefore a\npreviously unseen variable is just out-of-vocabulary. As a result the\nembedding of an unseen variable is random and interferes with the\nstate of the controller. We're not completely sure yet how to deal\nwith this problem. We might try to use a skip-gram embedding, process\nthe input at the charcater level, or modify the architecture to\ncapture some form of part-of-speech tagging. Another simple solution\nwould be to rename variables to make sure they all belong to the set\nof variables used at train time. Although practical, this solution is\nmuch less interesting from a learning perspective.", "title": "Re: Evaluating strong generalization?"}, "BkReiFEQx": {"type": "rebuttal", "replyto": "S1cMNnJXl", "comment": "\"Given a set data structure, isn't the task of finding uninitialized\nvariables fairly easy in the proposed language? You chase through the\ncode paths and put initialized variables in the set, and check the\nused variables against the set.\"\n\nYes, it is indeed a very simple problem. The difficulty here is that\nwe are learning the program analyzer purely from examples and directly\nfrom the tokens without feature engineering. Also, the LSTM needs to\nlearn to use the set data structure. It's a toy example in the same\nvein as adding integers or reversing sequences, but it is useful to\nunderstand what can be learned effectively.\n\n\"Why is doing this with an LSTM interesting? It's just some simple\nlogic... unless the LSTM is doing something with modeling the variable\nvalues (i.e., certain if statements could be mutually exclusive).. Not\nclear why this teaches us anything about LSTMs in more complex\nsituations.\"\n\nI agree that this paper doesn't teach much about LSTMs, but I hope it\ndoes say something about program analysis. Until recently, learning a\nprogram analyzer from examples might have seemed unrealistic: this is\nunderstandable given that other learning methods failed at it and\nrequired intricate feature engineering. Now, it is good to know that\nusing LSTM and differentiable data structure, it is possible to learn\na program analyzer for this task. It doesn't mean that program\nanalysis will be \"solved\" thanks to deep learning, but at least it\nshows that it doesn't obviously fail at it.", "title": "Re: Isn't using a differentiable set \"cheating\" in some sense?"}, "S1cMNnJXl": {"type": "review", "replyto": "ry54RWtxx", "review": "Given a set data structure, isn't the task of finding uninitialized variables fairly easy in the proposed language? You chase through the code paths and put initialized variables in the set, and check the used variables against the set.\n\nWhy is doing this with an LSTM interesting? It's just some simple logic... unless the LSTM is doing something with modeling the variable values (i.e., certain if statements could be mutually exclusive).. Not clear why this teaches us anything about LSTMs in more complex situations.The authors are trying to understand whether static analysis can be learned. As I hinted in my question, I think that all of the interesting complexity of static analysis has been removed in the toy language --- extraordinarily simple logic using a set can solve the problem posed, and an LSTM (unsurprisingly) can learn the extraordinarily simple logic (when given a differentiable set object). This extreme simplicity gives me no confidence that a more realistic static analysis problem can be solved.\n\nLSTMs (and deep learning) have had remarkable successes in solving messy real-world language problems. It's certainly possible that LSTMs could solve static analysis -- but being technically timid is not the right way to go about it.", "title": "Isn't using a differentiable set \"cheating\" in some sense?", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "ByjRiby4g": {"type": "review", "replyto": "ry54RWtxx", "review": "Given a set data structure, isn't the task of finding uninitialized variables fairly easy in the proposed language? You chase through the code paths and put initialized variables in the set, and check the used variables against the set.\n\nWhy is doing this with an LSTM interesting? It's just some simple logic... unless the LSTM is doing something with modeling the variable values (i.e., certain if statements could be mutually exclusive).. Not clear why this teaches us anything about LSTMs in more complex situations.The authors are trying to understand whether static analysis can be learned. As I hinted in my question, I think that all of the interesting complexity of static analysis has been removed in the toy language --- extraordinarily simple logic using a set can solve the problem posed, and an LSTM (unsurprisingly) can learn the extraordinarily simple logic (when given a differentiable set object). This extreme simplicity gives me no confidence that a more realistic static analysis problem can be solved.\n\nLSTMs (and deep learning) have had remarkable successes in solving messy real-world language problems. It's certainly possible that LSTMs could solve static analysis -- but being technically timid is not the right way to go about it.", "title": "Isn't using a differentiable set \"cheating\" in some sense?", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "H1MHizoGx": {"type": "rebuttal", "replyto": "Ska_o0Fzx", "comment": "1. This is a very good suggestion. We will run new experiments to test\ngeneralization for longer programs and an extended set of\nvariables. As a side note, we would like to mention that we just\nupdated our paper with results on an experiment using differentiable\ndata structures. Our hope is that the policy learned by the network\nwill indeed generalize well.\n\n2. The threshold was chosen by looking at a few examples, and it is\nindeed optimizing the presented example. We usually use a scale of\ncolors to indicate whether a variable might have been uninitialized\nbut for clarity we use a two color scheme in the paper. We haven't\nconsidered doing a more quantitative evaluation of that component. We\nthink it would be a good thing to do, but in the context of this paper\nour goal was mainly to address the concern of programmer feedback and\nshow that it is possible to interpret to some extent why a decision\nwas made.\n\nThank you for the reference, it is indeed interesting and we will\nupdate the paper accordingly.", "title": "Re: Evaluating strong generalization?"}, "Ska_o0Fzx": {"type": "review", "replyto": "ry54RWtxx", "review": "Two questions:\n\n1. It seems very hard to generate a dataset of ~200k programs that have all the variability that one would expect to find in real source code. Thus, it would be desirable to use models that exhibit strong generalization (i.e., they generalize well even when test data is systematically different from training data). For example, one might hope that even if the learned static analyzer were run on a program that was much longer and used more identifiers than any program seen during training, the system would still perform well. Have you considered evaluating models in terms of stronger types of generalization?\n\n2. How is the threshold used to color figure 3 chosen? Was it chosen to optimize performance on that example? Have you considered building a quantitative evaluation for that component?\n\n\nAlso, you may be interested in the following citation, which also uses a trained language model to localize errors in code:\nCampbell, Joshua Charles, Abram Hindle, and Jos\u00e9 Nelson Amaral. \"Syntax errors just aren't natural: improving error reporting with language models.\" Proceedings of the 11th Working Conference on Mining Software Repositories. ACM, 2014.This paper takes a first step towards learning to statically analyze source code. It develops a simple toy programming language that includes loops and branching. The aim is to determine whether all variables in the program are defined before they are used. The paper tries a variety of off-the-shelf sequence classification models and develops a new model that makes use of a ``differentiable set'' to keep track of which variables have been defined so far. Result show that an LSTM model can achieve 98% accuracy, and the differentiable set model can achieve 99.3% accuracy with sequence-level supervision and 99.7% accuracy with strong token-level supervision. An additional result is used whereby an LSTM language model is trained over correct code, and then low probability (where a threshold to determine low is tuned by hand) tokens are highlighted as sources of possible error.\n\nOne further question is if the authors could clarify what reasoning patterns are needed to solve these problems. Does the model need to, e.g., statically determine whether an `if` condition can ever evaluate to true in order to solve these tasks? Or is it just as simple as checking whether a variable appears on a LHS before it appears on a RHS later in the textual representation of the program?\n\nStrengths:\n- Learning a static analyzer is an interesting concept, and I think there is good potential for this line of work\n- The ability to determine whether variables are defined before they are used is certainly a prerequisite for more complicated static analysis.\n- The experimental setup seems reasonable\n- The differentiable set seems like a useful (albeit simple) modelling tool\n\nWeaknesses:\n- The setup is very toy, and it's not clear to me that this makes much progress towards the challenges that would arise if one were trying to learn a static analyzer \n- The models are mostly very simple. The one novelty on the modelling front (the differentiable set) provides a small win on this task, but it's not clear if it is a useful general construct or not.\n\nOverall:\nI think it's an interesting start, and I'm eager to see how this line of work progresses. In my opinion, it's a bit too early to accept this work to ICLR, but I'd be excited about seeing what happens as the authors try to push the system to learn to analyze more properties of code, and as they push towards scenarios where the learned static analyzer would be useful, perhaps leveraging strengths of machine learning that are not available to standard programming languages analyses.", "title": "Evaluating strong generalization?", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "BJqhp5-Eg": {"type": "review", "replyto": "ry54RWtxx", "review": "Two questions:\n\n1. It seems very hard to generate a dataset of ~200k programs that have all the variability that one would expect to find in real source code. Thus, it would be desirable to use models that exhibit strong generalization (i.e., they generalize well even when test data is systematically different from training data). For example, one might hope that even if the learned static analyzer were run on a program that was much longer and used more identifiers than any program seen during training, the system would still perform well. Have you considered evaluating models in terms of stronger types of generalization?\n\n2. How is the threshold used to color figure 3 chosen? Was it chosen to optimize performance on that example? Have you considered building a quantitative evaluation for that component?\n\n\nAlso, you may be interested in the following citation, which also uses a trained language model to localize errors in code:\nCampbell, Joshua Charles, Abram Hindle, and Jos\u00e9 Nelson Amaral. \"Syntax errors just aren't natural: improving error reporting with language models.\" Proceedings of the 11th Working Conference on Mining Software Repositories. ACM, 2014.This paper takes a first step towards learning to statically analyze source code. It develops a simple toy programming language that includes loops and branching. The aim is to determine whether all variables in the program are defined before they are used. The paper tries a variety of off-the-shelf sequence classification models and develops a new model that makes use of a ``differentiable set'' to keep track of which variables have been defined so far. Result show that an LSTM model can achieve 98% accuracy, and the differentiable set model can achieve 99.3% accuracy with sequence-level supervision and 99.7% accuracy with strong token-level supervision. An additional result is used whereby an LSTM language model is trained over correct code, and then low probability (where a threshold to determine low is tuned by hand) tokens are highlighted as sources of possible error.\n\nOne further question is if the authors could clarify what reasoning patterns are needed to solve these problems. Does the model need to, e.g., statically determine whether an `if` condition can ever evaluate to true in order to solve these tasks? Or is it just as simple as checking whether a variable appears on a LHS before it appears on a RHS later in the textual representation of the program?\n\nStrengths:\n- Learning a static analyzer is an interesting concept, and I think there is good potential for this line of work\n- The ability to determine whether variables are defined before they are used is certainly a prerequisite for more complicated static analysis.\n- The experimental setup seems reasonable\n- The differentiable set seems like a useful (albeit simple) modelling tool\n\nWeaknesses:\n- The setup is very toy, and it's not clear to me that this makes much progress towards the challenges that would arise if one were trying to learn a static analyzer \n- The models are mostly very simple. The one novelty on the modelling front (the differentiable set) provides a small win on this task, but it's not clear if it is a useful general construct or not.\n\nOverall:\nI think it's an interesting start, and I'm eager to see how this line of work progresses. In my opinion, it's a bit too early to accept this work to ICLR, but I'd be excited about seeing what happens as the authors try to push the system to learn to analyze more properties of code, and as they push towards scenarios where the learned static analyzer would be useful, perhaps leveraging strengths of machine learning that are not available to standard programming languages analyses.", "title": "Evaluating strong generalization?", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}}