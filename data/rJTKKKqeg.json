{"paper": {"title": "Tracking the World State with Recurrent Entity Networks", "authors": ["Mikael Henaff", "Jason Weston", "Arthur Szlam", "Antoine Bordes", "Yann LeCun"], "authorids": ["mbh305@nyu.edu", "jase@fb.com", "azslam@fb.com", "abordes@fb.com", "yann@fb.com"], "summary": "A new memory-augmented model which learns to track the world state, obtaining SOTA on the bAbI tasks amongst other results.", "abstract": "We introduce a new model, the Recurrent Entity Network (EntNet). It is equipped\nwith a dynamic long-term memory which allows it to maintain and update a rep-\nresentation of the state of the world as it receives new data. For language under-\nstanding tasks, it can reason on-the-fly as it reads text, not just when it is required\nto answer a question or respond as is the case for a Memory Network (Sukhbaatar\net al., 2015). Like a Neural Turing Machine or Differentiable Neural Computer\n(Graves et al., 2014; 2016) it maintains a fixed size memory and can learn to\nperform location and content-based read and write operations. However, unlike\nthose models it has a simple parallel architecture in which several memory loca-\ntions can be updated simultaneously. The EntNet sets a new state-of-the-art on\nthe bAbI tasks, and is the first method to solve all the tasks in the 10k training\nexamples setting. We also demonstrate that it can solve a reasoning task which\nrequires a large number of supporting facts, which other methods are not able to\nsolve, and can generalize past its training horizon. It can also be practically used\non large scale datasets such as Children\u2019s Book Test, where it obtains competitive\nperformance, reading the story in a single pass.", "keywords": ["Natural language processing", "Deep learning"]}, "meta": {"decision": "Accept (Poster)", "comment": "Reviewers found this work to be a \"well-motivated\", \"good contribution\", and \"clever\". The idea was clearly conveyed and reviewers were convinced that the approach was simpler than others like NTMs. Experiments are sufficient, and the work will likely be used in the future. \n \n Pros:\n - Well-explained and expected to be widely implemented\n - Experimental results convincing on the tasks.\n \n Cons:\n - Several questions about \"generalization to some unseen entities\". \n - Reliance on synthetic tasks unclear if \"scalable to complex real tasks\"\n - Training process seems quite complicated (although again simpler that NTMs)"}, "review": {"SJ0rnJ0Pl": {"type": "rebuttal", "replyto": "rJTKKKqeg", "comment": "1) When you first train on the bAbi tasks, do you train on all the tasks simultaneously and test simultaneously or do you train and test each task individually?", "title": "Question on Training bAbI"}, "SJymuqMUl": {"type": "rebuttal", "replyto": "HkLyMxLVx", "comment": "Thank you for the review! To answer your questions:\n\n1. The f_i vectors are fixed to be the same size as the embedding dimension, which is d=20 for the world model experiments and d=100 for the others. The number of f_i vectors is equal to the maximum sentence/window length. For the bAbI tasks this was typically between 5 and 10 (depending on the task), for the CBT experiments it was 5 and for the world model experiments it was 4. So, the words in a sentence or window are embedded, each word embedding is then multiplied pointwise with the corresponding f_i vector, and the resulting vectors are summed to produce a single vector representing the entire sentence or window.  \n\n2. Yes, we will release the source code in the near future, so that others can reproduce the results. ", "title": "Re: Reviewer 3"}, "SJtfb5zIx": {"type": "rebuttal", "replyto": "H1K9R08Eg", "comment": "Thank you for the comment. For both the LSTM and the EntNet, the set of possible answers is restricted to the candidate set at test time. In the case of the EntNet, since there is no interaction between the different memory slots, even if we made more memories for words that were not candidates (for example, one memory slot per word in the vocabulary), this would not affect the final result since the set of possible answers is restricted to the candidate set at test time. Restricting the set of memories to the candidates does not change performance and is simply a computational speedup. ", "title": "Re: Single-pass models"}, "rkTglOg8l": {"type": "rebuttal", "replyto": "rJTKKKqeg", "comment": "Hi authors, \n\nHave you had a chance to read over the reviews and the anonymous comments posted? If you have any rebuttals this would be a great chance to add them to the discussion.\n\nThanks!", "title": "Authors: Any rebuttal comments?"}, "H1K9R08Eg": {"type": "rebuttal", "replyto": "rJTKKKqeg", "comment": "I am not entirely sure that the comparison between LSTM and EntityNet that you make is fair. You call both LSTM and EntityNet \"single-pass\" models, as opposed to \"multi-pass\" models with attention. However, thanks to the weight-tying that you employ, EntityNet knows what the candidate answers are when it reads the context. I think that this alone gives it a huge advantage over LSTM. Can you please comment on that?", "title": "Single-pass models"}, "ryWXk3nQl": {"type": "rebuttal", "replyto": "rJTKKKqeg", "comment": "Dear all, \n\nWe have updated the paper with the following changes:\n\n- Specified error ranges for tables in Section 5.1.\n- Added NTM results to main table in Section 5.2.\n- Separated world model visualization table in Section 5.2 into two separate tables. \n- Added CBT results for general EntNet to table in Section 5.3\n- Added note in Appendix C specifying the experiments are designed to better understand effect of architecture and weight tying. \n- Added note to Section 3 about how weight tying can be used to handle unseen entities.\n\nPlease let us know if you have any other questions or comments. \n\nThanks!", "title": "Paper update"}, "Sk4VWZVQe": {"type": "rebuttal", "replyto": "SJJAOvyQe", "comment": "1. We did not experiment with using a POS tagger ourselves. However, in the CBT experiments we tied the key vectors to the embeddings of the words occurring in the candidate set, which were originally chosen using a POS tagger when the dataset was constructed.\n\n2. Yes, it is possible that there could be a different number of entities in the training and testing sets. Entities not occurring in the testing data could have their memory slots removed, which might help performance. One strategy for dealing with entities occurring in the test set but not the training set would be to add memory slots for these entities and initialize the word embeddings/key vectors with embeddings trained on a larger corpus.\n\n", "title": "Re: Question about entity"}, "rybk5X7Xg": {"type": "rebuttal", "replyto": "SJzcDl0fx", "comment": "Good question! We checked in the case using BoW encoding and untied keys, and found that the embedding for a given entity was often close to more than one key vector (in terms of cosine distance). We also plotted gate activations and found that more than 2 or 3 gates can open at a time (for the examples we looked at, up to 7). This suggests that the model is storing information distributed across several memory slots. ", "title": "Re: Interpretability"}, "S1mc_XXmg": {"type": "rebuttal", "replyto": "S1MO6B17g", "comment": "Thank you for your helpful feedback. To answer your questions:\n\n1. Yes, in Tables 1 and 2 the error ranges from 0 to 1. We will make this clear.\n\n2. Thank you for pointing this out, we will add the NTM results to the table.\n\n3. We will make the change to the figure.\n\n4. We will run this experiment and add the results to the paper soon.\n\n5. We included the results comparing EntNet to MemN2N using the exact same BoW encoding to help understand the effects of the model architecture while keeping the encoder fixed. Since none of the other published models shown in Table 3 use simple BoW (which is generally less effective than other encoding schemes), we felt it would be confusing to include the results with BoW encoding in Table 3. We view Table 3 as the \u201cbest results\u201d for each model architecture, and Table 6 as an ablation study to understand the effects of architecture and weight tying. We will clarify this distinction in the paper.\n\n6. With our current implementation, the EntNet takes about 3x longer to train than a MemN2N. We very much agree that trying different initializations is a suboptimal approach, and we are currently investigating the variance problem. However, this is a common issue with models evaluated on the bAbI tasks and not specific to our model (all models reported in Table 3 except D-NTM select the best out of 10 or more runs). \n", "title": "Re: Few questions"}, "SJJAOvyQe": {"type": "review", "replyto": "rJTKKKqeg", "review": "1. The paper mentioned it could use POS tagging to define entities for finding entities. Have you tried it for some experiments/cases? \n2. If the entities are extracted from data, would there be different number of entities for a testing data? Then the length of your hidden state h_j would be varied based on the data. The paper proposed a multi-memory mechanism that memorizes different information into different components/entities. It could be considered as a mixture model in RNN. This is a very interesting model and result is convincing.\n\nA limitation is that we do not know how to generalize to some unseen entities and how to visualize what entities the model learned.", "title": "Question about entity", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "rk7ROfU4e": {"type": "review", "replyto": "rJTKKKqeg", "review": "1. The paper mentioned it could use POS tagging to define entities for finding entities. Have you tried it for some experiments/cases? \n2. If the entities are extracted from data, would there be different number of entities for a testing data? Then the length of your hidden state h_j would be varied based on the data. The paper proposed a multi-memory mechanism that memorizes different information into different components/entities. It could be considered as a mixture model in RNN. This is a very interesting model and result is convincing.\n\nA limitation is that we do not know how to generalize to some unseen entities and how to visualize what entities the model learned.", "title": "Question about entity", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "S1MO6B17g": {"type": "review", "replyto": "rJTKKKqeg", "review": "1. Error values in tables 1 and 2 range from 0 to 1 or 0 to 100? I can guess that it is from 0 to 1, but good to make it explicit in the caption.\n2. You say that you report NTM results in Table 3, but it is missing.\n3. Can you please modify table 4 and make the story part and key/NN part two separate figures or tables? My initial impression from the table was that for each line in the story you have a key/NN. It is quite confusing.\n4. For CBT, authors say that setting U=V=0 and W=I helps. What is the performance of the general EntNet without these changes? Is it too worse? I think it is good to report those numbers as well.\n5. I think EntNet+BoW results should go to Table 3 (and not to appendix). In table 3, all the models are not exactly comparable since different models use different encoder representations. So authors should report the performance of EntNet with proposed encoder representation and EntNet with BoW encoder representation in the main table itself.\n6. How much time does it take to train EntNet on babi tasks? 10 runs with different initialization for all tasks seems to be too much for me. It is worth investigating and solving the variance problem than simply increasing the computation.This paper proposes a new memory augmented neural network (MANN) model called recurrent entity network (EntNet). EntNet can be considered as a bank of RNNs with gating mechanism to update the hidden states of the RNNs and the hidden states act like the memory slots. The model is very much relevant to NTM style architectures. It is known that training the controller in NTM to read/write from memory slots is challenging. EntNet cleverly pushes the complexity of the controller to individual memory slots. It is as if each slot has a controller and they all act in a distributed manner.\n\nAuthors report strong results in bAbI tasks where the model achieves state of the art performance. Synthetic world experiments justify that the model learns to capture the world dynamics. However it is not clear if this will be scalable to complex real tasks. EntNet also achieves reasonable performance with one-shot reading of the passage in CBT task.\n\nI see EntNet as a generalization of RNNs and has some advantage over NTMs when it comes to training complexity. This is definitely a good contribution to the conference. I see that EntNet can have several other applications in future.\n\nAuthors have provided convincing answers to my pre-review questions.\n\nFew more questions:\n1. Do you fix the size of the f vector set in equation (1)? If so, to what size in all the experiments?\n2. There are so many training details in the paper which makes it difficult to reproduce the results. Can the authors release the source code to reproduce all the results in the paper? I am willing to increase my rating if authors can release the code.\n", "title": "Few questions", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "HkLyMxLVx": {"type": "review", "replyto": "rJTKKKqeg", "review": "1. Error values in tables 1 and 2 range from 0 to 1 or 0 to 100? I can guess that it is from 0 to 1, but good to make it explicit in the caption.\n2. You say that you report NTM results in Table 3, but it is missing.\n3. Can you please modify table 4 and make the story part and key/NN part two separate figures or tables? My initial impression from the table was that for each line in the story you have a key/NN. It is quite confusing.\n4. For CBT, authors say that setting U=V=0 and W=I helps. What is the performance of the general EntNet without these changes? Is it too worse? I think it is good to report those numbers as well.\n5. I think EntNet+BoW results should go to Table 3 (and not to appendix). In table 3, all the models are not exactly comparable since different models use different encoder representations. So authors should report the performance of EntNet with proposed encoder representation and EntNet with BoW encoder representation in the main table itself.\n6. How much time does it take to train EntNet on babi tasks? 10 runs with different initialization for all tasks seems to be too much for me. It is worth investigating and solving the variance problem than simply increasing the computation.This paper proposes a new memory augmented neural network (MANN) model called recurrent entity network (EntNet). EntNet can be considered as a bank of RNNs with gating mechanism to update the hidden states of the RNNs and the hidden states act like the memory slots. The model is very much relevant to NTM style architectures. It is known that training the controller in NTM to read/write from memory slots is challenging. EntNet cleverly pushes the complexity of the controller to individual memory slots. It is as if each slot has a controller and they all act in a distributed manner.\n\nAuthors report strong results in bAbI tasks where the model achieves state of the art performance. Synthetic world experiments justify that the model learns to capture the world dynamics. However it is not clear if this will be scalable to complex real tasks. EntNet also achieves reasonable performance with one-shot reading of the passage in CBT task.\n\nI see EntNet as a generalization of RNNs and has some advantage over NTMs when it comes to training complexity. This is definitely a good contribution to the conference. I see that EntNet can have several other applications in future.\n\nAuthors have provided convincing answers to my pre-review questions.\n\nFew more questions:\n1. Do you fix the size of the f vector set in equation (1)? If so, to what size in all the experiments?\n2. There are so many training details in the paper which makes it difficult to reproduce the results. Can the authors release the source code to reproduce all the results in the paper? I am willing to increase my rating if authors can release the code.\n", "title": "Few questions", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "SJzcDl0fx": {"type": "review", "replyto": "rJTKKKqeg", "review": "I really enjoyed the visualization in Table 4. Have you checked key vectors in the case where you do not explicitly tie them to see if there is anything interpretable still, e.g. by looking at which s_t activates which w_j? Or is it mostly distributed and does not focus to a single concept/topic/entity?The work proposes a variant of a recurrent neural network that can selectively update a fixed number of multiple memory slots to update entity states.\n\nThe architecture is well motivated, especially with the motivating example, and the operation is shown to validate the intuition as shown in visualizations.\n\nExperimental results, datasets and the baselines used are sufficient to quantitatively show the strength of the proposed architecture.\n\nA limitation is failing to (explicitly) generalize to unseen entities, however this is not a trivial problem on its own and the authors have addressed to this issue and proposed several ideas as workarounds.\n\nI consider the work as a good conference contribution.", "title": "Interpretability", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "Sy9rRTHEg": {"type": "review", "replyto": "rJTKKKqeg", "review": "I really enjoyed the visualization in Table 4. Have you checked key vectors in the case where you do not explicitly tie them to see if there is anything interpretable still, e.g. by looking at which s_t activates which w_j? Or is it mostly distributed and does not focus to a single concept/topic/entity?The work proposes a variant of a recurrent neural network that can selectively update a fixed number of multiple memory slots to update entity states.\n\nThe architecture is well motivated, especially with the motivating example, and the operation is shown to validate the intuition as shown in visualizations.\n\nExperimental results, datasets and the baselines used are sufficient to quantitatively show the strength of the proposed architecture.\n\nA limitation is failing to (explicitly) generalize to unseen entities, however this is not a trivial problem on its own and the authors have addressed to this issue and proposed several ideas as workarounds.\n\nI consider the work as a good conference contribution.", "title": "Interpretability", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "rykiPj7Me": {"type": "rebuttal", "replyto": "BJFtxpdbl", "comment": "Thank you for your comment. The untied model assumes that the training and test sets are drawn from the same distribution. However, the tied model can be applied to cases with entities unseen during training, if the type of entity is known beforehand to be important for the task. For example, one could use a part-of-speech tagger to return a list of nouns in the story at test time, and tie memory keys to their embeddings. Word embeddings could be pre-trained on a larger corpus to cover words not occurring in the training set, as is usually done. \n\n\nNote that in the CBT experiments, there are entities which occur in the test set and not the training set. In that task, candidates are given which allow us to know beforehand which words to record information about. These could also be produced with a part-of-speech tagger (which is in fact used to construct the dataset in the first place) or another method.", "title": "Re: Nature of keys"}, "BJFtxpdbl": {"type": "rebuttal", "replyto": "rJTKKKqeg", "comment": "It's a nice and clean paper that is easy to understand. I am however still not clear about the notion of having separate learned keys for each entity cell. It seems clear that keys, w_j, are important in storing the entity information; but how do these keys generalize to new entities? E.g. if the model is only trained on data with entities John, Mary, and Jim, and during testing we have a new entity Michael, how would it match any of the keys? The paper mentions that the key parameters are obtained during learning and fixed during inference (except for the \"tied\" case but that is not used in any comparative experiments), so the explanation on section 3 paragraph 2 (One choice the model could make is to associate...) also does not seem sufficient. What am I missing?\n\n", "title": "Nature of keys"}}}