{"paper": {"title": "A Way out of the Odyssey: Analyzing and Combining Recent Insights for LSTMs", "authors": ["Shayne Longpre", "Sabeek Pradhan", "Caiming Xiong", "Richard Socher"], "authorids": ["slongpre@cs.stanford.edu", "sabeekp@cs.stanford.edu", "cxiong@salesforce.com", "rsocher@salesforce.com"], "summary": "Relatively simple augmentations to the LSTM, such as Monte Carlo test time averaging, deep vector averaging, and residual connections, can yield massive accuracy improvements on text classification datasets.", "abstract": "LSTMs have become a basic building block for many deep NLP models. In recent years, many improvements and variations have been proposed for deep sequence models in general, and LSTMs in particular. We propose and analyze a series of architectural modifications for LSTM networks resulting in improved performance for text classification datasets. We observe compounding improvements on traditional LSTMs using Monte Carlo test-time model averaging, deep vector averaging (DVA), and residual connections, along with four other suggested modifications. Our analysis provides a simple, reliable, and high quality baseline model.", "keywords": ["Natural language processing", "Deep learning", "Supervised Learning"]}, "meta": {"decision": "Reject", "comment": "The paper attempts to perform an interesting exploration (how to combine different tricks for LSTM training) but does not take it far enough. \n \n Pros:\n - interesting attempt at studying different techniques to improve LSTM training results\n Cons:\n - not very strong baselines\n - limited set of domains were explored\n - low in novelty (which wouldn't be a problem if the comparison was more thorough -- see above 2 points)."}, "review": {"HJhLKpWEx": {"type": "rebuttal", "replyto": "ry_bEmsXx", "comment": "This is a great point, and one we plan to explore in the near future, probably starting with language modeling. Our focus in this paper was simply to establish a number of techniques which showed statistically relevant and compounding improvements on a simple, yet highly competitive (read: benchmarked) task. These \u201cenhancements\u201d are also intended for \u2018baseline\u2019, deep models, or to be used in conjunction (since we show their ability to effectively compound improvements) with whatever other techniques one is experimenting with for classification. We did however intentionally choose two quite distinct sentiment classification datasets, in their makeup, to verify that our best techniques were effective across quite different forms of text data. SST and IMDB\u2019s examples differ quite markedly from each other on their length, the detail of the descriptions, grammar and degree to which they\u2019ve been sanitized. Of the SST training examples (including the sub-phrases) their mean and standard deviation for length are 19.14 and 9.31 respectively, whereas for IMDB they are 279.93 and 207.87 respectively. SST is also fine-grain while IMDB is coarse-grain. Lastly, SST examples are usually single sentences, cleanly written and grammatically correct, whereas IMDB examples are littered with \u201c<br />\u201d, email addresses, mid-sentence punctuation (usually for emphasis) and other such colloquial features. \n\nWe absolutely intend to further our research with these techniques into other tasks, as next steps, though felt that the datasets provided were ample to show their efficacy for text classification as a whole. This more narrow focus also gave us the capacity to delve deeper into all the alternative implementations of these techniques (a great deal of failed experimentation not shown) and determine what actually are the most effective off-the-shelf enhancements for baseline deep classification models.", "title": "Choice of Datasets/Tasks"}, "HkFXypZ4l": {"type": "rebuttal", "replyto": "ryQKQ7iml", "comment": "Point taken. Sorry if some of the terms we used were confusing or ambiguous. We acknowledge that deep vector averaging and Monte Carlo model averaging aren't modifications to the LSTM cell itself. Originally, when we talked about \"architectural modifications\", we didn't intend it to mean architectural modifications just to the LSTM cell itself but rather to the entire model (\"LSTM network\"), which includes the LSTM cell, the procedure for stacking layers, and the inference method. We've changed the wording to clear up this ambiguity. \n\nAnd you're right that in principle you could use an MLP of any size for our deep vector averaging; after some experimentation, we ultimately used an MLP with a single layer and a hidden dimension of size 300. We initially chose to use the term \"deep\" to indicate that we were using not the vector average itself but rather the output of a network using that average as input. However, we have renamed it to \"embed average pooling,\" which we hope is better at conveying what the method does.", "title": "Clarification and modification re terms used in the paper"}, "ryQKQ7iml": {"type": "review", "replyto": "rJsiFTYex", "review": "I find some \"key\" terms not proper. It would be great if you can explain more. \n\n1. You said that you proposed a series of architectural modifications for LSTM networks. But in fact many of them are not \"architectural modifications\". In the Monte Carlo model averaging, you didn't change the model at all. What you did is to use a different method for inference. In Deep vector averaging, what you did is to simply combine an LSTM network with a MLP at the (pre)-output layer, you thus didn't modify the LSTM architecture. \n\n2. \"Deep vector averaging\": I was wondering if you are abusing the term \"deep\". Basically any MLPs can be used in spite of their depth. Can you also report the size of the MLPs you used? The paper proposes and analyses three methods applied to traditional LSTMs: Monte Carlo test-time model averaging, average pooling, and residual connections. It shows that those methods help to enhance traditional LSTMs on sentiment analysis. \n\nAlthough the paper is well written, the experiment section is definitely its dead point. Firstly, although it shows some improvements over traditional LSTMs, those results are not on par with the state of the art. Secondly, if the purpose is to take those extensions as strong baselines for further research, the experiments are not adequate: the both two datasets which were used are quite similar (though they have different statistics). I thus suggest to carry out more experiments on more diverse tasks, like those in \"LSTM: A Search Space Odyssey\"). \n\nBesides, those extensions are not really novel.", "title": "terms used in the paper", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "rJLoZtr4g": {"type": "review", "replyto": "rJsiFTYex", "review": "I find some \"key\" terms not proper. It would be great if you can explain more. \n\n1. You said that you proposed a series of architectural modifications for LSTM networks. But in fact many of them are not \"architectural modifications\". In the Monte Carlo model averaging, you didn't change the model at all. What you did is to use a different method for inference. In Deep vector averaging, what you did is to simply combine an LSTM network with a MLP at the (pre)-output layer, you thus didn't modify the LSTM architecture. \n\n2. \"Deep vector averaging\": I was wondering if you are abusing the term \"deep\". Basically any MLPs can be used in spite of their depth. Can you also report the size of the MLPs you used? The paper proposes and analyses three methods applied to traditional LSTMs: Monte Carlo test-time model averaging, average pooling, and residual connections. It shows that those methods help to enhance traditional LSTMs on sentiment analysis. \n\nAlthough the paper is well written, the experiment section is definitely its dead point. Firstly, although it shows some improvements over traditional LSTMs, those results are not on par with the state of the art. Secondly, if the purpose is to take those extensions as strong baselines for further research, the experiments are not adequate: the both two datasets which were used are quite similar (though they have different statistics). I thus suggest to carry out more experiments on more diverse tasks, like those in \"LSTM: A Search Space Odyssey\"). \n\nBesides, those extensions are not really novel.", "title": "terms used in the paper", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}}}